I0401 16:54:15.511200      16 test_context.go:405] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-994794615
I0401 16:54:15.511322      16 e2e.go:240] Starting e2e run "c7e07883-549e-11e9-871e-828ee0b576f8" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1554137654 - Will randomize all specs
Will run 204 of 3584 specs

Apr  1 16:54:15.644: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
Apr  1 16:54:15.649: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Apr  1 16:54:15.662: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Apr  1 16:54:15.701: INFO: 6 / 6 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Apr  1 16:54:15.701: INFO: expected 6 pod replicas in namespace 'kube-system', 6 are Running and Ready.
Apr  1 16:54:15.701: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Apr  1 16:54:15.710: INFO: e2e test version: v1.14.0
Apr  1 16:54:15.712: INFO: kube-apiserver version: v1.14.0
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 16:54:15.712: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename configmap
Apr  1 16:54:15.749: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-c8893bfa-549e-11e9-871e-828ee0b576f8
STEP: Creating a pod to test consume configMaps
Apr  1 16:54:15.778: INFO: Waiting up to 5m0s for pod "pod-configmaps-c88bc74f-549e-11e9-871e-828ee0b576f8" in namespace "configmap-4940" to be "success or failure"
Apr  1 16:54:15.783: INFO: Pod "pod-configmaps-c88bc74f-549e-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.704458ms
Apr  1 16:54:17.787: INFO: Pod "pod-configmaps-c88bc74f-549e-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009655546s
Apr  1 16:54:19.792: INFO: Pod "pod-configmaps-c88bc74f-549e-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01416418s
STEP: Saw pod success
Apr  1 16:54:19.792: INFO: Pod "pod-configmaps-c88bc74f-549e-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 16:54:19.795: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-configmaps-c88bc74f-549e-11e9-871e-828ee0b576f8 container configmap-volume-test: <nil>
STEP: delete the pod
Apr  1 16:54:19.841: INFO: Waiting for pod pod-configmaps-c88bc74f-549e-11e9-871e-828ee0b576f8 to disappear
Apr  1 16:54:19.844: INFO: Pod pod-configmaps-c88bc74f-549e-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 16:54:19.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4940" for this suite.
Apr  1 16:54:25.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 16:54:26.047: INFO: namespace configmap-4940 deletion completed in 6.199368626s

• [SLOW TEST:10.335 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 16:54:26.047: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-ceb1c3e3-549e-11e9-871e-828ee0b576f8
STEP: Creating a pod to test consume secrets
Apr  1 16:54:26.101: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ceb35ee7-549e-11e9-871e-828ee0b576f8" in namespace "projected-3770" to be "success or failure"
Apr  1 16:54:26.106: INFO: Pod "pod-projected-secrets-ceb35ee7-549e-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.517212ms
Apr  1 16:54:28.111: INFO: Pod "pod-projected-secrets-ceb35ee7-549e-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009278303s
Apr  1 16:54:30.115: INFO: Pod "pod-projected-secrets-ceb35ee7-549e-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013788621s
STEP: Saw pod success
Apr  1 16:54:30.115: INFO: Pod "pod-projected-secrets-ceb35ee7-549e-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 16:54:30.120: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-projected-secrets-ceb35ee7-549e-11e9-871e-828ee0b576f8 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr  1 16:54:30.142: INFO: Waiting for pod pod-projected-secrets-ceb35ee7-549e-11e9-871e-828ee0b576f8 to disappear
Apr  1 16:54:30.146: INFO: Pod pod-projected-secrets-ceb35ee7-549e-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 16:54:30.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3770" for this suite.
Apr  1 16:54:36.163: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 16:54:36.325: INFO: namespace projected-3770 deletion completed in 6.175363994s

• [SLOW TEST:10.277 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 16:54:36.325: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  1 16:54:36.359: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 16:54:40.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6919" for this suite.
Apr  1 16:55:20.495: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 16:55:20.604: INFO: namespace pods-6919 deletion completed in 40.122477318s

• [SLOW TEST:44.279 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 16:55:20.604: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0401 16:55:51.180014      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr  1 16:55:51.180: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 16:55:51.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-999" for this suite.
Apr  1 16:55:57.197: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 16:55:57.308: INFO: namespace gc-999 deletion completed in 6.124558054s

• [SLOW TEST:36.704 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 16:55:57.308: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Apr  1 16:55:57.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 create -f - --namespace=kubectl-5881'
Apr  1 16:55:57.836: INFO: stderr: ""
Apr  1 16:55:57.836: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Apr  1 16:55:58.841: INFO: Selector matched 1 pods for map[app:redis]
Apr  1 16:55:58.841: INFO: Found 0 / 1
Apr  1 16:55:59.841: INFO: Selector matched 1 pods for map[app:redis]
Apr  1 16:55:59.841: INFO: Found 0 / 1
Apr  1 16:56:00.840: INFO: Selector matched 1 pods for map[app:redis]
Apr  1 16:56:00.840: INFO: Found 1 / 1
Apr  1 16:56:00.840: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Apr  1 16:56:00.844: INFO: Selector matched 1 pods for map[app:redis]
Apr  1 16:56:00.844: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr  1 16:56:00.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 patch pod redis-master-n4j5p --namespace=kubectl-5881 -p {"metadata":{"annotations":{"x":"y"}}}'
Apr  1 16:56:00.931: INFO: stderr: ""
Apr  1 16:56:00.931: INFO: stdout: "pod/redis-master-n4j5p patched\n"
STEP: checking annotations
Apr  1 16:56:00.934: INFO: Selector matched 1 pods for map[app:redis]
Apr  1 16:56:00.934: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 16:56:00.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5881" for this suite.
Apr  1 16:56:22.951: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 16:56:23.078: INFO: namespace kubectl-5881 deletion completed in 22.139985264s

• [SLOW TEST:25.770 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 16:56:23.078: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  1 16:56:23.151: INFO: (0) /api/v1/nodes/ip-172-31-22-24/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 28.532329ms)
Apr  1 16:56:23.156: INFO: (1) /api/v1/nodes/ip-172-31-22-24/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.763766ms)
Apr  1 16:56:23.162: INFO: (2) /api/v1/nodes/ip-172-31-22-24/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.970423ms)
Apr  1 16:56:23.166: INFO: (3) /api/v1/nodes/ip-172-31-22-24/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.341902ms)
Apr  1 16:56:23.171: INFO: (4) /api/v1/nodes/ip-172-31-22-24/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.403823ms)
Apr  1 16:56:23.175: INFO: (5) /api/v1/nodes/ip-172-31-22-24/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.63755ms)
Apr  1 16:56:23.180: INFO: (6) /api/v1/nodes/ip-172-31-22-24/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.343807ms)
Apr  1 16:56:23.184: INFO: (7) /api/v1/nodes/ip-172-31-22-24/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.733306ms)
Apr  1 16:56:23.189: INFO: (8) /api/v1/nodes/ip-172-31-22-24/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.976287ms)
Apr  1 16:56:23.194: INFO: (9) /api/v1/nodes/ip-172-31-22-24/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.603983ms)
Apr  1 16:56:23.198: INFO: (10) /api/v1/nodes/ip-172-31-22-24/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.350542ms)
Apr  1 16:56:23.278: INFO: (11) /api/v1/nodes/ip-172-31-22-24/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 80.091788ms)
Apr  1 16:56:23.283: INFO: (12) /api/v1/nodes/ip-172-31-22-24/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.037325ms)
Apr  1 16:56:23.288: INFO: (13) /api/v1/nodes/ip-172-31-22-24/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.322674ms)
Apr  1 16:56:23.292: INFO: (14) /api/v1/nodes/ip-172-31-22-24/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.286696ms)
Apr  1 16:56:23.297: INFO: (15) /api/v1/nodes/ip-172-31-22-24/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.988294ms)
Apr  1 16:56:23.303: INFO: (16) /api/v1/nodes/ip-172-31-22-24/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.820474ms)
Apr  1 16:56:23.307: INFO: (17) /api/v1/nodes/ip-172-31-22-24/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.347467ms)
Apr  1 16:56:23.312: INFO: (18) /api/v1/nodes/ip-172-31-22-24/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.768689ms)
Apr  1 16:56:23.317: INFO: (19) /api/v1/nodes/ip-172-31-22-24/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.365953ms)
[AfterEach] version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 16:56:23.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8334" for this suite.
Apr  1 16:56:29.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 16:56:29.457: INFO: namespace proxy-8334 deletion completed in 6.137054557s

• [SLOW TEST:6.379 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 16:56:29.457: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1455
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr  1 16:56:29.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=kubectl-8027'
Apr  1 16:56:29.879: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr  1 16:56:29.879: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1460
Apr  1 16:56:31.888: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 delete deployment e2e-test-nginx-deployment --namespace=kubectl-8027'
Apr  1 16:56:31.967: INFO: stderr: ""
Apr  1 16:56:31.967: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 16:56:31.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8027" for this suite.
Apr  1 16:56:37.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 16:56:38.099: INFO: namespace kubectl-8027 deletion completed in 6.126438685s

• [SLOW TEST:8.642 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 16:56:38.099: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating pod
Apr  1 16:56:42.161: INFO: Pod pod-hostip-1d66d9f9-549f-11e9-871e-828ee0b576f8 has hostIP: 172.31.3.176
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 16:56:42.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8758" for this suite.
Apr  1 16:57:04.180: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 16:57:04.333: INFO: namespace pods-8758 deletion completed in 22.167987342s

• [SLOW TEST:26.234 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 16:57:04.333: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-2d0adeef-549f-11e9-871e-828ee0b576f8
STEP: Creating a pod to test consume configMaps
Apr  1 16:57:04.394: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2d0c3dab-549f-11e9-871e-828ee0b576f8" in namespace "projected-5841" to be "success or failure"
Apr  1 16:57:04.400: INFO: Pod "pod-projected-configmaps-2d0c3dab-549f-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.057076ms
Apr  1 16:57:06.405: INFO: Pod "pod-projected-configmaps-2d0c3dab-549f-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011003748s
Apr  1 16:57:08.410: INFO: Pod "pod-projected-configmaps-2d0c3dab-549f-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016015621s
STEP: Saw pod success
Apr  1 16:57:08.410: INFO: Pod "pod-projected-configmaps-2d0c3dab-549f-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 16:57:08.415: INFO: Trying to get logs from node ip-172-31-75-215 pod pod-projected-configmaps-2d0c3dab-549f-11e9-871e-828ee0b576f8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr  1 16:57:08.489: INFO: Waiting for pod pod-projected-configmaps-2d0c3dab-549f-11e9-871e-828ee0b576f8 to disappear
Apr  1 16:57:08.493: INFO: Pod pod-projected-configmaps-2d0c3dab-549f-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 16:57:08.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
Apr  1 16:57:08.497: INFO: Condition Ready of node ip-172-31-3-176 is false, but Node is tainted by NodeController with [{node.kubernetes.io/not-ready  NoSchedule 2019-04-01 16:57:04 +0000 UTC} {node.kubernetes.io/not-ready  NoExecute 2019-04-01 16:57:06 +0000 UTC}]. Failure
Apr  1 16:57:10.509: INFO: Condition Ready of node ip-172-31-3-176 is false, but Node is tainted by NodeController with [{node.kubernetes.io/not-ready  NoSchedule 2019-04-01 16:57:04 +0000 UTC} {node.kubernetes.io/not-ready  NoExecute 2019-04-01 16:57:06 +0000 UTC}]. Failure
Apr  1 16:57:12.503: INFO: Condition Ready of node ip-172-31-3-176 is false, but Node is tainted by NodeController with [{node.kubernetes.io/not-ready  NoSchedule 2019-04-01 16:57:04 +0000 UTC} {node.kubernetes.io/not-ready  NoExecute 2019-04-01 16:57:06 +0000 UTC}]. Failure
Apr  1 16:57:14.503: INFO: Condition Ready of node ip-172-31-3-176 is true, but Node is tainted by NodeController with [{node.kubernetes.io/not-ready  NoExecute 2019-04-01 16:57:06 +0000 UTC}]. Failure
Apr  1 16:57:16.503: INFO: Condition Ready of node ip-172-31-3-176 is true, but Node is tainted by NodeController with [{node.kubernetes.io/not-ready  NoExecute 2019-04-01 16:57:06 +0000 UTC}]. Failure
STEP: Destroying namespace "projected-5841" for this suite.
Apr  1 16:57:24.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 16:57:24.653: INFO: namespace projected-5841 deletion completed in 6.151025169s

• [SLOW TEST:20.320 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 16:57:24.653: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0401 16:57:30.729147      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr  1 16:57:30.729: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 16:57:30.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3195" for this suite.
Apr  1 16:57:38.750: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 16:57:38.927: INFO: namespace gc-3195 deletion completed in 8.192460443s

• [SLOW TEST:14.274 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 16:57:38.928: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-41a8dbf0-549f-11e9-871e-828ee0b576f8
STEP: Creating a pod to test consume configMaps
Apr  1 16:57:38.980: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-41a9f5d0-549f-11e9-871e-828ee0b576f8" in namespace "projected-7193" to be "success or failure"
Apr  1 16:57:38.984: INFO: Pod "pod-projected-configmaps-41a9f5d0-549f-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.496917ms
Apr  1 16:57:40.989: INFO: Pod "pod-projected-configmaps-41a9f5d0-549f-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008867557s
Apr  1 16:57:42.993: INFO: Pod "pod-projected-configmaps-41a9f5d0-549f-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013239697s
STEP: Saw pod success
Apr  1 16:57:42.993: INFO: Pod "pod-projected-configmaps-41a9f5d0-549f-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 16:57:42.997: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-projected-configmaps-41a9f5d0-549f-11e9-871e-828ee0b576f8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr  1 16:57:43.037: INFO: Waiting for pod pod-projected-configmaps-41a9f5d0-549f-11e9-871e-828ee0b576f8 to disappear
Apr  1 16:57:43.041: INFO: Pod pod-projected-configmaps-41a9f5d0-549f-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 16:57:43.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7193" for this suite.
Apr  1 16:57:49.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 16:57:49.174: INFO: namespace projected-7193 deletion completed in 6.129739302s

• [SLOW TEST:10.247 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 16:57:49.174: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override command
Apr  1 16:57:49.219: INFO: Waiting up to 5m0s for pod "client-containers-47c3fc58-549f-11e9-871e-828ee0b576f8" in namespace "containers-5486" to be "success or failure"
Apr  1 16:57:49.224: INFO: Pod "client-containers-47c3fc58-549f-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.859717ms
Apr  1 16:57:51.230: INFO: Pod "client-containers-47c3fc58-549f-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010699546s
Apr  1 16:57:53.234: INFO: Pod "client-containers-47c3fc58-549f-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015177159s
STEP: Saw pod success
Apr  1 16:57:53.234: INFO: Pod "client-containers-47c3fc58-549f-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 16:57:53.238: INFO: Trying to get logs from node ip-172-31-3-176 pod client-containers-47c3fc58-549f-11e9-871e-828ee0b576f8 container test-container: <nil>
STEP: delete the pod
Apr  1 16:57:53.257: INFO: Waiting for pod client-containers-47c3fc58-549f-11e9-871e-828ee0b576f8 to disappear
Apr  1 16:57:53.261: INFO: Pod client-containers-47c3fc58-549f-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 16:57:53.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5486" for this suite.
Apr  1 16:57:59.279: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 16:57:59.394: INFO: namespace containers-5486 deletion completed in 6.130426921s

• [SLOW TEST:10.220 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 16:57:59.395: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Apr  1 16:58:07.496: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr  1 16:58:07.500: INFO: Pod pod-with-poststart-http-hook still exists
Apr  1 16:58:09.500: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr  1 16:58:09.504: INFO: Pod pod-with-poststart-http-hook still exists
Apr  1 16:58:11.500: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr  1 16:58:11.504: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 16:58:11.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5934" for this suite.
Apr  1 16:58:33.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 16:58:33.650: INFO: namespace container-lifecycle-hook-5934 deletion completed in 22.142235921s

• [SLOW TEST:34.255 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 16:58:33.650: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  1 16:58:33.702: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Apr  1 16:58:38.707: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr  1 16:58:38.707: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr  1 16:58:42.740: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-8959,SelfLink:/apis/apps/v1/namespaces/deployment-8959/deployments/test-cleanup-deployment,UID:6542af9b-549f-11e9-9aab-028387864c62,ResourceVersion:2719,Generation:1,CreationTimestamp:2019-04-01 16:58:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-04-01 16:58:38 +0000 UTC 2019-04-01 16:58:38 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-04-01 16:58:40 +0000 UTC 2019-04-01 16:58:38 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-55cbfbc8f5" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Apr  1 16:58:42.744: INFO: New ReplicaSet "test-cleanup-deployment-55cbfbc8f5" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55cbfbc8f5,GenerateName:,Namespace:deployment-8959,SelfLink:/apis/apps/v1/namespaces/deployment-8959/replicasets/test-cleanup-deployment-55cbfbc8f5,UID:65483575-549f-11e9-84d7-12a9dd9b0c8a,ResourceVersion:2708,Generation:1,CreationTimestamp:2019-04-01 16:58:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 6542af9b-549f-11e9-9aab-028387864c62 0xc001a782c7 0xc001a782c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Apr  1 16:58:42.748: INFO: Pod "test-cleanup-deployment-55cbfbc8f5-h58ff" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55cbfbc8f5-h58ff,GenerateName:test-cleanup-deployment-55cbfbc8f5-,Namespace:deployment-8959,SelfLink:/api/v1/namespaces/deployment-8959/pods/test-cleanup-deployment-55cbfbc8f5-h58ff,UID:6549107e-549f-11e9-84d7-12a9dd9b0c8a,ResourceVersion:2707,Generation:0,CreationTimestamp:2019-04-01 16:58:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-55cbfbc8f5 65483575-549f-11e9-84d7-12a9dd9b0c8a 0xc000fd7737 0xc000fd7738}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6vztp {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6vztp,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-6vztp true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-3-176,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000fd77b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000fd77d0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 16:58:38 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 16:58:40 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 16:58:40 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 16:58:38 +0000 UTC  }],Message:,Reason:,HostIP:172.31.3.176,PodIP:10.1.83.21,StartTime:2019-04-01 16:58:38 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-04-01 16:58:40 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://18c6845971273916074ad2053ad88e76ea82e2ec68b734185c3311cea2b8dea7}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 16:58:42.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8959" for this suite.
Apr  1 16:58:48.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 16:58:48.883: INFO: namespace deployment-8959 deletion completed in 6.13072864s

• [SLOW TEST:15.232 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 16:58:48.883: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-l7zb
STEP: Creating a pod to test atomic-volume-subpath
Apr  1 16:58:48.939: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-l7zb" in namespace "subpath-194" to be "success or failure"
Apr  1 16:58:48.945: INFO: Pod "pod-subpath-test-configmap-l7zb": Phase="Pending", Reason="", readiness=false. Elapsed: 5.684729ms
Apr  1 16:58:50.951: INFO: Pod "pod-subpath-test-configmap-l7zb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011975845s
Apr  1 16:58:52.956: INFO: Pod "pod-subpath-test-configmap-l7zb": Phase="Running", Reason="", readiness=true. Elapsed: 4.016714801s
Apr  1 16:58:54.960: INFO: Pod "pod-subpath-test-configmap-l7zb": Phase="Running", Reason="", readiness=true. Elapsed: 6.021506312s
Apr  1 16:58:57.399: INFO: Pod "pod-subpath-test-configmap-l7zb": Phase="Running", Reason="", readiness=true. Elapsed: 8.459618206s
Apr  1 16:58:59.403: INFO: Pod "pod-subpath-test-configmap-l7zb": Phase="Running", Reason="", readiness=true. Elapsed: 10.464315444s
Apr  1 16:59:01.408: INFO: Pod "pod-subpath-test-configmap-l7zb": Phase="Running", Reason="", readiness=true. Elapsed: 12.469427199s
Apr  1 16:59:03.413: INFO: Pod "pod-subpath-test-configmap-l7zb": Phase="Running", Reason="", readiness=true. Elapsed: 14.474402487s
Apr  1 16:59:05.418: INFO: Pod "pod-subpath-test-configmap-l7zb": Phase="Running", Reason="", readiness=true. Elapsed: 16.479265849s
Apr  1 16:59:07.423: INFO: Pod "pod-subpath-test-configmap-l7zb": Phase="Running", Reason="", readiness=true. Elapsed: 18.484156524s
Apr  1 16:59:09.428: INFO: Pod "pod-subpath-test-configmap-l7zb": Phase="Running", Reason="", readiness=true. Elapsed: 20.488660408s
Apr  1 16:59:11.432: INFO: Pod "pod-subpath-test-configmap-l7zb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.493239422s
STEP: Saw pod success
Apr  1 16:59:11.432: INFO: Pod "pod-subpath-test-configmap-l7zb" satisfied condition "success or failure"
Apr  1 16:59:11.436: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-subpath-test-configmap-l7zb container test-container-subpath-configmap-l7zb: <nil>
STEP: delete the pod
Apr  1 16:59:11.459: INFO: Waiting for pod pod-subpath-test-configmap-l7zb to disappear
Apr  1 16:59:11.464: INFO: Pod pod-subpath-test-configmap-l7zb no longer exists
STEP: Deleting pod pod-subpath-test-configmap-l7zb
Apr  1 16:59:11.464: INFO: Deleting pod "pod-subpath-test-configmap-l7zb" in namespace "subpath-194"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 16:59:11.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-194" for this suite.
Apr  1 16:59:17.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 16:59:17.603: INFO: namespace subpath-194 deletion completed in 6.130663203s

• [SLOW TEST:28.720 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 16:59:17.603: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0401 16:59:27.713140      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr  1 16:59:27.713: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 16:59:27.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9890" for this suite.
Apr  1 16:59:35.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 16:59:35.930: INFO: namespace gc-9890 deletion completed in 8.214147547s

• [SLOW TEST:18.328 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 16:59:35.931: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Apr  1 16:59:44.031: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  1 16:59:44.035: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  1 16:59:46.036: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  1 16:59:46.041: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  1 16:59:48.036: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  1 16:59:48.040: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  1 16:59:50.036: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  1 16:59:50.040: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  1 16:59:52.036: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  1 16:59:52.040: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  1 16:59:54.036: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  1 16:59:54.040: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  1 16:59:56.036: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  1 16:59:56.040: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  1 16:59:58.036: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  1 16:59:58.040: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  1 17:00:00.036: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  1 17:00:00.040: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  1 17:00:02.036: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  1 17:00:02.041: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  1 17:00:04.036: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  1 17:00:04.040: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:00:04.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7110" for this suite.
Apr  1 17:00:26.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:00:26.230: INFO: namespace container-lifecycle-hook-7110 deletion completed in 22.185882934s

• [SLOW TEST:50.299 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:00:26.230: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-72
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating stateful set ss in namespace statefulset-72
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-72
Apr  1 17:00:26.284: INFO: Found 0 stateful pods, waiting for 1
Apr  1 17:00:36.288: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Apr  1 17:00:36.292: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 exec --namespace=statefulset-72 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  1 17:00:36.512: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  1 17:00:36.512: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  1 17:00:36.512: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr  1 17:00:36.516: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr  1 17:00:46.520: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr  1 17:00:46.520: INFO: Waiting for statefulset status.replicas updated to 0
Apr  1 17:00:46.536: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Apr  1 17:00:46.536: INFO: ss-0  ip-172-31-3-176  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:00:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:00:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:00:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:00:26 +0000 UTC  }]
Apr  1 17:00:46.536: INFO: 
Apr  1 17:00:46.536: INFO: StatefulSet ss has not reached scale 3, at 1
Apr  1 17:00:47.541: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.99644385s
Apr  1 17:00:48.546: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.991745836s
Apr  1 17:00:49.550: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.987132687s
Apr  1 17:00:50.555: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.982273442s
Apr  1 17:00:51.560: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.977514989s
Apr  1 17:00:52.565: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.972774728s
Apr  1 17:00:53.570: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.967762631s
Apr  1 17:00:54.575: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.962712317s
Apr  1 17:00:55.580: INFO: Verifying statefulset ss doesn't scale past 3 for another 957.943533ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-72
Apr  1 17:00:56.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 exec --namespace=statefulset-72 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  1 17:01:01.820: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr  1 17:01:01.820: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr  1 17:01:01.820: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr  1 17:01:01.820: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 exec --namespace=statefulset-72 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  1 17:01:02.178: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr  1 17:01:02.178: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr  1 17:01:02.178: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr  1 17:01:02.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 exec --namespace=statefulset-72 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  1 17:01:02.506: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr  1 17:01:02.506: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr  1 17:01:02.506: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr  1 17:01:02.511: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr  1 17:01:02.511: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr  1 17:01:02.511: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Apr  1 17:01:02.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 exec --namespace=statefulset-72 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  1 17:01:02.825: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  1 17:01:02.825: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  1 17:01:02.825: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr  1 17:01:02.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 exec --namespace=statefulset-72 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  1 17:01:03.073: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  1 17:01:03.073: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  1 17:01:03.073: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr  1 17:01:03.073: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 exec --namespace=statefulset-72 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  1 17:01:03.428: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  1 17:01:03.428: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  1 17:01:03.428: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr  1 17:01:03.429: INFO: Waiting for statefulset status.replicas updated to 0
Apr  1 17:01:03.434: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Apr  1 17:01:13.550: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr  1 17:01:13.550: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr  1 17:01:13.550: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr  1 17:01:13.564: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Apr  1 17:01:13.564: INFO: ss-0  ip-172-31-3-176   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:00:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:01:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:01:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:00:26 +0000 UTC  }]
Apr  1 17:01:13.564: INFO: ss-1  ip-172-31-22-24   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:00:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:01:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:01:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:00:46 +0000 UTC  }]
Apr  1 17:01:13.564: INFO: ss-2  ip-172-31-75-215  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:00:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:01:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:01:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:00:46 +0000 UTC  }]
Apr  1 17:01:13.564: INFO: 
Apr  1 17:01:13.564: INFO: StatefulSet ss has not reached scale 0, at 3
Apr  1 17:01:14.575: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Apr  1 17:01:14.575: INFO: ss-0  ip-172-31-3-176   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:00:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:01:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:01:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:00:26 +0000 UTC  }]
Apr  1 17:01:14.575: INFO: ss-1  ip-172-31-22-24   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:00:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:01:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:01:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:00:46 +0000 UTC  }]
Apr  1 17:01:14.575: INFO: ss-2  ip-172-31-75-215  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:00:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:01:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:01:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:00:46 +0000 UTC  }]
Apr  1 17:01:14.575: INFO: 
Apr  1 17:01:14.575: INFO: StatefulSet ss has not reached scale 0, at 3
Apr  1 17:01:15.580: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Apr  1 17:01:15.580: INFO: ss-0  ip-172-31-3-176   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:00:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:01:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:01:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:00:26 +0000 UTC  }]
Apr  1 17:01:15.580: INFO: ss-1  ip-172-31-22-24   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:00:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:01:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:01:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:00:46 +0000 UTC  }]
Apr  1 17:01:15.580: INFO: ss-2  ip-172-31-75-215  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:00:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:01:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:01:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:00:46 +0000 UTC  }]
Apr  1 17:01:15.580: INFO: 
Apr  1 17:01:15.580: INFO: StatefulSet ss has not reached scale 0, at 3
Apr  1 17:01:16.585: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Apr  1 17:01:16.585: INFO: ss-1  ip-172-31-22-24  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:00:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:01:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:01:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:00:46 +0000 UTC  }]
Apr  1 17:01:16.585: INFO: 
Apr  1 17:01:16.585: INFO: StatefulSet ss has not reached scale 0, at 1
Apr  1 17:01:17.590: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Apr  1 17:01:17.590: INFO: ss-1  ip-172-31-22-24  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:00:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:01:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:01:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:00:46 +0000 UTC  }]
Apr  1 17:01:17.590: INFO: 
Apr  1 17:01:17.590: INFO: StatefulSet ss has not reached scale 0, at 1
Apr  1 17:01:18.595: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Apr  1 17:01:18.595: INFO: ss-1  ip-172-31-22-24  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:00:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:01:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:01:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:00:46 +0000 UTC  }]
Apr  1 17:01:18.595: INFO: 
Apr  1 17:01:18.595: INFO: StatefulSet ss has not reached scale 0, at 1
Apr  1 17:01:19.599: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Apr  1 17:01:19.599: INFO: ss-1  ip-172-31-22-24  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:00:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:01:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:01:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:00:46 +0000 UTC  }]
Apr  1 17:01:19.599: INFO: 
Apr  1 17:01:19.599: INFO: StatefulSet ss has not reached scale 0, at 1
Apr  1 17:01:20.605: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Apr  1 17:01:20.605: INFO: ss-1  ip-172-31-22-24  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:00:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:01:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:01:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:00:46 +0000 UTC  }]
Apr  1 17:01:20.605: INFO: 
Apr  1 17:01:20.605: INFO: StatefulSet ss has not reached scale 0, at 1
Apr  1 17:01:21.609: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.954069648s
Apr  1 17:01:22.614: INFO: Verifying statefulset ss doesn't scale past 0 for another 949.541614ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-72
Apr  1 17:01:23.618: INFO: Scaling statefulset ss to 0
Apr  1 17:01:23.631: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr  1 17:01:23.635: INFO: Deleting all statefulset in ns statefulset-72
Apr  1 17:01:23.639: INFO: Scaling statefulset ss to 0
Apr  1 17:01:23.650: INFO: Waiting for statefulset status.replicas updated to 0
Apr  1 17:01:23.653: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:01:23.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-72" for this suite.
Apr  1 17:01:29.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:01:29.841: INFO: namespace statefulset-72 deletion completed in 6.164043217s

• [SLOW TEST:63.611 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:01:29.842: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-4436
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr  1 17:01:29.886: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr  1 17:01:55.995: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.1.83.29:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4436 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  1 17:01:55.995: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
Apr  1 17:01:56.276: INFO: Found all expected endpoints: [netserver-0]
Apr  1 17:01:56.280: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.1.81.17:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4436 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  1 17:01:56.280: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
Apr  1 17:01:56.519: INFO: Found all expected endpoints: [netserver-1]
Apr  1 17:01:56.524: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.1.101.14:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4436 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  1 17:01:56.524: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
Apr  1 17:01:56.735: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:01:56.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4436" for this suite.
Apr  1 17:02:18.757: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:02:18.869: INFO: namespace pod-network-test-4436 deletion completed in 22.12942934s

• [SLOW TEST:49.027 seconds]
[sig-network] Networking
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:02:18.869: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3663.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-3663.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3663.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3663.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-3663.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3663.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr  1 17:02:30.969: INFO: DNS probes using dns-3663/dns-test-e884986a-549f-11e9-871e-828ee0b576f8 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:02:30.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3663" for this suite.
Apr  1 17:02:37.000: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:02:37.129: INFO: namespace dns-3663 deletion completed in 6.141786541s

• [SLOW TEST:18.259 seconds]
[sig-network] DNS
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:02:37.129: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-f36764e0-549f-11e9-871e-828ee0b576f8
STEP: Creating a pod to test consume secrets
Apr  1 17:02:37.184: INFO: Waiting up to 5m0s for pod "pod-secrets-f36879cc-549f-11e9-871e-828ee0b576f8" in namespace "secrets-26" to be "success or failure"
Apr  1 17:02:37.188: INFO: Pod "pod-secrets-f36879cc-549f-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.037807ms
Apr  1 17:02:39.192: INFO: Pod "pod-secrets-f36879cc-549f-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008420987s
Apr  1 17:02:41.197: INFO: Pod "pod-secrets-f36879cc-549f-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01306501s
STEP: Saw pod success
Apr  1 17:02:41.197: INFO: Pod "pod-secrets-f36879cc-549f-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 17:02:41.201: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-secrets-f36879cc-549f-11e9-871e-828ee0b576f8 container secret-volume-test: <nil>
STEP: delete the pod
Apr  1 17:02:41.222: INFO: Waiting for pod pod-secrets-f36879cc-549f-11e9-871e-828ee0b576f8 to disappear
Apr  1 17:02:41.226: INFO: Pod pod-secrets-f36879cc-549f-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:02:41.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-26" for this suite.
Apr  1 17:02:47.243: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:02:47.430: INFO: namespace secrets-26 deletion completed in 6.200705414s

• [SLOW TEST:10.301 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:02:47.430: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  1 17:02:47.480: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f98b3024-549f-11e9-871e-828ee0b576f8" in namespace "projected-4189" to be "success or failure"
Apr  1 17:02:47.486: INFO: Pod "downwardapi-volume-f98b3024-549f-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.132797ms
Apr  1 17:02:49.495: INFO: Pod "downwardapi-volume-f98b3024-549f-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015506084s
Apr  1 17:02:51.500: INFO: Pod "downwardapi-volume-f98b3024-549f-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020183374s
STEP: Saw pod success
Apr  1 17:02:51.500: INFO: Pod "downwardapi-volume-f98b3024-549f-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 17:02:51.504: INFO: Trying to get logs from node ip-172-31-3-176 pod downwardapi-volume-f98b3024-549f-11e9-871e-828ee0b576f8 container client-container: <nil>
STEP: delete the pod
Apr  1 17:02:51.529: INFO: Waiting for pod downwardapi-volume-f98b3024-549f-11e9-871e-828ee0b576f8 to disappear
Apr  1 17:02:51.533: INFO: Pod downwardapi-volume-f98b3024-549f-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:02:51.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4189" for this suite.
Apr  1 17:02:57.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:02:57.666: INFO: namespace projected-4189 deletion completed in 6.129650376s

• [SLOW TEST:10.236 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:02:57.667: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's command
Apr  1 17:02:57.711: INFO: Waiting up to 5m0s for pod "var-expansion-ffa45ca7-549f-11e9-871e-828ee0b576f8" in namespace "var-expansion-371" to be "success or failure"
Apr  1 17:02:57.716: INFO: Pod "var-expansion-ffa45ca7-549f-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.021988ms
Apr  1 17:02:59.720: INFO: Pod "var-expansion-ffa45ca7-549f-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009484171s
Apr  1 17:03:01.725: INFO: Pod "var-expansion-ffa45ca7-549f-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013891903s
STEP: Saw pod success
Apr  1 17:03:01.725: INFO: Pod "var-expansion-ffa45ca7-549f-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 17:03:01.729: INFO: Trying to get logs from node ip-172-31-3-176 pod var-expansion-ffa45ca7-549f-11e9-871e-828ee0b576f8 container dapi-container: <nil>
STEP: delete the pod
Apr  1 17:03:01.755: INFO: Waiting for pod var-expansion-ffa45ca7-549f-11e9-871e-828ee0b576f8 to disappear
Apr  1 17:03:01.760: INFO: Pod var-expansion-ffa45ca7-549f-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:03:01.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-371" for this suite.
Apr  1 17:03:07.780: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:03:07.910: INFO: namespace var-expansion-371 deletion completed in 6.144251136s

• [SLOW TEST:10.244 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:03:07.910: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-downwardapi-7lfp
STEP: Creating a pod to test atomic-volume-subpath
Apr  1 17:03:07.965: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-7lfp" in namespace "subpath-4753" to be "success or failure"
Apr  1 17:03:07.970: INFO: Pod "pod-subpath-test-downwardapi-7lfp": Phase="Pending", Reason="", readiness=false. Elapsed: 5.454804ms
Apr  1 17:03:09.975: INFO: Pod "pod-subpath-test-downwardapi-7lfp": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010095876s
Apr  1 17:03:11.980: INFO: Pod "pod-subpath-test-downwardapi-7lfp": Phase="Running", Reason="", readiness=true. Elapsed: 4.015001491s
Apr  1 17:03:13.984: INFO: Pod "pod-subpath-test-downwardapi-7lfp": Phase="Running", Reason="", readiness=true. Elapsed: 6.019603881s
Apr  1 17:03:15.989: INFO: Pod "pod-subpath-test-downwardapi-7lfp": Phase="Running", Reason="", readiness=true. Elapsed: 8.024423437s
Apr  1 17:03:17.994: INFO: Pod "pod-subpath-test-downwardapi-7lfp": Phase="Running", Reason="", readiness=true. Elapsed: 10.029045156s
Apr  1 17:03:19.998: INFO: Pod "pod-subpath-test-downwardapi-7lfp": Phase="Running", Reason="", readiness=true. Elapsed: 12.03389431s
Apr  1 17:03:22.003: INFO: Pod "pod-subpath-test-downwardapi-7lfp": Phase="Running", Reason="", readiness=true. Elapsed: 14.038423343s
Apr  1 17:03:24.007: INFO: Pod "pod-subpath-test-downwardapi-7lfp": Phase="Running", Reason="", readiness=true. Elapsed: 16.0428292s
Apr  1 17:03:26.012: INFO: Pod "pod-subpath-test-downwardapi-7lfp": Phase="Running", Reason="", readiness=true. Elapsed: 18.047157277s
Apr  1 17:03:28.016: INFO: Pod "pod-subpath-test-downwardapi-7lfp": Phase="Running", Reason="", readiness=true. Elapsed: 20.051275428s
Apr  1 17:03:30.021: INFO: Pod "pod-subpath-test-downwardapi-7lfp": Phase="Running", Reason="", readiness=true. Elapsed: 22.056053731s
Apr  1 17:03:32.025: INFO: Pod "pod-subpath-test-downwardapi-7lfp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.060642931s
STEP: Saw pod success
Apr  1 17:03:32.025: INFO: Pod "pod-subpath-test-downwardapi-7lfp" satisfied condition "success or failure"
Apr  1 17:03:32.029: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-subpath-test-downwardapi-7lfp container test-container-subpath-downwardapi-7lfp: <nil>
STEP: delete the pod
Apr  1 17:03:32.053: INFO: Waiting for pod pod-subpath-test-downwardapi-7lfp to disappear
Apr  1 17:03:32.057: INFO: Pod pod-subpath-test-downwardapi-7lfp no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-7lfp
Apr  1 17:03:32.057: INFO: Deleting pod "pod-subpath-test-downwardapi-7lfp" in namespace "subpath-4753"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:03:32.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4753" for this suite.
Apr  1 17:03:38.078: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:03:38.194: INFO: namespace subpath-4753 deletion completed in 6.130728956s

• [SLOW TEST:30.284 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:03:38.194: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with configMap that has name projected-configmap-test-upd-17cd7eca-54a0-11e9-871e-828ee0b576f8
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-17cd7eca-54a0-11e9-871e-828ee0b576f8
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:04:45.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1778" for this suite.
Apr  1 17:05:07.636: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:05:07.753: INFO: namespace projected-1778 deletion completed in 22.130867946s

• [SLOW TEST:89.558 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:05:07.753: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Apr  1 17:05:07.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 create -f - --namespace=kubectl-5822'
Apr  1 17:05:07.972: INFO: stderr: ""
Apr  1 17:05:07.972: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr  1 17:05:07.972: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5822'
Apr  1 17:05:08.069: INFO: stderr: ""
Apr  1 17:05:08.069: INFO: stdout: "update-demo-nautilus-586xx update-demo-nautilus-7fncb "
Apr  1 17:05:08.069: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods update-demo-nautilus-586xx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5822'
Apr  1 17:05:08.158: INFO: stderr: ""
Apr  1 17:05:08.158: INFO: stdout: ""
Apr  1 17:05:08.158: INFO: update-demo-nautilus-586xx is created but not running
Apr  1 17:05:13.159: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5822'
Apr  1 17:05:13.242: INFO: stderr: ""
Apr  1 17:05:13.242: INFO: stdout: "update-demo-nautilus-586xx update-demo-nautilus-7fncb "
Apr  1 17:05:13.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods update-demo-nautilus-586xx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5822'
Apr  1 17:05:13.316: INFO: stderr: ""
Apr  1 17:05:13.316: INFO: stdout: "true"
Apr  1 17:05:13.316: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods update-demo-nautilus-586xx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5822'
Apr  1 17:05:13.425: INFO: stderr: ""
Apr  1 17:05:13.425: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  1 17:05:13.425: INFO: validating pod update-demo-nautilus-586xx
Apr  1 17:05:13.431: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  1 17:05:13.431: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  1 17:05:13.431: INFO: update-demo-nautilus-586xx is verified up and running
Apr  1 17:05:13.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods update-demo-nautilus-7fncb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5822'
Apr  1 17:05:13.514: INFO: stderr: ""
Apr  1 17:05:13.514: INFO: stdout: "true"
Apr  1 17:05:13.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods update-demo-nautilus-7fncb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5822'
Apr  1 17:05:13.610: INFO: stderr: ""
Apr  1 17:05:13.610: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  1 17:05:13.610: INFO: validating pod update-demo-nautilus-7fncb
Apr  1 17:05:13.620: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  1 17:05:13.620: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  1 17:05:13.620: INFO: update-demo-nautilus-7fncb is verified up and running
STEP: scaling down the replication controller
Apr  1 17:05:13.622: INFO: scanned /root for discovery docs: <nil>
Apr  1 17:05:13.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-5822'
Apr  1 17:05:14.748: INFO: stderr: ""
Apr  1 17:05:14.748: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr  1 17:05:14.748: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5822'
Apr  1 17:05:14.832: INFO: stderr: ""
Apr  1 17:05:14.832: INFO: stdout: "update-demo-nautilus-586xx update-demo-nautilus-7fncb "
STEP: Replicas for name=update-demo: expected=1 actual=2
Apr  1 17:05:19.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5822'
Apr  1 17:05:19.905: INFO: stderr: ""
Apr  1 17:05:19.905: INFO: stdout: "update-demo-nautilus-7fncb "
Apr  1 17:05:19.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods update-demo-nautilus-7fncb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5822'
Apr  1 17:05:19.979: INFO: stderr: ""
Apr  1 17:05:19.979: INFO: stdout: "true"
Apr  1 17:05:19.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods update-demo-nautilus-7fncb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5822'
Apr  1 17:05:20.102: INFO: stderr: ""
Apr  1 17:05:20.102: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  1 17:05:20.102: INFO: validating pod update-demo-nautilus-7fncb
Apr  1 17:05:20.107: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  1 17:05:20.107: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  1 17:05:20.107: INFO: update-demo-nautilus-7fncb is verified up and running
STEP: scaling up the replication controller
Apr  1 17:05:20.108: INFO: scanned /root for discovery docs: <nil>
Apr  1 17:05:20.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-5822'
Apr  1 17:05:21.213: INFO: stderr: ""
Apr  1 17:05:21.213: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr  1 17:05:21.213: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5822'
Apr  1 17:05:21.296: INFO: stderr: ""
Apr  1 17:05:21.296: INFO: stdout: "update-demo-nautilus-7fncb update-demo-nautilus-tkkjq "
Apr  1 17:05:21.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods update-demo-nautilus-7fncb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5822'
Apr  1 17:05:21.403: INFO: stderr: ""
Apr  1 17:05:21.403: INFO: stdout: "true"
Apr  1 17:05:21.403: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods update-demo-nautilus-7fncb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5822'
Apr  1 17:05:21.483: INFO: stderr: ""
Apr  1 17:05:21.483: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  1 17:05:21.483: INFO: validating pod update-demo-nautilus-7fncb
Apr  1 17:05:21.487: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  1 17:05:21.487: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  1 17:05:21.487: INFO: update-demo-nautilus-7fncb is verified up and running
Apr  1 17:05:21.487: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods update-demo-nautilus-tkkjq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5822'
Apr  1 17:05:21.568: INFO: stderr: ""
Apr  1 17:05:21.568: INFO: stdout: ""
Apr  1 17:05:21.568: INFO: update-demo-nautilus-tkkjq is created but not running
Apr  1 17:05:26.568: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5822'
Apr  1 17:05:26.639: INFO: stderr: ""
Apr  1 17:05:26.639: INFO: stdout: "update-demo-nautilus-7fncb update-demo-nautilus-tkkjq "
Apr  1 17:05:26.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods update-demo-nautilus-7fncb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5822'
Apr  1 17:05:26.717: INFO: stderr: ""
Apr  1 17:05:26.717: INFO: stdout: "true"
Apr  1 17:05:26.717: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods update-demo-nautilus-7fncb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5822'
Apr  1 17:05:26.790: INFO: stderr: ""
Apr  1 17:05:26.790: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  1 17:05:26.790: INFO: validating pod update-demo-nautilus-7fncb
Apr  1 17:05:26.796: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  1 17:05:26.796: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  1 17:05:26.796: INFO: update-demo-nautilus-7fncb is verified up and running
Apr  1 17:05:26.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods update-demo-nautilus-tkkjq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5822'
Apr  1 17:05:26.865: INFO: stderr: ""
Apr  1 17:05:26.865: INFO: stdout: "true"
Apr  1 17:05:26.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods update-demo-nautilus-tkkjq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5822'
Apr  1 17:05:26.935: INFO: stderr: ""
Apr  1 17:05:26.935: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  1 17:05:26.935: INFO: validating pod update-demo-nautilus-tkkjq
Apr  1 17:05:26.940: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  1 17:05:26.940: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  1 17:05:26.940: INFO: update-demo-nautilus-tkkjq is verified up and running
STEP: using delete to clean up resources
Apr  1 17:05:26.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 delete --grace-period=0 --force -f - --namespace=kubectl-5822'
Apr  1 17:05:27.032: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  1 17:05:27.032: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr  1 17:05:27.032: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-5822'
Apr  1 17:05:27.144: INFO: stderr: "No resources found.\n"
Apr  1 17:05:27.144: INFO: stdout: ""
Apr  1 17:05:27.144: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods -l name=update-demo --namespace=kubectl-5822 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr  1 17:05:27.239: INFO: stderr: ""
Apr  1 17:05:27.239: INFO: stdout: "update-demo-nautilus-7fncb\nupdate-demo-nautilus-tkkjq\n"
Apr  1 17:05:27.740: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-5822'
Apr  1 17:05:27.831: INFO: stderr: "No resources found.\n"
Apr  1 17:05:27.831: INFO: stdout: ""
Apr  1 17:05:27.831: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods -l name=update-demo --namespace=kubectl-5822 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr  1 17:05:27.916: INFO: stderr: ""
Apr  1 17:05:27.916: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:05:27.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5822" for this suite.
Apr  1 17:05:49.935: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:05:50.054: INFO: namespace kubectl-5822 deletion completed in 22.133556954s

• [SLOW TEST:42.301 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:05:50.054: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-projected-all-test-volume-6664e138-54a0-11e9-871e-828ee0b576f8
STEP: Creating secret with name secret-projected-all-test-volume-6664e124-54a0-11e9-871e-828ee0b576f8
STEP: Creating a pod to test Check all projections for projected volume plugin
Apr  1 17:05:50.109: INFO: Waiting up to 5m0s for pod "projected-volume-6664e0e9-54a0-11e9-871e-828ee0b576f8" in namespace "projected-672" to be "success or failure"
Apr  1 17:05:50.115: INFO: Pod "projected-volume-6664e0e9-54a0-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.602676ms
Apr  1 17:05:52.119: INFO: Pod "projected-volume-6664e0e9-54a0-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010107342s
Apr  1 17:05:54.124: INFO: Pod "projected-volume-6664e0e9-54a0-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014820957s
STEP: Saw pod success
Apr  1 17:05:54.124: INFO: Pod "projected-volume-6664e0e9-54a0-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 17:05:54.128: INFO: Trying to get logs from node ip-172-31-3-176 pod projected-volume-6664e0e9-54a0-11e9-871e-828ee0b576f8 container projected-all-volume-test: <nil>
STEP: delete the pod
Apr  1 17:05:54.151: INFO: Waiting for pod projected-volume-6664e0e9-54a0-11e9-871e-828ee0b576f8 to disappear
Apr  1 17:05:54.154: INFO: Pod projected-volume-6664e0e9-54a0-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:05:54.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-672" for this suite.
Apr  1 17:06:00.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:06:00.304: INFO: namespace projected-672 deletion completed in 6.146946781s

• [SLOW TEST:10.250 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:06:00.305: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  1 17:06:00.350: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6c80dd88-54a0-11e9-871e-828ee0b576f8" in namespace "projected-5726" to be "success or failure"
Apr  1 17:06:00.355: INFO: Pod "downwardapi-volume-6c80dd88-54a0-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.375343ms
Apr  1 17:06:02.361: INFO: Pod "downwardapi-volume-6c80dd88-54a0-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010371474s
Apr  1 17:06:04.365: INFO: Pod "downwardapi-volume-6c80dd88-54a0-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015247048s
STEP: Saw pod success
Apr  1 17:06:04.366: INFO: Pod "downwardapi-volume-6c80dd88-54a0-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 17:06:04.369: INFO: Trying to get logs from node ip-172-31-3-176 pod downwardapi-volume-6c80dd88-54a0-11e9-871e-828ee0b576f8 container client-container: <nil>
STEP: delete the pod
Apr  1 17:06:04.392: INFO: Waiting for pod downwardapi-volume-6c80dd88-54a0-11e9-871e-828ee0b576f8 to disappear
Apr  1 17:06:04.396: INFO: Pod downwardapi-volume-6c80dd88-54a0-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:06:04.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5726" for this suite.
Apr  1 17:06:10.414: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:06:10.528: INFO: namespace projected-5726 deletion completed in 6.128985146s

• [SLOW TEST:10.224 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:06:10.528: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr  1 17:06:10.574: INFO: Waiting up to 5m0s for pod "downward-api-72989e2c-54a0-11e9-871e-828ee0b576f8" in namespace "downward-api-6303" to be "success or failure"
Apr  1 17:06:10.579: INFO: Pod "downward-api-72989e2c-54a0-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.869508ms
Apr  1 17:06:12.583: INFO: Pod "downward-api-72989e2c-54a0-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009472588s
Apr  1 17:06:14.588: INFO: Pod "downward-api-72989e2c-54a0-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014049919s
STEP: Saw pod success
Apr  1 17:06:14.588: INFO: Pod "downward-api-72989e2c-54a0-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 17:06:14.591: INFO: Trying to get logs from node ip-172-31-3-176 pod downward-api-72989e2c-54a0-11e9-871e-828ee0b576f8 container dapi-container: <nil>
STEP: delete the pod
Apr  1 17:06:14.613: INFO: Waiting for pod downward-api-72989e2c-54a0-11e9-871e-828ee0b576f8 to disappear
Apr  1 17:06:14.617: INFO: Pod downward-api-72989e2c-54a0-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:06:14.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6303" for this suite.
Apr  1 17:06:20.635: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:06:20.758: INFO: namespace downward-api-6303 deletion completed in 6.137402904s

• [SLOW TEST:10.229 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:06:20.758: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  1 17:06:26.840: INFO: Waiting up to 5m0s for pod "client-envvars-7c4b4bf1-54a0-11e9-871e-828ee0b576f8" in namespace "pods-7834" to be "success or failure"
Apr  1 17:06:26.848: INFO: Pod "client-envvars-7c4b4bf1-54a0-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 7.510266ms
Apr  1 17:06:28.853: INFO: Pod "client-envvars-7c4b4bf1-54a0-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012339922s
Apr  1 17:06:30.858: INFO: Pod "client-envvars-7c4b4bf1-54a0-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018054588s
STEP: Saw pod success
Apr  1 17:06:30.858: INFO: Pod "client-envvars-7c4b4bf1-54a0-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 17:06:30.862: INFO: Trying to get logs from node ip-172-31-3-176 pod client-envvars-7c4b4bf1-54a0-11e9-871e-828ee0b576f8 container env3cont: <nil>
STEP: delete the pod
Apr  1 17:06:30.884: INFO: Waiting for pod client-envvars-7c4b4bf1-54a0-11e9-871e-828ee0b576f8 to disappear
Apr  1 17:06:30.887: INFO: Pod client-envvars-7c4b4bf1-54a0-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:06:30.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7834" for this suite.
Apr  1 17:07:16.906: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:07:17.074: INFO: namespace pods-7834 deletion completed in 46.182690607s

• [SLOW TEST:56.316 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:07:17.074: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Apr  1 17:07:17.151: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-7026,SelfLink:/api/v1/namespaces/watch-7026/configmaps/e2e-watch-test-resource-version,UID:9a3e2868-54a0-11e9-9aab-028387864c62,ResourceVersion:4551,Generation:0,CreationTimestamp:2019-04-01 17:07:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr  1 17:07:17.151: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-7026,SelfLink:/api/v1/namespaces/watch-7026/configmaps/e2e-watch-test-resource-version,UID:9a3e2868-54a0-11e9-9aab-028387864c62,ResourceVersion:4552,Generation:0,CreationTimestamp:2019-04-01 17:07:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:07:17.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7026" for this suite.
Apr  1 17:07:23.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:07:23.335: INFO: namespace watch-7026 deletion completed in 6.1799322s

• [SLOW TEST:6.261 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:07:23.336: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Apr  1 17:07:23.421: INFO: Number of nodes with available pods: 0
Apr  1 17:07:23.421: INFO: Node ip-172-31-22-24 is running more than one daemon pod
Apr  1 17:07:24.433: INFO: Number of nodes with available pods: 0
Apr  1 17:07:24.433: INFO: Node ip-172-31-22-24 is running more than one daemon pod
Apr  1 17:07:25.434: INFO: Number of nodes with available pods: 0
Apr  1 17:07:25.434: INFO: Node ip-172-31-22-24 is running more than one daemon pod
Apr  1 17:07:26.450: INFO: Number of nodes with available pods: 3
Apr  1 17:07:26.450: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Apr  1 17:07:26.487: INFO: Number of nodes with available pods: 2
Apr  1 17:07:26.487: INFO: Node ip-172-31-75-215 is running more than one daemon pod
Apr  1 17:07:27.511: INFO: Number of nodes with available pods: 2
Apr  1 17:07:27.511: INFO: Node ip-172-31-75-215 is running more than one daemon pod
Apr  1 17:07:28.505: INFO: Number of nodes with available pods: 2
Apr  1 17:07:28.505: INFO: Node ip-172-31-75-215 is running more than one daemon pod
Apr  1 17:07:29.506: INFO: Number of nodes with available pods: 3
Apr  1 17:07:29.506: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5883, will wait for the garbage collector to delete the pods
Apr  1 17:07:29.595: INFO: Deleting DaemonSet.extensions daemon-set took: 10.447442ms
Apr  1 17:07:29.905: INFO: Terminating DaemonSet.extensions daemon-set pods took: 309.595499ms
Apr  1 17:07:41.809: INFO: Number of nodes with available pods: 0
Apr  1 17:07:41.809: INFO: Number of running nodes: 0, number of available pods: 0
Apr  1 17:07:41.813: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5883/daemonsets","resourceVersion":"4676"},"items":null}

Apr  1 17:07:41.817: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5883/pods","resourceVersion":"4676"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:07:41.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5883" for this suite.
Apr  1 17:07:47.850: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:07:47.964: INFO: namespace daemonsets-5883 deletion completed in 6.128457069s

• [SLOW TEST:24.628 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:07:47.964: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap that has name configmap-test-emptyKey-acac4251-54a0-11e9-871e-828ee0b576f8
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:07:48.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2469" for this suite.
Apr  1 17:07:54.024: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:07:54.156: INFO: namespace configmap-2469 deletion completed in 6.145774505s

• [SLOW TEST:6.193 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:07:54.156: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: executing a command with run --rm and attach with stdin
Apr  1 17:07:54.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 --namespace=kubectl-6441 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Apr  1 17:07:56.951: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Apr  1 17:07:56.952: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:07:58.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6441" for this suite.
Apr  1 17:08:04.977: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:08:05.118: INFO: namespace kubectl-6441 deletion completed in 6.155116161s

• [SLOW TEST:10.962 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:08:05.118: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Apr  1 17:08:05.161: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr  1 17:08:05.171: INFO: Waiting for terminating namespaces to be deleted...
Apr  1 17:08:05.176: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-22-24 before test
Apr  1 17:08:05.186: INFO: default-http-backend-kubernetes-worker-5b8b477c-swdj9 from ingress-nginx-kubernetes-worker started at 2019-04-01 16:46:41 +0000 UTC (1 container statuses recorded)
Apr  1 17:08:05.186: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
Apr  1 17:08:05.186: INFO: sonobuoy-systemd-logs-daemon-set-1ce1df115e164dcd-4wc8p from heptio-sonobuoy started at 2019-04-01 16:53:44 +0000 UTC (2 container statuses recorded)
Apr  1 17:08:05.186: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Apr  1 17:08:05.186: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr  1 17:08:05.186: INFO: coredns-6b957bfc77-w7lct from kube-system started at 2019-04-01 16:46:38 +0000 UTC (1 container statuses recorded)
Apr  1 17:08:05.186: INFO: 	Container coredns ready: true, restart count 0
Apr  1 17:08:05.186: INFO: nginx-ingress-controller-kubernetes-worker-xt5ts from ingress-nginx-kubernetes-worker started at 2019-04-01 16:46:41 +0000 UTC (1 container statuses recorded)
Apr  1 17:08:05.186: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Apr  1 17:08:05.186: INFO: monitoring-influxdb-grafana-v4-cfc94db54-csmb5 from kube-system started at 2019-04-01 16:46:38 +0000 UTC (2 container statuses recorded)
Apr  1 17:08:05.186: INFO: 	Container grafana ready: true, restart count 0
Apr  1 17:08:05.186: INFO: 	Container influxdb ready: true, restart count 0
Apr  1 17:08:05.186: INFO: coredns-6b957bfc77-lmplw from kube-system started at 2019-04-01 16:46:38 +0000 UTC (1 container statuses recorded)
Apr  1 17:08:05.186: INFO: 	Container coredns ready: true, restart count 0
Apr  1 17:08:05.186: INFO: kubernetes-dashboard-9f49769c8-bnt5k from kube-system started at 2019-04-01 16:46:38 +0000 UTC (1 container statuses recorded)
Apr  1 17:08:05.186: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Apr  1 17:08:05.186: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-3-176 before test
Apr  1 17:08:05.196: INFO: nginx-ingress-controller-kubernetes-worker-w7khc from ingress-nginx-kubernetes-worker started at 2019-04-01 16:46:54 +0000 UTC (1 container statuses recorded)
Apr  1 17:08:05.196: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Apr  1 17:08:05.196: INFO: metrics-server-v0.3.1-6d75b744b4-xmldb from kube-system started at 2019-04-01 16:46:59 +0000 UTC (2 container statuses recorded)
Apr  1 17:08:05.196: INFO: 	Container metrics-server ready: true, restart count 0
Apr  1 17:08:05.196: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Apr  1 17:08:05.196: INFO: sonobuoy from heptio-sonobuoy started at 2019-04-01 16:53:34 +0000 UTC (1 container statuses recorded)
Apr  1 17:08:05.196: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr  1 17:08:05.196: INFO: sonobuoy-systemd-logs-daemon-set-1ce1df115e164dcd-nl9n4 from heptio-sonobuoy started at 2019-04-01 16:53:44 +0000 UTC (2 container statuses recorded)
Apr  1 17:08:05.196: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Apr  1 17:08:05.196: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr  1 17:08:05.196: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-75-215 before test
Apr  1 17:08:05.206: INFO: nginx-ingress-controller-kubernetes-worker-7btnv from ingress-nginx-kubernetes-worker started at 2019-04-01 16:46:47 +0000 UTC (1 container statuses recorded)
Apr  1 17:08:05.206: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Apr  1 17:08:05.206: INFO: heapster-v1.6.0-beta.1-84cb679df9-6qmcv from kube-system started at 2019-04-01 16:47:00 +0000 UTC (4 container statuses recorded)
Apr  1 17:08:05.206: INFO: 	Container eventer ready: true, restart count 0
Apr  1 17:08:05.206: INFO: 	Container eventer-nanny ready: true, restart count 0
Apr  1 17:08:05.206: INFO: 	Container heapster ready: true, restart count 0
Apr  1 17:08:05.206: INFO: 	Container heapster-nanny ready: true, restart count 0
Apr  1 17:08:05.206: INFO: sonobuoy-e2e-job-f0d281cdea304082 from heptio-sonobuoy started at 2019-04-01 16:53:44 +0000 UTC (2 container statuses recorded)
Apr  1 17:08:05.206: INFO: 	Container e2e ready: true, restart count 0
Apr  1 17:08:05.206: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr  1 17:08:05.206: INFO: sonobuoy-systemd-logs-daemon-set-1ce1df115e164dcd-tz2fc from heptio-sonobuoy started at 2019-04-01 16:53:44 +0000 UTC (2 container statuses recorded)
Apr  1 17:08:05.206: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Apr  1 17:08:05.206: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-b95631e4-54a0-11e9-871e-828ee0b576f8 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-b95631e4-54a0-11e9-871e-828ee0b576f8 off the node ip-172-31-3-176
STEP: verifying the node doesn't have the label kubernetes.io/e2e-b95631e4-54a0-11e9-871e-828ee0b576f8
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:08:13.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6107" for this suite.
Apr  1 17:08:21.306: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:08:21.429: INFO: namespace sched-pred-6107 deletion completed in 8.135672225s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:16.311 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:08:21.429: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Apr  1 17:08:21.463: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:08:26.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3600" for this suite.
Apr  1 17:08:48.026: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:08:48.137: INFO: namespace init-container-3600 deletion completed in 22.124707918s

• [SLOW TEST:26.708 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:08:48.137: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  1 17:08:48.181: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d089c09c-54a0-11e9-871e-828ee0b576f8" in namespace "projected-9826" to be "success or failure"
Apr  1 17:08:48.185: INFO: Pod "downwardapi-volume-d089c09c-54a0-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.66075ms
Apr  1 17:08:50.190: INFO: Pod "downwardapi-volume-d089c09c-54a0-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009176766s
Apr  1 17:08:52.195: INFO: Pod "downwardapi-volume-d089c09c-54a0-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013817701s
STEP: Saw pod success
Apr  1 17:08:52.195: INFO: Pod "downwardapi-volume-d089c09c-54a0-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 17:08:52.198: INFO: Trying to get logs from node ip-172-31-3-176 pod downwardapi-volume-d089c09c-54a0-11e9-871e-828ee0b576f8 container client-container: <nil>
STEP: delete the pod
Apr  1 17:08:52.220: INFO: Waiting for pod downwardapi-volume-d089c09c-54a0-11e9-871e-828ee0b576f8 to disappear
Apr  1 17:08:52.223: INFO: Pod downwardapi-volume-d089c09c-54a0-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:08:52.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9826" for this suite.
Apr  1 17:08:58.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:08:58.349: INFO: namespace projected-9826 deletion completed in 6.122232901s

• [SLOW TEST:10.212 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:08:58.349: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  1 17:08:58.397: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d6a0aafb-54a0-11e9-871e-828ee0b576f8" in namespace "downward-api-9320" to be "success or failure"
Apr  1 17:08:58.402: INFO: Pod "downwardapi-volume-d6a0aafb-54a0-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.001758ms
Apr  1 17:09:00.406: INFO: Pod "downwardapi-volume-d6a0aafb-54a0-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009363922s
STEP: Saw pod success
Apr  1 17:09:00.406: INFO: Pod "downwardapi-volume-d6a0aafb-54a0-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 17:09:00.409: INFO: Trying to get logs from node ip-172-31-3-176 pod downwardapi-volume-d6a0aafb-54a0-11e9-871e-828ee0b576f8 container client-container: <nil>
STEP: delete the pod
Apr  1 17:09:00.432: INFO: Waiting for pod downwardapi-volume-d6a0aafb-54a0-11e9-871e-828ee0b576f8 to disappear
Apr  1 17:09:00.436: INFO: Pod downwardapi-volume-d6a0aafb-54a0-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:09:00.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9320" for this suite.
Apr  1 17:09:06.454: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:09:06.584: INFO: namespace downward-api-9320 deletion completed in 6.144087943s

• [SLOW TEST:8.235 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:09:06.584: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test env composition
Apr  1 17:09:06.641: INFO: Waiting up to 5m0s for pod "var-expansion-db8a3b08-54a0-11e9-871e-828ee0b576f8" in namespace "var-expansion-5772" to be "success or failure"
Apr  1 17:09:06.654: INFO: Pod "var-expansion-db8a3b08-54a0-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 12.758053ms
Apr  1 17:09:08.659: INFO: Pod "var-expansion-db8a3b08-54a0-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017268892s
Apr  1 17:09:10.663: INFO: Pod "var-expansion-db8a3b08-54a0-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021575724s
STEP: Saw pod success
Apr  1 17:09:10.663: INFO: Pod "var-expansion-db8a3b08-54a0-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 17:09:10.666: INFO: Trying to get logs from node ip-172-31-3-176 pod var-expansion-db8a3b08-54a0-11e9-871e-828ee0b576f8 container dapi-container: <nil>
STEP: delete the pod
Apr  1 17:09:10.690: INFO: Waiting for pod var-expansion-db8a3b08-54a0-11e9-871e-828ee0b576f8 to disappear
Apr  1 17:09:10.703: INFO: Pod var-expansion-db8a3b08-54a0-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:09:10.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5772" for this suite.
Apr  1 17:09:16.720: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:09:16.829: INFO: namespace var-expansion-5772 deletion completed in 6.122446234s

• [SLOW TEST:10.245 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:09:16.830: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  1 17:09:16.879: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e1a41e82-54a0-11e9-871e-828ee0b576f8" in namespace "downward-api-6380" to be "success or failure"
Apr  1 17:09:16.883: INFO: Pod "downwardapi-volume-e1a41e82-54a0-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.349581ms
Apr  1 17:09:18.887: INFO: Pod "downwardapi-volume-e1a41e82-54a0-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008554939s
Apr  1 17:09:20.892: INFO: Pod "downwardapi-volume-e1a41e82-54a0-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012922458s
STEP: Saw pod success
Apr  1 17:09:20.892: INFO: Pod "downwardapi-volume-e1a41e82-54a0-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 17:09:20.895: INFO: Trying to get logs from node ip-172-31-3-176 pod downwardapi-volume-e1a41e82-54a0-11e9-871e-828ee0b576f8 container client-container: <nil>
STEP: delete the pod
Apr  1 17:09:20.916: INFO: Waiting for pod downwardapi-volume-e1a41e82-54a0-11e9-871e-828ee0b576f8 to disappear
Apr  1 17:09:20.920: INFO: Pod downwardapi-volume-e1a41e82-54a0-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:09:20.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6380" for this suite.
Apr  1 17:09:26.936: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:09:27.048: INFO: namespace downward-api-6380 deletion completed in 6.125421529s

• [SLOW TEST:10.219 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:09:27.049: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  1 17:09:27.082: INFO: Creating deployment "test-recreate-deployment"
Apr  1 17:09:27.092: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Apr  1 17:09:27.100: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Apr  1 17:09:29.107: INFO: Waiting deployment "test-recreate-deployment" to complete
Apr  1 17:09:29.111: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689735367, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689735367, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689735367, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689735367, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d57d5ff7c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  1 17:09:31.116: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Apr  1 17:09:31.125: INFO: Updating deployment test-recreate-deployment
Apr  1 17:09:31.125: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr  1 17:09:31.201: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-1401,SelfLink:/apis/apps/v1/namespaces/deployment-1401/deployments/test-recreate-deployment,UID:e7b5c83d-54a0-11e9-9aab-028387864c62,ResourceVersion:5154,Generation:2,CreationTimestamp:2019-04-01 17:09:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-04-01 17:09:31 +0000 UTC 2019-04-01 17:09:31 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-04-01 17:09:31 +0000 UTC 2019-04-01 17:09:27 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-c9cbd8684" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Apr  1 17:09:31.206: INFO: New ReplicaSet "test-recreate-deployment-c9cbd8684" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-c9cbd8684,GenerateName:,Namespace:deployment-1401,SelfLink:/apis/apps/v1/namespaces/deployment-1401/replicasets/test-recreate-deployment-c9cbd8684,UID:ea2958d3-54a0-11e9-84d7-12a9dd9b0c8a,ResourceVersion:5151,Generation:1,CreationTimestamp:2019-04-01 17:09:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment e7b5c83d-54a0-11e9-9aab-028387864c62 0xc002cf5570 0xc002cf5571}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr  1 17:09:31.206: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Apr  1 17:09:31.206: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7d57d5ff7c,GenerateName:,Namespace:deployment-1401,SelfLink:/apis/apps/v1/namespaces/deployment-1401/replicasets/test-recreate-deployment-7d57d5ff7c,UID:e7bcb90b-54a0-11e9-84d7-12a9dd9b0c8a,ResourceVersion:5141,Generation:2,CreationTimestamp:2019-04-01 17:09:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment e7b5c83d-54a0-11e9-9aab-028387864c62 0xc002cf54b7 0xc002cf54b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr  1 17:09:31.210: INFO: Pod "test-recreate-deployment-c9cbd8684-zmwdn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-c9cbd8684-zmwdn,GenerateName:test-recreate-deployment-c9cbd8684-,Namespace:deployment-1401,SelfLink:/api/v1/namespaces/deployment-1401/pods/test-recreate-deployment-c9cbd8684-zmwdn,UID:ea2a66f8-54a0-11e9-84d7-12a9dd9b0c8a,ResourceVersion:5153,Generation:0,CreationTimestamp:2019-04-01 17:09:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-c9cbd8684 ea2958d3-54a0-11e9-84d7-12a9dd9b0c8a 0xc002cf5e10 0xc002cf5e11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-ztmrj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ztmrj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ztmrj true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-3-176,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002cf5e90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002cf5eb0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:09:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:09:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:09:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:09:31 +0000 UTC  }],Message:,Reason:,HostIP:172.31.3.176,PodIP:,StartTime:2019-04-01 17:09:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:09:31.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1401" for this suite.
Apr  1 17:09:37.230: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:09:37.347: INFO: namespace deployment-1401 deletion completed in 6.133363064s

• [SLOW TEST:10.298 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:09:37.347: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  1 17:09:37.396: INFO: Waiting up to 5m0s for pod "downwardapi-volume-eddf2f2e-54a0-11e9-871e-828ee0b576f8" in namespace "downward-api-8861" to be "success or failure"
Apr  1 17:09:37.400: INFO: Pod "downwardapi-volume-eddf2f2e-54a0-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.067106ms
Apr  1 17:09:39.405: INFO: Pod "downwardapi-volume-eddf2f2e-54a0-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008897803s
Apr  1 17:09:41.410: INFO: Pod "downwardapi-volume-eddf2f2e-54a0-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013519951s
STEP: Saw pod success
Apr  1 17:09:41.410: INFO: Pod "downwardapi-volume-eddf2f2e-54a0-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 17:09:41.414: INFO: Trying to get logs from node ip-172-31-3-176 pod downwardapi-volume-eddf2f2e-54a0-11e9-871e-828ee0b576f8 container client-container: <nil>
STEP: delete the pod
Apr  1 17:09:41.434: INFO: Waiting for pod downwardapi-volume-eddf2f2e-54a0-11e9-871e-828ee0b576f8 to disappear
Apr  1 17:09:41.437: INFO: Pod downwardapi-volume-eddf2f2e-54a0-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:09:41.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8861" for this suite.
Apr  1 17:09:47.457: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:09:47.568: INFO: namespace downward-api-8861 deletion completed in 6.127220022s

• [SLOW TEST:10.221 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:09:47.568: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  1 17:09:47.625: INFO: Create a RollingUpdate DaemonSet
Apr  1 17:09:47.634: INFO: Check that daemon pods launch on every node of the cluster
Apr  1 17:09:47.655: INFO: Number of nodes with available pods: 0
Apr  1 17:09:47.655: INFO: Node ip-172-31-22-24 is running more than one daemon pod
Apr  1 17:09:48.920: INFO: Number of nodes with available pods: 0
Apr  1 17:09:48.920: INFO: Node ip-172-31-22-24 is running more than one daemon pod
Apr  1 17:09:49.663: INFO: Number of nodes with available pods: 3
Apr  1 17:09:49.663: INFO: Number of running nodes: 3, number of available pods: 3
Apr  1 17:09:49.663: INFO: Update the DaemonSet to trigger a rollout
Apr  1 17:09:49.672: INFO: Updating DaemonSet daemon-set
Apr  1 17:10:04.684: INFO: Roll back the DaemonSet before rollout is complete
Apr  1 17:10:04.693: INFO: Updating DaemonSet daemon-set
Apr  1 17:10:04.693: INFO: Make sure DaemonSet rollback is complete
Apr  1 17:10:04.698: INFO: Wrong image for pod: daemon-set-gdzdt. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr  1 17:10:04.698: INFO: Pod daemon-set-gdzdt is not available
Apr  1 17:10:05.832: INFO: Wrong image for pod: daemon-set-gdzdt. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr  1 17:10:05.832: INFO: Pod daemon-set-gdzdt is not available
Apr  1 17:10:06.706: INFO: Wrong image for pod: daemon-set-gdzdt. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr  1 17:10:06.706: INFO: Pod daemon-set-gdzdt is not available
Apr  1 17:10:07.706: INFO: Wrong image for pod: daemon-set-gdzdt. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr  1 17:10:07.706: INFO: Pod daemon-set-gdzdt is not available
Apr  1 17:10:08.706: INFO: Wrong image for pod: daemon-set-gdzdt. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr  1 17:10:08.706: INFO: Pod daemon-set-gdzdt is not available
Apr  1 17:10:09.706: INFO: Wrong image for pod: daemon-set-gdzdt. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr  1 17:10:09.706: INFO: Pod daemon-set-gdzdt is not available
Apr  1 17:10:10.706: INFO: Wrong image for pod: daemon-set-gdzdt. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr  1 17:10:10.706: INFO: Pod daemon-set-gdzdt is not available
Apr  1 17:10:11.706: INFO: Wrong image for pod: daemon-set-gdzdt. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr  1 17:10:11.706: INFO: Pod daemon-set-gdzdt is not available
Apr  1 17:10:12.706: INFO: Wrong image for pod: daemon-set-gdzdt. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr  1 17:10:12.706: INFO: Pod daemon-set-gdzdt is not available
Apr  1 17:10:13.706: INFO: Wrong image for pod: daemon-set-gdzdt. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr  1 17:10:13.706: INFO: Pod daemon-set-gdzdt is not available
Apr  1 17:10:14.706: INFO: Pod daemon-set-4ztwv is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-535, will wait for the garbage collector to delete the pods
Apr  1 17:10:14.781: INFO: Deleting DaemonSet.extensions daemon-set took: 10.938573ms
Apr  1 17:10:15.081: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.234199ms
Apr  1 17:11:53.985: INFO: Number of nodes with available pods: 0
Apr  1 17:11:53.985: INFO: Number of running nodes: 0, number of available pods: 0
Apr  1 17:11:53.989: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-535/daemonsets","resourceVersion":"5540"},"items":null}

Apr  1 17:11:53.992: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-535/pods","resourceVersion":"5540"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:11:54.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-535" for this suite.
Apr  1 17:12:00.025: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:12:00.141: INFO: namespace daemonsets-535 deletion completed in 6.130687607s

• [SLOW TEST:132.573 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:12:00.141: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Apr  1 17:12:04.720: INFO: Successfully updated pod "labelsupdate42fb9c6d-54a1-11e9-871e-828ee0b576f8"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:12:06.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-517" for this suite.
Apr  1 17:12:28.756: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:12:28.869: INFO: namespace projected-517 deletion completed in 22.126751422s

• [SLOW TEST:28.728 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:12:28.870: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Apr  1 17:12:34.010: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:12:35.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-7328" for this suite.
Apr  1 17:12:57.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:12:57.181: INFO: namespace replicaset-7328 deletion completed in 22.135425225s

• [SLOW TEST:28.311 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:12:57.181: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:13:57.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9334" for this suite.
Apr  1 17:14:19.247: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:14:19.359: INFO: namespace container-probe-9334 deletion completed in 22.125158711s

• [SLOW TEST:82.178 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:14:19.359: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Apr  1 17:14:19.405: INFO: Waiting up to 5m0s for pod "pod-95f69d38-54a1-11e9-871e-828ee0b576f8" in namespace "emptydir-4144" to be "success or failure"
Apr  1 17:14:19.408: INFO: Pod "pod-95f69d38-54a1-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.503448ms
Apr  1 17:14:21.412: INFO: Pod "pod-95f69d38-54a1-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007815333s
Apr  1 17:14:23.417: INFO: Pod "pod-95f69d38-54a1-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012303952s
STEP: Saw pod success
Apr  1 17:14:23.417: INFO: Pod "pod-95f69d38-54a1-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 17:14:23.421: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-95f69d38-54a1-11e9-871e-828ee0b576f8 container test-container: <nil>
STEP: delete the pod
Apr  1 17:14:23.446: INFO: Waiting for pod pod-95f69d38-54a1-11e9-871e-828ee0b576f8 to disappear
Apr  1 17:14:23.449: INFO: Pod pod-95f69d38-54a1-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:14:23.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4144" for this suite.
Apr  1 17:14:29.466: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:14:29.577: INFO: namespace emptydir-4144 deletion completed in 6.124183683s

• [SLOW TEST:10.218 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:14:29.577: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1619
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr  1 17:14:29.615: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-9074'
Apr  1 17:14:29.703: INFO: stderr: ""
Apr  1 17:14:29.704: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Apr  1 17:14:34.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pod e2e-test-nginx-pod --namespace=kubectl-9074 -o json'
Apr  1 17:14:34.829: INFO: stderr: ""
Apr  1 17:14:34.830: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-04-01T17:14:29Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-9074\",\n        \"resourceVersion\": \"5985\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-9074/pods/e2e-test-nginx-pod\",\n        \"uid\": \"9c19859b-54a1-11e9-84d7-12a9dd9b0c8a\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-59v48\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-172-31-3-176\",\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-59v48\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-59v48\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-01T17:14:29Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-01T17:14:31Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-01T17:14:31Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-01T17:14:29Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://c45a55e50e847d9e6cd76310702ea2981a594b48826b6bd4be54096e463b7c93\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-04-01T17:14:30Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.31.3.176\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.1.83.64\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-04-01T17:14:29Z\"\n    }\n}\n"
STEP: replace the image in the pod
Apr  1 17:14:34.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 replace -f - --namespace=kubectl-9074'
Apr  1 17:14:35.066: INFO: stderr: ""
Apr  1 17:14:35.066: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1624
Apr  1 17:14:35.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 delete pods e2e-test-nginx-pod --namespace=kubectl-9074'
Apr  1 17:14:43.949: INFO: stderr: ""
Apr  1 17:14:43.949: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:14:43.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9074" for this suite.
Apr  1 17:14:49.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:14:50.123: INFO: namespace kubectl-9074 deletion completed in 6.168351177s

• [SLOW TEST:20.546 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:14:50.123: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-a84c7edc-54a1-11e9-871e-828ee0b576f8
STEP: Creating a pod to test consume secrets
Apr  1 17:14:50.172: INFO: Waiting up to 5m0s for pod "pod-secrets-a84d9403-54a1-11e9-871e-828ee0b576f8" in namespace "secrets-6254" to be "success or failure"
Apr  1 17:14:50.177: INFO: Pod "pod-secrets-a84d9403-54a1-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.52619ms
Apr  1 17:14:52.181: INFO: Pod "pod-secrets-a84d9403-54a1-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008470422s
Apr  1 17:14:54.189: INFO: Pod "pod-secrets-a84d9403-54a1-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01638853s
STEP: Saw pod success
Apr  1 17:14:54.189: INFO: Pod "pod-secrets-a84d9403-54a1-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 17:14:54.193: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-secrets-a84d9403-54a1-11e9-871e-828ee0b576f8 container secret-env-test: <nil>
STEP: delete the pod
Apr  1 17:14:54.215: INFO: Waiting for pod pod-secrets-a84d9403-54a1-11e9-871e-828ee0b576f8 to disappear
Apr  1 17:14:54.218: INFO: Pod pod-secrets-a84d9403-54a1-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:14:54.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6254" for this suite.
Apr  1 17:15:00.244: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:15:00.431: INFO: namespace secrets-6254 deletion completed in 6.206646591s

• [SLOW TEST:10.308 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:15:00.432: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:15:02.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-8612" for this suite.
Apr  1 17:15:08.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:15:08.665: INFO: namespace emptydir-wrapper-8612 deletion completed in 6.12145223s

• [SLOW TEST:8.234 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:15:08.665: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  1 17:15:08.729: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"b355ecf7-54a1-11e9-9aab-028387864c62", Controller:(*bool)(0xc0027d0eae), BlockOwnerDeletion:(*bool)(0xc0027d0eaf)}}
Apr  1 17:15:08.735: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"b353be6c-54a1-11e9-9aab-028387864c62", Controller:(*bool)(0xc002e61b3e), BlockOwnerDeletion:(*bool)(0xc002e61b3f)}}
Apr  1 17:15:08.741: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"b3551116-54a1-11e9-9aab-028387864c62", Controller:(*bool)(0xc002e61dae), BlockOwnerDeletion:(*bool)(0xc002e61daf)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:15:13.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1554" for this suite.
Apr  1 17:15:19.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:15:19.893: INFO: namespace gc-1554 deletion completed in 6.137577377s

• [SLOW TEST:11.228 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:15:19.893: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:15:46.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-9431" for this suite.
Apr  1 17:15:52.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:15:52.185: INFO: namespace namespaces-9431 deletion completed in 6.13790236s
STEP: Destroying namespace "nsdeletetest-5189" for this suite.
Apr  1 17:15:52.188: INFO: Namespace nsdeletetest-5189 was already deleted
STEP: Destroying namespace "nsdeletetest-8219" for this suite.
Apr  1 17:15:58.202: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:15:58.315: INFO: namespace nsdeletetest-8219 deletion completed in 6.126701744s

• [SLOW TEST:38.421 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:15:58.315: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-d0f1ef68-54a1-11e9-871e-828ee0b576f8
STEP: Creating a pod to test consume secrets
Apr  1 17:15:58.368: INFO: Waiting up to 5m0s for pod "pod-secrets-d0f34ed5-54a1-11e9-871e-828ee0b576f8" in namespace "secrets-7488" to be "success or failure"
Apr  1 17:15:58.372: INFO: Pod "pod-secrets-d0f34ed5-54a1-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.526882ms
Apr  1 17:16:00.376: INFO: Pod "pod-secrets-d0f34ed5-54a1-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008703592s
STEP: Saw pod success
Apr  1 17:16:00.376: INFO: Pod "pod-secrets-d0f34ed5-54a1-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 17:16:00.380: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-secrets-d0f34ed5-54a1-11e9-871e-828ee0b576f8 container secret-volume-test: <nil>
STEP: delete the pod
Apr  1 17:16:00.407: INFO: Waiting for pod pod-secrets-d0f34ed5-54a1-11e9-871e-828ee0b576f8 to disappear
Apr  1 17:16:00.411: INFO: Pod pod-secrets-d0f34ed5-54a1-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:16:00.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7488" for this suite.
Apr  1 17:16:06.429: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:16:06.597: INFO: namespace secrets-7488 deletion completed in 6.182446895s

• [SLOW TEST:8.282 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:16:06.597: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Starting the proxy
Apr  1 17:16:06.632: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-994794615 proxy --unix-socket=/tmp/kubectl-proxy-unix303973738/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:16:06.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-568" for this suite.
Apr  1 17:16:12.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:16:12.823: INFO: namespace kubectl-568 deletion completed in 6.124651601s

• [SLOW TEST:6.226 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:16:12.824: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Apr  1 17:16:12.859: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:16:16.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2719" for this suite.
Apr  1 17:16:22.969: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:16:23.126: INFO: namespace init-container-2719 deletion completed in 6.173565538s

• [SLOW TEST:10.302 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:16:23.126: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-9745/configmap-test-dfbea7d0-54a1-11e9-871e-828ee0b576f8
STEP: Creating a pod to test consume configMaps
Apr  1 17:16:23.195: INFO: Waiting up to 5m0s for pod "pod-configmaps-dfbfd9c8-54a1-11e9-871e-828ee0b576f8" in namespace "configmap-9745" to be "success or failure"
Apr  1 17:16:23.198: INFO: Pod "pod-configmaps-dfbfd9c8-54a1-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.807334ms
Apr  1 17:16:25.203: INFO: Pod "pod-configmaps-dfbfd9c8-54a1-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008784167s
STEP: Saw pod success
Apr  1 17:16:25.203: INFO: Pod "pod-configmaps-dfbfd9c8-54a1-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 17:16:25.207: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-configmaps-dfbfd9c8-54a1-11e9-871e-828ee0b576f8 container env-test: <nil>
STEP: delete the pod
Apr  1 17:16:25.690: INFO: Waiting for pod pod-configmaps-dfbfd9c8-54a1-11e9-871e-828ee0b576f8 to disappear
Apr  1 17:16:25.697: INFO: Pod pod-configmaps-dfbfd9c8-54a1-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:16:25.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9745" for this suite.
Apr  1 17:16:31.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:16:31.840: INFO: namespace configmap-9745 deletion completed in 6.138672277s

• [SLOW TEST:8.714 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:16:31.840: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override arguments
Apr  1 17:16:31.886: INFO: Waiting up to 5m0s for pod "client-containers-e4edab68-54a1-11e9-871e-828ee0b576f8" in namespace "containers-238" to be "success or failure"
Apr  1 17:16:31.891: INFO: Pod "client-containers-e4edab68-54a1-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.900208ms
Apr  1 17:16:33.895: INFO: Pod "client-containers-e4edab68-54a1-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009315199s
STEP: Saw pod success
Apr  1 17:16:33.895: INFO: Pod "client-containers-e4edab68-54a1-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 17:16:33.899: INFO: Trying to get logs from node ip-172-31-3-176 pod client-containers-e4edab68-54a1-11e9-871e-828ee0b576f8 container test-container: <nil>
STEP: delete the pod
Apr  1 17:16:33.921: INFO: Waiting for pod client-containers-e4edab68-54a1-11e9-871e-828ee0b576f8 to disappear
Apr  1 17:16:33.924: INFO: Pod client-containers-e4edab68-54a1-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:16:33.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-238" for this suite.
Apr  1 17:16:39.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:16:40.057: INFO: namespace containers-238 deletion completed in 6.128598499s

• [SLOW TEST:8.217 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:16:40.057: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:177
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:16:40.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9845" for this suite.
Apr  1 17:17:02.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:17:02.645: INFO: namespace pods-9845 deletion completed in 22.530813718s

• [SLOW TEST:22.589 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:17:02.646: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:17:02.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5614" for this suite.
Apr  1 17:17:24.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:17:24.854: INFO: namespace kubelet-test-5614 deletion completed in 22.132336461s

• [SLOW TEST:22.208 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:17:24.854: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4755.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4755.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr  1 17:17:28.979: INFO: DNS probes using dns-4755/dns-test-0488370c-54a2-11e9-871e-828ee0b576f8 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:17:28.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4755" for this suite.
Apr  1 17:17:35.016: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:17:35.148: INFO: namespace dns-4755 deletion completed in 6.149246952s

• [SLOW TEST:10.294 seconds]
[sig-network] DNS
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:17:35.148: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Apr  1 17:17:35.192: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr  1 17:17:35.201: INFO: Waiting for terminating namespaces to be deleted...
Apr  1 17:17:35.205: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-22-24 before test
Apr  1 17:17:35.215: INFO: coredns-6b957bfc77-lmplw from kube-system started at 2019-04-01 16:46:38 +0000 UTC (1 container statuses recorded)
Apr  1 17:17:35.215: INFO: 	Container coredns ready: true, restart count 0
Apr  1 17:17:35.215: INFO: kubernetes-dashboard-9f49769c8-bnt5k from kube-system started at 2019-04-01 16:46:38 +0000 UTC (1 container statuses recorded)
Apr  1 17:17:35.215: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Apr  1 17:17:35.215: INFO: monitoring-influxdb-grafana-v4-cfc94db54-csmb5 from kube-system started at 2019-04-01 16:46:38 +0000 UTC (2 container statuses recorded)
Apr  1 17:17:35.215: INFO: 	Container grafana ready: true, restart count 0
Apr  1 17:17:35.215: INFO: 	Container influxdb ready: true, restart count 0
Apr  1 17:17:35.215: INFO: coredns-6b957bfc77-w7lct from kube-system started at 2019-04-01 16:46:38 +0000 UTC (1 container statuses recorded)
Apr  1 17:17:35.215: INFO: 	Container coredns ready: true, restart count 0
Apr  1 17:17:35.215: INFO: nginx-ingress-controller-kubernetes-worker-xt5ts from ingress-nginx-kubernetes-worker started at 2019-04-01 16:46:41 +0000 UTC (1 container statuses recorded)
Apr  1 17:17:35.215: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Apr  1 17:17:35.215: INFO: default-http-backend-kubernetes-worker-5b8b477c-swdj9 from ingress-nginx-kubernetes-worker started at 2019-04-01 16:46:41 +0000 UTC (1 container statuses recorded)
Apr  1 17:17:35.215: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
Apr  1 17:17:35.215: INFO: sonobuoy-systemd-logs-daemon-set-1ce1df115e164dcd-4wc8p from heptio-sonobuoy started at 2019-04-01 16:53:44 +0000 UTC (2 container statuses recorded)
Apr  1 17:17:35.215: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Apr  1 17:17:35.215: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr  1 17:17:35.215: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-3-176 before test
Apr  1 17:17:35.222: INFO: sonobuoy-systemd-logs-daemon-set-1ce1df115e164dcd-nl9n4 from heptio-sonobuoy started at 2019-04-01 16:53:44 +0000 UTC (2 container statuses recorded)
Apr  1 17:17:35.222: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Apr  1 17:17:35.222: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr  1 17:17:35.222: INFO: nginx-ingress-controller-kubernetes-worker-w7khc from ingress-nginx-kubernetes-worker started at 2019-04-01 16:46:54 +0000 UTC (1 container statuses recorded)
Apr  1 17:17:35.222: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Apr  1 17:17:35.222: INFO: metrics-server-v0.3.1-6d75b744b4-xmldb from kube-system started at 2019-04-01 16:46:59 +0000 UTC (2 container statuses recorded)
Apr  1 17:17:35.222: INFO: 	Container metrics-server ready: true, restart count 0
Apr  1 17:17:35.222: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Apr  1 17:17:35.222: INFO: sonobuoy from heptio-sonobuoy started at 2019-04-01 16:53:34 +0000 UTC (1 container statuses recorded)
Apr  1 17:17:35.222: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr  1 17:17:35.222: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-75-215 before test
Apr  1 17:17:35.234: INFO: nginx-ingress-controller-kubernetes-worker-7btnv from ingress-nginx-kubernetes-worker started at 2019-04-01 16:46:47 +0000 UTC (1 container statuses recorded)
Apr  1 17:17:35.234: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Apr  1 17:17:35.234: INFO: heapster-v1.6.0-beta.1-84cb679df9-6qmcv from kube-system started at 2019-04-01 16:47:00 +0000 UTC (4 container statuses recorded)
Apr  1 17:17:35.234: INFO: 	Container eventer ready: true, restart count 0
Apr  1 17:17:35.234: INFO: 	Container eventer-nanny ready: true, restart count 0
Apr  1 17:17:35.234: INFO: 	Container heapster ready: true, restart count 0
Apr  1 17:17:35.234: INFO: 	Container heapster-nanny ready: true, restart count 0
Apr  1 17:17:35.234: INFO: sonobuoy-e2e-job-f0d281cdea304082 from heptio-sonobuoy started at 2019-04-01 16:53:44 +0000 UTC (2 container statuses recorded)
Apr  1 17:17:35.234: INFO: 	Container e2e ready: true, restart count 0
Apr  1 17:17:35.234: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr  1 17:17:35.234: INFO: sonobuoy-systemd-logs-daemon-set-1ce1df115e164dcd-tz2fc from heptio-sonobuoy started at 2019-04-01 16:53:44 +0000 UTC (2 container statuses recorded)
Apr  1 17:17:35.234: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Apr  1 17:17:35.234: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: verifying the node has the label node ip-172-31-22-24
STEP: verifying the node has the label node ip-172-31-3-176
STEP: verifying the node has the label node ip-172-31-75-215
Apr  1 17:17:35.286: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-172-31-3-176
Apr  1 17:17:35.286: INFO: Pod sonobuoy-e2e-job-f0d281cdea304082 requesting resource cpu=0m on Node ip-172-31-75-215
Apr  1 17:17:35.286: INFO: Pod sonobuoy-systemd-logs-daemon-set-1ce1df115e164dcd-4wc8p requesting resource cpu=0m on Node ip-172-31-22-24
Apr  1 17:17:35.286: INFO: Pod sonobuoy-systemd-logs-daemon-set-1ce1df115e164dcd-nl9n4 requesting resource cpu=0m on Node ip-172-31-3-176
Apr  1 17:17:35.286: INFO: Pod sonobuoy-systemd-logs-daemon-set-1ce1df115e164dcd-tz2fc requesting resource cpu=0m on Node ip-172-31-75-215
Apr  1 17:17:35.286: INFO: Pod default-http-backend-kubernetes-worker-5b8b477c-swdj9 requesting resource cpu=10m on Node ip-172-31-22-24
Apr  1 17:17:35.286: INFO: Pod nginx-ingress-controller-kubernetes-worker-7btnv requesting resource cpu=0m on Node ip-172-31-75-215
Apr  1 17:17:35.286: INFO: Pod nginx-ingress-controller-kubernetes-worker-w7khc requesting resource cpu=0m on Node ip-172-31-3-176
Apr  1 17:17:35.286: INFO: Pod nginx-ingress-controller-kubernetes-worker-xt5ts requesting resource cpu=0m on Node ip-172-31-22-24
Apr  1 17:17:35.286: INFO: Pod coredns-6b957bfc77-lmplw requesting resource cpu=100m on Node ip-172-31-22-24
Apr  1 17:17:35.286: INFO: Pod coredns-6b957bfc77-w7lct requesting resource cpu=100m on Node ip-172-31-22-24
Apr  1 17:17:35.286: INFO: Pod heapster-v1.6.0-beta.1-84cb679df9-6qmcv requesting resource cpu=288m on Node ip-172-31-75-215
Apr  1 17:17:35.286: INFO: Pod kubernetes-dashboard-9f49769c8-bnt5k requesting resource cpu=0m on Node ip-172-31-22-24
Apr  1 17:17:35.286: INFO: Pod metrics-server-v0.3.1-6d75b744b4-xmldb requesting resource cpu=53m on Node ip-172-31-3-176
Apr  1 17:17:35.286: INFO: Pod monitoring-influxdb-grafana-v4-cfc94db54-csmb5 requesting resource cpu=200m on Node ip-172-31-22-24
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0ab962ab-54a2-11e9-871e-828ee0b576f8.1591693c92d8b788], Reason = [Scheduled], Message = [Successfully assigned sched-pred-1629/filler-pod-0ab962ab-54a2-11e9-871e-828ee0b576f8 to ip-172-31-22-24]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0ab962ab-54a2-11e9-871e-828ee0b576f8.1591693cd1425756], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0ab962ab-54a2-11e9-871e-828ee0b576f8.1591693cd7207af7], Reason = [Created], Message = [Created container filler-pod-0ab962ab-54a2-11e9-871e-828ee0b576f8]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0ab962ab-54a2-11e9-871e-828ee0b576f8.1591693ce603e95f], Reason = [Started], Message = [Started container filler-pod-0ab962ab-54a2-11e9-871e-828ee0b576f8]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0abb60c1-54a2-11e9-871e-828ee0b576f8.1591693c936e59d4], Reason = [Scheduled], Message = [Successfully assigned sched-pred-1629/filler-pod-0abb60c1-54a2-11e9-871e-828ee0b576f8 to ip-172-31-3-176]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0abb60c1-54a2-11e9-871e-828ee0b576f8.1591693cd96cebd0], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0abb60c1-54a2-11e9-871e-828ee0b576f8.1591693ce09e4228], Reason = [Created], Message = [Created container filler-pod-0abb60c1-54a2-11e9-871e-828ee0b576f8]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0abb60c1-54a2-11e9-871e-828ee0b576f8.1591693cf11c7803], Reason = [Started], Message = [Started container filler-pod-0abb60c1-54a2-11e9-871e-828ee0b576f8]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0abc5a04-54a2-11e9-871e-828ee0b576f8.1591693c93f9bec0], Reason = [Scheduled], Message = [Successfully assigned sched-pred-1629/filler-pod-0abc5a04-54a2-11e9-871e-828ee0b576f8 to ip-172-31-75-215]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0abc5a04-54a2-11e9-871e-828ee0b576f8.1591693cd74e4706], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0abc5a04-54a2-11e9-871e-828ee0b576f8.1591693cdcc7d0a8], Reason = [Created], Message = [Created container filler-pod-0abc5a04-54a2-11e9-871e-828ee0b576f8]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0abc5a04-54a2-11e9-871e-828ee0b576f8.1591693ced5c0fbd], Reason = [Started], Message = [Started container filler-pod-0abc5a04-54a2-11e9-871e-828ee0b576f8]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1591693d84698cb9], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node ip-172-31-22-24
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-172-31-3-176
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-172-31-75-215
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:17:40.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1629" for this suite.
Apr  1 17:17:46.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:17:46.744: INFO: namespace sched-pred-1629 deletion completed in 6.324990304s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:11.596 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:17:46.745: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1510
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr  1 17:17:46.789: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-8897'
Apr  1 17:17:46.911: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr  1 17:17:46.911: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1515
Apr  1 17:17:46.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 delete jobs e2e-test-nginx-job --namespace=kubectl-8897'
Apr  1 17:17:47.022: INFO: stderr: ""
Apr  1 17:17:47.022: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:17:47.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8897" for this suite.
Apr  1 17:18:09.047: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:18:09.179: INFO: namespace kubectl-8897 deletion completed in 22.152205788s

• [SLOW TEST:22.435 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:18:09.180: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Apr  1 17:18:14.349: INFO: Successfully updated pod "labelsupdate1f4b4c9b-54a2-11e9-871e-828ee0b576f8"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:18:16.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5593" for this suite.
Apr  1 17:18:38.395: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:18:38.517: INFO: namespace downward-api-5593 deletion completed in 22.145755021s

• [SLOW TEST:29.337 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:18:38.517: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-306ec27e-54a2-11e9-871e-828ee0b576f8
STEP: Creating a pod to test consume configMaps
Apr  1 17:18:38.566: INFO: Waiting up to 5m0s for pod "pod-configmaps-306ff5b7-54a2-11e9-871e-828ee0b576f8" in namespace "configmap-7580" to be "success or failure"
Apr  1 17:18:38.572: INFO: Pod "pod-configmaps-306ff5b7-54a2-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.661543ms
Apr  1 17:18:40.576: INFO: Pod "pod-configmaps-306ff5b7-54a2-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009812696s
Apr  1 17:18:42.583: INFO: Pod "pod-configmaps-306ff5b7-54a2-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016682132s
STEP: Saw pod success
Apr  1 17:18:42.583: INFO: Pod "pod-configmaps-306ff5b7-54a2-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 17:18:42.588: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-configmaps-306ff5b7-54a2-11e9-871e-828ee0b576f8 container configmap-volume-test: <nil>
STEP: delete the pod
Apr  1 17:18:42.610: INFO: Waiting for pod pod-configmaps-306ff5b7-54a2-11e9-871e-828ee0b576f8 to disappear
Apr  1 17:18:42.614: INFO: Pod pod-configmaps-306ff5b7-54a2-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:18:42.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7580" for this suite.
Apr  1 17:18:48.638: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:18:48.777: INFO: namespace configmap-7580 deletion completed in 6.152890936s

• [SLOW TEST:10.260 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:18:48.777: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-368d66dc-54a2-11e9-871e-828ee0b576f8
STEP: Creating a pod to test consume secrets
Apr  1 17:18:48.839: INFO: Waiting up to 5m0s for pod "pod-secrets-368f73cb-54a2-11e9-871e-828ee0b576f8" in namespace "secrets-5481" to be "success or failure"
Apr  1 17:18:48.846: INFO: Pod "pod-secrets-368f73cb-54a2-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.125598ms
Apr  1 17:18:50.858: INFO: Pod "pod-secrets-368f73cb-54a2-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018899672s
Apr  1 17:18:52.873: INFO: Pod "pod-secrets-368f73cb-54a2-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033279153s
STEP: Saw pod success
Apr  1 17:18:52.873: INFO: Pod "pod-secrets-368f73cb-54a2-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 17:18:52.891: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-secrets-368f73cb-54a2-11e9-871e-828ee0b576f8 container secret-volume-test: <nil>
STEP: delete the pod
Apr  1 17:18:52.936: INFO: Waiting for pod pod-secrets-368f73cb-54a2-11e9-871e-828ee0b576f8 to disappear
Apr  1 17:18:52.943: INFO: Pod pod-secrets-368f73cb-54a2-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:18:52.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5481" for this suite.
Apr  1 17:18:58.971: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:18:59.111: INFO: namespace secrets-5481 deletion completed in 6.161803995s

• [SLOW TEST:10.334 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:18:59.112: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-projected-tpbd
STEP: Creating a pod to test atomic-volume-subpath
Apr  1 17:18:59.168: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-tpbd" in namespace "subpath-5689" to be "success or failure"
Apr  1 17:18:59.174: INFO: Pod "pod-subpath-test-projected-tpbd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.217817ms
Apr  1 17:19:01.179: INFO: Pod "pod-subpath-test-projected-tpbd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011230337s
Apr  1 17:19:03.195: INFO: Pod "pod-subpath-test-projected-tpbd": Phase="Running", Reason="", readiness=true. Elapsed: 4.026499857s
Apr  1 17:19:05.199: INFO: Pod "pod-subpath-test-projected-tpbd": Phase="Running", Reason="", readiness=true. Elapsed: 6.030930342s
Apr  1 17:19:07.205: INFO: Pod "pod-subpath-test-projected-tpbd": Phase="Running", Reason="", readiness=true. Elapsed: 8.036303767s
Apr  1 17:19:09.213: INFO: Pod "pod-subpath-test-projected-tpbd": Phase="Running", Reason="", readiness=true. Elapsed: 10.044719666s
Apr  1 17:19:11.222: INFO: Pod "pod-subpath-test-projected-tpbd": Phase="Running", Reason="", readiness=true. Elapsed: 12.05378158s
Apr  1 17:19:13.227: INFO: Pod "pod-subpath-test-projected-tpbd": Phase="Running", Reason="", readiness=true. Elapsed: 14.059001916s
Apr  1 17:19:15.236: INFO: Pod "pod-subpath-test-projected-tpbd": Phase="Running", Reason="", readiness=true. Elapsed: 16.067737848s
Apr  1 17:19:17.241: INFO: Pod "pod-subpath-test-projected-tpbd": Phase="Running", Reason="", readiness=true. Elapsed: 18.07310746s
Apr  1 17:19:19.246: INFO: Pod "pod-subpath-test-projected-tpbd": Phase="Running", Reason="", readiness=true. Elapsed: 20.077612384s
Apr  1 17:19:21.251: INFO: Pod "pod-subpath-test-projected-tpbd": Phase="Running", Reason="", readiness=true. Elapsed: 22.082440622s
Apr  1 17:19:23.255: INFO: Pod "pod-subpath-test-projected-tpbd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.087177074s
STEP: Saw pod success
Apr  1 17:19:23.255: INFO: Pod "pod-subpath-test-projected-tpbd" satisfied condition "success or failure"
Apr  1 17:19:23.259: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-subpath-test-projected-tpbd container test-container-subpath-projected-tpbd: <nil>
STEP: delete the pod
Apr  1 17:19:23.286: INFO: Waiting for pod pod-subpath-test-projected-tpbd to disappear
Apr  1 17:19:23.290: INFO: Pod pod-subpath-test-projected-tpbd no longer exists
STEP: Deleting pod pod-subpath-test-projected-tpbd
Apr  1 17:19:23.290: INFO: Deleting pod "pod-subpath-test-projected-tpbd" in namespace "subpath-5689"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:19:23.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5689" for this suite.
Apr  1 17:19:29.312: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:19:29.424: INFO: namespace subpath-5689 deletion completed in 6.126559246s

• [SLOW TEST:30.312 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:19:29.424: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Apr  1 17:19:34.006: INFO: Successfully updated pod "pod-update-activedeadlineseconds-4ec693a7-54a2-11e9-871e-828ee0b576f8"
Apr  1 17:19:34.006: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-4ec693a7-54a2-11e9-871e-828ee0b576f8" in namespace "pods-7857" to be "terminated due to deadline exceeded"
Apr  1 17:19:34.015: INFO: Pod "pod-update-activedeadlineseconds-4ec693a7-54a2-11e9-871e-828ee0b576f8": Phase="Running", Reason="", readiness=true. Elapsed: 8.350885ms
Apr  1 17:19:36.019: INFO: Pod "pod-update-activedeadlineseconds-4ec693a7-54a2-11e9-871e-828ee0b576f8": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.012995453s
Apr  1 17:19:36.019: INFO: Pod "pod-update-activedeadlineseconds-4ec693a7-54a2-11e9-871e-828ee0b576f8" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:19:36.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7857" for this suite.
Apr  1 17:19:42.043: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:19:42.218: INFO: namespace pods-7857 deletion completed in 6.19434585s

• [SLOW TEST:12.794 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:19:42.218: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:69
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Registering the sample API server.
Apr  1 17:19:42.770: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Apr  1 17:19:44.832: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689735982, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689735982, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689735982, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689735982, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  1 17:19:46.839: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689735982, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689735982, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689735982, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689735982, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  1 17:19:48.838: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689735982, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689735982, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689735982, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689735982, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  1 17:19:51.575: INFO: Waited 731.345503ms for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:60
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:19:52.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-6288" for this suite.
Apr  1 17:19:58.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:19:58.322: INFO: namespace aggregator-6288 deletion completed in 6.253616838s

• [SLOW TEST:16.104 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:19:58.323: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  1 17:19:58.392: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Apr  1 17:19:58.409: INFO: Number of nodes with available pods: 0
Apr  1 17:19:58.409: INFO: Node ip-172-31-22-24 is running more than one daemon pod
Apr  1 17:19:59.417: INFO: Number of nodes with available pods: 0
Apr  1 17:19:59.417: INFO: Node ip-172-31-22-24 is running more than one daemon pod
Apr  1 17:20:00.424: INFO: Number of nodes with available pods: 0
Apr  1 17:20:00.424: INFO: Node ip-172-31-22-24 is running more than one daemon pod
Apr  1 17:20:01.424: INFO: Number of nodes with available pods: 3
Apr  1 17:20:01.424: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Apr  1 17:20:01.477: INFO: Wrong image for pod: daemon-set-bbltg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:01.477: INFO: Wrong image for pod: daemon-set-m9g79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:01.477: INFO: Wrong image for pod: daemon-set-qvbv5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:02.493: INFO: Wrong image for pod: daemon-set-bbltg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:02.493: INFO: Wrong image for pod: daemon-set-m9g79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:02.493: INFO: Wrong image for pod: daemon-set-qvbv5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:03.487: INFO: Wrong image for pod: daemon-set-bbltg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:03.487: INFO: Wrong image for pod: daemon-set-m9g79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:03.487: INFO: Wrong image for pod: daemon-set-qvbv5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:04.491: INFO: Wrong image for pod: daemon-set-bbltg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:04.491: INFO: Wrong image for pod: daemon-set-m9g79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:04.491: INFO: Wrong image for pod: daemon-set-qvbv5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:04.491: INFO: Pod daemon-set-qvbv5 is not available
Apr  1 17:20:05.486: INFO: Wrong image for pod: daemon-set-bbltg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:05.486: INFO: Wrong image for pod: daemon-set-m9g79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:05.486: INFO: Wrong image for pod: daemon-set-qvbv5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:05.486: INFO: Pod daemon-set-qvbv5 is not available
Apr  1 17:20:06.487: INFO: Wrong image for pod: daemon-set-bbltg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:06.487: INFO: Wrong image for pod: daemon-set-m9g79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:06.487: INFO: Wrong image for pod: daemon-set-qvbv5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:06.487: INFO: Pod daemon-set-qvbv5 is not available
Apr  1 17:20:07.485: INFO: Wrong image for pod: daemon-set-bbltg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:07.485: INFO: Wrong image for pod: daemon-set-m9g79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:07.485: INFO: Wrong image for pod: daemon-set-qvbv5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:07.485: INFO: Pod daemon-set-qvbv5 is not available
Apr  1 17:20:08.486: INFO: Wrong image for pod: daemon-set-bbltg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:08.486: INFO: Wrong image for pod: daemon-set-m9g79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:08.486: INFO: Wrong image for pod: daemon-set-qvbv5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:08.486: INFO: Pod daemon-set-qvbv5 is not available
Apr  1 17:20:09.485: INFO: Wrong image for pod: daemon-set-bbltg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:09.486: INFO: Wrong image for pod: daemon-set-m9g79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:09.486: INFO: Wrong image for pod: daemon-set-qvbv5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:09.486: INFO: Pod daemon-set-qvbv5 is not available
Apr  1 17:20:10.485: INFO: Wrong image for pod: daemon-set-bbltg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:10.486: INFO: Wrong image for pod: daemon-set-m9g79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:10.486: INFO: Wrong image for pod: daemon-set-qvbv5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:10.486: INFO: Pod daemon-set-qvbv5 is not available
Apr  1 17:20:11.486: INFO: Wrong image for pod: daemon-set-bbltg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:11.486: INFO: Wrong image for pod: daemon-set-m9g79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:11.486: INFO: Pod daemon-set-pdtxn is not available
Apr  1 17:20:12.486: INFO: Wrong image for pod: daemon-set-bbltg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:12.486: INFO: Wrong image for pod: daemon-set-m9g79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:12.486: INFO: Pod daemon-set-pdtxn is not available
Apr  1 17:20:13.485: INFO: Wrong image for pod: daemon-set-bbltg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:13.485: INFO: Wrong image for pod: daemon-set-m9g79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:13.485: INFO: Pod daemon-set-pdtxn is not available
Apr  1 17:20:14.486: INFO: Wrong image for pod: daemon-set-bbltg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:14.486: INFO: Wrong image for pod: daemon-set-m9g79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:14.486: INFO: Pod daemon-set-pdtxn is not available
Apr  1 17:20:15.486: INFO: Wrong image for pod: daemon-set-bbltg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:15.486: INFO: Wrong image for pod: daemon-set-m9g79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:15.486: INFO: Pod daemon-set-pdtxn is not available
Apr  1 17:20:16.486: INFO: Wrong image for pod: daemon-set-bbltg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:16.486: INFO: Wrong image for pod: daemon-set-m9g79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:16.486: INFO: Pod daemon-set-pdtxn is not available
Apr  1 17:20:17.487: INFO: Wrong image for pod: daemon-set-bbltg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:17.487: INFO: Wrong image for pod: daemon-set-m9g79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:17.487: INFO: Pod daemon-set-pdtxn is not available
Apr  1 17:20:18.634: INFO: Wrong image for pod: daemon-set-bbltg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:18.635: INFO: Wrong image for pod: daemon-set-m9g79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:18.635: INFO: Pod daemon-set-pdtxn is not available
Apr  1 17:20:19.486: INFO: Wrong image for pod: daemon-set-bbltg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:19.486: INFO: Wrong image for pod: daemon-set-m9g79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:20.486: INFO: Wrong image for pod: daemon-set-bbltg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:20.486: INFO: Wrong image for pod: daemon-set-m9g79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:21.486: INFO: Wrong image for pod: daemon-set-bbltg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:21.486: INFO: Wrong image for pod: daemon-set-m9g79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:21.486: INFO: Pod daemon-set-m9g79 is not available
Apr  1 17:20:22.486: INFO: Wrong image for pod: daemon-set-bbltg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:22.486: INFO: Wrong image for pod: daemon-set-m9g79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:22.486: INFO: Pod daemon-set-m9g79 is not available
Apr  1 17:20:23.485: INFO: Wrong image for pod: daemon-set-bbltg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:23.485: INFO: Wrong image for pod: daemon-set-m9g79. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:23.485: INFO: Pod daemon-set-m9g79 is not available
Apr  1 17:20:24.485: INFO: Wrong image for pod: daemon-set-bbltg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:24.486: INFO: Pod daemon-set-dbzmv is not available
Apr  1 17:20:25.485: INFO: Wrong image for pod: daemon-set-bbltg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:25.485: INFO: Pod daemon-set-dbzmv is not available
Apr  1 17:20:26.485: INFO: Wrong image for pod: daemon-set-bbltg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:27.697: INFO: Wrong image for pod: daemon-set-bbltg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  1 17:20:27.698: INFO: Pod daemon-set-bbltg is not available
Apr  1 17:20:28.486: INFO: Pod daemon-set-sl6z8 is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Apr  1 17:20:28.497: INFO: Number of nodes with available pods: 2
Apr  1 17:20:28.497: INFO: Node ip-172-31-75-215 is running more than one daemon pod
Apr  1 17:20:29.509: INFO: Number of nodes with available pods: 2
Apr  1 17:20:29.509: INFO: Node ip-172-31-75-215 is running more than one daemon pod
Apr  1 17:20:30.509: INFO: Number of nodes with available pods: 2
Apr  1 17:20:30.509: INFO: Node ip-172-31-75-215 is running more than one daemon pod
Apr  1 17:20:31.506: INFO: Number of nodes with available pods: 2
Apr  1 17:20:31.506: INFO: Node ip-172-31-75-215 is running more than one daemon pod
Apr  1 17:20:32.506: INFO: Number of nodes with available pods: 2
Apr  1 17:20:32.506: INFO: Node ip-172-31-75-215 is running more than one daemon pod
Apr  1 17:20:33.636: INFO: Number of nodes with available pods: 2
Apr  1 17:20:33.636: INFO: Node ip-172-31-75-215 is running more than one daemon pod
Apr  1 17:20:34.506: INFO: Number of nodes with available pods: 2
Apr  1 17:20:34.506: INFO: Node ip-172-31-75-215 is running more than one daemon pod
Apr  1 17:20:35.591: INFO: Number of nodes with available pods: 2
Apr  1 17:20:35.591: INFO: Node ip-172-31-75-215 is running more than one daemon pod
Apr  1 17:20:36.506: INFO: Number of nodes with available pods: 3
Apr  1 17:20:36.506: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5673, will wait for the garbage collector to delete the pods
Apr  1 17:20:36.586: INFO: Deleting DaemonSet.extensions daemon-set took: 9.379075ms
Apr  1 17:20:36.886: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.236631ms
Apr  1 17:20:43.990: INFO: Number of nodes with available pods: 0
Apr  1 17:20:43.990: INFO: Number of running nodes: 0, number of available pods: 0
Apr  1 17:20:43.993: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5673/daemonsets","resourceVersion":"7400"},"items":null}

Apr  1 17:20:43.996: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5673/pods","resourceVersion":"7400"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:20:44.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5673" for this suite.
Apr  1 17:20:50.344: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:20:50.734: INFO: namespace daemonsets-5673 deletion completed in 6.719319161s

• [SLOW TEST:52.410 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:20:50.734: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:20:55.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6535" for this suite.
Apr  1 17:21:39.338: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:21:39.459: INFO: namespace kubelet-test-6535 deletion completed in 44.152612695s

• [SLOW TEST:48.725 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a read only busybox container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:21:39.460: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Apr  1 17:21:39.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 create -f - --namespace=kubectl-7905'
Apr  1 17:21:40.042: INFO: stderr: ""
Apr  1 17:21:40.042: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr  1 17:21:40.042: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7905'
Apr  1 17:21:40.125: INFO: stderr: ""
Apr  1 17:21:40.125: INFO: stdout: "update-demo-nautilus-42brk update-demo-nautilus-4dnrn "
Apr  1 17:21:40.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods update-demo-nautilus-42brk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7905'
Apr  1 17:21:40.198: INFO: stderr: ""
Apr  1 17:21:40.198: INFO: stdout: ""
Apr  1 17:21:40.198: INFO: update-demo-nautilus-42brk is created but not running
Apr  1 17:21:45.198: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7905'
Apr  1 17:21:45.265: INFO: stderr: ""
Apr  1 17:21:45.265: INFO: stdout: "update-demo-nautilus-42brk update-demo-nautilus-4dnrn "
Apr  1 17:21:45.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods update-demo-nautilus-42brk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7905'
Apr  1 17:21:45.335: INFO: stderr: ""
Apr  1 17:21:45.335: INFO: stdout: "true"
Apr  1 17:21:45.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods update-demo-nautilus-42brk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7905'
Apr  1 17:21:45.402: INFO: stderr: ""
Apr  1 17:21:45.402: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  1 17:21:45.402: INFO: validating pod update-demo-nautilus-42brk
Apr  1 17:21:45.408: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  1 17:21:45.408: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  1 17:21:45.408: INFO: update-demo-nautilus-42brk is verified up and running
Apr  1 17:21:45.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods update-demo-nautilus-4dnrn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7905'
Apr  1 17:21:45.474: INFO: stderr: ""
Apr  1 17:21:45.474: INFO: stdout: "true"
Apr  1 17:21:45.474: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods update-demo-nautilus-4dnrn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7905'
Apr  1 17:21:45.563: INFO: stderr: ""
Apr  1 17:21:45.563: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  1 17:21:45.563: INFO: validating pod update-demo-nautilus-4dnrn
Apr  1 17:21:45.569: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  1 17:21:45.569: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  1 17:21:45.569: INFO: update-demo-nautilus-4dnrn is verified up and running
STEP: using delete to clean up resources
Apr  1 17:21:45.569: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 delete --grace-period=0 --force -f - --namespace=kubectl-7905'
Apr  1 17:21:45.683: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  1 17:21:45.683: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr  1 17:21:45.683: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7905'
Apr  1 17:21:45.789: INFO: stderr: "No resources found.\n"
Apr  1 17:21:45.789: INFO: stdout: ""
Apr  1 17:21:45.789: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods -l name=update-demo --namespace=kubectl-7905 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr  1 17:21:45.878: INFO: stderr: ""
Apr  1 17:21:45.878: INFO: stdout: "update-demo-nautilus-42brk\nupdate-demo-nautilus-4dnrn\n"
Apr  1 17:21:46.378: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7905'
Apr  1 17:21:46.506: INFO: stderr: "No resources found.\n"
Apr  1 17:21:46.506: INFO: stdout: ""
Apr  1 17:21:46.506: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods -l name=update-demo --namespace=kubectl-7905 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr  1 17:21:46.640: INFO: stderr: ""
Apr  1 17:21:46.640: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:21:46.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7905" for this suite.
Apr  1 17:21:52.660: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:21:52.826: INFO: namespace kubectl-7905 deletion completed in 6.181358208s

• [SLOW TEST:13.366 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:21:52.826: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  1 17:21:52.883: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a4411449-54a2-11e9-871e-828ee0b576f8" in namespace "projected-919" to be "success or failure"
Apr  1 17:21:52.891: INFO: Pod "downwardapi-volume-a4411449-54a2-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 7.804372ms
Apr  1 17:21:54.895: INFO: Pod "downwardapi-volume-a4411449-54a2-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012134379s
Apr  1 17:21:56.900: INFO: Pod "downwardapi-volume-a4411449-54a2-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017346799s
STEP: Saw pod success
Apr  1 17:21:56.900: INFO: Pod "downwardapi-volume-a4411449-54a2-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 17:21:56.904: INFO: Trying to get logs from node ip-172-31-3-176 pod downwardapi-volume-a4411449-54a2-11e9-871e-828ee0b576f8 container client-container: <nil>
STEP: delete the pod
Apr  1 17:21:56.927: INFO: Waiting for pod downwardapi-volume-a4411449-54a2-11e9-871e-828ee0b576f8 to disappear
Apr  1 17:21:56.931: INFO: Pod downwardapi-volume-a4411449-54a2-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:21:56.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-919" for this suite.
Apr  1 17:22:02.948: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:22:03.072: INFO: namespace projected-919 deletion completed in 6.137869015s

• [SLOW TEST:10.246 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:22:03.072: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-aa5cfa61-54a2-11e9-871e-828ee0b576f8
STEP: Creating a pod to test consume secrets
Apr  1 17:22:03.137: INFO: Waiting up to 5m0s for pod "pod-secrets-aa5ec753-54a2-11e9-871e-828ee0b576f8" in namespace "secrets-9215" to be "success or failure"
Apr  1 17:22:03.141: INFO: Pod "pod-secrets-aa5ec753-54a2-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.441612ms
Apr  1 17:22:05.146: INFO: Pod "pod-secrets-aa5ec753-54a2-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009043237s
Apr  1 17:22:07.274: INFO: Pod "pod-secrets-aa5ec753-54a2-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.136635884s
STEP: Saw pod success
Apr  1 17:22:07.274: INFO: Pod "pod-secrets-aa5ec753-54a2-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 17:22:07.277: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-secrets-aa5ec753-54a2-11e9-871e-828ee0b576f8 container secret-volume-test: <nil>
STEP: delete the pod
Apr  1 17:22:07.306: INFO: Waiting for pod pod-secrets-aa5ec753-54a2-11e9-871e-828ee0b576f8 to disappear
Apr  1 17:22:07.310: INFO: Pod pod-secrets-aa5ec753-54a2-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:22:07.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9215" for this suite.
Apr  1 17:22:13.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:22:13.452: INFO: namespace secrets-9215 deletion completed in 6.138515244s

• [SLOW TEST:10.380 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:22:13.452: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service multi-endpoint-test in namespace services-2714
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2714 to expose endpoints map[]
Apr  1 17:22:13.506: INFO: Get endpoints failed (4.798758ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Apr  1 17:22:14.511: INFO: successfully validated that service multi-endpoint-test in namespace services-2714 exposes endpoints map[] (1.009545305s elapsed)
STEP: Creating pod pod1 in namespace services-2714
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2714 to expose endpoints map[pod1:[100]]
Apr  1 17:22:17.553: INFO: successfully validated that service multi-endpoint-test in namespace services-2714 exposes endpoints map[pod1:[100]] (3.033516149s elapsed)
STEP: Creating pod pod2 in namespace services-2714
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2714 to expose endpoints map[pod1:[100] pod2:[101]]
Apr  1 17:22:19.594: INFO: successfully validated that service multi-endpoint-test in namespace services-2714 exposes endpoints map[pod1:[100] pod2:[101]] (2.035545263s elapsed)
STEP: Deleting pod pod1 in namespace services-2714
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2714 to expose endpoints map[pod2:[101]]
Apr  1 17:22:20.617: INFO: successfully validated that service multi-endpoint-test in namespace services-2714 exposes endpoints map[pod2:[101]] (1.01577654s elapsed)
STEP: Deleting pod pod2 in namespace services-2714
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2714 to expose endpoints map[]
Apr  1 17:22:20.628: INFO: successfully validated that service multi-endpoint-test in namespace services-2714 exposes endpoints map[] (3.776018ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:22:20.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2714" for this suite.
Apr  1 17:22:26.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:22:26.877: INFO: namespace services-2714 deletion completed in 6.209846363s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:13.425 seconds]
[sig-network] Services
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:22:26.877: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-b88cc321-54a2-11e9-871e-828ee0b576f8
STEP: Creating configMap with name cm-test-opt-upd-b88cc362-54a2-11e9-871e-828ee0b576f8
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-b88cc321-54a2-11e9-871e-828ee0b576f8
STEP: Updating configmap cm-test-opt-upd-b88cc362-54a2-11e9-871e-828ee0b576f8
STEP: Creating configMap with name cm-test-opt-create-b88cc374-54a2-11e9-871e-828ee0b576f8
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:22:33.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5817" for this suite.
Apr  1 17:22:55.449: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:22:55.582: INFO: namespace projected-5817 deletion completed in 22.537060963s

• [SLOW TEST:28.705 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:22:55.582: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Apr  1 17:22:55.627: INFO: Waiting up to 5m0s for pod "pod-c9a7c7b8-54a2-11e9-871e-828ee0b576f8" in namespace "emptydir-3855" to be "success or failure"
Apr  1 17:22:55.631: INFO: Pod "pod-c9a7c7b8-54a2-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.885948ms
Apr  1 17:22:57.635: INFO: Pod "pod-c9a7c7b8-54a2-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008247519s
STEP: Saw pod success
Apr  1 17:22:57.635: INFO: Pod "pod-c9a7c7b8-54a2-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 17:22:57.639: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-c9a7c7b8-54a2-11e9-871e-828ee0b576f8 container test-container: <nil>
STEP: delete the pod
Apr  1 17:22:57.663: INFO: Waiting for pod pod-c9a7c7b8-54a2-11e9-871e-828ee0b576f8 to disappear
Apr  1 17:22:57.667: INFO: Pod pod-c9a7c7b8-54a2-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:22:57.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3855" for this suite.
Apr  1 17:23:03.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:23:04.081: INFO: namespace emptydir-3855 deletion completed in 6.408880958s

• [SLOW TEST:8.499 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:23:04.082: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-cebc43bd-54a2-11e9-871e-828ee0b576f8
STEP: Creating a pod to test consume secrets
Apr  1 17:23:04.190: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-cebec80b-54a2-11e9-871e-828ee0b576f8" in namespace "projected-2021" to be "success or failure"
Apr  1 17:23:04.212: INFO: Pod "pod-projected-secrets-cebec80b-54a2-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 22.405164ms
Apr  1 17:23:06.223: INFO: Pod "pod-projected-secrets-cebec80b-54a2-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032733462s
Apr  1 17:23:08.239: INFO: Pod "pod-projected-secrets-cebec80b-54a2-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048937269s
STEP: Saw pod success
Apr  1 17:23:08.239: INFO: Pod "pod-projected-secrets-cebec80b-54a2-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 17:23:08.251: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-projected-secrets-cebec80b-54a2-11e9-871e-828ee0b576f8 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr  1 17:23:08.295: INFO: Waiting for pod pod-projected-secrets-cebec80b-54a2-11e9-871e-828ee0b576f8 to disappear
Apr  1 17:23:08.301: INFO: Pod pod-projected-secrets-cebec80b-54a2-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:23:08.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2021" for this suite.
Apr  1 17:23:14.350: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:23:14.466: INFO: namespace projected-2021 deletion completed in 6.153682495s

• [SLOW TEST:10.384 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:23:14.466: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating server pod server in namespace prestop-9733
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-9733
STEP: Deleting pre-stop pod
Apr  1 17:23:28.076: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:23:28.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-9733" for this suite.
Apr  1 17:24:06.103: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:24:06.226: INFO: namespace prestop-9733 deletion completed in 38.138971302s

• [SLOW TEST:51.760 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:24:06.226: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  1 17:24:06.273: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f3c38492-54a2-11e9-871e-828ee0b576f8" in namespace "projected-4066" to be "success or failure"
Apr  1 17:24:06.279: INFO: Pod "downwardapi-volume-f3c38492-54a2-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.82353ms
Apr  1 17:24:08.284: INFO: Pod "downwardapi-volume-f3c38492-54a2-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010532167s
Apr  1 17:24:10.288: INFO: Pod "downwardapi-volume-f3c38492-54a2-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015130979s
STEP: Saw pod success
Apr  1 17:24:10.288: INFO: Pod "downwardapi-volume-f3c38492-54a2-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 17:24:10.292: INFO: Trying to get logs from node ip-172-31-3-176 pod downwardapi-volume-f3c38492-54a2-11e9-871e-828ee0b576f8 container client-container: <nil>
STEP: delete the pod
Apr  1 17:24:10.314: INFO: Waiting for pod downwardapi-volume-f3c38492-54a2-11e9-871e-828ee0b576f8 to disappear
Apr  1 17:24:10.317: INFO: Pod downwardapi-volume-f3c38492-54a2-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:24:10.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4066" for this suite.
Apr  1 17:24:16.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:24:16.547: INFO: namespace projected-4066 deletion completed in 6.226309022s

• [SLOW TEST:10.321 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:24:16.547: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:24:39.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5912" for this suite.
Apr  1 17:24:46.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:24:46.638: INFO: namespace container-runtime-5912 deletion completed in 6.170490887s

• [SLOW TEST:30.091 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  blackbox test
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:24:46.638: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-8076
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-8076
STEP: Creating statefulset with conflicting port in namespace statefulset-8076
STEP: Waiting until pod test-pod will start running in namespace statefulset-8076
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-8076
Apr  1 17:24:50.723: INFO: Observed stateful pod in namespace: statefulset-8076, name: ss-0, uid: 0e24fd03-54a3-11e9-84d7-12a9dd9b0c8a, status phase: Pending. Waiting for statefulset controller to delete.
Apr  1 17:24:51.112: INFO: Observed stateful pod in namespace: statefulset-8076, name: ss-0, uid: 0e24fd03-54a3-11e9-84d7-12a9dd9b0c8a, status phase: Failed. Waiting for statefulset controller to delete.
Apr  1 17:24:51.120: INFO: Observed stateful pod in namespace: statefulset-8076, name: ss-0, uid: 0e24fd03-54a3-11e9-84d7-12a9dd9b0c8a, status phase: Failed. Waiting for statefulset controller to delete.
Apr  1 17:24:51.124: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-8076
STEP: Removing pod with conflicting port in namespace statefulset-8076
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-8076 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr  1 17:24:55.156: INFO: Deleting all statefulset in ns statefulset-8076
Apr  1 17:24:55.160: INFO: Scaling statefulset ss to 0
Apr  1 17:25:05.189: INFO: Waiting for statefulset status.replicas updated to 0
Apr  1 17:25:05.193: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:25:05.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8076" for this suite.
Apr  1 17:25:11.226: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:25:11.408: INFO: namespace statefulset-8076 deletion completed in 6.19577532s

• [SLOW TEST:24.770 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:25:11.408: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Apr  1 17:25:11.811: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8787,SelfLink:/api/v1/namespaces/watch-8787/configmaps/e2e-watch-test-configmap-a,UID:1aca7fb4-54a3-11e9-9aab-028387864c62,ResourceVersion:8464,Generation:0,CreationTimestamp:2019-04-01 17:25:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr  1 17:25:11.811: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8787,SelfLink:/api/v1/namespaces/watch-8787/configmaps/e2e-watch-test-configmap-a,UID:1aca7fb4-54a3-11e9-9aab-028387864c62,ResourceVersion:8464,Generation:0,CreationTimestamp:2019-04-01 17:25:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Apr  1 17:25:21.820: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8787,SelfLink:/api/v1/namespaces/watch-8787/configmaps/e2e-watch-test-configmap-a,UID:1aca7fb4-54a3-11e9-9aab-028387864c62,ResourceVersion:8480,Generation:0,CreationTimestamp:2019-04-01 17:25:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Apr  1 17:25:21.821: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8787,SelfLink:/api/v1/namespaces/watch-8787/configmaps/e2e-watch-test-configmap-a,UID:1aca7fb4-54a3-11e9-9aab-028387864c62,ResourceVersion:8480,Generation:0,CreationTimestamp:2019-04-01 17:25:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Apr  1 17:25:31.834: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8787,SelfLink:/api/v1/namespaces/watch-8787/configmaps/e2e-watch-test-configmap-a,UID:1aca7fb4-54a3-11e9-9aab-028387864c62,ResourceVersion:8498,Generation:0,CreationTimestamp:2019-04-01 17:25:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr  1 17:25:31.834: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8787,SelfLink:/api/v1/namespaces/watch-8787/configmaps/e2e-watch-test-configmap-a,UID:1aca7fb4-54a3-11e9-9aab-028387864c62,ResourceVersion:8498,Generation:0,CreationTimestamp:2019-04-01 17:25:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Apr  1 17:25:41.843: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8787,SelfLink:/api/v1/namespaces/watch-8787/configmaps/e2e-watch-test-configmap-a,UID:1aca7fb4-54a3-11e9-9aab-028387864c62,ResourceVersion:8516,Generation:0,CreationTimestamp:2019-04-01 17:25:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr  1 17:25:41.843: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8787,SelfLink:/api/v1/namespaces/watch-8787/configmaps/e2e-watch-test-configmap-a,UID:1aca7fb4-54a3-11e9-9aab-028387864c62,ResourceVersion:8516,Generation:0,CreationTimestamp:2019-04-01 17:25:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Apr  1 17:25:51.852: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-8787,SelfLink:/api/v1/namespaces/watch-8787/configmaps/e2e-watch-test-configmap-b,UID:32a8f1b9-54a3-11e9-9aab-028387864c62,ResourceVersion:8533,Generation:0,CreationTimestamp:2019-04-01 17:25:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr  1 17:25:51.852: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-8787,SelfLink:/api/v1/namespaces/watch-8787/configmaps/e2e-watch-test-configmap-b,UID:32a8f1b9-54a3-11e9-9aab-028387864c62,ResourceVersion:8533,Generation:0,CreationTimestamp:2019-04-01 17:25:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Apr  1 17:26:01.862: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-8787,SelfLink:/api/v1/namespaces/watch-8787/configmaps/e2e-watch-test-configmap-b,UID:32a8f1b9-54a3-11e9-9aab-028387864c62,ResourceVersion:8552,Generation:0,CreationTimestamp:2019-04-01 17:25:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr  1 17:26:01.862: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-8787,SelfLink:/api/v1/namespaces/watch-8787/configmaps/e2e-watch-test-configmap-b,UID:32a8f1b9-54a3-11e9-9aab-028387864c62,ResourceVersion:8552,Generation:0,CreationTimestamp:2019-04-01 17:25:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:26:11.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8787" for this suite.
Apr  1 17:26:17.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:26:18.083: INFO: namespace watch-8787 deletion completed in 6.216101341s

• [SLOW TEST:66.676 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:26:18.083: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-2660
Apr  1 17:26:22.158: INFO: Started pod liveness-http in namespace container-probe-2660
STEP: checking the pod's current state and verifying that restartCount is present
Apr  1 17:26:22.163: INFO: Initial restart count of pod liveness-http is 0
Apr  1 17:26:36.199: INFO: Restart count of pod container-probe-2660/liveness-http is now 1 (14.035566117s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:26:36.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2660" for this suite.
Apr  1 17:26:42.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:26:42.346: INFO: namespace container-probe-2660 deletion completed in 6.127499386s

• [SLOW TEST:24.262 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:26:42.346: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-50fc6832-54a3-11e9-871e-828ee0b576f8
STEP: Creating a pod to test consume configMaps
Apr  1 17:26:42.678: INFO: Waiting up to 5m0s for pod "pod-configmaps-50fd88a4-54a3-11e9-871e-828ee0b576f8" in namespace "configmap-9575" to be "success or failure"
Apr  1 17:26:42.684: INFO: Pod "pod-configmaps-50fd88a4-54a3-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.549523ms
Apr  1 17:26:44.688: INFO: Pod "pod-configmaps-50fd88a4-54a3-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009988359s
Apr  1 17:26:46.693: INFO: Pod "pod-configmaps-50fd88a4-54a3-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014537605s
STEP: Saw pod success
Apr  1 17:26:46.693: INFO: Pod "pod-configmaps-50fd88a4-54a3-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 17:26:46.701: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-configmaps-50fd88a4-54a3-11e9-871e-828ee0b576f8 container configmap-volume-test: <nil>
STEP: delete the pod
Apr  1 17:26:46.729: INFO: Waiting for pod pod-configmaps-50fd88a4-54a3-11e9-871e-828ee0b576f8 to disappear
Apr  1 17:26:46.732: INFO: Pod pod-configmaps-50fd88a4-54a3-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:26:46.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9575" for this suite.
Apr  1 17:26:52.750: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:26:52.965: INFO: namespace configmap-9575 deletion completed in 6.228808275s

• [SLOW TEST:10.619 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:26:52.965: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0401 17:27:03.044047      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr  1 17:27:03.044: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:27:03.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3084" for this suite.
Apr  1 17:27:09.063: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:27:09.185: INFO: namespace gc-3084 deletion completed in 6.137257132s

• [SLOW TEST:16.219 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:27:09.185: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1354
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr  1 17:27:09.221: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-6839'
Apr  1 17:27:09.771: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr  1 17:27:09.771: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Apr  1 17:27:09.782: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-8p6cr]
Apr  1 17:27:09.782: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-8p6cr" in namespace "kubectl-6839" to be "running and ready"
Apr  1 17:27:09.787: INFO: Pod "e2e-test-nginx-rc-8p6cr": Phase="Pending", Reason="", readiness=false. Elapsed: 4.189212ms
Apr  1 17:27:11.792: INFO: Pod "e2e-test-nginx-rc-8p6cr": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009247141s
Apr  1 17:27:13.796: INFO: Pod "e2e-test-nginx-rc-8p6cr": Phase="Running", Reason="", readiness=true. Elapsed: 4.013852668s
Apr  1 17:27:13.796: INFO: Pod "e2e-test-nginx-rc-8p6cr" satisfied condition "running and ready"
Apr  1 17:27:13.796: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-8p6cr]
Apr  1 17:27:13.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 logs rc/e2e-test-nginx-rc --namespace=kubectl-6839'
Apr  1 17:27:13.916: INFO: stderr: ""
Apr  1 17:27:13.916: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1359
Apr  1 17:27:13.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 delete rc e2e-test-nginx-rc --namespace=kubectl-6839'
Apr  1 17:27:14.036: INFO: stderr: ""
Apr  1 17:27:14.036: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:27:14.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6839" for this suite.
Apr  1 17:27:20.066: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:27:20.261: INFO: namespace kubectl-6839 deletion completed in 6.219363301s

• [SLOW TEST:11.076 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:27:20.262: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  1 17:27:20.321: INFO: Waiting up to 5m0s for pod "downwardapi-volume-676cd94c-54a3-11e9-871e-828ee0b576f8" in namespace "downward-api-2855" to be "success or failure"
Apr  1 17:27:20.326: INFO: Pod "downwardapi-volume-676cd94c-54a3-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.560912ms
Apr  1 17:27:22.334: INFO: Pod "downwardapi-volume-676cd94c-54a3-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012627891s
Apr  1 17:27:24.338: INFO: Pod "downwardapi-volume-676cd94c-54a3-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017170869s
STEP: Saw pod success
Apr  1 17:27:24.338: INFO: Pod "downwardapi-volume-676cd94c-54a3-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 17:27:24.345: INFO: Trying to get logs from node ip-172-31-3-176 pod downwardapi-volume-676cd94c-54a3-11e9-871e-828ee0b576f8 container client-container: <nil>
STEP: delete the pod
Apr  1 17:27:24.378: INFO: Waiting for pod downwardapi-volume-676cd94c-54a3-11e9-871e-828ee0b576f8 to disappear
Apr  1 17:27:24.383: INFO: Pod downwardapi-volume-676cd94c-54a3-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:27:24.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2855" for this suite.
Apr  1 17:27:30.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:27:30.664: INFO: namespace downward-api-2855 deletion completed in 6.273019824s

• [SLOW TEST:10.403 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:27:30.664: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Apr  1 17:27:30.748: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:27:43.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3087" for this suite.
Apr  1 17:27:49.977: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:27:50.110: INFO: namespace pods-3087 deletion completed in 6.149678803s

• [SLOW TEST:19.446 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:27:50.111: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr  1 17:27:50.157: INFO: Waiting up to 5m0s for pod "downward-api-79357417-54a3-11e9-871e-828ee0b576f8" in namespace "downward-api-3714" to be "success or failure"
Apr  1 17:27:50.164: INFO: Pod "downward-api-79357417-54a3-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.852794ms
Apr  1 17:27:52.169: INFO: Pod "downward-api-79357417-54a3-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011833882s
Apr  1 17:27:54.174: INFO: Pod "downward-api-79357417-54a3-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016617351s
STEP: Saw pod success
Apr  1 17:27:54.174: INFO: Pod "downward-api-79357417-54a3-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 17:27:54.178: INFO: Trying to get logs from node ip-172-31-3-176 pod downward-api-79357417-54a3-11e9-871e-828ee0b576f8 container dapi-container: <nil>
STEP: delete the pod
Apr  1 17:27:54.212: INFO: Waiting for pod downward-api-79357417-54a3-11e9-871e-828ee0b576f8 to disappear
Apr  1 17:27:54.220: INFO: Pod downward-api-79357417-54a3-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:27:54.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3714" for this suite.
Apr  1 17:28:00.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:28:00.366: INFO: namespace downward-api-3714 deletion completed in 6.141008752s

• [SLOW TEST:10.255 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:28:00.366: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Apr  1 17:28:00.423: INFO: Waiting up to 5m0s for pod "pod-7f53f4e4-54a3-11e9-871e-828ee0b576f8" in namespace "emptydir-286" to be "success or failure"
Apr  1 17:28:00.429: INFO: Pod "pod-7f53f4e4-54a3-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.372312ms
Apr  1 17:28:02.434: INFO: Pod "pod-7f53f4e4-54a3-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01118908s
STEP: Saw pod success
Apr  1 17:28:02.434: INFO: Pod "pod-7f53f4e4-54a3-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 17:28:02.438: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-7f53f4e4-54a3-11e9-871e-828ee0b576f8 container test-container: <nil>
STEP: delete the pod
Apr  1 17:28:02.461: INFO: Waiting for pod pod-7f53f4e4-54a3-11e9-871e-828ee0b576f8 to disappear
Apr  1 17:28:02.464: INFO: Pod pod-7f53f4e4-54a3-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:28:02.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-286" for this suite.
Apr  1 17:28:08.482: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:28:08.598: INFO: namespace emptydir-286 deletion completed in 6.13022788s

• [SLOW TEST:8.232 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:28:08.599: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-843a2d07-54a3-11e9-871e-828ee0b576f8
STEP: Creating a pod to test consume configMaps
Apr  1 17:28:08.648: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-843b846d-54a3-11e9-871e-828ee0b576f8" in namespace "projected-892" to be "success or failure"
Apr  1 17:28:08.653: INFO: Pod "pod-projected-configmaps-843b846d-54a3-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.780032ms
Apr  1 17:28:10.657: INFO: Pod "pod-projected-configmaps-843b846d-54a3-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009115625s
STEP: Saw pod success
Apr  1 17:28:10.657: INFO: Pod "pod-projected-configmaps-843b846d-54a3-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 17:28:10.662: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-projected-configmaps-843b846d-54a3-11e9-871e-828ee0b576f8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr  1 17:28:10.683: INFO: Waiting for pod pod-projected-configmaps-843b846d-54a3-11e9-871e-828ee0b576f8 to disappear
Apr  1 17:28:10.686: INFO: Pod pod-projected-configmaps-843b846d-54a3-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:28:10.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-892" for this suite.
Apr  1 17:28:16.705: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:28:16.890: INFO: namespace projected-892 deletion completed in 6.199705337s

• [SLOW TEST:8.291 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:28:16.890: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Apr  1 17:28:16.985: INFO: Number of nodes with available pods: 0
Apr  1 17:28:16.985: INFO: Node ip-172-31-22-24 is running more than one daemon pod
Apr  1 17:28:17.994: INFO: Number of nodes with available pods: 0
Apr  1 17:28:17.994: INFO: Node ip-172-31-22-24 is running more than one daemon pod
Apr  1 17:28:18.994: INFO: Number of nodes with available pods: 0
Apr  1 17:28:18.994: INFO: Node ip-172-31-22-24 is running more than one daemon pod
Apr  1 17:28:20.005: INFO: Number of nodes with available pods: 3
Apr  1 17:28:20.005: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Apr  1 17:28:20.030: INFO: Number of nodes with available pods: 2
Apr  1 17:28:20.030: INFO: Node ip-172-31-22-24 is running more than one daemon pod
Apr  1 17:28:21.040: INFO: Number of nodes with available pods: 2
Apr  1 17:28:21.040: INFO: Node ip-172-31-22-24 is running more than one daemon pod
Apr  1 17:28:22.039: INFO: Number of nodes with available pods: 2
Apr  1 17:28:22.039: INFO: Node ip-172-31-22-24 is running more than one daemon pod
Apr  1 17:28:23.038: INFO: Number of nodes with available pods: 2
Apr  1 17:28:23.038: INFO: Node ip-172-31-22-24 is running more than one daemon pod
Apr  1 17:28:24.038: INFO: Number of nodes with available pods: 2
Apr  1 17:28:24.038: INFO: Node ip-172-31-22-24 is running more than one daemon pod
Apr  1 17:28:25.039: INFO: Number of nodes with available pods: 2
Apr  1 17:28:25.039: INFO: Node ip-172-31-22-24 is running more than one daemon pod
Apr  1 17:28:26.039: INFO: Number of nodes with available pods: 3
Apr  1 17:28:26.039: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-968, will wait for the garbage collector to delete the pods
Apr  1 17:28:26.107: INFO: Deleting DaemonSet.extensions daemon-set took: 10.484861ms
Apr  1 17:28:26.408: INFO: Terminating DaemonSet.extensions daemon-set pods took: 301.023239ms
Apr  1 17:28:34.012: INFO: Number of nodes with available pods: 0
Apr  1 17:28:34.012: INFO: Number of running nodes: 0, number of available pods: 0
Apr  1 17:28:34.016: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-968/daemonsets","resourceVersion":"9159"},"items":null}

Apr  1 17:28:34.019: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-968/pods","resourceVersion":"9159"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:28:34.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-968" for this suite.
Apr  1 17:28:40.050: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:28:40.164: INFO: namespace daemonsets-968 deletion completed in 6.127324546s

• [SLOW TEST:23.274 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:28:40.164: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating secret secrets-7647/secret-test-970afa6c-54a3-11e9-871e-828ee0b576f8
STEP: Creating a pod to test consume secrets
Apr  1 17:28:40.215: INFO: Waiting up to 5m0s for pod "pod-configmaps-970c49b6-54a3-11e9-871e-828ee0b576f8" in namespace "secrets-7647" to be "success or failure"
Apr  1 17:28:40.220: INFO: Pod "pod-configmaps-970c49b6-54a3-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.882271ms
Apr  1 17:28:42.224: INFO: Pod "pod-configmaps-970c49b6-54a3-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009120408s
STEP: Saw pod success
Apr  1 17:28:42.224: INFO: Pod "pod-configmaps-970c49b6-54a3-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 17:28:42.228: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-configmaps-970c49b6-54a3-11e9-871e-828ee0b576f8 container env-test: <nil>
STEP: delete the pod
Apr  1 17:28:42.252: INFO: Waiting for pod pod-configmaps-970c49b6-54a3-11e9-871e-828ee0b576f8 to disappear
Apr  1 17:28:42.256: INFO: Pod pod-configmaps-970c49b6-54a3-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:28:42.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7647" for this suite.
Apr  1 17:28:48.273: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:28:48.384: INFO: namespace secrets-7647 deletion completed in 6.124811515s

• [SLOW TEST:8.220 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:28:48.385: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
STEP: reading a file in the container
Apr  1 17:28:50.953: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4110 pod-service-account-9c3ff1c7-54a3-11e9-871e-828ee0b576f8 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Apr  1 17:28:56.179: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4110 pod-service-account-9c3ff1c7-54a3-11e9-871e-828ee0b576f8 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Apr  1 17:28:56.467: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4110 pod-service-account-9c3ff1c7-54a3-11e9-871e-828ee0b576f8 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:29:01.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4110" for this suite.
Apr  1 17:29:07.690: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:29:07.807: INFO: namespace svcaccounts-4110 deletion completed in 6.131604662s

• [SLOW TEST:19.422 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:29:07.807: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  1 17:29:07.854: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a784def8-54a3-11e9-871e-828ee0b576f8" in namespace "downward-api-5302" to be "success or failure"
Apr  1 17:29:07.859: INFO: Pod "downwardapi-volume-a784def8-54a3-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.922135ms
Apr  1 17:29:09.864: INFO: Pod "downwardapi-volume-a784def8-54a3-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009612775s
Apr  1 17:29:11.868: INFO: Pod "downwardapi-volume-a784def8-54a3-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014166143s
STEP: Saw pod success
Apr  1 17:29:11.868: INFO: Pod "downwardapi-volume-a784def8-54a3-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 17:29:11.872: INFO: Trying to get logs from node ip-172-31-3-176 pod downwardapi-volume-a784def8-54a3-11e9-871e-828ee0b576f8 container client-container: <nil>
STEP: delete the pod
Apr  1 17:29:11.900: INFO: Waiting for pod downwardapi-volume-a784def8-54a3-11e9-871e-828ee0b576f8 to disappear
Apr  1 17:29:11.903: INFO: Pod downwardapi-volume-a784def8-54a3-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:29:11.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5302" for this suite.
Apr  1 17:29:18.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:29:18.236: INFO: namespace downward-api-5302 deletion completed in 6.328663078s

• [SLOW TEST:10.429 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:29:18.236: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Apr  1 17:29:18.291: INFO: Waiting up to 5m0s for pod "pod-adbd183a-54a3-11e9-871e-828ee0b576f8" in namespace "emptydir-8487" to be "success or failure"
Apr  1 17:29:18.296: INFO: Pod "pod-adbd183a-54a3-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.822778ms
Apr  1 17:29:20.301: INFO: Pod "pod-adbd183a-54a3-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009614497s
Apr  1 17:29:22.305: INFO: Pod "pod-adbd183a-54a3-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014165522s
STEP: Saw pod success
Apr  1 17:29:22.305: INFO: Pod "pod-adbd183a-54a3-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 17:29:22.309: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-adbd183a-54a3-11e9-871e-828ee0b576f8 container test-container: <nil>
STEP: delete the pod
Apr  1 17:29:22.332: INFO: Waiting for pod pod-adbd183a-54a3-11e9-871e-828ee0b576f8 to disappear
Apr  1 17:29:22.335: INFO: Pod pod-adbd183a-54a3-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:29:22.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8487" for this suite.
Apr  1 17:29:28.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:29:28.726: INFO: namespace emptydir-8487 deletion completed in 6.387221917s

• [SLOW TEST:10.490 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:29:28.726: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Apr  1 17:29:28.775: INFO: Waiting up to 5m0s for pod "pod-b3fd68cd-54a3-11e9-871e-828ee0b576f8" in namespace "emptydir-4210" to be "success or failure"
Apr  1 17:29:28.782: INFO: Pod "pod-b3fd68cd-54a3-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 7.004604ms
Apr  1 17:29:30.787: INFO: Pod "pod-b3fd68cd-54a3-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011738827s
Apr  1 17:29:32.791: INFO: Pod "pod-b3fd68cd-54a3-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016585133s
STEP: Saw pod success
Apr  1 17:29:32.792: INFO: Pod "pod-b3fd68cd-54a3-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 17:29:32.796: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-b3fd68cd-54a3-11e9-871e-828ee0b576f8 container test-container: <nil>
STEP: delete the pod
Apr  1 17:29:32.817: INFO: Waiting for pod pod-b3fd68cd-54a3-11e9-871e-828ee0b576f8 to disappear
Apr  1 17:29:32.820: INFO: Pod pod-b3fd68cd-54a3-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:29:32.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4210" for this suite.
Apr  1 17:29:38.839: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:29:39.039: INFO: namespace emptydir-4210 deletion completed in 6.215398098s

• [SLOW TEST:10.313 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:29:39.039: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
Apr  1 17:29:39.616: INFO: created pod pod-service-account-defaultsa
Apr  1 17:29:39.616: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Apr  1 17:29:39.624: INFO: created pod pod-service-account-mountsa
Apr  1 17:29:39.624: INFO: pod pod-service-account-mountsa service account token volume mount: true
Apr  1 17:29:39.630: INFO: created pod pod-service-account-nomountsa
Apr  1 17:29:39.630: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Apr  1 17:29:39.636: INFO: created pod pod-service-account-defaultsa-mountspec
Apr  1 17:29:39.636: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Apr  1 17:29:39.642: INFO: created pod pod-service-account-mountsa-mountspec
Apr  1 17:29:39.642: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Apr  1 17:29:39.649: INFO: created pod pod-service-account-nomountsa-mountspec
Apr  1 17:29:39.649: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Apr  1 17:29:39.654: INFO: created pod pod-service-account-defaultsa-nomountspec
Apr  1 17:29:39.654: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Apr  1 17:29:39.660: INFO: created pod pod-service-account-mountsa-nomountspec
Apr  1 17:29:39.660: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Apr  1 17:29:39.667: INFO: created pod pod-service-account-nomountsa-nomountspec
Apr  1 17:29:39.667: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:29:39.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-2968" for this suite.
Apr  1 17:29:45.694: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:29:45.879: INFO: namespace svcaccounts-2968 deletion completed in 6.204474044s

• [SLOW TEST:6.839 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:29:45.879: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:29:49.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7965" for this suite.
Apr  1 17:30:35.984: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:30:36.172: INFO: namespace kubelet-test-7965 deletion completed in 46.208763829s

• [SLOW TEST:50.294 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:30:36.173: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-dc3147aa-54a3-11e9-871e-828ee0b576f8
STEP: Creating a pod to test consume secrets
Apr  1 17:30:36.235: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-dc32c7d5-54a3-11e9-871e-828ee0b576f8" in namespace "projected-261" to be "success or failure"
Apr  1 17:30:36.243: INFO: Pod "pod-projected-secrets-dc32c7d5-54a3-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.125629ms
Apr  1 17:30:38.247: INFO: Pod "pod-projected-secrets-dc32c7d5-54a3-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012351829s
Apr  1 17:30:40.254: INFO: Pod "pod-projected-secrets-dc32c7d5-54a3-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018970906s
STEP: Saw pod success
Apr  1 17:30:40.254: INFO: Pod "pod-projected-secrets-dc32c7d5-54a3-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 17:30:40.258: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-projected-secrets-dc32c7d5-54a3-11e9-871e-828ee0b576f8 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr  1 17:30:40.279: INFO: Waiting for pod pod-projected-secrets-dc32c7d5-54a3-11e9-871e-828ee0b576f8 to disappear
Apr  1 17:30:40.285: INFO: Pod pod-projected-secrets-dc32c7d5-54a3-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:30:40.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-261" for this suite.
Apr  1 17:30:46.312: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:30:46.527: INFO: namespace projected-261 deletion completed in 6.238195706s

• [SLOW TEST:10.355 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:30:46.528: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  1 17:30:46.582: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Apr  1 17:30:46.593: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr  1 17:30:51.597: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr  1 17:30:51.597: INFO: Creating deployment "test-rolling-update-deployment"
Apr  1 17:30:51.603: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Apr  1 17:30:51.611: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Apr  1 17:30:53.620: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Apr  1 17:30:53.623: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689736651, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689736651, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689736651, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689736651, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-67599b4d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  1 17:30:55.628: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr  1 17:30:55.639: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-8864,SelfLink:/apis/apps/v1/namespaces/deployment-8864/deployments/test-rolling-update-deployment,UID:e552a545-54a3-11e9-9aab-028387864c62,ResourceVersion:9742,Generation:1,CreationTimestamp:2019-04-01 17:30:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-04-01 17:30:51 +0000 UTC 2019-04-01 17:30:51 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-04-01 17:30:55 +0000 UTC 2019-04-01 17:30:51 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-67599b4d9" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Apr  1 17:30:55.643: INFO: New ReplicaSet "test-rolling-update-deployment-67599b4d9" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-67599b4d9,GenerateName:,Namespace:deployment-8864,SelfLink:/apis/apps/v1/namespaces/deployment-8864/replicasets/test-rolling-update-deployment-67599b4d9,UID:e55eca51-54a3-11e9-84d7-12a9dd9b0c8a,ResourceVersion:9731,Generation:1,CreationTimestamp:2019-04-01 17:30:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment e552a545-54a3-11e9-9aab-028387864c62 0xc002e98480 0xc002e98481}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Apr  1 17:30:55.643: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Apr  1 17:30:55.643: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-8864,SelfLink:/apis/apps/v1/namespaces/deployment-8864/replicasets/test-rolling-update-controller,UID:e25550f6-54a3-11e9-9aab-028387864c62,ResourceVersion:9741,Generation:2,CreationTimestamp:2019-04-01 17:30:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment e552a545-54a3-11e9-9aab-028387864c62 0xc002e983af 0xc002e983c0}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr  1 17:30:55.647: INFO: Pod "test-rolling-update-deployment-67599b4d9-fttmm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-67599b4d9-fttmm,GenerateName:test-rolling-update-deployment-67599b4d9-,Namespace:deployment-8864,SelfLink:/api/v1/namespaces/deployment-8864/pods/test-rolling-update-deployment-67599b4d9-fttmm,UID:e55fe1e0-54a3-11e9-84d7-12a9dd9b0c8a,ResourceVersion:9730,Generation:0,CreationTimestamp:2019-04-01 17:30:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-67599b4d9 e55eca51-54a3-11e9-84d7-12a9dd9b0c8a 0xc002c31da0 0xc002c31da1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-j4bdq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j4bdq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-j4bdq true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-3-176,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c31e10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c31e30}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:30:51 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:30:55 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:30:55 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:30:51 +0000 UTC  }],Message:,Reason:,HostIP:172.31.3.176,PodIP:10.1.83.124,StartTime:2019-04-01 17:30:51 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-04-01 17:30:53 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://93d57dd22c26c8b241fbb73af25f4ddc085da4f198276e938bb9d4776545106e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:30:55.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8864" for this suite.
Apr  1 17:31:01.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:31:01.802: INFO: namespace deployment-8864 deletion completed in 6.151656315s

• [SLOW TEST:15.275 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:31:01.802: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Apr  1 17:31:03.891: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-eb794b0b-54a3-11e9-871e-828ee0b576f8,GenerateName:,Namespace:events-9326,SelfLink:/api/v1/namespaces/events-9326/pods/send-events-eb794b0b-54a3-11e9-871e-828ee0b576f8,UID:eb6f8b88-54a3-11e9-9aab-028387864c62,ResourceVersion:9793,Generation:0,CreationTimestamp:2019-04-01 17:31:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 850807858,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9bwdp {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9bwdp,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-9bwdp true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-3-176,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002dae000} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002dae020}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:31:01 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:31:03 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:31:03 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 17:31:01 +0000 UTC  }],Message:,Reason:,HostIP:172.31.3.176,PodIP:10.1.83.125,StartTime:2019-04-01 17:31:01 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-04-01 17:31:03 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://51474ebd33af0f366ff8cae7401dd23e430bf74e307c86284199539797fcda05}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Apr  1 17:31:05.896: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Apr  1 17:31:07.900: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:31:07.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-9326" for this suite.
Apr  1 17:31:45.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:31:46.050: INFO: namespace events-9326 deletion completed in 38.13847595s

• [SLOW TEST:44.248 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:31:46.050: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Apr  1 17:31:46.096: INFO: Waiting up to 5m0s for pod "pod-05d71126-54a4-11e9-871e-828ee0b576f8" in namespace "emptydir-8484" to be "success or failure"
Apr  1 17:31:46.100: INFO: Pod "pod-05d71126-54a4-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.251922ms
Apr  1 17:31:48.105: INFO: Pod "pod-05d71126-54a4-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008591636s
STEP: Saw pod success
Apr  1 17:31:48.105: INFO: Pod "pod-05d71126-54a4-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 17:31:48.108: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-05d71126-54a4-11e9-871e-828ee0b576f8 container test-container: <nil>
STEP: delete the pod
Apr  1 17:31:48.135: INFO: Waiting for pod pod-05d71126-54a4-11e9-871e-828ee0b576f8 to disappear
Apr  1 17:31:48.139: INFO: Pod pod-05d71126-54a4-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:31:48.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8484" for this suite.
Apr  1 17:31:54.157: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:31:54.271: INFO: namespace emptydir-8484 deletion completed in 6.128302642s

• [SLOW TEST:8.221 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:31:54.272: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting the proxy server
Apr  1 17:31:54.305: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-994794615 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:31:54.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3733" for this suite.
Apr  1 17:32:00.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:32:00.536: INFO: namespace kubectl-3733 deletion completed in 6.16022563s

• [SLOW TEST:6.265 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:32:00.537: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Apr  1 17:32:00.582: INFO: Waiting up to 5m0s for pod "pod-0e796056-54a4-11e9-871e-828ee0b576f8" in namespace "emptydir-8434" to be "success or failure"
Apr  1 17:32:00.587: INFO: Pod "pod-0e796056-54a4-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.75066ms
Apr  1 17:32:02.591: INFO: Pod "pod-0e796056-54a4-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009429898s
Apr  1 17:32:04.596: INFO: Pod "pod-0e796056-54a4-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014066887s
STEP: Saw pod success
Apr  1 17:32:04.596: INFO: Pod "pod-0e796056-54a4-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 17:32:04.600: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-0e796056-54a4-11e9-871e-828ee0b576f8 container test-container: <nil>
STEP: delete the pod
Apr  1 17:32:04.623: INFO: Waiting for pod pod-0e796056-54a4-11e9-871e-828ee0b576f8 to disappear
Apr  1 17:32:04.626: INFO: Pod pod-0e796056-54a4-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:32:04.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8434" for this suite.
Apr  1 17:32:10.647: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:32:10.769: INFO: namespace emptydir-8434 deletion completed in 6.135292046s

• [SLOW TEST:10.232 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:32:10.769: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1108
STEP: creating the pod
Apr  1 17:32:10.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 create -f - --namespace=kubectl-4509'
Apr  1 17:32:12.194: INFO: stderr: ""
Apr  1 17:32:12.194: INFO: stdout: "pod/pause created\n"
Apr  1 17:32:12.194: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Apr  1 17:32:12.194: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-4509" to be "running and ready"
Apr  1 17:32:12.198: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 3.919087ms
Apr  1 17:32:14.202: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008749353s
Apr  1 17:32:16.207: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.013217211s
Apr  1 17:32:16.207: INFO: Pod "pause" satisfied condition "running and ready"
Apr  1 17:32:16.207: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: adding the label testing-label with value testing-label-value to a pod
Apr  1 17:32:16.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 label pods pause testing-label=testing-label-value --namespace=kubectl-4509'
Apr  1 17:32:16.310: INFO: stderr: ""
Apr  1 17:32:16.310: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Apr  1 17:32:16.310: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pod pause -L testing-label --namespace=kubectl-4509'
Apr  1 17:32:16.398: INFO: stderr: ""
Apr  1 17:32:16.398: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Apr  1 17:32:16.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 label pods pause testing-label- --namespace=kubectl-4509'
Apr  1 17:32:16.489: INFO: stderr: ""
Apr  1 17:32:16.489: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Apr  1 17:32:16.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pod pause -L testing-label --namespace=kubectl-4509'
Apr  1 17:32:16.589: INFO: stderr: ""
Apr  1 17:32:16.589: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1115
STEP: using delete to clean up resources
Apr  1 17:32:16.589: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 delete --grace-period=0 --force -f - --namespace=kubectl-4509'
Apr  1 17:32:16.739: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  1 17:32:16.739: INFO: stdout: "pod \"pause\" force deleted\n"
Apr  1 17:32:16.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get rc,svc -l name=pause --no-headers --namespace=kubectl-4509'
Apr  1 17:32:16.878: INFO: stderr: "No resources found.\n"
Apr  1 17:32:16.878: INFO: stdout: ""
Apr  1 17:32:16.878: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods -l name=pause --namespace=kubectl-4509 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr  1 17:32:16.996: INFO: stderr: ""
Apr  1 17:32:16.996: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:32:16.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4509" for this suite.
Apr  1 17:32:23.027: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:32:23.149: INFO: namespace kubectl-4509 deletion completed in 6.144910032s

• [SLOW TEST:12.380 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:32:23.149: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-1bf419b2-54a4-11e9-871e-828ee0b576f8
STEP: Creating secret with name s-test-opt-upd-1bf419ef-54a4-11e9-871e-828ee0b576f8
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-1bf419b2-54a4-11e9-871e-828ee0b576f8
STEP: Updating secret s-test-opt-upd-1bf419ef-54a4-11e9-871e-828ee0b576f8
STEP: Creating secret with name s-test-opt-create-1bf41a06-54a4-11e9-871e-828ee0b576f8
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:32:31.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9019" for this suite.
Apr  1 17:32:53.367: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:32:53.489: INFO: namespace secrets-9019 deletion completed in 22.136168966s

• [SLOW TEST:30.340 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:32:53.489: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Apr  1 17:32:56.066: INFO: Successfully updated pod "pod-update-2e0963fc-54a4-11e9-871e-828ee0b576f8"
STEP: verifying the updated pod is in kubernetes
Apr  1 17:32:56.074: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:32:56.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6807" for this suite.
Apr  1 17:33:18.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:33:18.247: INFO: namespace pods-6807 deletion completed in 22.16908293s

• [SLOW TEST:24.757 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:33:18.247: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:33:22.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2709" for this suite.
Apr  1 17:34:06.393: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:34:06.512: INFO: namespace kubelet-test-2709 deletion completed in 44.133013214s

• [SLOW TEST:48.265 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command in a pod
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:34:06.512: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-rrl8
STEP: Creating a pod to test atomic-volume-subpath
Apr  1 17:34:06.581: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-rrl8" in namespace "subpath-3075" to be "success or failure"
Apr  1 17:34:06.587: INFO: Pod "pod-subpath-test-configmap-rrl8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.289295ms
Apr  1 17:34:08.592: INFO: Pod "pod-subpath-test-configmap-rrl8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011102597s
Apr  1 17:34:10.596: INFO: Pod "pod-subpath-test-configmap-rrl8": Phase="Running", Reason="", readiness=true. Elapsed: 4.015589568s
Apr  1 17:34:12.602: INFO: Pod "pod-subpath-test-configmap-rrl8": Phase="Running", Reason="", readiness=true. Elapsed: 6.021020644s
Apr  1 17:34:14.607: INFO: Pod "pod-subpath-test-configmap-rrl8": Phase="Running", Reason="", readiness=true. Elapsed: 8.02634498s
Apr  1 17:34:16.612: INFO: Pod "pod-subpath-test-configmap-rrl8": Phase="Running", Reason="", readiness=true. Elapsed: 10.031286361s
Apr  1 17:34:18.617: INFO: Pod "pod-subpath-test-configmap-rrl8": Phase="Running", Reason="", readiness=true. Elapsed: 12.03633666s
Apr  1 17:34:20.622: INFO: Pod "pod-subpath-test-configmap-rrl8": Phase="Running", Reason="", readiness=true. Elapsed: 14.04103135s
Apr  1 17:34:22.626: INFO: Pod "pod-subpath-test-configmap-rrl8": Phase="Running", Reason="", readiness=true. Elapsed: 16.045661854s
Apr  1 17:34:24.632: INFO: Pod "pod-subpath-test-configmap-rrl8": Phase="Running", Reason="", readiness=true. Elapsed: 18.05067333s
Apr  1 17:34:26.641: INFO: Pod "pod-subpath-test-configmap-rrl8": Phase="Running", Reason="", readiness=true. Elapsed: 20.059721405s
Apr  1 17:34:28.645: INFO: Pod "pod-subpath-test-configmap-rrl8": Phase="Running", Reason="", readiness=true. Elapsed: 22.064260321s
Apr  1 17:34:30.650: INFO: Pod "pod-subpath-test-configmap-rrl8": Phase="Running", Reason="", readiness=true. Elapsed: 24.068983037s
Apr  1 17:34:33.047: INFO: Pod "pod-subpath-test-configmap-rrl8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.466286822s
STEP: Saw pod success
Apr  1 17:34:33.047: INFO: Pod "pod-subpath-test-configmap-rrl8" satisfied condition "success or failure"
Apr  1 17:34:33.053: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-subpath-test-configmap-rrl8 container test-container-subpath-configmap-rrl8: <nil>
STEP: delete the pod
Apr  1 17:34:33.074: INFO: Waiting for pod pod-subpath-test-configmap-rrl8 to disappear
Apr  1 17:34:33.078: INFO: Pod pod-subpath-test-configmap-rrl8 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-rrl8
Apr  1 17:34:33.078: INFO: Deleting pod "pod-subpath-test-configmap-rrl8" in namespace "subpath-3075"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:34:33.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3075" for this suite.
Apr  1 17:34:39.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:34:39.215: INFO: namespace subpath-3075 deletion completed in 6.130031494s

• [SLOW TEST:32.703 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:34:39.215: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  1 17:34:39.262: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6d0dc462-54a4-11e9-871e-828ee0b576f8" in namespace "projected-3957" to be "success or failure"
Apr  1 17:34:39.267: INFO: Pod "downwardapi-volume-6d0dc462-54a4-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.705166ms
Apr  1 17:34:41.272: INFO: Pod "downwardapi-volume-6d0dc462-54a4-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00945488s
Apr  1 17:34:43.276: INFO: Pod "downwardapi-volume-6d0dc462-54a4-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014300418s
STEP: Saw pod success
Apr  1 17:34:43.276: INFO: Pod "downwardapi-volume-6d0dc462-54a4-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 17:34:43.280: INFO: Trying to get logs from node ip-172-31-3-176 pod downwardapi-volume-6d0dc462-54a4-11e9-871e-828ee0b576f8 container client-container: <nil>
STEP: delete the pod
Apr  1 17:34:43.306: INFO: Waiting for pod downwardapi-volume-6d0dc462-54a4-11e9-871e-828ee0b576f8 to disappear
Apr  1 17:34:43.309: INFO: Pod downwardapi-volume-6d0dc462-54a4-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:34:43.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3957" for this suite.
Apr  1 17:34:49.338: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:34:49.455: INFO: namespace projected-3957 deletion completed in 6.141766152s

• [SLOW TEST:10.240 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:34:49.455: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-7121
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr  1 17:34:49.489: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr  1 17:35:15.588: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.1.101.27 8081 | grep -v '^\s*$'] Namespace:pod-network-test-7121 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  1 17:35:15.588: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
Apr  1 17:35:16.758: INFO: Found all expected endpoints: [netserver-0]
Apr  1 17:35:16.763: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.1.83.135 8081 | grep -v '^\s*$'] Namespace:pod-network-test-7121 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  1 17:35:16.763: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
Apr  1 17:35:17.902: INFO: Found all expected endpoints: [netserver-1]
Apr  1 17:35:17.907: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.1.81.31 8081 | grep -v '^\s*$'] Namespace:pod-network-test-7121 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  1 17:35:17.907: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
Apr  1 17:35:19.031: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:35:19.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7121" for this suite.
Apr  1 17:35:41.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:35:41.178: INFO: namespace pod-network-test-7121 deletion completed in 22.140496038s

• [SLOW TEST:51.723 seconds]
[sig-network] Networking
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:35:41.179: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name projected-secret-test-91fcf124-54a4-11e9-871e-828ee0b576f8
STEP: Creating a pod to test consume secrets
Apr  1 17:35:41.231: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-91fe13f5-54a4-11e9-871e-828ee0b576f8" in namespace "projected-2786" to be "success or failure"
Apr  1 17:35:41.236: INFO: Pod "pod-projected-secrets-91fe13f5-54a4-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.993198ms
Apr  1 17:35:43.241: INFO: Pod "pod-projected-secrets-91fe13f5-54a4-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009421006s
Apr  1 17:35:45.245: INFO: Pod "pod-projected-secrets-91fe13f5-54a4-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014204222s
STEP: Saw pod success
Apr  1 17:35:45.246: INFO: Pod "pod-projected-secrets-91fe13f5-54a4-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 17:35:45.251: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-projected-secrets-91fe13f5-54a4-11e9-871e-828ee0b576f8 container secret-volume-test: <nil>
STEP: delete the pod
Apr  1 17:35:45.275: INFO: Waiting for pod pod-projected-secrets-91fe13f5-54a4-11e9-871e-828ee0b576f8 to disappear
Apr  1 17:35:45.279: INFO: Pod pod-projected-secrets-91fe13f5-54a4-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:35:45.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2786" for this suite.
Apr  1 17:35:51.296: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:35:51.411: INFO: namespace projected-2786 deletion completed in 6.128792472s

• [SLOW TEST:10.233 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:35:51.411: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-984c62d1-54a4-11e9-871e-828ee0b576f8
STEP: Creating a pod to test consume configMaps
Apr  1 17:35:51.818: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-984d87e6-54a4-11e9-871e-828ee0b576f8" in namespace "projected-8906" to be "success or failure"
Apr  1 17:35:51.824: INFO: Pod "pod-projected-configmaps-984d87e6-54a4-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.952013ms
Apr  1 17:35:53.828: INFO: Pod "pod-projected-configmaps-984d87e6-54a4-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010390575s
STEP: Saw pod success
Apr  1 17:35:53.828: INFO: Pod "pod-projected-configmaps-984d87e6-54a4-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 17:35:53.833: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-projected-configmaps-984d87e6-54a4-11e9-871e-828ee0b576f8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr  1 17:35:53.854: INFO: Waiting for pod pod-projected-configmaps-984d87e6-54a4-11e9-871e-828ee0b576f8 to disappear
Apr  1 17:35:53.857: INFO: Pod pod-projected-configmaps-984d87e6-54a4-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:35:53.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8906" for this suite.
Apr  1 17:35:59.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:35:59.988: INFO: namespace projected-8906 deletion completed in 6.127353603s

• [SLOW TEST:8.577 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:35:59.989: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  1 17:36:00.043: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9d33e4e0-54a4-11e9-871e-828ee0b576f8" in namespace "projected-6077" to be "success or failure"
Apr  1 17:36:00.047: INFO: Pod "downwardapi-volume-9d33e4e0-54a4-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.537183ms
Apr  1 17:36:02.052: INFO: Pod "downwardapi-volume-9d33e4e0-54a4-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00876887s
Apr  1 17:36:04.060: INFO: Pod "downwardapi-volume-9d33e4e0-54a4-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017121561s
STEP: Saw pod success
Apr  1 17:36:04.060: INFO: Pod "downwardapi-volume-9d33e4e0-54a4-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 17:36:04.064: INFO: Trying to get logs from node ip-172-31-3-176 pod downwardapi-volume-9d33e4e0-54a4-11e9-871e-828ee0b576f8 container client-container: <nil>
STEP: delete the pod
Apr  1 17:36:04.113: INFO: Waiting for pod downwardapi-volume-9d33e4e0-54a4-11e9-871e-828ee0b576f8 to disappear
Apr  1 17:36:04.119: INFO: Pod downwardapi-volume-9d33e4e0-54a4-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:36:04.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6077" for this suite.
Apr  1 17:36:10.140: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:36:10.264: INFO: namespace projected-6077 deletion completed in 6.13995831s

• [SLOW TEST:10.276 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:36:10.265: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-a3540b9a-54a4-11e9-871e-828ee0b576f8
STEP: Creating a pod to test consume secrets
Apr  1 17:36:10.369: INFO: Waiting up to 5m0s for pod "pod-secrets-a35c3412-54a4-11e9-871e-828ee0b576f8" in namespace "secrets-4482" to be "success or failure"
Apr  1 17:36:10.373: INFO: Pod "pod-secrets-a35c3412-54a4-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.111561ms
Apr  1 17:36:12.388: INFO: Pod "pod-secrets-a35c3412-54a4-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019273179s
Apr  1 17:36:14.394: INFO: Pod "pod-secrets-a35c3412-54a4-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024754662s
STEP: Saw pod success
Apr  1 17:36:14.394: INFO: Pod "pod-secrets-a35c3412-54a4-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 17:36:14.397: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-secrets-a35c3412-54a4-11e9-871e-828ee0b576f8 container secret-volume-test: <nil>
STEP: delete the pod
Apr  1 17:36:14.423: INFO: Waiting for pod pod-secrets-a35c3412-54a4-11e9-871e-828ee0b576f8 to disappear
Apr  1 17:36:14.426: INFO: Pod pod-secrets-a35c3412-54a4-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:36:14.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4482" for this suite.
Apr  1 17:36:20.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:36:20.559: INFO: namespace secrets-4482 deletion completed in 6.128974334s
STEP: Destroying namespace "secret-namespace-4763" for this suite.
Apr  1 17:36:26.572: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:36:26.685: INFO: namespace secret-namespace-4763 deletion completed in 6.126202044s

• [SLOW TEST:16.421 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:36:26.686: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-3272
Apr  1 17:36:30.756: INFO: Started pod liveness-http in namespace container-probe-3272
STEP: checking the pod's current state and verifying that restartCount is present
Apr  1 17:36:30.760: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:40:32.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3272" for this suite.
Apr  1 17:40:38.094: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:40:38.224: INFO: namespace container-probe-3272 deletion completed in 6.144269269s

• [SLOW TEST:251.539 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:40:38.224: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-316
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr  1 17:40:38.731: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr  1 17:41:04.835: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.1.83.143:8080/dial?request=hostName&protocol=udp&host=10.1.83.142&port=8081&tries=1'] Namespace:pod-network-test-316 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  1 17:41:04.835: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
Apr  1 17:41:05.006: INFO: Waiting for endpoints: map[]
Apr  1 17:41:05.010: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.1.83.143:8080/dial?request=hostName&protocol=udp&host=10.1.81.32&port=8081&tries=1'] Namespace:pod-network-test-316 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  1 17:41:05.010: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
Apr  1 17:41:05.153: INFO: Waiting for endpoints: map[]
Apr  1 17:41:05.157: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.1.83.143:8080/dial?request=hostName&protocol=udp&host=10.1.101.28&port=8081&tries=1'] Namespace:pod-network-test-316 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  1 17:41:05.157: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
Apr  1 17:41:05.361: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:41:05.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-316" for this suite.
Apr  1 17:41:29.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:41:29.528: INFO: namespace pod-network-test-316 deletion completed in 24.159150036s

• [SLOW TEST:51.303 seconds]
[sig-network] Networking
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:41:29.528: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1318
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr  1 17:41:29.564: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-5824'
Apr  1 17:41:29.657: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr  1 17:41:29.657: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1324
Apr  1 17:41:31.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 delete deployment e2e-test-nginx-deployment --namespace=kubectl-5824'
Apr  1 17:41:31.770: INFO: stderr: ""
Apr  1 17:41:31.770: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:41:31.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5824" for this suite.
Apr  1 17:41:37.789: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:41:37.924: INFO: namespace kubectl-5824 deletion completed in 6.149622097s

• [SLOW TEST:8.396 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:41:37.924: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  1 17:41:37.970: INFO: Waiting up to 5m0s for pod "downwardapi-volume-669fa9a8-54a5-11e9-871e-828ee0b576f8" in namespace "downward-api-2756" to be "success or failure"
Apr  1 17:41:37.976: INFO: Pod "downwardapi-volume-669fa9a8-54a5-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.014861ms
Apr  1 17:41:39.981: INFO: Pod "downwardapi-volume-669fa9a8-54a5-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010314296s
Apr  1 17:41:41.985: INFO: Pod "downwardapi-volume-669fa9a8-54a5-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01475632s
STEP: Saw pod success
Apr  1 17:41:41.985: INFO: Pod "downwardapi-volume-669fa9a8-54a5-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 17:41:41.989: INFO: Trying to get logs from node ip-172-31-3-176 pod downwardapi-volume-669fa9a8-54a5-11e9-871e-828ee0b576f8 container client-container: <nil>
STEP: delete the pod
Apr  1 17:41:42.016: INFO: Waiting for pod downwardapi-volume-669fa9a8-54a5-11e9-871e-828ee0b576f8 to disappear
Apr  1 17:41:42.020: INFO: Pod downwardapi-volume-669fa9a8-54a5-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:41:42.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2756" for this suite.
Apr  1 17:41:48.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:41:48.154: INFO: namespace downward-api-2756 deletion completed in 6.129700642s

• [SLOW TEST:10.230 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:41:48.154: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Apr  1 17:41:54.266: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3224 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  1 17:41:54.266: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
Apr  1 17:41:54.369: INFO: Exec stderr: ""
Apr  1 17:41:54.369: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3224 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  1 17:41:54.369: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
Apr  1 17:41:54.492: INFO: Exec stderr: ""
Apr  1 17:41:54.492: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3224 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  1 17:41:54.492: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
Apr  1 17:41:54.596: INFO: Exec stderr: ""
Apr  1 17:41:54.596: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3224 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  1 17:41:54.596: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
Apr  1 17:41:54.711: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Apr  1 17:41:54.711: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3224 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  1 17:41:54.711: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
Apr  1 17:41:54.825: INFO: Exec stderr: ""
Apr  1 17:41:54.825: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3224 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  1 17:41:54.825: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
Apr  1 17:41:54.940: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Apr  1 17:41:54.940: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3224 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  1 17:41:54.940: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
Apr  1 17:41:55.053: INFO: Exec stderr: ""
Apr  1 17:41:55.053: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3224 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  1 17:41:55.053: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
Apr  1 17:41:55.143: INFO: Exec stderr: ""
Apr  1 17:41:55.143: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3224 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  1 17:41:55.143: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
Apr  1 17:41:55.225: INFO: Exec stderr: ""
Apr  1 17:41:55.225: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3224 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  1 17:41:55.225: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
Apr  1 17:41:55.307: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:41:55.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-3224" for this suite.
Apr  1 17:42:47.326: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:42:47.466: INFO: namespace e2e-kubelet-etc-hosts-3224 deletion completed in 52.154091866s

• [SLOW TEST:59.312 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:42:47.466: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Apr  1 17:42:52.047: INFO: Successfully updated pod "annotationupdate9012a7c7-54a5-11e9-871e-828ee0b576f8"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:42:54.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6969" for this suite.
Apr  1 17:43:16.085: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:43:16.221: INFO: namespace downward-api-6969 deletion completed in 22.151525277s

• [SLOW TEST:28.755 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:43:16.222: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Apr  1 17:43:16.283: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-6089,SelfLink:/api/v1/namespaces/watch-6089/configmaps/e2e-watch-test-watch-closed,UID:a12b8664-54a5-11e9-9aab-028387864c62,ResourceVersion:11725,Generation:0,CreationTimestamp:2019-04-01 17:43:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr  1 17:43:16.283: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-6089,SelfLink:/api/v1/namespaces/watch-6089/configmaps/e2e-watch-test-watch-closed,UID:a12b8664-54a5-11e9-9aab-028387864c62,ResourceVersion:11726,Generation:0,CreationTimestamp:2019-04-01 17:43:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Apr  1 17:43:16.301: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-6089,SelfLink:/api/v1/namespaces/watch-6089/configmaps/e2e-watch-test-watch-closed,UID:a12b8664-54a5-11e9-9aab-028387864c62,ResourceVersion:11727,Generation:0,CreationTimestamp:2019-04-01 17:43:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr  1 17:43:16.301: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-6089,SelfLink:/api/v1/namespaces/watch-6089/configmaps/e2e-watch-test-watch-closed,UID:a12b8664-54a5-11e9-9aab-028387864c62,ResourceVersion:11728,Generation:0,CreationTimestamp:2019-04-01 17:43:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:43:16.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6089" for this suite.
Apr  1 17:43:22.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:43:22.436: INFO: namespace watch-6089 deletion completed in 6.130766966s

• [SLOW TEST:6.215 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:43:22.436: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test hostPath mode
Apr  1 17:43:22.484: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-8864" to be "success or failure"
Apr  1 17:43:22.488: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.849164ms
Apr  1 17:43:24.494: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010605609s
Apr  1 17:43:26.499: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015086152s
STEP: Saw pod success
Apr  1 17:43:26.499: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Apr  1 17:43:26.502: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Apr  1 17:43:26.525: INFO: Waiting for pod pod-host-path-test to disappear
Apr  1 17:43:26.528: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:43:26.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-8864" for this suite.
Apr  1 17:43:32.546: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:43:32.665: INFO: namespace hostpath-8864 deletion completed in 6.133060793s

• [SLOW TEST:10.229 seconds]
[sig-storage] HostPath
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:43:32.665: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test use defaults
Apr  1 17:43:32.719: INFO: Waiting up to 5m0s for pod "client-containers-ab03f348-54a5-11e9-871e-828ee0b576f8" in namespace "containers-8626" to be "success or failure"
Apr  1 17:43:32.723: INFO: Pod "client-containers-ab03f348-54a5-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.41829ms
Apr  1 17:43:34.728: INFO: Pod "client-containers-ab03f348-54a5-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009100158s
Apr  1 17:43:36.733: INFO: Pod "client-containers-ab03f348-54a5-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013586921s
STEP: Saw pod success
Apr  1 17:43:36.733: INFO: Pod "client-containers-ab03f348-54a5-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 17:43:36.736: INFO: Trying to get logs from node ip-172-31-3-176 pod client-containers-ab03f348-54a5-11e9-871e-828ee0b576f8 container test-container: <nil>
STEP: delete the pod
Apr  1 17:43:36.777: INFO: Waiting for pod client-containers-ab03f348-54a5-11e9-871e-828ee0b576f8 to disappear
Apr  1 17:43:36.781: INFO: Pod client-containers-ab03f348-54a5-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:43:36.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8626" for this suite.
Apr  1 17:43:42.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:43:42.934: INFO: namespace containers-8626 deletion completed in 6.14948327s

• [SLOW TEST:10.269 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:43:42.935: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-1139
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Apr  1 17:43:42.993: INFO: Found 0 stateful pods, waiting for 3
Apr  1 17:43:52.998: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr  1 17:43:52.998: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr  1 17:43:52.998: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Apr  1 17:43:53.031: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Apr  1 17:44:03.070: INFO: Updating stateful set ss2
Apr  1 17:44:03.078: INFO: Waiting for Pod statefulset-1139/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Apr  1 17:44:13.650: INFO: Found 2 stateful pods, waiting for 3
Apr  1 17:44:23.656: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr  1 17:44:23.656: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr  1 17:44:23.656: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Apr  1 17:44:23.698: INFO: Updating stateful set ss2
Apr  1 17:44:23.733: INFO: Waiting for Pod statefulset-1139/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr  1 17:44:33.786: INFO: Updating stateful set ss2
Apr  1 17:44:33.816: INFO: Waiting for StatefulSet statefulset-1139/ss2 to complete update
Apr  1 17:44:33.816: INFO: Waiting for Pod statefulset-1139/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr  1 17:44:43.824: INFO: Waiting for StatefulSet statefulset-1139/ss2 to complete update
Apr  1 17:44:43.824: INFO: Waiting for Pod statefulset-1139/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr  1 17:44:53.825: INFO: Deleting all statefulset in ns statefulset-1139
Apr  1 17:44:53.829: INFO: Scaling statefulset ss2 to 0
Apr  1 17:45:03.848: INFO: Waiting for statefulset status.replicas updated to 0
Apr  1 17:45:03.852: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:45:03.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1139" for this suite.
Apr  1 17:45:09.898: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:45:10.026: INFO: namespace statefulset-1139 deletion completed in 6.152672312s

• [SLOW TEST:87.092 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:45:10.027: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  1 17:45:10.074: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e50c3101-54a5-11e9-871e-828ee0b576f8" in namespace "downward-api-9885" to be "success or failure"
Apr  1 17:45:10.078: INFO: Pod "downwardapi-volume-e50c3101-54a5-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.005755ms
Apr  1 17:45:12.083: INFO: Pod "downwardapi-volume-e50c3101-54a5-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008392102s
Apr  1 17:45:14.087: INFO: Pod "downwardapi-volume-e50c3101-54a5-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01304166s
STEP: Saw pod success
Apr  1 17:45:14.087: INFO: Pod "downwardapi-volume-e50c3101-54a5-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 17:45:14.091: INFO: Trying to get logs from node ip-172-31-3-176 pod downwardapi-volume-e50c3101-54a5-11e9-871e-828ee0b576f8 container client-container: <nil>
STEP: delete the pod
Apr  1 17:45:14.114: INFO: Waiting for pod downwardapi-volume-e50c3101-54a5-11e9-871e-828ee0b576f8 to disappear
Apr  1 17:45:14.117: INFO: Pod downwardapi-volume-e50c3101-54a5-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:45:14.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9885" for this suite.
Apr  1 17:45:20.135: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:45:20.251: INFO: namespace downward-api-9885 deletion completed in 6.130260281s

• [SLOW TEST:10.224 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:45:20.251: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-1146
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-1146
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-1146
Apr  1 17:45:20.308: INFO: Found 0 stateful pods, waiting for 1
Apr  1 17:45:30.312: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Apr  1 17:45:30.316: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 exec --namespace=statefulset-1146 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  1 17:45:30.526: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  1 17:45:30.526: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  1 17:45:30.526: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr  1 17:45:30.532: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr  1 17:45:40.537: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr  1 17:45:40.537: INFO: Waiting for statefulset status.replicas updated to 0
Apr  1 17:45:40.556: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999617s
Apr  1 17:45:41.560: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.994331957s
Apr  1 17:45:42.565: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.989655347s
Apr  1 17:45:43.570: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.984861801s
Apr  1 17:45:44.575: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.979957897s
Apr  1 17:45:45.579: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.975415566s
Apr  1 17:45:46.584: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.970910012s
Apr  1 17:45:47.588: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.96623095s
Apr  1 17:45:48.593: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.961636007s
Apr  1 17:45:49.597: INFO: Verifying statefulset ss doesn't scale past 1 for another 957.39442ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-1146
Apr  1 17:45:50.602: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 exec --namespace=statefulset-1146 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  1 17:45:50.822: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr  1 17:45:50.822: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr  1 17:45:50.822: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr  1 17:45:50.827: INFO: Found 1 stateful pods, waiting for 3
Apr  1 17:46:00.832: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr  1 17:46:00.832: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr  1 17:46:00.832: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Apr  1 17:46:00.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 exec --namespace=statefulset-1146 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  1 17:46:01.121: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  1 17:46:01.121: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  1 17:46:01.121: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr  1 17:46:01.121: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 exec --namespace=statefulset-1146 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  1 17:46:01.817: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  1 17:46:01.817: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  1 17:46:01.817: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr  1 17:46:01.817: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 exec --namespace=statefulset-1146 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  1 17:46:02.080: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  1 17:46:02.080: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  1 17:46:02.080: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr  1 17:46:02.080: INFO: Waiting for statefulset status.replicas updated to 0
Apr  1 17:46:02.087: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Apr  1 17:46:12.098: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr  1 17:46:12.098: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr  1 17:46:12.098: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr  1 17:46:12.119: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999672s
Apr  1 17:46:13.125: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.994953546s
Apr  1 17:46:14.130: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.989780477s
Apr  1 17:46:15.135: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.98430329s
Apr  1 17:46:16.142: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.979115607s
Apr  1 17:46:17.149: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.972526946s
Apr  1 17:46:18.154: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.965493493s
Apr  1 17:46:19.161: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.958585384s
Apr  1 17:46:20.170: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.953638145s
Apr  1 17:46:21.175: INFO: Verifying statefulset ss doesn't scale past 3 for another 943.968763ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-1146
Apr  1 17:46:22.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 exec --namespace=statefulset-1146 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  1 17:46:22.446: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr  1 17:46:22.446: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr  1 17:46:22.446: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr  1 17:46:22.446: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 exec --namespace=statefulset-1146 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  1 17:46:22.843: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr  1 17:46:22.843: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr  1 17:46:22.843: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr  1 17:46:22.843: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 exec --namespace=statefulset-1146 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  1 17:46:23.087: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr  1 17:46:23.087: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr  1 17:46:23.087: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr  1 17:46:23.087: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr  1 17:46:43.107: INFO: Deleting all statefulset in ns statefulset-1146
Apr  1 17:46:43.111: INFO: Scaling statefulset ss to 0
Apr  1 17:46:43.125: INFO: Waiting for statefulset status.replicas updated to 0
Apr  1 17:46:43.129: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:46:43.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1146" for this suite.
Apr  1 17:46:49.169: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:46:49.393: INFO: namespace statefulset-1146 deletion completed in 6.239100314s

• [SLOW TEST:89.141 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:46:49.393: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Apr  1 17:46:50.100: INFO: Pod name wrapped-volume-race-20a9f350-54a6-11e9-871e-828ee0b576f8: Found 0 pods out of 5
Apr  1 17:46:55.107: INFO: Pod name wrapped-volume-race-20a9f350-54a6-11e9-871e-828ee0b576f8: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-20a9f350-54a6-11e9-871e-828ee0b576f8 in namespace emptydir-wrapper-3791, will wait for the garbage collector to delete the pods
Apr  1 17:47:05.216: INFO: Deleting ReplicationController wrapped-volume-race-20a9f350-54a6-11e9-871e-828ee0b576f8 took: 10.766394ms
Apr  1 17:47:05.616: INFO: Terminating ReplicationController wrapped-volume-race-20a9f350-54a6-11e9-871e-828ee0b576f8 pods took: 400.232889ms
STEP: Creating RC which spawns configmap-volume pods
Apr  1 17:47:43.553: INFO: Pod name wrapped-volume-race-40835e01-54a6-11e9-871e-828ee0b576f8: Found 0 pods out of 5
Apr  1 17:47:48.559: INFO: Pod name wrapped-volume-race-40835e01-54a6-11e9-871e-828ee0b576f8: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-40835e01-54a6-11e9-871e-828ee0b576f8 in namespace emptydir-wrapper-3791, will wait for the garbage collector to delete the pods
Apr  1 17:48:00.656: INFO: Deleting ReplicationController wrapped-volume-race-40835e01-54a6-11e9-871e-828ee0b576f8 took: 12.045696ms
Apr  1 17:48:00.956: INFO: Terminating ReplicationController wrapped-volume-race-40835e01-54a6-11e9-871e-828ee0b576f8 pods took: 300.188121ms
STEP: Creating RC which spawns configmap-volume pods
Apr  1 17:48:41.278: INFO: Pod name wrapped-volume-race-62edcc3a-54a6-11e9-871e-828ee0b576f8: Found 0 pods out of 5
Apr  1 17:48:46.299: INFO: Pod name wrapped-volume-race-62edcc3a-54a6-11e9-871e-828ee0b576f8: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-62edcc3a-54a6-11e9-871e-828ee0b576f8 in namespace emptydir-wrapper-3791, will wait for the garbage collector to delete the pods
Apr  1 17:48:56.405: INFO: Deleting ReplicationController wrapped-volume-race-62edcc3a-54a6-11e9-871e-828ee0b576f8 took: 9.659863ms
Apr  1 17:48:56.805: INFO: Terminating ReplicationController wrapped-volume-race-62edcc3a-54a6-11e9-871e-828ee0b576f8 pods took: 400.202373ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:49:42.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-3791" for this suite.
Apr  1 17:49:50.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:49:51.141: INFO: namespace emptydir-wrapper-3791 deletion completed in 8.288830881s

• [SLOW TEST:181.749 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:49:51.142: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  1 17:49:51.223: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8c9c6d47-54a6-11e9-871e-828ee0b576f8" in namespace "downward-api-4124" to be "success or failure"
Apr  1 17:49:51.237: INFO: Pod "downwardapi-volume-8c9c6d47-54a6-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 14.05679ms
Apr  1 17:49:53.245: INFO: Pod "downwardapi-volume-8c9c6d47-54a6-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022419589s
Apr  1 17:49:55.250: INFO: Pod "downwardapi-volume-8c9c6d47-54a6-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027696912s
STEP: Saw pod success
Apr  1 17:49:55.250: INFO: Pod "downwardapi-volume-8c9c6d47-54a6-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 17:49:55.256: INFO: Trying to get logs from node ip-172-31-3-176 pod downwardapi-volume-8c9c6d47-54a6-11e9-871e-828ee0b576f8 container client-container: <nil>
STEP: delete the pod
Apr  1 17:49:55.288: INFO: Waiting for pod downwardapi-volume-8c9c6d47-54a6-11e9-871e-828ee0b576f8 to disappear
Apr  1 17:49:55.293: INFO: Pod downwardapi-volume-8c9c6d47-54a6-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:49:55.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4124" for this suite.
Apr  1 17:50:01.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:50:01.810: INFO: namespace downward-api-4124 deletion completed in 6.510013399s

• [SLOW TEST:10.669 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:50:01.810: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-2757
Apr  1 17:50:05.994: INFO: Started pod liveness-exec in namespace container-probe-2757
STEP: checking the pod's current state and verifying that restartCount is present
Apr  1 17:50:06.001: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:54:06.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2757" for this suite.
Apr  1 17:54:12.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:54:12.814: INFO: namespace container-probe-2757 deletion completed in 6.144663624s

• [SLOW TEST:251.003 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:54:12.814: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-28932d92-54a7-11e9-871e-828ee0b576f8
STEP: Creating a pod to test consume configMaps
Apr  1 17:54:12.871: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-28948dab-54a7-11e9-871e-828ee0b576f8" in namespace "projected-2079" to be "success or failure"
Apr  1 17:54:12.876: INFO: Pod "pod-projected-configmaps-28948dab-54a7-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.683529ms
Apr  1 17:54:15.033: INFO: Pod "pod-projected-configmaps-28948dab-54a7-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.161217984s
Apr  1 17:54:17.039: INFO: Pod "pod-projected-configmaps-28948dab-54a7-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.1673766s
STEP: Saw pod success
Apr  1 17:54:17.039: INFO: Pod "pod-projected-configmaps-28948dab-54a7-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 17:54:17.043: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-projected-configmaps-28948dab-54a7-11e9-871e-828ee0b576f8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr  1 17:54:17.071: INFO: Waiting for pod pod-projected-configmaps-28948dab-54a7-11e9-871e-828ee0b576f8 to disappear
Apr  1 17:54:17.075: INFO: Pod pod-projected-configmaps-28948dab-54a7-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:54:17.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2079" for this suite.
Apr  1 17:54:23.101: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:54:23.233: INFO: namespace projected-2079 deletion completed in 6.154005373s

• [SLOW TEST:10.420 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:54:23.234: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Apr  1 17:54:31.340: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr  1 17:54:31.343: INFO: Pod pod-with-prestop-http-hook still exists
Apr  1 17:54:33.344: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr  1 17:54:33.348: INFO: Pod pod-with-prestop-http-hook still exists
Apr  1 17:54:35.344: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr  1 17:54:35.349: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:54:35.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9721" for this suite.
Apr  1 17:54:57.385: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:54:57.539: INFO: namespace container-lifecycle-hook-9721 deletion completed in 22.175754392s

• [SLOW TEST:34.305 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:54:57.539: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:55:01.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2490" for this suite.
Apr  1 17:55:07.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:55:07.779: INFO: namespace kubelet-test-2490 deletion completed in 6.16375687s

• [SLOW TEST:10.240 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:55:07.779: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1583
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr  1 17:55:07.820: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-3599'
Apr  1 17:55:08.288: INFO: stderr: ""
Apr  1 17:55:08.288: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1588
Apr  1 17:55:08.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 delete pods e2e-test-nginx-pod --namespace=kubectl-3599'
Apr  1 17:55:13.944: INFO: stderr: ""
Apr  1 17:55:13.944: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:55:13.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3599" for this suite.
Apr  1 17:55:19.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:55:20.556: INFO: namespace kubectl-3599 deletion completed in 6.608342124s

• [SLOW TEST:12.777 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:55:20.556: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-106
Apr  1 17:55:24.622: INFO: Started pod liveness-exec in namespace container-probe-106
STEP: checking the pod's current state and verifying that restartCount is present
Apr  1 17:55:24.625: INFO: Initial restart count of pod liveness-exec is 0
Apr  1 17:56:14.755: INFO: Restart count of pod container-probe-106/liveness-exec is now 1 (50.129930511s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:56:14.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-106" for this suite.
Apr  1 17:56:20.786: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:56:20.962: INFO: namespace container-probe-106 deletion completed in 6.190082371s

• [SLOW TEST:60.406 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:56:20.963: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Apr  1 17:56:21.019: INFO: Waiting up to 5m0s for pod "pod-74f599f8-54a7-11e9-871e-828ee0b576f8" in namespace "emptydir-6858" to be "success or failure"
Apr  1 17:56:21.024: INFO: Pod "pod-74f599f8-54a7-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.938409ms
Apr  1 17:56:23.030: INFO: Pod "pod-74f599f8-54a7-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010744801s
Apr  1 17:56:25.037: INFO: Pod "pod-74f599f8-54a7-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01850447s
STEP: Saw pod success
Apr  1 17:56:25.038: INFO: Pod "pod-74f599f8-54a7-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 17:56:25.044: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-74f599f8-54a7-11e9-871e-828ee0b576f8 container test-container: <nil>
STEP: delete the pod
Apr  1 17:56:25.069: INFO: Waiting for pod pod-74f599f8-54a7-11e9-871e-828ee0b576f8 to disappear
Apr  1 17:56:25.075: INFO: Pod pod-74f599f8-54a7-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:56:25.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6858" for this suite.
Apr  1 17:56:31.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:56:31.215: INFO: namespace emptydir-6858 deletion completed in 6.135746931s

• [SLOW TEST:10.252 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:56:31.215: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the initial replication controller
Apr  1 17:56:31.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 create -f - --namespace=kubectl-1465'
Apr  1 17:56:31.523: INFO: stderr: ""
Apr  1 17:56:31.523: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr  1 17:56:31.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1465'
Apr  1 17:56:31.617: INFO: stderr: ""
Apr  1 17:56:31.617: INFO: stdout: "update-demo-nautilus-9n2hz update-demo-nautilus-cx4g9 "
Apr  1 17:56:31.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods update-demo-nautilus-9n2hz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1465'
Apr  1 17:56:31.690: INFO: stderr: ""
Apr  1 17:56:31.690: INFO: stdout: ""
Apr  1 17:56:31.690: INFO: update-demo-nautilus-9n2hz is created but not running
Apr  1 17:56:36.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1465'
Apr  1 17:56:36.763: INFO: stderr: ""
Apr  1 17:56:36.763: INFO: stdout: "update-demo-nautilus-9n2hz update-demo-nautilus-cx4g9 "
Apr  1 17:56:36.763: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods update-demo-nautilus-9n2hz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1465'
Apr  1 17:56:36.827: INFO: stderr: ""
Apr  1 17:56:36.827: INFO: stdout: "true"
Apr  1 17:56:36.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods update-demo-nautilus-9n2hz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1465'
Apr  1 17:56:36.897: INFO: stderr: ""
Apr  1 17:56:36.897: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  1 17:56:36.897: INFO: validating pod update-demo-nautilus-9n2hz
Apr  1 17:56:36.902: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  1 17:56:36.902: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  1 17:56:36.902: INFO: update-demo-nautilus-9n2hz is verified up and running
Apr  1 17:56:36.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods update-demo-nautilus-cx4g9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1465'
Apr  1 17:56:36.968: INFO: stderr: ""
Apr  1 17:56:36.968: INFO: stdout: "true"
Apr  1 17:56:36.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods update-demo-nautilus-cx4g9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1465'
Apr  1 17:56:37.035: INFO: stderr: ""
Apr  1 17:56:37.035: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  1 17:56:37.035: INFO: validating pod update-demo-nautilus-cx4g9
Apr  1 17:56:37.043: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  1 17:56:37.043: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  1 17:56:37.043: INFO: update-demo-nautilus-cx4g9 is verified up and running
STEP: rolling-update to new replication controller
Apr  1 17:56:37.044: INFO: scanned /root for discovery docs: <nil>
Apr  1 17:56:37.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-1465'
Apr  1 17:56:59.463: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Apr  1 17:56:59.463: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr  1 17:56:59.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1465'
Apr  1 17:56:59.608: INFO: stderr: ""
Apr  1 17:56:59.608: INFO: stdout: "update-demo-kitten-44776 update-demo-kitten-flpv9 update-demo-nautilus-cx4g9 "
STEP: Replicas for name=update-demo: expected=2 actual=3
Apr  1 17:57:04.608: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1465'
Apr  1 17:57:04.699: INFO: stderr: ""
Apr  1 17:57:04.699: INFO: stdout: "update-demo-kitten-44776 update-demo-kitten-flpv9 "
Apr  1 17:57:04.700: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods update-demo-kitten-44776 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1465'
Apr  1 17:57:04.765: INFO: stderr: ""
Apr  1 17:57:04.765: INFO: stdout: "true"
Apr  1 17:57:04.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods update-demo-kitten-44776 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1465'
Apr  1 17:57:04.833: INFO: stderr: ""
Apr  1 17:57:04.833: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Apr  1 17:57:04.833: INFO: validating pod update-demo-kitten-44776
Apr  1 17:57:04.845: INFO: got data: {
  "image": "kitten.jpg"
}

Apr  1 17:57:04.846: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Apr  1 17:57:04.846: INFO: update-demo-kitten-44776 is verified up and running
Apr  1 17:57:04.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods update-demo-kitten-flpv9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1465'
Apr  1 17:57:04.912: INFO: stderr: ""
Apr  1 17:57:04.912: INFO: stdout: "true"
Apr  1 17:57:04.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods update-demo-kitten-flpv9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1465'
Apr  1 17:57:04.980: INFO: stderr: ""
Apr  1 17:57:04.980: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Apr  1 17:57:04.980: INFO: validating pod update-demo-kitten-flpv9
Apr  1 17:57:04.991: INFO: got data: {
  "image": "kitten.jpg"
}

Apr  1 17:57:04.992: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Apr  1 17:57:04.992: INFO: update-demo-kitten-flpv9 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:57:04.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1465" for this suite.
Apr  1 17:57:27.020: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:57:27.141: INFO: namespace kubectl-1465 deletion completed in 22.143789009s

• [SLOW TEST:55.927 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:57:27.142: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-9c67a038-54a7-11e9-871e-828ee0b576f8
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-9c67a038-54a7-11e9-871e-828ee0b576f8
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:59:02.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-134" for this suite.
Apr  1 17:59:26.088: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:59:26.421: INFO: namespace configmap-134 deletion completed in 24.35224615s

• [SLOW TEST:119.279 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:59:26.421: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Apr  1 17:59:26.523: INFO: namespace kubectl-9989
Apr  1 17:59:26.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 create -f - --namespace=kubectl-9989'
Apr  1 17:59:26.716: INFO: stderr: ""
Apr  1 17:59:26.716: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Apr  1 17:59:27.722: INFO: Selector matched 1 pods for map[app:redis]
Apr  1 17:59:27.722: INFO: Found 0 / 1
Apr  1 17:59:28.722: INFO: Selector matched 1 pods for map[app:redis]
Apr  1 17:59:28.722: INFO: Found 0 / 1
Apr  1 17:59:29.722: INFO: Selector matched 1 pods for map[app:redis]
Apr  1 17:59:29.722: INFO: Found 1 / 1
Apr  1 17:59:29.722: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr  1 17:59:29.727: INFO: Selector matched 1 pods for map[app:redis]
Apr  1 17:59:29.727: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr  1 17:59:29.727: INFO: wait on redis-master startup in kubectl-9989 
Apr  1 17:59:29.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 logs redis-master-4ff48 redis-master --namespace=kubectl-9989'
Apr  1 17:59:29.829: INFO: stderr: ""
Apr  1 17:59:29.829: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 01 Apr 17:59:28.068 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 01 Apr 17:59:28.068 # Server started, Redis version 3.2.12\n1:M 01 Apr 17:59:28.068 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 01 Apr 17:59:28.068 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Apr  1 17:59:29.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-9989'
Apr  1 17:59:29.931: INFO: stderr: ""
Apr  1 17:59:29.931: INFO: stdout: "service/rm2 exposed\n"
Apr  1 17:59:29.945: INFO: Service rm2 in namespace kubectl-9989 found.
STEP: exposing service
Apr  1 17:59:31.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-9989'
Apr  1 17:59:32.074: INFO: stderr: ""
Apr  1 17:59:32.074: INFO: stdout: "service/rm3 exposed\n"
Apr  1 17:59:32.079: INFO: Service rm3 in namespace kubectl-9989 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:59:34.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9989" for this suite.
Apr  1 17:59:56.112: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 17:59:56.362: INFO: namespace kubectl-9989 deletion completed in 22.271282471s

• [SLOW TEST:29.941 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create services for rc  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 17:59:56.362: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  1 17:59:56.394: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 version'
Apr  1 17:59:56.464: INFO: stderr: ""
Apr  1 17:59:56.464: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.0\", GitCommit:\"641856db18352033a0d96dbc99153fa3b27298e5\", GitTreeState:\"clean\", BuildDate:\"2019-03-25T15:53:57Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.0\", GitCommit:\"641856db18352033a0d96dbc99153fa3b27298e5\", GitTreeState:\"clean\", BuildDate:\"2019-03-25T15:45:25Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 17:59:56.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3848" for this suite.
Apr  1 18:00:02.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:00:03.158: INFO: namespace kubectl-3848 deletion completed in 6.246483369s

• [SLOW TEST:6.796 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:00:03.158: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-1358
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr  1 18:00:03.424: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr  1 18:00:27.540: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.1.83.169:8080/dial?request=hostName&protocol=http&host=10.1.101.35&port=8080&tries=1'] Namespace:pod-network-test-1358 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  1 18:00:27.540: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
Apr  1 18:00:27.774: INFO: Waiting for endpoints: map[]
Apr  1 18:00:27.778: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.1.83.169:8080/dial?request=hostName&protocol=http&host=10.1.81.51&port=8080&tries=1'] Namespace:pod-network-test-1358 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  1 18:00:27.778: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
Apr  1 18:00:27.930: INFO: Waiting for endpoints: map[]
Apr  1 18:00:27.936: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.1.83.169:8080/dial?request=hostName&protocol=http&host=10.1.83.168&port=8080&tries=1'] Namespace:pod-network-test-1358 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  1 18:00:27.936: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
Apr  1 18:00:28.090: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:00:28.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1358" for this suite.
Apr  1 18:00:50.110: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:00:50.232: INFO: namespace pod-network-test-1358 deletion completed in 22.13636016s

• [SLOW TEST:47.073 seconds]
[sig-network] Networking
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:00:50.232: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  1 18:00:50.269: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:00:51.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-6105" for this suite.
Apr  1 18:00:57.340: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:00:57.461: INFO: namespace custom-resource-definition-6105 deletion completed in 6.136119338s

• [SLOW TEST:7.229 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:00:57.462: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0401 18:00:58.818631      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr  1 18:00:58.818: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:00:58.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4305" for this suite.
Apr  1 18:01:04.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:01:04.995: INFO: namespace gc-4305 deletion completed in 6.17276197s

• [SLOW TEST:7.533 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:01:04.995: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-1e4f022c-54a8-11e9-871e-828ee0b576f8
STEP: Creating a pod to test consume secrets
Apr  1 18:01:05.238: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1e507af1-54a8-11e9-871e-828ee0b576f8" in namespace "projected-5286" to be "success or failure"
Apr  1 18:01:05.245: INFO: Pod "pod-projected-secrets-1e507af1-54a8-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.43107ms
Apr  1 18:01:07.249: INFO: Pod "pod-projected-secrets-1e507af1-54a8-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010829449s
Apr  1 18:01:09.254: INFO: Pod "pod-projected-secrets-1e507af1-54a8-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015654128s
STEP: Saw pod success
Apr  1 18:01:09.254: INFO: Pod "pod-projected-secrets-1e507af1-54a8-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 18:01:09.258: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-projected-secrets-1e507af1-54a8-11e9-871e-828ee0b576f8 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr  1 18:01:09.281: INFO: Waiting for pod pod-projected-secrets-1e507af1-54a8-11e9-871e-828ee0b576f8 to disappear
Apr  1 18:01:09.284: INFO: Pod pod-projected-secrets-1e507af1-54a8-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:01:09.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5286" for this suite.
Apr  1 18:01:15.302: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:01:15.569: INFO: namespace projected-5286 deletion completed in 6.280996522s

• [SLOW TEST:10.574 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:01:15.570: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override all
Apr  1 18:01:15.617: INFO: Waiting up to 5m0s for pod "client-containers-248e5f4a-54a8-11e9-871e-828ee0b576f8" in namespace "containers-7587" to be "success or failure"
Apr  1 18:01:15.623: INFO: Pod "client-containers-248e5f4a-54a8-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.676397ms
Apr  1 18:01:17.821: INFO: Pod "client-containers-248e5f4a-54a8-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.204524877s
Apr  1 18:01:19.826: INFO: Pod "client-containers-248e5f4a-54a8-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.209294317s
STEP: Saw pod success
Apr  1 18:01:19.826: INFO: Pod "client-containers-248e5f4a-54a8-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 18:01:19.831: INFO: Trying to get logs from node ip-172-31-3-176 pod client-containers-248e5f4a-54a8-11e9-871e-828ee0b576f8 container test-container: <nil>
STEP: delete the pod
Apr  1 18:01:19.855: INFO: Waiting for pod client-containers-248e5f4a-54a8-11e9-871e-828ee0b576f8 to disappear
Apr  1 18:01:19.858: INFO: Pod client-containers-248e5f4a-54a8-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:01:19.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7587" for this suite.
Apr  1 18:01:25.882: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:01:26.006: INFO: namespace containers-7587 deletion completed in 6.144140183s

• [SLOW TEST:10.437 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:01:26.007: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-2ac6d31e-54a8-11e9-871e-828ee0b576f8
STEP: Creating a pod to test consume configMaps
Apr  1 18:01:26.058: INFO: Waiting up to 5m0s for pod "pod-configmaps-2ac7f5eb-54a8-11e9-871e-828ee0b576f8" in namespace "configmap-6274" to be "success or failure"
Apr  1 18:01:26.062: INFO: Pod "pod-configmaps-2ac7f5eb-54a8-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.820995ms
Apr  1 18:01:28.067: INFO: Pod "pod-configmaps-2ac7f5eb-54a8-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009765968s
Apr  1 18:01:30.073: INFO: Pod "pod-configmaps-2ac7f5eb-54a8-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015389498s
STEP: Saw pod success
Apr  1 18:01:30.073: INFO: Pod "pod-configmaps-2ac7f5eb-54a8-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 18:01:30.077: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-configmaps-2ac7f5eb-54a8-11e9-871e-828ee0b576f8 container configmap-volume-test: <nil>
STEP: delete the pod
Apr  1 18:01:30.110: INFO: Waiting for pod pod-configmaps-2ac7f5eb-54a8-11e9-871e-828ee0b576f8 to disappear
Apr  1 18:01:30.113: INFO: Pod pod-configmaps-2ac7f5eb-54a8-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:01:30.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6274" for this suite.
Apr  1 18:01:36.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:01:36.265: INFO: namespace configmap-6274 deletion completed in 6.148357624s

• [SLOW TEST:10.258 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:01:36.265: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1414
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr  1 18:01:36.400: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-9674'
Apr  1 18:01:36.493: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr  1 18:01:36.493: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Apr  1 18:01:36.499: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Apr  1 18:01:36.501: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Apr  1 18:01:36.514: INFO: scanned /root for discovery docs: <nil>
Apr  1 18:01:36.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-9674'
Apr  1 18:01:52.302: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Apr  1 18:01:52.302: INFO: stdout: "Created e2e-test-nginx-rc-0f9bede3c0edcdcf0a5a3b4e06e7bfb2\nScaling up e2e-test-nginx-rc-0f9bede3c0edcdcf0a5a3b4e06e7bfb2 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-0f9bede3c0edcdcf0a5a3b4e06e7bfb2 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-0f9bede3c0edcdcf0a5a3b4e06e7bfb2 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Apr  1 18:01:52.302: INFO: stdout: "Created e2e-test-nginx-rc-0f9bede3c0edcdcf0a5a3b4e06e7bfb2\nScaling up e2e-test-nginx-rc-0f9bede3c0edcdcf0a5a3b4e06e7bfb2 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-0f9bede3c0edcdcf0a5a3b4e06e7bfb2 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-0f9bede3c0edcdcf0a5a3b4e06e7bfb2 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Apr  1 18:01:52.302: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-9674'
Apr  1 18:01:52.376: INFO: stderr: ""
Apr  1 18:01:52.376: INFO: stdout: "e2e-test-nginx-rc-0f9bede3c0edcdcf0a5a3b4e06e7bfb2-zsp6p "
Apr  1 18:01:52.376: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods e2e-test-nginx-rc-0f9bede3c0edcdcf0a5a3b4e06e7bfb2-zsp6p -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9674'
Apr  1 18:01:52.468: INFO: stderr: ""
Apr  1 18:01:52.468: INFO: stdout: "true"
Apr  1 18:01:52.468: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods e2e-test-nginx-rc-0f9bede3c0edcdcf0a5a3b4e06e7bfb2-zsp6p -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9674'
Apr  1 18:01:52.552: INFO: stderr: ""
Apr  1 18:01:52.552: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Apr  1 18:01:52.552: INFO: e2e-test-nginx-rc-0f9bede3c0edcdcf0a5a3b4e06e7bfb2-zsp6p is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1420
Apr  1 18:01:52.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 delete rc e2e-test-nginx-rc --namespace=kubectl-9674'
Apr  1 18:01:52.635: INFO: stderr: ""
Apr  1 18:01:52.635: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:01:52.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9674" for this suite.
Apr  1 18:02:14.658: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:02:14.783: INFO: namespace kubectl-9674 deletion completed in 22.143000949s

• [SLOW TEST:38.518 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:02:14.783: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  1 18:02:14.830: INFO: (0) /api/v1/nodes/ip-172-31-22-24:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 8.338296ms)
Apr  1 18:02:14.835: INFO: (1) /api/v1/nodes/ip-172-31-22-24:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.515393ms)
Apr  1 18:02:14.839: INFO: (2) /api/v1/nodes/ip-172-31-22-24:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.294018ms)
Apr  1 18:02:14.843: INFO: (3) /api/v1/nodes/ip-172-31-22-24:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.368485ms)
Apr  1 18:02:14.848: INFO: (4) /api/v1/nodes/ip-172-31-22-24:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.880844ms)
Apr  1 18:02:14.853: INFO: (5) /api/v1/nodes/ip-172-31-22-24:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.907256ms)
Apr  1 18:02:14.858: INFO: (6) /api/v1/nodes/ip-172-31-22-24:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.492023ms)
Apr  1 18:02:14.862: INFO: (7) /api/v1/nodes/ip-172-31-22-24:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.467102ms)
Apr  1 18:02:14.867: INFO: (8) /api/v1/nodes/ip-172-31-22-24:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.384789ms)
Apr  1 18:02:14.871: INFO: (9) /api/v1/nodes/ip-172-31-22-24:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.409922ms)
Apr  1 18:02:14.876: INFO: (10) /api/v1/nodes/ip-172-31-22-24:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.309864ms)
Apr  1 18:02:14.880: INFO: (11) /api/v1/nodes/ip-172-31-22-24:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.814592ms)
Apr  1 18:02:14.885: INFO: (12) /api/v1/nodes/ip-172-31-22-24:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.311502ms)
Apr  1 18:02:14.889: INFO: (13) /api/v1/nodes/ip-172-31-22-24:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.252766ms)
Apr  1 18:02:14.893: INFO: (14) /api/v1/nodes/ip-172-31-22-24:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.351505ms)
Apr  1 18:02:14.898: INFO: (15) /api/v1/nodes/ip-172-31-22-24:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.548531ms)
Apr  1 18:02:14.903: INFO: (16) /api/v1/nodes/ip-172-31-22-24:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.601254ms)
Apr  1 18:02:14.907: INFO: (17) /api/v1/nodes/ip-172-31-22-24:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.434595ms)
Apr  1 18:02:14.911: INFO: (18) /api/v1/nodes/ip-172-31-22-24:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.195927ms)
Apr  1 18:02:14.916: INFO: (19) /api/v1/nodes/ip-172-31-22-24:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.215117ms)
[AfterEach] version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:02:14.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8189" for this suite.
Apr  1 18:02:20.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:02:21.055: INFO: namespace proxy-8189 deletion completed in 6.135242898s

• [SLOW TEST:6.272 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:02:21.055: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  1 18:02:21.628: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4b96cccd-54a8-11e9-871e-828ee0b576f8" in namespace "downward-api-9571" to be "success or failure"
Apr  1 18:02:21.633: INFO: Pod "downwardapi-volume-4b96cccd-54a8-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.769859ms
Apr  1 18:02:23.650: INFO: Pod "downwardapi-volume-4b96cccd-54a8-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022297159s
Apr  1 18:02:25.656: INFO: Pod "downwardapi-volume-4b96cccd-54a8-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027599688s
STEP: Saw pod success
Apr  1 18:02:25.656: INFO: Pod "downwardapi-volume-4b96cccd-54a8-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 18:02:25.661: INFO: Trying to get logs from node ip-172-31-3-176 pod downwardapi-volume-4b96cccd-54a8-11e9-871e-828ee0b576f8 container client-container: <nil>
STEP: delete the pod
Apr  1 18:02:25.685: INFO: Waiting for pod downwardapi-volume-4b96cccd-54a8-11e9-871e-828ee0b576f8 to disappear
Apr  1 18:02:25.690: INFO: Pod downwardapi-volume-4b96cccd-54a8-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:02:25.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9571" for this suite.
Apr  1 18:02:31.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:02:31.835: INFO: namespace downward-api-9571 deletion completed in 6.14058598s

• [SLOW TEST:10.780 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:02:31.835: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-52036e07-54a8-11e9-871e-828ee0b576f8
STEP: Creating a pod to test consume secrets
Apr  1 18:02:31.888: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5204aade-54a8-11e9-871e-828ee0b576f8" in namespace "projected-7956" to be "success or failure"
Apr  1 18:02:31.893: INFO: Pod "pod-projected-secrets-5204aade-54a8-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.616983ms
Apr  1 18:02:33.897: INFO: Pod "pod-projected-secrets-5204aade-54a8-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009074292s
STEP: Saw pod success
Apr  1 18:02:33.897: INFO: Pod "pod-projected-secrets-5204aade-54a8-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 18:02:33.903: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-projected-secrets-5204aade-54a8-11e9-871e-828ee0b576f8 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr  1 18:02:34.479: INFO: Waiting for pod pod-projected-secrets-5204aade-54a8-11e9-871e-828ee0b576f8 to disappear
Apr  1 18:02:34.483: INFO: Pod pod-projected-secrets-5204aade-54a8-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:02:34.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7956" for this suite.
Apr  1 18:02:40.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:02:40.696: INFO: namespace projected-7956 deletion completed in 6.205867233s

• [SLOW TEST:8.861 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:02:40.696: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Apr  1 18:02:40.734: INFO: PodSpec: initContainers in spec.initContainers
Apr  1 18:03:27.607: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-574beba1-54a8-11e9-871e-828ee0b576f8", GenerateName:"", Namespace:"init-container-5614", SelfLink:"/api/v1/namespaces/init-container-5614/pods/pod-init-574beba1-54a8-11e9-871e-828ee0b576f8", UID:"574e748f-54a8-11e9-9aab-028387864c62", ResourceVersion:"16025", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63689738560, loc:(*time.Location)(0x89f10e0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"734305631"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-xpx7l", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc003004480), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-xpx7l", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-xpx7l", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-xpx7l", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0024116e8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-172-31-3-176", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0026a78c0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002411770)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002411790)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc002411798)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689738560, loc:(*time.Location)(0x89f10e0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689738560, loc:(*time.Location)(0x89f10e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689738560, loc:(*time.Location)(0x89f10e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689738560, loc:(*time.Location)(0x89f10e0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.31.3.176", PodIP:"10.1.83.178", StartTime:(*v1.Time)(0xc002c0ac20), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001ea7420)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001ea7490)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://0db6fa6da1b57161dc944e22ec3ca7302b52901b62bd02a5017d296977cf3887"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002c0ac60), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002c0ac40), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:03:27.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5614" for this suite.
Apr  1 18:03:49.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:03:49.787: INFO: namespace init-container-5614 deletion completed in 22.17124868s

• [SLOW TEST:69.091 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:03:49.787: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-807b314c-54a8-11e9-871e-828ee0b576f8
STEP: Creating a pod to test consume configMaps
Apr  1 18:03:49.865: INFO: Waiting up to 5m0s for pod "pod-configmaps-807e7453-54a8-11e9-871e-828ee0b576f8" in namespace "configmap-7222" to be "success or failure"
Apr  1 18:03:49.877: INFO: Pod "pod-configmaps-807e7453-54a8-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 11.73486ms
Apr  1 18:03:51.884: INFO: Pod "pod-configmaps-807e7453-54a8-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018646007s
STEP: Saw pod success
Apr  1 18:03:51.884: INFO: Pod "pod-configmaps-807e7453-54a8-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 18:03:51.887: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-configmaps-807e7453-54a8-11e9-871e-828ee0b576f8 container configmap-volume-test: <nil>
STEP: delete the pod
Apr  1 18:03:51.911: INFO: Waiting for pod pod-configmaps-807e7453-54a8-11e9-871e-828ee0b576f8 to disappear
Apr  1 18:03:51.918: INFO: Pod pod-configmaps-807e7453-54a8-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:03:51.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7222" for this suite.
Apr  1 18:03:59.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:04:00.110: INFO: namespace configmap-7222 deletion completed in 8.186916522s

• [SLOW TEST:10.323 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:04:00.110: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Apr  1 18:04:00.175: INFO: Waiting up to 5m0s for pod "pod-86a29199-54a8-11e9-871e-828ee0b576f8" in namespace "emptydir-4751" to be "success or failure"
Apr  1 18:04:00.179: INFO: Pod "pod-86a29199-54a8-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.072034ms
Apr  1 18:04:02.183: INFO: Pod "pod-86a29199-54a8-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008623219s
Apr  1 18:04:04.188: INFO: Pod "pod-86a29199-54a8-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013138144s
STEP: Saw pod success
Apr  1 18:04:04.188: INFO: Pod "pod-86a29199-54a8-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 18:04:04.193: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-86a29199-54a8-11e9-871e-828ee0b576f8 container test-container: <nil>
STEP: delete the pod
Apr  1 18:04:04.218: INFO: Waiting for pod pod-86a29199-54a8-11e9-871e-828ee0b576f8 to disappear
Apr  1 18:04:04.222: INFO: Pod pod-86a29199-54a8-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:04:04.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4751" for this suite.
Apr  1 18:04:10.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:04:10.380: INFO: namespace emptydir-4751 deletion completed in 6.153833902s

• [SLOW TEST:10.270 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:04:10.380: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-6466
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Apr  1 18:04:10.436: INFO: Found 0 stateful pods, waiting for 3
Apr  1 18:04:20.440: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr  1 18:04:20.440: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr  1 18:04:20.440: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Apr  1 18:04:20.451: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 exec --namespace=statefulset-6466 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  1 18:04:20.713: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  1 18:04:20.713: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  1 18:04:20.713: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Apr  1 18:04:30.753: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Apr  1 18:04:40.781: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 exec --namespace=statefulset-6466 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  1 18:04:41.033: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr  1 18:04:41.033: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr  1 18:04:41.033: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr  1 18:05:01.061: INFO: Waiting for StatefulSet statefulset-6466/ss2 to complete update
Apr  1 18:05:01.061: INFO: Waiting for Pod statefulset-6466/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Apr  1 18:05:11.069: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 exec --namespace=statefulset-6466 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  1 18:05:11.343: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  1 18:05:11.343: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  1 18:05:11.343: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr  1 18:05:21.397: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Apr  1 18:05:31.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 exec --namespace=statefulset-6466 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  1 18:05:31.666: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr  1 18:05:31.666: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr  1 18:05:31.666: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr  1 18:05:41.690: INFO: Waiting for StatefulSet statefulset-6466/ss2 to complete update
Apr  1 18:05:41.690: INFO: Waiting for Pod statefulset-6466/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Apr  1 18:05:51.698: INFO: Waiting for StatefulSet statefulset-6466/ss2 to complete update
Apr  1 18:05:51.698: INFO: Waiting for Pod statefulset-6466/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr  1 18:06:01.702: INFO: Deleting all statefulset in ns statefulset-6466
Apr  1 18:06:01.705: INFO: Scaling statefulset ss2 to 0
Apr  1 18:06:31.731: INFO: Waiting for statefulset status.replicas updated to 0
Apr  1 18:06:31.735: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:06:31.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6466" for this suite.
Apr  1 18:06:37.773: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:06:37.934: INFO: namespace statefulset-6466 deletion completed in 6.175102343s

• [SLOW TEST:147.554 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:06:37.934: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-e4b45630-54a8-11e9-871e-828ee0b576f8
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:06:42.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8129" for this suite.
Apr  1 18:07:04.053: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:07:04.180: INFO: namespace configmap-8129 deletion completed in 22.142302647s

• [SLOW TEST:26.246 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:07:04.180: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Apr  1 18:07:04.241: INFO: Waiting up to 5m0s for pod "pod-f459da57-54a8-11e9-871e-828ee0b576f8" in namespace "emptydir-2453" to be "success or failure"
Apr  1 18:07:04.245: INFO: Pod "pod-f459da57-54a8-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.399339ms
Apr  1 18:07:06.250: INFO: Pod "pod-f459da57-54a8-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009914781s
Apr  1 18:07:08.255: INFO: Pod "pod-f459da57-54a8-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014615414s
STEP: Saw pod success
Apr  1 18:07:08.255: INFO: Pod "pod-f459da57-54a8-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 18:07:08.259: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-f459da57-54a8-11e9-871e-828ee0b576f8 container test-container: <nil>
STEP: delete the pod
Apr  1 18:07:08.282: INFO: Waiting for pod pod-f459da57-54a8-11e9-871e-828ee0b576f8 to disappear
Apr  1 18:07:08.285: INFO: Pod pod-f459da57-54a8-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:07:08.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2453" for this suite.
Apr  1 18:07:14.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:07:14.427: INFO: namespace emptydir-2453 deletion completed in 6.13766686s

• [SLOW TEST:10.246 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:07:14.427: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:07:20.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-3125" for this suite.
Apr  1 18:07:26.582: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:07:26.732: INFO: namespace namespaces-3125 deletion completed in 6.165857987s
STEP: Destroying namespace "nsdeletetest-2089" for this suite.
Apr  1 18:07:26.738: INFO: Namespace nsdeletetest-2089 was already deleted
STEP: Destroying namespace "nsdeletetest-9578" for this suite.
Apr  1 18:07:32.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:07:32.876: INFO: namespace nsdeletetest-9578 deletion completed in 6.138095894s

• [SLOW TEST:18.449 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:07:32.876: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-057292dc-54a9-11e9-871e-828ee0b576f8
STEP: Creating a pod to test consume configMaps
Apr  1 18:07:32.929: INFO: Waiting up to 5m0s for pod "pod-configmaps-0573fda7-54a9-11e9-871e-828ee0b576f8" in namespace "configmap-9671" to be "success or failure"
Apr  1 18:07:32.934: INFO: Pod "pod-configmaps-0573fda7-54a9-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.967768ms
Apr  1 18:07:34.938: INFO: Pod "pod-configmaps-0573fda7-54a9-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009277996s
STEP: Saw pod success
Apr  1 18:07:34.939: INFO: Pod "pod-configmaps-0573fda7-54a9-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 18:07:34.943: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-configmaps-0573fda7-54a9-11e9-871e-828ee0b576f8 container configmap-volume-test: <nil>
STEP: delete the pod
Apr  1 18:07:34.968: INFO: Waiting for pod pod-configmaps-0573fda7-54a9-11e9-871e-828ee0b576f8 to disappear
Apr  1 18:07:34.972: INFO: Pod pod-configmaps-0573fda7-54a9-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:07:34.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9671" for this suite.
Apr  1 18:07:40.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:07:41.102: INFO: namespace configmap-9671 deletion completed in 6.126787505s

• [SLOW TEST:8.226 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:07:41.103: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0401 18:08:21.359357      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr  1 18:08:21.359: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:08:21.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3770" for this suite.
Apr  1 18:08:27.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:08:27.543: INFO: namespace gc-3770 deletion completed in 6.180470882s

• [SLOW TEST:46.440 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:08:27.543: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on tmpfs
Apr  1 18:08:27.597: INFO: Waiting up to 5m0s for pod "pod-26095820-54a9-11e9-871e-828ee0b576f8" in namespace "emptydir-9085" to be "success or failure"
Apr  1 18:08:27.602: INFO: Pod "pod-26095820-54a9-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.123468ms
Apr  1 18:08:29.607: INFO: Pod "pod-26095820-54a9-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009735182s
Apr  1 18:08:31.619: INFO: Pod "pod-26095820-54a9-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022152754s
STEP: Saw pod success
Apr  1 18:08:31.620: INFO: Pod "pod-26095820-54a9-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 18:08:31.625: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-26095820-54a9-11e9-871e-828ee0b576f8 container test-container: <nil>
STEP: delete the pod
Apr  1 18:08:31.652: INFO: Waiting for pod pod-26095820-54a9-11e9-871e-828ee0b576f8 to disappear
Apr  1 18:08:31.656: INFO: Pod pod-26095820-54a9-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:08:31.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9085" for this suite.
Apr  1 18:08:37.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:08:37.814: INFO: namespace emptydir-9085 deletion completed in 6.146038379s

• [SLOW TEST:10.271 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:08:37.815: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's args
Apr  1 18:08:37.859: INFO: Waiting up to 5m0s for pod "var-expansion-2c275b11-54a9-11e9-871e-828ee0b576f8" in namespace "var-expansion-7737" to be "success or failure"
Apr  1 18:08:37.865: INFO: Pod "var-expansion-2c275b11-54a9-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.091194ms
Apr  1 18:08:39.871: INFO: Pod "var-expansion-2c275b11-54a9-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011614486s
Apr  1 18:08:42.037: INFO: Pod "var-expansion-2c275b11-54a9-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.177760679s
STEP: Saw pod success
Apr  1 18:08:42.037: INFO: Pod "var-expansion-2c275b11-54a9-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 18:08:42.042: INFO: Trying to get logs from node ip-172-31-3-176 pod var-expansion-2c275b11-54a9-11e9-871e-828ee0b576f8 container dapi-container: <nil>
STEP: delete the pod
Apr  1 18:08:43.112: INFO: Waiting for pod var-expansion-2c275b11-54a9-11e9-871e-828ee0b576f8 to disappear
Apr  1 18:08:43.117: INFO: Pod var-expansion-2c275b11-54a9-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:08:43.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7737" for this suite.
Apr  1 18:08:49.138: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:08:49.335: INFO: namespace var-expansion-7737 deletion completed in 6.21409024s

• [SLOW TEST:11.521 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:08:49.335: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-353.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-353.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-353.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-353.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-353.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-353.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-353.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-353.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-353.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-353.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-353.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-353.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-353.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 106.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.106_udp@PTR;check="$$(dig +tcp +noall +answer +search 106.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.106_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-353.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-353.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-353.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-353.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-353.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-353.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-353.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-353.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-353.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-353.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-353.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-353.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-353.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 106.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.106_udp@PTR;check="$$(dig +tcp +noall +answer +search 106.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.106_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr  1 18:08:53.430: INFO: Unable to read wheezy_udp@dns-test-service.dns-353.svc.cluster.local from pod dns-353/dns-test-3308920b-54a9-11e9-871e-828ee0b576f8: the server could not find the requested resource (get pods dns-test-3308920b-54a9-11e9-871e-828ee0b576f8)
Apr  1 18:08:53.434: INFO: Unable to read wheezy_tcp@dns-test-service.dns-353.svc.cluster.local from pod dns-353/dns-test-3308920b-54a9-11e9-871e-828ee0b576f8: the server could not find the requested resource (get pods dns-test-3308920b-54a9-11e9-871e-828ee0b576f8)
Apr  1 18:08:53.439: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-353.svc.cluster.local from pod dns-353/dns-test-3308920b-54a9-11e9-871e-828ee0b576f8: the server could not find the requested resource (get pods dns-test-3308920b-54a9-11e9-871e-828ee0b576f8)
Apr  1 18:08:53.443: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-353.svc.cluster.local from pod dns-353/dns-test-3308920b-54a9-11e9-871e-828ee0b576f8: the server could not find the requested resource (get pods dns-test-3308920b-54a9-11e9-871e-828ee0b576f8)
Apr  1 18:08:53.503: INFO: Unable to read jessie_udp@dns-test-service.dns-353.svc.cluster.local from pod dns-353/dns-test-3308920b-54a9-11e9-871e-828ee0b576f8: the server could not find the requested resource (get pods dns-test-3308920b-54a9-11e9-871e-828ee0b576f8)
Apr  1 18:08:53.510: INFO: Unable to read jessie_tcp@dns-test-service.dns-353.svc.cluster.local from pod dns-353/dns-test-3308920b-54a9-11e9-871e-828ee0b576f8: the server could not find the requested resource (get pods dns-test-3308920b-54a9-11e9-871e-828ee0b576f8)
Apr  1 18:08:53.524: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-353.svc.cluster.local from pod dns-353/dns-test-3308920b-54a9-11e9-871e-828ee0b576f8: the server could not find the requested resource (get pods dns-test-3308920b-54a9-11e9-871e-828ee0b576f8)
Apr  1 18:08:53.532: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-353.svc.cluster.local from pod dns-353/dns-test-3308920b-54a9-11e9-871e-828ee0b576f8: the server could not find the requested resource (get pods dns-test-3308920b-54a9-11e9-871e-828ee0b576f8)
Apr  1 18:08:53.575: INFO: Lookups using dns-353/dns-test-3308920b-54a9-11e9-871e-828ee0b576f8 failed for: [wheezy_udp@dns-test-service.dns-353.svc.cluster.local wheezy_tcp@dns-test-service.dns-353.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-353.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-353.svc.cluster.local jessie_udp@dns-test-service.dns-353.svc.cluster.local jessie_tcp@dns-test-service.dns-353.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-353.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-353.svc.cluster.local]

Apr  1 18:08:58.657: INFO: DNS probes using dns-353/dns-test-3308920b-54a9-11e9-871e-828ee0b576f8 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:08:58.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-353" for this suite.
Apr  1 18:09:04.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:09:04.880: INFO: namespace dns-353 deletion completed in 6.153741569s

• [SLOW TEST:15.544 seconds]
[sig-network] DNS
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:09:04.880: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-3c493de7-54a9-11e9-871e-828ee0b576f8
STEP: Creating a pod to test consume secrets
Apr  1 18:09:04.932: INFO: Waiting up to 5m0s for pod "pod-secrets-3c4aa098-54a9-11e9-871e-828ee0b576f8" in namespace "secrets-6102" to be "success or failure"
Apr  1 18:09:04.938: INFO: Pod "pod-secrets-3c4aa098-54a9-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.352143ms
Apr  1 18:09:06.943: INFO: Pod "pod-secrets-3c4aa098-54a9-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010914678s
STEP: Saw pod success
Apr  1 18:09:06.943: INFO: Pod "pod-secrets-3c4aa098-54a9-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 18:09:06.947: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-secrets-3c4aa098-54a9-11e9-871e-828ee0b576f8 container secret-volume-test: <nil>
STEP: delete the pod
Apr  1 18:09:06.970: INFO: Waiting for pod pod-secrets-3c4aa098-54a9-11e9-871e-828ee0b576f8 to disappear
Apr  1 18:09:06.976: INFO: Pod pod-secrets-3c4aa098-54a9-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:09:06.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6102" for this suite.
Apr  1 18:09:13.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:09:13.173: INFO: namespace secrets-6102 deletion completed in 6.192787108s

• [SLOW TEST:8.293 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:09:13.174: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  1 18:09:13.256: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Apr  1 18:09:13.274: INFO: Number of nodes with available pods: 0
Apr  1 18:09:13.274: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Apr  1 18:09:13.300: INFO: Number of nodes with available pods: 0
Apr  1 18:09:13.300: INFO: Node ip-172-31-22-24 is running more than one daemon pod
Apr  1 18:09:14.304: INFO: Number of nodes with available pods: 0
Apr  1 18:09:14.304: INFO: Node ip-172-31-22-24 is running more than one daemon pod
Apr  1 18:09:15.305: INFO: Number of nodes with available pods: 1
Apr  1 18:09:15.305: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Apr  1 18:09:15.331: INFO: Number of nodes with available pods: 0
Apr  1 18:09:15.331: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Apr  1 18:09:15.349: INFO: Number of nodes with available pods: 0
Apr  1 18:09:15.349: INFO: Node ip-172-31-22-24 is running more than one daemon pod
Apr  1 18:09:16.355: INFO: Number of nodes with available pods: 0
Apr  1 18:09:16.355: INFO: Node ip-172-31-22-24 is running more than one daemon pod
Apr  1 18:09:17.354: INFO: Number of nodes with available pods: 0
Apr  1 18:09:17.354: INFO: Node ip-172-31-22-24 is running more than one daemon pod
Apr  1 18:09:18.354: INFO: Number of nodes with available pods: 0
Apr  1 18:09:18.354: INFO: Node ip-172-31-22-24 is running more than one daemon pod
Apr  1 18:09:19.355: INFO: Number of nodes with available pods: 0
Apr  1 18:09:19.355: INFO: Node ip-172-31-22-24 is running more than one daemon pod
Apr  1 18:09:20.357: INFO: Number of nodes with available pods: 0
Apr  1 18:09:20.357: INFO: Node ip-172-31-22-24 is running more than one daemon pod
Apr  1 18:09:21.355: INFO: Number of nodes with available pods: 1
Apr  1 18:09:21.355: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2822, will wait for the garbage collector to delete the pods
Apr  1 18:09:21.430: INFO: Deleting DaemonSet.extensions daemon-set took: 10.384748ms
Apr  1 18:09:21.831: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.262045ms
Apr  1 18:09:25.344: INFO: Number of nodes with available pods: 0
Apr  1 18:09:25.344: INFO: Number of running nodes: 0, number of available pods: 0
Apr  1 18:09:25.354: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2822/daemonsets","resourceVersion":"17525"},"items":null}

Apr  1 18:09:25.374: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2822/pods","resourceVersion":"17525"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:09:25.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2822" for this suite.
Apr  1 18:09:31.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:09:31.641: INFO: namespace daemonsets-2822 deletion completed in 6.192080068s

• [SLOW TEST:18.467 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:09:31.641: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Apr  1 18:09:31.694: INFO: Waiting up to 5m0s for pod "pod-4c3d57db-54a9-11e9-871e-828ee0b576f8" in namespace "emptydir-2953" to be "success or failure"
Apr  1 18:09:31.698: INFO: Pod "pod-4c3d57db-54a9-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.16441ms
Apr  1 18:09:33.714: INFO: Pod "pod-4c3d57db-54a9-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019994147s
Apr  1 18:09:35.722: INFO: Pod "pod-4c3d57db-54a9-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027620263s
STEP: Saw pod success
Apr  1 18:09:35.722: INFO: Pod "pod-4c3d57db-54a9-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 18:09:35.730: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-4c3d57db-54a9-11e9-871e-828ee0b576f8 container test-container: <nil>
STEP: delete the pod
Apr  1 18:09:35.773: INFO: Waiting for pod pod-4c3d57db-54a9-11e9-871e-828ee0b576f8 to disappear
Apr  1 18:09:35.780: INFO: Pod pod-4c3d57db-54a9-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:09:35.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2953" for this suite.
Apr  1 18:09:41.801: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:09:41.924: INFO: namespace emptydir-2953 deletion completed in 6.138920288s

• [SLOW TEST:10.282 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:09:41.924: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  1 18:09:41.959: INFO: Creating deployment "nginx-deployment"
Apr  1 18:09:41.967: INFO: Waiting for observed generation 1
Apr  1 18:09:44.517: INFO: Waiting for all required pods to come up
Apr  1 18:09:44.522: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Apr  1 18:09:46.533: INFO: Waiting for deployment "nginx-deployment" to complete
Apr  1 18:09:46.540: INFO: Updating deployment "nginx-deployment" with a non-existent image
Apr  1 18:09:46.553: INFO: Updating deployment nginx-deployment
Apr  1 18:09:46.553: INFO: Waiting for observed generation 2
Apr  1 18:09:48.564: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Apr  1 18:09:48.567: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Apr  1 18:09:48.573: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Apr  1 18:09:48.584: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Apr  1 18:09:48.584: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Apr  1 18:09:48.590: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Apr  1 18:09:48.597: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Apr  1 18:09:48.598: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Apr  1 18:09:48.608: INFO: Updating deployment nginx-deployment
Apr  1 18:09:48.608: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Apr  1 18:09:48.620: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Apr  1 18:09:50.639: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr  1 18:09:50.651: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-5763,SelfLink:/apis/apps/v1/namespaces/deployment-5763/deployments/nginx-deployment,UID:5261a8e2-54a9-11e9-9aab-028387864c62,ResourceVersion:17872,Generation:3,CreationTimestamp:2019-04-01 18:09:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-04-01 18:09:48 +0000 UTC 2019-04-01 18:09:48 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-04-01 18:09:48 +0000 UTC 2019-04-01 18:09:42 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-5f9595f595" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Apr  1 18:09:50.655: INFO: New ReplicaSet "nginx-deployment-5f9595f595" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595,GenerateName:,Namespace:deployment-5763,SelfLink:/apis/apps/v1/namespaces/deployment-5763/replicasets/nginx-deployment-5f9595f595,UID:551a584a-54a9-11e9-84d7-12a9dd9b0c8a,ResourceVersion:17867,Generation:3,CreationTimestamp:2019-04-01 18:09:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 5261a8e2-54a9-11e9-9aab-028387864c62 0xc00161d617 0xc00161d618}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr  1 18:09:50.655: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Apr  1 18:09:50.655: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8,GenerateName:,Namespace:deployment-5763,SelfLink:/apis/apps/v1/namespaces/deployment-5763/replicasets/nginx-deployment-6f478d8d8,UID:525e9f16-54a9-11e9-84d7-12a9dd9b0c8a,ResourceVersion:17861,Generation:3,CreationTimestamp:2019-04-01 18:09:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 5261a8e2-54a9-11e9-9aab-028387864c62 0xc00161d6f7 0xc00161d6f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Apr  1 18:09:50.661: INFO: Pod "nginx-deployment-5f9595f595-2qf6l" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-2qf6l,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-5763,SelfLink:/api/v1/namespaces/deployment-5763/pods/nginx-deployment-5f9595f595-2qf6l,UID:565ad89e-54a9-11e9-84d7-12a9dd9b0c8a,ResourceVersion:17880,Generation:0,CreationTimestamp:2019-04-01 18:09:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 551a584a-54a9-11e9-84d7-12a9dd9b0c8a 0xc00277d787 0xc00277d788}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9qsrv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9qsrv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9qsrv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-22-24,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00277d800} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00277d820}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC  }],Message:,Reason:,HostIP:172.31.22.24,PodIP:,StartTime:2019-04-01 18:09:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  1 18:09:50.661: INFO: Pod "nginx-deployment-5f9595f595-4jc5g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-4jc5g,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-5763,SelfLink:/api/v1/namespaces/deployment-5763/pods/nginx-deployment-5f9595f595-4jc5g,UID:551b65f4-54a9-11e9-84d7-12a9dd9b0c8a,ResourceVersion:17930,Generation:0,CreationTimestamp:2019-04-01 18:09:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 551a584a-54a9-11e9-84d7-12a9dd9b0c8a 0xc00277d8e0 0xc00277d8e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9qsrv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9qsrv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9qsrv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-3-176,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00277d960} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00277d980}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:46 +0000 UTC  }],Message:,Reason:,HostIP:172.31.3.176,PodIP:10.1.83.198,StartTime:2019-04-01 18:09:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  1 18:09:50.661: INFO: Pod "nginx-deployment-5f9595f595-5jnk7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-5jnk7,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-5763,SelfLink:/api/v1/namespaces/deployment-5763/pods/nginx-deployment-5f9595f595-5jnk7,UID:56586a7a-54a9-11e9-84d7-12a9dd9b0c8a,ResourceVersion:17869,Generation:0,CreationTimestamp:2019-04-01 18:09:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 551a584a-54a9-11e9-84d7-12a9dd9b0c8a 0xc00277da60 0xc00277da61}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9qsrv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9qsrv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9qsrv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-3-176,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00277dae0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00277db00}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC  }],Message:,Reason:,HostIP:172.31.3.176,PodIP:,StartTime:2019-04-01 18:09:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  1 18:09:50.661: INFO: Pod "nginx-deployment-5f9595f595-5nqqv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-5nqqv,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-5763,SelfLink:/api/v1/namespaces/deployment-5763/pods/nginx-deployment-5f9595f595-5nqqv,UID:552450c2-54a9-11e9-84d7-12a9dd9b0c8a,ResourceVersion:17942,Generation:0,CreationTimestamp:2019-04-01 18:09:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 551a584a-54a9-11e9-84d7-12a9dd9b0c8a 0xc00277dbc0 0xc00277dbc1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9qsrv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9qsrv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9qsrv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-3-176,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00277dc40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00277dc60}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:46 +0000 UTC  }],Message:,Reason:,HostIP:172.31.3.176,PodIP:10.1.83.199,StartTime:2019-04-01 18:09:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  1 18:09:50.662: INFO: Pod "nginx-deployment-5f9595f595-6m45t" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-6m45t,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-5763,SelfLink:/api/v1/namespaces/deployment-5763/pods/nginx-deployment-5f9595f595-6m45t,UID:551cfb0b-54a9-11e9-84d7-12a9dd9b0c8a,ResourceVersion:17941,Generation:0,CreationTimestamp:2019-04-01 18:09:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 551a584a-54a9-11e9-84d7-12a9dd9b0c8a 0xc00277dd40 0xc00277dd41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9qsrv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9qsrv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9qsrv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-75-215,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00277ddc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00277dde0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:46 +0000 UTC  }],Message:,Reason:,HostIP:172.31.75.215,PodIP:10.1.101.46,StartTime:2019-04-01 18:09:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ImagePullBackOff,Message:Back-off pulling image "nginx:404",} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  1 18:09:50.662: INFO: Pod "nginx-deployment-5f9595f595-d8kq7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-d8kq7,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-5763,SelfLink:/api/v1/namespaces/deployment-5763/pods/nginx-deployment-5f9595f595-d8kq7,UID:565b0953-54a9-11e9-84d7-12a9dd9b0c8a,ResourceVersion:17914,Generation:0,CreationTimestamp:2019-04-01 18:09:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 551a584a-54a9-11e9-84d7-12a9dd9b0c8a 0xc00277dec0 0xc00277dec1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9qsrv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9qsrv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9qsrv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-3-176,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00277df40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00277df60}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC  }],Message:,Reason:,HostIP:172.31.3.176,PodIP:,StartTime:2019-04-01 18:09:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  1 18:09:50.662: INFO: Pod "nginx-deployment-5f9595f595-fctkv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-fctkv,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-5763,SelfLink:/api/v1/namespaces/deployment-5763/pods/nginx-deployment-5f9595f595-fctkv,UID:5658810b-54a9-11e9-84d7-12a9dd9b0c8a,ResourceVersion:17889,Generation:0,CreationTimestamp:2019-04-01 18:09:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 551a584a-54a9-11e9-84d7-12a9dd9b0c8a 0xc002e44020 0xc002e44021}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9qsrv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9qsrv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9qsrv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-75-215,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e440a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e440c0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC  }],Message:,Reason:,HostIP:172.31.75.215,PodIP:,StartTime:2019-04-01 18:09:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  1 18:09:50.662: INFO: Pod "nginx-deployment-5f9595f595-fmqcs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-fmqcs,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-5763,SelfLink:/api/v1/namespaces/deployment-5763/pods/nginx-deployment-5f9595f595-fmqcs,UID:55257b89-54a9-11e9-84d7-12a9dd9b0c8a,ResourceVersion:17964,Generation:0,CreationTimestamp:2019-04-01 18:09:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 551a584a-54a9-11e9-84d7-12a9dd9b0c8a 0xc002e44180 0xc002e44181}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9qsrv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9qsrv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9qsrv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-75-215,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e44200} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e44220}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:46 +0000 UTC  }],Message:,Reason:,HostIP:172.31.75.215,PodIP:10.1.101.47,StartTime:2019-04-01 18:09:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  1 18:09:50.662: INFO: Pod "nginx-deployment-5f9595f595-j97c4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-j97c4,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-5763,SelfLink:/api/v1/namespaces/deployment-5763/pods/nginx-deployment-5f9595f595-j97c4,UID:565c32c2-54a9-11e9-84d7-12a9dd9b0c8a,ResourceVersion:17900,Generation:0,CreationTimestamp:2019-04-01 18:09:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 551a584a-54a9-11e9-84d7-12a9dd9b0c8a 0xc002e44300 0xc002e44301}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9qsrv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9qsrv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9qsrv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-22-24,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e44380} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e443a0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC  }],Message:,Reason:,HostIP:172.31.22.24,PodIP:,StartTime:2019-04-01 18:09:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  1 18:09:50.662: INFO: Pod "nginx-deployment-5f9595f595-k5sr7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-k5sr7,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-5763,SelfLink:/api/v1/namespaces/deployment-5763/pods/nginx-deployment-5f9595f595-k5sr7,UID:56562783-54a9-11e9-84d7-12a9dd9b0c8a,ResourceVersion:17950,Generation:0,CreationTimestamp:2019-04-01 18:09:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 551a584a-54a9-11e9-84d7-12a9dd9b0c8a 0xc002e44460 0xc002e44461}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9qsrv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9qsrv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9qsrv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-22-24,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e444e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e44500}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC  }],Message:,Reason:,HostIP:172.31.22.24,PodIP:10.1.81.66,StartTime:2019-04-01 18:09:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  1 18:09:50.663: INFO: Pod "nginx-deployment-5f9595f595-pkhzj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-pkhzj,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-5763,SelfLink:/api/v1/namespaces/deployment-5763/pods/nginx-deployment-5f9595f595-pkhzj,UID:565c1125-54a9-11e9-84d7-12a9dd9b0c8a,ResourceVersion:17928,Generation:0,CreationTimestamp:2019-04-01 18:09:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 551a584a-54a9-11e9-84d7-12a9dd9b0c8a 0xc002e445e0 0xc002e445e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9qsrv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9qsrv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9qsrv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-75-215,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e44670} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e446a0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC  }],Message:,Reason:,HostIP:172.31.75.215,PodIP:,StartTime:2019-04-01 18:09:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  1 18:09:50.663: INFO: Pod "nginx-deployment-5f9595f595-skbqs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-skbqs,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-5763,SelfLink:/api/v1/namespaces/deployment-5763/pods/nginx-deployment-5f9595f595-skbqs,UID:551cfcdb-54a9-11e9-84d7-12a9dd9b0c8a,ResourceVersion:17946,Generation:0,CreationTimestamp:2019-04-01 18:09:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 551a584a-54a9-11e9-84d7-12a9dd9b0c8a 0xc002e44770 0xc002e44771}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9qsrv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9qsrv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9qsrv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-22-24,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e447f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e44810}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:46 +0000 UTC  }],Message:,Reason:,HostIP:172.31.22.24,PodIP:10.1.81.65,StartTime:2019-04-01 18:09:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ImagePullBackOff,Message:Back-off pulling image "nginx:404",} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  1 18:09:50.663: INFO: Pod "nginx-deployment-5f9595f595-vzvpv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-vzvpv,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-5763,SelfLink:/api/v1/namespaces/deployment-5763/pods/nginx-deployment-5f9595f595-vzvpv,UID:565eba45-54a9-11e9-84d7-12a9dd9b0c8a,ResourceVersion:17921,Generation:0,CreationTimestamp:2019-04-01 18:09:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 551a584a-54a9-11e9-84d7-12a9dd9b0c8a 0xc002e448f0 0xc002e448f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9qsrv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9qsrv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9qsrv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-3-176,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e44980} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e449b0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC  }],Message:,Reason:,HostIP:172.31.3.176,PodIP:,StartTime:2019-04-01 18:09:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  1 18:09:50.663: INFO: Pod "nginx-deployment-6f478d8d8-458gs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-458gs,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5763,SelfLink:/api/v1/namespaces/deployment-5763/pods/nginx-deployment-6f478d8d8-458gs,UID:565a186c-54a9-11e9-84d7-12a9dd9b0c8a,ResourceVersion:17876,Generation:0,CreationTimestamp:2019-04-01 18:09:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 525e9f16-54a9-11e9-84d7-12a9dd9b0c8a 0xc002e44a90 0xc002e44a91}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9qsrv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9qsrv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9qsrv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-3-176,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e44b00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e44b20}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC  }],Message:,Reason:,HostIP:172.31.3.176,PodIP:,StartTime:2019-04-01 18:09:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  1 18:09:50.663: INFO: Pod "nginx-deployment-6f478d8d8-856l7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-856l7,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5763,SelfLink:/api/v1/namespaces/deployment-5763/pods/nginx-deployment-6f478d8d8-856l7,UID:56546c1c-54a9-11e9-84d7-12a9dd9b0c8a,ResourceVersion:17839,Generation:0,CreationTimestamp:2019-04-01 18:09:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 525e9f16-54a9-11e9-84d7-12a9dd9b0c8a 0xc002e44bd7 0xc002e44bd8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9qsrv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9qsrv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9qsrv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-75-215,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e44c50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e44c70}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC  }],Message:,Reason:,HostIP:172.31.75.215,PodIP:,StartTime:2019-04-01 18:09:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  1 18:09:50.663: INFO: Pod "nginx-deployment-6f478d8d8-b4s86" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-b4s86,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5763,SelfLink:/api/v1/namespaces/deployment-5763/pods/nginx-deployment-6f478d8d8-b4s86,UID:5655e219-54a9-11e9-84d7-12a9dd9b0c8a,ResourceVersion:17864,Generation:0,CreationTimestamp:2019-04-01 18:09:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 525e9f16-54a9-11e9-84d7-12a9dd9b0c8a 0xc002e44d27 0xc002e44d28}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9qsrv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9qsrv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9qsrv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-75-215,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e44da0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e44dc0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC  }],Message:,Reason:,HostIP:172.31.75.215,PodIP:,StartTime:2019-04-01 18:09:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  1 18:09:50.663: INFO: Pod "nginx-deployment-6f478d8d8-ctmnr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-ctmnr,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5763,SelfLink:/api/v1/namespaces/deployment-5763/pods/nginx-deployment-6f478d8d8-ctmnr,UID:52b7455a-54a9-11e9-84d7-12a9dd9b0c8a,ResourceVersion:17720,Generation:0,CreationTimestamp:2019-04-01 18:09:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 525e9f16-54a9-11e9-84d7-12a9dd9b0c8a 0xc002e44e77 0xc002e44e78}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9qsrv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9qsrv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9qsrv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-22-24,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e44ef0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e44f10}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:42 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:45 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:45 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:42 +0000 UTC  }],Message:,Reason:,HostIP:172.31.22.24,PodIP:10.1.81.63,StartTime:2019-04-01 18:09:42 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-01 18:09:44 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://d19e4db01e032f5837a0c12fd47440862067bba55462aa194e4d74c2d9c6eafd}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  1 18:09:50.663: INFO: Pod "nginx-deployment-6f478d8d8-cwdbr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-cwdbr,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5763,SelfLink:/api/v1/namespaces/deployment-5763/pods/nginx-deployment-6f478d8d8-cwdbr,UID:5659a332-54a9-11e9-84d7-12a9dd9b0c8a,ResourceVersion:17883,Generation:0,CreationTimestamp:2019-04-01 18:09:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 525e9f16-54a9-11e9-84d7-12a9dd9b0c8a 0xc002e44fd0 0xc002e44fd1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9qsrv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9qsrv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9qsrv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-3-176,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e45040} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e45060}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC  }],Message:,Reason:,HostIP:172.31.3.176,PodIP:,StartTime:2019-04-01 18:09:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  1 18:09:50.663: INFO: Pod "nginx-deployment-6f478d8d8-dvg2s" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-dvg2s,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5763,SelfLink:/api/v1/namespaces/deployment-5763/pods/nginx-deployment-6f478d8d8-dvg2s,UID:52b340c0-54a9-11e9-84d7-12a9dd9b0c8a,ResourceVersion:17684,Generation:0,CreationTimestamp:2019-04-01 18:09:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 525e9f16-54a9-11e9-84d7-12a9dd9b0c8a 0xc002e45117 0xc002e45118}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9qsrv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9qsrv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9qsrv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-75-215,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e45190} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e451b0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:42 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:44 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:44 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:42 +0000 UTC  }],Message:,Reason:,HostIP:172.31.75.215,PodIP:10.1.101.43,StartTime:2019-04-01 18:09:42 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-01 18:09:43 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://cae7f12c711ff3ab3b1147196b93649e8561415fbf63fdca15099866b24fe743}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  1 18:09:50.663: INFO: Pod "nginx-deployment-6f478d8d8-dxw7p" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-dxw7p,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5763,SelfLink:/api/v1/namespaces/deployment-5763/pods/nginx-deployment-6f478d8d8-dxw7p,UID:56572d3a-54a9-11e9-84d7-12a9dd9b0c8a,ResourceVersion:17843,Generation:0,CreationTimestamp:2019-04-01 18:09:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 525e9f16-54a9-11e9-84d7-12a9dd9b0c8a 0xc002e45270 0xc002e45271}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9qsrv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9qsrv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9qsrv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-3-176,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e452e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e45300}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC  }],Message:,Reason:,HostIP:172.31.3.176,PodIP:,StartTime:2019-04-01 18:09:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  1 18:09:50.663: INFO: Pod "nginx-deployment-6f478d8d8-fh5sb" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-fh5sb,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5763,SelfLink:/api/v1/namespaces/deployment-5763/pods/nginx-deployment-6f478d8d8-fh5sb,UID:52b4cb52-54a9-11e9-84d7-12a9dd9b0c8a,ResourceVersion:17708,Generation:0,CreationTimestamp:2019-04-01 18:09:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 525e9f16-54a9-11e9-84d7-12a9dd9b0c8a 0xc002e453b7 0xc002e453b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9qsrv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9qsrv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9qsrv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-3-176,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e45430} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e45450}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:42 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:45 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:45 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:42 +0000 UTC  }],Message:,Reason:,HostIP:172.31.3.176,PodIP:10.1.83.197,StartTime:2019-04-01 18:09:42 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-01 18:09:44 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://a832affa9cf7e43cd419e6dadb08d26762dc8b5f2ef852b22d111125b2972ba3}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  1 18:09:50.664: INFO: Pod "nginx-deployment-6f478d8d8-gn2v9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-gn2v9,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5763,SelfLink:/api/v1/namespaces/deployment-5763/pods/nginx-deployment-6f478d8d8-gn2v9,UID:52b354ac-54a9-11e9-84d7-12a9dd9b0c8a,ResourceVersion:17689,Generation:0,CreationTimestamp:2019-04-01 18:09:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 525e9f16-54a9-11e9-84d7-12a9dd9b0c8a 0xc002e45510 0xc002e45511}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9qsrv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9qsrv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9qsrv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-22-24,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e45580} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e455a0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:42 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:44 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:44 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:42 +0000 UTC  }],Message:,Reason:,HostIP:172.31.22.24,PodIP:10.1.81.61,StartTime:2019-04-01 18:09:42 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-01 18:09:43 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://35c01a9f25aca2b07e6381ddb88b636534891e8bd811cea2c3a63b8a15722733}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  1 18:09:50.664: INFO: Pod "nginx-deployment-6f478d8d8-lvkc5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-lvkc5,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5763,SelfLink:/api/v1/namespaces/deployment-5763/pods/nginx-deployment-6f478d8d8-lvkc5,UID:52b4e704-54a9-11e9-84d7-12a9dd9b0c8a,ResourceVersion:17692,Generation:0,CreationTimestamp:2019-04-01 18:09:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 525e9f16-54a9-11e9-84d7-12a9dd9b0c8a 0xc002e45660 0xc002e45661}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9qsrv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9qsrv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9qsrv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-22-24,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e456d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e456f0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:42 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:44 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:44 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:42 +0000 UTC  }],Message:,Reason:,HostIP:172.31.22.24,PodIP:10.1.81.62,StartTime:2019-04-01 18:09:42 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-01 18:09:44 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://f7565b182f979e49f62420118699a27d64bc82398072236616ec9cce740b4758}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  1 18:09:50.664: INFO: Pod "nginx-deployment-6f478d8d8-np55s" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-np55s,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5763,SelfLink:/api/v1/namespaces/deployment-5763/pods/nginx-deployment-6f478d8d8-np55s,UID:5659fda0-54a9-11e9-84d7-12a9dd9b0c8a,ResourceVersion:17912,Generation:0,CreationTimestamp:2019-04-01 18:09:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 525e9f16-54a9-11e9-84d7-12a9dd9b0c8a 0xc002e457b0 0xc002e457b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9qsrv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9qsrv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9qsrv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-75-215,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e45820} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e45840}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC  }],Message:,Reason:,HostIP:172.31.75.215,PodIP:,StartTime:2019-04-01 18:09:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  1 18:09:50.664: INFO: Pod "nginx-deployment-6f478d8d8-q2gtv" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-q2gtv,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5763,SelfLink:/api/v1/namespaces/deployment-5763/pods/nginx-deployment-6f478d8d8-q2gtv,UID:52b784c4-54a9-11e9-84d7-12a9dd9b0c8a,ResourceVersion:17723,Generation:0,CreationTimestamp:2019-04-01 18:09:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 525e9f16-54a9-11e9-84d7-12a9dd9b0c8a 0xc002e458f7 0xc002e458f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9qsrv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9qsrv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9qsrv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-22-24,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e45970} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e45990}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:42 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:45 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:45 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:42 +0000 UTC  }],Message:,Reason:,HostIP:172.31.22.24,PodIP:10.1.81.64,StartTime:2019-04-01 18:09:42 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-01 18:09:44 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://1d0ac170bd58d31205f5ce683f438bfc7c436caca0ce615a6ec47c50bc50a5a7}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  1 18:09:50.664: INFO: Pod "nginx-deployment-6f478d8d8-sz6x9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-sz6x9,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5763,SelfLink:/api/v1/namespaces/deployment-5763/pods/nginx-deployment-6f478d8d8-sz6x9,UID:52b4f284-54a9-11e9-84d7-12a9dd9b0c8a,ResourceVersion:17711,Generation:0,CreationTimestamp:2019-04-01 18:09:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 525e9f16-54a9-11e9-84d7-12a9dd9b0c8a 0xc002e45a50 0xc002e45a51}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9qsrv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9qsrv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9qsrv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-3-176,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e45ac0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e45ae0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:42 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:45 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:45 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:42 +0000 UTC  }],Message:,Reason:,HostIP:172.31.3.176,PodIP:10.1.83.196,StartTime:2019-04-01 18:09:42 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-01 18:09:44 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://b6efdcb0e155e31bc634f39ac52d7b008ce5d517ec75a54cab97ef5775aaa370}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  1 18:09:50.665: INFO: Pod "nginx-deployment-6f478d8d8-t5rxn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-t5rxn,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5763,SelfLink:/api/v1/namespaces/deployment-5763/pods/nginx-deployment-6f478d8d8-t5rxn,UID:56579f23-54a9-11e9-84d7-12a9dd9b0c8a,ResourceVersion:17878,Generation:0,CreationTimestamp:2019-04-01 18:09:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 525e9f16-54a9-11e9-84d7-12a9dd9b0c8a 0xc002e45ba0 0xc002e45ba1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9qsrv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9qsrv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9qsrv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-75-215,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e45c10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e45c30}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC  }],Message:,Reason:,HostIP:172.31.75.215,PodIP:,StartTime:2019-04-01 18:09:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  1 18:09:50.665: INFO: Pod "nginx-deployment-6f478d8d8-tjbtc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-tjbtc,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5763,SelfLink:/api/v1/namespaces/deployment-5763/pods/nginx-deployment-6f478d8d8-tjbtc,UID:52b1e7a6-54a9-11e9-84d7-12a9dd9b0c8a,ResourceVersion:17705,Generation:0,CreationTimestamp:2019-04-01 18:09:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 525e9f16-54a9-11e9-84d7-12a9dd9b0c8a 0xc002e45ce7 0xc002e45ce8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9qsrv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9qsrv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9qsrv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-3-176,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e45d60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e45d80}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:42 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:45 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:45 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:42 +0000 UTC  }],Message:,Reason:,HostIP:172.31.3.176,PodIP:10.1.83.195,StartTime:2019-04-01 18:09:42 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-01 18:09:44 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://945b481e17ae633e697a0f5c954f103fb99bb43a379396dacde565dd1e66c146}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  1 18:09:50.665: INFO: Pod "nginx-deployment-6f478d8d8-tn245" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-tn245,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5763,SelfLink:/api/v1/namespaces/deployment-5763/pods/nginx-deployment-6f478d8d8-tn245,UID:56557562-54a9-11e9-84d7-12a9dd9b0c8a,ResourceVersion:17871,Generation:0,CreationTimestamp:2019-04-01 18:09:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 525e9f16-54a9-11e9-84d7-12a9dd9b0c8a 0xc002e45e40 0xc002e45e41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9qsrv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9qsrv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9qsrv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-75-215,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e45eb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e45ed0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC  }],Message:,Reason:,HostIP:172.31.75.215,PodIP:,StartTime:2019-04-01 18:09:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  1 18:09:50.665: INFO: Pod "nginx-deployment-6f478d8d8-v2jdp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-v2jdp,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5763,SelfLink:/api/v1/namespaces/deployment-5763/pods/nginx-deployment-6f478d8d8-v2jdp,UID:5659e600-54a9-11e9-84d7-12a9dd9b0c8a,ResourceVersion:17870,Generation:0,CreationTimestamp:2019-04-01 18:09:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 525e9f16-54a9-11e9-84d7-12a9dd9b0c8a 0xc002e45f87 0xc002e45f88}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9qsrv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9qsrv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9qsrv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-22-24,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0032e8000} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0032e8020}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC  }],Message:,Reason:,HostIP:172.31.22.24,PodIP:,StartTime:2019-04-01 18:09:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  1 18:09:50.665: INFO: Pod "nginx-deployment-6f478d8d8-v5xdx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-v5xdx,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5763,SelfLink:/api/v1/namespaces/deployment-5763/pods/nginx-deployment-6f478d8d8-v5xdx,UID:565a46d4-54a9-11e9-84d7-12a9dd9b0c8a,ResourceVersion:17920,Generation:0,CreationTimestamp:2019-04-01 18:09:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 525e9f16-54a9-11e9-84d7-12a9dd9b0c8a 0xc0032e80d7 0xc0032e80d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9qsrv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9qsrv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9qsrv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-75-215,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0032e8150} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0032e8170}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC  }],Message:,Reason:,HostIP:172.31.75.215,PodIP:,StartTime:2019-04-01 18:09:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  1 18:09:50.665: INFO: Pod "nginx-deployment-6f478d8d8-v9vqf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-v9vqf,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5763,SelfLink:/api/v1/namespaces/deployment-5763/pods/nginx-deployment-6f478d8d8-v9vqf,UID:5657ba65-54a9-11e9-84d7-12a9dd9b0c8a,ResourceVersion:17855,Generation:0,CreationTimestamp:2019-04-01 18:09:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 525e9f16-54a9-11e9-84d7-12a9dd9b0c8a 0xc0032e8227 0xc0032e8228}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9qsrv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9qsrv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9qsrv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-22-24,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0032e82a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0032e82c0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC  }],Message:,Reason:,HostIP:172.31.22.24,PodIP:,StartTime:2019-04-01 18:09:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  1 18:09:50.665: INFO: Pod "nginx-deployment-6f478d8d8-wxfdh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-wxfdh,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5763,SelfLink:/api/v1/namespaces/deployment-5763/pods/nginx-deployment-6f478d8d8-wxfdh,UID:56575344-54a9-11e9-84d7-12a9dd9b0c8a,ResourceVersion:17859,Generation:0,CreationTimestamp:2019-04-01 18:09:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 525e9f16-54a9-11e9-84d7-12a9dd9b0c8a 0xc0032e8377 0xc0032e8378}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9qsrv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9qsrv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9qsrv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-3-176,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0032e83f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0032e8410}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:09:48 +0000 UTC  }],Message:,Reason:,HostIP:172.31.3.176,PodIP:,StartTime:2019-04-01 18:09:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:09:50.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5763" for this suite.
Apr  1 18:09:58.707: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:09:58.933: INFO: namespace deployment-5763 deletion completed in 8.2597404s

• [SLOW TEST:17.009 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:09:58.933: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-5c829c18-54a9-11e9-871e-828ee0b576f8
STEP: Creating a pod to test consume configMaps
Apr  1 18:09:58.993: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5c83cb95-54a9-11e9-871e-828ee0b576f8" in namespace "projected-8741" to be "success or failure"
Apr  1 18:09:58.998: INFO: Pod "pod-projected-configmaps-5c83cb95-54a9-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.974879ms
Apr  1 18:10:01.006: INFO: Pod "pod-projected-configmaps-5c83cb95-54a9-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012997406s
Apr  1 18:10:03.011: INFO: Pod "pod-projected-configmaps-5c83cb95-54a9-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01781791s
STEP: Saw pod success
Apr  1 18:10:03.011: INFO: Pod "pod-projected-configmaps-5c83cb95-54a9-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 18:10:03.021: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-projected-configmaps-5c83cb95-54a9-11e9-871e-828ee0b576f8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr  1 18:10:03.048: INFO: Waiting for pod pod-projected-configmaps-5c83cb95-54a9-11e9-871e-828ee0b576f8 to disappear
Apr  1 18:10:03.052: INFO: Pod pod-projected-configmaps-5c83cb95-54a9-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:10:03.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8741" for this suite.
Apr  1 18:10:09.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:10:09.329: INFO: namespace projected-8741 deletion completed in 6.269212911s

• [SLOW TEST:10.396 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:10:09.329: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating api versions
Apr  1 18:10:09.376: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 api-versions'
Apr  1 18:10:09.977: INFO: stderr: ""
Apr  1 18:10:09.977: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:10:09.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4837" for this suite.
Apr  1 18:10:16.003: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:10:16.169: INFO: namespace kubectl-4837 deletion completed in 6.186637463s

• [SLOW TEST:6.840 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:10:16.169: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Apr  1 18:10:16.224: INFO: Pod name pod-release: Found 0 pods out of 1
Apr  1 18:10:21.232: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:10:22.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6575" for this suite.
Apr  1 18:10:28.279: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:10:28.395: INFO: namespace replication-controller-6575 deletion completed in 6.129606741s

• [SLOW TEST:12.226 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:10:28.395: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on node default medium
Apr  1 18:10:28.441: INFO: Waiting up to 5m0s for pod "pod-6e106ff9-54a9-11e9-871e-828ee0b576f8" in namespace "emptydir-4130" to be "success or failure"
Apr  1 18:10:28.444: INFO: Pod "pod-6e106ff9-54a9-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.469424ms
Apr  1 18:10:30.449: INFO: Pod "pod-6e106ff9-54a9-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008656884s
Apr  1 18:10:32.456: INFO: Pod "pod-6e106ff9-54a9-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015576177s
STEP: Saw pod success
Apr  1 18:10:32.456: INFO: Pod "pod-6e106ff9-54a9-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 18:10:32.460: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-6e106ff9-54a9-11e9-871e-828ee0b576f8 container test-container: <nil>
STEP: delete the pod
Apr  1 18:10:32.482: INFO: Waiting for pod pod-6e106ff9-54a9-11e9-871e-828ee0b576f8 to disappear
Apr  1 18:10:32.486: INFO: Pod pod-6e106ff9-54a9-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:10:32.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4130" for this suite.
Apr  1 18:10:38.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:10:38.623: INFO: namespace emptydir-4130 deletion completed in 6.132802978s

• [SLOW TEST:10.228 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:10:38.624: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-9xhmw in namespace proxy-9951
I0401 18:10:38.685380      16 runners.go:184] Created replication controller with name: proxy-service-9xhmw, namespace: proxy-9951, replica count: 1
I0401 18:10:39.735737      16 runners.go:184] proxy-service-9xhmw Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0401 18:10:40.735918      16 runners.go:184] proxy-service-9xhmw Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0401 18:10:41.736132      16 runners.go:184] proxy-service-9xhmw Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0401 18:10:42.736380      16 runners.go:184] proxy-service-9xhmw Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0401 18:10:43.736571      16 runners.go:184] proxy-service-9xhmw Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr  1 18:10:43.740: INFO: setup took 5.078005014s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Apr  1 18:10:43.745: INFO: (0) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:162/proxy/: bar (200; 4.528148ms)
Apr  1 18:10:43.747: INFO: (0) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:160/proxy/: foo (200; 6.552459ms)
Apr  1 18:10:43.747: INFO: (0) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:1080/proxy/rewriteme">... (200; 7.133971ms)
Apr  1 18:10:43.748: INFO: (0) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj/proxy/rewriteme">test</a> (200; 7.184519ms)
Apr  1 18:10:43.748: INFO: (0) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:160/proxy/: foo (200; 7.769343ms)
Apr  1 18:10:43.752: INFO: (0) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:162/proxy/: bar (200; 11.486847ms)
Apr  1 18:10:43.753: INFO: (0) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:1080/proxy/rewriteme">test<... (200; 12.946275ms)
Apr  1 18:10:43.753: INFO: (0) /api/v1/namespaces/proxy-9951/services/proxy-service-9xhmw:portname2/proxy/: bar (200; 13.024051ms)
Apr  1 18:10:43.753: INFO: (0) /api/v1/namespaces/proxy-9951/services/http:proxy-service-9xhmw:portname2/proxy/: bar (200; 13.081473ms)
Apr  1 18:10:43.753: INFO: (0) /api/v1/namespaces/proxy-9951/services/proxy-service-9xhmw:portname1/proxy/: foo (200; 13.14162ms)
Apr  1 18:10:43.753: INFO: (0) /api/v1/namespaces/proxy-9951/services/http:proxy-service-9xhmw:portname1/proxy/: foo (200; 13.026799ms)
Apr  1 18:10:43.754: INFO: (0) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:460/proxy/: tls baz (200; 14.245701ms)
Apr  1 18:10:43.755: INFO: (0) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:462/proxy/: tls qux (200; 14.365887ms)
Apr  1 18:10:43.757: INFO: (0) /api/v1/namespaces/proxy-9951/services/https:proxy-service-9xhmw:tlsportname2/proxy/: tls qux (200; 16.730605ms)
Apr  1 18:10:43.758: INFO: (0) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:443/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:443/proxy/tlsrewritem... (200; 18.009291ms)
Apr  1 18:10:43.759: INFO: (0) /api/v1/namespaces/proxy-9951/services/https:proxy-service-9xhmw:tlsportname1/proxy/: tls baz (200; 18.259607ms)
Apr  1 18:10:43.764: INFO: (1) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:460/proxy/: tls baz (200; 5.324599ms)
Apr  1 18:10:43.765: INFO: (1) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:443/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:443/proxy/tlsrewritem... (200; 6.114753ms)
Apr  1 18:10:43.765: INFO: (1) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:162/proxy/: bar (200; 6.551189ms)
Apr  1 18:10:43.765: INFO: (1) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj/proxy/rewriteme">test</a> (200; 6.498267ms)
Apr  1 18:10:43.766: INFO: (1) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:160/proxy/: foo (200; 6.496308ms)
Apr  1 18:10:43.766: INFO: (1) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:160/proxy/: foo (200; 6.653302ms)
Apr  1 18:10:43.766: INFO: (1) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:162/proxy/: bar (200; 7.38605ms)
Apr  1 18:10:43.767: INFO: (1) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:1080/proxy/rewriteme">... (200; 7.640315ms)
Apr  1 18:10:43.767: INFO: (1) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:462/proxy/: tls qux (200; 7.767161ms)
Apr  1 18:10:43.767: INFO: (1) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:1080/proxy/rewriteme">test<... (200; 8.26191ms)
Apr  1 18:10:43.768: INFO: (1) /api/v1/namespaces/proxy-9951/services/https:proxy-service-9xhmw:tlsportname2/proxy/: tls qux (200; 8.984116ms)
Apr  1 18:10:43.770: INFO: (1) /api/v1/namespaces/proxy-9951/services/http:proxy-service-9xhmw:portname1/proxy/: foo (200; 11.145553ms)
Apr  1 18:10:43.770: INFO: (1) /api/v1/namespaces/proxy-9951/services/proxy-service-9xhmw:portname2/proxy/: bar (200; 10.992978ms)
Apr  1 18:10:43.770: INFO: (1) /api/v1/namespaces/proxy-9951/services/https:proxy-service-9xhmw:tlsportname1/proxy/: tls baz (200; 11.517013ms)
Apr  1 18:10:43.770: INFO: (1) /api/v1/namespaces/proxy-9951/services/proxy-service-9xhmw:portname1/proxy/: foo (200; 11.426634ms)
Apr  1 18:10:43.771: INFO: (1) /api/v1/namespaces/proxy-9951/services/http:proxy-service-9xhmw:portname2/proxy/: bar (200; 11.600435ms)
Apr  1 18:10:43.775: INFO: (2) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:162/proxy/: bar (200; 4.113463ms)
Apr  1 18:10:43.776: INFO: (2) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:1080/proxy/rewriteme">test<... (200; 5.316496ms)
Apr  1 18:10:43.776: INFO: (2) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:160/proxy/: foo (200; 5.510055ms)
Apr  1 18:10:43.777: INFO: (2) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:462/proxy/: tls qux (200; 6.240454ms)
Apr  1 18:10:43.779: INFO: (2) /api/v1/namespaces/proxy-9951/services/https:proxy-service-9xhmw:tlsportname2/proxy/: tls qux (200; 8.344786ms)
Apr  1 18:10:43.779: INFO: (2) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:162/proxy/: bar (200; 8.235428ms)
Apr  1 18:10:43.780: INFO: (2) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:1080/proxy/rewriteme">... (200; 9.031226ms)
Apr  1 18:10:43.780: INFO: (2) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:460/proxy/: tls baz (200; 9.560712ms)
Apr  1 18:10:43.782: INFO: (2) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:160/proxy/: foo (200; 10.856189ms)
Apr  1 18:10:43.782: INFO: (2) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj/proxy/rewriteme">test</a> (200; 11.060842ms)
Apr  1 18:10:43.782: INFO: (2) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:443/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:443/proxy/tlsrewritem... (200; 11.416046ms)
Apr  1 18:10:43.782: INFO: (2) /api/v1/namespaces/proxy-9951/services/http:proxy-service-9xhmw:portname2/proxy/: bar (200; 11.43797ms)
Apr  1 18:10:43.782: INFO: (2) /api/v1/namespaces/proxy-9951/services/https:proxy-service-9xhmw:tlsportname1/proxy/: tls baz (200; 11.51808ms)
Apr  1 18:10:43.782: INFO: (2) /api/v1/namespaces/proxy-9951/services/proxy-service-9xhmw:portname2/proxy/: bar (200; 11.768891ms)
Apr  1 18:10:43.783: INFO: (2) /api/v1/namespaces/proxy-9951/services/proxy-service-9xhmw:portname1/proxy/: foo (200; 11.847713ms)
Apr  1 18:10:43.783: INFO: (2) /api/v1/namespaces/proxy-9951/services/http:proxy-service-9xhmw:portname1/proxy/: foo (200; 11.814328ms)
Apr  1 18:10:43.788: INFO: (3) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:162/proxy/: bar (200; 5.602951ms)
Apr  1 18:10:43.788: INFO: (3) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:460/proxy/: tls baz (200; 5.911079ms)
Apr  1 18:10:43.790: INFO: (3) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:162/proxy/: bar (200; 7.014049ms)
Apr  1 18:10:43.792: INFO: (3) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:160/proxy/: foo (200; 8.29906ms)
Apr  1 18:10:43.792: INFO: (3) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:443/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:443/proxy/tlsrewritem... (200; 9.219847ms)
Apr  1 18:10:43.792: INFO: (3) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:1080/proxy/rewriteme">... (200; 9.214366ms)
Apr  1 18:10:43.793: INFO: (3) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:160/proxy/: foo (200; 9.405106ms)
Apr  1 18:10:43.793: INFO: (3) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:462/proxy/: tls qux (200; 9.891792ms)
Apr  1 18:10:43.793: INFO: (3) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj/proxy/rewriteme">test</a> (200; 9.847301ms)
Apr  1 18:10:43.793: INFO: (3) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:1080/proxy/rewriteme">test<... (200; 10.155981ms)
Apr  1 18:10:43.795: INFO: (3) /api/v1/namespaces/proxy-9951/services/http:proxy-service-9xhmw:portname1/proxy/: foo (200; 11.889688ms)
Apr  1 18:10:43.795: INFO: (3) /api/v1/namespaces/proxy-9951/services/https:proxy-service-9xhmw:tlsportname2/proxy/: tls qux (200; 11.883652ms)
Apr  1 18:10:43.795: INFO: (3) /api/v1/namespaces/proxy-9951/services/http:proxy-service-9xhmw:portname2/proxy/: bar (200; 12.074349ms)
Apr  1 18:10:43.798: INFO: (3) /api/v1/namespaces/proxy-9951/services/proxy-service-9xhmw:portname1/proxy/: foo (200; 14.688975ms)
Apr  1 18:10:43.798: INFO: (3) /api/v1/namespaces/proxy-9951/services/https:proxy-service-9xhmw:tlsportname1/proxy/: tls baz (200; 15.099728ms)
Apr  1 18:10:43.798: INFO: (3) /api/v1/namespaces/proxy-9951/services/proxy-service-9xhmw:portname2/proxy/: bar (200; 15.266442ms)
Apr  1 18:10:43.804: INFO: (4) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:1080/proxy/rewriteme">test<... (200; 5.703173ms)
Apr  1 18:10:43.804: INFO: (4) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:162/proxy/: bar (200; 5.911647ms)
Apr  1 18:10:43.805: INFO: (4) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:1080/proxy/rewriteme">... (200; 6.928069ms)
Apr  1 18:10:43.805: INFO: (4) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:462/proxy/: tls qux (200; 7.110058ms)
Apr  1 18:10:43.805: INFO: (4) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:443/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:443/proxy/tlsrewritem... (200; 7.018348ms)
Apr  1 18:10:43.806: INFO: (4) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:460/proxy/: tls baz (200; 7.81042ms)
Apr  1 18:10:43.806: INFO: (4) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:160/proxy/: foo (200; 7.587797ms)
Apr  1 18:10:43.807: INFO: (4) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:162/proxy/: bar (200; 8.559489ms)
Apr  1 18:10:43.808: INFO: (4) /api/v1/namespaces/proxy-9951/services/https:proxy-service-9xhmw:tlsportname2/proxy/: tls qux (200; 9.326084ms)
Apr  1 18:10:43.808: INFO: (4) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:160/proxy/: foo (200; 9.320348ms)
Apr  1 18:10:43.808: INFO: (4) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj/proxy/rewriteme">test</a> (200; 9.396215ms)
Apr  1 18:10:43.808: INFO: (4) /api/v1/namespaces/proxy-9951/services/proxy-service-9xhmw:portname2/proxy/: bar (200; 9.972809ms)
Apr  1 18:10:43.809: INFO: (4) /api/v1/namespaces/proxy-9951/services/https:proxy-service-9xhmw:tlsportname1/proxy/: tls baz (200; 10.175256ms)
Apr  1 18:10:43.810: INFO: (4) /api/v1/namespaces/proxy-9951/services/http:proxy-service-9xhmw:portname1/proxy/: foo (200; 11.500389ms)
Apr  1 18:10:43.810: INFO: (4) /api/v1/namespaces/proxy-9951/services/http:proxy-service-9xhmw:portname2/proxy/: bar (200; 11.517771ms)
Apr  1 18:10:43.810: INFO: (4) /api/v1/namespaces/proxy-9951/services/proxy-service-9xhmw:portname1/proxy/: foo (200; 11.568276ms)
Apr  1 18:10:43.814: INFO: (5) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:462/proxy/: tls qux (200; 4.182034ms)
Apr  1 18:10:43.815: INFO: (5) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:443/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:443/proxy/tlsrewritem... (200; 5.36521ms)
Apr  1 18:10:43.816: INFO: (5) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj/proxy/rewriteme">test</a> (200; 5.453896ms)
Apr  1 18:10:43.817: INFO: (5) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:160/proxy/: foo (200; 7.096875ms)
Apr  1 18:10:43.818: INFO: (5) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:162/proxy/: bar (200; 7.406209ms)
Apr  1 18:10:43.818: INFO: (5) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:460/proxy/: tls baz (200; 8.111421ms)
Apr  1 18:10:43.818: INFO: (5) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:162/proxy/: bar (200; 8.122455ms)
Apr  1 18:10:43.818: INFO: (5) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:1080/proxy/rewriteme">test<... (200; 8.266692ms)
Apr  1 18:10:43.818: INFO: (5) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:160/proxy/: foo (200; 8.114464ms)
Apr  1 18:10:43.819: INFO: (5) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:1080/proxy/rewriteme">... (200; 8.553938ms)
Apr  1 18:10:43.819: INFO: (5) /api/v1/namespaces/proxy-9951/services/http:proxy-service-9xhmw:portname1/proxy/: foo (200; 8.927361ms)
Apr  1 18:10:43.821: INFO: (5) /api/v1/namespaces/proxy-9951/services/proxy-service-9xhmw:portname2/proxy/: bar (200; 10.433607ms)
Apr  1 18:10:43.821: INFO: (5) /api/v1/namespaces/proxy-9951/services/https:proxy-service-9xhmw:tlsportname2/proxy/: tls qux (200; 10.710763ms)
Apr  1 18:10:43.824: INFO: (5) /api/v1/namespaces/proxy-9951/services/proxy-service-9xhmw:portname1/proxy/: foo (200; 13.745983ms)
Apr  1 18:10:43.824: INFO: (5) /api/v1/namespaces/proxy-9951/services/https:proxy-service-9xhmw:tlsportname1/proxy/: tls baz (200; 14.147496ms)
Apr  1 18:10:43.824: INFO: (5) /api/v1/namespaces/proxy-9951/services/http:proxy-service-9xhmw:portname2/proxy/: bar (200; 14.24327ms)
Apr  1 18:10:43.830: INFO: (6) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:460/proxy/: tls baz (200; 5.850958ms)
Apr  1 18:10:43.833: INFO: (6) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:160/proxy/: foo (200; 8.62084ms)
Apr  1 18:10:43.835: INFO: (6) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:162/proxy/: bar (200; 10.09188ms)
Apr  1 18:10:43.835: INFO: (6) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:462/proxy/: tls qux (200; 10.07312ms)
Apr  1 18:10:43.835: INFO: (6) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:162/proxy/: bar (200; 10.170383ms)
Apr  1 18:10:43.835: INFO: (6) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:1080/proxy/rewriteme">... (200; 10.04998ms)
Apr  1 18:10:43.835: INFO: (6) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj/proxy/rewriteme">test</a> (200; 10.060157ms)
Apr  1 18:10:43.835: INFO: (6) /api/v1/namespaces/proxy-9951/services/http:proxy-service-9xhmw:portname1/proxy/: foo (200; 10.469371ms)
Apr  1 18:10:43.835: INFO: (6) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:1080/proxy/rewriteme">test<... (200; 10.912378ms)
Apr  1 18:10:43.835: INFO: (6) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:443/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:443/proxy/tlsrewritem... (200; 11.0303ms)
Apr  1 18:10:43.836: INFO: (6) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:160/proxy/: foo (200; 11.909103ms)
Apr  1 18:10:43.837: INFO: (6) /api/v1/namespaces/proxy-9951/services/https:proxy-service-9xhmw:tlsportname2/proxy/: tls qux (200; 12.457086ms)
Apr  1 18:10:43.837: INFO: (6) /api/v1/namespaces/proxy-9951/services/http:proxy-service-9xhmw:portname2/proxy/: bar (200; 13.010691ms)
Apr  1 18:10:43.838: INFO: (6) /api/v1/namespaces/proxy-9951/services/proxy-service-9xhmw:portname2/proxy/: bar (200; 13.020617ms)
Apr  1 18:10:43.838: INFO: (6) /api/v1/namespaces/proxy-9951/services/proxy-service-9xhmw:portname1/proxy/: foo (200; 13.639757ms)
Apr  1 18:10:43.838: INFO: (6) /api/v1/namespaces/proxy-9951/services/https:proxy-service-9xhmw:tlsportname1/proxy/: tls baz (200; 13.55761ms)
Apr  1 18:10:43.842: INFO: (7) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:162/proxy/: bar (200; 3.83313ms)
Apr  1 18:10:43.843: INFO: (7) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:462/proxy/: tls qux (200; 5.203102ms)
Apr  1 18:10:43.845: INFO: (7) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:1080/proxy/rewriteme">test<... (200; 7.119746ms)
Apr  1 18:10:43.846: INFO: (7) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:160/proxy/: foo (200; 7.20541ms)
Apr  1 18:10:43.847: INFO: (7) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:460/proxy/: tls baz (200; 8.36798ms)
Apr  1 18:10:43.847: INFO: (7) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:443/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:443/proxy/tlsrewritem... (200; 8.503048ms)
Apr  1 18:10:43.847: INFO: (7) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:160/proxy/: foo (200; 8.551367ms)
Apr  1 18:10:43.847: INFO: (7) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:162/proxy/: bar (200; 8.693059ms)
Apr  1 18:10:43.847: INFO: (7) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:1080/proxy/rewriteme">... (200; 8.62742ms)
Apr  1 18:10:43.847: INFO: (7) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj/proxy/rewriteme">test</a> (200; 8.85839ms)
Apr  1 18:10:43.848: INFO: (7) /api/v1/namespaces/proxy-9951/services/https:proxy-service-9xhmw:tlsportname2/proxy/: tls qux (200; 9.812153ms)
Apr  1 18:10:43.849: INFO: (7) /api/v1/namespaces/proxy-9951/services/http:proxy-service-9xhmw:portname1/proxy/: foo (200; 11.057764ms)
Apr  1 18:10:43.853: INFO: (7) /api/v1/namespaces/proxy-9951/services/http:proxy-service-9xhmw:portname2/proxy/: bar (200; 14.850409ms)
Apr  1 18:10:43.853: INFO: (7) /api/v1/namespaces/proxy-9951/services/proxy-service-9xhmw:portname2/proxy/: bar (200; 14.883098ms)
Apr  1 18:10:43.853: INFO: (7) /api/v1/namespaces/proxy-9951/services/proxy-service-9xhmw:portname1/proxy/: foo (200; 14.716725ms)
Apr  1 18:10:43.853: INFO: (7) /api/v1/namespaces/proxy-9951/services/https:proxy-service-9xhmw:tlsportname1/proxy/: tls baz (200; 15.0504ms)
Apr  1 18:10:43.858: INFO: (8) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj/proxy/rewriteme">test</a> (200; 4.786999ms)
Apr  1 18:10:43.861: INFO: (8) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:162/proxy/: bar (200; 7.525901ms)
Apr  1 18:10:43.863: INFO: (8) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:443/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:443/proxy/tlsrewritem... (200; 9.049108ms)
Apr  1 18:10:43.863: INFO: (8) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:162/proxy/: bar (200; 8.987726ms)
Apr  1 18:10:43.862: INFO: (8) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:460/proxy/: tls baz (200; 8.977534ms)
Apr  1 18:10:43.863: INFO: (8) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:1080/proxy/rewriteme">test<... (200; 9.49541ms)
Apr  1 18:10:43.863: INFO: (8) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:160/proxy/: foo (200; 9.414364ms)
Apr  1 18:10:43.863: INFO: (8) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:160/proxy/: foo (200; 9.384096ms)
Apr  1 18:10:43.863: INFO: (8) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:462/proxy/: tls qux (200; 9.592249ms)
Apr  1 18:10:43.863: INFO: (8) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:1080/proxy/rewriteme">... (200; 9.564524ms)
Apr  1 18:10:43.863: INFO: (8) /api/v1/namespaces/proxy-9951/services/proxy-service-9xhmw:portname2/proxy/: bar (200; 10.025273ms)
Apr  1 18:10:43.864: INFO: (8) /api/v1/namespaces/proxy-9951/services/http:proxy-service-9xhmw:portname2/proxy/: bar (200; 10.55822ms)
Apr  1 18:10:43.864: INFO: (8) /api/v1/namespaces/proxy-9951/services/http:proxy-service-9xhmw:portname1/proxy/: foo (200; 10.851225ms)
Apr  1 18:10:43.865: INFO: (8) /api/v1/namespaces/proxy-9951/services/https:proxy-service-9xhmw:tlsportname2/proxy/: tls qux (200; 11.130699ms)
Apr  1 18:10:43.865: INFO: (8) /api/v1/namespaces/proxy-9951/services/https:proxy-service-9xhmw:tlsportname1/proxy/: tls baz (200; 11.488828ms)
Apr  1 18:10:43.865: INFO: (8) /api/v1/namespaces/proxy-9951/services/proxy-service-9xhmw:portname1/proxy/: foo (200; 11.427131ms)
Apr  1 18:10:43.869: INFO: (9) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:443/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:443/proxy/tlsrewritem... (200; 4.377582ms)
Apr  1 18:10:43.871: INFO: (9) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj/proxy/rewriteme">test</a> (200; 5.601981ms)
Apr  1 18:10:43.871: INFO: (9) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:160/proxy/: foo (200; 5.858211ms)
Apr  1 18:10:43.871: INFO: (9) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:160/proxy/: foo (200; 5.848214ms)
Apr  1 18:10:43.872: INFO: (9) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:1080/proxy/rewriteme">... (200; 6.530394ms)
Apr  1 18:10:43.872: INFO: (9) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:460/proxy/: tls baz (200; 6.429082ms)
Apr  1 18:10:43.872: INFO: (9) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:1080/proxy/rewriteme">test<... (200; 6.688301ms)
Apr  1 18:10:43.873: INFO: (9) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:462/proxy/: tls qux (200; 7.497239ms)
Apr  1 18:10:43.873: INFO: (9) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:162/proxy/: bar (200; 7.495143ms)
Apr  1 18:10:43.873: INFO: (9) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:162/proxy/: bar (200; 7.795513ms)
Apr  1 18:10:43.875: INFO: (9) /api/v1/namespaces/proxy-9951/services/http:proxy-service-9xhmw:portname2/proxy/: bar (200; 10.126748ms)
Apr  1 18:10:43.877: INFO: (9) /api/v1/namespaces/proxy-9951/services/https:proxy-service-9xhmw:tlsportname2/proxy/: tls qux (200; 11.459139ms)
Apr  1 18:10:43.877: INFO: (9) /api/v1/namespaces/proxy-9951/services/proxy-service-9xhmw:portname1/proxy/: foo (200; 11.833645ms)
Apr  1 18:10:43.877: INFO: (9) /api/v1/namespaces/proxy-9951/services/https:proxy-service-9xhmw:tlsportname1/proxy/: tls baz (200; 12.107471ms)
Apr  1 18:10:43.877: INFO: (9) /api/v1/namespaces/proxy-9951/services/proxy-service-9xhmw:portname2/proxy/: bar (200; 11.956792ms)
Apr  1 18:10:43.878: INFO: (9) /api/v1/namespaces/proxy-9951/services/http:proxy-service-9xhmw:portname1/proxy/: foo (200; 12.592036ms)
Apr  1 18:10:43.883: INFO: (10) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:160/proxy/: foo (200; 5.393088ms)
Apr  1 18:10:43.884: INFO: (10) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:162/proxy/: bar (200; 5.585819ms)
Apr  1 18:10:43.884: INFO: (10) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:160/proxy/: foo (200; 5.924246ms)
Apr  1 18:10:43.885: INFO: (10) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj/proxy/rewriteme">test</a> (200; 6.704521ms)
Apr  1 18:10:43.885: INFO: (10) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:460/proxy/: tls baz (200; 6.656235ms)
Apr  1 18:10:43.885: INFO: (10) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:162/proxy/: bar (200; 6.849255ms)
Apr  1 18:10:43.885: INFO: (10) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:1080/proxy/rewriteme">... (200; 6.828301ms)
Apr  1 18:10:43.886: INFO: (10) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:443/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:443/proxy/tlsrewritem... (200; 8.034424ms)
Apr  1 18:10:43.886: INFO: (10) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:1080/proxy/rewriteme">test<... (200; 8.487005ms)
Apr  1 18:10:43.886: INFO: (10) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:462/proxy/: tls qux (200; 8.354211ms)
Apr  1 18:10:43.886: INFO: (10) /api/v1/namespaces/proxy-9951/services/proxy-service-9xhmw:portname2/proxy/: bar (200; 8.433562ms)
Apr  1 18:10:43.886: INFO: (10) /api/v1/namespaces/proxy-9951/services/https:proxy-service-9xhmw:tlsportname1/proxy/: tls baz (200; 8.583914ms)
Apr  1 18:10:43.888: INFO: (10) /api/v1/namespaces/proxy-9951/services/http:proxy-service-9xhmw:portname1/proxy/: foo (200; 9.816549ms)
Apr  1 18:10:43.889: INFO: (10) /api/v1/namespaces/proxy-9951/services/proxy-service-9xhmw:portname1/proxy/: foo (200; 11.333046ms)
Apr  1 18:10:43.889: INFO: (10) /api/v1/namespaces/proxy-9951/services/http:proxy-service-9xhmw:portname2/proxy/: bar (200; 11.252441ms)
Apr  1 18:10:43.889: INFO: (10) /api/v1/namespaces/proxy-9951/services/https:proxy-service-9xhmw:tlsportname2/proxy/: tls qux (200; 11.425884ms)
Apr  1 18:10:43.893: INFO: (11) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj/proxy/rewriteme">test</a> (200; 4.020212ms)
Apr  1 18:10:43.894: INFO: (11) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:162/proxy/: bar (200; 4.327874ms)
Apr  1 18:10:43.894: INFO: (11) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:162/proxy/: bar (200; 4.879261ms)
Apr  1 18:10:43.895: INFO: (11) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:1080/proxy/rewriteme">test<... (200; 5.1461ms)
Apr  1 18:10:43.896: INFO: (11) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:462/proxy/: tls qux (200; 6.335348ms)
Apr  1 18:10:43.897: INFO: (11) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:443/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:443/proxy/tlsrewritem... (200; 6.757129ms)
Apr  1 18:10:43.897: INFO: (11) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:160/proxy/: foo (200; 7.462206ms)
Apr  1 18:10:43.897: INFO: (11) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:1080/proxy/rewriteme">... (200; 7.624119ms)
Apr  1 18:10:43.897: INFO: (11) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:460/proxy/: tls baz (200; 7.38097ms)
Apr  1 18:10:43.898: INFO: (11) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:160/proxy/: foo (200; 7.809984ms)
Apr  1 18:10:43.898: INFO: (11) /api/v1/namespaces/proxy-9951/services/https:proxy-service-9xhmw:tlsportname2/proxy/: tls qux (200; 8.418289ms)
Apr  1 18:10:43.900: INFO: (11) /api/v1/namespaces/proxy-9951/services/proxy-service-9xhmw:portname2/proxy/: bar (200; 9.913613ms)
Apr  1 18:10:43.900: INFO: (11) /api/v1/namespaces/proxy-9951/services/http:proxy-service-9xhmw:portname2/proxy/: bar (200; 9.621884ms)
Apr  1 18:10:43.900: INFO: (11) /api/v1/namespaces/proxy-9951/services/proxy-service-9xhmw:portname1/proxy/: foo (200; 10.107036ms)
Apr  1 18:10:43.900: INFO: (11) /api/v1/namespaces/proxy-9951/services/https:proxy-service-9xhmw:tlsportname1/proxy/: tls baz (200; 10.312978ms)
Apr  1 18:10:43.900: INFO: (11) /api/v1/namespaces/proxy-9951/services/http:proxy-service-9xhmw:portname1/proxy/: foo (200; 10.183545ms)
Apr  1 18:10:43.905: INFO: (12) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:443/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:443/proxy/tlsrewritem... (200; 4.394715ms)
Apr  1 18:10:43.908: INFO: (12) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:462/proxy/: tls qux (200; 7.298426ms)
Apr  1 18:10:43.908: INFO: (12) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:1080/proxy/rewriteme">... (200; 7.364052ms)
Apr  1 18:10:43.908: INFO: (12) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:162/proxy/: bar (200; 7.693109ms)
Apr  1 18:10:43.909: INFO: (12) /api/v1/namespaces/proxy-9951/services/proxy-service-9xhmw:portname1/proxy/: foo (200; 8.240626ms)
Apr  1 18:10:43.910: INFO: (12) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:1080/proxy/rewriteme">test<... (200; 8.850222ms)
Apr  1 18:10:43.910: INFO: (12) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:460/proxy/: tls baz (200; 8.930607ms)
Apr  1 18:10:43.910: INFO: (12) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:162/proxy/: bar (200; 9.376154ms)
Apr  1 18:10:43.910: INFO: (12) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:160/proxy/: foo (200; 9.46801ms)
Apr  1 18:10:43.910: INFO: (12) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:160/proxy/: foo (200; 9.78202ms)
Apr  1 18:10:43.912: INFO: (12) /api/v1/namespaces/proxy-9951/services/proxy-service-9xhmw:portname2/proxy/: bar (200; 11.092759ms)
Apr  1 18:10:43.912: INFO: (12) /api/v1/namespaces/proxy-9951/services/http:proxy-service-9xhmw:portname2/proxy/: bar (200; 11.480043ms)
Apr  1 18:10:43.912: INFO: (12) /api/v1/namespaces/proxy-9951/services/https:proxy-service-9xhmw:tlsportname2/proxy/: tls qux (200; 11.480078ms)
Apr  1 18:10:43.912: INFO: (12) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj/proxy/rewriteme">test</a> (200; 11.67967ms)
Apr  1 18:10:43.912: INFO: (12) /api/v1/namespaces/proxy-9951/services/http:proxy-service-9xhmw:portname1/proxy/: foo (200; 11.724133ms)
Apr  1 18:10:43.913: INFO: (12) /api/v1/namespaces/proxy-9951/services/https:proxy-service-9xhmw:tlsportname1/proxy/: tls baz (200; 12.119506ms)
Apr  1 18:10:43.916: INFO: (13) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:462/proxy/: tls qux (200; 3.838531ms)
Apr  1 18:10:43.918: INFO: (13) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:460/proxy/: tls baz (200; 5.242779ms)
Apr  1 18:10:43.918: INFO: (13) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj/proxy/rewriteme">test</a> (200; 5.154728ms)
Apr  1 18:10:43.919: INFO: (13) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:160/proxy/: foo (200; 6.458352ms)
Apr  1 18:10:43.920: INFO: (13) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:443/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:443/proxy/tlsrewritem... (200; 7.005102ms)
Apr  1 18:10:43.921: INFO: (13) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:1080/proxy/rewriteme">test<... (200; 8.07023ms)
Apr  1 18:10:43.921: INFO: (13) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:162/proxy/: bar (200; 8.402452ms)
Apr  1 18:10:43.922: INFO: (13) /api/v1/namespaces/proxy-9951/services/https:proxy-service-9xhmw:tlsportname1/proxy/: tls baz (200; 9.513598ms)
Apr  1 18:10:43.922: INFO: (13) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:1080/proxy/rewriteme">... (200; 9.466787ms)
Apr  1 18:10:43.922: INFO: (13) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:160/proxy/: foo (200; 9.444576ms)
Apr  1 18:10:43.923: INFO: (13) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:162/proxy/: bar (200; 10.067227ms)
Apr  1 18:10:43.923: INFO: (13) /api/v1/namespaces/proxy-9951/services/http:proxy-service-9xhmw:portname1/proxy/: foo (200; 10.241513ms)
Apr  1 18:10:43.924: INFO: (13) /api/v1/namespaces/proxy-9951/services/proxy-service-9xhmw:portname1/proxy/: foo (200; 11.285505ms)
Apr  1 18:10:43.924: INFO: (13) /api/v1/namespaces/proxy-9951/services/https:proxy-service-9xhmw:tlsportname2/proxy/: tls qux (200; 11.336103ms)
Apr  1 18:10:43.925: INFO: (13) /api/v1/namespaces/proxy-9951/services/proxy-service-9xhmw:portname2/proxy/: bar (200; 12.138569ms)
Apr  1 18:10:43.925: INFO: (13) /api/v1/namespaces/proxy-9951/services/http:proxy-service-9xhmw:portname2/proxy/: bar (200; 12.0303ms)
Apr  1 18:10:43.930: INFO: (14) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:443/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:443/proxy/tlsrewritem... (200; 5.131497ms)
Apr  1 18:10:43.930: INFO: (14) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:1080/proxy/rewriteme">test<... (200; 5.159072ms)
Apr  1 18:10:43.931: INFO: (14) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:460/proxy/: tls baz (200; 5.590186ms)
Apr  1 18:10:43.931: INFO: (14) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:162/proxy/: bar (200; 6.185902ms)
Apr  1 18:10:43.932: INFO: (14) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:160/proxy/: foo (200; 6.744525ms)
Apr  1 18:10:43.932: INFO: (14) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:162/proxy/: bar (200; 6.954687ms)
Apr  1 18:10:43.933: INFO: (14) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj/proxy/rewriteme">test</a> (200; 7.481773ms)
Apr  1 18:10:43.933: INFO: (14) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:160/proxy/: foo (200; 7.187669ms)
Apr  1 18:10:43.933: INFO: (14) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:462/proxy/: tls qux (200; 7.351242ms)
Apr  1 18:10:43.933: INFO: (14) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:1080/proxy/rewriteme">... (200; 7.748119ms)
Apr  1 18:10:43.934: INFO: (14) /api/v1/namespaces/proxy-9951/services/https:proxy-service-9xhmw:tlsportname2/proxy/: tls qux (200; 8.653639ms)
Apr  1 18:10:43.934: INFO: (14) /api/v1/namespaces/proxy-9951/services/https:proxy-service-9xhmw:tlsportname1/proxy/: tls baz (200; 8.937039ms)
Apr  1 18:10:43.934: INFO: (14) /api/v1/namespaces/proxy-9951/services/http:proxy-service-9xhmw:portname1/proxy/: foo (200; 8.961101ms)
Apr  1 18:10:43.936: INFO: (14) /api/v1/namespaces/proxy-9951/services/http:proxy-service-9xhmw:portname2/proxy/: bar (200; 10.810103ms)
Apr  1 18:10:43.936: INFO: (14) /api/v1/namespaces/proxy-9951/services/proxy-service-9xhmw:portname2/proxy/: bar (200; 11.081372ms)
Apr  1 18:10:43.936: INFO: (14) /api/v1/namespaces/proxy-9951/services/proxy-service-9xhmw:portname1/proxy/: foo (200; 11.055285ms)
Apr  1 18:10:43.942: INFO: (15) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:462/proxy/: tls qux (200; 5.6024ms)
Apr  1 18:10:43.942: INFO: (15) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:460/proxy/: tls baz (200; 5.804785ms)
Apr  1 18:10:43.942: INFO: (15) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:160/proxy/: foo (200; 5.694603ms)
Apr  1 18:10:43.943: INFO: (15) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:160/proxy/: foo (200; 5.966332ms)
Apr  1 18:10:43.944: INFO: (15) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj/proxy/rewriteme">test</a> (200; 6.90459ms)
Apr  1 18:10:43.944: INFO: (15) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:162/proxy/: bar (200; 6.964754ms)
Apr  1 18:10:43.944: INFO: (15) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:1080/proxy/rewriteme">... (200; 6.85509ms)
Apr  1 18:10:43.944: INFO: (15) /api/v1/namespaces/proxy-9951/services/http:proxy-service-9xhmw:portname2/proxy/: bar (200; 7.834561ms)
Apr  1 18:10:43.945: INFO: (15) /api/v1/namespaces/proxy-9951/services/http:proxy-service-9xhmw:portname1/proxy/: foo (200; 8.108209ms)
Apr  1 18:10:43.945: INFO: (15) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:1080/proxy/rewriteme">test<... (200; 8.279269ms)
Apr  1 18:10:43.946: INFO: (15) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:162/proxy/: bar (200; 8.783368ms)
Apr  1 18:10:43.946: INFO: (15) /api/v1/namespaces/proxy-9951/services/https:proxy-service-9xhmw:tlsportname2/proxy/: tls qux (200; 9.076579ms)
Apr  1 18:10:43.946: INFO: (15) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:443/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:443/proxy/tlsrewritem... (200; 8.639987ms)
Apr  1 18:10:43.946: INFO: (15) /api/v1/namespaces/proxy-9951/services/proxy-service-9xhmw:portname1/proxy/: foo (200; 8.750202ms)
Apr  1 18:10:43.946: INFO: (15) /api/v1/namespaces/proxy-9951/services/proxy-service-9xhmw:portname2/proxy/: bar (200; 9.536294ms)
Apr  1 18:10:43.952: INFO: (15) /api/v1/namespaces/proxy-9951/services/https:proxy-service-9xhmw:tlsportname1/proxy/: tls baz (200; 14.629123ms)
Apr  1 18:10:43.957: INFO: (16) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:1080/proxy/rewriteme">... (200; 5.35753ms)
Apr  1 18:10:43.957: INFO: (16) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:162/proxy/: bar (200; 5.44667ms)
Apr  1 18:10:43.958: INFO: (16) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:1080/proxy/rewriteme">test<... (200; 5.749444ms)
Apr  1 18:10:43.958: INFO: (16) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:160/proxy/: foo (200; 5.642743ms)
Apr  1 18:10:43.958: INFO: (16) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:162/proxy/: bar (200; 6.292643ms)
Apr  1 18:10:43.960: INFO: (16) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj/proxy/rewriteme">test</a> (200; 7.696747ms)
Apr  1 18:10:43.960: INFO: (16) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:160/proxy/: foo (200; 7.877038ms)
Apr  1 18:10:43.961: INFO: (16) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:462/proxy/: tls qux (200; 8.610478ms)
Apr  1 18:10:43.961: INFO: (16) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:443/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:443/proxy/tlsrewritem... (200; 8.453952ms)
Apr  1 18:10:43.961: INFO: (16) /api/v1/namespaces/proxy-9951/services/https:proxy-service-9xhmw:tlsportname1/proxy/: tls baz (200; 9.555505ms)
Apr  1 18:10:43.961: INFO: (16) /api/v1/namespaces/proxy-9951/services/proxy-service-9xhmw:portname2/proxy/: bar (200; 9.237869ms)
Apr  1 18:10:43.961: INFO: (16) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:460/proxy/: tls baz (200; 9.397981ms)
Apr  1 18:10:43.962: INFO: (16) /api/v1/namespaces/proxy-9951/services/https:proxy-service-9xhmw:tlsportname2/proxy/: tls qux (200; 10.56652ms)
Apr  1 18:10:43.962: INFO: (16) /api/v1/namespaces/proxy-9951/services/http:proxy-service-9xhmw:portname1/proxy/: foo (200; 10.714745ms)
Apr  1 18:10:43.962: INFO: (16) /api/v1/namespaces/proxy-9951/services/proxy-service-9xhmw:portname1/proxy/: foo (200; 10.38783ms)
Apr  1 18:10:43.963: INFO: (16) /api/v1/namespaces/proxy-9951/services/http:proxy-service-9xhmw:portname2/proxy/: bar (200; 10.812061ms)
Apr  1 18:10:43.969: INFO: (17) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:160/proxy/: foo (200; 6.558342ms)
Apr  1 18:10:43.969: INFO: (17) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj/proxy/rewriteme">test</a> (200; 6.741866ms)
Apr  1 18:10:43.970: INFO: (17) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:443/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:443/proxy/tlsrewritem... (200; 6.990411ms)
Apr  1 18:10:43.970: INFO: (17) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:162/proxy/: bar (200; 7.228315ms)
Apr  1 18:10:43.970: INFO: (17) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:1080/proxy/rewriteme">... (200; 7.625948ms)
Apr  1 18:10:43.970: INFO: (17) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:460/proxy/: tls baz (200; 7.566962ms)
Apr  1 18:10:43.971: INFO: (17) /api/v1/namespaces/proxy-9951/services/proxy-service-9xhmw:portname1/proxy/: foo (200; 8.203079ms)
Apr  1 18:10:43.971: INFO: (17) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:462/proxy/: tls qux (200; 8.620242ms)
Apr  1 18:10:43.972: INFO: (17) /api/v1/namespaces/proxy-9951/services/http:proxy-service-9xhmw:portname2/proxy/: bar (200; 8.863611ms)
Apr  1 18:10:43.972: INFO: (17) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:160/proxy/: foo (200; 8.832431ms)
Apr  1 18:10:43.972: INFO: (17) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:162/proxy/: bar (200; 9.471541ms)
Apr  1 18:10:43.972: INFO: (17) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:1080/proxy/rewriteme">test<... (200; 9.638639ms)
Apr  1 18:10:43.973: INFO: (17) /api/v1/namespaces/proxy-9951/services/http:proxy-service-9xhmw:portname1/proxy/: foo (200; 9.925237ms)
Apr  1 18:10:43.973: INFO: (17) /api/v1/namespaces/proxy-9951/services/https:proxy-service-9xhmw:tlsportname2/proxy/: tls qux (200; 9.786796ms)
Apr  1 18:10:43.974: INFO: (17) /api/v1/namespaces/proxy-9951/services/proxy-service-9xhmw:portname2/proxy/: bar (200; 10.977313ms)
Apr  1 18:10:43.975: INFO: (17) /api/v1/namespaces/proxy-9951/services/https:proxy-service-9xhmw:tlsportname1/proxy/: tls baz (200; 12.163846ms)
Apr  1 18:10:43.981: INFO: (18) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:160/proxy/: foo (200; 4.754796ms)
Apr  1 18:10:43.981: INFO: (18) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:160/proxy/: foo (200; 5.853926ms)
Apr  1 18:10:43.981: INFO: (18) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:460/proxy/: tls baz (200; 5.902875ms)
Apr  1 18:10:43.981: INFO: (18) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:443/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:443/proxy/tlsrewritem... (200; 6.186039ms)
Apr  1 18:10:43.982: INFO: (18) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:1080/proxy/rewriteme">... (200; 5.814197ms)
Apr  1 18:10:43.982: INFO: (18) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj/proxy/rewriteme">test</a> (200; 6.729434ms)
Apr  1 18:10:43.982: INFO: (18) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:162/proxy/: bar (200; 6.964711ms)
Apr  1 18:10:43.983: INFO: (18) /api/v1/namespaces/proxy-9951/services/https:proxy-service-9xhmw:tlsportname2/proxy/: tls qux (200; 7.9058ms)
Apr  1 18:10:43.983: INFO: (18) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:1080/proxy/rewriteme">test<... (200; 7.656324ms)
Apr  1 18:10:43.983: INFO: (18) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:162/proxy/: bar (200; 7.89264ms)
Apr  1 18:10:43.983: INFO: (18) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:462/proxy/: tls qux (200; 7.868934ms)
Apr  1 18:10:43.984: INFO: (18) /api/v1/namespaces/proxy-9951/services/http:proxy-service-9xhmw:portname1/proxy/: foo (200; 8.519832ms)
Apr  1 18:10:43.986: INFO: (18) /api/v1/namespaces/proxy-9951/services/https:proxy-service-9xhmw:tlsportname1/proxy/: tls baz (200; 10.399635ms)
Apr  1 18:10:43.987: INFO: (18) /api/v1/namespaces/proxy-9951/services/proxy-service-9xhmw:portname1/proxy/: foo (200; 11.110882ms)
Apr  1 18:10:43.987: INFO: (18) /api/v1/namespaces/proxy-9951/services/http:proxy-service-9xhmw:portname2/proxy/: bar (200; 11.329464ms)
Apr  1 18:10:43.990: INFO: (18) /api/v1/namespaces/proxy-9951/services/proxy-service-9xhmw:portname2/proxy/: bar (200; 14.374172ms)
Apr  1 18:10:43.993: INFO: (19) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:462/proxy/: tls qux (200; 3.688885ms)
Apr  1 18:10:43.997: INFO: (19) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:460/proxy/: tls baz (200; 7.618354ms)
Apr  1 18:10:43.998: INFO: (19) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:160/proxy/: foo (200; 8.44022ms)
Apr  1 18:10:43.999: INFO: (19) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:162/proxy/: bar (200; 8.65398ms)
Apr  1 18:10:43.999: INFO: (19) /api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:443/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/https:proxy-service-9xhmw-czmzj:443/proxy/tlsrewritem... (200; 8.50335ms)
Apr  1 18:10:43.999: INFO: (19) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:160/proxy/: foo (200; 8.962763ms)
Apr  1 18:10:44.000: INFO: (19) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:1080/proxy/rewriteme">... (200; 9.896481ms)
Apr  1 18:10:44.000: INFO: (19) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj/proxy/rewriteme">test</a> (200; 9.853696ms)
Apr  1 18:10:44.000: INFO: (19) /api/v1/namespaces/proxy-9951/services/http:proxy-service-9xhmw:portname1/proxy/: foo (200; 10.020853ms)
Apr  1 18:10:44.001: INFO: (19) /api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:1080/proxy/: <a href="/api/v1/namespaces/proxy-9951/pods/proxy-service-9xhmw-czmzj:1080/proxy/rewriteme">test<... (200; 10.72568ms)
Apr  1 18:10:44.001: INFO: (19) /api/v1/namespaces/proxy-9951/pods/http:proxy-service-9xhmw-czmzj:162/proxy/: bar (200; 10.748865ms)
Apr  1 18:10:44.001: INFO: (19) /api/v1/namespaces/proxy-9951/services/http:proxy-service-9xhmw:portname2/proxy/: bar (200; 10.940362ms)
Apr  1 18:10:44.002: INFO: (19) /api/v1/namespaces/proxy-9951/services/https:proxy-service-9xhmw:tlsportname1/proxy/: tls baz (200; 12.073661ms)
Apr  1 18:10:44.003: INFO: (19) /api/v1/namespaces/proxy-9951/services/proxy-service-9xhmw:portname2/proxy/: bar (200; 13.028414ms)
Apr  1 18:10:44.003: INFO: (19) /api/v1/namespaces/proxy-9951/services/proxy-service-9xhmw:portname1/proxy/: foo (200; 13.266516ms)
Apr  1 18:10:44.003: INFO: (19) /api/v1/namespaces/proxy-9951/services/https:proxy-service-9xhmw:tlsportname2/proxy/: tls qux (200; 13.537037ms)
STEP: deleting ReplicationController proxy-service-9xhmw in namespace proxy-9951, will wait for the garbage collector to delete the pods
Apr  1 18:10:44.066: INFO: Deleting ReplicationController proxy-service-9xhmw took: 9.181973ms
Apr  1 18:10:44.366: INFO: Terminating ReplicationController proxy-service-9xhmw pods took: 300.150562ms
[AfterEach] version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:10:46.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-9951" for this suite.
Apr  1 18:10:52.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:10:52.429: INFO: namespace proxy-9951 deletion completed in 6.157747023s

• [SLOW TEST:13.805 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:10:52.429: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Apr  1 18:11:00.519: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  1 18:11:00.523: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  1 18:11:02.524: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  1 18:11:02.531: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  1 18:11:04.524: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  1 18:11:04.535: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  1 18:11:06.524: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  1 18:11:06.538: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  1 18:11:08.523: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  1 18:11:08.528: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  1 18:11:10.523: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  1 18:11:10.527: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  1 18:11:12.523: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  1 18:11:12.527: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  1 18:11:14.524: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  1 18:11:14.528: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  1 18:11:16.523: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  1 18:11:16.528: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  1 18:11:18.523: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  1 18:11:18.527: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:11:18.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3570" for this suite.
Apr  1 18:11:40.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:11:40.764: INFO: namespace container-lifecycle-hook-3570 deletion completed in 22.221253848s

• [SLOW TEST:48.334 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:11:40.764: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating cluster-info
Apr  1 18:11:40.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 cluster-info'
Apr  1 18:11:41.240: INFO: stderr: ""
Apr  1 18:11:41.240: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.152.183.1:443\x1b[0m\n\x1b[0;32mHeapster\x1b[0m is running at \x1b[0;33mhttps://10.152.183.1:443/api/v1/namespaces/kube-system/services/heapster/proxy\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.152.183.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mMetrics-server\x1b[0m is running at \x1b[0;33mhttps://10.152.183.1:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\x1b[0;32mGrafana\x1b[0m is running at \x1b[0;33mhttps://10.152.183.1:443/api/v1/namespaces/kube-system/services/monitoring-grafana/proxy\x1b[0m\n\x1b[0;32mInfluxDB\x1b[0m is running at \x1b[0;33mhttps://10.152.183.1:443/api/v1/namespaces/kube-system/services/monitoring-influxdb:http/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:11:41.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7801" for this suite.
Apr  1 18:11:47.261: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:11:47.421: INFO: namespace kubectl-7801 deletion completed in 6.174246826s

• [SLOW TEST:6.657 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:11:47.421: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:11:52.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3129" for this suite.
Apr  1 18:12:14.514: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:12:14.627: INFO: namespace replication-controller-3129 deletion completed in 22.12764469s

• [SLOW TEST:27.206 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:12:14.627: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr  1 18:12:14.674: INFO: Waiting up to 5m0s for pod "downward-api-ad62593a-54a9-11e9-871e-828ee0b576f8" in namespace "downward-api-4843" to be "success or failure"
Apr  1 18:12:14.678: INFO: Pod "downward-api-ad62593a-54a9-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.934431ms
Apr  1 18:12:16.683: INFO: Pod "downward-api-ad62593a-54a9-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008629126s
Apr  1 18:12:18.688: INFO: Pod "downward-api-ad62593a-54a9-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013048558s
STEP: Saw pod success
Apr  1 18:12:18.688: INFO: Pod "downward-api-ad62593a-54a9-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 18:12:18.691: INFO: Trying to get logs from node ip-172-31-3-176 pod downward-api-ad62593a-54a9-11e9-871e-828ee0b576f8 container dapi-container: <nil>
STEP: delete the pod
Apr  1 18:12:18.716: INFO: Waiting for pod downward-api-ad62593a-54a9-11e9-871e-828ee0b576f8 to disappear
Apr  1 18:12:18.719: INFO: Pod downward-api-ad62593a-54a9-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:12:18.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4843" for this suite.
Apr  1 18:12:24.736: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:12:24.859: INFO: namespace downward-api-4843 deletion completed in 6.135990387s

• [SLOW TEST:10.231 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:12:24.859: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Apr  1 18:12:27.446: INFO: Successfully updated pod "annotationupdateb37be78b-54a9-11e9-871e-828ee0b576f8"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:12:29.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3191" for this suite.
Apr  1 18:12:51.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:12:51.637: INFO: namespace projected-3191 deletion completed in 22.169601842s

• [SLOW TEST:26.779 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:12:51.638: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-c371bdbd-54a9-11e9-871e-828ee0b576f8
STEP: Creating a pod to test consume configMaps
Apr  1 18:12:51.690: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c372fb77-54a9-11e9-871e-828ee0b576f8" in namespace "projected-3660" to be "success or failure"
Apr  1 18:12:51.695: INFO: Pod "pod-projected-configmaps-c372fb77-54a9-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.265456ms
Apr  1 18:12:53.699: INFO: Pod "pod-projected-configmaps-c372fb77-54a9-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008874966s
Apr  1 18:12:55.704: INFO: Pod "pod-projected-configmaps-c372fb77-54a9-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013400726s
STEP: Saw pod success
Apr  1 18:12:55.704: INFO: Pod "pod-projected-configmaps-c372fb77-54a9-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 18:12:55.708: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-projected-configmaps-c372fb77-54a9-11e9-871e-828ee0b576f8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr  1 18:12:55.732: INFO: Waiting for pod pod-projected-configmaps-c372fb77-54a9-11e9-871e-828ee0b576f8 to disappear
Apr  1 18:12:55.735: INFO: Pod pod-projected-configmaps-c372fb77-54a9-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:12:55.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3660" for this suite.
Apr  1 18:13:01.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:13:01.878: INFO: namespace projected-3660 deletion completed in 6.138779875s

• [SLOW TEST:10.240 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:13:01.878: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  1 18:13:01.930: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c98cfe7c-54a9-11e9-871e-828ee0b576f8" in namespace "projected-4127" to be "success or failure"
Apr  1 18:13:01.936: INFO: Pod "downwardapi-volume-c98cfe7c-54a9-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.404478ms
Apr  1 18:13:03.941: INFO: Pod "downwardapi-volume-c98cfe7c-54a9-11e9-871e-828ee0b576f8": Phase="Running", Reason="", readiness=true. Elapsed: 2.010062727s
Apr  1 18:13:05.945: INFO: Pod "downwardapi-volume-c98cfe7c-54a9-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014734803s
STEP: Saw pod success
Apr  1 18:13:05.945: INFO: Pod "downwardapi-volume-c98cfe7c-54a9-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 18:13:05.949: INFO: Trying to get logs from node ip-172-31-3-176 pod downwardapi-volume-c98cfe7c-54a9-11e9-871e-828ee0b576f8 container client-container: <nil>
STEP: delete the pod
Apr  1 18:13:05.970: INFO: Waiting for pod downwardapi-volume-c98cfe7c-54a9-11e9-871e-828ee0b576f8 to disappear
Apr  1 18:13:05.973: INFO: Pod downwardapi-volume-c98cfe7c-54a9-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:13:05.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4127" for this suite.
Apr  1 18:13:11.993: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:13:12.126: INFO: namespace projected-4127 deletion completed in 6.148690222s

• [SLOW TEST:10.248 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:13:12.126: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr  1 18:13:12.175: INFO: Waiting up to 5m0s for pod "downward-api-cfa83a56-54a9-11e9-871e-828ee0b576f8" in namespace "downward-api-5390" to be "success or failure"
Apr  1 18:13:12.325: INFO: Pod "downward-api-cfa83a56-54a9-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 149.432278ms
Apr  1 18:13:14.330: INFO: Pod "downward-api-cfa83a56-54a9-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.154261894s
Apr  1 18:13:16.334: INFO: Pod "downward-api-cfa83a56-54a9-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.159151332s
STEP: Saw pod success
Apr  1 18:13:16.334: INFO: Pod "downward-api-cfa83a56-54a9-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 18:13:16.338: INFO: Trying to get logs from node ip-172-31-3-176 pod downward-api-cfa83a56-54a9-11e9-871e-828ee0b576f8 container dapi-container: <nil>
STEP: delete the pod
Apr  1 18:13:16.359: INFO: Waiting for pod downward-api-cfa83a56-54a9-11e9-871e-828ee0b576f8 to disappear
Apr  1 18:13:16.362: INFO: Pod downward-api-cfa83a56-54a9-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:13:16.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5390" for this suite.
Apr  1 18:13:22.382: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:13:22.495: INFO: namespace downward-api-5390 deletion completed in 6.128820364s

• [SLOW TEST:10.369 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:13:22.495: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1190
STEP: creating an rc
Apr  1 18:13:22.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 create -f - --namespace=kubectl-3158'
Apr  1 18:13:22.730: INFO: stderr: ""
Apr  1 18:13:22.730: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Waiting for Redis master to start.
Apr  1 18:13:23.735: INFO: Selector matched 1 pods for map[app:redis]
Apr  1 18:13:23.735: INFO: Found 0 / 1
Apr  1 18:13:24.735: INFO: Selector matched 1 pods for map[app:redis]
Apr  1 18:13:24.735: INFO: Found 1 / 1
Apr  1 18:13:24.735: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr  1 18:13:24.738: INFO: Selector matched 1 pods for map[app:redis]
Apr  1 18:13:24.738: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Apr  1 18:13:24.738: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 logs redis-master-2qs22 redis-master --namespace=kubectl-3158'
Apr  1 18:13:24.837: INFO: stderr: ""
Apr  1 18:13:24.837: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 01 Apr 18:13:24.202 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 01 Apr 18:13:24.202 # Server started, Redis version 3.2.12\n1:M 01 Apr 18:13:24.202 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 01 Apr 18:13:24.202 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Apr  1 18:13:24.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 log redis-master-2qs22 redis-master --namespace=kubectl-3158 --tail=1'
Apr  1 18:13:24.918: INFO: stderr: ""
Apr  1 18:13:24.918: INFO: stdout: "1:M 01 Apr 18:13:24.202 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Apr  1 18:13:24.918: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 log redis-master-2qs22 redis-master --namespace=kubectl-3158 --limit-bytes=1'
Apr  1 18:13:24.999: INFO: stderr: ""
Apr  1 18:13:24.999: INFO: stdout: " "
STEP: exposing timestamps
Apr  1 18:13:24.999: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 log redis-master-2qs22 redis-master --namespace=kubectl-3158 --tail=1 --timestamps'
Apr  1 18:13:25.079: INFO: stderr: ""
Apr  1 18:13:25.080: INFO: stdout: "2019-04-01T18:13:24.20406873Z 1:M 01 Apr 18:13:24.202 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Apr  1 18:13:27.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 log redis-master-2qs22 redis-master --namespace=kubectl-3158 --since=1s'
Apr  1 18:13:27.672: INFO: stderr: ""
Apr  1 18:13:27.672: INFO: stdout: ""
Apr  1 18:13:27.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 log redis-master-2qs22 redis-master --namespace=kubectl-3158 --since=24h'
Apr  1 18:13:27.760: INFO: stderr: ""
Apr  1 18:13:27.761: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 01 Apr 18:13:24.202 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 01 Apr 18:13:24.202 # Server started, Redis version 3.2.12\n1:M 01 Apr 18:13:24.202 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 01 Apr 18:13:24.202 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1196
STEP: using delete to clean up resources
Apr  1 18:13:27.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 delete --grace-period=0 --force -f - --namespace=kubectl-3158'
Apr  1 18:13:27.835: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  1 18:13:27.835: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Apr  1 18:13:27.835: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get rc,svc -l name=nginx --no-headers --namespace=kubectl-3158'
Apr  1 18:13:27.921: INFO: stderr: "No resources found.\n"
Apr  1 18:13:27.921: INFO: stdout: ""
Apr  1 18:13:27.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 get pods -l name=nginx --namespace=kubectl-3158 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr  1 18:13:27.996: INFO: stderr: ""
Apr  1 18:13:27.996: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:13:27.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3158" for this suite.
Apr  1 18:13:50.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:13:50.158: INFO: namespace kubectl-3158 deletion completed in 22.15690953s

• [SLOW TEST:27.662 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:13:50.158: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  1 18:13:50.305: INFO: Pod name rollover-pod: Found 0 pods out of 1
Apr  1 18:13:55.310: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr  1 18:13:55.310: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Apr  1 18:13:57.315: INFO: Creating deployment "test-rollover-deployment"
Apr  1 18:13:57.324: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Apr  1 18:13:59.334: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Apr  1 18:13:59.342: INFO: Ensure that both replica sets have 1 created replica
Apr  1 18:13:59.349: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Apr  1 18:13:59.359: INFO: Updating deployment test-rollover-deployment
Apr  1 18:13:59.359: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Apr  1 18:14:01.370: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Apr  1 18:14:01.378: INFO: Make sure deployment "test-rollover-deployment" is complete
Apr  1 18:14:01.385: INFO: all replica sets need to contain the pod-template-hash label
Apr  1 18:14:01.385: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689739237, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689739237, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689739239, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689739237, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  1 18:14:03.393: INFO: all replica sets need to contain the pod-template-hash label
Apr  1 18:14:03.393: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689739237, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689739237, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689739241, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689739237, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  1 18:14:05.393: INFO: all replica sets need to contain the pod-template-hash label
Apr  1 18:14:05.393: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689739237, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689739237, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689739241, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689739237, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  1 18:14:07.393: INFO: all replica sets need to contain the pod-template-hash label
Apr  1 18:14:07.393: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689739237, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689739237, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689739241, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689739237, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  1 18:14:09.393: INFO: all replica sets need to contain the pod-template-hash label
Apr  1 18:14:09.393: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689739237, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689739237, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689739241, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689739237, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  1 18:14:11.394: INFO: all replica sets need to contain the pod-template-hash label
Apr  1 18:14:11.394: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689739237, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689739237, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689739241, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689739237, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  1 18:14:13.394: INFO: 
Apr  1 18:14:13.394: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr  1 18:14:13.404: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-9255,SelfLink:/apis/apps/v1/namespaces/deployment-9255/deployments/test-rollover-deployment,UID:ea962d0c-54a9-11e9-9aab-028387864c62,ResourceVersion:19164,Generation:2,CreationTimestamp:2019-04-01 18:13:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-04-01 18:13:57 +0000 UTC 2019-04-01 18:13:57 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-04-01 18:14:11 +0000 UTC 2019-04-01 18:13:57 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-766b4d6c9d" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Apr  1 18:14:13.408: INFO: New ReplicaSet "test-rollover-deployment-766b4d6c9d" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-766b4d6c9d,GenerateName:,Namespace:deployment-9255,SelfLink:/apis/apps/v1/namespaces/deployment-9255/replicasets/test-rollover-deployment-766b4d6c9d,UID:ebc8a802-54a9-11e9-84d7-12a9dd9b0c8a,ResourceVersion:19153,Generation:2,CreationTimestamp:2019-04-01 18:13:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment ea962d0c-54a9-11e9-9aab-028387864c62 0xc002cf57b7 0xc002cf57b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Apr  1 18:14:13.408: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Apr  1 18:14:13.408: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-9255,SelfLink:/apis/apps/v1/namespaces/deployment-9255/replicasets/test-rollover-controller,UID:e666c72c-54a9-11e9-9aab-028387864c62,ResourceVersion:19162,Generation:2,CreationTimestamp:2019-04-01 18:13:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment ea962d0c-54a9-11e9-9aab-028387864c62 0xc002cf5607 0xc002cf5608}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr  1 18:14:13.408: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6455657675,GenerateName:,Namespace:deployment-9255,SelfLink:/apis/apps/v1/namespaces/deployment-9255/replicasets/test-rollover-deployment-6455657675,UID:ea92ce46-54a9-11e9-84d7-12a9dd9b0c8a,ResourceVersion:19117,Generation:2,CreationTimestamp:2019-04-01 18:13:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment ea962d0c-54a9-11e9-9aab-028387864c62 0xc002cf56d7 0xc002cf56d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr  1 18:14:13.412: INFO: Pod "test-rollover-deployment-766b4d6c9d-hzvpk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-766b4d6c9d-hzvpk,GenerateName:test-rollover-deployment-766b4d6c9d-,Namespace:deployment-9255,SelfLink:/api/v1/namespaces/deployment-9255/pods/test-rollover-deployment-766b4d6c9d-hzvpk,UID:ebcd4ceb-54a9-11e9-84d7-12a9dd9b0c8a,ResourceVersion:19132,Generation:0,CreationTimestamp:2019-04-01 18:13:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-766b4d6c9d ebc8a802-54a9-11e9-84d7-12a9dd9b0c8a 0xc00082d3b7 0xc00082d3b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-rxdct {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rxdct,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-rxdct true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-3-176,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00082d4f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00082d570}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:13:59 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:14:01 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:14:01 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-01 18:13:59 +0000 UTC  }],Message:,Reason:,HostIP:172.31.3.176,PodIP:10.1.83.223,StartTime:2019-04-01 18:13:59 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-04-01 18:14:01 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://ec9a53133ea772ad07ab01a159f0876abcff1271e3c48c0741da46c5ebfc15ad}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:14:13.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9255" for this suite.
Apr  1 18:14:19.430: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:14:19.544: INFO: namespace deployment-9255 deletion completed in 6.128074666s

• [SLOW TEST:29.386 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:14:19.544: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-f7d7216f-54a9-11e9-871e-828ee0b576f8
STEP: Creating a pod to test consume secrets
Apr  1 18:14:19.594: INFO: Waiting up to 5m0s for pod "pod-secrets-f7d8448c-54a9-11e9-871e-828ee0b576f8" in namespace "secrets-8809" to be "success or failure"
Apr  1 18:14:19.598: INFO: Pod "pod-secrets-f7d8448c-54a9-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.560604ms
Apr  1 18:14:21.603: INFO: Pod "pod-secrets-f7d8448c-54a9-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008918715s
Apr  1 18:14:23.607: INFO: Pod "pod-secrets-f7d8448c-54a9-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013392934s
STEP: Saw pod success
Apr  1 18:14:23.607: INFO: Pod "pod-secrets-f7d8448c-54a9-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 18:14:23.611: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-secrets-f7d8448c-54a9-11e9-871e-828ee0b576f8 container secret-volume-test: <nil>
STEP: delete the pod
Apr  1 18:14:23.632: INFO: Waiting for pod pod-secrets-f7d8448c-54a9-11e9-871e-828ee0b576f8 to disappear
Apr  1 18:14:23.636: INFO: Pod pod-secrets-f7d8448c-54a9-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:14:23.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8809" for this suite.
Apr  1 18:14:29.656: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:14:30.003: INFO: namespace secrets-8809 deletion completed in 6.363750745s

• [SLOW TEST:10.460 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:14:30.003: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  1 18:14:30.041: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:14:34.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1204" for this suite.
Apr  1 18:15:16.102: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:15:16.214: INFO: namespace pods-1204 deletion completed in 42.126427706s

• [SLOW TEST:46.210 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:15:16.214: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating replication controller my-hostname-basic-199ecf46-54aa-11e9-871e-828ee0b576f8
Apr  1 18:15:16.264: INFO: Pod name my-hostname-basic-199ecf46-54aa-11e9-871e-828ee0b576f8: Found 0 pods out of 1
Apr  1 18:15:21.269: INFO: Pod name my-hostname-basic-199ecf46-54aa-11e9-871e-828ee0b576f8: Found 1 pods out of 1
Apr  1 18:15:21.269: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-199ecf46-54aa-11e9-871e-828ee0b576f8" are running
Apr  1 18:15:21.273: INFO: Pod "my-hostname-basic-199ecf46-54aa-11e9-871e-828ee0b576f8-vllpx" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-01 18:15:16 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-01 18:15:18 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-01 18:15:18 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-01 18:15:16 +0000 UTC Reason: Message:}])
Apr  1 18:15:21.273: INFO: Trying to dial the pod
Apr  1 18:15:26.285: INFO: Controller my-hostname-basic-199ecf46-54aa-11e9-871e-828ee0b576f8: Got expected result from replica 1 [my-hostname-basic-199ecf46-54aa-11e9-871e-828ee0b576f8-vllpx]: "my-hostname-basic-199ecf46-54aa-11e9-871e-828ee0b576f8-vllpx", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:15:26.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9010" for this suite.
Apr  1 18:15:32.302: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:15:32.408: INFO: namespace replication-controller-9010 deletion completed in 6.119131621s

• [SLOW TEST:16.194 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:15:32.408: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-23455273-54aa-11e9-871e-828ee0b576f8
STEP: Creating a pod to test consume configMaps
Apr  1 18:15:32.457: INFO: Waiting up to 5m0s for pod "pod-configmaps-234666cd-54aa-11e9-871e-828ee0b576f8" in namespace "configmap-5819" to be "success or failure"
Apr  1 18:15:32.462: INFO: Pod "pod-configmaps-234666cd-54aa-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.257649ms
Apr  1 18:15:34.466: INFO: Pod "pod-configmaps-234666cd-54aa-11e9-871e-828ee0b576f8": Phase="Running", Reason="", readiness=true. Elapsed: 2.008850304s
Apr  1 18:15:36.471: INFO: Pod "pod-configmaps-234666cd-54aa-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013364113s
STEP: Saw pod success
Apr  1 18:15:36.471: INFO: Pod "pod-configmaps-234666cd-54aa-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 18:15:36.474: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-configmaps-234666cd-54aa-11e9-871e-828ee0b576f8 container configmap-volume-test: <nil>
STEP: delete the pod
Apr  1 18:15:36.496: INFO: Waiting for pod pod-configmaps-234666cd-54aa-11e9-871e-828ee0b576f8 to disappear
Apr  1 18:15:36.499: INFO: Pod pod-configmaps-234666cd-54aa-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:15:36.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5819" for this suite.
Apr  1 18:15:42.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:15:42.642: INFO: namespace configmap-5819 deletion completed in 6.140105727s

• [SLOW TEST:10.234 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:15:42.642: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Apr  1 18:15:42.687: INFO: Waiting up to 5m0s for pod "pod-295ee26d-54aa-11e9-871e-828ee0b576f8" in namespace "emptydir-602" to be "success or failure"
Apr  1 18:15:42.695: INFO: Pod "pod-295ee26d-54aa-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 7.593074ms
Apr  1 18:15:44.699: INFO: Pod "pod-295ee26d-54aa-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012288281s
Apr  1 18:15:46.704: INFO: Pod "pod-295ee26d-54aa-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016654434s
STEP: Saw pod success
Apr  1 18:15:46.704: INFO: Pod "pod-295ee26d-54aa-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 18:15:46.707: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-295ee26d-54aa-11e9-871e-828ee0b576f8 container test-container: <nil>
STEP: delete the pod
Apr  1 18:15:46.729: INFO: Waiting for pod pod-295ee26d-54aa-11e9-871e-828ee0b576f8 to disappear
Apr  1 18:15:46.733: INFO: Pod pod-295ee26d-54aa-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:15:46.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-602" for this suite.
Apr  1 18:15:52.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:15:52.896: INFO: namespace emptydir-602 deletion completed in 6.158948619s

• [SLOW TEST:10.254 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:15:52.897: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-5422/configmap-test-2f7bd2d5-54aa-11e9-871e-828ee0b576f8
STEP: Creating a pod to test consume configMaps
Apr  1 18:15:52.948: INFO: Waiting up to 5m0s for pod "pod-configmaps-2f7ce06e-54aa-11e9-871e-828ee0b576f8" in namespace "configmap-5422" to be "success or failure"
Apr  1 18:15:52.953: INFO: Pod "pod-configmaps-2f7ce06e-54aa-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.523596ms
Apr  1 18:15:54.959: INFO: Pod "pod-configmaps-2f7ce06e-54aa-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010695925s
Apr  1 18:15:56.966: INFO: Pod "pod-configmaps-2f7ce06e-54aa-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017267114s
STEP: Saw pod success
Apr  1 18:15:56.966: INFO: Pod "pod-configmaps-2f7ce06e-54aa-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 18:15:56.971: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-configmaps-2f7ce06e-54aa-11e9-871e-828ee0b576f8 container env-test: <nil>
STEP: delete the pod
Apr  1 18:15:56.993: INFO: Waiting for pod pod-configmaps-2f7ce06e-54aa-11e9-871e-828ee0b576f8 to disappear
Apr  1 18:15:56.996: INFO: Pod pod-configmaps-2f7ce06e-54aa-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:15:56.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5422" for this suite.
Apr  1 18:16:03.018: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:16:03.140: INFO: namespace configmap-5422 deletion completed in 6.14016271s

• [SLOW TEST:10.244 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:16:03.140: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating all guestbook components
Apr  1 18:16:03.180: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Apr  1 18:16:03.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 create -f - --namespace=kubectl-2374'
Apr  1 18:16:03.413: INFO: stderr: ""
Apr  1 18:16:03.413: INFO: stdout: "service/redis-slave created\n"
Apr  1 18:16:03.413: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Apr  1 18:16:03.413: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 create -f - --namespace=kubectl-2374'
Apr  1 18:16:03.638: INFO: stderr: ""
Apr  1 18:16:03.638: INFO: stdout: "service/redis-master created\n"
Apr  1 18:16:03.638: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Apr  1 18:16:03.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 create -f - --namespace=kubectl-2374'
Apr  1 18:16:03.905: INFO: stderr: ""
Apr  1 18:16:03.905: INFO: stdout: "service/frontend created\n"
Apr  1 18:16:03.906: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Apr  1 18:16:03.906: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 create -f - --namespace=kubectl-2374'
Apr  1 18:16:04.122: INFO: stderr: ""
Apr  1 18:16:04.122: INFO: stdout: "deployment.apps/frontend created\n"
Apr  1 18:16:04.122: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Apr  1 18:16:04.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 create -f - --namespace=kubectl-2374'
Apr  1 18:16:04.330: INFO: stderr: ""
Apr  1 18:16:04.330: INFO: stdout: "deployment.apps/redis-master created\n"
Apr  1 18:16:04.331: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Apr  1 18:16:04.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 create -f - --namespace=kubectl-2374'
Apr  1 18:16:04.521: INFO: stderr: ""
Apr  1 18:16:04.521: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Apr  1 18:16:04.521: INFO: Waiting for all frontend pods to be Running.
Apr  1 18:16:19.572: INFO: Waiting for frontend to serve content.
Apr  1 18:16:19.586: INFO: Trying to add a new entry to the guestbook.
Apr  1 18:16:19.694: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Apr  1 18:16:19.708: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 delete --grace-period=0 --force -f - --namespace=kubectl-2374'
Apr  1 18:16:19.801: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  1 18:16:19.801: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Apr  1 18:16:19.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 delete --grace-period=0 --force -f - --namespace=kubectl-2374'
Apr  1 18:16:19.910: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  1 18:16:19.910: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Apr  1 18:16:19.910: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 delete --grace-period=0 --force -f - --namespace=kubectl-2374'
Apr  1 18:16:20.014: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  1 18:16:20.014: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Apr  1 18:16:20.015: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 delete --grace-period=0 --force -f - --namespace=kubectl-2374'
Apr  1 18:16:20.115: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  1 18:16:20.116: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Apr  1 18:16:20.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 delete --grace-period=0 --force -f - --namespace=kubectl-2374'
Apr  1 18:16:20.191: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  1 18:16:20.191: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Apr  1 18:16:20.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 delete --grace-period=0 --force -f - --namespace=kubectl-2374'
Apr  1 18:16:20.286: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  1 18:16:20.286: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:16:20.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2374" for this suite.
Apr  1 18:18:24.305: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:18:24.426: INFO: namespace kubectl-2374 deletion completed in 2m4.136011391s

• [SLOW TEST:141.286 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:18:24.426: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Apr  1 18:18:24.463: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr  1 18:18:24.471: INFO: Waiting for terminating namespaces to be deleted...
Apr  1 18:18:24.475: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-22-24 before test
Apr  1 18:18:24.484: INFO: monitoring-influxdb-grafana-v4-cfc94db54-csmb5 from kube-system started at 2019-04-01 16:46:38 +0000 UTC (2 container statuses recorded)
Apr  1 18:18:24.484: INFO: 	Container grafana ready: true, restart count 0
Apr  1 18:18:24.484: INFO: 	Container influxdb ready: true, restart count 0
Apr  1 18:18:24.484: INFO: coredns-6b957bfc77-lmplw from kube-system started at 2019-04-01 16:46:38 +0000 UTC (1 container statuses recorded)
Apr  1 18:18:24.484: INFO: 	Container coredns ready: true, restart count 0
Apr  1 18:18:24.484: INFO: kubernetes-dashboard-9f49769c8-bnt5k from kube-system started at 2019-04-01 16:46:38 +0000 UTC (1 container statuses recorded)
Apr  1 18:18:24.484: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Apr  1 18:18:24.484: INFO: coredns-6b957bfc77-w7lct from kube-system started at 2019-04-01 16:46:38 +0000 UTC (1 container statuses recorded)
Apr  1 18:18:24.484: INFO: 	Container coredns ready: true, restart count 0
Apr  1 18:18:24.484: INFO: nginx-ingress-controller-kubernetes-worker-xt5ts from ingress-nginx-kubernetes-worker started at 2019-04-01 16:46:41 +0000 UTC (1 container statuses recorded)
Apr  1 18:18:24.484: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Apr  1 18:18:24.484: INFO: default-http-backend-kubernetes-worker-5b8b477c-swdj9 from ingress-nginx-kubernetes-worker started at 2019-04-01 16:46:41 +0000 UTC (1 container statuses recorded)
Apr  1 18:18:24.484: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
Apr  1 18:18:24.484: INFO: sonobuoy-systemd-logs-daemon-set-1ce1df115e164dcd-4wc8p from heptio-sonobuoy started at 2019-04-01 16:53:44 +0000 UTC (2 container statuses recorded)
Apr  1 18:18:24.484: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Apr  1 18:18:24.484: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Apr  1 18:18:24.484: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-3-176 before test
Apr  1 18:18:24.493: INFO: sonobuoy from heptio-sonobuoy started at 2019-04-01 16:53:34 +0000 UTC (1 container statuses recorded)
Apr  1 18:18:24.493: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr  1 18:18:24.493: INFO: sonobuoy-systemd-logs-daemon-set-1ce1df115e164dcd-nl9n4 from heptio-sonobuoy started at 2019-04-01 16:53:44 +0000 UTC (2 container statuses recorded)
Apr  1 18:18:24.493: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Apr  1 18:18:24.493: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Apr  1 18:18:24.493: INFO: nginx-ingress-controller-kubernetes-worker-w7khc from ingress-nginx-kubernetes-worker started at 2019-04-01 16:46:54 +0000 UTC (1 container statuses recorded)
Apr  1 18:18:24.493: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Apr  1 18:18:24.493: INFO: metrics-server-v0.3.1-6d75b744b4-xmldb from kube-system started at 2019-04-01 16:46:59 +0000 UTC (2 container statuses recorded)
Apr  1 18:18:24.493: INFO: 	Container metrics-server ready: true, restart count 0
Apr  1 18:18:24.493: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Apr  1 18:18:24.493: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-75-215 before test
Apr  1 18:18:24.502: INFO: sonobuoy-systemd-logs-daemon-set-1ce1df115e164dcd-tz2fc from heptio-sonobuoy started at 2019-04-01 16:53:44 +0000 UTC (2 container statuses recorded)
Apr  1 18:18:24.502: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Apr  1 18:18:24.502: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Apr  1 18:18:24.502: INFO: nginx-ingress-controller-kubernetes-worker-7btnv from ingress-nginx-kubernetes-worker started at 2019-04-01 16:46:47 +0000 UTC (1 container statuses recorded)
Apr  1 18:18:24.502: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Apr  1 18:18:24.502: INFO: sonobuoy-e2e-job-f0d281cdea304082 from heptio-sonobuoy started at 2019-04-01 16:53:44 +0000 UTC (2 container statuses recorded)
Apr  1 18:18:24.502: INFO: 	Container e2e ready: true, restart count 0
Apr  1 18:18:24.502: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr  1 18:18:24.502: INFO: heapster-v1.6.0-beta.1-84cb679df9-6qmcv from kube-system started at 2019-04-01 16:47:00 +0000 UTC (4 container statuses recorded)
Apr  1 18:18:24.502: INFO: 	Container eventer ready: true, restart count 0
Apr  1 18:18:24.502: INFO: 	Container eventer-nanny ready: true, restart count 0
Apr  1 18:18:24.502: INFO: 	Container heapster ready: true, restart count 0
Apr  1 18:18:24.502: INFO: 	Container heapster-nanny ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15916c8e38a31f23], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:18:25.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2866" for this suite.
Apr  1 18:18:31.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:18:31.660: INFO: namespace sched-pred-2866 deletion completed in 6.127001053s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.235 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:18:31.661: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Apr  1 18:18:31.694: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:18:34.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-587" for this suite.
Apr  1 18:18:40.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:18:41.089: INFO: namespace init-container-587 deletion completed in 6.198038224s

• [SLOW TEST:9.428 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:18:41.089: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:18:41.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1228" for this suite.
Apr  1 18:18:47.149: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:18:47.267: INFO: namespace services-1228 deletion completed in 6.132567504s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:6.178 seconds]
[sig-network] Services
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:18:47.267: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  1 18:18:47.311: INFO: Waiting up to 5m0s for pod "downwardapi-volume-976a4507-54aa-11e9-871e-828ee0b576f8" in namespace "projected-9022" to be "success or failure"
Apr  1 18:18:47.343: INFO: Pod "downwardapi-volume-976a4507-54aa-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 32.296888ms
Apr  1 18:18:49.349: INFO: Pod "downwardapi-volume-976a4507-54aa-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.038518347s
STEP: Saw pod success
Apr  1 18:18:49.349: INFO: Pod "downwardapi-volume-976a4507-54aa-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 18:18:49.354: INFO: Trying to get logs from node ip-172-31-3-176 pod downwardapi-volume-976a4507-54aa-11e9-871e-828ee0b576f8 container client-container: <nil>
STEP: delete the pod
Apr  1 18:18:49.382: INFO: Waiting for pod downwardapi-volume-976a4507-54aa-11e9-871e-828ee0b576f8 to disappear
Apr  1 18:18:49.386: INFO: Pod downwardapi-volume-976a4507-54aa-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:18:49.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9022" for this suite.
Apr  1 18:18:55.404: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:18:55.544: INFO: namespace projected-9022 deletion completed in 6.153968164s

• [SLOW TEST:8.277 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:18:55.545: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-9c5c5f53-54aa-11e9-871e-828ee0b576f8
STEP: Creating configMap with name cm-test-opt-upd-9c5c5f88-54aa-11e9-871e-828ee0b576f8
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-9c5c5f53-54aa-11e9-871e-828ee0b576f8
STEP: Updating configmap cm-test-opt-upd-9c5c5f88-54aa-11e9-871e-828ee0b576f8
STEP: Creating configMap with name cm-test-opt-create-9c5c5f99-54aa-11e9-871e-828ee0b576f8
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:19:03.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2611" for this suite.
Apr  1 18:19:25.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:19:25.872: INFO: namespace configmap-2611 deletion completed in 22.121735215s

• [SLOW TEST:30.327 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:19:25.872: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-ae6df8db-54aa-11e9-871e-828ee0b576f8
STEP: Creating secret with name s-test-opt-upd-ae6df918-54aa-11e9-871e-828ee0b576f8
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-ae6df8db-54aa-11e9-871e-828ee0b576f8
STEP: Updating secret s-test-opt-upd-ae6df918-54aa-11e9-871e-828ee0b576f8
STEP: Creating secret with name s-test-opt-create-ae6df92b-54aa-11e9-871e-828ee0b576f8
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:20:44.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9637" for this suite.
Apr  1 18:21:06.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:21:06.646: INFO: namespace projected-9637 deletion completed in 22.183590237s

• [SLOW TEST:100.774 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:21:06.646: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  1 18:21:28.730: INFO: Container started at 2019-04-01 18:21:08 +0000 UTC, pod became ready at 2019-04-01 18:21:27 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:21:28.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7714" for this suite.
Apr  1 18:21:50.749: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:21:50.871: INFO: namespace container-probe-7714 deletion completed in 22.137210602s

• [SLOW TEST:44.224 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:21:50.871: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating replication controller svc-latency-rc in namespace svc-latency-4483
I0401 18:21:50.965162      16 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-4483, replica count: 1
I0401 18:21:52.015667      16 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0401 18:21:53.015895      16 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr  1 18:21:53.127: INFO: Created: latency-svc-78w94
Apr  1 18:21:53.134: INFO: Got endpoints: latency-svc-78w94 [17.996579ms]
Apr  1 18:21:53.151: INFO: Created: latency-svc-67zdr
Apr  1 18:21:53.157: INFO: Got endpoints: latency-svc-67zdr [22.965146ms]
Apr  1 18:21:53.160: INFO: Created: latency-svc-hsj7z
Apr  1 18:21:53.164: INFO: Got endpoints: latency-svc-hsj7z [30.415704ms]
Apr  1 18:21:53.168: INFO: Created: latency-svc-knqdj
Apr  1 18:21:53.176: INFO: Created: latency-svc-g2dbb
Apr  1 18:21:53.183: INFO: Created: latency-svc-s6vp9
Apr  1 18:21:53.189: INFO: Created: latency-svc-srxsc
Apr  1 18:21:53.195: INFO: Created: latency-svc-v5bj2
Apr  1 18:21:53.197: INFO: Got endpoints: latency-svc-s6vp9 [62.641643ms]
Apr  1 18:21:53.200: INFO: Got endpoints: latency-svc-knqdj [65.501076ms]
Apr  1 18:21:53.200: INFO: Got endpoints: latency-svc-g2dbb [65.554405ms]
Apr  1 18:21:53.204: INFO: Got endpoints: latency-svc-srxsc [69.551852ms]
Apr  1 18:21:53.205: INFO: Created: latency-svc-272z5
Apr  1 18:21:53.212: INFO: Created: latency-svc-t8xrs
Apr  1 18:21:53.217: INFO: Created: latency-svc-2jqbf
Apr  1 18:21:53.224: INFO: Created: latency-svc-t4k2n
Apr  1 18:21:53.230: INFO: Created: latency-svc-gxczv
Apr  1 18:21:53.234: INFO: Created: latency-svc-5v7kc
Apr  1 18:21:53.240: INFO: Created: latency-svc-j8gg6
Apr  1 18:21:53.246: INFO: Created: latency-svc-8crst
Apr  1 18:21:53.259: INFO: Created: latency-svc-2smrd
Apr  1 18:21:53.738: INFO: Got endpoints: latency-svc-t8xrs [604.122772ms]
Apr  1 18:21:53.741: INFO: Created: latency-svc-jnpck
Apr  1 18:21:53.742: INFO: Got endpoints: latency-svc-2jqbf [607.624982ms]
Apr  1 18:21:53.742: INFO: Got endpoints: latency-svc-272z5 [607.912639ms]
Apr  1 18:21:53.742: INFO: Got endpoints: latency-svc-v5bj2 [608.044127ms]
Apr  1 18:21:53.742: INFO: Got endpoints: latency-svc-t4k2n [608.108477ms]
Apr  1 18:21:53.746: INFO: Got endpoints: latency-svc-gxczv [611.940823ms]
Apr  1 18:21:53.749: INFO: Created: latency-svc-49nf8
Apr  1 18:21:53.754: INFO: Got endpoints: latency-svc-2smrd [596.782276ms]
Apr  1 18:21:53.754: INFO: Got endpoints: latency-svc-5v7kc [619.561353ms]
Apr  1 18:21:53.756: INFO: Got endpoints: latency-svc-j8gg6 [621.902605ms]
Apr  1 18:21:53.756: INFO: Got endpoints: latency-svc-8crst [621.993844ms]
Apr  1 18:21:53.759: INFO: Got endpoints: latency-svc-jnpck [594.278115ms]
Apr  1 18:21:53.762: INFO: Created: latency-svc-fb2kd
Apr  1 18:21:53.763: INFO: Got endpoints: latency-svc-49nf8 [565.864951ms]
Apr  1 18:21:53.771: INFO: Created: latency-svc-5ps4n
Apr  1 18:21:53.771: INFO: Got endpoints: latency-svc-fb2kd [571.958591ms]
Apr  1 18:21:53.778: INFO: Got endpoints: latency-svc-5ps4n [578.614155ms]
Apr  1 18:21:53.779: INFO: Created: latency-svc-c47dm
Apr  1 18:21:54.443: INFO: Created: latency-svc-v5v4d
Apr  1 18:21:54.443: INFO: Got endpoints: latency-svc-c47dm [1.239546119s]
Apr  1 18:21:54.452: INFO: Got endpoints: latency-svc-v5v4d [713.766397ms]
Apr  1 18:21:54.452: INFO: Created: latency-svc-77v2k
Apr  1 18:21:54.455: INFO: Got endpoints: latency-svc-77v2k [713.55881ms]
Apr  1 18:21:54.459: INFO: Created: latency-svc-nfgq6
Apr  1 18:21:54.463: INFO: Got endpoints: latency-svc-nfgq6 [720.597611ms]
Apr  1 18:21:54.467: INFO: Created: latency-svc-5l2r9
Apr  1 18:21:54.473: INFO: Got endpoints: latency-svc-5l2r9 [730.437733ms]
Apr  1 18:21:54.475: INFO: Created: latency-svc-vlc4x
Apr  1 18:21:54.480: INFO: Got endpoints: latency-svc-vlc4x [738.353116ms]
Apr  1 18:21:54.482: INFO: Created: latency-svc-kkrb8
Apr  1 18:21:54.486: INFO: Got endpoints: latency-svc-kkrb8 [740.116172ms]
Apr  1 18:21:54.489: INFO: Created: latency-svc-4jw7j
Apr  1 18:21:54.494: INFO: Got endpoints: latency-svc-4jw7j [740.297447ms]
Apr  1 18:21:54.499: INFO: Created: latency-svc-sknrb
Apr  1 18:21:54.502: INFO: Got endpoints: latency-svc-sknrb [748.531722ms]
Apr  1 18:21:54.504: INFO: Created: latency-svc-txbf7
Apr  1 18:21:54.509: INFO: Got endpoints: latency-svc-txbf7 [752.797513ms]
Apr  1 18:21:54.514: INFO: Created: latency-svc-szqmt
Apr  1 18:21:54.519: INFO: Got endpoints: latency-svc-szqmt [763.456741ms]
Apr  1 18:21:54.522: INFO: Created: latency-svc-jzdcx
Apr  1 18:21:54.528: INFO: Created: latency-svc-5m2h2
Apr  1 18:21:54.530: INFO: Got endpoints: latency-svc-jzdcx [771.373141ms]
Apr  1 18:21:54.533: INFO: Created: latency-svc-rzqv6
Apr  1 18:21:54.533: INFO: Got endpoints: latency-svc-5m2h2 [770.740822ms]
Apr  1 18:21:54.537: INFO: Got endpoints: latency-svc-rzqv6 [765.189919ms]
Apr  1 18:21:54.544: INFO: Created: latency-svc-2hlvq
Apr  1 18:21:54.548: INFO: Got endpoints: latency-svc-2hlvq [769.404143ms]
Apr  1 18:21:54.550: INFO: Created: latency-svc-xnmc7
Apr  1 18:21:54.555: INFO: Got endpoints: latency-svc-xnmc7 [111.80222ms]
Apr  1 18:21:54.558: INFO: Created: latency-svc-llq4z
Apr  1 18:21:54.561: INFO: Got endpoints: latency-svc-llq4z [108.654413ms]
Apr  1 18:21:54.565: INFO: Created: latency-svc-w9852
Apr  1 18:21:54.569: INFO: Got endpoints: latency-svc-w9852 [113.88842ms]
Apr  1 18:21:54.572: INFO: Created: latency-svc-nlnj7
Apr  1 18:21:54.576: INFO: Created: latency-svc-w4bqk
Apr  1 18:21:54.577: INFO: Got endpoints: latency-svc-nlnj7 [114.064512ms]
Apr  1 18:21:54.582: INFO: Got endpoints: latency-svc-w4bqk [109.827307ms]
Apr  1 18:21:54.586: INFO: Created: latency-svc-s6m5q
Apr  1 18:21:54.591: INFO: Got endpoints: latency-svc-s6m5q [110.437263ms]
Apr  1 18:21:54.593: INFO: Created: latency-svc-47dqz
Apr  1 18:21:54.600: INFO: Got endpoints: latency-svc-47dqz [113.318286ms]
Apr  1 18:21:54.601: INFO: Created: latency-svc-85wk7
Apr  1 18:21:54.607: INFO: Created: latency-svc-tgq9c
Apr  1 18:21:54.609: INFO: Got endpoints: latency-svc-85wk7 [114.810671ms]
Apr  1 18:21:54.611: INFO: Got endpoints: latency-svc-tgq9c [109.070957ms]
Apr  1 18:21:54.621: INFO: Created: latency-svc-nx477
Apr  1 18:21:54.621: INFO: Got endpoints: latency-svc-nx477 [112.466223ms]
Apr  1 18:21:54.626: INFO: Created: latency-svc-rkxm2
Apr  1 18:21:54.629: INFO: Got endpoints: latency-svc-rkxm2 [109.905138ms]
Apr  1 18:21:54.636: INFO: Created: latency-svc-lxd5c
Apr  1 18:21:54.640: INFO: Got endpoints: latency-svc-lxd5c [109.477747ms]
Apr  1 18:21:54.642: INFO: Created: latency-svc-m8rxz
Apr  1 18:21:54.646: INFO: Got endpoints: latency-svc-m8rxz [112.958086ms]
Apr  1 18:21:54.649: INFO: Created: latency-svc-vscm4
Apr  1 18:21:54.654: INFO: Got endpoints: latency-svc-vscm4 [117.429062ms]
Apr  1 18:21:54.663: INFO: Created: latency-svc-pwl68
Apr  1 18:21:54.664: INFO: Got endpoints: latency-svc-pwl68 [116.163414ms]
Apr  1 18:21:54.665: INFO: Created: latency-svc-pt2d2
Apr  1 18:21:54.673: INFO: Got endpoints: latency-svc-pt2d2 [117.627893ms]
Apr  1 18:21:54.675: INFO: Created: latency-svc-rlth9
Apr  1 18:21:54.681: INFO: Got endpoints: latency-svc-rlth9 [120.197046ms]
Apr  1 18:21:54.683: INFO: Created: latency-svc-wls4r
Apr  1 18:21:54.688: INFO: Got endpoints: latency-svc-wls4r [119.066812ms]
Apr  1 18:21:54.692: INFO: Created: latency-svc-wz79j
Apr  1 18:21:54.695: INFO: Got endpoints: latency-svc-wz79j [118.483212ms]
Apr  1 18:21:54.700: INFO: Created: latency-svc-dgdkt
Apr  1 18:21:54.705: INFO: Got endpoints: latency-svc-dgdkt [122.116494ms]
Apr  1 18:21:54.708: INFO: Created: latency-svc-cc4p7
Apr  1 18:21:54.716: INFO: Created: latency-svc-wq2hm
Apr  1 18:21:54.716: INFO: Got endpoints: latency-svc-cc4p7 [124.982702ms]
Apr  1 18:21:54.722: INFO: Created: latency-svc-54t8r
Apr  1 18:21:54.731: INFO: Created: latency-svc-j8tnp
Apr  1 18:21:54.738: INFO: Created: latency-svc-lgjmz
Apr  1 18:21:54.746: INFO: Created: latency-svc-nnx4b
Apr  1 18:21:54.751: INFO: Got endpoints: latency-svc-wq2hm [151.279149ms]
Apr  1 18:21:54.754: INFO: Created: latency-svc-j4xnx
Apr  1 18:21:54.760: INFO: Created: latency-svc-8pjq6
Apr  1 18:21:54.764: INFO: Created: latency-svc-vn6lp
Apr  1 18:21:54.776: INFO: Created: latency-svc-phk8f
Apr  1 18:21:54.783: INFO: Created: latency-svc-xkks6
Apr  1 18:21:54.791: INFO: Created: latency-svc-w8nmh
Apr  1 18:21:54.798: INFO: Created: latency-svc-66lxp
Apr  1 18:21:54.801: INFO: Got endpoints: latency-svc-54t8r [191.950332ms]
Apr  1 18:21:54.805: INFO: Created: latency-svc-4mmsq
Apr  1 18:21:54.808: INFO: Created: latency-svc-2cq5x
Apr  1 18:21:54.817: INFO: Created: latency-svc-gs8zg
Apr  1 18:21:54.823: INFO: Created: latency-svc-q9m9g
Apr  1 18:21:54.830: INFO: Created: latency-svc-qpb68
Apr  1 18:21:54.848: INFO: Got endpoints: latency-svc-j8tnp [237.129777ms]
Apr  1 18:21:54.866: INFO: Created: latency-svc-xr22t
Apr  1 18:21:54.898: INFO: Got endpoints: latency-svc-lgjmz [277.293172ms]
Apr  1 18:21:54.910: INFO: Created: latency-svc-ddwz2
Apr  1 18:21:54.949: INFO: Got endpoints: latency-svc-nnx4b [319.608652ms]
Apr  1 18:21:54.960: INFO: Created: latency-svc-bsdf5
Apr  1 18:21:54.999: INFO: Got endpoints: latency-svc-j4xnx [359.277099ms]
Apr  1 18:21:55.012: INFO: Created: latency-svc-rds7r
Apr  1 18:21:55.052: INFO: Got endpoints: latency-svc-8pjq6 [405.453772ms]
Apr  1 18:21:55.064: INFO: Created: latency-svc-x8dbj
Apr  1 18:21:55.098: INFO: Got endpoints: latency-svc-vn6lp [444.233811ms]
Apr  1 18:21:55.109: INFO: Created: latency-svc-pllnz
Apr  1 18:21:55.149: INFO: Got endpoints: latency-svc-phk8f [485.026496ms]
Apr  1 18:21:55.163: INFO: Created: latency-svc-k69gr
Apr  1 18:21:55.199: INFO: Got endpoints: latency-svc-xkks6 [525.938991ms]
Apr  1 18:21:55.209: INFO: Created: latency-svc-54bm7
Apr  1 18:21:55.249: INFO: Got endpoints: latency-svc-w8nmh [567.618568ms]
Apr  1 18:21:55.260: INFO: Created: latency-svc-8krrs
Apr  1 18:21:55.299: INFO: Got endpoints: latency-svc-66lxp [610.53231ms]
Apr  1 18:21:55.314: INFO: Created: latency-svc-mrnhf
Apr  1 18:21:55.349: INFO: Got endpoints: latency-svc-4mmsq [653.460158ms]
Apr  1 18:21:55.465: INFO: Got endpoints: latency-svc-2cq5x [760.015224ms]
Apr  1 18:21:55.465: INFO: Got endpoints: latency-svc-gs8zg [749.221059ms]
Apr  1 18:21:55.469: INFO: Created: latency-svc-pm9pn
Apr  1 18:21:55.477: INFO: Created: latency-svc-bbgtf
Apr  1 18:21:55.485: INFO: Created: latency-svc-z5dr4
Apr  1 18:21:55.499: INFO: Got endpoints: latency-svc-q9m9g [747.641773ms]
Apr  1 18:21:55.509: INFO: Created: latency-svc-czmkg
Apr  1 18:21:55.549: INFO: Got endpoints: latency-svc-qpb68 [747.868945ms]
Apr  1 18:21:55.561: INFO: Created: latency-svc-vw5t8
Apr  1 18:21:55.598: INFO: Got endpoints: latency-svc-xr22t [749.930455ms]
Apr  1 18:21:55.611: INFO: Created: latency-svc-xnl7r
Apr  1 18:21:55.649: INFO: Got endpoints: latency-svc-ddwz2 [750.052848ms]
Apr  1 18:21:55.659: INFO: Created: latency-svc-4m7hr
Apr  1 18:21:55.698: INFO: Got endpoints: latency-svc-bsdf5 [749.110749ms]
Apr  1 18:21:55.710: INFO: Created: latency-svc-zqljc
Apr  1 18:21:55.749: INFO: Got endpoints: latency-svc-rds7r [750.242451ms]
Apr  1 18:21:55.761: INFO: Created: latency-svc-m4794
Apr  1 18:21:55.799: INFO: Got endpoints: latency-svc-x8dbj [746.714702ms]
Apr  1 18:21:55.809: INFO: Created: latency-svc-mj8h8
Apr  1 18:21:55.850: INFO: Got endpoints: latency-svc-pllnz [751.08156ms]
Apr  1 18:21:55.861: INFO: Created: latency-svc-hsf8g
Apr  1 18:21:55.899: INFO: Got endpoints: latency-svc-k69gr [749.801063ms]
Apr  1 18:21:55.911: INFO: Created: latency-svc-vkdsz
Apr  1 18:21:55.949: INFO: Got endpoints: latency-svc-54bm7 [749.850129ms]
Apr  1 18:21:55.959: INFO: Created: latency-svc-xkl4k
Apr  1 18:21:55.998: INFO: Got endpoints: latency-svc-8krrs [749.825446ms]
Apr  1 18:21:56.009: INFO: Created: latency-svc-ff5rp
Apr  1 18:21:56.050: INFO: Got endpoints: latency-svc-mrnhf [750.833804ms]
Apr  1 18:21:56.062: INFO: Created: latency-svc-4f4gm
Apr  1 18:21:56.099: INFO: Got endpoints: latency-svc-pm9pn [749.776151ms]
Apr  1 18:21:56.110: INFO: Created: latency-svc-qd56l
Apr  1 18:21:56.149: INFO: Got endpoints: latency-svc-bbgtf [683.872434ms]
Apr  1 18:21:56.159: INFO: Created: latency-svc-8shcx
Apr  1 18:21:56.199: INFO: Got endpoints: latency-svc-z5dr4 [733.870311ms]
Apr  1 18:21:56.210: INFO: Created: latency-svc-srthv
Apr  1 18:21:56.249: INFO: Got endpoints: latency-svc-czmkg [750.398529ms]
Apr  1 18:21:56.260: INFO: Created: latency-svc-xkm58
Apr  1 18:21:56.301: INFO: Got endpoints: latency-svc-vw5t8 [752.257146ms]
Apr  1 18:21:56.311: INFO: Created: latency-svc-nqqtg
Apr  1 18:21:56.349: INFO: Got endpoints: latency-svc-xnl7r [750.835261ms]
Apr  1 18:21:56.362: INFO: Created: latency-svc-g29b2
Apr  1 18:21:56.399: INFO: Got endpoints: latency-svc-4m7hr [750.135497ms]
Apr  1 18:21:56.410: INFO: Created: latency-svc-4vbpk
Apr  1 18:21:56.449: INFO: Got endpoints: latency-svc-zqljc [751.003686ms]
Apr  1 18:21:56.460: INFO: Created: latency-svc-scv46
Apr  1 18:21:56.500: INFO: Got endpoints: latency-svc-m4794 [750.260871ms]
Apr  1 18:21:56.513: INFO: Created: latency-svc-gpbqp
Apr  1 18:21:56.549: INFO: Got endpoints: latency-svc-mj8h8 [750.541664ms]
Apr  1 18:21:56.560: INFO: Created: latency-svc-mvhvs
Apr  1 18:21:56.600: INFO: Got endpoints: latency-svc-hsf8g [749.91751ms]
Apr  1 18:21:56.610: INFO: Created: latency-svc-js92m
Apr  1 18:21:56.649: INFO: Got endpoints: latency-svc-vkdsz [749.751113ms]
Apr  1 18:21:56.661: INFO: Created: latency-svc-xjd9k
Apr  1 18:21:56.699: INFO: Got endpoints: latency-svc-xkl4k [750.570212ms]
Apr  1 18:21:56.715: INFO: Created: latency-svc-n26bn
Apr  1 18:21:56.749: INFO: Got endpoints: latency-svc-ff5rp [750.441357ms]
Apr  1 18:21:56.761: INFO: Created: latency-svc-g5wj5
Apr  1 18:21:56.799: INFO: Got endpoints: latency-svc-4f4gm [748.84762ms]
Apr  1 18:21:56.812: INFO: Created: latency-svc-6x8bj
Apr  1 18:21:56.850: INFO: Got endpoints: latency-svc-qd56l [750.76726ms]
Apr  1 18:21:56.861: INFO: Created: latency-svc-kcvtb
Apr  1 18:21:56.900: INFO: Got endpoints: latency-svc-8shcx [750.683605ms]
Apr  1 18:21:56.912: INFO: Created: latency-svc-hj2ng
Apr  1 18:21:56.951: INFO: Got endpoints: latency-svc-srthv [752.009661ms]
Apr  1 18:21:56.961: INFO: Created: latency-svc-n2v97
Apr  1 18:21:56.999: INFO: Got endpoints: latency-svc-xkm58 [750.218143ms]
Apr  1 18:21:57.011: INFO: Created: latency-svc-pbwbf
Apr  1 18:21:57.049: INFO: Got endpoints: latency-svc-nqqtg [748.326992ms]
Apr  1 18:21:57.061: INFO: Created: latency-svc-tq6b7
Apr  1 18:21:57.100: INFO: Got endpoints: latency-svc-g29b2 [751.049199ms]
Apr  1 18:21:57.112: INFO: Created: latency-svc-kks64
Apr  1 18:21:57.149: INFO: Got endpoints: latency-svc-4vbpk [750.26502ms]
Apr  1 18:21:57.161: INFO: Created: latency-svc-68fq5
Apr  1 18:21:57.199: INFO: Got endpoints: latency-svc-scv46 [749.314467ms]
Apr  1 18:21:57.211: INFO: Created: latency-svc-qrjlp
Apr  1 18:21:57.250: INFO: Got endpoints: latency-svc-gpbqp [750.31664ms]
Apr  1 18:21:57.261: INFO: Created: latency-svc-p5tpc
Apr  1 18:21:57.299: INFO: Got endpoints: latency-svc-mvhvs [750.107128ms]
Apr  1 18:21:57.311: INFO: Created: latency-svc-k58dr
Apr  1 18:21:57.349: INFO: Got endpoints: latency-svc-js92m [749.129874ms]
Apr  1 18:21:57.361: INFO: Created: latency-svc-qkjdk
Apr  1 18:21:57.400: INFO: Got endpoints: latency-svc-xjd9k [751.253669ms]
Apr  1 18:21:57.410: INFO: Created: latency-svc-rszzn
Apr  1 18:21:57.449: INFO: Got endpoints: latency-svc-n26bn [749.821913ms]
Apr  1 18:21:57.460: INFO: Created: latency-svc-ssdr9
Apr  1 18:21:57.500: INFO: Got endpoints: latency-svc-g5wj5 [751.0202ms]
Apr  1 18:21:57.512: INFO: Created: latency-svc-snl49
Apr  1 18:21:57.550: INFO: Got endpoints: latency-svc-6x8bj [751.268276ms]
Apr  1 18:21:57.561: INFO: Created: latency-svc-rpcdp
Apr  1 18:21:57.599: INFO: Got endpoints: latency-svc-kcvtb [749.442668ms]
Apr  1 18:21:57.610: INFO: Created: latency-svc-nkc84
Apr  1 18:21:57.649: INFO: Got endpoints: latency-svc-hj2ng [748.844356ms]
Apr  1 18:21:57.660: INFO: Created: latency-svc-rqdfz
Apr  1 18:21:57.699: INFO: Got endpoints: latency-svc-n2v97 [748.799361ms]
Apr  1 18:21:57.710: INFO: Created: latency-svc-gbxzs
Apr  1 18:21:57.752: INFO: Got endpoints: latency-svc-pbwbf [752.673909ms]
Apr  1 18:21:57.763: INFO: Created: latency-svc-k5q2v
Apr  1 18:21:57.799: INFO: Got endpoints: latency-svc-tq6b7 [749.016658ms]
Apr  1 18:21:57.812: INFO: Created: latency-svc-whkbp
Apr  1 18:21:57.849: INFO: Got endpoints: latency-svc-kks64 [748.390946ms]
Apr  1 18:21:57.860: INFO: Created: latency-svc-szlhh
Apr  1 18:21:57.899: INFO: Got endpoints: latency-svc-68fq5 [750.256298ms]
Apr  1 18:21:57.913: INFO: Created: latency-svc-4zk9w
Apr  1 18:21:57.949: INFO: Got endpoints: latency-svc-qrjlp [750.69459ms]
Apr  1 18:21:57.962: INFO: Created: latency-svc-gdj27
Apr  1 18:21:57.999: INFO: Got endpoints: latency-svc-p5tpc [749.214067ms]
Apr  1 18:21:58.012: INFO: Created: latency-svc-xzq22
Apr  1 18:21:58.049: INFO: Got endpoints: latency-svc-k58dr [749.446084ms]
Apr  1 18:21:58.060: INFO: Created: latency-svc-njkmd
Apr  1 18:21:58.099: INFO: Got endpoints: latency-svc-qkjdk [750.216981ms]
Apr  1 18:21:58.113: INFO: Created: latency-svc-2lplg
Apr  1 18:21:58.150: INFO: Got endpoints: latency-svc-rszzn [750.164196ms]
Apr  1 18:21:58.163: INFO: Created: latency-svc-mn6vm
Apr  1 18:21:58.199: INFO: Got endpoints: latency-svc-ssdr9 [750.186114ms]
Apr  1 18:21:58.212: INFO: Created: latency-svc-97dps
Apr  1 18:21:58.250: INFO: Got endpoints: latency-svc-snl49 [749.640201ms]
Apr  1 18:21:58.263: INFO: Created: latency-svc-kl5zt
Apr  1 18:21:58.300: INFO: Got endpoints: latency-svc-rpcdp [749.973347ms]
Apr  1 18:21:58.311: INFO: Created: latency-svc-b96p6
Apr  1 18:21:58.354: INFO: Got endpoints: latency-svc-nkc84 [754.455745ms]
Apr  1 18:21:58.368: INFO: Created: latency-svc-2jk2p
Apr  1 18:21:58.402: INFO: Got endpoints: latency-svc-rqdfz [753.310076ms]
Apr  1 18:21:58.419: INFO: Created: latency-svc-n2gcz
Apr  1 18:21:58.451: INFO: Got endpoints: latency-svc-gbxzs [751.628199ms]
Apr  1 18:21:58.470: INFO: Created: latency-svc-6rv7z
Apr  1 18:21:58.500: INFO: Got endpoints: latency-svc-k5q2v [747.720885ms]
Apr  1 18:21:58.511: INFO: Created: latency-svc-2v4gl
Apr  1 18:21:58.554: INFO: Got endpoints: latency-svc-whkbp [755.891307ms]
Apr  1 18:21:58.570: INFO: Created: latency-svc-skpc2
Apr  1 18:21:58.599: INFO: Got endpoints: latency-svc-szlhh [750.323253ms]
Apr  1 18:21:58.610: INFO: Created: latency-svc-27hm8
Apr  1 18:21:58.650: INFO: Got endpoints: latency-svc-4zk9w [750.639095ms]
Apr  1 18:21:58.664: INFO: Created: latency-svc-mc2n5
Apr  1 18:21:58.699: INFO: Got endpoints: latency-svc-gdj27 [749.916635ms]
Apr  1 18:21:58.712: INFO: Created: latency-svc-6q4pm
Apr  1 18:21:58.749: INFO: Got endpoints: latency-svc-xzq22 [749.926034ms]
Apr  1 18:21:58.761: INFO: Created: latency-svc-bzmv8
Apr  1 18:21:58.799: INFO: Got endpoints: latency-svc-njkmd [749.638559ms]
Apr  1 18:21:58.811: INFO: Created: latency-svc-2zjds
Apr  1 18:21:58.849: INFO: Got endpoints: latency-svc-2lplg [750.18679ms]
Apr  1 18:21:58.865: INFO: Created: latency-svc-f6k5c
Apr  1 18:21:58.899: INFO: Got endpoints: latency-svc-mn6vm [749.352052ms]
Apr  1 18:21:58.911: INFO: Created: latency-svc-pngz9
Apr  1 18:21:58.950: INFO: Got endpoints: latency-svc-97dps [750.529433ms]
Apr  1 18:21:58.966: INFO: Created: latency-svc-dcns4
Apr  1 18:21:59.003: INFO: Got endpoints: latency-svc-kl5zt [753.523397ms]
Apr  1 18:21:59.015: INFO: Created: latency-svc-8qqdx
Apr  1 18:21:59.052: INFO: Got endpoints: latency-svc-b96p6 [751.467421ms]
Apr  1 18:21:59.067: INFO: Created: latency-svc-6m2mj
Apr  1 18:21:59.100: INFO: Got endpoints: latency-svc-2jk2p [746.154609ms]
Apr  1 18:21:59.111: INFO: Created: latency-svc-k9dvk
Apr  1 18:21:59.159: INFO: Got endpoints: latency-svc-n2gcz [757.274746ms]
Apr  1 18:21:59.170: INFO: Created: latency-svc-j4v8k
Apr  1 18:21:59.200: INFO: Got endpoints: latency-svc-6rv7z [748.657476ms]
Apr  1 18:21:59.214: INFO: Created: latency-svc-tw5wp
Apr  1 18:21:59.249: INFO: Got endpoints: latency-svc-2v4gl [749.431513ms]
Apr  1 18:21:59.262: INFO: Created: latency-svc-zlrbs
Apr  1 18:21:59.299: INFO: Got endpoints: latency-svc-skpc2 [744.353508ms]
Apr  1 18:21:59.315: INFO: Created: latency-svc-tlqq7
Apr  1 18:21:59.351: INFO: Got endpoints: latency-svc-27hm8 [752.076979ms]
Apr  1 18:21:59.366: INFO: Created: latency-svc-5hfhn
Apr  1 18:21:59.399: INFO: Got endpoints: latency-svc-mc2n5 [748.359303ms]
Apr  1 18:21:59.410: INFO: Created: latency-svc-fwshw
Apr  1 18:21:59.450: INFO: Got endpoints: latency-svc-6q4pm [751.167366ms]
Apr  1 18:21:59.893: INFO: Got endpoints: latency-svc-bzmv8 [1.1437096s]
Apr  1 18:21:59.893: INFO: Got endpoints: latency-svc-2zjds [1.094498849s]
Apr  1 18:21:59.894: INFO: Got endpoints: latency-svc-dcns4 [944.461347ms]
Apr  1 18:21:59.894: INFO: Got endpoints: latency-svc-f6k5c [1.045211329s]
Apr  1 18:21:59.894: INFO: Got endpoints: latency-svc-pngz9 [994.981684ms]
Apr  1 18:21:59.898: INFO: Created: latency-svc-t682m
Apr  1 18:21:59.904: INFO: Got endpoints: latency-svc-8qqdx [901.072682ms]
Apr  1 18:21:59.905: INFO: Got endpoints: latency-svc-6m2mj [853.383313ms]
Apr  1 18:21:59.909: INFO: Got endpoints: latency-svc-j4v8k [749.243536ms]
Apr  1 18:21:59.909: INFO: Got endpoints: latency-svc-k9dvk [809.054252ms]
Apr  1 18:21:59.909: INFO: Created: latency-svc-qc585
Apr  1 18:21:59.917: INFO: Created: latency-svc-nmsq7
Apr  1 18:21:59.926: INFO: Created: latency-svc-mqft7
Apr  1 18:21:59.932: INFO: Created: latency-svc-wzzlg
Apr  1 18:21:59.939: INFO: Created: latency-svc-tf7l8
Apr  1 18:21:59.949: INFO: Got endpoints: latency-svc-tw5wp [749.579334ms]
Apr  1 18:21:59.956: INFO: Created: latency-svc-nk4dt
Apr  1 18:21:59.962: INFO: Created: latency-svc-9c89b
Apr  1 18:21:59.970: INFO: Created: latency-svc-xkgkr
Apr  1 18:21:59.976: INFO: Created: latency-svc-z7r8w
Apr  1 18:21:59.984: INFO: Created: latency-svc-c9tvb
Apr  1 18:22:00.029: INFO: Got endpoints: latency-svc-zlrbs [779.829949ms]
Apr  1 18:22:00.088: INFO: Got endpoints: latency-svc-tlqq7 [788.876923ms]
Apr  1 18:22:00.091: INFO: Created: latency-svc-c4bhx
Apr  1 18:22:00.099: INFO: Got endpoints: latency-svc-5hfhn [747.98547ms]
Apr  1 18:22:00.100: INFO: Created: latency-svc-5g958
Apr  1 18:22:00.111: INFO: Created: latency-svc-tlmgj
Apr  1 18:22:00.149: INFO: Got endpoints: latency-svc-fwshw [750.367291ms]
Apr  1 18:22:00.160: INFO: Created: latency-svc-lfrw8
Apr  1 18:22:00.199: INFO: Got endpoints: latency-svc-t682m [748.869614ms]
Apr  1 18:22:00.210: INFO: Created: latency-svc-f8l7c
Apr  1 18:22:00.249: INFO: Got endpoints: latency-svc-qc585 [355.86799ms]
Apr  1 18:22:00.261: INFO: Created: latency-svc-d6bds
Apr  1 18:22:00.300: INFO: Got endpoints: latency-svc-nmsq7 [406.757418ms]
Apr  1 18:22:00.311: INFO: Created: latency-svc-zlvws
Apr  1 18:22:00.351: INFO: Got endpoints: latency-svc-mqft7 [456.148628ms]
Apr  1 18:22:00.363: INFO: Created: latency-svc-rsrk6
Apr  1 18:22:00.400: INFO: Got endpoints: latency-svc-wzzlg [505.42401ms]
Apr  1 18:22:00.420: INFO: Created: latency-svc-gj4kh
Apr  1 18:22:00.450: INFO: Got endpoints: latency-svc-tf7l8 [555.463234ms]
Apr  1 18:22:00.464: INFO: Created: latency-svc-hfq2d
Apr  1 18:22:00.504: INFO: Got endpoints: latency-svc-nk4dt [599.578726ms]
Apr  1 18:22:00.516: INFO: Created: latency-svc-twqdp
Apr  1 18:22:00.549: INFO: Got endpoints: latency-svc-9c89b [644.057075ms]
Apr  1 18:22:00.560: INFO: Created: latency-svc-5mjtc
Apr  1 18:22:00.599: INFO: Got endpoints: latency-svc-xkgkr [690.578047ms]
Apr  1 18:22:00.611: INFO: Created: latency-svc-d6x2l
Apr  1 18:22:00.650: INFO: Got endpoints: latency-svc-z7r8w [741.257701ms]
Apr  1 18:22:00.662: INFO: Created: latency-svc-vjd2d
Apr  1 18:22:00.699: INFO: Got endpoints: latency-svc-c9tvb [749.567526ms]
Apr  1 18:22:00.710: INFO: Created: latency-svc-qk9mr
Apr  1 18:22:00.749: INFO: Got endpoints: latency-svc-c4bhx [719.806989ms]
Apr  1 18:22:00.759: INFO: Created: latency-svc-4gdtz
Apr  1 18:22:00.800: INFO: Got endpoints: latency-svc-5g958 [711.833046ms]
Apr  1 18:22:00.812: INFO: Created: latency-svc-g4xxf
Apr  1 18:22:00.849: INFO: Got endpoints: latency-svc-tlmgj [748.95604ms]
Apr  1 18:22:00.860: INFO: Created: latency-svc-5q9lv
Apr  1 18:22:00.902: INFO: Got endpoints: latency-svc-lfrw8 [752.992203ms]
Apr  1 18:22:00.915: INFO: Created: latency-svc-2tqvk
Apr  1 18:22:00.949: INFO: Got endpoints: latency-svc-f8l7c [749.923046ms]
Apr  1 18:22:00.960: INFO: Created: latency-svc-t9g2n
Apr  1 18:22:01.001: INFO: Got endpoints: latency-svc-d6bds [751.913901ms]
Apr  1 18:22:01.413: INFO: Created: latency-svc-k5cs5
Apr  1 18:22:01.413: INFO: Got endpoints: latency-svc-zlvws [1.113179221s]
Apr  1 18:22:01.416: INFO: Got endpoints: latency-svc-rsrk6 [1.065698015s]
Apr  1 18:22:01.417: INFO: Got endpoints: latency-svc-twqdp [913.022055ms]
Apr  1 18:22:01.417: INFO: Got endpoints: latency-svc-gj4kh [1.016913193s]
Apr  1 18:22:01.417: INFO: Got endpoints: latency-svc-hfq2d [967.10402ms]
Apr  1 18:22:01.435: INFO: Got endpoints: latency-svc-vjd2d [785.069996ms]
Apr  1 18:22:01.435: INFO: Got endpoints: latency-svc-5mjtc [886.229028ms]
Apr  1 18:22:01.435: INFO: Got endpoints: latency-svc-d6x2l [835.90142ms]
Apr  1 18:22:01.436: INFO: Created: latency-svc-dt4ps
Apr  1 18:22:01.445: INFO: Created: latency-svc-q9zrw
Apr  1 18:22:01.450: INFO: Got endpoints: latency-svc-qk9mr [750.731403ms]
Apr  1 18:22:01.452: INFO: Created: latency-svc-6bjq8
Apr  1 18:22:01.499: INFO: Got endpoints: latency-svc-4gdtz [749.848524ms]
Apr  1 18:22:01.550: INFO: Got endpoints: latency-svc-g4xxf [750.730646ms]
Apr  1 18:22:01.599: INFO: Got endpoints: latency-svc-5q9lv [750.484886ms]
Apr  1 18:22:01.649: INFO: Got endpoints: latency-svc-2tqvk [746.644364ms]
Apr  1 18:22:01.699: INFO: Got endpoints: latency-svc-t9g2n [749.878576ms]
Apr  1 18:22:01.749: INFO: Got endpoints: latency-svc-k5cs5 [748.260548ms]
Apr  1 18:22:01.799: INFO: Got endpoints: latency-svc-dt4ps [385.74752ms]
Apr  1 18:22:01.850: INFO: Got endpoints: latency-svc-q9zrw [433.159447ms]
Apr  1 18:22:01.902: INFO: Got endpoints: latency-svc-6bjq8 [485.36392ms]
Apr  1 18:22:01.902: INFO: Latencies: [22.965146ms 30.415704ms 62.641643ms 65.501076ms 65.554405ms 69.551852ms 108.654413ms 109.070957ms 109.477747ms 109.827307ms 109.905138ms 110.437263ms 111.80222ms 112.466223ms 112.958086ms 113.318286ms 113.88842ms 114.064512ms 114.810671ms 116.163414ms 117.429062ms 117.627893ms 118.483212ms 119.066812ms 120.197046ms 122.116494ms 124.982702ms 151.279149ms 191.950332ms 237.129777ms 277.293172ms 319.608652ms 355.86799ms 359.277099ms 385.74752ms 405.453772ms 406.757418ms 433.159447ms 444.233811ms 456.148628ms 485.026496ms 485.36392ms 505.42401ms 525.938991ms 555.463234ms 565.864951ms 567.618568ms 571.958591ms 578.614155ms 594.278115ms 596.782276ms 599.578726ms 604.122772ms 607.624982ms 607.912639ms 608.044127ms 608.108477ms 610.53231ms 611.940823ms 619.561353ms 621.902605ms 621.993844ms 644.057075ms 653.460158ms 683.872434ms 690.578047ms 711.833046ms 713.55881ms 713.766397ms 719.806989ms 720.597611ms 730.437733ms 733.870311ms 738.353116ms 740.116172ms 740.297447ms 741.257701ms 744.353508ms 746.154609ms 746.644364ms 746.714702ms 747.641773ms 747.720885ms 747.868945ms 747.98547ms 748.260548ms 748.326992ms 748.359303ms 748.390946ms 748.531722ms 748.657476ms 748.799361ms 748.844356ms 748.84762ms 748.869614ms 748.95604ms 749.016658ms 749.110749ms 749.129874ms 749.214067ms 749.221059ms 749.243536ms 749.314467ms 749.352052ms 749.431513ms 749.442668ms 749.446084ms 749.567526ms 749.579334ms 749.638559ms 749.640201ms 749.751113ms 749.776151ms 749.801063ms 749.821913ms 749.825446ms 749.848524ms 749.850129ms 749.878576ms 749.916635ms 749.91751ms 749.923046ms 749.926034ms 749.930455ms 749.973347ms 750.052848ms 750.107128ms 750.135497ms 750.164196ms 750.186114ms 750.18679ms 750.216981ms 750.218143ms 750.242451ms 750.256298ms 750.260871ms 750.26502ms 750.31664ms 750.323253ms 750.367291ms 750.398529ms 750.441357ms 750.484886ms 750.529433ms 750.541664ms 750.570212ms 750.639095ms 750.683605ms 750.69459ms 750.730646ms 750.731403ms 750.76726ms 750.833804ms 750.835261ms 751.003686ms 751.0202ms 751.049199ms 751.08156ms 751.167366ms 751.253669ms 751.268276ms 751.467421ms 751.628199ms 751.913901ms 752.009661ms 752.076979ms 752.257146ms 752.673909ms 752.797513ms 752.992203ms 753.310076ms 753.523397ms 754.455745ms 755.891307ms 757.274746ms 760.015224ms 763.456741ms 765.189919ms 769.404143ms 770.740822ms 771.373141ms 779.829949ms 785.069996ms 788.876923ms 809.054252ms 835.90142ms 853.383313ms 886.229028ms 901.072682ms 913.022055ms 944.461347ms 967.10402ms 994.981684ms 1.016913193s 1.045211329s 1.065698015s 1.094498849s 1.113179221s 1.1437096s 1.239546119s]
Apr  1 18:22:01.903: INFO: 50 %ile: 749.221059ms
Apr  1 18:22:01.903: INFO: 90 %ile: 771.373141ms
Apr  1 18:22:01.903: INFO: 99 %ile: 1.1437096s
Apr  1 18:22:01.903: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:22:01.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-4483" for this suite.
Apr  1 18:22:15.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:22:16.043: INFO: namespace svc-latency-4483 deletion completed in 14.135900833s

• [SLOW TEST:25.173 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:22:16.044: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Apr  1 18:22:16.110: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-814,SelfLink:/api/v1/namespaces/watch-814/configmaps/e2e-watch-test-label-changed,UID:13e169a3-54ab-11e9-9aab-028387864c62,ResourceVersion:21871,Generation:0,CreationTimestamp:2019-04-01 18:22:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr  1 18:22:16.111: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-814,SelfLink:/api/v1/namespaces/watch-814/configmaps/e2e-watch-test-label-changed,UID:13e169a3-54ab-11e9-9aab-028387864c62,ResourceVersion:21872,Generation:0,CreationTimestamp:2019-04-01 18:22:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Apr  1 18:22:16.111: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-814,SelfLink:/api/v1/namespaces/watch-814/configmaps/e2e-watch-test-label-changed,UID:13e169a3-54ab-11e9-9aab-028387864c62,ResourceVersion:21873,Generation:0,CreationTimestamp:2019-04-01 18:22:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Apr  1 18:22:26.144: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-814,SelfLink:/api/v1/namespaces/watch-814/configmaps/e2e-watch-test-label-changed,UID:13e169a3-54ab-11e9-9aab-028387864c62,ResourceVersion:21892,Generation:0,CreationTimestamp:2019-04-01 18:22:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr  1 18:22:26.145: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-814,SelfLink:/api/v1/namespaces/watch-814/configmaps/e2e-watch-test-label-changed,UID:13e169a3-54ab-11e9-9aab-028387864c62,ResourceVersion:21893,Generation:0,CreationTimestamp:2019-04-01 18:22:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Apr  1 18:22:26.145: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-814,SelfLink:/api/v1/namespaces/watch-814/configmaps/e2e-watch-test-label-changed,UID:13e169a3-54ab-11e9-9aab-028387864c62,ResourceVersion:21894,Generation:0,CreationTimestamp:2019-04-01 18:22:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:22:26.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-814" for this suite.
Apr  1 18:22:32.163: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:22:32.274: INFO: namespace watch-814 deletion completed in 6.125101919s

• [SLOW TEST:16.230 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:22:32.274: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr  1 18:22:32.324: INFO: Waiting up to 5m0s for pod "downward-api-1d888033-54ab-11e9-871e-828ee0b576f8" in namespace "downward-api-9336" to be "success or failure"
Apr  1 18:22:32.330: INFO: Pod "downward-api-1d888033-54ab-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.479199ms
Apr  1 18:22:34.338: INFO: Pod "downward-api-1d888033-54ab-11e9-871e-828ee0b576f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014494205s
Apr  1 18:22:36.344: INFO: Pod "downward-api-1d888033-54ab-11e9-871e-828ee0b576f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02028739s
STEP: Saw pod success
Apr  1 18:22:36.344: INFO: Pod "downward-api-1d888033-54ab-11e9-871e-828ee0b576f8" satisfied condition "success or failure"
Apr  1 18:22:36.348: INFO: Trying to get logs from node ip-172-31-3-176 pod downward-api-1d888033-54ab-11e9-871e-828ee0b576f8 container dapi-container: <nil>
STEP: delete the pod
Apr  1 18:22:36.368: INFO: Waiting for pod downward-api-1d888033-54ab-11e9-871e-828ee0b576f8 to disappear
Apr  1 18:22:36.371: INFO: Pod downward-api-1d888033-54ab-11e9-871e-828ee0b576f8 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:22:36.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9336" for this suite.
Apr  1 18:22:42.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:22:42.496: INFO: namespace downward-api-9336 deletion completed in 6.121382109s

• [SLOW TEST:10.222 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:22:42.496: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-6390
Apr  1 18:22:44.551: INFO: Started pod liveness-http in namespace container-probe-6390
STEP: checking the pod's current state and verifying that restartCount is present
Apr  1 18:22:44.555: INFO: Initial restart count of pod liveness-http is 0
Apr  1 18:23:06.609: INFO: Restart count of pod container-probe-6390/liveness-http is now 1 (22.05403325s elapsed)
Apr  1 18:23:26.667: INFO: Restart count of pod container-probe-6390/liveness-http is now 2 (42.111875335s elapsed)
Apr  1 18:23:46.723: INFO: Restart count of pod container-probe-6390/liveness-http is now 3 (1m2.168339529s elapsed)
Apr  1 18:24:07.203: INFO: Restart count of pod container-probe-6390/liveness-http is now 4 (1m22.647626795s elapsed)
Apr  1 18:25:19.399: INFO: Restart count of pod container-probe-6390/liveness-http is now 5 (2m34.844466163s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:25:19.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6390" for this suite.
Apr  1 18:25:25.431: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:25:25.550: INFO: namespace container-probe-6390 deletion completed in 6.132776936s

• [SLOW TEST:163.054 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:25:25.551: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  1 18:25:25.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 version --client'
Apr  1 18:25:25.669: INFO: stderr: ""
Apr  1 18:25:25.669: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.0\", GitCommit:\"641856db18352033a0d96dbc99153fa3b27298e5\", GitTreeState:\"clean\", BuildDate:\"2019-03-25T15:53:57Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Apr  1 18:25:25.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 create -f - --namespace=kubectl-1153'
Apr  1 18:25:26.189: INFO: stderr: ""
Apr  1 18:25:26.189: INFO: stdout: "replicationcontroller/redis-master created\n"
Apr  1 18:25:26.189: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 create -f - --namespace=kubectl-1153'
Apr  1 18:25:26.387: INFO: stderr: ""
Apr  1 18:25:26.387: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Apr  1 18:25:27.391: INFO: Selector matched 1 pods for map[app:redis]
Apr  1 18:25:27.391: INFO: Found 0 / 1
Apr  1 18:25:28.391: INFO: Selector matched 1 pods for map[app:redis]
Apr  1 18:25:28.391: INFO: Found 1 / 1
Apr  1 18:25:28.391: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr  1 18:25:28.395: INFO: Selector matched 1 pods for map[app:redis]
Apr  1 18:25:28.395: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr  1 18:25:28.395: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 describe pod redis-master-ttgsf --namespace=kubectl-1153'
Apr  1 18:25:28.517: INFO: stderr: ""
Apr  1 18:25:28.517: INFO: stdout: "Name:           redis-master-ttgsf\nNamespace:      kubectl-1153\nNode:           ip-172-31-3-176/172.31.3.176\nStart Time:     Mon, 01 Apr 2019 18:25:26 +0000\nLabels:         app=redis\n                role=master\nAnnotations:    <none>\nStatus:         Running\nIP:             10.1.83.241\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://77c7512c4a7daad388e7f77d1676fa3ab51c588b9e31f84eda33a27c772e8765\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 01 Apr 2019 18:25:27 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-jr9q4 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-jr9q4:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-jr9q4\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                      Message\n  ----    ------     ----  ----                      -------\n  Normal  Scheduled  2s    default-scheduler         Successfully assigned kubectl-1153/redis-master-ttgsf to ip-172-31-3-176\n  Normal  Pulled     1s    kubelet, ip-172-31-3-176  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, ip-172-31-3-176  Created container redis-master\n  Normal  Started    1s    kubelet, ip-172-31-3-176  Started container redis-master\n"
Apr  1 18:25:28.517: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 describe rc redis-master --namespace=kubectl-1153'
Apr  1 18:25:29.022: INFO: stderr: ""
Apr  1 18:25:29.023: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-1153\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-ttgsf\n"
Apr  1 18:25:29.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 describe service redis-master --namespace=kubectl-1153'
Apr  1 18:25:29.127: INFO: stderr: ""
Apr  1 18:25:29.127: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-1153\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.152.183.25\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.1.83.241:6379\nSession Affinity:  None\nEvents:            <none>\n"
Apr  1 18:25:29.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 describe node ip-172-31-22-24'
Apr  1 18:25:29.288: INFO: stderr: ""
Apr  1 18:25:29.288: INFO: stdout: "Name:               ip-172-31-22-24\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    juju-application=kubernetes-worker\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ip-172-31-22-24\n                    kubernetes.io/os=linux\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 01 Apr 2019 16:46:38 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Mon, 01 Apr 2019 18:24:38 +0000   Mon, 01 Apr 2019 16:46:38 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Mon, 01 Apr 2019 18:24:38 +0000   Mon, 01 Apr 2019 16:46:38 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Mon, 01 Apr 2019 18:24:38 +0000   Mon, 01 Apr 2019 16:46:38 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Mon, 01 Apr 2019 18:24:38 +0000   Mon, 01 Apr 2019 16:55:11 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  172.31.22.24\n  Hostname:    ip-172-31-22-24\nCapacity:\n cpu:                4\n ephemeral-storage:  16197480Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16235508Ki\n pods:               110\nAllocatable:\n cpu:                4\n ephemeral-storage:  14927597544\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16133108Ki\n pods:               110\nSystem Info:\n Machine ID:                       ec208e9088ae032794f27b742fe897cc\n System UUID:                      EC208E90-88AE-0327-94F2-7B742FE897CC\n Boot ID:                          e0287eba-e4ff-41ea-bb5f-4a251c4c773b\n Kernel Version:                   4.15.0-1034-aws\n OS Image:                         Ubuntu 18.04.2 LTS\n Operating System:                 linux\n Architecture:                     amd64\n Container Runtime Version:        docker://18.9.2\n Kubelet Version:                  v1.14.0\n Kube-Proxy Version:               v1.14.0\nNon-terminated Pods:               (7 in total)\n  Namespace                        Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                        ----                                                       ------------  ----------  ---------------  -------------  ---\n  heptio-sonobuoy                  sonobuoy-systemd-logs-daemon-set-1ce1df115e164dcd-4wc8p    0 (0%)        0 (0%)      0 (0%)           0 (0%)         91m\n  ingress-nginx-kubernetes-worker  default-http-backend-kubernetes-worker-5b8b477c-swdj9      10m (0%)      10m (0%)    20Mi (0%)        20Mi (0%)      98m\n  ingress-nginx-kubernetes-worker  nginx-ingress-controller-kubernetes-worker-xt5ts           0 (0%)        0 (0%)      0 (0%)           0 (0%)         98m\n  kube-system                      coredns-6b957bfc77-lmplw                                   100m (2%)     0 (0%)      70Mi (0%)        170Mi (1%)     99m\n  kube-system                      coredns-6b957bfc77-w7lct                                   100m (2%)     0 (0%)      70Mi (0%)        170Mi (1%)     99m\n  kube-system                      kubernetes-dashboard-9f49769c8-bnt5k                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         99m\n  kube-system                      monitoring-influxdb-grafana-v4-cfc94db54-csmb5             200m (5%)     200m (5%)   600Mi (3%)       600Mi (3%)     99m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                410m (10%)  210m (5%)\n  memory             760Mi (4%)  960Mi (6%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:              <none>\n"
Apr  1 18:25:29.288: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994794615 describe namespace kubectl-1153'
Apr  1 18:25:29.402: INFO: stderr: ""
Apr  1 18:25:29.402: INFO: stdout: "Name:         kubectl-1153\nLabels:       e2e-framework=kubectl\n              e2e-run=c7e07883-549e-11e9-871e-828ee0b576f8\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:25:29.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1153" for this suite.
Apr  1 18:25:51.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:25:51.752: INFO: namespace kubectl-1153 deletion completed in 22.346113745s

• [SLOW TEST:26.201 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:25:51.752: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  1 18:25:51.791: INFO: Creating ReplicaSet my-hostname-basic-946e66a1-54ab-11e9-871e-828ee0b576f8
Apr  1 18:25:51.803: INFO: Pod name my-hostname-basic-946e66a1-54ab-11e9-871e-828ee0b576f8: Found 0 pods out of 1
Apr  1 18:25:56.808: INFO: Pod name my-hostname-basic-946e66a1-54ab-11e9-871e-828ee0b576f8: Found 1 pods out of 1
Apr  1 18:25:56.808: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-946e66a1-54ab-11e9-871e-828ee0b576f8" is running
Apr  1 18:25:56.812: INFO: Pod "my-hostname-basic-946e66a1-54ab-11e9-871e-828ee0b576f8-xwtvv" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-01 18:25:52 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-01 18:25:53 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-01 18:25:53 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-01 18:25:51 +0000 UTC Reason: Message:}])
Apr  1 18:25:56.812: INFO: Trying to dial the pod
Apr  1 18:26:01.824: INFO: Controller my-hostname-basic-946e66a1-54ab-11e9-871e-828ee0b576f8: Got expected result from replica 1 [my-hostname-basic-946e66a1-54ab-11e9-871e-828ee0b576f8-xwtvv]: "my-hostname-basic-946e66a1-54ab-11e9-871e-828ee0b576f8-xwtvv", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:26:01.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-7296" for this suite.
Apr  1 18:26:07.842: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:26:07.955: INFO: namespace replicaset-7296 deletion completed in 6.126011225s

• [SLOW TEST:16.203 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:26:07.955: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-secret-r9cx
STEP: Creating a pod to test atomic-volume-subpath
Apr  1 18:26:08.365: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-r9cx" in namespace "subpath-6045" to be "success or failure"
Apr  1 18:26:08.371: INFO: Pod "pod-subpath-test-secret-r9cx": Phase="Pending", Reason="", readiness=false. Elapsed: 6.23145ms
Apr  1 18:26:10.376: INFO: Pod "pod-subpath-test-secret-r9cx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010842142s
Apr  1 18:26:12.380: INFO: Pod "pod-subpath-test-secret-r9cx": Phase="Running", Reason="", readiness=true. Elapsed: 4.01553997s
Apr  1 18:26:14.386: INFO: Pod "pod-subpath-test-secret-r9cx": Phase="Running", Reason="", readiness=true. Elapsed: 6.02129864s
Apr  1 18:26:16.392: INFO: Pod "pod-subpath-test-secret-r9cx": Phase="Running", Reason="", readiness=true. Elapsed: 8.026907229s
Apr  1 18:26:18.397: INFO: Pod "pod-subpath-test-secret-r9cx": Phase="Running", Reason="", readiness=true. Elapsed: 10.031695118s
Apr  1 18:26:20.401: INFO: Pod "pod-subpath-test-secret-r9cx": Phase="Running", Reason="", readiness=true. Elapsed: 12.036120475s
Apr  1 18:26:22.407: INFO: Pod "pod-subpath-test-secret-r9cx": Phase="Running", Reason="", readiness=true. Elapsed: 14.041772158s
Apr  1 18:26:24.421: INFO: Pod "pod-subpath-test-secret-r9cx": Phase="Running", Reason="", readiness=true. Elapsed: 16.056620161s
Apr  1 18:26:26.426: INFO: Pod "pod-subpath-test-secret-r9cx": Phase="Running", Reason="", readiness=true. Elapsed: 18.061464782s
Apr  1 18:26:28.431: INFO: Pod "pod-subpath-test-secret-r9cx": Phase="Running", Reason="", readiness=true. Elapsed: 20.066410752s
Apr  1 18:26:30.436: INFO: Pod "pod-subpath-test-secret-r9cx": Phase="Running", Reason="", readiness=true. Elapsed: 22.071167897s
Apr  1 18:26:32.441: INFO: Pod "pod-subpath-test-secret-r9cx": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.075658947s
STEP: Saw pod success
Apr  1 18:26:32.441: INFO: Pod "pod-subpath-test-secret-r9cx" satisfied condition "success or failure"
Apr  1 18:26:32.445: INFO: Trying to get logs from node ip-172-31-3-176 pod pod-subpath-test-secret-r9cx container test-container-subpath-secret-r9cx: <nil>
STEP: delete the pod
Apr  1 18:26:32.469: INFO: Waiting for pod pod-subpath-test-secret-r9cx to disappear
Apr  1 18:26:32.473: INFO: Pod pod-subpath-test-secret-r9cx no longer exists
STEP: Deleting pod pod-subpath-test-secret-r9cx
Apr  1 18:26:32.473: INFO: Deleting pod "pod-subpath-test-secret-r9cx" in namespace "subpath-6045"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:26:32.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6045" for this suite.
Apr  1 18:26:38.497: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:26:38.610: INFO: namespace subpath-6045 deletion completed in 6.128178128s

• [SLOW TEST:30.655 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  1 18:26:38.610: INFO: >>> kubeConfig: /tmp/kubeconfig-994794615
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service endpoint-test2 in namespace services-996
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-996 to expose endpoints map[]
Apr  1 18:26:38.668: INFO: successfully validated that service endpoint-test2 in namespace services-996 exposes endpoints map[] (5.222484ms elapsed)
STEP: Creating pod pod1 in namespace services-996
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-996 to expose endpoints map[pod1:[80]]
Apr  1 18:26:40.704: INFO: successfully validated that service endpoint-test2 in namespace services-996 exposes endpoints map[pod1:[80]] (2.022869223s elapsed)
STEP: Creating pod pod2 in namespace services-996
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-996 to expose endpoints map[pod1:[80] pod2:[80]]
Apr  1 18:26:43.762: INFO: successfully validated that service endpoint-test2 in namespace services-996 exposes endpoints map[pod1:[80] pod2:[80]] (3.051050538s elapsed)
STEP: Deleting pod pod1 in namespace services-996
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-996 to expose endpoints map[pod2:[80]]
Apr  1 18:26:44.791: INFO: successfully validated that service endpoint-test2 in namespace services-996 exposes endpoints map[pod2:[80]] (1.022527934s elapsed)
STEP: Deleting pod pod2 in namespace services-996
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-996 to expose endpoints map[]
Apr  1 18:26:45.809: INFO: successfully validated that service endpoint-test2 in namespace services-996 exposes endpoints map[] (1.009067764s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  1 18:26:45.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-996" for this suite.
Apr  1 18:27:07.848: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  1 18:27:08.076: INFO: namespace services-996 deletion completed in 22.242658068s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:29.466 seconds]
[sig-network] Services
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSApr  1 18:27:08.076: INFO: Running AfterSuite actions on all nodes
Apr  1 18:27:08.076: INFO: Running AfterSuite actions on node 1
Apr  1 18:27:08.076: INFO: Skipping dumping logs from cluster

Ran 204 of 3584 Specs in 5572.432 seconds
SUCCESS! -- 204 Passed | 0 Failed | 0 Pending | 3380 Skipped PASS

Ginkgo ran 1 suite in 1h32m53.523226759s
Test Suite Passed
