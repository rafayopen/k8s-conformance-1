I1121 08:10:41.775165      17 test_context.go:405] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-073157133
I1121 08:10:41.775347      17 e2e.go:240] Starting e2e run "681fa7d8-0c36-11ea-a569-4e55f5a7674f" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1574323839 - Will randomize all specs
Will run 204 of 3584 specs

Nov 21 08:10:41.967: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
Nov 21 08:10:41.971: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Nov 21 08:10:42.001: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Nov 21 08:10:42.020: INFO: 3 / 3 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Nov 21 08:10:42.020: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
Nov 21 08:10:42.020: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Nov 21 08:10:42.025: INFO: e2e test version: v1.14.1
Nov 21 08:10:42.026: INFO: kube-apiserver version: v1.14.1
SSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:10:42.026: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename sched-pred
Nov 21 08:10:42.091: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Nov 21 08:10:42.092: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov 21 08:10:42.096: INFO: Waiting for terminating namespaces to be deleted...
Nov 21 08:10:42.097: INFO: 
Logging pods the kubelet thinks is on node 192.168.0.92 before test
Nov 21 08:10:42.106: INFO: ckecsi-provisioner-0 from default started at 2019-11-21 06:54:20 +0000 UTC (1 container statuses recorded)
Nov 21 08:10:42.106: INFO: 	Container ckecsi-provisioner ready: true, restart count 0
Nov 21 08:10:42.106: INFO: kubernetes-dashboard-7767bf47b6-sflp4 from kube-system started at 2019-11-21 06:54:20 +0000 UTC (1 container statuses recorded)
Nov 21 08:10:42.106: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Nov 21 08:10:42.106: INFO: ckecsi-57xl8 from default started at 2019-11-21 06:54:21 +0000 UTC (2 container statuses recorded)
Nov 21 08:10:42.106: INFO: 	Container ckecsi ready: true, restart count 0
Nov 21 08:10:42.106: INFO: 	Container driver-registrar ready: true, restart count 0
Nov 21 08:10:42.106: INFO: ckecsi-attacher-1 from default started at 2019-11-21 06:55:05 +0000 UTC (1 container statuses recorded)
Nov 21 08:10:42.106: INFO: 	Container ckecsi-attacher ready: true, restart count 0
Nov 21 08:10:42.106: INFO: sonobuoy-e2e-job-56ce796c30644ea3 from sonobuoy started at 2019-11-21 08:10:37 +0000 UTC (2 container statuses recorded)
Nov 21 08:10:42.106: INFO: 	Container e2e ready: true, restart count 0
Nov 21 08:10:42.106: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 21 08:10:42.106: INFO: 
Logging pods the kubelet thinks is on node 192.168.0.93 before test
Nov 21 08:10:42.115: INFO: sonobuoy from sonobuoy started at 2019-11-21 08:10:34 +0000 UTC (1 container statuses recorded)
Nov 21 08:10:42.115: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov 21 08:10:42.115: INFO: coredns-67b8c5b5d8-6lncm from kube-system started at 2019-11-21 06:54:21 +0000 UTC (1 container statuses recorded)
Nov 21 08:10:42.115: INFO: 	Container coredns ready: true, restart count 0
Nov 21 08:10:42.115: INFO: ckecsi-attacher-0 from default started at 2019-11-21 06:54:21 +0000 UTC (1 container statuses recorded)
Nov 21 08:10:42.115: INFO: 	Container ckecsi-attacher ready: true, restart count 0
Nov 21 08:10:42.115: INFO: calico-kube-controllers-79fd644cdf-nj4bj from kube-system started at 2019-11-21 06:54:21 +0000 UTC (1 container statuses recorded)
Nov 21 08:10:42.115: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Nov 21 08:10:42.115: INFO: ckecsi-gmm9x from default started at 2019-11-21 06:54:21 +0000 UTC (2 container statuses recorded)
Nov 21 08:10:42.115: INFO: 	Container ckecsi ready: true, restart count 0
Nov 21 08:10:42.115: INFO: 	Container driver-registrar ready: true, restart count 0
Nov 21 08:10:42.115: INFO: ckecsi-provisioner-1 from default started at 2019-11-21 06:54:25 +0000 UTC (1 container statuses recorded)
Nov 21 08:10:42.115: INFO: 	Container ckecsi-provisioner ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: verifying the node has the label node 192.168.0.92
STEP: verifying the node has the label node 192.168.0.93
Nov 21 08:10:42.167: INFO: Pod ckecsi-57xl8 requesting resource cpu=0m on Node 192.168.0.92
Nov 21 08:10:42.167: INFO: Pod ckecsi-attacher-0 requesting resource cpu=0m on Node 192.168.0.93
Nov 21 08:10:42.167: INFO: Pod ckecsi-attacher-1 requesting resource cpu=0m on Node 192.168.0.92
Nov 21 08:10:42.167: INFO: Pod ckecsi-gmm9x requesting resource cpu=0m on Node 192.168.0.93
Nov 21 08:10:42.167: INFO: Pod ckecsi-provisioner-0 requesting resource cpu=0m on Node 192.168.0.92
Nov 21 08:10:42.167: INFO: Pod ckecsi-provisioner-1 requesting resource cpu=0m on Node 192.168.0.93
Nov 21 08:10:42.167: INFO: Pod calico-kube-controllers-79fd644cdf-nj4bj requesting resource cpu=0m on Node 192.168.0.93
Nov 21 08:10:42.167: INFO: Pod coredns-67b8c5b5d8-6lncm requesting resource cpu=100m on Node 192.168.0.93
Nov 21 08:10:42.167: INFO: Pod kubernetes-dashboard-7767bf47b6-sflp4 requesting resource cpu=0m on Node 192.168.0.92
Nov 21 08:10:42.167: INFO: Pod sonobuoy requesting resource cpu=0m on Node 192.168.0.93
Nov 21 08:10:42.167: INFO: Pod sonobuoy-e2e-job-56ce796c30644ea3 requesting resource cpu=0m on Node 192.168.0.92
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-693e2c41-0c36-11ea-a569-4e55f5a7674f.15d91f317e755177], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2768/filler-pod-693e2c41-0c36-11ea-a569-4e55f5a7674f to 192.168.0.92]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-693e2c41-0c36-11ea-a569-4e55f5a7674f.15d91f31e904fa54], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-693e2c41-0c36-11ea-a569-4e55f5a7674f.15d91f31f182fb37], Reason = [Created], Message = [Created container filler-pod-693e2c41-0c36-11ea-a569-4e55f5a7674f]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-693e2c41-0c36-11ea-a569-4e55f5a7674f.15d91f31fd7bdeeb], Reason = [Started], Message = [Started container filler-pod-693e2c41-0c36-11ea-a569-4e55f5a7674f]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-693ea9ac-0c36-11ea-a569-4e55f5a7674f.15d91f318267e495], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2768/filler-pod-693ea9ac-0c36-11ea-a569-4e55f5a7674f to 192.168.0.93]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-693ea9ac-0c36-11ea-a569-4e55f5a7674f.15d91f31ed049023], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-693ea9ac-0c36-11ea-a569-4e55f5a7674f.15d91f31f9492381], Reason = [Created], Message = [Created container filler-pod-693ea9ac-0c36-11ea-a569-4e55f5a7674f]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-693ea9ac-0c36-11ea-a569-4e55f5a7674f.15d91f320b77ff13], Reason = [Started], Message = [Started container filler-pod-693ea9ac-0c36-11ea-a569-4e55f5a7674f]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15d91f32715e8e05], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu.]
STEP: removing the label node off the node 192.168.0.92
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 192.168.0.93
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:10:47.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2768" for this suite.
Nov 21 08:10:53.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:10:53.425: INFO: namespace sched-pred-2768 deletion completed in 6.076646678s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

â€¢ [SLOW TEST:11.399 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:10:53.425: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service multi-endpoint-test in namespace services-4864
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4864 to expose endpoints map[]
Nov 21 08:10:53.539: INFO: successfully validated that service multi-endpoint-test in namespace services-4864 exposes endpoints map[] (17.126539ms elapsed)
STEP: Creating pod pod1 in namespace services-4864
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4864 to expose endpoints map[pod1:[100]]
Nov 21 08:10:56.583: INFO: successfully validated that service multi-endpoint-test in namespace services-4864 exposes endpoints map[pod1:[100]] (3.038508495s elapsed)
STEP: Creating pod pod2 in namespace services-4864
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4864 to expose endpoints map[pod1:[100] pod2:[101]]
Nov 21 08:10:59.633: INFO: successfully validated that service multi-endpoint-test in namespace services-4864 exposes endpoints map[pod1:[100] pod2:[101]] (3.047822757s elapsed)
STEP: Deleting pod pod1 in namespace services-4864
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4864 to expose endpoints map[pod2:[101]]
Nov 21 08:11:00.659: INFO: successfully validated that service multi-endpoint-test in namespace services-4864 exposes endpoints map[pod2:[101]] (1.022925625s elapsed)
STEP: Deleting pod pod2 in namespace services-4864
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4864 to expose endpoints map[]
Nov 21 08:11:01.684: INFO: successfully validated that service multi-endpoint-test in namespace services-4864 exposes endpoints map[] (1.022781081s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:11:01.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4864" for this suite.
Nov 21 08:11:23.740: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:11:23.786: INFO: namespace services-4864 deletion completed in 22.056995082s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

â€¢ [SLOW TEST:30.361 seconds]
[sig-network] Services
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:11:23.786: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Nov 21 08:11:23.831: INFO: Waiting up to 5m0s for pod "pod-821273d4-0c36-11ea-a569-4e55f5a7674f" in namespace "emptydir-7764" to be "success or failure"
Nov 21 08:11:23.836: INFO: Pod "pod-821273d4-0c36-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.449855ms
Nov 21 08:11:25.838: INFO: Pod "pod-821273d4-0c36-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006461879s
Nov 21 08:11:27.840: INFO: Pod "pod-821273d4-0c36-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008880834s
STEP: Saw pod success
Nov 21 08:11:27.840: INFO: Pod "pod-821273d4-0c36-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 08:11:27.842: INFO: Trying to get logs from node 192.168.0.93 pod pod-821273d4-0c36-11ea-a569-4e55f5a7674f container test-container: <nil>
STEP: delete the pod
Nov 21 08:11:27.864: INFO: Waiting for pod pod-821273d4-0c36-11ea-a569-4e55f5a7674f to disappear
Nov 21 08:11:27.870: INFO: Pod pod-821273d4-0c36-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:11:27.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7764" for this suite.
Nov 21 08:11:33.877: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:11:33.917: INFO: namespace emptydir-7764 deletion completed in 6.045370306s

â€¢ [SLOW TEST:10.131 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:11:33.917: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Nov 21 08:11:33.956: INFO: Creating ReplicaSet my-hostname-basic-881ca896-0c36-11ea-a569-4e55f5a7674f
Nov 21 08:11:33.967: INFO: Pod name my-hostname-basic-881ca896-0c36-11ea-a569-4e55f5a7674f: Found 0 pods out of 1
Nov 21 08:11:38.969: INFO: Pod name my-hostname-basic-881ca896-0c36-11ea-a569-4e55f5a7674f: Found 1 pods out of 1
Nov 21 08:11:38.969: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-881ca896-0c36-11ea-a569-4e55f5a7674f" is running
Nov 21 08:11:38.971: INFO: Pod "my-hostname-basic-881ca896-0c36-11ea-a569-4e55f5a7674f-cb9pp" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-21 08:11:34 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-21 08:11:36 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-21 08:11:36 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-21 08:11:33 +0000 UTC Reason: Message:}])
Nov 21 08:11:38.971: INFO: Trying to dial the pod
Nov 21 08:11:43.977: INFO: Controller my-hostname-basic-881ca896-0c36-11ea-a569-4e55f5a7674f: Got expected result from replica 1 [my-hostname-basic-881ca896-0c36-11ea-a569-4e55f5a7674f-cb9pp]: "my-hostname-basic-881ca896-0c36-11ea-a569-4e55f5a7674f-cb9pp", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:11:43.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-4165" for this suite.
Nov 21 08:11:49.992: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:11:50.032: INFO: namespace replicaset-4165 deletion completed in 6.053036058s

â€¢ [SLOW TEST:16.115 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:11:50.032: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Nov 21 08:11:50.077: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov 21 08:11:50.084: INFO: Waiting for terminating namespaces to be deleted...
Nov 21 08:11:50.085: INFO: 
Logging pods the kubelet thinks is on node 192.168.0.92 before test
Nov 21 08:11:50.088: INFO: ckecsi-provisioner-0 from default started at 2019-11-21 06:54:20 +0000 UTC (1 container statuses recorded)
Nov 21 08:11:50.088: INFO: 	Container ckecsi-provisioner ready: true, restart count 0
Nov 21 08:11:50.088: INFO: kubernetes-dashboard-7767bf47b6-sflp4 from kube-system started at 2019-11-21 06:54:20 +0000 UTC (1 container statuses recorded)
Nov 21 08:11:50.088: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Nov 21 08:11:50.088: INFO: ckecsi-57xl8 from default started at 2019-11-21 06:54:21 +0000 UTC (2 container statuses recorded)
Nov 21 08:11:50.088: INFO: 	Container ckecsi ready: true, restart count 0
Nov 21 08:11:50.088: INFO: 	Container driver-registrar ready: true, restart count 0
Nov 21 08:11:50.088: INFO: ckecsi-attacher-1 from default started at 2019-11-21 06:55:05 +0000 UTC (1 container statuses recorded)
Nov 21 08:11:50.088: INFO: 	Container ckecsi-attacher ready: true, restart count 0
Nov 21 08:11:50.088: INFO: sonobuoy-e2e-job-56ce796c30644ea3 from sonobuoy started at 2019-11-21 08:10:37 +0000 UTC (2 container statuses recorded)
Nov 21 08:11:50.088: INFO: 	Container e2e ready: true, restart count 0
Nov 21 08:11:50.088: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 21 08:11:50.088: INFO: 
Logging pods the kubelet thinks is on node 192.168.0.93 before test
Nov 21 08:11:50.092: INFO: coredns-67b8c5b5d8-6lncm from kube-system started at 2019-11-21 06:54:21 +0000 UTC (1 container statuses recorded)
Nov 21 08:11:50.092: INFO: 	Container coredns ready: true, restart count 0
Nov 21 08:11:50.092: INFO: ckecsi-attacher-0 from default started at 2019-11-21 06:54:21 +0000 UTC (1 container statuses recorded)
Nov 21 08:11:50.092: INFO: 	Container ckecsi-attacher ready: true, restart count 0
Nov 21 08:11:50.092: INFO: calico-kube-controllers-79fd644cdf-nj4bj from kube-system started at 2019-11-21 06:54:21 +0000 UTC (1 container statuses recorded)
Nov 21 08:11:50.092: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Nov 21 08:11:50.092: INFO: ckecsi-gmm9x from default started at 2019-11-21 06:54:21 +0000 UTC (2 container statuses recorded)
Nov 21 08:11:50.092: INFO: 	Container ckecsi ready: true, restart count 0
Nov 21 08:11:50.092: INFO: 	Container driver-registrar ready: true, restart count 0
Nov 21 08:11:50.092: INFO: ckecsi-provisioner-1 from default started at 2019-11-21 06:54:25 +0000 UTC (1 container statuses recorded)
Nov 21 08:11:50.092: INFO: 	Container ckecsi-provisioner ready: true, restart count 0
Nov 21 08:11:50.092: INFO: sonobuoy from sonobuoy started at 2019-11-21 08:10:34 +0000 UTC (1 container statuses recorded)
Nov 21 08:11:50.092: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-9423ed4b-0c36-11ea-a569-4e55f5a7674f 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-9423ed4b-0c36-11ea-a569-4e55f5a7674f off the node 192.168.0.93
STEP: verifying the node doesn't have the label kubernetes.io/e2e-9423ed4b-0c36-11ea-a569-4e55f5a7674f
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:11:58.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2363" for this suite.
Nov 21 08:12:06.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:12:06.272: INFO: namespace sched-pred-2363 deletion completed in 8.052148554s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

â€¢ [SLOW TEST:16.240 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:12:06.272: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Nov 21 08:12:06.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 create -f - --namespace=kubectl-7925'
Nov 21 08:12:07.427: INFO: stderr: ""
Nov 21 08:12:07.427: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Nov 21 08:12:08.430: INFO: Selector matched 1 pods for map[app:redis]
Nov 21 08:12:08.430: INFO: Found 0 / 1
Nov 21 08:12:09.430: INFO: Selector matched 1 pods for map[app:redis]
Nov 21 08:12:09.430: INFO: Found 0 / 1
Nov 21 08:12:10.430: INFO: Selector matched 1 pods for map[app:redis]
Nov 21 08:12:10.430: INFO: Found 1 / 1
Nov 21 08:12:10.430: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Nov 21 08:12:10.431: INFO: Selector matched 1 pods for map[app:redis]
Nov 21 08:12:10.431: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov 21 08:12:10.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 patch pod redis-master-t5mpr --namespace=kubectl-7925 -p {"metadata":{"annotations":{"x":"y"}}}'
Nov 21 08:12:10.542: INFO: stderr: ""
Nov 21 08:12:10.542: INFO: stdout: "pod/redis-master-t5mpr patched\n"
STEP: checking annotations
Nov 21 08:12:10.545: INFO: Selector matched 1 pods for map[app:redis]
Nov 21 08:12:10.545: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:12:10.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7925" for this suite.
Nov 21 08:12:32.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:12:32.593: INFO: namespace kubectl-7925 deletion completed in 22.046033162s

â€¢ [SLOW TEST:26.321 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:12:32.593: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-ab1e29b8-0c36-11ea-a569-4e55f5a7674f
STEP: Creating a pod to test consume configMaps
Nov 21 08:12:32.701: INFO: Waiting up to 5m0s for pod "pod-configmaps-ab1f404d-0c36-11ea-a569-4e55f5a7674f" in namespace "configmap-7453" to be "success or failure"
Nov 21 08:12:32.705: INFO: Pod "pod-configmaps-ab1f404d-0c36-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.708041ms
Nov 21 08:12:34.707: INFO: Pod "pod-configmaps-ab1f404d-0c36-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006571378s
Nov 21 08:12:36.709: INFO: Pod "pod-configmaps-ab1f404d-0c36-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008513798s
STEP: Saw pod success
Nov 21 08:12:36.709: INFO: Pod "pod-configmaps-ab1f404d-0c36-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 08:12:36.711: INFO: Trying to get logs from node 192.168.0.93 pod pod-configmaps-ab1f404d-0c36-11ea-a569-4e55f5a7674f container configmap-volume-test: <nil>
STEP: delete the pod
Nov 21 08:12:36.734: INFO: Waiting for pod pod-configmaps-ab1f404d-0c36-11ea-a569-4e55f5a7674f to disappear
Nov 21 08:12:36.739: INFO: Pod pod-configmaps-ab1f404d-0c36-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:12:36.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7453" for this suite.
Nov 21 08:12:42.749: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:12:42.799: INFO: namespace configmap-7453 deletion completed in 6.057616211s

â€¢ [SLOW TEST:10.206 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:12:42.799: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-b130610b-0c36-11ea-a569-4e55f5a7674f
STEP: Creating a pod to test consume secrets
Nov 21 08:12:42.884: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b13127c1-0c36-11ea-a569-4e55f5a7674f" in namespace "projected-5412" to be "success or failure"
Nov 21 08:12:42.900: INFO: Pod "pod-projected-secrets-b13127c1-0c36-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 15.677433ms
Nov 21 08:12:44.902: INFO: Pod "pod-projected-secrets-b13127c1-0c36-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017948447s
Nov 21 08:12:46.904: INFO: Pod "pod-projected-secrets-b13127c1-0c36-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020083497s
STEP: Saw pod success
Nov 21 08:12:46.904: INFO: Pod "pod-projected-secrets-b13127c1-0c36-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 08:12:46.906: INFO: Trying to get logs from node 192.168.0.92 pod pod-projected-secrets-b13127c1-0c36-11ea-a569-4e55f5a7674f container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov 21 08:12:46.918: INFO: Waiting for pod pod-projected-secrets-b13127c1-0c36-11ea-a569-4e55f5a7674f to disappear
Nov 21 08:12:46.922: INFO: Pod pod-projected-secrets-b13127c1-0c36-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:12:46.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5412" for this suite.
Nov 21 08:12:52.947: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:12:53.002: INFO: namespace projected-5412 deletion completed in 6.064547209s

â€¢ [SLOW TEST:10.203 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:12:53.002: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Nov 21 08:12:53.112: INFO: Number of nodes with available pods: 0
Nov 21 08:12:53.112: INFO: Node 192.168.0.92 is running more than one daemon pod
Nov 21 08:12:54.119: INFO: Number of nodes with available pods: 0
Nov 21 08:12:54.119: INFO: Node 192.168.0.92 is running more than one daemon pod
Nov 21 08:12:55.116: INFO: Number of nodes with available pods: 0
Nov 21 08:12:55.116: INFO: Node 192.168.0.92 is running more than one daemon pod
Nov 21 08:12:56.116: INFO: Number of nodes with available pods: 2
Nov 21 08:12:56.116: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Nov 21 08:12:56.131: INFO: Number of nodes with available pods: 1
Nov 21 08:12:56.131: INFO: Node 192.168.0.92 is running more than one daemon pod
Nov 21 08:12:57.135: INFO: Number of nodes with available pods: 1
Nov 21 08:12:57.135: INFO: Node 192.168.0.92 is running more than one daemon pod
Nov 21 08:12:58.135: INFO: Number of nodes with available pods: 1
Nov 21 08:12:58.135: INFO: Node 192.168.0.92 is running more than one daemon pod
Nov 21 08:12:59.135: INFO: Number of nodes with available pods: 1
Nov 21 08:12:59.135: INFO: Node 192.168.0.92 is running more than one daemon pod
Nov 21 08:13:00.135: INFO: Number of nodes with available pods: 1
Nov 21 08:13:00.135: INFO: Node 192.168.0.92 is running more than one daemon pod
Nov 21 08:13:01.135: INFO: Number of nodes with available pods: 1
Nov 21 08:13:01.135: INFO: Node 192.168.0.92 is running more than one daemon pod
Nov 21 08:13:02.135: INFO: Number of nodes with available pods: 2
Nov 21 08:13:02.135: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2938, will wait for the garbage collector to delete the pods
Nov 21 08:13:02.191: INFO: Deleting DaemonSet.extensions daemon-set took: 2.893299ms
Nov 21 08:13:02.491: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.145031ms
Nov 21 08:13:05.397: INFO: Number of nodes with available pods: 0
Nov 21 08:13:05.397: INFO: Number of running nodes: 0, number of available pods: 0
Nov 21 08:13:05.413: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2938/daemonsets","resourceVersion":"7542"},"items":null}

Nov 21 08:13:05.414: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2938/pods","resourceVersion":"7542"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:13:05.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2938" for this suite.
Nov 21 08:13:11.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:13:11.485: INFO: namespace daemonsets-2938 deletion completed in 6.057883243s

â€¢ [SLOW TEST:18.482 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:13:11.485: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating secret secrets-6112/secret-test-c24529c0-0c36-11ea-a569-4e55f5a7674f
STEP: Creating a pod to test consume secrets
Nov 21 08:13:11.553: INFO: Waiting up to 5m0s for pod "pod-configmaps-c247b51b-0c36-11ea-a569-4e55f5a7674f" in namespace "secrets-6112" to be "success or failure"
Nov 21 08:13:11.558: INFO: Pod "pod-configmaps-c247b51b-0c36-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.534535ms
Nov 21 08:13:13.560: INFO: Pod "pod-configmaps-c247b51b-0c36-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006477678s
Nov 21 08:13:15.562: INFO: Pod "pod-configmaps-c247b51b-0c36-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008733003s
STEP: Saw pod success
Nov 21 08:13:15.562: INFO: Pod "pod-configmaps-c247b51b-0c36-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 08:13:15.563: INFO: Trying to get logs from node 192.168.0.93 pod pod-configmaps-c247b51b-0c36-11ea-a569-4e55f5a7674f container env-test: <nil>
STEP: delete the pod
Nov 21 08:13:15.615: INFO: Waiting for pod pod-configmaps-c247b51b-0c36-11ea-a569-4e55f5a7674f to disappear
Nov 21 08:13:15.620: INFO: Pod pod-configmaps-c247b51b-0c36-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:13:15.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6112" for this suite.
Nov 21 08:13:21.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:13:21.693: INFO: namespace secrets-6112 deletion completed in 6.071095475s

â€¢ [SLOW TEST:10.209 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:13:21.694: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:13:21.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8333" for this suite.
Nov 21 08:13:27.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:13:27.793: INFO: namespace services-8333 deletion completed in 6.044913152s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

â€¢ [SLOW TEST:6.100 seconds]
[sig-network] Services
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:13:27.793: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-4037
Nov 21 08:13:29.863: INFO: Started pod liveness-exec in namespace container-probe-4037
STEP: checking the pod's current state and verifying that restartCount is present
Nov 21 08:13:29.864: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:17:30.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4037" for this suite.
Nov 21 08:17:36.190: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:17:36.229: INFO: namespace container-probe-4037 deletion completed in 6.053105382s

â€¢ [SLOW TEST:248.435 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:17:36.229: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-2329.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-2329.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2329.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-2329.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-2329.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2329.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov 21 08:17:40.316: INFO: DNS probes using dns-2329/dns-test-6012101d-0c37-11ea-a569-4e55f5a7674f succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:17:40.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2329" for this suite.
Nov 21 08:17:46.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:17:46.420: INFO: namespace dns-2329 deletion completed in 6.048444724s

â€¢ [SLOW TEST:10.192 seconds]
[sig-network] DNS
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:17:46.421: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1121 08:17:52.492907      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov 21 08:17:52.492: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:17:52.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4267" for this suite.
Nov 21 08:17:58.539: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:17:58.579: INFO: namespace gc-4267 deletion completed in 6.084234497s

â€¢ [SLOW TEST:12.158 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:17:58.579: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
STEP: reading a file in the container
Nov 21 08:18:01.193: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3620 pod-service-account-6db64e40-0c37-11ea-a569-4e55f5a7674f -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Nov 21 08:18:01.398: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3620 pod-service-account-6db64e40-0c37-11ea-a569-4e55f5a7674f -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Nov 21 08:18:01.576: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3620 pod-service-account-6db64e40-0c37-11ea-a569-4e55f5a7674f -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:18:01.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-3620" for this suite.
Nov 21 08:18:07.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:18:07.808: INFO: namespace svcaccounts-3620 deletion completed in 6.051572363s

â€¢ [SLOW TEST:9.229 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:18:07.808: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test hostPath mode
Nov 21 08:18:07.888: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-7171" to be "success or failure"
Nov 21 08:18:07.893: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.593891ms
Nov 21 08:18:10.022: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.133975371s
Nov 21 08:18:12.025: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.136343926s
STEP: Saw pod success
Nov 21 08:18:12.025: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Nov 21 08:18:12.026: INFO: Trying to get logs from node 192.168.0.93 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Nov 21 08:18:12.104: INFO: Waiting for pod pod-host-path-test to disappear
Nov 21 08:18:12.110: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:18:12.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-7171" for this suite.
Nov 21 08:18:18.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:18:18.159: INFO: namespace hostpath-7171 deletion completed in 6.046937277s

â€¢ [SLOW TEST:10.351 seconds]
[sig-storage] HostPath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:18:18.159: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Nov 21 08:18:26.242: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 21 08:18:26.258: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 21 08:18:28.258: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 21 08:18:28.260: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 21 08:18:30.258: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 21 08:18:30.260: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 21 08:18:32.258: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 21 08:18:32.260: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 21 08:18:34.258: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 21 08:18:34.260: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 21 08:18:36.258: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 21 08:18:36.260: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 21 08:18:38.258: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 21 08:18:38.260: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 21 08:18:40.258: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 21 08:18:40.260: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 21 08:18:42.258: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 21 08:18:42.260: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 21 08:18:44.258: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 21 08:18:44.261: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:18:44.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6637" for this suite.
Nov 21 08:19:06.290: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:19:06.330: INFO: namespace container-lifecycle-hook-6637 deletion completed in 22.060467754s

â€¢ [SLOW TEST:48.171 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:19:06.330: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Nov 21 08:19:10.910: INFO: Successfully updated pod "labelsupdate95c78346-0c37-11ea-a569-4e55f5a7674f"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:19:12.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8309" for this suite.
Nov 21 08:19:34.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:19:34.993: INFO: namespace projected-8309 deletion completed in 22.051853249s

â€¢ [SLOW TEST:28.663 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:19:34.993: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Nov 21 08:19:35.072: INFO: Waiting up to 5m0s for pod "downward-api-a6df9382-0c37-11ea-a569-4e55f5a7674f" in namespace "downward-api-3475" to be "success or failure"
Nov 21 08:19:35.088: INFO: Pod "downward-api-a6df9382-0c37-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 15.72482ms
Nov 21 08:19:37.090: INFO: Pod "downward-api-a6df9382-0c37-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01797082s
Nov 21 08:19:39.093: INFO: Pod "downward-api-a6df9382-0c37-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020342002s
STEP: Saw pod success
Nov 21 08:19:39.093: INFO: Pod "downward-api-a6df9382-0c37-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 08:19:39.094: INFO: Trying to get logs from node 192.168.0.93 pod downward-api-a6df9382-0c37-11ea-a569-4e55f5a7674f container dapi-container: <nil>
STEP: delete the pod
Nov 21 08:19:39.106: INFO: Waiting for pod downward-api-a6df9382-0c37-11ea-a569-4e55f5a7674f to disappear
Nov 21 08:19:39.111: INFO: Pod downward-api-a6df9382-0c37-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:19:39.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3475" for this suite.
Nov 21 08:19:45.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:19:45.185: INFO: namespace downward-api-3475 deletion completed in 6.067233536s

â€¢ [SLOW TEST:10.192 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:19:45.185: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:19:47.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7914" for this suite.
Nov 21 08:20:37.278: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:20:37.318: INFO: namespace kubelet-test-7914 deletion completed in 50.044255432s

â€¢ [SLOW TEST:52.133 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a read only busybox container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:20:37.318: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-cc014862-0c37-11ea-a569-4e55f5a7674f
STEP: Creating a pod to test consume secrets
Nov 21 08:20:37.400: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-cc01f182-0c37-11ea-a569-4e55f5a7674f" in namespace "projected-7739" to be "success or failure"
Nov 21 08:20:37.409: INFO: Pod "pod-projected-secrets-cc01f182-0c37-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 9.227916ms
Nov 21 08:20:39.411: INFO: Pod "pod-projected-secrets-cc01f182-0c37-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011719664s
Nov 21 08:20:41.414: INFO: Pod "pod-projected-secrets-cc01f182-0c37-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014234789s
STEP: Saw pod success
Nov 21 08:20:41.414: INFO: Pod "pod-projected-secrets-cc01f182-0c37-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 08:20:41.415: INFO: Trying to get logs from node 192.168.0.93 pod pod-projected-secrets-cc01f182-0c37-11ea-a569-4e55f5a7674f container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov 21 08:20:41.444: INFO: Waiting for pod pod-projected-secrets-cc01f182-0c37-11ea-a569-4e55f5a7674f to disappear
Nov 21 08:20:41.449: INFO: Pod pod-projected-secrets-cc01f182-0c37-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:20:41.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7739" for this suite.
Nov 21 08:20:47.457: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:20:47.497: INFO: namespace projected-7739 deletion completed in 6.046699889s

â€¢ [SLOW TEST:10.179 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:20:47.498: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Nov 21 08:20:47.542: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:20:52.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7316" for this suite.
Nov 21 08:20:58.252: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:20:58.297: INFO: namespace init-container-7316 deletion completed in 6.062759899s

â€¢ [SLOW TEST:10.800 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:20:58.298: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:21:02.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6255" for this suite.
Nov 21 08:21:52.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:21:52.433: INFO: namespace kubelet-test-6255 deletion completed in 50.046522269s

â€¢ [SLOW TEST:54.135 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:21:52.433: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-f8c6cd97-0c37-11ea-a569-4e55f5a7674f
STEP: Creating a pod to test consume secrets
Nov 21 08:21:52.485: INFO: Waiting up to 5m0s for pod "pod-secrets-f8c79df8-0c37-11ea-a569-4e55f5a7674f" in namespace "secrets-2760" to be "success or failure"
Nov 21 08:21:52.490: INFO: Pod "pod-secrets-f8c79df8-0c37-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.740925ms
Nov 21 08:21:54.492: INFO: Pod "pod-secrets-f8c79df8-0c37-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006636188s
Nov 21 08:21:56.494: INFO: Pod "pod-secrets-f8c79df8-0c37-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008628204s
STEP: Saw pod success
Nov 21 08:21:56.494: INFO: Pod "pod-secrets-f8c79df8-0c37-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 08:21:56.495: INFO: Trying to get logs from node 192.168.0.92 pod pod-secrets-f8c79df8-0c37-11ea-a569-4e55f5a7674f container secret-volume-test: <nil>
STEP: delete the pod
Nov 21 08:21:56.514: INFO: Waiting for pod pod-secrets-f8c79df8-0c37-11ea-a569-4e55f5a7674f to disappear
Nov 21 08:21:56.518: INFO: Pod pod-secrets-f8c79df8-0c37-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:21:56.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2760" for this suite.
Nov 21 08:22:02.526: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:22:02.565: INFO: namespace secrets-2760 deletion completed in 6.045118576s

â€¢ [SLOW TEST:10.133 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:22:02.566: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1121 08:22:12.755742      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov 21 08:22:12.755: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:22:12.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5621" for this suite.
Nov 21 08:22:18.794: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:22:18.866: INFO: namespace gc-5621 deletion completed in 6.108895859s

â€¢ [SLOW TEST:16.301 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:22:18.866: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Nov 21 08:22:22.931: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-088989ca-0c38-11ea-a569-4e55f5a7674f,GenerateName:,Namespace:events-1148,SelfLink:/api/v1/namespaces/events-1148/pods/send-events-088989ca-0c38-11ea-a569-4e55f5a7674f,UID:088a39ce-0c38-11ea-b617-0202c0a8005b,ResourceVersion:9444,Generation:0,CreationTimestamp:2019-11-21 08:22:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 915481664,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-j7l9v {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j7l9v,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-j7l9v true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.93,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024fa000} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024fa020}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:22:18 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:22:20 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:22:20 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:22:18 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.93,PodIP:172.49.166.157,StartTime:2019-11-21 08:22:18 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-11-21 08:22:20 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/k8s-authenticated-test/serve-hostname:1.1 docker-pullable://reg.mg.hcbss/devcke/serve-hostname@sha256:5792caa151fd823f01e765c535bcdb0386e0e9c9a2b5687e4a613cecadfa3505 docker://084dc1aa77fdf5fa61e59798d85c68f7f818452fed84c03e88d4eda598666f65}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Nov 21 08:22:24.933: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Nov 21 08:22:26.936: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:22:26.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-1148" for this suite.
Nov 21 08:23:04.973: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:23:05.012: INFO: namespace events-1148 deletion completed in 38.054396074s

â€¢ [SLOW TEST:46.146 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:23:05.013: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Nov 21 08:23:05.063: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:23:09.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3900" for this suite.
Nov 21 08:23:53.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:23:53.167: INFO: namespace pods-3900 deletion completed in 44.0469553s

â€¢ [SLOW TEST:48.154 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:23:53.167: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4486.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-4486.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4486.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-4486.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4486.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-4486.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4486.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-4486.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4486.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-4486.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4486.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-4486.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4486.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 221.231.254.11.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/11.254.231.221_udp@PTR;check="$$(dig +tcp +noall +answer +search 221.231.254.11.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/11.254.231.221_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4486.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-4486.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4486.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-4486.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4486.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-4486.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4486.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-4486.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4486.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-4486.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4486.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-4486.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4486.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 221.231.254.11.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/11.254.231.221_udp@PTR;check="$$(dig +tcp +noall +answer +search 221.231.254.11.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/11.254.231.221_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov 21 08:23:59.310: INFO: Unable to read wheezy_udp@dns-test-service.dns-4486.svc.cluster.local from pod dns-4486/dns-test-40c884c1-0c38-11ea-a569-4e55f5a7674f: the server could not find the requested resource (get pods dns-test-40c884c1-0c38-11ea-a569-4e55f5a7674f)
Nov 21 08:23:59.312: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4486.svc.cluster.local from pod dns-4486/dns-test-40c884c1-0c38-11ea-a569-4e55f5a7674f: the server could not find the requested resource (get pods dns-test-40c884c1-0c38-11ea-a569-4e55f5a7674f)
Nov 21 08:23:59.314: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4486.svc.cluster.local from pod dns-4486/dns-test-40c884c1-0c38-11ea-a569-4e55f5a7674f: the server could not find the requested resource (get pods dns-test-40c884c1-0c38-11ea-a569-4e55f5a7674f)
Nov 21 08:23:59.315: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4486.svc.cluster.local from pod dns-4486/dns-test-40c884c1-0c38-11ea-a569-4e55f5a7674f: the server could not find the requested resource (get pods dns-test-40c884c1-0c38-11ea-a569-4e55f5a7674f)
Nov 21 08:23:59.327: INFO: Unable to read jessie_udp@dns-test-service.dns-4486.svc.cluster.local from pod dns-4486/dns-test-40c884c1-0c38-11ea-a569-4e55f5a7674f: the server could not find the requested resource (get pods dns-test-40c884c1-0c38-11ea-a569-4e55f5a7674f)
Nov 21 08:23:59.329: INFO: Unable to read jessie_tcp@dns-test-service.dns-4486.svc.cluster.local from pod dns-4486/dns-test-40c884c1-0c38-11ea-a569-4e55f5a7674f: the server could not find the requested resource (get pods dns-test-40c884c1-0c38-11ea-a569-4e55f5a7674f)
Nov 21 08:23:59.331: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4486.svc.cluster.local from pod dns-4486/dns-test-40c884c1-0c38-11ea-a569-4e55f5a7674f: the server could not find the requested resource (get pods dns-test-40c884c1-0c38-11ea-a569-4e55f5a7674f)
Nov 21 08:23:59.332: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4486.svc.cluster.local from pod dns-4486/dns-test-40c884c1-0c38-11ea-a569-4e55f5a7674f: the server could not find the requested resource (get pods dns-test-40c884c1-0c38-11ea-a569-4e55f5a7674f)
Nov 21 08:23:59.343: INFO: Lookups using dns-4486/dns-test-40c884c1-0c38-11ea-a569-4e55f5a7674f failed for: [wheezy_udp@dns-test-service.dns-4486.svc.cluster.local wheezy_tcp@dns-test-service.dns-4486.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4486.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4486.svc.cluster.local jessie_udp@dns-test-service.dns-4486.svc.cluster.local jessie_tcp@dns-test-service.dns-4486.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4486.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4486.svc.cluster.local]

Nov 21 08:24:04.376: INFO: DNS probes using dns-4486/dns-test-40c884c1-0c38-11ea-a569-4e55f5a7674f succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:24:04.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4486" for this suite.
Nov 21 08:24:10.573: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:24:10.613: INFO: namespace dns-4486 deletion completed in 6.057145401s

â€¢ [SLOW TEST:17.446 seconds]
[sig-network] DNS
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:24:10.613: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:25:10.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-606" for this suite.
Nov 21 08:25:32.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:25:32.761: INFO: namespace container-probe-606 deletion completed in 22.06725164s

â€¢ [SLOW TEST:82.148 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:25:32.761: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W1121 08:26:02.884847      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov 21 08:26:02.884: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:26:02.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9845" for this suite.
Nov 21 08:26:08.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:26:08.934: INFO: namespace gc-9845 deletion completed in 6.047679608s

â€¢ [SLOW TEST:36.173 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:26:08.934: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Nov 21 08:26:09.009: INFO: Creating deployment "test-recreate-deployment"
Nov 21 08:26:09.040: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Nov 21 08:26:09.048: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Nov 21 08:26:11.052: INFO: Waiting deployment "test-recreate-deployment" to complete
Nov 21 08:26:11.053: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709921569, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709921569, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709921569, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709921569, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d57d5ff7c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 21 08:26:13.055: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Nov 21 08:26:13.059: INFO: Updating deployment test-recreate-deployment
Nov 21 08:26:13.059: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Nov 21 08:26:13.214: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-5732,SelfLink:/apis/apps/v1/namespaces/deployment-5732/deployments/test-recreate-deployment,UID:91af1bb6-0c38-11ea-b617-0202c0a8005b,ResourceVersion:10056,Generation:2,CreationTimestamp:2019-11-21 08:26:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-11-21 08:26:13 +0000 UTC 2019-11-21 08:26:13 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-11-21 08:26:13 +0000 UTC 2019-11-21 08:26:09 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-c9cbd8684" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Nov 21 08:26:13.216: INFO: New ReplicaSet "test-recreate-deployment-c9cbd8684" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-c9cbd8684,GenerateName:,Namespace:deployment-5732,SelfLink:/apis/apps/v1/namespaces/deployment-5732/replicasets/test-recreate-deployment-c9cbd8684,UID:942424d9-0c38-11ea-b617-0202c0a8005b,ResourceVersion:10055,Generation:1,CreationTimestamp:2019-11-21 08:26:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 91af1bb6-0c38-11ea-b617-0202c0a8005b 0xc0026f2f10 0xc0026f2f11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov 21 08:26:13.216: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Nov 21 08:26:13.217: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7d57d5ff7c,GenerateName:,Namespace:deployment-5732,SelfLink:/apis/apps/v1/namespaces/deployment-5732/replicasets/test-recreate-deployment-7d57d5ff7c,UID:91b3db23-0c38-11ea-b617-0202c0a8005b,ResourceVersion:10045,Generation:2,CreationTimestamp:2019-11-21 08:26:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 91af1bb6-0c38-11ea-b617-0202c0a8005b 0xc0026f2e47 0xc0026f2e48}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov 21 08:26:13.226: INFO: Pod "test-recreate-deployment-c9cbd8684-pn8b7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-c9cbd8684-pn8b7,GenerateName:test-recreate-deployment-c9cbd8684-,Namespace:deployment-5732,SelfLink:/api/v1/namespaces/deployment-5732/pods/test-recreate-deployment-c9cbd8684-pn8b7,UID:94245b63-0c38-11ea-b617-0202c0a8005b,ResourceVersion:10057,Generation:0,CreationTimestamp:2019-11-21 08:26:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-c9cbd8684 942424d9-0c38-11ea-b617-0202c0a8005b 0xc0026f3730 0xc0026f3731}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6t5bt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6t5bt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6t5bt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.92,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0026f37a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0026f37c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:26:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:26:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:26:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:26:13 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.92,PodIP:,StartTime:2019-11-21 08:26:13 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:26:13.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5732" for this suite.
Nov 21 08:26:19.233: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:26:19.271: INFO: namespace deployment-5732 deletion completed in 6.043334561s

â€¢ [SLOW TEST:10.337 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:26:19.271: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Nov 21 08:26:19.319: INFO: Waiting up to 5m0s for pod "downward-api-97d31999-0c38-11ea-a569-4e55f5a7674f" in namespace "downward-api-5270" to be "success or failure"
Nov 21 08:26:19.343: INFO: Pod "downward-api-97d31999-0c38-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 24.036536ms
Nov 21 08:26:21.345: INFO: Pod "downward-api-97d31999-0c38-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02625435s
Nov 21 08:26:23.347: INFO: Pod "downward-api-97d31999-0c38-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028505634s
STEP: Saw pod success
Nov 21 08:26:23.347: INFO: Pod "downward-api-97d31999-0c38-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 08:26:23.349: INFO: Trying to get logs from node 192.168.0.93 pod downward-api-97d31999-0c38-11ea-a569-4e55f5a7674f container dapi-container: <nil>
STEP: delete the pod
Nov 21 08:26:23.395: INFO: Waiting for pod downward-api-97d31999-0c38-11ea-a569-4e55f5a7674f to disappear
Nov 21 08:26:23.403: INFO: Pod downward-api-97d31999-0c38-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:26:23.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5270" for this suite.
Nov 21 08:26:29.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:26:29.450: INFO: namespace downward-api-5270 deletion completed in 6.045246499s

â€¢ [SLOW TEST:10.179 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:26:29.450: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Nov 21 08:26:33.649: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 21 08:26:33.654: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 21 08:26:35.655: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 21 08:26:35.656: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 21 08:26:37.655: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 21 08:26:37.656: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 21 08:26:39.655: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 21 08:26:39.657: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 21 08:26:41.655: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 21 08:26:41.657: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 21 08:26:43.655: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 21 08:26:43.656: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 21 08:26:45.655: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 21 08:26:45.657: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 21 08:26:47.655: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 21 08:26:47.658: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 21 08:26:49.655: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 21 08:26:49.657: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 21 08:26:51.655: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 21 08:26:51.657: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 21 08:26:53.655: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 21 08:26:53.657: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 21 08:26:55.655: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 21 08:26:55.657: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 21 08:26:57.655: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 21 08:26:57.657: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 21 08:26:59.655: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 21 08:26:59.657: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 21 08:27:01.655: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 21 08:27:01.657: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:27:01.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8656" for this suite.
Nov 21 08:27:23.668: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:27:23.709: INFO: namespace container-lifecycle-hook-8656 deletion completed in 22.04991721s

â€¢ [SLOW TEST:54.259 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:27:23.709: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the initial replication controller
Nov 21 08:27:23.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 create -f - --namespace=kubectl-5878'
Nov 21 08:27:24.714: INFO: stderr: ""
Nov 21 08:27:24.714: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov 21 08:27:24.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5878'
Nov 21 08:27:24.828: INFO: stderr: ""
Nov 21 08:27:24.828: INFO: stdout: "update-demo-nautilus-5sgdb update-demo-nautilus-7dmrj "
Nov 21 08:27:24.828: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods update-demo-nautilus-5sgdb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5878'
Nov 21 08:27:24.898: INFO: stderr: ""
Nov 21 08:27:24.898: INFO: stdout: ""
Nov 21 08:27:24.898: INFO: update-demo-nautilus-5sgdb is created but not running
Nov 21 08:27:29.899: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5878'
Nov 21 08:27:29.968: INFO: stderr: ""
Nov 21 08:27:29.968: INFO: stdout: "update-demo-nautilus-5sgdb update-demo-nautilus-7dmrj "
Nov 21 08:27:29.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods update-demo-nautilus-5sgdb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5878'
Nov 21 08:27:30.038: INFO: stderr: ""
Nov 21 08:27:30.038: INFO: stdout: "true"
Nov 21 08:27:30.038: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods update-demo-nautilus-5sgdb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5878'
Nov 21 08:27:30.103: INFO: stderr: ""
Nov 21 08:27:30.103: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 21 08:27:30.103: INFO: validating pod update-demo-nautilus-5sgdb
Nov 21 08:27:30.111: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 21 08:27:30.111: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 21 08:27:30.111: INFO: update-demo-nautilus-5sgdb is verified up and running
Nov 21 08:27:30.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods update-demo-nautilus-7dmrj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5878'
Nov 21 08:27:30.178: INFO: stderr: ""
Nov 21 08:27:30.178: INFO: stdout: "true"
Nov 21 08:27:30.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods update-demo-nautilus-7dmrj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5878'
Nov 21 08:27:30.245: INFO: stderr: ""
Nov 21 08:27:30.245: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 21 08:27:30.245: INFO: validating pod update-demo-nautilus-7dmrj
Nov 21 08:27:30.258: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 21 08:27:30.258: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 21 08:27:30.258: INFO: update-demo-nautilus-7dmrj is verified up and running
STEP: rolling-update to new replication controller
Nov 21 08:27:30.259: INFO: scanned /root for discovery docs: <nil>
Nov 21 08:27:30.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-5878'
Nov 21 08:27:52.746: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Nov 21 08:27:52.746: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov 21 08:27:52.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5878'
Nov 21 08:27:52.818: INFO: stderr: ""
Nov 21 08:27:52.818: INFO: stdout: "update-demo-kitten-2pxrd update-demo-kitten-5fqbx "
Nov 21 08:27:52.818: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods update-demo-kitten-2pxrd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5878'
Nov 21 08:27:52.886: INFO: stderr: ""
Nov 21 08:27:52.886: INFO: stdout: "true"
Nov 21 08:27:52.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods update-demo-kitten-2pxrd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5878'
Nov 21 08:27:52.955: INFO: stderr: ""
Nov 21 08:27:52.955: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Nov 21 08:27:52.955: INFO: validating pod update-demo-kitten-2pxrd
Nov 21 08:27:52.967: INFO: got data: {
  "image": "kitten.jpg"
}

Nov 21 08:27:52.967: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Nov 21 08:27:52.967: INFO: update-demo-kitten-2pxrd is verified up and running
Nov 21 08:27:52.967: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods update-demo-kitten-5fqbx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5878'
Nov 21 08:27:53.037: INFO: stderr: ""
Nov 21 08:27:53.037: INFO: stdout: "true"
Nov 21 08:27:53.037: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods update-demo-kitten-5fqbx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5878'
Nov 21 08:27:53.106: INFO: stderr: ""
Nov 21 08:27:53.106: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Nov 21 08:27:53.106: INFO: validating pod update-demo-kitten-5fqbx
Nov 21 08:27:53.120: INFO: got data: {
  "image": "kitten.jpg"
}

Nov 21 08:27:53.120: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Nov 21 08:27:53.120: INFO: update-demo-kitten-5fqbx is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:27:53.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5878" for this suite.
Nov 21 08:28:15.132: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:28:15.173: INFO: namespace kubectl-5878 deletion completed in 22.050130144s

â€¢ [SLOW TEST:51.464 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:28:15.173: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Nov 21 08:28:23.308: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov 21 08:28:23.313: INFO: Pod pod-with-poststart-http-hook still exists
Nov 21 08:28:25.313: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov 21 08:28:25.315: INFO: Pod pod-with-poststart-http-hook still exists
Nov 21 08:28:27.313: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov 21 08:28:27.315: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:28:27.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2416" for this suite.
Nov 21 08:28:49.326: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:28:49.368: INFO: namespace container-lifecycle-hook-2416 deletion completed in 22.050403756s

â€¢ [SLOW TEST:34.195 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:28:49.369: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:28:54.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6111" for this suite.
Nov 21 08:29:16.459: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:29:16.501: INFO: namespace replication-controller-6111 deletion completed in 22.051991339s

â€¢ [SLOW TEST:27.132 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:29:16.501: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-017bc9e8-0c39-11ea-a569-4e55f5a7674f
STEP: Creating secret with name s-test-opt-upd-017bca3b-0c39-11ea-a569-4e55f5a7674f
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-017bc9e8-0c39-11ea-a569-4e55f5a7674f
STEP: Updating secret s-test-opt-upd-017bca3b-0c39-11ea-a569-4e55f5a7674f
STEP: Creating secret with name s-test-opt-create-017bca54-0c39-11ea-a569-4e55f5a7674f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:30:28.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5816" for this suite.
Nov 21 08:30:50.888: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:30:50.928: INFO: namespace secrets-5816 deletion completed in 22.050509642s

â€¢ [SLOW TEST:94.427 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:30:50.928: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's args
Nov 21 08:30:50.985: INFO: Waiting up to 5m0s for pod "var-expansion-39bfc61c-0c39-11ea-a569-4e55f5a7674f" in namespace "var-expansion-3354" to be "success or failure"
Nov 21 08:30:50.989: INFO: Pod "var-expansion-39bfc61c-0c39-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.450973ms
Nov 21 08:30:52.991: INFO: Pod "var-expansion-39bfc61c-0c39-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006610768s
Nov 21 08:30:54.993: INFO: Pod "var-expansion-39bfc61c-0c39-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008742549s
STEP: Saw pod success
Nov 21 08:30:54.993: INFO: Pod "var-expansion-39bfc61c-0c39-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 08:30:54.995: INFO: Trying to get logs from node 192.168.0.92 pod var-expansion-39bfc61c-0c39-11ea-a569-4e55f5a7674f container dapi-container: <nil>
STEP: delete the pod
Nov 21 08:30:55.013: INFO: Waiting for pod var-expansion-39bfc61c-0c39-11ea-a569-4e55f5a7674f to disappear
Nov 21 08:30:55.040: INFO: Pod var-expansion-39bfc61c-0c39-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:30:55.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3354" for this suite.
Nov 21 08:31:01.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:31:01.093: INFO: namespace var-expansion-3354 deletion completed in 6.051540636s

â€¢ [SLOW TEST:10.165 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:31:01.093: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-3fd393fb-0c39-11ea-a569-4e55f5a7674f
STEP: Creating configMap with name cm-test-opt-upd-3fd3944d-0c39-11ea-a569-4e55f5a7674f
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-3fd393fb-0c39-11ea-a569-4e55f5a7674f
STEP: Updating configmap cm-test-opt-upd-3fd3944d-0c39-11ea-a569-4e55f5a7674f
STEP: Creating configMap with name cm-test-opt-create-3fd39462-0c39-11ea-a569-4e55f5a7674f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:31:07.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4897" for this suite.
Nov 21 08:31:29.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:31:29.310: INFO: namespace projected-4897 deletion completed in 22.050281996s

â€¢ [SLOW TEST:28.216 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:31:29.310: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1318
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov 21 08:31:29.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-8246'
Nov 21 08:31:29.446: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov 21 08:31:29.446: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1324
Nov 21 08:31:31.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 delete deployment e2e-test-nginx-deployment --namespace=kubectl-8246'
Nov 21 08:31:31.535: INFO: stderr: ""
Nov 21 08:31:31.535: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:31:31.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8246" for this suite.
Nov 21 08:32:51.546: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:32:51.585: INFO: namespace kubectl-8246 deletion completed in 1m20.047747632s

â€¢ [SLOW TEST:82.275 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:32:51.585: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:32:57.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8024" for this suite.
Nov 21 08:33:03.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:33:03.861: INFO: namespace namespaces-8024 deletion completed in 6.045658108s
STEP: Destroying namespace "nsdeletetest-3626" for this suite.
Nov 21 08:33:03.862: INFO: Namespace nsdeletetest-3626 was already deleted
STEP: Destroying namespace "nsdeletetest-2770" for this suite.
Nov 21 08:33:09.872: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:33:09.911: INFO: namespace nsdeletetest-2770 deletion completed in 6.049303499s

â€¢ [SLOW TEST:18.327 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:33:09.912: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating replication controller svc-latency-rc in namespace svc-latency-754
I1121 08:33:09.962794      17 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-754, replica count: 1
I1121 08:33:11.013116      17 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1121 08:33:12.013276      17 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1121 08:33:13.013513      17 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 21 08:33:13.134: INFO: Created: latency-svc-hbcbf
Nov 21 08:33:13.139: INFO: Got endpoints: latency-svc-hbcbf [26.012388ms]
Nov 21 08:33:13.163: INFO: Created: latency-svc-vgppc
Nov 21 08:33:13.168: INFO: Got endpoints: latency-svc-vgppc [28.634966ms]
Nov 21 08:33:13.200: INFO: Created: latency-svc-w2chb
Nov 21 08:33:13.220: INFO: Got endpoints: latency-svc-w2chb [80.490754ms]
Nov 21 08:33:13.220: INFO: Created: latency-svc-q4p2l
Nov 21 08:33:13.225: INFO: Got endpoints: latency-svc-q4p2l [85.66323ms]
Nov 21 08:33:13.243: INFO: Created: latency-svc-5gspc
Nov 21 08:33:13.248: INFO: Got endpoints: latency-svc-5gspc [108.685414ms]
Nov 21 08:33:13.266: INFO: Created: latency-svc-fk7pz
Nov 21 08:33:13.271: INFO: Got endpoints: latency-svc-fk7pz [131.480938ms]
Nov 21 08:33:13.289: INFO: Created: latency-svc-ktj5w
Nov 21 08:33:13.294: INFO: Got endpoints: latency-svc-ktj5w [154.266569ms]
Nov 21 08:33:13.331: INFO: Created: latency-svc-z2tgn
Nov 21 08:33:13.352: INFO: Got endpoints: latency-svc-z2tgn [212.073299ms]
Nov 21 08:33:13.352: INFO: Created: latency-svc-wtrm6
Nov 21 08:33:13.369: INFO: Got endpoints: latency-svc-wtrm6 [229.464005ms]
Nov 21 08:33:13.386: INFO: Created: latency-svc-zsnlq
Nov 21 08:33:13.391: INFO: Got endpoints: latency-svc-zsnlq [251.535292ms]
Nov 21 08:33:13.409: INFO: Created: latency-svc-99qzp
Nov 21 08:33:13.414: INFO: Got endpoints: latency-svc-99qzp [274.585219ms]
Nov 21 08:33:13.451: INFO: Created: latency-svc-vgjhr
Nov 21 08:33:13.472: INFO: Got endpoints: latency-svc-vgjhr [332.845314ms]
Nov 21 08:33:13.472: INFO: Created: latency-svc-k8874
Nov 21 08:33:13.477: INFO: Got endpoints: latency-svc-k8874 [337.403431ms]
Nov 21 08:33:13.496: INFO: Created: latency-svc-9xvhc
Nov 21 08:33:13.512: INFO: Got endpoints: latency-svc-9xvhc [372.945537ms]
Nov 21 08:33:13.530: INFO: Created: latency-svc-95kq5
Nov 21 08:33:13.534: INFO: Got endpoints: latency-svc-95kq5 [394.732529ms]
Nov 21 08:33:13.571: INFO: Created: latency-svc-v7bgb
Nov 21 08:33:13.593: INFO: Got endpoints: latency-svc-v7bgb [453.044762ms]
Nov 21 08:33:13.593: INFO: Created: latency-svc-t4fp5
Nov 21 08:33:13.610: INFO: Got endpoints: latency-svc-t4fp5 [441.737455ms]
Nov 21 08:33:13.627: INFO: Created: latency-svc-2n9pg
Nov 21 08:33:13.637: INFO: Got endpoints: latency-svc-2n9pg [417.287392ms]
Nov 21 08:33:13.656: INFO: Created: latency-svc-zslnw
Nov 21 08:33:13.666: INFO: Got endpoints: latency-svc-zslnw [440.626054ms]
Nov 21 08:33:13.715: INFO: Created: latency-svc-vrwdb
Nov 21 08:33:13.736: INFO: Got endpoints: latency-svc-vrwdb [487.861435ms]
Nov 21 08:33:13.736: INFO: Created: latency-svc-jzdrr
Nov 21 08:33:13.759: INFO: Got endpoints: latency-svc-jzdrr [487.830284ms]
Nov 21 08:33:13.782: INFO: Created: latency-svc-86www
Nov 21 08:33:13.792: INFO: Got endpoints: latency-svc-86www [498.097101ms]
Nov 21 08:33:13.811: INFO: Created: latency-svc-zrjhk
Nov 21 08:33:13.862: INFO: Got endpoints: latency-svc-zrjhk [510.898065ms]
Nov 21 08:33:13.863: INFO: Created: latency-svc-wg587
Nov 21 08:33:13.872: INFO: Got endpoints: latency-svc-wg587 [502.693169ms]
Nov 21 08:33:13.891: INFO: Created: latency-svc-2gd6v
Nov 21 08:33:13.900: INFO: Got endpoints: latency-svc-2gd6v [509.444469ms]
Nov 21 08:33:13.919: INFO: Created: latency-svc-8br7s
Nov 21 08:33:13.929: INFO: Got endpoints: latency-svc-8br7s [515.011409ms]
Nov 21 08:33:13.948: INFO: Created: latency-svc-tx9gk
Nov 21 08:33:13.958: INFO: Got endpoints: latency-svc-tx9gk [485.265277ms]
Nov 21 08:33:14.011: INFO: Created: latency-svc-v55ql
Nov 21 08:33:14.034: INFO: Got endpoints: latency-svc-v55ql [556.921616ms]
Nov 21 08:33:14.034: INFO: Created: latency-svc-9l8wl
Nov 21 08:33:14.043: INFO: Got endpoints: latency-svc-9l8wl [530.932739ms]
Nov 21 08:33:14.063: INFO: Created: latency-svc-j6jsz
Nov 21 08:33:14.072: INFO: Got endpoints: latency-svc-j6jsz [537.926071ms]
Nov 21 08:33:14.092: INFO: Created: latency-svc-8bsfn
Nov 21 08:33:14.101: INFO: Got endpoints: latency-svc-8bsfn [508.113321ms]
Nov 21 08:33:14.149: INFO: Created: latency-svc-dvkl9
Nov 21 08:33:14.171: INFO: Got endpoints: latency-svc-dvkl9 [561.630087ms]
Nov 21 08:33:14.172: INFO: Created: latency-svc-696r5
Nov 21 08:33:14.181: INFO: Got endpoints: latency-svc-696r5 [543.423351ms]
Nov 21 08:33:14.200: INFO: Created: latency-svc-wdp7z
Nov 21 08:33:14.209: INFO: Got endpoints: latency-svc-wdp7z [543.592028ms]
Nov 21 08:33:14.229: INFO: Created: latency-svc-wnhn6
Nov 21 08:33:14.238: INFO: Got endpoints: latency-svc-wnhn6 [501.843837ms]
Nov 21 08:33:14.286: INFO: Created: latency-svc-8zmzd
Nov 21 08:33:14.309: INFO: Got endpoints: latency-svc-8zmzd [550.043119ms]
Nov 21 08:33:14.309: INFO: Created: latency-svc-58zr7
Nov 21 08:33:14.332: INFO: Got endpoints: latency-svc-58zr7 [539.675722ms]
Nov 21 08:33:14.355: INFO: Created: latency-svc-nzcvg
Nov 21 08:33:14.364: INFO: Got endpoints: latency-svc-nzcvg [501.37622ms]
Nov 21 08:33:14.384: INFO: Created: latency-svc-5n4fh
Nov 21 08:33:14.424: INFO: Got endpoints: latency-svc-5n4fh [551.953498ms]
Nov 21 08:33:14.425: INFO: Created: latency-svc-mbl86
Nov 21 08:33:14.432: INFO: Got endpoints: latency-svc-mbl86 [531.935536ms]
Nov 21 08:33:14.452: INFO: Created: latency-svc-w4jvh
Nov 21 08:33:14.461: INFO: Got endpoints: latency-svc-w4jvh [531.820407ms]
Nov 21 08:33:14.481: INFO: Created: latency-svc-lbr9n
Nov 21 08:33:14.490: INFO: Got endpoints: latency-svc-lbr9n [532.056094ms]
Nov 21 08:33:14.510: INFO: Created: latency-svc-9n9xr
Nov 21 08:33:14.518: INFO: Got endpoints: latency-svc-9n9xr [484.383322ms]
Nov 21 08:33:14.571: INFO: Created: latency-svc-9pxjr
Nov 21 08:33:14.589: INFO: Got endpoints: latency-svc-9pxjr [546.08033ms]
Nov 21 08:33:14.590: INFO: Created: latency-svc-cfdtk
Nov 21 08:33:14.598: INFO: Got endpoints: latency-svc-cfdtk [526.043609ms]
Nov 21 08:33:14.618: INFO: Created: latency-svc-gx2kt
Nov 21 08:33:14.627: INFO: Got endpoints: latency-svc-gx2kt [526.191105ms]
Nov 21 08:33:14.647: INFO: Created: latency-svc-bk8dk
Nov 21 08:33:14.670: INFO: Got endpoints: latency-svc-bk8dk [498.218241ms]
Nov 21 08:33:14.726: INFO: Created: latency-svc-fpkpp
Nov 21 08:33:14.744: INFO: Got endpoints: latency-svc-fpkpp [563.650239ms]
Nov 21 08:33:14.745: INFO: Created: latency-svc-d9f4f
Nov 21 08:33:14.753: INFO: Got endpoints: latency-svc-d9f4f [543.39916ms]
Nov 21 08:33:14.808: INFO: Created: latency-svc-clfzp
Nov 21 08:33:14.859: INFO: Got endpoints: latency-svc-clfzp [621.200472ms]
Nov 21 08:33:14.865: INFO: Created: latency-svc-rjnwv
Nov 21 08:33:14.873: INFO: Got endpoints: latency-svc-rjnwv [564.069062ms]
Nov 21 08:33:14.899: INFO: Created: latency-svc-vd8mq
Nov 21 08:33:14.907: INFO: Got endpoints: latency-svc-vd8mq [575.59477ms]
Nov 21 08:33:14.934: INFO: Created: latency-svc-2pgg2
Nov 21 08:33:14.942: INFO: Got endpoints: latency-svc-2pgg2 [578.216574ms]
Nov 21 08:33:15.009: INFO: Created: latency-svc-sxw6z
Nov 21 08:33:15.014: INFO: Got endpoints: latency-svc-sxw6z [590.180805ms]
Nov 21 08:33:15.037: INFO: Created: latency-svc-wkbrm
Nov 21 08:33:15.045: INFO: Got endpoints: latency-svc-wkbrm [612.136117ms]
Nov 21 08:33:15.066: INFO: Created: latency-svc-827fd
Nov 21 08:33:15.073: INFO: Got endpoints: latency-svc-827fd [612.279531ms]
Nov 21 08:33:15.094: INFO: Created: latency-svc-777wd
Nov 21 08:33:15.102: INFO: Got endpoints: latency-svc-777wd [612.038093ms]
Nov 21 08:33:15.154: INFO: Created: latency-svc-8f5fh
Nov 21 08:33:15.174: INFO: Got endpoints: latency-svc-8f5fh [655.945648ms]
Nov 21 08:33:15.175: INFO: Created: latency-svc-k997p
Nov 21 08:33:15.182: INFO: Got endpoints: latency-svc-k997p [592.186289ms]
Nov 21 08:33:15.204: INFO: Created: latency-svc-h6wds
Nov 21 08:33:15.211: INFO: Got endpoints: latency-svc-h6wds [612.295415ms]
Nov 21 08:33:15.232: INFO: Created: latency-svc-zzk4z
Nov 21 08:33:15.295: INFO: Got endpoints: latency-svc-zzk4z [667.975133ms]
Nov 21 08:33:15.296: INFO: Created: latency-svc-hqjms
Nov 21 08:33:15.302: INFO: Got endpoints: latency-svc-hqjms [632.273568ms]
Nov 21 08:33:15.318: INFO: Created: latency-svc-cnv2g
Nov 21 08:33:15.325: INFO: Got endpoints: latency-svc-cnv2g [580.475993ms]
Nov 21 08:33:15.341: INFO: Created: latency-svc-dsjxh
Nov 21 08:33:15.348: INFO: Got endpoints: latency-svc-dsjxh [594.850781ms]
Nov 21 08:33:15.364: INFO: Created: latency-svc-997vm
Nov 21 08:33:15.371: INFO: Got endpoints: latency-svc-997vm [511.398679ms]
Nov 21 08:33:15.386: INFO: Created: latency-svc-8dhj6
Nov 21 08:33:15.393: INFO: Got endpoints: latency-svc-8dhj6 [520.469638ms]
Nov 21 08:33:15.444: INFO: Created: latency-svc-hc299
Nov 21 08:33:15.449: INFO: Got endpoints: latency-svc-hc299 [542.032232ms]
Nov 21 08:33:15.467: INFO: Created: latency-svc-q7fd8
Nov 21 08:33:15.474: INFO: Got endpoints: latency-svc-q7fd8 [531.314143ms]
Nov 21 08:33:15.490: INFO: Created: latency-svc-86ztq
Nov 21 08:33:15.496: INFO: Got endpoints: latency-svc-86ztq [482.509437ms]
Nov 21 08:33:15.512: INFO: Created: latency-svc-hv52k
Nov 21 08:33:15.519: INFO: Got endpoints: latency-svc-hv52k [474.708933ms]
Nov 21 08:33:15.535: INFO: Created: latency-svc-hghgx
Nov 21 08:33:15.542: INFO: Got endpoints: latency-svc-hghgx [468.930948ms]
Nov 21 08:33:15.589: INFO: Created: latency-svc-w58c8
Nov 21 08:33:15.604: INFO: Got endpoints: latency-svc-w58c8 [502.180029ms]
Nov 21 08:33:15.604: INFO: Created: latency-svc-77gg9
Nov 21 08:33:15.611: INFO: Got endpoints: latency-svc-77gg9 [436.737524ms]
Nov 21 08:33:15.627: INFO: Created: latency-svc-hxzbk
Nov 21 08:33:15.644: INFO: Got endpoints: latency-svc-hxzbk [462.406229ms]
Nov 21 08:33:15.662: INFO: Created: latency-svc-hc9g2
Nov 21 08:33:15.668: INFO: Got endpoints: latency-svc-hc9g2 [457.575518ms]
Nov 21 08:33:15.685: INFO: Created: latency-svc-6t9dp
Nov 21 08:33:15.725: INFO: Got endpoints: latency-svc-6t9dp [429.765115ms]
Nov 21 08:33:15.726: INFO: Created: latency-svc-zvqvx
Nov 21 08:33:15.731: INFO: Got endpoints: latency-svc-zvqvx [429.064261ms]
Nov 21 08:33:15.748: INFO: Created: latency-svc-7n9gl
Nov 21 08:33:15.754: INFO: Got endpoints: latency-svc-7n9gl [429.059276ms]
Nov 21 08:33:15.771: INFO: Created: latency-svc-glz94
Nov 21 08:33:15.777: INFO: Got endpoints: latency-svc-glz94 [429.257854ms]
Nov 21 08:33:15.793: INFO: Created: latency-svc-jckkz
Nov 21 08:33:15.800: INFO: Got endpoints: latency-svc-jckkz [429.14499ms]
Nov 21 08:33:15.817: INFO: Created: latency-svc-jqhrw
Nov 21 08:33:15.823: INFO: Got endpoints: latency-svc-jqhrw [429.134028ms]
Nov 21 08:33:15.857: INFO: Created: latency-svc-db47p
Nov 21 08:33:15.863: INFO: Got endpoints: latency-svc-db47p [413.425798ms]
Nov 21 08:33:15.880: INFO: Created: latency-svc-f7t5r
Nov 21 08:33:15.886: INFO: Got endpoints: latency-svc-f7t5r [412.005831ms]
Nov 21 08:33:15.908: INFO: Created: latency-svc-t6ctv
Nov 21 08:33:15.926: INFO: Got endpoints: latency-svc-t6ctv [429.148028ms]
Nov 21 08:33:15.949: INFO: Created: latency-svc-w458k
Nov 21 08:33:15.954: INFO: Got endpoints: latency-svc-w458k [434.88006ms]
Nov 21 08:33:15.990: INFO: Created: latency-svc-g79vs
Nov 21 08:33:15.994: INFO: Got endpoints: latency-svc-g79vs [452.144413ms]
Nov 21 08:33:16.012: INFO: Created: latency-svc-t9crq
Nov 21 08:33:16.017: INFO: Got endpoints: latency-svc-t9crq [413.243704ms]
Nov 21 08:33:16.035: INFO: Created: latency-svc-8fmk7
Nov 21 08:33:16.040: INFO: Got endpoints: latency-svc-8fmk7 [429.363265ms]
Nov 21 08:33:16.069: INFO: Created: latency-svc-xz644
Nov 21 08:33:16.086: INFO: Created: latency-svc-kb4pp
Nov 21 08:33:16.121: INFO: Got endpoints: latency-svc-xz644 [476.540171ms]
Nov 21 08:33:16.122: INFO: Created: latency-svc-2b8p7
Nov 21 08:33:16.143: INFO: Got endpoints: latency-svc-kb4pp [475.1071ms]
Nov 21 08:33:16.161: INFO: Created: latency-svc-5x8q6
Nov 21 08:33:16.184: INFO: Created: latency-svc-vq425
Nov 21 08:33:16.189: INFO: Got endpoints: latency-svc-2b8p7 [464.141516ms]
Nov 21 08:33:16.207: INFO: Created: latency-svc-7j4dw
Nov 21 08:33:16.251: INFO: Got endpoints: latency-svc-5x8q6 [520.237744ms]
Nov 21 08:33:16.252: INFO: Created: latency-svc-7hnd5
Nov 21 08:33:16.286: INFO: Got endpoints: latency-svc-vq425 [532.431494ms]
Nov 21 08:33:16.287: INFO: Created: latency-svc-89mhb
Nov 21 08:33:16.310: INFO: Created: latency-svc-tf4rx
Nov 21 08:33:16.333: INFO: Created: latency-svc-qbkq8
Nov 21 08:33:16.338: INFO: Got endpoints: latency-svc-7j4dw [560.572964ms]
Nov 21 08:33:16.379: INFO: Created: latency-svc-8bx5n
Nov 21 08:33:16.401: INFO: Got endpoints: latency-svc-7hnd5 [601.512835ms]
Nov 21 08:33:16.402: INFO: Created: latency-svc-vm86r
Nov 21 08:33:16.424: INFO: Created: latency-svc-n8qlj
Nov 21 08:33:16.447: INFO: Got endpoints: latency-svc-89mhb [624.720178ms]
Nov 21 08:33:16.448: INFO: Created: latency-svc-kpc65
Nov 21 08:33:16.470: INFO: Created: latency-svc-qf9hl
Nov 21 08:33:16.514: INFO: Got endpoints: latency-svc-tf4rx [651.375984ms]
Nov 21 08:33:16.514: INFO: Created: latency-svc-nftg5
Nov 21 08:33:16.533: INFO: Created: latency-svc-vn7hg
Nov 21 08:33:16.538: INFO: Got endpoints: latency-svc-qbkq8 [652.192037ms]
Nov 21 08:33:16.556: INFO: Created: latency-svc-rnd5l
Nov 21 08:33:16.585: INFO: Created: latency-svc-2dg27
Nov 21 08:33:16.601: INFO: Got endpoints: latency-svc-8bx5n [675.187563ms]
Nov 21 08:33:16.634: INFO: Created: latency-svc-6rhsp
Nov 21 08:33:16.654: INFO: Got endpoints: latency-svc-vm86r [699.485569ms]
Nov 21 08:33:16.654: INFO: Created: latency-svc-v69gm
Nov 21 08:33:16.683: INFO: Created: latency-svc-8xnjg
Nov 21 08:33:16.692: INFO: Got endpoints: latency-svc-n8qlj [698.058458ms]
Nov 21 08:33:16.711: INFO: Created: latency-svc-wk5dd
Nov 21 08:33:16.792: INFO: Got endpoints: latency-svc-qf9hl [751.578848ms]
Nov 21 08:33:16.792: INFO: Got endpoints: latency-svc-kpc65 [774.668698ms]
Nov 21 08:33:16.792: INFO: Created: latency-svc-dfr8p
Nov 21 08:33:16.820: INFO: Created: latency-svc-64xn8
Nov 21 08:33:16.849: INFO: Got endpoints: latency-svc-nftg5 [728.016051ms]
Nov 21 08:33:16.849: INFO: Created: latency-svc-8k7cs
Nov 21 08:33:16.878: INFO: Created: latency-svc-nf5qx
Nov 21 08:33:16.887: INFO: Got endpoints: latency-svc-vn7hg [743.686742ms]
Nov 21 08:33:16.950: INFO: Got endpoints: latency-svc-rnd5l [760.986806ms]
Nov 21 08:33:16.950: INFO: Created: latency-svc-42ph4
Nov 21 08:33:16.969: INFO: Created: latency-svc-fxqkl
Nov 21 08:33:16.998: INFO: Got endpoints: latency-svc-2dg27 [746.513209ms]
Nov 21 08:33:16.998: INFO: Created: latency-svc-rv7wb
Nov 21 08:33:17.044: INFO: Got endpoints: latency-svc-6rhsp [757.326486ms]
Nov 21 08:33:17.044: INFO: Created: latency-svc-lx6gk
Nov 21 08:33:17.110: INFO: Got endpoints: latency-svc-v69gm [772.252366ms]
Nov 21 08:33:17.111: INFO: Created: latency-svc-jpgnr
Nov 21 08:33:17.135: INFO: Created: latency-svc-tfnd4
Nov 21 08:33:17.144: INFO: Got endpoints: latency-svc-8xnjg [742.928056ms]
Nov 21 08:33:17.164: INFO: Created: latency-svc-5mw92
Nov 21 08:33:17.187: INFO: Got endpoints: latency-svc-wk5dd [739.367313ms]
Nov 21 08:33:17.210: INFO: Created: latency-svc-h5xns
Nov 21 08:33:17.257: INFO: Got endpoints: latency-svc-dfr8p [742.575245ms]
Nov 21 08:33:17.258: INFO: Created: latency-svc-l5z7f
Nov 21 08:33:17.284: INFO: Created: latency-svc-kxhpc
Nov 21 08:33:17.293: INFO: Got endpoints: latency-svc-64xn8 [755.26928ms]
Nov 21 08:33:17.313: INFO: Created: latency-svc-5jxq4
Nov 21 08:33:17.342: INFO: Got endpoints: latency-svc-8k7cs [740.820878ms]
Nov 21 08:33:17.342: INFO: Created: latency-svc-cvv42
Nov 21 08:33:17.419: INFO: Got endpoints: latency-svc-nf5qx [765.110044ms]
Nov 21 08:33:17.419: INFO: Created: latency-svc-dmw7z
Nov 21 08:33:17.439: INFO: Got endpoints: latency-svc-42ph4 [746.520145ms]
Nov 21 08:33:17.439: INFO: Created: latency-svc-pxtdj
Nov 21 08:33:17.485: INFO: Created: latency-svc-gms2s
Nov 21 08:33:17.493: INFO: Got endpoints: latency-svc-fxqkl [701.136442ms]
Nov 21 08:33:17.514: INFO: Created: latency-svc-8wnq6
Nov 21 08:33:17.562: INFO: Got endpoints: latency-svc-rv7wb [769.698537ms]
Nov 21 08:33:17.563: INFO: Created: latency-svc-tq9wx
Nov 21 08:33:17.588: INFO: Got endpoints: latency-svc-lx6gk [739.249615ms]
Nov 21 08:33:17.589: INFO: Created: latency-svc-kgkkf
Nov 21 08:33:17.617: INFO: Created: latency-svc-2wnx4
Nov 21 08:33:17.636: INFO: Got endpoints: latency-svc-jpgnr [748.952818ms]
Nov 21 08:33:17.708: INFO: Got endpoints: latency-svc-tfnd4 [758.050034ms]
Nov 21 08:33:17.708: INFO: Created: latency-svc-mrqfd
Nov 21 08:33:17.731: INFO: Created: latency-svc-xzn2b
Nov 21 08:33:17.748: INFO: Got endpoints: latency-svc-5mw92 [750.546568ms]
Nov 21 08:33:17.772: INFO: Created: latency-svc-rpszq
Nov 21 08:33:17.786: INFO: Got endpoints: latency-svc-h5xns [742.134342ms]
Nov 21 08:33:17.806: INFO: Created: latency-svc-bwdzx
Nov 21 08:33:17.840: INFO: Got endpoints: latency-svc-l5z7f [729.797297ms]
Nov 21 08:33:17.881: INFO: Created: latency-svc-td8vv
Nov 21 08:33:17.888: INFO: Got endpoints: latency-svc-kxhpc [743.747052ms]
Nov 21 08:33:17.921: INFO: Created: latency-svc-wzpbl
Nov 21 08:33:17.936: INFO: Got endpoints: latency-svc-5jxq4 [749.645492ms]
Nov 21 08:33:17.961: INFO: Created: latency-svc-zvp8j
Nov 21 08:33:17.987: INFO: Got endpoints: latency-svc-cvv42 [729.788128ms]
Nov 21 08:33:18.024: INFO: Created: latency-svc-xcdrg
Nov 21 08:33:18.036: INFO: Got endpoints: latency-svc-dmw7z [743.203645ms]
Nov 21 08:33:18.122: INFO: Got endpoints: latency-svc-pxtdj [780.641368ms]
Nov 21 08:33:18.123: INFO: Created: latency-svc-c6xpc
Nov 21 08:33:18.139: INFO: Got endpoints: latency-svc-gms2s [719.81124ms]
Nov 21 08:33:18.139: INFO: Created: latency-svc-j794p
Nov 21 08:33:18.162: INFO: Created: latency-svc-gnrht
Nov 21 08:33:18.186: INFO: Got endpoints: latency-svc-8wnq6 [747.181148ms]
Nov 21 08:33:18.208: INFO: Created: latency-svc-hnmzr
Nov 21 08:33:18.257: INFO: Got endpoints: latency-svc-tq9wx [763.456593ms]
Nov 21 08:33:18.277: INFO: Created: latency-svc-mjvrz
Nov 21 08:33:18.286: INFO: Got endpoints: latency-svc-kgkkf [724.216208ms]
Nov 21 08:33:18.305: INFO: Created: latency-svc-svm5k
Nov 21 08:33:18.336: INFO: Got endpoints: latency-svc-2wnx4 [747.891905ms]
Nov 21 08:33:18.357: INFO: Created: latency-svc-q96sx
Nov 21 08:33:18.411: INFO: Got endpoints: latency-svc-mrqfd [774.914274ms]
Nov 21 08:33:18.432: INFO: Created: latency-svc-wbmjn
Nov 21 08:33:18.437: INFO: Got endpoints: latency-svc-xzn2b [728.653646ms]
Nov 21 08:33:18.460: INFO: Created: latency-svc-s7jmj
Nov 21 08:33:18.486: INFO: Got endpoints: latency-svc-rpszq [737.340137ms]
Nov 21 08:33:18.506: INFO: Created: latency-svc-zj9mp
Nov 21 08:33:18.542: INFO: Got endpoints: latency-svc-bwdzx [756.197453ms]
Nov 21 08:33:18.586: INFO: Created: latency-svc-rlk7n
Nov 21 08:33:18.591: INFO: Got endpoints: latency-svc-td8vv [751.272289ms]
Nov 21 08:33:18.626: INFO: Created: latency-svc-dwq9g
Nov 21 08:33:18.636: INFO: Got endpoints: latency-svc-wzpbl [747.998599ms]
Nov 21 08:33:18.700: INFO: Got endpoints: latency-svc-zvp8j [763.385129ms]
Nov 21 08:33:18.700: INFO: Created: latency-svc-cvk94
Nov 21 08:33:18.718: INFO: Created: latency-svc-m5msd
Nov 21 08:33:18.736: INFO: Got endpoints: latency-svc-xcdrg [749.43162ms]
Nov 21 08:33:18.758: INFO: Created: latency-svc-gkg67
Nov 21 08:33:18.786: INFO: Got endpoints: latency-svc-c6xpc [749.535922ms]
Nov 21 08:33:18.860: INFO: Got endpoints: latency-svc-j794p [737.800216ms]
Nov 21 08:33:18.860: INFO: Created: latency-svc-cgsws
Nov 21 08:33:18.901: INFO: Got endpoints: latency-svc-gnrht [762.396669ms]
Nov 21 08:33:18.902: INFO: Created: latency-svc-lfzvc
Nov 21 08:33:18.924: INFO: Created: latency-svc-t2vpw
Nov 21 08:33:18.936: INFO: Got endpoints: latency-svc-hnmzr [749.664875ms]
Nov 21 08:33:18.959: INFO: Created: latency-svc-2xrr7
Nov 21 08:33:19.000: INFO: Got endpoints: latency-svc-mjvrz [742.823469ms]
Nov 21 08:33:19.022: INFO: Created: latency-svc-djfkn
Nov 21 08:33:19.036: INFO: Got endpoints: latency-svc-svm5k [749.977062ms]
Nov 21 08:33:19.056: INFO: Created: latency-svc-hsgn4
Nov 21 08:33:19.086: INFO: Got endpoints: latency-svc-q96sx [749.888348ms]
Nov 21 08:33:19.163: INFO: Got endpoints: latency-svc-wbmjn [752.052105ms]
Nov 21 08:33:19.163: INFO: Created: latency-svc-7qhqz
Nov 21 08:33:19.182: INFO: Created: latency-svc-tc7wf
Nov 21 08:33:19.205: INFO: Got endpoints: latency-svc-s7jmj [768.064588ms]
Nov 21 08:33:19.234: INFO: Created: latency-svc-tlwkx
Nov 21 08:33:19.243: INFO: Got endpoints: latency-svc-zj9mp [757.257547ms]
Nov 21 08:33:19.312: INFO: Got endpoints: latency-svc-rlk7n [769.5247ms]
Nov 21 08:33:19.312: INFO: Created: latency-svc-h2572
Nov 21 08:33:19.331: INFO: Created: latency-svc-mg2j6
Nov 21 08:33:19.340: INFO: Got endpoints: latency-svc-dwq9g [749.237793ms]
Nov 21 08:33:19.394: INFO: Got endpoints: latency-svc-cvk94 [757.86874ms]
Nov 21 08:33:19.394: INFO: Created: latency-svc-ppfg6
Nov 21 08:33:19.478: INFO: Got endpoints: latency-svc-m5msd [777.824497ms]
Nov 21 08:33:19.478: INFO: Created: latency-svc-9vt7v
Nov 21 08:33:19.497: INFO: Got endpoints: latency-svc-gkg67 [760.938688ms]
Nov 21 08:33:19.497: INFO: Created: latency-svc-vhpnz
Nov 21 08:33:19.549: INFO: Got endpoints: latency-svc-cgsws [762.769612ms]
Nov 21 08:33:19.549: INFO: Created: latency-svc-c4bnv
Nov 21 08:33:19.578: INFO: Created: latency-svc-fqwnj
Nov 21 08:33:19.628: INFO: Got endpoints: latency-svc-lfzvc [768.074467ms]
Nov 21 08:33:19.652: INFO: Got endpoints: latency-svc-t2vpw [750.851494ms]
Nov 21 08:33:19.652: INFO: Created: latency-svc-w828b
Nov 21 08:33:19.698: INFO: Got endpoints: latency-svc-2xrr7 [761.976835ms]
Nov 21 08:33:19.698: INFO: Created: latency-svc-p2z8n
Nov 21 08:33:19.727: INFO: Created: latency-svc-tlhwk
Nov 21 08:33:19.777: INFO: Got endpoints: latency-svc-djfkn [777.348254ms]
Nov 21 08:33:19.801: INFO: Got endpoints: latency-svc-hsgn4 [765.038579ms]
Nov 21 08:33:19.801: INFO: Created: latency-svc-5pndc
Nov 21 08:33:19.830: INFO: Created: latency-svc-snprp
Nov 21 08:33:19.838: INFO: Got endpoints: latency-svc-7qhqz [752.343542ms]
Nov 21 08:33:19.914: INFO: Got endpoints: latency-svc-tc7wf [750.931783ms]
Nov 21 08:33:19.914: INFO: Created: latency-svc-t7nkv
Nov 21 08:33:19.939: INFO: Got endpoints: latency-svc-tlwkx [733.994683ms]
Nov 21 08:33:19.939: INFO: Created: latency-svc-9shrp
Nov 21 08:33:19.968: INFO: Created: latency-svc-m5tvf
Nov 21 08:33:19.991: INFO: Got endpoints: latency-svc-h2572 [748.022485ms]
Nov 21 08:33:20.056: INFO: Got endpoints: latency-svc-mg2j6 [744.003878ms]
Nov 21 08:33:20.056: INFO: Created: latency-svc-gqvdn
Nov 21 08:33:20.071: INFO: Created: latency-svc-md2k5
Nov 21 08:33:20.087: INFO: Got endpoints: latency-svc-ppfg6 [746.333818ms]
Nov 21 08:33:20.105: INFO: Created: latency-svc-r57hm
Nov 21 08:33:20.137: INFO: Got endpoints: latency-svc-9vt7v [742.808234ms]
Nov 21 08:33:20.188: INFO: Got endpoints: latency-svc-vhpnz [710.601469ms]
Nov 21 08:33:20.209: INFO: Created: latency-svc-sv6jb
Nov 21 08:33:20.232: INFO: Created: latency-svc-rqc4f
Nov 21 08:33:20.238: INFO: Got endpoints: latency-svc-c4bnv [741.260398ms]
Nov 21 08:33:20.260: INFO: Created: latency-svc-v9zw6
Nov 21 08:33:20.286: INFO: Got endpoints: latency-svc-fqwnj [737.204572ms]
Nov 21 08:33:20.340: INFO: Got endpoints: latency-svc-w828b [711.774068ms]
Nov 21 08:33:20.341: INFO: Created: latency-svc-dvgvw
Nov 21 08:33:20.363: INFO: Created: latency-svc-frlh2
Nov 21 08:33:20.386: INFO: Got endpoints: latency-svc-p2z8n [733.566013ms]
Nov 21 08:33:20.404: INFO: Created: latency-svc-4qw9t
Nov 21 08:33:20.462: INFO: Got endpoints: latency-svc-tlhwk [764.293059ms]
Nov 21 08:33:20.484: INFO: Created: latency-svc-2b6x7
Nov 21 08:33:20.501: INFO: Got endpoints: latency-svc-5pndc [723.682256ms]
Nov 21 08:33:20.524: INFO: Created: latency-svc-9ts95
Nov 21 08:33:20.536: INFO: Got endpoints: latency-svc-snprp [734.576905ms]
Nov 21 08:33:20.558: INFO: Created: latency-svc-zxzsq
Nov 21 08:33:20.605: INFO: Got endpoints: latency-svc-t7nkv [766.890674ms]
Nov 21 08:33:20.627: INFO: Created: latency-svc-vxrqx
Nov 21 08:33:20.650: INFO: Got endpoints: latency-svc-9shrp [735.741425ms]
Nov 21 08:33:20.673: INFO: Created: latency-svc-x7b8h
Nov 21 08:33:20.686: INFO: Got endpoints: latency-svc-m5tvf [747.388275ms]
Nov 21 08:33:20.747: INFO: Got endpoints: latency-svc-gqvdn [756.104354ms]
Nov 21 08:33:20.748: INFO: Created: latency-svc-5qms7
Nov 21 08:33:20.765: INFO: Created: latency-svc-bzkt2
Nov 21 08:33:20.786: INFO: Got endpoints: latency-svc-md2k5 [730.107755ms]
Nov 21 08:33:20.816: INFO: Created: latency-svc-ksbn7
Nov 21 08:33:20.836: INFO: Got endpoints: latency-svc-r57hm [749.71332ms]
Nov 21 08:33:20.908: INFO: Got endpoints: latency-svc-sv6jb [770.871407ms]
Nov 21 08:33:20.908: INFO: Created: latency-svc-sv9tg
Nov 21 08:33:20.931: INFO: Created: latency-svc-vr5r7
Nov 21 08:33:20.948: INFO: Got endpoints: latency-svc-rqc4f [759.559659ms]
Nov 21 08:33:20.971: INFO: Created: latency-svc-b7n45
Nov 21 08:33:20.986: INFO: Got endpoints: latency-svc-v9zw6 [747.398724ms]
Nov 21 08:33:21.039: INFO: Got endpoints: latency-svc-dvgvw [753.401003ms]
Nov 21 08:33:21.086: INFO: Got endpoints: latency-svc-frlh2 [745.731987ms]
Nov 21 08:33:21.136: INFO: Got endpoints: latency-svc-4qw9t [749.962476ms]
Nov 21 08:33:21.186: INFO: Got endpoints: latency-svc-2b6x7 [723.850283ms]
Nov 21 08:33:21.236: INFO: Got endpoints: latency-svc-9ts95 [735.551515ms]
Nov 21 08:33:21.286: INFO: Got endpoints: latency-svc-zxzsq [750.110404ms]
Nov 21 08:33:21.336: INFO: Got endpoints: latency-svc-vxrqx [730.632224ms]
Nov 21 08:33:21.405: INFO: Got endpoints: latency-svc-x7b8h [755.446793ms]
Nov 21 08:33:21.436: INFO: Got endpoints: latency-svc-5qms7 [749.863766ms]
Nov 21 08:33:21.487: INFO: Got endpoints: latency-svc-bzkt2 [739.256876ms]
Nov 21 08:33:21.543: INFO: Got endpoints: latency-svc-ksbn7 [756.811252ms]
Nov 21 08:33:21.586: INFO: Got endpoints: latency-svc-sv9tg [749.884529ms]
Nov 21 08:33:21.645: INFO: Got endpoints: latency-svc-vr5r7 [737.757767ms]
Nov 21 08:33:21.686: INFO: Got endpoints: latency-svc-b7n45 [737.964622ms]
Nov 21 08:33:21.686: INFO: Latencies: [28.634966ms 80.490754ms 85.66323ms 108.685414ms 131.480938ms 154.266569ms 212.073299ms 229.464005ms 251.535292ms 274.585219ms 332.845314ms 337.403431ms 372.945537ms 394.732529ms 412.005831ms 413.243704ms 413.425798ms 417.287392ms 429.059276ms 429.064261ms 429.134028ms 429.14499ms 429.148028ms 429.257854ms 429.363265ms 429.765115ms 434.88006ms 436.737524ms 440.626054ms 441.737455ms 452.144413ms 453.044762ms 457.575518ms 462.406229ms 464.141516ms 468.930948ms 474.708933ms 475.1071ms 476.540171ms 482.509437ms 484.383322ms 485.265277ms 487.830284ms 487.861435ms 498.097101ms 498.218241ms 501.37622ms 501.843837ms 502.180029ms 502.693169ms 508.113321ms 509.444469ms 510.898065ms 511.398679ms 515.011409ms 520.237744ms 520.469638ms 526.043609ms 526.191105ms 530.932739ms 531.314143ms 531.820407ms 531.935536ms 532.056094ms 532.431494ms 537.926071ms 539.675722ms 542.032232ms 543.39916ms 543.423351ms 543.592028ms 546.08033ms 550.043119ms 551.953498ms 556.921616ms 560.572964ms 561.630087ms 563.650239ms 564.069062ms 575.59477ms 578.216574ms 580.475993ms 590.180805ms 592.186289ms 594.850781ms 601.512835ms 612.038093ms 612.136117ms 612.279531ms 612.295415ms 621.200472ms 624.720178ms 632.273568ms 651.375984ms 652.192037ms 655.945648ms 667.975133ms 675.187563ms 698.058458ms 699.485569ms 701.136442ms 710.601469ms 711.774068ms 719.81124ms 723.682256ms 723.850283ms 724.216208ms 728.016051ms 728.653646ms 729.788128ms 729.797297ms 730.107755ms 730.632224ms 733.566013ms 733.994683ms 734.576905ms 735.551515ms 735.741425ms 737.204572ms 737.340137ms 737.757767ms 737.800216ms 737.964622ms 739.249615ms 739.256876ms 739.367313ms 740.820878ms 741.260398ms 742.134342ms 742.575245ms 742.808234ms 742.823469ms 742.928056ms 743.203645ms 743.686742ms 743.747052ms 744.003878ms 745.731987ms 746.333818ms 746.513209ms 746.520145ms 747.181148ms 747.388275ms 747.398724ms 747.891905ms 747.998599ms 748.022485ms 748.952818ms 749.237793ms 749.43162ms 749.535922ms 749.645492ms 749.664875ms 749.71332ms 749.863766ms 749.884529ms 749.888348ms 749.962476ms 749.977062ms 750.110404ms 750.546568ms 750.851494ms 750.931783ms 751.272289ms 751.578848ms 752.052105ms 752.343542ms 753.401003ms 755.26928ms 755.446793ms 756.104354ms 756.197453ms 756.811252ms 757.257547ms 757.326486ms 757.86874ms 758.050034ms 759.559659ms 760.938688ms 760.986806ms 761.976835ms 762.396669ms 762.769612ms 763.385129ms 763.456593ms 764.293059ms 765.038579ms 765.110044ms 766.890674ms 768.064588ms 768.074467ms 769.5247ms 769.698537ms 770.871407ms 772.252366ms 774.668698ms 774.914274ms 777.348254ms 777.824497ms 780.641368ms]
Nov 21 08:33:21.686: INFO: 50 %ile: 701.136442ms
Nov 21 08:33:21.686: INFO: 90 %ile: 761.976835ms
Nov 21 08:33:21.686: INFO: 99 %ile: 777.824497ms
Nov 21 08:33:21.686: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:33:21.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-754" for this suite.
Nov 21 08:33:37.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:33:37.774: INFO: namespace svc-latency-754 deletion completed in 16.082892462s

â€¢ [SLOW TEST:27.862 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:33:37.774: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap that has name configmap-test-emptyKey-9d347a53-0c39-11ea-a569-4e55f5a7674f
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:33:37.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-607" for this suite.
Nov 21 08:33:43.848: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:33:43.886: INFO: namespace configmap-607 deletion completed in 6.048734637s

â€¢ [SLOW TEST:6.112 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:33:43.887: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override all
Nov 21 08:33:43.958: INFO: Waiting up to 5m0s for pod "client-containers-a0da4b52-0c39-11ea-a569-4e55f5a7674f" in namespace "containers-1908" to be "success or failure"
Nov 21 08:33:43.961: INFO: Pod "client-containers-a0da4b52-0c39-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.766975ms
Nov 21 08:33:45.963: INFO: Pod "client-containers-a0da4b52-0c39-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005705382s
Nov 21 08:33:47.965: INFO: Pod "client-containers-a0da4b52-0c39-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007817478s
STEP: Saw pod success
Nov 21 08:33:47.965: INFO: Pod "client-containers-a0da4b52-0c39-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 08:33:47.967: INFO: Trying to get logs from node 192.168.0.92 pod client-containers-a0da4b52-0c39-11ea-a569-4e55f5a7674f container test-container: <nil>
STEP: delete the pod
Nov 21 08:33:48.018: INFO: Waiting for pod client-containers-a0da4b52-0c39-11ea-a569-4e55f5a7674f to disappear
Nov 21 08:33:48.024: INFO: Pod client-containers-a0da4b52-0c39-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:33:48.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1908" for this suite.
Nov 21 08:33:54.032: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:33:54.076: INFO: namespace containers-1908 deletion completed in 6.049525978s

â€¢ [SLOW TEST:10.189 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:33:54.076: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W1121 08:34:34.146746      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov 21 08:34:34.146: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:34:34.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4184" for this suite.
Nov 21 08:34:40.274: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:34:40.335: INFO: namespace gc-4184 deletion completed in 6.187199427s

â€¢ [SLOW TEST:46.260 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:34:40.336: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Nov 21 08:34:40.439: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c2841050-0c39-11ea-a569-4e55f5a7674f" in namespace "projected-8529" to be "success or failure"
Nov 21 08:34:40.458: INFO: Pod "downwardapi-volume-c2841050-0c39-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 19.167984ms
Nov 21 08:34:42.460: INFO: Pod "downwardapi-volume-c2841050-0c39-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021712701s
Nov 21 08:34:44.463: INFO: Pod "downwardapi-volume-c2841050-0c39-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024083478s
STEP: Saw pod success
Nov 21 08:34:44.463: INFO: Pod "downwardapi-volume-c2841050-0c39-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 08:34:44.464: INFO: Trying to get logs from node 192.168.0.93 pod downwardapi-volume-c2841050-0c39-11ea-a569-4e55f5a7674f container client-container: <nil>
STEP: delete the pod
Nov 21 08:34:44.527: INFO: Waiting for pod downwardapi-volume-c2841050-0c39-11ea-a569-4e55f5a7674f to disappear
Nov 21 08:34:44.534: INFO: Pod downwardapi-volume-c2841050-0c39-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:34:44.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8529" for this suite.
Nov 21 08:34:50.542: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:34:50.590: INFO: namespace projected-8529 deletion completed in 6.053157179s

â€¢ [SLOW TEST:10.254 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:34:50.590: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1510
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov 21 08:34:50.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-7974'
Nov 21 08:34:50.759: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov 21 08:34:50.759: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1515
Nov 21 08:34:50.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 delete jobs e2e-test-nginx-job --namespace=kubectl-7974'
Nov 21 08:34:50.857: INFO: stderr: ""
Nov 21 08:34:50.857: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:34:50.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7974" for this suite.
Nov 21 08:34:56.867: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:34:56.905: INFO: namespace kubectl-7974 deletion completed in 6.046352175s

â€¢ [SLOW TEST:6.315 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:34:56.905: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-v7jmk in namespace proxy-1368
I1121 08:34:57.049229      17 runners.go:184] Created replication controller with name: proxy-service-v7jmk, namespace: proxy-1368, replica count: 1
I1121 08:34:58.099497      17 runners.go:184] proxy-service-v7jmk Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1121 08:34:59.099643      17 runners.go:184] proxy-service-v7jmk Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1121 08:35:00.099789      17 runners.go:184] proxy-service-v7jmk Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1121 08:35:01.099944      17 runners.go:184] proxy-service-v7jmk Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 21 08:35:01.101: INFO: setup took 4.149069474s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Nov 21 08:35:01.105: INFO: (0) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:160/proxy/: foo (200; 3.643518ms)
Nov 21 08:35:01.105: INFO: (0) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk/proxy/rewriteme">test</a> (200; 3.944317ms)
Nov 21 08:35:01.106: INFO: (0) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:1080/proxy/rewriteme">... (200; 4.15934ms)
Nov 21 08:35:01.106: INFO: (0) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:1080/proxy/rewriteme">test<... (200; 4.238113ms)
Nov 21 08:35:01.106: INFO: (0) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:162/proxy/: bar (200; 4.2008ms)
Nov 21 08:35:01.106: INFO: (0) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:162/proxy/: bar (200; 4.270359ms)
Nov 21 08:35:01.106: INFO: (0) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:160/proxy/: foo (200; 4.410159ms)
Nov 21 08:35:01.106: INFO: (0) /api/v1/namespaces/proxy-1368/services/proxy-service-v7jmk:portname1/proxy/: foo (200; 4.474157ms)
Nov 21 08:35:01.106: INFO: (0) /api/v1/namespaces/proxy-1368/services/http:proxy-service-v7jmk:portname2/proxy/: bar (200; 4.468013ms)
Nov 21 08:35:01.106: INFO: (0) /api/v1/namespaces/proxy-1368/services/http:proxy-service-v7jmk:portname1/proxy/: foo (200; 4.545972ms)
Nov 21 08:35:01.106: INFO: (0) /api/v1/namespaces/proxy-1368/services/proxy-service-v7jmk:portname2/proxy/: bar (200; 4.651903ms)
Nov 21 08:35:01.110: INFO: (0) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:460/proxy/: tls baz (200; 8.872191ms)
Nov 21 08:35:01.110: INFO: (0) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:462/proxy/: tls qux (200; 8.868407ms)
Nov 21 08:35:01.111: INFO: (0) /api/v1/namespaces/proxy-1368/services/https:proxy-service-v7jmk:tlsportname1/proxy/: tls baz (200; 9.005182ms)
Nov 21 08:35:01.114: INFO: (0) /api/v1/namespaces/proxy-1368/services/https:proxy-service-v7jmk:tlsportname2/proxy/: tls qux (200; 12.412534ms)
Nov 21 08:35:01.114: INFO: (0) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:443/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:443/proxy/tlsrewritem... (200; 12.659324ms)
Nov 21 08:35:01.116: INFO: (1) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk/proxy/rewriteme">test</a> (200; 1.960645ms)
Nov 21 08:35:01.116: INFO: (1) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:460/proxy/: tls baz (200; 1.971744ms)
Nov 21 08:35:01.117: INFO: (1) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:462/proxy/: tls qux (200; 2.318729ms)
Nov 21 08:35:01.117: INFO: (1) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:160/proxy/: foo (200; 2.391099ms)
Nov 21 08:35:01.117: INFO: (1) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:443/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:443/proxy/tlsrewritem... (200; 2.525952ms)
Nov 21 08:35:01.117: INFO: (1) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:1080/proxy/rewriteme">... (200; 2.464176ms)
Nov 21 08:35:01.117: INFO: (1) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:160/proxy/: foo (200; 2.529262ms)
Nov 21 08:35:01.117: INFO: (1) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:162/proxy/: bar (200; 2.609445ms)
Nov 21 08:35:01.117: INFO: (1) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:1080/proxy/rewriteme">test<... (200; 2.824561ms)
Nov 21 08:35:01.117: INFO: (1) /api/v1/namespaces/proxy-1368/services/proxy-service-v7jmk:portname2/proxy/: bar (200; 2.927566ms)
Nov 21 08:35:01.117: INFO: (1) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:162/proxy/: bar (200; 3.07639ms)
Nov 21 08:35:01.117: INFO: (1) /api/v1/namespaces/proxy-1368/services/https:proxy-service-v7jmk:tlsportname2/proxy/: tls qux (200; 3.143158ms)
Nov 21 08:35:01.117: INFO: (1) /api/v1/namespaces/proxy-1368/services/proxy-service-v7jmk:portname1/proxy/: foo (200; 3.13028ms)
Nov 21 08:35:01.117: INFO: (1) /api/v1/namespaces/proxy-1368/services/http:proxy-service-v7jmk:portname2/proxy/: bar (200; 3.100977ms)
Nov 21 08:35:01.117: INFO: (1) /api/v1/namespaces/proxy-1368/services/https:proxy-service-v7jmk:tlsportname1/proxy/: tls baz (200; 3.136713ms)
Nov 21 08:35:01.117: INFO: (1) /api/v1/namespaces/proxy-1368/services/http:proxy-service-v7jmk:portname1/proxy/: foo (200; 3.220487ms)
Nov 21 08:35:01.119: INFO: (2) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:462/proxy/: tls qux (200; 1.873892ms)
Nov 21 08:35:01.120: INFO: (2) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:162/proxy/: bar (200; 2.313521ms)
Nov 21 08:35:01.120: INFO: (2) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:160/proxy/: foo (200; 2.929873ms)
Nov 21 08:35:01.120: INFO: (2) /api/v1/namespaces/proxy-1368/services/https:proxy-service-v7jmk:tlsportname2/proxy/: tls qux (200; 2.988786ms)
Nov 21 08:35:01.120: INFO: (2) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:160/proxy/: foo (200; 2.960871ms)
Nov 21 08:35:01.121: INFO: (2) /api/v1/namespaces/proxy-1368/services/http:proxy-service-v7jmk:portname2/proxy/: bar (200; 2.955196ms)
Nov 21 08:35:01.121: INFO: (2) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:443/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:443/proxy/tlsrewritem... (200; 2.960671ms)
Nov 21 08:35:01.121: INFO: (2) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:1080/proxy/rewriteme">... (200; 2.944963ms)
Nov 21 08:35:01.121: INFO: (2) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:460/proxy/: tls baz (200; 3.008613ms)
Nov 21 08:35:01.121: INFO: (2) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk/proxy/rewriteme">test</a> (200; 3.061054ms)
Nov 21 08:35:01.121: INFO: (2) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:162/proxy/: bar (200; 3.091645ms)
Nov 21 08:35:01.121: INFO: (2) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:1080/proxy/rewriteme">test<... (200; 3.129376ms)
Nov 21 08:35:01.121: INFO: (2) /api/v1/namespaces/proxy-1368/services/https:proxy-service-v7jmk:tlsportname1/proxy/: tls baz (200; 3.134145ms)
Nov 21 08:35:01.121: INFO: (2) /api/v1/namespaces/proxy-1368/services/proxy-service-v7jmk:portname2/proxy/: bar (200; 3.280428ms)
Nov 21 08:35:01.121: INFO: (2) /api/v1/namespaces/proxy-1368/services/http:proxy-service-v7jmk:portname1/proxy/: foo (200; 3.355425ms)
Nov 21 08:35:01.121: INFO: (2) /api/v1/namespaces/proxy-1368/services/proxy-service-v7jmk:portname1/proxy/: foo (200; 3.336957ms)
Nov 21 08:35:01.123: INFO: (3) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk/proxy/rewriteme">test</a> (200; 1.626124ms)
Nov 21 08:35:01.123: INFO: (3) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:162/proxy/: bar (200; 1.789687ms)
Nov 21 08:35:01.124: INFO: (3) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:1080/proxy/rewriteme">test<... (200; 3.399262ms)
Nov 21 08:35:01.124: INFO: (3) /api/v1/namespaces/proxy-1368/services/http:proxy-service-v7jmk:portname2/proxy/: bar (200; 3.370051ms)
Nov 21 08:35:01.125: INFO: (3) /api/v1/namespaces/proxy-1368/services/proxy-service-v7jmk:portname1/proxy/: foo (200; 3.574084ms)
Nov 21 08:35:01.125: INFO: (3) /api/v1/namespaces/proxy-1368/services/proxy-service-v7jmk:portname2/proxy/: bar (200; 3.673552ms)
Nov 21 08:35:01.125: INFO: (3) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:460/proxy/: tls baz (200; 3.610907ms)
Nov 21 08:35:01.125: INFO: (3) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:443/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:443/proxy/tlsrewritem... (200; 3.614269ms)
Nov 21 08:35:01.125: INFO: (3) /api/v1/namespaces/proxy-1368/services/http:proxy-service-v7jmk:portname1/proxy/: foo (200; 3.678017ms)
Nov 21 08:35:01.125: INFO: (3) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:1080/proxy/rewriteme">... (200; 3.710898ms)
Nov 21 08:35:01.125: INFO: (3) /api/v1/namespaces/proxy-1368/services/https:proxy-service-v7jmk:tlsportname1/proxy/: tls baz (200; 3.695164ms)
Nov 21 08:35:01.125: INFO: (3) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:160/proxy/: foo (200; 3.676463ms)
Nov 21 08:35:01.125: INFO: (3) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:160/proxy/: foo (200; 3.689111ms)
Nov 21 08:35:01.125: INFO: (3) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:462/proxy/: tls qux (200; 3.690596ms)
Nov 21 08:35:01.125: INFO: (3) /api/v1/namespaces/proxy-1368/services/https:proxy-service-v7jmk:tlsportname2/proxy/: tls qux (200; 3.664265ms)
Nov 21 08:35:01.125: INFO: (3) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:162/proxy/: bar (200; 3.682561ms)
Nov 21 08:35:01.127: INFO: (4) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:460/proxy/: tls baz (200; 1.904307ms)
Nov 21 08:35:01.127: INFO: (4) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:160/proxy/: foo (200; 2.062152ms)
Nov 21 08:35:01.127: INFO: (4) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:1080/proxy/rewriteme">test<... (200; 2.027473ms)
Nov 21 08:35:01.127: INFO: (4) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk/proxy/rewriteme">test</a> (200; 2.304212ms)
Nov 21 08:35:01.127: INFO: (4) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:1080/proxy/rewriteme">... (200; 2.301776ms)
Nov 21 08:35:01.127: INFO: (4) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:162/proxy/: bar (200; 2.365569ms)
Nov 21 08:35:01.127: INFO: (4) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:462/proxy/: tls qux (200; 2.377133ms)
Nov 21 08:35:01.127: INFO: (4) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:162/proxy/: bar (200; 2.386563ms)
Nov 21 08:35:01.127: INFO: (4) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:443/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:443/proxy/tlsrewritem... (200; 2.504231ms)
Nov 21 08:35:01.127: INFO: (4) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:160/proxy/: foo (200; 2.518016ms)
Nov 21 08:35:01.128: INFO: (4) /api/v1/namespaces/proxy-1368/services/http:proxy-service-v7jmk:portname1/proxy/: foo (200; 2.689156ms)
Nov 21 08:35:01.128: INFO: (4) /api/v1/namespaces/proxy-1368/services/proxy-service-v7jmk:portname2/proxy/: bar (200; 2.790276ms)
Nov 21 08:35:01.128: INFO: (4) /api/v1/namespaces/proxy-1368/services/https:proxy-service-v7jmk:tlsportname2/proxy/: tls qux (200; 2.819397ms)
Nov 21 08:35:01.128: INFO: (4) /api/v1/namespaces/proxy-1368/services/https:proxy-service-v7jmk:tlsportname1/proxy/: tls baz (200; 2.84809ms)
Nov 21 08:35:01.128: INFO: (4) /api/v1/namespaces/proxy-1368/services/proxy-service-v7jmk:portname1/proxy/: foo (200; 2.927773ms)
Nov 21 08:35:01.128: INFO: (4) /api/v1/namespaces/proxy-1368/services/http:proxy-service-v7jmk:portname2/proxy/: bar (200; 2.974221ms)
Nov 21 08:35:01.130: INFO: (5) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:462/proxy/: tls qux (200; 1.965384ms)
Nov 21 08:35:01.130: INFO: (5) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:162/proxy/: bar (200; 1.927612ms)
Nov 21 08:35:01.130: INFO: (5) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:443/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:443/proxy/tlsrewritem... (200; 1.954524ms)
Nov 21 08:35:01.130: INFO: (5) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:460/proxy/: tls baz (200; 2.140676ms)
Nov 21 08:35:01.130: INFO: (5) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:160/proxy/: foo (200; 2.115341ms)
Nov 21 08:35:01.130: INFO: (5) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:1080/proxy/rewriteme">test<... (200; 2.268451ms)
Nov 21 08:35:01.130: INFO: (5) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk/proxy/rewriteme">test</a> (200; 2.366668ms)
Nov 21 08:35:01.130: INFO: (5) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:162/proxy/: bar (200; 2.391087ms)
Nov 21 08:35:01.130: INFO: (5) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:160/proxy/: foo (200; 2.400014ms)
Nov 21 08:35:01.130: INFO: (5) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:1080/proxy/rewriteme">... (200; 2.42787ms)
Nov 21 08:35:01.130: INFO: (5) /api/v1/namespaces/proxy-1368/services/https:proxy-service-v7jmk:tlsportname1/proxy/: tls baz (200; 2.562782ms)
Nov 21 08:35:01.131: INFO: (5) /api/v1/namespaces/proxy-1368/services/proxy-service-v7jmk:portname2/proxy/: bar (200; 2.717681ms)
Nov 21 08:35:01.131: INFO: (5) /api/v1/namespaces/proxy-1368/services/http:proxy-service-v7jmk:portname2/proxy/: bar (200; 2.802161ms)
Nov 21 08:35:01.131: INFO: (5) /api/v1/namespaces/proxy-1368/services/https:proxy-service-v7jmk:tlsportname2/proxy/: tls qux (200; 2.801147ms)
Nov 21 08:35:01.131: INFO: (5) /api/v1/namespaces/proxy-1368/services/proxy-service-v7jmk:portname1/proxy/: foo (200; 2.860366ms)
Nov 21 08:35:01.131: INFO: (5) /api/v1/namespaces/proxy-1368/services/http:proxy-service-v7jmk:portname1/proxy/: foo (200; 2.828734ms)
Nov 21 08:35:01.133: INFO: (6) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:162/proxy/: bar (200; 2.330753ms)
Nov 21 08:35:01.133: INFO: (6) /api/v1/namespaces/proxy-1368/services/http:proxy-service-v7jmk:portname2/proxy/: bar (200; 2.569225ms)
Nov 21 08:35:01.134: INFO: (6) /api/v1/namespaces/proxy-1368/services/proxy-service-v7jmk:portname1/proxy/: foo (200; 2.786358ms)
Nov 21 08:35:01.134: INFO: (6) /api/v1/namespaces/proxy-1368/services/https:proxy-service-v7jmk:tlsportname2/proxy/: tls qux (200; 2.986735ms)
Nov 21 08:35:01.134: INFO: (6) /api/v1/namespaces/proxy-1368/services/https:proxy-service-v7jmk:tlsportname1/proxy/: tls baz (200; 2.958486ms)
Nov 21 08:35:01.134: INFO: (6) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk/proxy/rewriteme">test</a> (200; 2.991324ms)
Nov 21 08:35:01.134: INFO: (6) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:1080/proxy/rewriteme">test<... (200; 3.006895ms)
Nov 21 08:35:01.134: INFO: (6) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:160/proxy/: foo (200; 2.993644ms)
Nov 21 08:35:01.134: INFO: (6) /api/v1/namespaces/proxy-1368/services/proxy-service-v7jmk:portname2/proxy/: bar (200; 2.994147ms)
Nov 21 08:35:01.134: INFO: (6) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:1080/proxy/rewriteme">... (200; 2.98183ms)
Nov 21 08:35:01.134: INFO: (6) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:162/proxy/: bar (200; 3.065656ms)
Nov 21 08:35:01.134: INFO: (6) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:462/proxy/: tls qux (200; 3.03571ms)
Nov 21 08:35:01.134: INFO: (6) /api/v1/namespaces/proxy-1368/services/http:proxy-service-v7jmk:portname1/proxy/: foo (200; 3.114ms)
Nov 21 08:35:01.134: INFO: (6) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:460/proxy/: tls baz (200; 3.068082ms)
Nov 21 08:35:01.134: INFO: (6) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:160/proxy/: foo (200; 3.105205ms)
Nov 21 08:35:01.134: INFO: (6) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:443/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:443/proxy/tlsrewritem... (200; 3.156549ms)
Nov 21 08:35:01.136: INFO: (7) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:462/proxy/: tls qux (200; 2.126359ms)
Nov 21 08:35:01.136: INFO: (7) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:443/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:443/proxy/tlsrewritem... (200; 2.054506ms)
Nov 21 08:35:01.136: INFO: (7) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:160/proxy/: foo (200; 2.160565ms)
Nov 21 08:35:01.136: INFO: (7) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk/proxy/rewriteme">test</a> (200; 2.250544ms)
Nov 21 08:35:01.137: INFO: (7) /api/v1/namespaces/proxy-1368/services/proxy-service-v7jmk:portname2/proxy/: bar (200; 2.647067ms)
Nov 21 08:35:01.137: INFO: (7) /api/v1/namespaces/proxy-1368/services/https:proxy-service-v7jmk:tlsportname1/proxy/: tls baz (200; 2.804136ms)
Nov 21 08:35:01.137: INFO: (7) /api/v1/namespaces/proxy-1368/services/proxy-service-v7jmk:portname1/proxy/: foo (200; 2.83887ms)
Nov 21 08:35:01.137: INFO: (7) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:1080/proxy/rewriteme">test<... (200; 2.853939ms)
Nov 21 08:35:01.137: INFO: (7) /api/v1/namespaces/proxy-1368/services/https:proxy-service-v7jmk:tlsportname2/proxy/: tls qux (200; 2.935784ms)
Nov 21 08:35:01.137: INFO: (7) /api/v1/namespaces/proxy-1368/services/http:proxy-service-v7jmk:portname1/proxy/: foo (200; 2.911823ms)
Nov 21 08:35:01.137: INFO: (7) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:1080/proxy/rewriteme">... (200; 2.8433ms)
Nov 21 08:35:01.137: INFO: (7) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:460/proxy/: tls baz (200; 2.93012ms)
Nov 21 08:35:01.137: INFO: (7) /api/v1/namespaces/proxy-1368/services/http:proxy-service-v7jmk:portname2/proxy/: bar (200; 2.957457ms)
Nov 21 08:35:01.142: INFO: (7) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:162/proxy/: bar (200; 7.943746ms)
Nov 21 08:35:01.142: INFO: (7) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:160/proxy/: foo (200; 7.993ms)
Nov 21 08:35:01.142: INFO: (7) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:162/proxy/: bar (200; 8.059503ms)
Nov 21 08:35:01.144: INFO: (8) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:462/proxy/: tls qux (200; 1.764463ms)
Nov 21 08:35:01.144: INFO: (8) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:1080/proxy/rewriteme">test<... (200; 2.041813ms)
Nov 21 08:35:01.144: INFO: (8) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:162/proxy/: bar (200; 2.120373ms)
Nov 21 08:35:01.145: INFO: (8) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk/proxy/rewriteme">test</a> (200; 2.167961ms)
Nov 21 08:35:01.145: INFO: (8) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:160/proxy/: foo (200; 2.224644ms)
Nov 21 08:35:01.145: INFO: (8) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:460/proxy/: tls baz (200; 2.207154ms)
Nov 21 08:35:01.145: INFO: (8) /api/v1/namespaces/proxy-1368/services/proxy-service-v7jmk:portname1/proxy/: foo (200; 2.883928ms)
Nov 21 08:35:01.145: INFO: (8) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:162/proxy/: bar (200; 2.796241ms)
Nov 21 08:35:01.145: INFO: (8) /api/v1/namespaces/proxy-1368/services/http:proxy-service-v7jmk:portname1/proxy/: foo (200; 2.904434ms)
Nov 21 08:35:01.145: INFO: (8) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:1080/proxy/rewriteme">... (200; 2.861621ms)
Nov 21 08:35:01.145: INFO: (8) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:443/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:443/proxy/tlsrewritem... (200; 3.018814ms)
Nov 21 08:35:01.145: INFO: (8) /api/v1/namespaces/proxy-1368/services/https:proxy-service-v7jmk:tlsportname1/proxy/: tls baz (200; 3.052509ms)
Nov 21 08:35:01.145: INFO: (8) /api/v1/namespaces/proxy-1368/services/http:proxy-service-v7jmk:portname2/proxy/: bar (200; 3.099996ms)
Nov 21 08:35:01.146: INFO: (8) /api/v1/namespaces/proxy-1368/services/https:proxy-service-v7jmk:tlsportname2/proxy/: tls qux (200; 3.169596ms)
Nov 21 08:35:01.146: INFO: (8) /api/v1/namespaces/proxy-1368/services/proxy-service-v7jmk:portname2/proxy/: bar (200; 3.18948ms)
Nov 21 08:35:01.146: INFO: (8) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:160/proxy/: foo (200; 3.336069ms)
Nov 21 08:35:01.148: INFO: (9) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:460/proxy/: tls baz (200; 1.897761ms)
Nov 21 08:35:01.148: INFO: (9) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:443/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:443/proxy/tlsrewritem... (200; 2.341971ms)
Nov 21 08:35:01.148: INFO: (9) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk/proxy/rewriteme">test</a> (200; 2.336535ms)
Nov 21 08:35:01.148: INFO: (9) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:1080/proxy/rewriteme">test<... (200; 2.320835ms)
Nov 21 08:35:01.149: INFO: (9) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:162/proxy/: bar (200; 2.810822ms)
Nov 21 08:35:01.149: INFO: (9) /api/v1/namespaces/proxy-1368/services/http:proxy-service-v7jmk:portname2/proxy/: bar (200; 2.882443ms)
Nov 21 08:35:01.149: INFO: (9) /api/v1/namespaces/proxy-1368/services/http:proxy-service-v7jmk:portname1/proxy/: foo (200; 3.057122ms)
Nov 21 08:35:01.149: INFO: (9) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:1080/proxy/rewriteme">... (200; 3.174285ms)
Nov 21 08:35:01.149: INFO: (9) /api/v1/namespaces/proxy-1368/services/https:proxy-service-v7jmk:tlsportname2/proxy/: tls qux (200; 3.233737ms)
Nov 21 08:35:01.149: INFO: (9) /api/v1/namespaces/proxy-1368/services/proxy-service-v7jmk:portname1/proxy/: foo (200; 3.238201ms)
Nov 21 08:35:01.149: INFO: (9) /api/v1/namespaces/proxy-1368/services/https:proxy-service-v7jmk:tlsportname1/proxy/: tls baz (200; 3.245828ms)
Nov 21 08:35:01.149: INFO: (9) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:162/proxy/: bar (200; 3.35338ms)
Nov 21 08:35:01.149: INFO: (9) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:160/proxy/: foo (200; 3.378603ms)
Nov 21 08:35:01.149: INFO: (9) /api/v1/namespaces/proxy-1368/services/proxy-service-v7jmk:portname2/proxy/: bar (200; 3.337385ms)
Nov 21 08:35:01.149: INFO: (9) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:462/proxy/: tls qux (200; 3.338914ms)
Nov 21 08:35:01.149: INFO: (9) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:160/proxy/: foo (200; 3.350963ms)
Nov 21 08:35:01.151: INFO: (10) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:162/proxy/: bar (200; 1.920107ms)
Nov 21 08:35:01.152: INFO: (10) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:162/proxy/: bar (200; 2.851173ms)
Nov 21 08:35:01.152: INFO: (10) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:462/proxy/: tls qux (200; 2.926809ms)
Nov 21 08:35:01.152: INFO: (10) /api/v1/namespaces/proxy-1368/services/proxy-service-v7jmk:portname2/proxy/: bar (200; 2.915ms)
Nov 21 08:35:01.152: INFO: (10) /api/v1/namespaces/proxy-1368/services/proxy-service-v7jmk:portname1/proxy/: foo (200; 2.855425ms)
Nov 21 08:35:01.152: INFO: (10) /api/v1/namespaces/proxy-1368/services/http:proxy-service-v7jmk:portname1/proxy/: foo (200; 3.056928ms)
Nov 21 08:35:01.152: INFO: (10) /api/v1/namespaces/proxy-1368/services/https:proxy-service-v7jmk:tlsportname2/proxy/: tls qux (200; 3.104737ms)
Nov 21 08:35:01.156: INFO: (10) /api/v1/namespaces/proxy-1368/services/http:proxy-service-v7jmk:portname2/proxy/: bar (200; 6.402539ms)
Nov 21 08:35:01.156: INFO: (10) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:160/proxy/: foo (200; 6.465957ms)
Nov 21 08:35:01.156: INFO: (10) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:443/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:443/proxy/tlsrewritem... (200; 6.427074ms)
Nov 21 08:35:01.156: INFO: (10) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:1080/proxy/rewriteme">test<... (200; 6.466086ms)
Nov 21 08:35:01.156: INFO: (10) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk/proxy/rewriteme">test</a> (200; 6.46797ms)
Nov 21 08:35:01.156: INFO: (10) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:460/proxy/: tls baz (200; 6.515779ms)
Nov 21 08:35:01.156: INFO: (10) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:160/proxy/: foo (200; 6.616619ms)
Nov 21 08:35:01.156: INFO: (10) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:1080/proxy/rewriteme">... (200; 6.535699ms)
Nov 21 08:35:01.156: INFO: (10) /api/v1/namespaces/proxy-1368/services/https:proxy-service-v7jmk:tlsportname1/proxy/: tls baz (200; 6.533866ms)
Nov 21 08:35:01.158: INFO: (11) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:1080/proxy/rewriteme">... (200; 2.464223ms)
Nov 21 08:35:01.160: INFO: (11) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:162/proxy/: bar (200; 3.541147ms)
Nov 21 08:35:01.160: INFO: (11) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:460/proxy/: tls baz (200; 3.638427ms)
Nov 21 08:35:01.160: INFO: (11) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk/proxy/rewriteme">test</a> (200; 3.668804ms)
Nov 21 08:35:01.160: INFO: (11) /api/v1/namespaces/proxy-1368/services/https:proxy-service-v7jmk:tlsportname2/proxy/: tls qux (200; 3.708738ms)
Nov 21 08:35:01.160: INFO: (11) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:160/proxy/: foo (200; 3.66627ms)
Nov 21 08:35:01.160: INFO: (11) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:1080/proxy/rewriteme">test<... (200; 3.675758ms)
Nov 21 08:35:01.160: INFO: (11) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:443/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:443/proxy/tlsrewritem... (200; 3.745279ms)
Nov 21 08:35:01.160: INFO: (11) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:162/proxy/: bar (200; 3.672178ms)
Nov 21 08:35:01.160: INFO: (11) /api/v1/namespaces/proxy-1368/services/https:proxy-service-v7jmk:tlsportname1/proxy/: tls baz (200; 3.759541ms)
Nov 21 08:35:01.160: INFO: (11) /api/v1/namespaces/proxy-1368/services/http:proxy-service-v7jmk:portname1/proxy/: foo (200; 3.795073ms)
Nov 21 08:35:01.160: INFO: (11) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:160/proxy/: foo (200; 3.881995ms)
Nov 21 08:35:01.160: INFO: (11) /api/v1/namespaces/proxy-1368/services/proxy-service-v7jmk:portname2/proxy/: bar (200; 3.912222ms)
Nov 21 08:35:01.160: INFO: (11) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:462/proxy/: tls qux (200; 3.991818ms)
Nov 21 08:35:01.160: INFO: (11) /api/v1/namespaces/proxy-1368/services/proxy-service-v7jmk:portname1/proxy/: foo (200; 3.918608ms)
Nov 21 08:35:01.160: INFO: (11) /api/v1/namespaces/proxy-1368/services/http:proxy-service-v7jmk:portname2/proxy/: bar (200; 4.029535ms)
Nov 21 08:35:01.163: INFO: (12) /api/v1/namespaces/proxy-1368/services/proxy-service-v7jmk:portname1/proxy/: foo (200; 3.182359ms)
Nov 21 08:35:01.163: INFO: (12) /api/v1/namespaces/proxy-1368/services/proxy-service-v7jmk:portname2/proxy/: bar (200; 3.281025ms)
Nov 21 08:35:01.163: INFO: (12) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:162/proxy/: bar (200; 3.315402ms)
Nov 21 08:35:01.163: INFO: (12) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk/proxy/rewriteme">test</a> (200; 3.364363ms)
Nov 21 08:35:01.164: INFO: (12) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:1080/proxy/rewriteme">test<... (200; 3.468469ms)
Nov 21 08:35:01.164: INFO: (12) /api/v1/namespaces/proxy-1368/services/https:proxy-service-v7jmk:tlsportname2/proxy/: tls qux (200; 3.539959ms)
Nov 21 08:35:01.164: INFO: (12) /api/v1/namespaces/proxy-1368/services/http:proxy-service-v7jmk:portname1/proxy/: foo (200; 3.512303ms)
Nov 21 08:35:01.164: INFO: (12) /api/v1/namespaces/proxy-1368/services/https:proxy-service-v7jmk:tlsportname1/proxy/: tls baz (200; 3.596369ms)
Nov 21 08:35:01.164: INFO: (12) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:462/proxy/: tls qux (200; 3.556103ms)
Nov 21 08:35:01.164: INFO: (12) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:1080/proxy/rewriteme">... (200; 3.76243ms)
Nov 21 08:35:01.164: INFO: (12) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:443/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:443/proxy/tlsrewritem... (200; 3.862949ms)
Nov 21 08:35:01.164: INFO: (12) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:460/proxy/: tls baz (200; 3.933713ms)
Nov 21 08:35:01.164: INFO: (12) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:160/proxy/: foo (200; 3.949537ms)
Nov 21 08:35:01.164: INFO: (12) /api/v1/namespaces/proxy-1368/services/http:proxy-service-v7jmk:portname2/proxy/: bar (200; 4.009531ms)
Nov 21 08:35:01.164: INFO: (12) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:160/proxy/: foo (200; 3.919248ms)
Nov 21 08:35:01.164: INFO: (12) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:162/proxy/: bar (200; 4.018804ms)
Nov 21 08:35:01.167: INFO: (13) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:160/proxy/: foo (200; 2.463326ms)
Nov 21 08:35:01.167: INFO: (13) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:1080/proxy/rewriteme">... (200; 2.619041ms)
Nov 21 08:35:01.167: INFO: (13) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:460/proxy/: tls baz (200; 2.741857ms)
Nov 21 08:35:01.167: INFO: (13) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:160/proxy/: foo (200; 2.695724ms)
Nov 21 08:35:01.167: INFO: (13) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:443/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:443/proxy/tlsrewritem... (200; 2.862735ms)
Nov 21 08:35:01.167: INFO: (13) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk/proxy/rewriteme">test</a> (200; 3.087854ms)
Nov 21 08:35:01.167: INFO: (13) /api/v1/namespaces/proxy-1368/services/https:proxy-service-v7jmk:tlsportname1/proxy/: tls baz (200; 3.166315ms)
Nov 21 08:35:01.167: INFO: (13) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:162/proxy/: bar (200; 3.092622ms)
Nov 21 08:35:01.167: INFO: (13) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:162/proxy/: bar (200; 3.309402ms)
Nov 21 08:35:01.167: INFO: (13) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:462/proxy/: tls qux (200; 3.368766ms)
Nov 21 08:35:01.168: INFO: (13) /api/v1/namespaces/proxy-1368/services/proxy-service-v7jmk:portname1/proxy/: foo (200; 3.382937ms)
Nov 21 08:35:01.168: INFO: (13) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:1080/proxy/rewriteme">test<... (200; 3.496955ms)
Nov 21 08:35:01.168: INFO: (13) /api/v1/namespaces/proxy-1368/services/http:proxy-service-v7jmk:portname1/proxy/: foo (200; 3.571284ms)
Nov 21 08:35:01.168: INFO: (13) /api/v1/namespaces/proxy-1368/services/proxy-service-v7jmk:portname2/proxy/: bar (200; 3.592687ms)
Nov 21 08:35:01.168: INFO: (13) /api/v1/namespaces/proxy-1368/services/https:proxy-service-v7jmk:tlsportname2/proxy/: tls qux (200; 3.576256ms)
Nov 21 08:35:01.168: INFO: (13) /api/v1/namespaces/proxy-1368/services/http:proxy-service-v7jmk:portname2/proxy/: bar (200; 3.579801ms)
Nov 21 08:35:01.171: INFO: (14) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:1080/proxy/rewriteme">... (200; 2.89449ms)
Nov 21 08:35:01.171: INFO: (14) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:160/proxy/: foo (200; 2.809593ms)
Nov 21 08:35:01.171: INFO: (14) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:460/proxy/: tls baz (200; 2.931164ms)
Nov 21 08:35:01.171: INFO: (14) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:462/proxy/: tls qux (200; 2.907215ms)
Nov 21 08:35:01.171: INFO: (14) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:160/proxy/: foo (200; 2.898042ms)
Nov 21 08:35:01.171: INFO: (14) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:162/proxy/: bar (200; 2.872971ms)
Nov 21 08:35:01.171: INFO: (14) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:162/proxy/: bar (200; 2.843887ms)
Nov 21 08:35:01.171: INFO: (14) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:1080/proxy/rewriteme">test<... (200; 2.857759ms)
Nov 21 08:35:01.171: INFO: (14) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk/proxy/rewriteme">test</a> (200; 2.97011ms)
Nov 21 08:35:01.171: INFO: (14) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:443/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:443/proxy/tlsrewritem... (200; 2.9149ms)
Nov 21 08:35:01.171: INFO: (14) /api/v1/namespaces/proxy-1368/services/proxy-service-v7jmk:portname1/proxy/: foo (200; 3.461386ms)
Nov 21 08:35:01.171: INFO: (14) /api/v1/namespaces/proxy-1368/services/http:proxy-service-v7jmk:portname1/proxy/: foo (200; 3.523712ms)
Nov 21 08:35:01.171: INFO: (14) /api/v1/namespaces/proxy-1368/services/http:proxy-service-v7jmk:portname2/proxy/: bar (200; 3.503292ms)
Nov 21 08:35:01.171: INFO: (14) /api/v1/namespaces/proxy-1368/services/https:proxy-service-v7jmk:tlsportname1/proxy/: tls baz (200; 3.535468ms)
Nov 21 08:35:01.171: INFO: (14) /api/v1/namespaces/proxy-1368/services/https:proxy-service-v7jmk:tlsportname2/proxy/: tls qux (200; 3.530897ms)
Nov 21 08:35:01.171: INFO: (14) /api/v1/namespaces/proxy-1368/services/proxy-service-v7jmk:portname2/proxy/: bar (200; 3.608258ms)
Nov 21 08:35:01.173: INFO: (15) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:1080/proxy/rewriteme">... (200; 1.896507ms)
Nov 21 08:35:01.173: INFO: (15) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:460/proxy/: tls baz (200; 1.98899ms)
Nov 21 08:35:01.175: INFO: (15) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:160/proxy/: foo (200; 3.421021ms)
Nov 21 08:35:01.175: INFO: (15) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:462/proxy/: tls qux (200; 3.521415ms)
Nov 21 08:35:01.176: INFO: (15) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:162/proxy/: bar (200; 4.041429ms)
Nov 21 08:35:01.176: INFO: (15) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:443/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:443/proxy/tlsrewritem... (200; 4.019002ms)
Nov 21 08:35:01.176: INFO: (15) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:162/proxy/: bar (200; 4.216986ms)
Nov 21 08:35:01.176: INFO: (15) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk/proxy/rewriteme">test</a> (200; 4.21384ms)
Nov 21 08:35:01.176: INFO: (15) /api/v1/namespaces/proxy-1368/services/https:proxy-service-v7jmk:tlsportname2/proxy/: tls qux (200; 4.389646ms)
Nov 21 08:35:01.176: INFO: (15) /api/v1/namespaces/proxy-1368/services/https:proxy-service-v7jmk:tlsportname1/proxy/: tls baz (200; 4.413944ms)
Nov 21 08:35:01.176: INFO: (15) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:160/proxy/: foo (200; 4.416346ms)
Nov 21 08:35:01.176: INFO: (15) /api/v1/namespaces/proxy-1368/services/http:proxy-service-v7jmk:portname1/proxy/: foo (200; 4.469797ms)
Nov 21 08:35:01.176: INFO: (15) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:1080/proxy/rewriteme">test<... (200; 4.531503ms)
Nov 21 08:35:01.176: INFO: (15) /api/v1/namespaces/proxy-1368/services/http:proxy-service-v7jmk:portname2/proxy/: bar (200; 4.596995ms)
Nov 21 08:35:01.176: INFO: (15) /api/v1/namespaces/proxy-1368/services/proxy-service-v7jmk:portname2/proxy/: bar (200; 4.565109ms)
Nov 21 08:35:01.176: INFO: (15) /api/v1/namespaces/proxy-1368/services/proxy-service-v7jmk:portname1/proxy/: foo (200; 4.702844ms)
Nov 21 08:35:01.179: INFO: (16) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk/proxy/rewriteme">test</a> (200; 2.590655ms)
Nov 21 08:35:01.179: INFO: (16) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:443/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:443/proxy/tlsrewritem... (200; 2.621287ms)
Nov 21 08:35:01.179: INFO: (16) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:162/proxy/: bar (200; 2.684293ms)
Nov 21 08:35:01.179: INFO: (16) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:1080/proxy/rewriteme">test<... (200; 2.632445ms)
Nov 21 08:35:01.179: INFO: (16) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:460/proxy/: tls baz (200; 2.654916ms)
Nov 21 08:35:01.179: INFO: (16) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:1080/proxy/rewriteme">... (200; 2.609273ms)
Nov 21 08:35:01.179: INFO: (16) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:162/proxy/: bar (200; 2.751145ms)
Nov 21 08:35:01.179: INFO: (16) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:160/proxy/: foo (200; 2.823085ms)
Nov 21 08:35:01.179: INFO: (16) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:160/proxy/: foo (200; 3.263855ms)
Nov 21 08:35:01.179: INFO: (16) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:462/proxy/: tls qux (200; 3.181301ms)
Nov 21 08:35:01.180: INFO: (16) /api/v1/namespaces/proxy-1368/services/http:proxy-service-v7jmk:portname1/proxy/: foo (200; 3.487073ms)
Nov 21 08:35:01.180: INFO: (16) /api/v1/namespaces/proxy-1368/services/http:proxy-service-v7jmk:portname2/proxy/: bar (200; 3.474635ms)
Nov 21 08:35:01.180: INFO: (16) /api/v1/namespaces/proxy-1368/services/https:proxy-service-v7jmk:tlsportname1/proxy/: tls baz (200; 3.51861ms)
Nov 21 08:35:01.180: INFO: (16) /api/v1/namespaces/proxy-1368/services/https:proxy-service-v7jmk:tlsportname2/proxy/: tls qux (200; 3.438957ms)
Nov 21 08:35:01.180: INFO: (16) /api/v1/namespaces/proxy-1368/services/proxy-service-v7jmk:portname1/proxy/: foo (200; 3.547364ms)
Nov 21 08:35:01.180: INFO: (16) /api/v1/namespaces/proxy-1368/services/proxy-service-v7jmk:portname2/proxy/: bar (200; 3.54852ms)
Nov 21 08:35:01.183: INFO: (17) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:460/proxy/: tls baz (200; 2.656599ms)
Nov 21 08:35:01.183: INFO: (17) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:1080/proxy/rewriteme">test<... (200; 2.69086ms)
Nov 21 08:35:01.183: INFO: (17) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:1080/proxy/rewriteme">... (200; 2.777986ms)
Nov 21 08:35:01.183: INFO: (17) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk/proxy/rewriteme">test</a> (200; 2.751431ms)
Nov 21 08:35:01.183: INFO: (17) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:462/proxy/: tls qux (200; 3.171369ms)
Nov 21 08:35:01.183: INFO: (17) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:160/proxy/: foo (200; 3.250369ms)
Nov 21 08:35:01.183: INFO: (17) /api/v1/namespaces/proxy-1368/services/http:proxy-service-v7jmk:portname1/proxy/: foo (200; 3.448593ms)
Nov 21 08:35:01.183: INFO: (17) /api/v1/namespaces/proxy-1368/services/https:proxy-service-v7jmk:tlsportname1/proxy/: tls baz (200; 3.46692ms)
Nov 21 08:35:01.183: INFO: (17) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:443/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:443/proxy/tlsrewritem... (200; 3.555651ms)
Nov 21 08:35:01.183: INFO: (17) /api/v1/namespaces/proxy-1368/services/http:proxy-service-v7jmk:portname2/proxy/: bar (200; 3.517528ms)
Nov 21 08:35:01.183: INFO: (17) /api/v1/namespaces/proxy-1368/services/proxy-service-v7jmk:portname2/proxy/: bar (200; 3.537294ms)
Nov 21 08:35:01.183: INFO: (17) /api/v1/namespaces/proxy-1368/services/proxy-service-v7jmk:portname1/proxy/: foo (200; 3.541102ms)
Nov 21 08:35:01.184: INFO: (17) /api/v1/namespaces/proxy-1368/services/https:proxy-service-v7jmk:tlsportname2/proxy/: tls qux (200; 3.608822ms)
Nov 21 08:35:01.184: INFO: (17) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:160/proxy/: foo (200; 3.770635ms)
Nov 21 08:35:01.184: INFO: (17) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:162/proxy/: bar (200; 3.879082ms)
Nov 21 08:35:01.184: INFO: (17) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:162/proxy/: bar (200; 4.049432ms)
Nov 21 08:35:01.186: INFO: (18) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:1080/proxy/rewriteme">... (200; 2.273896ms)
Nov 21 08:35:01.186: INFO: (18) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:160/proxy/: foo (200; 2.316558ms)
Nov 21 08:35:01.186: INFO: (18) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:162/proxy/: bar (200; 2.466592ms)
Nov 21 08:35:01.186: INFO: (18) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:460/proxy/: tls baz (200; 2.453571ms)
Nov 21 08:35:01.186: INFO: (18) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk/proxy/rewriteme">test</a> (200; 2.516671ms)
Nov 21 08:35:01.186: INFO: (18) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:462/proxy/: tls qux (200; 2.538215ms)
Nov 21 08:35:01.187: INFO: (18) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:443/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:443/proxy/tlsrewritem... (200; 2.568627ms)
Nov 21 08:35:01.187: INFO: (18) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:1080/proxy/rewriteme">test<... (200; 2.507539ms)
Nov 21 08:35:01.187: INFO: (18) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:160/proxy/: foo (200; 2.465269ms)
Nov 21 08:35:01.187: INFO: (18) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:162/proxy/: bar (200; 2.583655ms)
Nov 21 08:35:01.187: INFO: (18) /api/v1/namespaces/proxy-1368/services/proxy-service-v7jmk:portname1/proxy/: foo (200; 3.066274ms)
Nov 21 08:35:01.187: INFO: (18) /api/v1/namespaces/proxy-1368/services/http:proxy-service-v7jmk:portname2/proxy/: bar (200; 3.146756ms)
Nov 21 08:35:01.187: INFO: (18) /api/v1/namespaces/proxy-1368/services/https:proxy-service-v7jmk:tlsportname2/proxy/: tls qux (200; 3.129932ms)
Nov 21 08:35:01.187: INFO: (18) /api/v1/namespaces/proxy-1368/services/proxy-service-v7jmk:portname2/proxy/: bar (200; 3.188173ms)
Nov 21 08:35:01.187: INFO: (18) /api/v1/namespaces/proxy-1368/services/http:proxy-service-v7jmk:portname1/proxy/: foo (200; 3.209822ms)
Nov 21 08:35:01.187: INFO: (18) /api/v1/namespaces/proxy-1368/services/https:proxy-service-v7jmk:tlsportname1/proxy/: tls baz (200; 3.256399ms)
Nov 21 08:35:01.189: INFO: (19) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:160/proxy/: foo (200; 2.148616ms)
Nov 21 08:35:01.189: INFO: (19) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:162/proxy/: bar (200; 2.20725ms)
Nov 21 08:35:01.190: INFO: (19) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:1080/proxy/rewriteme">test<... (200; 2.443178ms)
Nov 21 08:35:01.190: INFO: (19) /api/v1/namespaces/proxy-1368/services/proxy-service-v7jmk:portname2/proxy/: bar (200; 3.185843ms)
Nov 21 08:35:01.190: INFO: (19) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:462/proxy/: tls qux (200; 3.168631ms)
Nov 21 08:35:01.191: INFO: (19) /api/v1/namespaces/proxy-1368/services/https:proxy-service-v7jmk:tlsportname1/proxy/: tls baz (200; 3.25831ms)
Nov 21 08:35:01.191: INFO: (19) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:460/proxy/: tls baz (200; 3.152259ms)
Nov 21 08:35:01.191: INFO: (19) /api/v1/namespaces/proxy-1368/services/proxy-service-v7jmk:portname1/proxy/: foo (200; 3.265738ms)
Nov 21 08:35:01.191: INFO: (19) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk/proxy/rewriteme">test</a> (200; 3.189398ms)
Nov 21 08:35:01.191: INFO: (19) /api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:443/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/https:proxy-service-v7jmk-wz2lk:443/proxy/tlsrewritem... (200; 3.172495ms)
Nov 21 08:35:01.191: INFO: (19) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:162/proxy/: bar (200; 3.255819ms)
Nov 21 08:35:01.191: INFO: (19) /api/v1/namespaces/proxy-1368/services/http:proxy-service-v7jmk:portname1/proxy/: foo (200; 3.222717ms)
Nov 21 08:35:01.191: INFO: (19) /api/v1/namespaces/proxy-1368/services/https:proxy-service-v7jmk:tlsportname2/proxy/: tls qux (200; 3.186283ms)
Nov 21 08:35:01.191: INFO: (19) /api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:1080/proxy/: <a href="/api/v1/namespaces/proxy-1368/pods/http:proxy-service-v7jmk-wz2lk:1080/proxy/rewriteme">... (200; 3.262245ms)
Nov 21 08:35:01.191: INFO: (19) /api/v1/namespaces/proxy-1368/services/http:proxy-service-v7jmk:portname2/proxy/: bar (200; 3.434378ms)
Nov 21 08:35:01.191: INFO: (19) /api/v1/namespaces/proxy-1368/pods/proxy-service-v7jmk-wz2lk:160/proxy/: foo (200; 3.611004ms)
STEP: deleting ReplicationController proxy-service-v7jmk in namespace proxy-1368, will wait for the garbage collector to delete the pods
Nov 21 08:35:01.246: INFO: Deleting ReplicationController proxy-service-v7jmk took: 3.285525ms
Nov 21 08:35:01.346: INFO: Terminating ReplicationController proxy-service-v7jmk pods took: 100.132966ms
[AfterEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:35:10.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-1368" for this suite.
Nov 21 08:35:16.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:35:16.800: INFO: namespace proxy-1368 deletion completed in 6.051044816s

â€¢ [SLOW TEST:19.895 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:35:16.800: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-1794
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Nov 21 08:35:16.878: INFO: Found 0 stateful pods, waiting for 3
Nov 21 08:35:26.881: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 21 08:35:26.881: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 21 08:35:26.881: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Nov 21 08:35:26.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-1794 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov 21 08:35:27.094: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Nov 21 08:35:27.094: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov 21 08:35:27.094: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Nov 21 08:35:37.116: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Nov 21 08:35:47.136: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-1794 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 21 08:35:47.337: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Nov 21 08:35:47.337: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov 21 08:35:47.337: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

STEP: Rolling back to a previous revision
Nov 21 08:36:07.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-1794 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov 21 08:36:07.604: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Nov 21 08:36:07.604: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov 21 08:36:07.604: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov 21 08:36:17.625: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Nov 21 08:36:27.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-1794 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 21 08:36:27.863: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Nov 21 08:36:27.863: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov 21 08:36:27.863: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov 21 08:36:37.874: INFO: Waiting for StatefulSet statefulset-1794/ss2 to complete update
Nov 21 08:36:37.874: INFO: Waiting for Pod statefulset-1794/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Nov 21 08:36:37.874: INFO: Waiting for Pod statefulset-1794/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Nov 21 08:36:37.874: INFO: Waiting for Pod statefulset-1794/ss2-2 to have revision ss2-787997d666 update revision ss2-c79899b9
Nov 21 08:36:47.882: INFO: Waiting for StatefulSet statefulset-1794/ss2 to complete update
Nov 21 08:36:47.882: INFO: Waiting for Pod statefulset-1794/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Nov 21 08:36:47.882: INFO: Waiting for Pod statefulset-1794/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Nov 21 08:36:57.878: INFO: Waiting for StatefulSet statefulset-1794/ss2 to complete update
Nov 21 08:36:57.879: INFO: Waiting for Pod statefulset-1794/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Nov 21 08:37:07.878: INFO: Deleting all statefulset in ns statefulset-1794
Nov 21 08:37:07.880: INFO: Scaling statefulset ss2 to 0
Nov 21 08:37:37.922: INFO: Waiting for statefulset status.replicas updated to 0
Nov 21 08:37:37.924: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:37:37.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1794" for this suite.
Nov 21 08:37:43.945: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:37:43.984: INFO: namespace statefulset-1794 deletion completed in 6.049446683s

â€¢ [SLOW TEST:147.184 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:37:43.985: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Nov 21 08:37:44.059: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-7024,SelfLink:/api/v1/namespaces/watch-7024/configmaps/e2e-watch-test-resource-version,UID:2ff302ed-0c3a-11ea-b617-0202c0a8005b,ResourceVersion:13789,Generation:0,CreationTimestamp:2019-11-21 08:37:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov 21 08:37:44.059: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-7024,SelfLink:/api/v1/namespaces/watch-7024/configmaps/e2e-watch-test-resource-version,UID:2ff302ed-0c3a-11ea-b617-0202c0a8005b,ResourceVersion:13790,Generation:0,CreationTimestamp:2019-11-21 08:37:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:37:44.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7024" for this suite.
Nov 21 08:37:50.111: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:37:50.152: INFO: namespace watch-7024 deletion completed in 6.04893067s

â€¢ [SLOW TEST:6.167 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:37:50.152: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Nov 21 08:37:50.208: INFO: Waiting up to 5m0s for pod "downwardapi-volume-339ff229-0c3a-11ea-a569-4e55f5a7674f" in namespace "downward-api-3456" to be "success or failure"
Nov 21 08:37:50.225: INFO: Pod "downwardapi-volume-339ff229-0c3a-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 17.531643ms
Nov 21 08:37:52.228: INFO: Pod "downwardapi-volume-339ff229-0c3a-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019939005s
Nov 21 08:37:54.230: INFO: Pod "downwardapi-volume-339ff229-0c3a-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022079933s
STEP: Saw pod success
Nov 21 08:37:54.230: INFO: Pod "downwardapi-volume-339ff229-0c3a-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 08:37:54.231: INFO: Trying to get logs from node 192.168.0.92 pod downwardapi-volume-339ff229-0c3a-11ea-a569-4e55f5a7674f container client-container: <nil>
STEP: delete the pod
Nov 21 08:37:54.247: INFO: Waiting for pod downwardapi-volume-339ff229-0c3a-11ea-a569-4e55f5a7674f to disappear
Nov 21 08:37:54.264: INFO: Pod downwardapi-volume-339ff229-0c3a-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:37:54.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3456" for this suite.
Nov 21 08:38:00.298: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:38:00.364: INFO: namespace downward-api-3456 deletion completed in 6.097610718s

â€¢ [SLOW TEST:10.212 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:38:00.364: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-39b53bb7-0c3a-11ea-a569-4e55f5a7674f
STEP: Creating a pod to test consume secrets
Nov 21 08:38:00.501: INFO: Waiting up to 5m0s for pod "pod-secrets-39c1160b-0c3a-11ea-a569-4e55f5a7674f" in namespace "secrets-7972" to be "success or failure"
Nov 21 08:38:00.509: INFO: Pod "pod-secrets-39c1160b-0c3a-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.377717ms
Nov 21 08:38:02.514: INFO: Pod "pod-secrets-39c1160b-0c3a-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013003642s
STEP: Saw pod success
Nov 21 08:38:02.514: INFO: Pod "pod-secrets-39c1160b-0c3a-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 08:38:02.515: INFO: Trying to get logs from node 192.168.0.92 pod pod-secrets-39c1160b-0c3a-11ea-a569-4e55f5a7674f container secret-volume-test: <nil>
STEP: delete the pod
Nov 21 08:38:02.544: INFO: Waiting for pod pod-secrets-39c1160b-0c3a-11ea-a569-4e55f5a7674f to disappear
Nov 21 08:38:02.549: INFO: Pod pod-secrets-39c1160b-0c3a-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:38:02.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7972" for this suite.
Nov 21 08:38:08.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:38:08.602: INFO: namespace secrets-7972 deletion completed in 6.050305778s
STEP: Destroying namespace "secret-namespace-5772" for this suite.
Nov 21 08:38:14.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:38:14.648: INFO: namespace secret-namespace-5772 deletion completed in 6.046301454s

â€¢ [SLOW TEST:14.284 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:38:14.648: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Nov 21 08:38:14.699: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4239b163-0c3a-11ea-a569-4e55f5a7674f" in namespace "downward-api-37" to be "success or failure"
Nov 21 08:38:14.717: INFO: Pod "downwardapi-volume-4239b163-0c3a-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 17.461288ms
Nov 21 08:38:16.719: INFO: Pod "downwardapi-volume-4239b163-0c3a-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01984632s
Nov 21 08:38:18.721: INFO: Pod "downwardapi-volume-4239b163-0c3a-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022162533s
STEP: Saw pod success
Nov 21 08:38:18.721: INFO: Pod "downwardapi-volume-4239b163-0c3a-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 08:38:18.723: INFO: Trying to get logs from node 192.168.0.93 pod downwardapi-volume-4239b163-0c3a-11ea-a569-4e55f5a7674f container client-container: <nil>
STEP: delete the pod
Nov 21 08:38:18.745: INFO: Waiting for pod downwardapi-volume-4239b163-0c3a-11ea-a569-4e55f5a7674f to disappear
Nov 21 08:38:18.750: INFO: Pod downwardapi-volume-4239b163-0c3a-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:38:18.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-37" for this suite.
Nov 21 08:38:24.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:38:24.811: INFO: namespace downward-api-37 deletion completed in 6.059772259s

â€¢ [SLOW TEST:10.163 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:38:24.811: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:177
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:38:24.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7436" for this suite.
Nov 21 08:38:46.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:38:46.980: INFO: namespace pods-7436 deletion completed in 22.080970898s

â€¢ [SLOW TEST:22.168 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:38:46.980: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Nov 21 08:38:47.057: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Nov 21 08:38:47.064: INFO: Number of nodes with available pods: 0
Nov 21 08:38:47.064: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Nov 21 08:38:47.125: INFO: Number of nodes with available pods: 0
Nov 21 08:38:47.125: INFO: Node 192.168.0.92 is running more than one daemon pod
Nov 21 08:38:48.128: INFO: Number of nodes with available pods: 0
Nov 21 08:38:48.128: INFO: Node 192.168.0.92 is running more than one daemon pod
Nov 21 08:38:49.127: INFO: Number of nodes with available pods: 0
Nov 21 08:38:49.127: INFO: Node 192.168.0.92 is running more than one daemon pod
Nov 21 08:38:50.127: INFO: Number of nodes with available pods: 1
Nov 21 08:38:50.127: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Nov 21 08:38:50.152: INFO: Number of nodes with available pods: 1
Nov 21 08:38:50.152: INFO: Number of running nodes: 0, number of available pods: 1
Nov 21 08:38:51.154: INFO: Number of nodes with available pods: 0
Nov 21 08:38:51.154: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Nov 21 08:38:51.196: INFO: Number of nodes with available pods: 0
Nov 21 08:38:51.196: INFO: Node 192.168.0.92 is running more than one daemon pod
Nov 21 08:38:52.198: INFO: Number of nodes with available pods: 0
Nov 21 08:38:52.198: INFO: Node 192.168.0.92 is running more than one daemon pod
Nov 21 08:38:53.198: INFO: Number of nodes with available pods: 0
Nov 21 08:38:53.198: INFO: Node 192.168.0.92 is running more than one daemon pod
Nov 21 08:38:54.198: INFO: Number of nodes with available pods: 0
Nov 21 08:38:54.198: INFO: Node 192.168.0.92 is running more than one daemon pod
Nov 21 08:38:55.198: INFO: Number of nodes with available pods: 0
Nov 21 08:38:55.198: INFO: Node 192.168.0.92 is running more than one daemon pod
Nov 21 08:38:56.198: INFO: Number of nodes with available pods: 1
Nov 21 08:38:56.198: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3893, will wait for the garbage collector to delete the pods
Nov 21 08:38:56.255: INFO: Deleting DaemonSet.extensions daemon-set took: 2.652565ms
Nov 21 08:38:56.555: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.145495ms
Nov 21 08:38:59.457: INFO: Number of nodes with available pods: 0
Nov 21 08:38:59.457: INFO: Number of running nodes: 0, number of available pods: 0
Nov 21 08:38:59.458: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3893/daemonsets","resourceVersion":"14113"},"items":null}

Nov 21 08:38:59.460: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3893/pods","resourceVersion":"14113"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:38:59.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3893" for this suite.
Nov 21 08:39:05.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:39:05.559: INFO: namespace daemonsets-3893 deletion completed in 6.053713331s

â€¢ [SLOW TEST:18.579 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:39:05.559: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Nov 21 08:39:10.655: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:39:10.683: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-1290" for this suite.
Nov 21 08:39:32.735: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:39:32.777: INFO: namespace replicaset-1290 deletion completed in 22.066347682s

â€¢ [SLOW TEST:27.218 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:39:32.778: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Nov 21 08:39:32.855: INFO: Waiting up to 5m0s for pod "pod-70cf4577-0c3a-11ea-a569-4e55f5a7674f" in namespace "emptydir-9967" to be "success or failure"
Nov 21 08:39:32.872: INFO: Pod "pod-70cf4577-0c3a-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 17.165169ms
Nov 21 08:39:34.884: INFO: Pod "pod-70cf4577-0c3a-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029139871s
STEP: Saw pod success
Nov 21 08:39:34.884: INFO: Pod "pod-70cf4577-0c3a-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 08:39:34.885: INFO: Trying to get logs from node 192.168.0.93 pod pod-70cf4577-0c3a-11ea-a569-4e55f5a7674f container test-container: <nil>
STEP: delete the pod
Nov 21 08:39:34.906: INFO: Waiting for pod pod-70cf4577-0c3a-11ea-a569-4e55f5a7674f to disappear
Nov 21 08:39:34.911: INFO: Pod pod-70cf4577-0c3a-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:39:34.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9967" for this suite.
Nov 21 08:39:40.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:39:40.965: INFO: namespace emptydir-9967 deletion completed in 6.052544141s

â€¢ [SLOW TEST:8.188 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:39:40.965: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Nov 21 08:39:41.017: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 create -f - --namespace=kubectl-8809'
Nov 21 08:39:41.844: INFO: stderr: ""
Nov 21 08:39:41.844: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov 21 08:39:41.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8809'
Nov 21 08:39:41.930: INFO: stderr: ""
Nov 21 08:39:41.930: INFO: stdout: "update-demo-nautilus-pp6d9 update-demo-nautilus-v4w57 "
Nov 21 08:39:41.930: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods update-demo-nautilus-pp6d9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8809'
Nov 21 08:39:42.009: INFO: stderr: ""
Nov 21 08:39:42.009: INFO: stdout: ""
Nov 21 08:39:42.009: INFO: update-demo-nautilus-pp6d9 is created but not running
Nov 21 08:39:47.009: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8809'
Nov 21 08:39:47.079: INFO: stderr: ""
Nov 21 08:39:47.079: INFO: stdout: "update-demo-nautilus-pp6d9 update-demo-nautilus-v4w57 "
Nov 21 08:39:47.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods update-demo-nautilus-pp6d9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8809'
Nov 21 08:39:47.145: INFO: stderr: ""
Nov 21 08:39:47.145: INFO: stdout: "true"
Nov 21 08:39:47.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods update-demo-nautilus-pp6d9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8809'
Nov 21 08:39:47.211: INFO: stderr: ""
Nov 21 08:39:47.212: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 21 08:39:47.212: INFO: validating pod update-demo-nautilus-pp6d9
Nov 21 08:39:47.222: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 21 08:39:47.222: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 21 08:39:47.222: INFO: update-demo-nautilus-pp6d9 is verified up and running
Nov 21 08:39:47.222: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods update-demo-nautilus-v4w57 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8809'
Nov 21 08:39:47.289: INFO: stderr: ""
Nov 21 08:39:47.289: INFO: stdout: "true"
Nov 21 08:39:47.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods update-demo-nautilus-v4w57 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8809'
Nov 21 08:39:47.355: INFO: stderr: ""
Nov 21 08:39:47.355: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 21 08:39:47.355: INFO: validating pod update-demo-nautilus-v4w57
Nov 21 08:39:47.372: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 21 08:39:47.372: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 21 08:39:47.372: INFO: update-demo-nautilus-v4w57 is verified up and running
STEP: using delete to clean up resources
Nov 21 08:39:47.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 delete --grace-period=0 --force -f - --namespace=kubectl-8809'
Nov 21 08:39:47.445: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 21 08:39:47.445: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Nov 21 08:39:47.445: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8809'
Nov 21 08:39:47.515: INFO: stderr: "No resources found.\n"
Nov 21 08:39:47.515: INFO: stdout: ""
Nov 21 08:39:47.515: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods -l name=update-demo --namespace=kubectl-8809 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov 21 08:39:47.584: INFO: stderr: ""
Nov 21 08:39:47.584: INFO: stdout: "update-demo-nautilus-pp6d9\nupdate-demo-nautilus-v4w57\n"
Nov 21 08:39:48.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8809'
Nov 21 08:39:48.157: INFO: stderr: "No resources found.\n"
Nov 21 08:39:48.157: INFO: stdout: ""
Nov 21 08:39:48.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods -l name=update-demo --namespace=kubectl-8809 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov 21 08:39:48.225: INFO: stderr: ""
Nov 21 08:39:48.225: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:39:48.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8809" for this suite.
Nov 21 08:40:10.287: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:40:10.327: INFO: namespace kubectl-8809 deletion completed in 22.099083771s

â€¢ [SLOW TEST:29.361 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:40:10.327: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Nov 21 08:40:18.455: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 21 08:40:18.460: INFO: Pod pod-with-prestop-http-hook still exists
Nov 21 08:40:20.460: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 21 08:40:20.462: INFO: Pod pod-with-prestop-http-hook still exists
Nov 21 08:40:22.460: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 21 08:40:22.462: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:40:22.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2396" for this suite.
Nov 21 08:40:44.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:40:44.527: INFO: namespace container-lifecycle-hook-2396 deletion completed in 22.056659414s

â€¢ [SLOW TEST:34.200 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:40:44.527: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-9b8feb92-0c3a-11ea-a569-4e55f5a7674f
STEP: Creating a pod to test consume configMaps
Nov 21 08:40:44.618: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9b90b324-0c3a-11ea-a569-4e55f5a7674f" in namespace "projected-1043" to be "success or failure"
Nov 21 08:40:44.627: INFO: Pod "pod-projected-configmaps-9b90b324-0c3a-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.636952ms
Nov 21 08:40:46.629: INFO: Pod "pod-projected-configmaps-9b90b324-0c3a-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010667237s
STEP: Saw pod success
Nov 21 08:40:46.629: INFO: Pod "pod-projected-configmaps-9b90b324-0c3a-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 08:40:46.630: INFO: Trying to get logs from node 192.168.0.92 pod pod-projected-configmaps-9b90b324-0c3a-11ea-a569-4e55f5a7674f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 21 08:40:46.689: INFO: Waiting for pod pod-projected-configmaps-9b90b324-0c3a-11ea-a569-4e55f5a7674f to disappear
Nov 21 08:40:46.695: INFO: Pod pod-projected-configmaps-9b90b324-0c3a-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:40:46.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1043" for this suite.
Nov 21 08:40:52.725: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:40:52.765: INFO: namespace projected-1043 deletion completed in 6.06731051s

â€¢ [SLOW TEST:8.238 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:40:52.765: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-cb6d
STEP: Creating a pod to test atomic-volume-subpath
Nov 21 08:40:52.847: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-cb6d" in namespace "subpath-4678" to be "success or failure"
Nov 21 08:40:52.855: INFO: Pod "pod-subpath-test-configmap-cb6d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.271717ms
Nov 21 08:40:54.857: INFO: Pod "pod-subpath-test-configmap-cb6d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01021269s
Nov 21 08:40:56.860: INFO: Pod "pod-subpath-test-configmap-cb6d": Phase="Running", Reason="", readiness=true. Elapsed: 4.012722979s
Nov 21 08:40:58.862: INFO: Pod "pod-subpath-test-configmap-cb6d": Phase="Running", Reason="", readiness=true. Elapsed: 6.01457662s
Nov 21 08:41:00.864: INFO: Pod "pod-subpath-test-configmap-cb6d": Phase="Running", Reason="", readiness=true. Elapsed: 8.016964s
Nov 21 08:41:02.866: INFO: Pod "pod-subpath-test-configmap-cb6d": Phase="Running", Reason="", readiness=true. Elapsed: 10.019388735s
Nov 21 08:41:04.869: INFO: Pod "pod-subpath-test-configmap-cb6d": Phase="Running", Reason="", readiness=true. Elapsed: 12.021598905s
Nov 21 08:41:06.871: INFO: Pod "pod-subpath-test-configmap-cb6d": Phase="Running", Reason="", readiness=true. Elapsed: 14.023881013s
Nov 21 08:41:08.873: INFO: Pod "pod-subpath-test-configmap-cb6d": Phase="Running", Reason="", readiness=true. Elapsed: 16.025772888s
Nov 21 08:41:10.875: INFO: Pod "pod-subpath-test-configmap-cb6d": Phase="Running", Reason="", readiness=true. Elapsed: 18.027770951s
Nov 21 08:41:12.877: INFO: Pod "pod-subpath-test-configmap-cb6d": Phase="Running", Reason="", readiness=true. Elapsed: 20.029805738s
Nov 21 08:41:14.879: INFO: Pod "pod-subpath-test-configmap-cb6d": Phase="Running", Reason="", readiness=true. Elapsed: 22.031718566s
Nov 21 08:41:16.881: INFO: Pod "pod-subpath-test-configmap-cb6d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.033792453s
STEP: Saw pod success
Nov 21 08:41:16.881: INFO: Pod "pod-subpath-test-configmap-cb6d" satisfied condition "success or failure"
Nov 21 08:41:16.882: INFO: Trying to get logs from node 192.168.0.93 pod pod-subpath-test-configmap-cb6d container test-container-subpath-configmap-cb6d: <nil>
STEP: delete the pod
Nov 21 08:41:16.938: INFO: Waiting for pod pod-subpath-test-configmap-cb6d to disappear
Nov 21 08:41:16.941: INFO: Pod pod-subpath-test-configmap-cb6d no longer exists
STEP: Deleting pod pod-subpath-test-configmap-cb6d
Nov 21 08:41:16.941: INFO: Deleting pod "pod-subpath-test-configmap-cb6d" in namespace "subpath-4678"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:41:16.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4678" for this suite.
Nov 21 08:41:22.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:41:22.996: INFO: namespace subpath-4678 deletion completed in 6.051428073s

â€¢ [SLOW TEST:30.231 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:41:22.996: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Nov 21 08:41:25.613: INFO: Successfully updated pod "annotationupdateb27ddfbd-0c3a-11ea-a569-4e55f5a7674f"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:41:27.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3205" for this suite.
Nov 21 08:41:49.657: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:41:49.698: INFO: namespace projected-3205 deletion completed in 22.053516348s

â€¢ [SLOW TEST:26.702 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:41:49.698: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test use defaults
Nov 21 08:41:49.794: INFO: Waiting up to 5m0s for pod "client-containers-c26df9cf-0c3a-11ea-a569-4e55f5a7674f" in namespace "containers-2656" to be "success or failure"
Nov 21 08:41:49.799: INFO: Pod "client-containers-c26df9cf-0c3a-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.616746ms
Nov 21 08:41:51.801: INFO: Pod "client-containers-c26df9cf-0c3a-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006649535s
Nov 21 08:41:53.811: INFO: Pod "client-containers-c26df9cf-0c3a-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016970367s
STEP: Saw pod success
Nov 21 08:41:53.811: INFO: Pod "client-containers-c26df9cf-0c3a-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 08:41:53.812: INFO: Trying to get logs from node 192.168.0.93 pod client-containers-c26df9cf-0c3a-11ea-a569-4e55f5a7674f container test-container: <nil>
STEP: delete the pod
Nov 21 08:41:53.842: INFO: Waiting for pod client-containers-c26df9cf-0c3a-11ea-a569-4e55f5a7674f to disappear
Nov 21 08:41:53.850: INFO: Pod client-containers-c26df9cf-0c3a-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:41:53.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-2656" for this suite.
Nov 21 08:41:59.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:41:59.899: INFO: namespace containers-2656 deletion completed in 6.046630358s

â€¢ [SLOW TEST:10.200 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:41:59.899: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating cluster-info
Nov 21 08:41:59.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 cluster-info'
Nov 21 08:42:00.022: INFO: stderr: ""
Nov 21 08:42:00.022: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://11.254.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://11.254.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:42:00.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3141" for this suite.
Nov 21 08:42:06.035: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:42:06.075: INFO: namespace kubectl-3141 deletion completed in 6.050923727s

â€¢ [SLOW TEST:6.176 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:42:06.075: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Nov 21 08:42:10.735: INFO: Successfully updated pod "pod-update-cc2fef43-0c3a-11ea-a569-4e55f5a7674f"
STEP: verifying the updated pod is in kubernetes
Nov 21 08:42:10.782: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:42:10.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9432" for this suite.
Nov 21 08:42:32.810: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:42:32.849: INFO: namespace pods-9432 deletion completed in 22.065165422s

â€¢ [SLOW TEST:26.774 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:42:32.850: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1354
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov 21 08:42:32.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-5973'
Nov 21 08:42:32.989: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov 21 08:42:32.989: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Nov 21 08:42:32.999: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-45jfz]
Nov 21 08:42:32.999: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-45jfz" in namespace "kubectl-5973" to be "running and ready"
Nov 21 08:42:33.051: INFO: Pod "e2e-test-nginx-rc-45jfz": Phase="Pending", Reason="", readiness=false. Elapsed: 51.734623ms
Nov 21 08:42:35.053: INFO: Pod "e2e-test-nginx-rc-45jfz": Phase="Pending", Reason="", readiness=false. Elapsed: 2.053809391s
Nov 21 08:42:37.056: INFO: Pod "e2e-test-nginx-rc-45jfz": Phase="Running", Reason="", readiness=true. Elapsed: 4.056434402s
Nov 21 08:42:37.056: INFO: Pod "e2e-test-nginx-rc-45jfz" satisfied condition "running and ready"
Nov 21 08:42:37.056: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-45jfz]
Nov 21 08:42:37.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 logs rc/e2e-test-nginx-rc --namespace=kubectl-5973'
Nov 21 08:42:37.140: INFO: stderr: ""
Nov 21 08:42:37.140: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1359
Nov 21 08:42:37.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 delete rc e2e-test-nginx-rc --namespace=kubectl-5973'
Nov 21 08:42:37.213: INFO: stderr: ""
Nov 21 08:42:37.213: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:42:37.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5973" for this suite.
Nov 21 08:42:43.224: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:42:43.263: INFO: namespace kubectl-5973 deletion completed in 6.047843489s

â€¢ [SLOW TEST:10.413 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:42:43.263: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-e258774a-0c3a-11ea-a569-4e55f5a7674f
STEP: Creating a pod to test consume secrets
Nov 21 08:42:43.344: INFO: Waiting up to 5m0s for pod "pod-secrets-e2597a64-0c3a-11ea-a569-4e55f5a7674f" in namespace "secrets-6747" to be "success or failure"
Nov 21 08:42:43.348: INFO: Pod "pod-secrets-e2597a64-0c3a-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.468591ms
Nov 21 08:42:45.351: INFO: Pod "pod-secrets-e2597a64-0c3a-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006904169s
Nov 21 08:42:47.353: INFO: Pod "pod-secrets-e2597a64-0c3a-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009348619s
STEP: Saw pod success
Nov 21 08:42:47.353: INFO: Pod "pod-secrets-e2597a64-0c3a-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 08:42:47.355: INFO: Trying to get logs from node 192.168.0.92 pod pod-secrets-e2597a64-0c3a-11ea-a569-4e55f5a7674f container secret-volume-test: <nil>
STEP: delete the pod
Nov 21 08:42:47.386: INFO: Waiting for pod pod-secrets-e2597a64-0c3a-11ea-a569-4e55f5a7674f to disappear
Nov 21 08:42:47.394: INFO: Pod pod-secrets-e2597a64-0c3a-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:42:47.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6747" for this suite.
Nov 21 08:42:53.424: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:42:53.465: INFO: namespace secrets-6747 deletion completed in 6.053205727s

â€¢ [SLOW TEST:10.202 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:42:53.465: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Nov 21 08:42:53.541: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e86dff80-0c3a-11ea-a569-4e55f5a7674f" in namespace "projected-9093" to be "success or failure"
Nov 21 08:42:53.558: INFO: Pod "downwardapi-volume-e86dff80-0c3a-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 17.560282ms
Nov 21 08:42:55.588: INFO: Pod "downwardapi-volume-e86dff80-0c3a-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.047588751s
STEP: Saw pod success
Nov 21 08:42:55.588: INFO: Pod "downwardapi-volume-e86dff80-0c3a-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 08:42:55.594: INFO: Trying to get logs from node 192.168.0.93 pod downwardapi-volume-e86dff80-0c3a-11ea-a569-4e55f5a7674f container client-container: <nil>
STEP: delete the pod
Nov 21 08:42:55.617: INFO: Waiting for pod downwardapi-volume-e86dff80-0c3a-11ea-a569-4e55f5a7674f to disappear
Nov 21 08:42:55.622: INFO: Pod downwardapi-volume-e86dff80-0c3a-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:42:55.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9093" for this suite.
Nov 21 08:43:01.642: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:43:01.681: INFO: namespace projected-9093 deletion completed in 6.051981321s

â€¢ [SLOW TEST:8.216 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:43:01.682: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Nov 21 08:43:01.790: INFO: Waiting up to 5m0s for pod "downward-api-ed568484-0c3a-11ea-a569-4e55f5a7674f" in namespace "downward-api-2141" to be "success or failure"
Nov 21 08:43:01.800: INFO: Pod "downward-api-ed568484-0c3a-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 9.742548ms
Nov 21 08:43:03.802: INFO: Pod "downward-api-ed568484-0c3a-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01209266s
Nov 21 08:43:05.805: INFO: Pod "downward-api-ed568484-0c3a-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014308084s
STEP: Saw pod success
Nov 21 08:43:05.805: INFO: Pod "downward-api-ed568484-0c3a-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 08:43:05.806: INFO: Trying to get logs from node 192.168.0.92 pod downward-api-ed568484-0c3a-11ea-a569-4e55f5a7674f container dapi-container: <nil>
STEP: delete the pod
Nov 21 08:43:05.824: INFO: Waiting for pod downward-api-ed568484-0c3a-11ea-a569-4e55f5a7674f to disappear
Nov 21 08:43:05.828: INFO: Pod downward-api-ed568484-0c3a-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:43:05.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2141" for this suite.
Nov 21 08:43:11.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:43:11.901: INFO: namespace downward-api-2141 deletion completed in 6.070354617s

â€¢ [SLOW TEST:10.219 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:43:11.901: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Nov 21 08:43:12.024: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"f36e6783-0c3a-11ea-b617-0202c0a8005b", Controller:(*bool)(0xc0018a8fb6), BlockOwnerDeletion:(*bool)(0xc0018a8fb7)}}
Nov 21 08:43:12.042: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"f36d5c86-0c3a-11ea-b617-0202c0a8005b", Controller:(*bool)(0xc0028c22a6), BlockOwnerDeletion:(*bool)(0xc0028c22a7)}}
Nov 21 08:43:12.086: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"f36da709-0c3a-11ea-b617-0202c0a8005b", Controller:(*bool)(0xc0028c2456), BlockOwnerDeletion:(*bool)(0xc0028c2457)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:43:17.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5325" for this suite.
Nov 21 08:43:23.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:43:23.226: INFO: namespace gc-5325 deletion completed in 6.0535483s

â€¢ [SLOW TEST:11.325 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:43:23.226: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-2855
Nov 21 08:43:27.288: INFO: Started pod liveness-http in namespace container-probe-2855
STEP: checking the pod's current state and verifying that restartCount is present
Nov 21 08:43:27.290: INFO: Initial restart count of pod liveness-http is 0
Nov 21 08:43:49.316: INFO: Restart count of pod container-probe-2855/liveness-http is now 1 (22.025644003s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:43:49.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2855" for this suite.
Nov 21 08:43:55.357: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:43:55.399: INFO: namespace container-probe-2855 deletion completed in 6.054780932s

â€¢ [SLOW TEST:32.173 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:43:55.399: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Nov 21 08:43:55.506: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Nov 21 08:44:00.520: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov 21 08:44:00.520: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Nov 21 08:44:00.535: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-4124,SelfLink:/apis/apps/v1/namespaces/deployment-4124/deployments/test-cleanup-deployment,UID:105b1795-0c3b-11ea-b617-0202c0a8005b,ResourceVersion:15240,Generation:1,CreationTimestamp:2019-11-21 08:44:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Nov 21 08:44:00.538: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Nov 21 08:44:00.538: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Nov 21 08:44:00.538: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:deployment-4124,SelfLink:/apis/apps/v1/namespaces/deployment-4124/replicasets/test-cleanup-controller,UID:0d56759a-0c3b-11ea-b617-0202c0a8005b,ResourceVersion:15241,Generation:1,CreationTimestamp:2019-11-21 08:43:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 105b1795-0c3b-11ea-b617-0202c0a8005b 0xc0035e2c17 0xc0035e2c18}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Nov 21 08:44:00.554: INFO: Pod "test-cleanup-controller-d9mct" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-d9mct,GenerateName:test-cleanup-controller-,Namespace:deployment-4124,SelfLink:/api/v1/namespaces/deployment-4124/pods/test-cleanup-controller-d9mct,UID:0d5db084-0c3b-11ea-b617-0202c0a8005b,ResourceVersion:15235,Generation:0,CreationTimestamp:2019-11-21 08:43:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 0d56759a-0c3b-11ea-b617-0202c0a8005b 0xc0035e3287 0xc0035e3288}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-c2xff {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-c2xff,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-c2xff true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.93,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0035e3300} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0035e3320}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:43:55 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:43:57 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:43:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:43:55 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.93,PodIP:172.49.166.189,StartTime:2019-11-21 08:43:55 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-11-21 08:43:57 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://reg.mg.hcbss/devcke/nginx@sha256:d78215175f4c4257d821c76a04197f4ec8bd09e8032ae4a0465604f55a8a557c docker://bb97ca5a1800b6066112b8d7f461fdf2fe30a664dc0ab92c9be06a825090e59b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:44:00.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4124" for this suite.
Nov 21 08:44:06.648: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:44:06.689: INFO: namespace deployment-4124 deletion completed in 6.105537874s

â€¢ [SLOW TEST:11.290 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:44:06.689: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Nov 21 08:44:06.732: INFO: PodSpec: initContainers in spec.initContainers
Nov 21 08:44:51.476: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-140e826a-0c3b-11ea-a569-4e55f5a7674f", GenerateName:"", Namespace:"init-container-7289", SelfLink:"/api/v1/namespaces/init-container-7289/pods/pod-init-140e826a-0c3b-11ea-a569-4e55f5a7674f", UID:"140f7c33-0c3b-11ea-b617-0202c0a8005b", ResourceVersion:"15399", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63709922646, loc:(*time.Location)(0x8a060e0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"732046962"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-m4965", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0034d8040), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-m4965", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-m4965", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-m4965", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002e3e098), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"192.168.0.93", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0024b4000), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002e3e120)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002e3e140)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc002e3e148), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc002e3e14c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709922646, loc:(*time.Location)(0x8a060e0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709922646, loc:(*time.Location)(0x8a060e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709922646, loc:(*time.Location)(0x8a060e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709922646, loc:(*time.Location)(0x8a060e0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.0.93", PodIP:"172.49.166.190", StartTime:(*v1.Time)(0xc00273e060), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000e400e0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000e40150)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://reg.mg.hcbss/devcke/busybox@sha256:cbcde3595079b1f7a6b046e96e7547fe786d5c2c8eba678bc260161bc01b8dbe", ContainerID:"docker://eeaa4a0a766dd9150735174f8ae4255095f9e90d57ceafb38ceb87131c637be0"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00273e0a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00273e080), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:44:51.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7289" for this suite.
Nov 21 08:45:13.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:45:13.546: INFO: namespace init-container-7289 deletion completed in 22.052158534s

â€¢ [SLOW TEST:66.857 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:45:13.546: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-3bee59b8-0c3b-11ea-a569-4e55f5a7674f
STEP: Creating a pod to test consume configMaps
Nov 21 08:45:13.643: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3bee9c06-0c3b-11ea-a569-4e55f5a7674f" in namespace "projected-7091" to be "success or failure"
Nov 21 08:45:13.647: INFO: Pod "pod-projected-configmaps-3bee9c06-0c3b-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.626824ms
Nov 21 08:45:15.663: INFO: Pod "pod-projected-configmaps-3bee9c06-0c3b-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020219232s
Nov 21 08:45:17.666: INFO: Pod "pod-projected-configmaps-3bee9c06-0c3b-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022935038s
STEP: Saw pod success
Nov 21 08:45:17.666: INFO: Pod "pod-projected-configmaps-3bee9c06-0c3b-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 08:45:17.668: INFO: Trying to get logs from node 192.168.0.92 pod pod-projected-configmaps-3bee9c06-0c3b-11ea-a569-4e55f5a7674f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 21 08:45:17.683: INFO: Waiting for pod pod-projected-configmaps-3bee9c06-0c3b-11ea-a569-4e55f5a7674f to disappear
Nov 21 08:45:17.700: INFO: Pod pod-projected-configmaps-3bee9c06-0c3b-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:45:17.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7091" for this suite.
Nov 21 08:45:23.724: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:45:23.764: INFO: namespace projected-7091 deletion completed in 6.062478564s

â€¢ [SLOW TEST:10.218 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:45:23.764: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Nov 21 08:45:23.833: INFO: Waiting up to 5m0s for pod "pod-4202a639-0c3b-11ea-a569-4e55f5a7674f" in namespace "emptydir-9140" to be "success or failure"
Nov 21 08:45:23.836: INFO: Pod "pod-4202a639-0c3b-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.633901ms
Nov 21 08:45:25.838: INFO: Pod "pod-4202a639-0c3b-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005911652s
Nov 21 08:45:27.841: INFO: Pod "pod-4202a639-0c3b-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008315294s
STEP: Saw pod success
Nov 21 08:45:27.841: INFO: Pod "pod-4202a639-0c3b-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 08:45:27.843: INFO: Trying to get logs from node 192.168.0.93 pod pod-4202a639-0c3b-11ea-a569-4e55f5a7674f container test-container: <nil>
STEP: delete the pod
Nov 21 08:45:27.872: INFO: Waiting for pod pod-4202a639-0c3b-11ea-a569-4e55f5a7674f to disappear
Nov 21 08:45:27.882: INFO: Pod pod-4202a639-0c3b-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:45:27.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9140" for this suite.
Nov 21 08:45:33.973: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:45:34.032: INFO: namespace emptydir-9140 deletion completed in 6.148097637s

â€¢ [SLOW TEST:10.268 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:45:34.032: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-48209933-0c3b-11ea-a569-4e55f5a7674f
STEP: Creating a pod to test consume secrets
Nov 21 08:45:34.100: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4820d4ce-0c3b-11ea-a569-4e55f5a7674f" in namespace "projected-9029" to be "success or failure"
Nov 21 08:45:34.116: INFO: Pod "pod-projected-secrets-4820d4ce-0c3b-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 15.441998ms
Nov 21 08:45:36.118: INFO: Pod "pod-projected-secrets-4820d4ce-0c3b-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017872404s
Nov 21 08:45:38.121: INFO: Pod "pod-projected-secrets-4820d4ce-0c3b-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020755286s
STEP: Saw pod success
Nov 21 08:45:38.121: INFO: Pod "pod-projected-secrets-4820d4ce-0c3b-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 08:45:38.123: INFO: Trying to get logs from node 192.168.0.92 pod pod-projected-secrets-4820d4ce-0c3b-11ea-a569-4e55f5a7674f container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov 21 08:45:38.176: INFO: Waiting for pod pod-projected-secrets-4820d4ce-0c3b-11ea-a569-4e55f5a7674f to disappear
Nov 21 08:45:38.179: INFO: Pod pod-projected-secrets-4820d4ce-0c3b-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:45:38.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9029" for this suite.
Nov 21 08:45:44.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:45:44.233: INFO: namespace projected-9029 deletion completed in 6.050827261s

â€¢ [SLOW TEST:10.201 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:45:44.233: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Nov 21 08:45:44.341: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4e3b2b11-0c3b-11ea-a569-4e55f5a7674f" in namespace "downward-api-4503" to be "success or failure"
Nov 21 08:45:44.345: INFO: Pod "downwardapi-volume-4e3b2b11-0c3b-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.430593ms
Nov 21 08:45:46.361: INFO: Pod "downwardapi-volume-4e3b2b11-0c3b-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020320036s
STEP: Saw pod success
Nov 21 08:45:46.361: INFO: Pod "downwardapi-volume-4e3b2b11-0c3b-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 08:45:46.368: INFO: Trying to get logs from node 192.168.0.93 pod downwardapi-volume-4e3b2b11-0c3b-11ea-a569-4e55f5a7674f container client-container: <nil>
STEP: delete the pod
Nov 21 08:45:46.391: INFO: Waiting for pod downwardapi-volume-4e3b2b11-0c3b-11ea-a569-4e55f5a7674f to disappear
Nov 21 08:45:46.396: INFO: Pod downwardapi-volume-4e3b2b11-0c3b-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:45:46.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4503" for this suite.
Nov 21 08:45:52.404: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:45:52.443: INFO: namespace downward-api-4503 deletion completed in 6.044836848s

â€¢ [SLOW TEST:8.211 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:45:52.444: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating server pod server in namespace prestop-3944
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-3944
STEP: Deleting pre-stop pod
Nov 21 08:46:05.553: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:46:05.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-3944" for this suite.
Nov 21 08:46:43.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:46:43.627: INFO: namespace prestop-3944 deletion completed in 38.064075053s

â€¢ [SLOW TEST:51.184 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:46:43.627: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Nov 21 08:46:47.760: INFO: Waiting up to 5m0s for pod "client-envvars-7402ee91-0c3b-11ea-a569-4e55f5a7674f" in namespace "pods-2528" to be "success or failure"
Nov 21 08:46:47.762: INFO: Pod "client-envvars-7402ee91-0c3b-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 1.5668ms
Nov 21 08:46:49.780: INFO: Pod "client-envvars-7402ee91-0c3b-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020274186s
Nov 21 08:46:51.783: INFO: Pod "client-envvars-7402ee91-0c3b-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0225932s
STEP: Saw pod success
Nov 21 08:46:51.783: INFO: Pod "client-envvars-7402ee91-0c3b-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 08:46:51.784: INFO: Trying to get logs from node 192.168.0.93 pod client-envvars-7402ee91-0c3b-11ea-a569-4e55f5a7674f container env3cont: <nil>
STEP: delete the pod
Nov 21 08:46:51.804: INFO: Waiting for pod client-envvars-7402ee91-0c3b-11ea-a569-4e55f5a7674f to disappear
Nov 21 08:46:51.809: INFO: Pod client-envvars-7402ee91-0c3b-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:46:51.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2528" for this suite.
Nov 21 08:47:31.816: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:47:31.855: INFO: namespace pods-2528 deletion completed in 40.044540562s

â€¢ [SLOW TEST:48.228 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:47:31.855: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Nov 21 08:47:31.917: INFO: Waiting up to 5m0s for pod "pod-8e58e6f5-0c3b-11ea-a569-4e55f5a7674f" in namespace "emptydir-5696" to be "success or failure"
Nov 21 08:47:31.924: INFO: Pod "pod-8e58e6f5-0c3b-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.282867ms
Nov 21 08:47:33.926: INFO: Pod "pod-8e58e6f5-0c3b-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008536914s
Nov 21 08:47:35.928: INFO: Pod "pod-8e58e6f5-0c3b-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010730461s
STEP: Saw pod success
Nov 21 08:47:35.928: INFO: Pod "pod-8e58e6f5-0c3b-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 08:47:35.930: INFO: Trying to get logs from node 192.168.0.92 pod pod-8e58e6f5-0c3b-11ea-a569-4e55f5a7674f container test-container: <nil>
STEP: delete the pod
Nov 21 08:47:35.942: INFO: Waiting for pod pod-8e58e6f5-0c3b-11ea-a569-4e55f5a7674f to disappear
Nov 21 08:47:35.946: INFO: Pod pod-8e58e6f5-0c3b-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:47:35.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5696" for this suite.
Nov 21 08:47:41.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:47:41.993: INFO: namespace emptydir-5696 deletion completed in 6.044843677s

â€¢ [SLOW TEST:10.138 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:47:41.993: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-9464a0c7-0c3b-11ea-a569-4e55f5a7674f
STEP: Creating configMap with name cm-test-opt-upd-9464a0ff-0c3b-11ea-a569-4e55f5a7674f
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-9464a0c7-0c3b-11ea-a569-4e55f5a7674f
STEP: Updating configmap cm-test-opt-upd-9464a0ff-0c3b-11ea-a569-4e55f5a7674f
STEP: Creating configMap with name cm-test-opt-create-9464a115-0c3b-11ea-a569-4e55f5a7674f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:47:50.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7852" for this suite.
Nov 21 08:48:04.183: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:48:04.224: INFO: namespace configmap-7852 deletion completed in 14.053359822s

â€¢ [SLOW TEST:22.230 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:48:04.224: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Nov 21 08:48:06.853: INFO: Successfully updated pod "labelsupdatea1a3a466-0c3b-11ea-a569-4e55f5a7674f"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:48:08.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5487" for this suite.
Nov 21 08:48:30.903: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:48:30.943: INFO: namespace downward-api-5487 deletion completed in 22.0483745s

â€¢ [SLOW TEST:26.719 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:48:30.943: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating pod
Nov 21 08:48:35.044: INFO: Pod pod-hostip-b196695b-0c3b-11ea-a569-4e55f5a7674f has hostIP: 192.168.0.93
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:48:35.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5760" for this suite.
Nov 21 08:48:57.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:48:57.121: INFO: namespace pods-5760 deletion completed in 22.075019267s

â€¢ [SLOW TEST:26.177 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:48:57.121: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Nov 21 08:48:57.178: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-7714,SelfLink:/api/v1/namespaces/watch-7714/configmaps/e2e-watch-test-watch-closed,UID:c12b2c30-0c3b-11ea-b617-0202c0a8005b,ResourceVersion:16190,Generation:0,CreationTimestamp:2019-11-21 08:48:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov 21 08:48:57.178: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-7714,SelfLink:/api/v1/namespaces/watch-7714/configmaps/e2e-watch-test-watch-closed,UID:c12b2c30-0c3b-11ea-b617-0202c0a8005b,ResourceVersion:16191,Generation:0,CreationTimestamp:2019-11-21 08:48:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Nov 21 08:48:57.189: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-7714,SelfLink:/api/v1/namespaces/watch-7714/configmaps/e2e-watch-test-watch-closed,UID:c12b2c30-0c3b-11ea-b617-0202c0a8005b,ResourceVersion:16192,Generation:0,CreationTimestamp:2019-11-21 08:48:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov 21 08:48:57.189: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-7714,SelfLink:/api/v1/namespaces/watch-7714/configmaps/e2e-watch-test-watch-closed,UID:c12b2c30-0c3b-11ea-b617-0202c0a8005b,ResourceVersion:16193,Generation:0,CreationTimestamp:2019-11-21 08:48:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:48:57.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7714" for this suite.
Nov 21 08:49:03.224: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:49:03.264: INFO: namespace watch-7714 deletion completed in 6.052678272s

â€¢ [SLOW TEST:6.144 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:49:03.264: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:69
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Registering the sample API server.
Nov 21 08:49:03.903: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Nov 21 08:49:05.997: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709922943, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709922943, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709922943, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709922943, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 21 08:49:08.718: INFO: Waited 716.059988ms for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:60
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:49:09.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-4172" for this suite.
Nov 21 08:49:15.270: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:49:15.310: INFO: namespace aggregator-4172 deletion completed in 6.152272147s

â€¢ [SLOW TEST:12.045 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:49:15.310: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Nov 21 08:49:15.367: INFO: Waiting up to 5m0s for pod "pod-cc038476-0c3b-11ea-a569-4e55f5a7674f" in namespace "emptydir-7230" to be "success or failure"
Nov 21 08:49:15.384: INFO: Pod "pod-cc038476-0c3b-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 17.325087ms
Nov 21 08:49:17.386: INFO: Pod "pod-cc038476-0c3b-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019092804s
Nov 21 08:49:19.388: INFO: Pod "pod-cc038476-0c3b-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021095266s
STEP: Saw pod success
Nov 21 08:49:19.388: INFO: Pod "pod-cc038476-0c3b-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 08:49:19.392: INFO: Trying to get logs from node 192.168.0.93 pod pod-cc038476-0c3b-11ea-a569-4e55f5a7674f container test-container: <nil>
STEP: delete the pod
Nov 21 08:49:19.420: INFO: Waiting for pod pod-cc038476-0c3b-11ea-a569-4e55f5a7674f to disappear
Nov 21 08:49:19.428: INFO: Pod pod-cc038476-0c3b-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:49:19.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7230" for this suite.
Nov 21 08:49:25.436: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:49:25.475: INFO: namespace emptydir-7230 deletion completed in 6.045099455s

â€¢ [SLOW TEST:10.165 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:49:25.475: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Nov 21 08:49:25.561: INFO: Waiting up to 5m0s for pod "downward-api-d2172a7b-0c3b-11ea-a569-4e55f5a7674f" in namespace "downward-api-3979" to be "success or failure"
Nov 21 08:49:25.600: INFO: Pod "downward-api-d2172a7b-0c3b-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 38.507244ms
Nov 21 08:49:27.619: INFO: Pod "downward-api-d2172a7b-0c3b-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.057330972s
STEP: Saw pod success
Nov 21 08:49:27.619: INFO: Pod "downward-api-d2172a7b-0c3b-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 08:49:27.629: INFO: Trying to get logs from node 192.168.0.92 pod downward-api-d2172a7b-0c3b-11ea-a569-4e55f5a7674f container dapi-container: <nil>
STEP: delete the pod
Nov 21 08:49:27.676: INFO: Waiting for pod downward-api-d2172a7b-0c3b-11ea-a569-4e55f5a7674f to disappear
Nov 21 08:49:27.686: INFO: Pod downward-api-d2172a7b-0c3b-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:49:27.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3979" for this suite.
Nov 21 08:49:33.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:49:33.741: INFO: namespace downward-api-3979 deletion completed in 6.053670788s

â€¢ [SLOW TEST:8.266 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:49:33.741: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
Nov 21 08:49:34.307: INFO: created pod pod-service-account-defaultsa
Nov 21 08:49:34.307: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Nov 21 08:49:34.326: INFO: created pod pod-service-account-mountsa
Nov 21 08:49:34.326: INFO: pod pod-service-account-mountsa service account token volume mount: true
Nov 21 08:49:34.345: INFO: created pod pod-service-account-nomountsa
Nov 21 08:49:34.345: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Nov 21 08:49:34.355: INFO: created pod pod-service-account-defaultsa-mountspec
Nov 21 08:49:34.355: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Nov 21 08:49:34.426: INFO: created pod pod-service-account-mountsa-mountspec
Nov 21 08:49:34.426: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Nov 21 08:49:34.467: INFO: created pod pod-service-account-nomountsa-mountspec
Nov 21 08:49:34.467: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Nov 21 08:49:34.501: INFO: created pod pod-service-account-defaultsa-nomountspec
Nov 21 08:49:34.501: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Nov 21 08:49:34.583: INFO: created pod pod-service-account-mountsa-nomountspec
Nov 21 08:49:34.583: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Nov 21 08:49:34.594: INFO: created pod pod-service-account-nomountsa-nomountspec
Nov 21 08:49:34.594: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:49:34.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-2015" for this suite.
Nov 21 08:49:40.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:49:40.705: INFO: namespace svcaccounts-2015 deletion completed in 6.069592013s

â€¢ [SLOW TEST:6.963 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:49:40.705: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-9828
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov 21 08:49:40.806: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov 21 08:50:04.870: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.49.135.147:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9828 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 21 08:50:04.870: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
Nov 21 08:50:05.010: INFO: Found all expected endpoints: [netserver-0]
Nov 21 08:50:05.012: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.49.166.145:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9828 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 21 08:50:05.012: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
Nov 21 08:50:05.137: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:50:05.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9828" for this suite.
Nov 21 08:50:27.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:50:27.207: INFO: namespace pod-network-test-9828 deletion completed in 22.066971594s

â€¢ [SLOW TEST:46.502 seconds]
[sig-network] Networking
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:50:27.207: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Nov 21 08:50:27.287: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f6e10cfe-0c3b-11ea-a569-4e55f5a7674f" in namespace "downward-api-3135" to be "success or failure"
Nov 21 08:50:27.293: INFO: Pod "downwardapi-volume-f6e10cfe-0c3b-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.607262ms
Nov 21 08:50:29.295: INFO: Pod "downwardapi-volume-f6e10cfe-0c3b-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008081043s
Nov 21 08:50:31.328: INFO: Pod "downwardapi-volume-f6e10cfe-0c3b-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040303797s
STEP: Saw pod success
Nov 21 08:50:31.328: INFO: Pod "downwardapi-volume-f6e10cfe-0c3b-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 08:50:31.330: INFO: Trying to get logs from node 192.168.0.92 pod downwardapi-volume-f6e10cfe-0c3b-11ea-a569-4e55f5a7674f container client-container: <nil>
STEP: delete the pod
Nov 21 08:50:31.363: INFO: Waiting for pod downwardapi-volume-f6e10cfe-0c3b-11ea-a569-4e55f5a7674f to disappear
Nov 21 08:50:31.367: INFO: Pod downwardapi-volume-f6e10cfe-0c3b-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:50:31.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3135" for this suite.
Nov 21 08:50:37.382: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:50:37.422: INFO: namespace downward-api-3135 deletion completed in 6.052273275s

â€¢ [SLOW TEST:10.215 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:50:37.422: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on tmpfs
Nov 21 08:50:37.477: INFO: Waiting up to 5m0s for pod "pod-fcf494b5-0c3b-11ea-a569-4e55f5a7674f" in namespace "emptydir-1651" to be "success or failure"
Nov 21 08:50:37.514: INFO: Pod "pod-fcf494b5-0c3b-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 36.648213ms
Nov 21 08:50:39.516: INFO: Pod "pod-fcf494b5-0c3b-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038808032s
Nov 21 08:50:41.519: INFO: Pod "pod-fcf494b5-0c3b-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041202382s
STEP: Saw pod success
Nov 21 08:50:41.519: INFO: Pod "pod-fcf494b5-0c3b-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 08:50:41.520: INFO: Trying to get logs from node 192.168.0.93 pod pod-fcf494b5-0c3b-11ea-a569-4e55f5a7674f container test-container: <nil>
STEP: delete the pod
Nov 21 08:50:41.534: INFO: Waiting for pod pod-fcf494b5-0c3b-11ea-a569-4e55f5a7674f to disappear
Nov 21 08:50:41.539: INFO: Pod pod-fcf494b5-0c3b-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:50:41.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1651" for this suite.
Nov 21 08:50:47.547: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:50:47.588: INFO: namespace emptydir-1651 deletion completed in 6.046572601s

â€¢ [SLOW TEST:10.166 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:50:47.588: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Nov 21 08:50:47.692: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Nov 21 08:50:47.722: INFO: Number of nodes with available pods: 0
Nov 21 08:50:47.722: INFO: Node 192.168.0.92 is running more than one daemon pod
Nov 21 08:50:48.726: INFO: Number of nodes with available pods: 0
Nov 21 08:50:48.726: INFO: Node 192.168.0.92 is running more than one daemon pod
Nov 21 08:50:49.734: INFO: Number of nodes with available pods: 1
Nov 21 08:50:49.734: INFO: Node 192.168.0.93 is running more than one daemon pod
Nov 21 08:50:50.729: INFO: Number of nodes with available pods: 2
Nov 21 08:50:50.729: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Nov 21 08:50:50.788: INFO: Wrong image for pod: daemon-set-4pkjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 21 08:50:50.788: INFO: Wrong image for pod: daemon-set-sj9fc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 21 08:50:51.799: INFO: Wrong image for pod: daemon-set-4pkjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 21 08:50:51.799: INFO: Wrong image for pod: daemon-set-sj9fc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 21 08:50:52.799: INFO: Wrong image for pod: daemon-set-4pkjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 21 08:50:52.799: INFO: Wrong image for pod: daemon-set-sj9fc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 21 08:50:52.799: INFO: Pod daemon-set-sj9fc is not available
Nov 21 08:50:53.799: INFO: Wrong image for pod: daemon-set-4pkjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 21 08:50:53.799: INFO: Wrong image for pod: daemon-set-sj9fc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 21 08:50:53.799: INFO: Pod daemon-set-sj9fc is not available
Nov 21 08:50:54.799: INFO: Wrong image for pod: daemon-set-4pkjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 21 08:50:54.799: INFO: Wrong image for pod: daemon-set-sj9fc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 21 08:50:54.799: INFO: Pod daemon-set-sj9fc is not available
Nov 21 08:50:55.799: INFO: Wrong image for pod: daemon-set-4pkjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 21 08:50:55.799: INFO: Wrong image for pod: daemon-set-sj9fc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 21 08:50:55.799: INFO: Pod daemon-set-sj9fc is not available
Nov 21 08:50:56.799: INFO: Wrong image for pod: daemon-set-4pkjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 21 08:50:56.799: INFO: Wrong image for pod: daemon-set-sj9fc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 21 08:50:56.799: INFO: Pod daemon-set-sj9fc is not available
Nov 21 08:50:57.799: INFO: Wrong image for pod: daemon-set-4pkjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 21 08:50:57.799: INFO: Wrong image for pod: daemon-set-sj9fc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 21 08:50:57.799: INFO: Pod daemon-set-sj9fc is not available
Nov 21 08:50:58.799: INFO: Wrong image for pod: daemon-set-4pkjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 21 08:50:58.799: INFO: Wrong image for pod: daemon-set-sj9fc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 21 08:50:58.799: INFO: Pod daemon-set-sj9fc is not available
Nov 21 08:50:59.799: INFO: Wrong image for pod: daemon-set-4pkjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 21 08:50:59.799: INFO: Wrong image for pod: daemon-set-sj9fc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 21 08:50:59.799: INFO: Pod daemon-set-sj9fc is not available
Nov 21 08:51:00.799: INFO: Wrong image for pod: daemon-set-4pkjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 21 08:51:00.799: INFO: Pod daemon-set-b8stt is not available
Nov 21 08:51:01.799: INFO: Wrong image for pod: daemon-set-4pkjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 21 08:51:01.799: INFO: Pod daemon-set-b8stt is not available
Nov 21 08:51:02.828: INFO: Wrong image for pod: daemon-set-4pkjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 21 08:51:03.799: INFO: Wrong image for pod: daemon-set-4pkjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 21 08:51:04.799: INFO: Wrong image for pod: daemon-set-4pkjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 21 08:51:04.799: INFO: Pod daemon-set-4pkjd is not available
Nov 21 08:51:05.799: INFO: Pod daemon-set-95qdb is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Nov 21 08:51:05.805: INFO: Number of nodes with available pods: 1
Nov 21 08:51:05.805: INFO: Node 192.168.0.93 is running more than one daemon pod
Nov 21 08:51:06.809: INFO: Number of nodes with available pods: 1
Nov 21 08:51:06.809: INFO: Node 192.168.0.93 is running more than one daemon pod
Nov 21 08:51:07.810: INFO: Number of nodes with available pods: 2
Nov 21 08:51:07.810: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3546, will wait for the garbage collector to delete the pods
Nov 21 08:51:07.871: INFO: Deleting DaemonSet.extensions daemon-set took: 2.807479ms
Nov 21 08:51:08.171: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.172977ms
Nov 21 08:51:20.673: INFO: Number of nodes with available pods: 0
Nov 21 08:51:20.673: INFO: Number of running nodes: 0, number of available pods: 0
Nov 21 08:51:20.674: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3546/daemonsets","resourceVersion":"16977"},"items":null}

Nov 21 08:51:20.675: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3546/pods","resourceVersion":"16977"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:51:20.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3546" for this suite.
Nov 21 08:51:26.690: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:51:26.731: INFO: namespace daemonsets-3546 deletion completed in 6.047994642s

â€¢ [SLOW TEST:39.143 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:51:26.731: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-7869
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov 21 08:51:26.784: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov 21 08:51:52.936: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.49.166.146 8081 | grep -v '^\s*$'] Namespace:pod-network-test-7869 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 21 08:51:52.936: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
Nov 21 08:51:54.054: INFO: Found all expected endpoints: [netserver-0]
Nov 21 08:51:54.056: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.49.135.154 8081 | grep -v '^\s*$'] Namespace:pod-network-test-7869 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 21 08:51:54.056: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
Nov 21 08:51:55.159: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:51:55.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7869" for this suite.
Nov 21 08:52:17.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:52:17.211: INFO: namespace pod-network-test-7869 deletion completed in 22.049870215s

â€¢ [SLOW TEST:50.481 seconds]
[sig-network] Networking
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:52:17.212: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Nov 21 08:52:19.812: INFO: Successfully updated pod "pod-update-activedeadlineseconds-386f642b-0c3c-11ea-a569-4e55f5a7674f"
Nov 21 08:52:19.812: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-386f642b-0c3c-11ea-a569-4e55f5a7674f" in namespace "pods-9374" to be "terminated due to deadline exceeded"
Nov 21 08:52:19.821: INFO: Pod "pod-update-activedeadlineseconds-386f642b-0c3c-11ea-a569-4e55f5a7674f": Phase="Running", Reason="", readiness=true. Elapsed: 8.77064ms
Nov 21 08:52:21.822: INFO: Pod "pod-update-activedeadlineseconds-386f642b-0c3c-11ea-a569-4e55f5a7674f": Phase="Running", Reason="", readiness=true. Elapsed: 2.010627885s
Nov 21 08:52:23.824: INFO: Pod "pod-update-activedeadlineseconds-386f642b-0c3c-11ea-a569-4e55f5a7674f": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.012303224s
Nov 21 08:52:23.824: INFO: Pod "pod-update-activedeadlineseconds-386f642b-0c3c-11ea-a569-4e55f5a7674f" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:52:23.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9374" for this suite.
Nov 21 08:52:29.839: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:52:29.877: INFO: namespace pods-9374 deletion completed in 6.051359715s

â€¢ [SLOW TEST:12.666 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:52:29.878: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Nov 21 08:52:29.976: INFO: Waiting up to 5m0s for pod "downwardapi-volume-40028b65-0c3c-11ea-a569-4e55f5a7674f" in namespace "projected-7093" to be "success or failure"
Nov 21 08:52:29.981: INFO: Pod "downwardapi-volume-40028b65-0c3c-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.620453ms
Nov 21 08:52:31.983: INFO: Pod "downwardapi-volume-40028b65-0c3c-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006697032s
Nov 21 08:52:33.985: INFO: Pod "downwardapi-volume-40028b65-0c3c-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009014116s
STEP: Saw pod success
Nov 21 08:52:33.985: INFO: Pod "downwardapi-volume-40028b65-0c3c-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 08:52:33.987: INFO: Trying to get logs from node 192.168.0.93 pod downwardapi-volume-40028b65-0c3c-11ea-a569-4e55f5a7674f container client-container: <nil>
STEP: delete the pod
Nov 21 08:52:34.004: INFO: Waiting for pod downwardapi-volume-40028b65-0c3c-11ea-a569-4e55f5a7674f to disappear
Nov 21 08:52:34.009: INFO: Pod downwardapi-volume-40028b65-0c3c-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:52:34.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7093" for this suite.
Nov 21 08:52:40.017: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:52:40.056: INFO: namespace projected-7093 deletion completed in 6.044918697s

â€¢ [SLOW TEST:10.179 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:52:40.057: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Nov 21 08:52:40.103: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 version --client'
Nov 21 08:52:40.163: INFO: stderr: ""
Nov 21 08:52:40.163: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.1\", GitCommit:\"b7394102d6ef778017f2ca4046abbaa23b88c290\", GitTreeState:\"clean\", BuildDate:\"2019-04-08T17:11:31Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Nov 21 08:52:40.164: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 create -f - --namespace=kubectl-3177'
Nov 21 08:52:41.074: INFO: stderr: ""
Nov 21 08:52:41.074: INFO: stdout: "replicationcontroller/redis-master created\n"
Nov 21 08:52:41.074: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 create -f - --namespace=kubectl-3177'
Nov 21 08:52:41.298: INFO: stderr: ""
Nov 21 08:52:41.298: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Nov 21 08:52:42.300: INFO: Selector matched 1 pods for map[app:redis]
Nov 21 08:52:42.300: INFO: Found 0 / 1
Nov 21 08:52:43.303: INFO: Selector matched 1 pods for map[app:redis]
Nov 21 08:52:43.303: INFO: Found 0 / 1
Nov 21 08:52:44.300: INFO: Selector matched 1 pods for map[app:redis]
Nov 21 08:52:44.300: INFO: Found 1 / 1
Nov 21 08:52:44.300: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov 21 08:52:44.302: INFO: Selector matched 1 pods for map[app:redis]
Nov 21 08:52:44.302: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov 21 08:52:44.302: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 describe pod redis-master-z6nqv --namespace=kubectl-3177'
Nov 21 08:52:44.382: INFO: stderr: ""
Nov 21 08:52:44.382: INFO: stdout: "Name:               redis-master-z6nqv\nNamespace:          kubectl-3177\nPriority:           0\nPriorityClassName:  <none>\nNode:               192.168.0.92/192.168.0.92\nStart Time:         Thu, 21 Nov 2019 08:52:41 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 172.49.135.152\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://431ce4c68efd671964b457976d87a45110f6ff8d09607bb3a59417e8ee212e54\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://reg.mg.hcbss/devcke/redis@sha256:9b5b1c1ec462abb4b89145a23a1fbf7eb3b2bb25927fc94e820f89a73029889f\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Thu, 21 Nov 2019 08:52:42 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-7vb5p (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-7vb5p:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-7vb5p\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                   Message\n  ----    ------     ----  ----                   -------\n  Normal  Scheduled  3s    default-scheduler      Successfully assigned kubectl-3177/redis-master-z6nqv to 192.168.0.92\n  Normal  Pulled     2s    kubelet, 192.168.0.92  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, 192.168.0.92  Created container redis-master\n  Normal  Started    2s    kubelet, 192.168.0.92  Started container redis-master\n"
Nov 21 08:52:44.382: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 describe rc redis-master --namespace=kubectl-3177'
Nov 21 08:52:44.466: INFO: stderr: ""
Nov 21 08:52:44.466: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-3177\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-z6nqv\n"
Nov 21 08:52:44.466: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 describe service redis-master --namespace=kubectl-3177'
Nov 21 08:52:44.542: INFO: stderr: ""
Nov 21 08:52:44.542: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-3177\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                11.254.77.67\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         172.49.135.152:6379\nSession Affinity:  None\nEvents:            <none>\n"
Nov 21 08:52:44.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 describe node 192.168.0.92'
Nov 21 08:52:44.631: INFO: stderr: ""
Nov 21 08:52:44.631: INFO: stdout: "Name:               192.168.0.92\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=192.168.0.92\n                    kubernetes.io/os=linux\nAnnotations:        csi.volume.kubernetes.io/nodeid: {\"ckecsi\":\"192.168.0.92\"}\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Thu, 21 Nov 2019 06:54:20 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Thu, 21 Nov 2019 08:52:34 +0000   Thu, 21 Nov 2019 06:54:20 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Thu, 21 Nov 2019 08:52:34 +0000   Thu, 21 Nov 2019 06:54:20 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Thu, 21 Nov 2019 08:52:34 +0000   Thu, 21 Nov 2019 06:54:20 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Thu, 21 Nov 2019 08:52:34 +0000   Thu, 21 Nov 2019 06:54:20 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  192.168.0.92\n  Hostname:    192.168.0.92\nCapacity:\n cpu:                24\n ephemeral-storage:  865158628Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             131619316Ki\n pods:               110\nAllocatable:\n cpu:                4\n ephemeral-storage:  865158628Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             11297149137\n pods:               110\nSystem Info:\n Machine ID:                 \n System UUID:                ee4b32b6-d6c8-11e6-9fbe-18ded76a6cca\n Boot ID:                    888abc44-9227-41ea-a5d8-686bd87279fd\n Kernel Version:             4.19.8-1.el7.elrepo.x86_64\n OS Image:                   Alpine Linux v3.10\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.9.8\n Kubelet Version:            v1.14.1\n Kube-Proxy Version:         v1.14.1\nPodCIDR:                     172.49.0.0/24\nNon-terminated Pods:         (6 in total)\n  Namespace                  Name                                     CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                     ------------  ----------  ---------------  -------------  ---\n  default                    ckecsi-57xl8                             0 (0%)        0 (0%)      0 (0%)           0 (0%)         118m\n  default                    ckecsi-attacher-1                        0 (0%)        0 (0%)      0 (0%)           0 (0%)         117m\n  default                    ckecsi-provisioner-0                     0 (0%)        0 (0%)      0 (0%)           0 (0%)         119m\n  kube-system                kubernetes-dashboard-7767bf47b6-sflp4    0 (0%)        0 (0%)      0 (0%)           0 (0%)         119m\n  kubectl-3177               redis-master-z6nqv                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         3s\n  sonobuoy                   sonobuoy-e2e-job-56ce796c30644ea3        0 (0%)        0 (0%)      0 (0%)           0 (0%)         42m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests  Limits\n  --------           --------  ------\n  cpu                0 (0%)    0 (0%)\n  memory             0 (0%)    0 (0%)\n  ephemeral-storage  0 (0%)    0 (0%)\nEvents:              <none>\n"
Nov 21 08:52:44.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 describe namespace kubectl-3177'
Nov 21 08:52:44.704: INFO: stderr: ""
Nov 21 08:52:44.704: INFO: stdout: "Name:         kubectl-3177\nLabels:       e2e-framework=kubectl\n              e2e-run=681fa7d8-0c36-11ea-a569-4e55f5a7674f\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:52:44.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3177" for this suite.
Nov 21 08:53:04.720: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:53:04.759: INFO: namespace kubectl-3177 deletion completed in 20.05325366s

â€¢ [SLOW TEST:24.703 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:53:04.759: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-4055
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating stateful set ss in namespace statefulset-4055
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-4055
Nov 21 08:53:04.861: INFO: Found 0 stateful pods, waiting for 1
Nov 21 08:53:14.864: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Nov 21 08:53:14.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov 21 08:53:15.473: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Nov 21 08:53:15.473: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov 21 08:53:15.473: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov 21 08:53:15.475: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Nov 21 08:53:25.478: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov 21 08:53:25.478: INFO: Waiting for statefulset status.replicas updated to 0
Nov 21 08:53:25.485: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Nov 21 08:53:25.485: INFO: ss-0  192.168.0.93  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:04 +0000 UTC  }]
Nov 21 08:53:25.485: INFO: 
Nov 21 08:53:25.485: INFO: StatefulSet ss has not reached scale 3, at 1
Nov 21 08:53:26.488: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997883974s
Nov 21 08:53:27.490: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.995107401s
Nov 21 08:53:28.492: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.992374368s
Nov 21 08:53:29.495: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.990378782s
Nov 21 08:53:30.497: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.987890378s
Nov 21 08:53:31.500: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.985517787s
Nov 21 08:53:32.502: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.982677125s
Nov 21 08:53:33.505: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.980321323s
Nov 21 08:53:34.508: INFO: Verifying statefulset ss doesn't scale past 3 for another 977.367826ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-4055
Nov 21 08:53:35.511: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 21 08:53:35.744: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Nov 21 08:53:35.744: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov 21 08:53:35.744: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov 21 08:53:35.744: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 21 08:53:35.956: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Nov 21 08:53:35.956: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov 21 08:53:35.956: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov 21 08:53:35.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 21 08:53:36.137: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Nov 21 08:53:36.137: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov 21 08:53:36.137: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov 21 08:53:36.139: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Nov 21 08:53:46.141: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 21 08:53:46.141: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 21 08:53:46.141: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Nov 21 08:53:46.143: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov 21 08:53:46.366: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Nov 21 08:53:46.366: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov 21 08:53:46.366: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov 21 08:53:46.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov 21 08:53:46.567: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Nov 21 08:53:46.567: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov 21 08:53:46.567: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov 21 08:53:46.567: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov 21 08:53:46.803: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Nov 21 08:53:46.803: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov 21 08:53:46.803: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov 21 08:53:46.803: INFO: Waiting for statefulset status.replicas updated to 0
Nov 21 08:53:46.805: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Nov 21 08:53:56.809: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov 21 08:53:56.809: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Nov 21 08:53:56.809: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Nov 21 08:53:56.823: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Nov 21 08:53:56.823: INFO: ss-0  192.168.0.93  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:04 +0000 UTC  }]
Nov 21 08:53:56.823: INFO: ss-1  192.168.0.92  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:25 +0000 UTC  }]
Nov 21 08:53:56.823: INFO: ss-2  192.168.0.93  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:25 +0000 UTC  }]
Nov 21 08:53:56.823: INFO: 
Nov 21 08:53:56.823: INFO: StatefulSet ss has not reached scale 0, at 3
Nov 21 08:53:57.825: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Nov 21 08:53:57.825: INFO: ss-0  192.168.0.93  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:04 +0000 UTC  }]
Nov 21 08:53:57.825: INFO: ss-1  192.168.0.92  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:25 +0000 UTC  }]
Nov 21 08:53:57.825: INFO: ss-2  192.168.0.93  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:25 +0000 UTC  }]
Nov 21 08:53:57.825: INFO: 
Nov 21 08:53:57.825: INFO: StatefulSet ss has not reached scale 0, at 3
Nov 21 08:53:58.827: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Nov 21 08:53:58.827: INFO: ss-0  192.168.0.93  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:04 +0000 UTC  }]
Nov 21 08:53:58.827: INFO: ss-2  192.168.0.93  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:25 +0000 UTC  }]
Nov 21 08:53:58.827: INFO: 
Nov 21 08:53:58.827: INFO: StatefulSet ss has not reached scale 0, at 2
Nov 21 08:53:59.829: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Nov 21 08:53:59.830: INFO: ss-0  192.168.0.93  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:04 +0000 UTC  }]
Nov 21 08:53:59.830: INFO: ss-2  192.168.0.93  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:25 +0000 UTC  }]
Nov 21 08:53:59.830: INFO: 
Nov 21 08:53:59.830: INFO: StatefulSet ss has not reached scale 0, at 2
Nov 21 08:54:00.832: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Nov 21 08:54:00.832: INFO: ss-0  192.168.0.93  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:04 +0000 UTC  }]
Nov 21 08:54:00.832: INFO: ss-2  192.168.0.93  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:25 +0000 UTC  }]
Nov 21 08:54:00.832: INFO: 
Nov 21 08:54:00.832: INFO: StatefulSet ss has not reached scale 0, at 2
Nov 21 08:54:01.835: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Nov 21 08:54:01.835: INFO: ss-0  192.168.0.93  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:04 +0000 UTC  }]
Nov 21 08:54:01.835: INFO: ss-2  192.168.0.93  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:25 +0000 UTC  }]
Nov 21 08:54:01.835: INFO: 
Nov 21 08:54:01.835: INFO: StatefulSet ss has not reached scale 0, at 2
Nov 21 08:54:02.838: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Nov 21 08:54:02.838: INFO: ss-0  192.168.0.93  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:04 +0000 UTC  }]
Nov 21 08:54:02.838: INFO: ss-2  192.168.0.93  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:25 +0000 UTC  }]
Nov 21 08:54:02.838: INFO: 
Nov 21 08:54:02.838: INFO: StatefulSet ss has not reached scale 0, at 2
Nov 21 08:54:03.840: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Nov 21 08:54:03.840: INFO: ss-0  192.168.0.93  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:04 +0000 UTC  }]
Nov 21 08:54:03.841: INFO: ss-2  192.168.0.93  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:25 +0000 UTC  }]
Nov 21 08:54:03.841: INFO: 
Nov 21 08:54:03.841: INFO: StatefulSet ss has not reached scale 0, at 2
Nov 21 08:54:04.843: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Nov 21 08:54:04.843: INFO: ss-0  192.168.0.93  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:04 +0000 UTC  }]
Nov 21 08:54:04.843: INFO: ss-2  192.168.0.93  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:25 +0000 UTC  }]
Nov 21 08:54:04.843: INFO: 
Nov 21 08:54:04.843: INFO: StatefulSet ss has not reached scale 0, at 2
Nov 21 08:54:05.846: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Nov 21 08:54:05.847: INFO: ss-0  192.168.0.93  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:04 +0000 UTC  }]
Nov 21 08:54:05.847: INFO: ss-2  192.168.0.93  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 08:53:25 +0000 UTC  }]
Nov 21 08:54:05.847: INFO: 
Nov 21 08:54:05.847: INFO: StatefulSet ss has not reached scale 0, at 2
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-4055
Nov 21 08:54:06.849: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 21 08:54:06.933: INFO: rc: 1
Nov 21 08:54:06.933: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc0029c29c0 exit status 1 <nil> <nil> true [0xc00264a0d0 0xc00264a150 0xc00264a1f0] [0xc00264a0d0 0xc00264a150 0xc00264a1f0] [0xc00264a140 0xc00264a1a8] [0x9bf9f0 0x9bf9f0] 0xc002e68720 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Nov 21 08:54:16.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 21 08:54:17.021: INFO: rc: 1
Nov 21 08:54:17.021: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc002932360 exit status 1 <nil> <nil> true [0xc000010090 0xc000010640 0xc000010770] [0xc000010090 0xc000010640 0xc000010770] [0xc0000104a0 0xc0000106d8] [0x9bf9f0 0x9bf9f0] 0xc0027c4900 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Nov 21 08:54:27.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 21 08:54:27.085: INFO: rc: 1
Nov 21 08:54:27.085: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002666390 exit status 1 <nil> <nil> true [0xc00018e000 0xc00018f488 0xc00018f500] [0xc00018e000 0xc00018f488 0xc00018f500] [0xc00018f438 0xc00018f4d8] [0x9bf9f0 0x9bf9f0] 0xc002efe840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov 21 08:54:37.085: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 21 08:54:37.150: INFO: rc: 1
Nov 21 08:54:37.150: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0029326f0 exit status 1 <nil> <nil> true [0xc0000107f8 0xc000010870 0xc000010b48] [0xc0000107f8 0xc000010870 0xc000010b48] [0xc000010860 0xc0000108f8] [0x9bf9f0 0x9bf9f0] 0xc0027c5080 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov 21 08:54:47.150: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 21 08:54:47.213: INFO: rc: 1
Nov 21 08:54:47.213: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002932a50 exit status 1 <nil> <nil> true [0xc000010bb0 0xc000010dd0 0xc000010fd0] [0xc000010bb0 0xc000010dd0 0xc000010fd0] [0xc000010d40 0xc000010f18] [0x9bf9f0 0x9bf9f0] 0xc0027c5aa0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov 21 08:54:57.213: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 21 08:54:57.275: INFO: rc: 1
Nov 21 08:54:57.275: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002932de0 exit status 1 <nil> <nil> true [0xc0000110b0 0xc000011240 0xc000011438] [0xc0000110b0 0xc000011240 0xc000011438] [0xc0000111c0 0xc000011350] [0x9bf9f0 0x9bf9f0] 0xc003666000 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov 21 08:55:07.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 21 08:55:07.336: INFO: rc: 1
Nov 21 08:55:07.336: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002933140 exit status 1 <nil> <nil> true [0xc000011498 0xc0000114e0 0xc000011608] [0xc000011498 0xc0000114e0 0xc000011608] [0xc0000114c8 0xc0000115d0] [0x9bf9f0 0x9bf9f0] 0xc003666360 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov 21 08:55:17.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 21 08:55:17.401: INFO: rc: 1
Nov 21 08:55:17.401: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002666780 exit status 1 <nil> <nil> true [0xc00018f510 0xc00018f5c8 0xc00018f690] [0xc00018f510 0xc00018f5c8 0xc00018f690] [0xc00018f5a8 0xc00018f688] [0x9bf9f0 0x9bf9f0] 0xc002eff1a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov 21 08:55:27.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 21 08:55:27.464: INFO: rc: 1
Nov 21 08:55:27.464: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0029c2db0 exit status 1 <nil> <nil> true [0xc00264a238 0xc00264a300 0xc00264a360] [0xc00264a238 0xc00264a300 0xc00264a360] [0xc00264a2b0 0xc00264a340] [0x9bf9f0 0x9bf9f0] 0xc002e68de0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov 21 08:55:37.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 21 08:55:37.547: INFO: rc: 1
Nov 21 08:55:37.547: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0029334d0 exit status 1 <nil> <nil> true [0xc0000116b8 0xc000011740 0xc0000117f8] [0xc0000116b8 0xc000011740 0xc0000117f8] [0xc0000116e8 0xc0000117c8] [0x9bf9f0 0x9bf9f0] 0xc0036666c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov 21 08:55:47.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 21 08:55:47.609: INFO: rc: 1
Nov 21 08:55:47.609: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002933b30 exit status 1 <nil> <nil> true [0xc000011808 0xc000011930 0xc000011a20] [0xc000011808 0xc000011930 0xc000011a20] [0xc0000118f0 0xc0000119d8] [0x9bf9f0 0x9bf9f0] 0xc003666a20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov 21 08:55:57.609: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 21 08:55:57.672: INFO: rc: 1
Nov 21 08:55:57.672: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002933ec0 exit status 1 <nil> <nil> true [0xc000011a60 0xc000011b00 0xc000011be8] [0xc000011a60 0xc000011b00 0xc000011be8] [0xc000011af0 0xc000011bc8] [0x9bf9f0 0x9bf9f0] 0xc003667080 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov 21 08:56:07.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 21 08:56:07.735: INFO: rc: 1
Nov 21 08:56:07.735: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0023d6480 exit status 1 <nil> <nil> true [0xc000010340 0xc000010660 0xc0000107f8] [0xc000010340 0xc000010660 0xc0000107f8] [0xc000010640 0xc000010770] [0x9bf9f0 0x9bf9f0] 0xc0027c4900 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov 21 08:56:17.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 21 08:56:17.799: INFO: rc: 1
Nov 21 08:56:17.799: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002932330 exit status 1 <nil> <nil> true [0xc00018e000 0xc00018f488 0xc00018f500] [0xc00018e000 0xc00018f488 0xc00018f500] [0xc00018f438 0xc00018f4d8] [0x9bf9f0 0x9bf9f0] 0xc0036662a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov 21 08:56:27.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 21 08:56:27.863: INFO: rc: 1
Nov 21 08:56:27.863: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0026663f0 exit status 1 <nil> <nil> true [0xc00264a018 0xc00264a098 0xc00264a128] [0xc00264a018 0xc00264a098 0xc00264a128] [0xc00264a078 0xc00264a0d0] [0x9bf9f0 0x9bf9f0] 0xc002efe840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov 21 08:56:37.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 21 08:56:37.931: INFO: rc: 1
Nov 21 08:56:37.931: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0029326c0 exit status 1 <nil> <nil> true [0xc00018f510 0xc00018f5c8 0xc00018f690] [0xc00018f510 0xc00018f5c8 0xc00018f690] [0xc00018f5a8 0xc00018f688] [0x9bf9f0 0x9bf9f0] 0xc003666600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov 21 08:56:47.931: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 21 08:56:48.009: INFO: rc: 1
Nov 21 08:56:48.009: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0026667b0 exit status 1 <nil> <nil> true [0xc00264a140 0xc00264a1a8 0xc00264a270] [0xc00264a140 0xc00264a1a8 0xc00264a270] [0xc00264a160 0xc00264a238] [0x9bf9f0 0x9bf9f0] 0xc002eff1a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov 21 08:56:58.009: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 21 08:56:58.078: INFO: rc: 1
Nov 21 08:56:58.079: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0023d6810 exit status 1 <nil> <nil> true [0xc000010828 0xc000010888 0xc000010bb0] [0xc000010828 0xc000010888 0xc000010bb0] [0xc000010870 0xc000010b48] [0x9bf9f0 0x9bf9f0] 0xc0027c5080 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov 21 08:57:08.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 21 08:57:08.158: INFO: rc: 1
Nov 21 08:57:08.158: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002932ab0 exit status 1 <nil> <nil> true [0xc00018f698 0xc00018f778 0xc00018f858] [0xc00018f698 0xc00018f778 0xc00018f858] [0xc00018f750 0xc00018f7d0] [0x9bf9f0 0x9bf9f0] 0xc003666960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov 21 08:57:18.158: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 21 08:57:18.221: INFO: rc: 1
Nov 21 08:57:18.221: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002932e70 exit status 1 <nil> <nil> true [0xc00018f868 0xc00018f978 0xc00018fa58] [0xc00018f868 0xc00018f978 0xc00018fa58] [0xc00018f970 0xc00018f9e8] [0x9bf9f0 0x9bf9f0] 0xc003666f00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov 21 08:57:28.221: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 21 08:57:28.285: INFO: rc: 1
Nov 21 08:57:28.286: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0023d6d20 exit status 1 <nil> <nil> true [0xc000010c50 0xc000010e80 0xc0000110b0] [0xc000010c50 0xc000010e80 0xc0000110b0] [0xc000010dd0 0xc000010fd0] [0x9bf9f0 0x9bf9f0] 0xc0027c5aa0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov 21 08:57:38.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 21 08:57:38.347: INFO: rc: 1
Nov 21 08:57:38.348: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0023d7080 exit status 1 <nil> <nil> true [0xc0000111a0 0xc000011318 0xc000011498] [0xc0000111a0 0xc000011318 0xc000011498] [0xc000011240 0xc000011438] [0x9bf9f0 0x9bf9f0] 0xc002e68000 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov 21 08:57:48.348: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 21 08:57:48.411: INFO: rc: 1
Nov 21 08:57:48.411: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0029c26c0 exit status 1 <nil> <nil> true [0xc0001be038 0xc0027c0020 0xc0027c0060] [0xc0001be038 0xc0027c0020 0xc0027c0060] [0xc0027c0008 0xc0027c0058] [0x9bf9f0 0x9bf9f0] 0xc0024b42a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov 21 08:57:58.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 21 08:57:58.475: INFO: rc: 1
Nov 21 08:57:58.475: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002666b70 exit status 1 <nil> <nil> true [0xc00264a2b0 0xc00264a340 0xc00264a380] [0xc00264a2b0 0xc00264a340 0xc00264a380] [0xc00264a328 0xc00264a370] [0x9bf9f0 0x9bf9f0] 0xc00290a000 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov 21 08:58:08.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 21 08:58:08.540: INFO: rc: 1
Nov 21 08:58:08.540: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0021846f0 exit status 1 <nil> <nil> true [0xc0025f4008 0xc0025f4020 0xc0025f4038] [0xc0025f4008 0xc0025f4020 0xc0025f4038] [0xc0025f4018 0xc0025f4030] [0x9bf9f0 0x9bf9f0] 0xc0034a0480 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov 21 08:58:18.540: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 21 08:58:18.606: INFO: rc: 1
Nov 21 08:58:18.606: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0029c2360 exit status 1 <nil> <nil> true [0xc0001be038 0xc0027c0020 0xc0027c0060] [0xc0001be038 0xc0027c0020 0xc0027c0060] [0xc0027c0008 0xc0027c0058] [0x9bf9f0 0x9bf9f0] 0xc002efe840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov 21 08:58:28.606: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 21 08:58:28.678: INFO: rc: 1
Nov 21 08:58:28.678: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002184de0 exit status 1 <nil> <nil> true [0xc0025f4040 0xc0025f4058 0xc0025f4070] [0xc0025f4040 0xc0025f4058 0xc0025f4070] [0xc0025f4050 0xc0025f4068] [0x9bf9f0 0x9bf9f0] 0xc0027c4900 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov 21 08:58:38.678: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 21 08:58:38.741: INFO: rc: 1
Nov 21 08:58:38.741: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002666390 exit status 1 <nil> <nil> true [0xc00264a018 0xc00264a098 0xc00264a128] [0xc00264a018 0xc00264a098 0xc00264a128] [0xc00264a078 0xc00264a0d0] [0x9bf9f0 0x9bf9f0] 0xc0024b42a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov 21 08:58:48.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 21 08:58:48.808: INFO: rc: 1
Nov 21 08:58:48.808: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0023d64e0 exit status 1 <nil> <nil> true [0xc000010090 0xc000010640 0xc000010770] [0xc000010090 0xc000010640 0xc000010770] [0xc0000104a0 0xc0000106d8] [0x9bf9f0 0x9bf9f0] 0xc0034a0ae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov 21 08:58:58.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 21 08:58:58.871: INFO: rc: 1
Nov 21 08:58:58.871: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0023d6870 exit status 1 <nil> <nil> true [0xc0000107f8 0xc000010870 0xc000010b48] [0xc0000107f8 0xc000010870 0xc000010b48] [0xc000010860 0xc0000108f8] [0x9bf9f0 0x9bf9f0] 0xc0034a1020 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Nov 21 08:59:08.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-4055 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 21 08:59:08.934: INFO: rc: 1
Nov 21 08:59:08.934: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: 
Nov 21 08:59:08.934: INFO: Scaling statefulset ss to 0
Nov 21 08:59:08.939: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Nov 21 08:59:08.940: INFO: Deleting all statefulset in ns statefulset-4055
Nov 21 08:59:08.942: INFO: Scaling statefulset ss to 0
Nov 21 08:59:08.946: INFO: Waiting for statefulset status.replicas updated to 0
Nov 21 08:59:08.947: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:59:08.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4055" for this suite.
Nov 21 08:59:14.992: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:59:15.032: INFO: namespace statefulset-4055 deletion completed in 6.049536322s

â€¢ [SLOW TEST:370.272 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:59:15.032: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Nov 21 08:59:15.140: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3181d5b3-0c3d-11ea-a569-4e55f5a7674f" in namespace "projected-2440" to be "success or failure"
Nov 21 08:59:15.145: INFO: Pod "downwardapi-volume-3181d5b3-0c3d-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.539749ms
Nov 21 08:59:17.147: INFO: Pod "downwardapi-volume-3181d5b3-0c3d-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006718675s
Nov 21 08:59:19.149: INFO: Pod "downwardapi-volume-3181d5b3-0c3d-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00878466s
STEP: Saw pod success
Nov 21 08:59:19.149: INFO: Pod "downwardapi-volume-3181d5b3-0c3d-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 08:59:19.150: INFO: Trying to get logs from node 192.168.0.92 pod downwardapi-volume-3181d5b3-0c3d-11ea-a569-4e55f5a7674f container client-container: <nil>
STEP: delete the pod
Nov 21 08:59:19.179: INFO: Waiting for pod downwardapi-volume-3181d5b3-0c3d-11ea-a569-4e55f5a7674f to disappear
Nov 21 08:59:19.185: INFO: Pod downwardapi-volume-3181d5b3-0c3d-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:59:19.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2440" for this suite.
Nov 21 08:59:25.192: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:59:25.248: INFO: namespace projected-2440 deletion completed in 6.060955722s

â€¢ [SLOW TEST:10.216 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:59:25.248: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-wrht
STEP: Creating a pod to test atomic-volume-subpath
Nov 21 08:59:25.323: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-wrht" in namespace "subpath-8290" to be "success or failure"
Nov 21 08:59:25.328: INFO: Pod "pod-subpath-test-configmap-wrht": Phase="Pending", Reason="", readiness=false. Elapsed: 4.574418ms
Nov 21 08:59:27.330: INFO: Pod "pod-subpath-test-configmap-wrht": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006872966s
Nov 21 08:59:29.332: INFO: Pod "pod-subpath-test-configmap-wrht": Phase="Running", Reason="", readiness=true. Elapsed: 4.008930895s
Nov 21 08:59:31.335: INFO: Pod "pod-subpath-test-configmap-wrht": Phase="Running", Reason="", readiness=true. Elapsed: 6.011419654s
Nov 21 08:59:33.337: INFO: Pod "pod-subpath-test-configmap-wrht": Phase="Running", Reason="", readiness=true. Elapsed: 8.01350248s
Nov 21 08:59:35.339: INFO: Pod "pod-subpath-test-configmap-wrht": Phase="Running", Reason="", readiness=true. Elapsed: 10.01540614s
Nov 21 08:59:37.341: INFO: Pod "pod-subpath-test-configmap-wrht": Phase="Running", Reason="", readiness=true. Elapsed: 12.017835625s
Nov 21 08:59:39.343: INFO: Pod "pod-subpath-test-configmap-wrht": Phase="Running", Reason="", readiness=true. Elapsed: 14.019937505s
Nov 21 08:59:41.346: INFO: Pod "pod-subpath-test-configmap-wrht": Phase="Running", Reason="", readiness=true. Elapsed: 16.022449741s
Nov 21 08:59:43.348: INFO: Pod "pod-subpath-test-configmap-wrht": Phase="Running", Reason="", readiness=true. Elapsed: 18.024756801s
Nov 21 08:59:45.350: INFO: Pod "pod-subpath-test-configmap-wrht": Phase="Running", Reason="", readiness=true. Elapsed: 20.026671019s
Nov 21 08:59:47.352: INFO: Pod "pod-subpath-test-configmap-wrht": Phase="Running", Reason="", readiness=true. Elapsed: 22.028606915s
Nov 21 08:59:49.354: INFO: Pod "pod-subpath-test-configmap-wrht": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.030715974s
STEP: Saw pod success
Nov 21 08:59:49.354: INFO: Pod "pod-subpath-test-configmap-wrht" satisfied condition "success or failure"
Nov 21 08:59:49.355: INFO: Trying to get logs from node 192.168.0.93 pod pod-subpath-test-configmap-wrht container test-container-subpath-configmap-wrht: <nil>
STEP: delete the pod
Nov 21 08:59:49.375: INFO: Waiting for pod pod-subpath-test-configmap-wrht to disappear
Nov 21 08:59:49.394: INFO: Pod pod-subpath-test-configmap-wrht no longer exists
STEP: Deleting pod pod-subpath-test-configmap-wrht
Nov 21 08:59:49.394: INFO: Deleting pod "pod-subpath-test-configmap-wrht" in namespace "subpath-8290"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:59:49.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8290" for this suite.
Nov 21 08:59:55.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 08:59:55.450: INFO: namespace subpath-8290 deletion completed in 6.052663334s

â€¢ [SLOW TEST:30.202 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 08:59:55.450: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Starting the proxy
Nov 21 08:59:55.489: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-073157133 proxy --unix-socket=/tmp/kubectl-proxy-unix489754556/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 08:59:55.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5540" for this suite.
Nov 21 09:00:01.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:00:01.604: INFO: namespace kubectl-5540 deletion completed in 6.050237671s

â€¢ [SLOW TEST:6.154 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:00:01.605: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating all guestbook components
Nov 21 09:00:01.649: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Nov 21 09:00:01.649: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 create -f - --namespace=kubectl-4270'
Nov 21 09:00:01.863: INFO: stderr: ""
Nov 21 09:00:01.863: INFO: stdout: "service/redis-slave created\n"
Nov 21 09:00:01.863: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Nov 21 09:00:01.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 create -f - --namespace=kubectl-4270'
Nov 21 09:00:02.075: INFO: stderr: ""
Nov 21 09:00:02.075: INFO: stdout: "service/redis-master created\n"
Nov 21 09:00:02.075: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Nov 21 09:00:02.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 create -f - --namespace=kubectl-4270'
Nov 21 09:00:02.292: INFO: stderr: ""
Nov 21 09:00:02.292: INFO: stdout: "service/frontend created\n"
Nov 21 09:00:02.292: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Nov 21 09:00:02.292: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 create -f - --namespace=kubectl-4270'
Nov 21 09:00:02.501: INFO: stderr: ""
Nov 21 09:00:02.501: INFO: stdout: "deployment.apps/frontend created\n"
Nov 21 09:00:02.501: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Nov 21 09:00:02.501: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 create -f - --namespace=kubectl-4270'
Nov 21 09:00:02.736: INFO: stderr: ""
Nov 21 09:00:02.736: INFO: stdout: "deployment.apps/redis-master created\n"
Nov 21 09:00:02.736: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Nov 21 09:00:02.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 create -f - --namespace=kubectl-4270'
Nov 21 09:00:02.940: INFO: stderr: ""
Nov 21 09:00:02.940: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Nov 21 09:00:02.940: INFO: Waiting for all frontend pods to be Running.
Nov 21 09:00:07.990: INFO: Waiting for frontend to serve content.
Nov 21 09:00:08.033: INFO: Trying to add a new entry to the guestbook.
Nov 21 09:00:08.116: INFO: Verifying that added entry can be retrieved.
Nov 21 09:00:08.127: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Nov 21 09:00:13.138: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Nov 21 09:00:18.148: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Nov 21 09:00:23.159: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
STEP: using delete to clean up resources
Nov 21 09:00:28.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 delete --grace-period=0 --force -f - --namespace=kubectl-4270'
Nov 21 09:00:28.274: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 21 09:00:28.274: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Nov 21 09:00:28.274: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 delete --grace-period=0 --force -f - --namespace=kubectl-4270'
Nov 21 09:00:28.388: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 21 09:00:28.388: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Nov 21 09:00:28.388: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 delete --grace-period=0 --force -f - --namespace=kubectl-4270'
Nov 21 09:00:28.508: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 21 09:00:28.508: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Nov 21 09:00:28.509: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 delete --grace-period=0 --force -f - --namespace=kubectl-4270'
Nov 21 09:00:28.600: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 21 09:00:28.600: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Nov 21 09:00:28.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 delete --grace-period=0 --force -f - --namespace=kubectl-4270'
Nov 21 09:00:28.674: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 21 09:00:28.674: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Nov 21 09:00:28.674: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 delete --grace-period=0 --force -f - --namespace=kubectl-4270'
Nov 21 09:00:28.748: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 21 09:00:28.748: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:00:28.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4270" for this suite.
Nov 21 09:01:12.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:01:12.800: INFO: namespace kubectl-4270 deletion completed in 44.04969445s

â€¢ [SLOW TEST:71.196 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:01:12.800: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Nov 21 09:01:12.845: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:01:13.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-4606" for this suite.
Nov 21 09:01:19.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:01:19.931: INFO: namespace custom-resource-definition-4606 deletion completed in 6.051387667s

â€¢ [SLOW TEST:7.131 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:01:19.932: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Nov 21 09:01:20.005: INFO: Waiting up to 5m0s for pod "pod-7beebd69-0c3d-11ea-a569-4e55f5a7674f" in namespace "emptydir-7062" to be "success or failure"
Nov 21 09:01:20.010: INFO: Pod "pod-7beebd69-0c3d-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.286947ms
Nov 21 09:01:22.027: INFO: Pod "pod-7beebd69-0c3d-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022026428s
STEP: Saw pod success
Nov 21 09:01:22.028: INFO: Pod "pod-7beebd69-0c3d-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 09:01:22.033: INFO: Trying to get logs from node 192.168.0.92 pod pod-7beebd69-0c3d-11ea-a569-4e55f5a7674f container test-container: <nil>
STEP: delete the pod
Nov 21 09:01:22.080: INFO: Waiting for pod pod-7beebd69-0c3d-11ea-a569-4e55f5a7674f to disappear
Nov 21 09:01:22.084: INFO: Pod pod-7beebd69-0c3d-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:01:22.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7062" for this suite.
Nov 21 09:01:28.103: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:01:28.144: INFO: namespace emptydir-7062 deletion completed in 6.053177149s

â€¢ [SLOW TEST:8.212 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:01:28.144: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-80d01d1b-0c3d-11ea-a569-4e55f5a7674f
STEP: Creating a pod to test consume secrets
Nov 21 09:01:28.229: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-80d28dca-0c3d-11ea-a569-4e55f5a7674f" in namespace "projected-5487" to be "success or failure"
Nov 21 09:01:28.233: INFO: Pod "pod-projected-secrets-80d28dca-0c3d-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.72813ms
Nov 21 09:01:30.235: INFO: Pod "pod-projected-secrets-80d28dca-0c3d-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005736386s
Nov 21 09:01:32.237: INFO: Pod "pod-projected-secrets-80d28dca-0c3d-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007984159s
STEP: Saw pod success
Nov 21 09:01:32.237: INFO: Pod "pod-projected-secrets-80d28dca-0c3d-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 09:01:32.239: INFO: Trying to get logs from node 192.168.0.93 pod pod-projected-secrets-80d28dca-0c3d-11ea-a569-4e55f5a7674f container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov 21 09:01:32.292: INFO: Waiting for pod pod-projected-secrets-80d28dca-0c3d-11ea-a569-4e55f5a7674f to disappear
Nov 21 09:01:32.296: INFO: Pod pod-projected-secrets-80d28dca-0c3d-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:01:32.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5487" for this suite.
Nov 21 09:01:38.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:01:38.345: INFO: namespace projected-5487 deletion completed in 6.047762596s

â€¢ [SLOW TEST:10.202 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:01:38.346: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-86e5b78c-0c3d-11ea-a569-4e55f5a7674f
STEP: Creating a pod to test consume configMaps
Nov 21 09:01:38.412: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-86e718c1-0c3d-11ea-a569-4e55f5a7674f" in namespace "projected-3737" to be "success or failure"
Nov 21 09:01:38.429: INFO: Pod "pod-projected-configmaps-86e718c1-0c3d-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 17.376768ms
Nov 21 09:01:40.438: INFO: Pod "pod-projected-configmaps-86e718c1-0c3d-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.026581243s
STEP: Saw pod success
Nov 21 09:01:40.438: INFO: Pod "pod-projected-configmaps-86e718c1-0c3d-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 09:01:40.440: INFO: Trying to get logs from node 192.168.0.92 pod pod-projected-configmaps-86e718c1-0c3d-11ea-a569-4e55f5a7674f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 21 09:01:40.463: INFO: Waiting for pod pod-projected-configmaps-86e718c1-0c3d-11ea-a569-4e55f5a7674f to disappear
Nov 21 09:01:40.519: INFO: Pod pod-projected-configmaps-86e718c1-0c3d-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:01:40.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3737" for this suite.
Nov 21 09:01:46.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:01:46.604: INFO: namespace projected-3737 deletion completed in 6.082369816s

â€¢ [SLOW TEST:8.258 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:01:46.604: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1455
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov 21 09:01:46.651: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=kubectl-5643'
Nov 21 09:01:46.728: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov 21 09:01:46.728: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1460
Nov 21 09:01:48.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 delete deployment e2e-test-nginx-deployment --namespace=kubectl-5643'
Nov 21 09:01:48.869: INFO: stderr: ""
Nov 21 09:01:48.869: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:01:48.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5643" for this suite.
Nov 21 09:01:54.881: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:01:54.925: INFO: namespace kubectl-5643 deletion completed in 6.05317032s

â€¢ [SLOW TEST:8.321 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:01:54.925: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-6390
Nov 21 09:01:58.996: INFO: Started pod liveness-http in namespace container-probe-6390
STEP: checking the pod's current state and verifying that restartCount is present
Nov 21 09:01:58.998: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:05:59.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6390" for this suite.
Nov 21 09:06:05.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:06:05.357: INFO: namespace container-probe-6390 deletion completed in 6.075267209s

â€¢ [SLOW TEST:250.432 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:06:05.357: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:06:09.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3853" for this suite.
Nov 21 09:06:15.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:06:15.527: INFO: namespace kubelet-test-3853 deletion completed in 6.070766317s

â€¢ [SLOW TEST:10.170 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:06:15.527: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's command
Nov 21 09:06:15.597: INFO: Waiting up to 5m0s for pod "var-expansion-2c1dc231-0c3e-11ea-a569-4e55f5a7674f" in namespace "var-expansion-1094" to be "success or failure"
Nov 21 09:06:15.601: INFO: Pod "var-expansion-2c1dc231-0c3e-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.393071ms
Nov 21 09:06:17.608: INFO: Pod "var-expansion-2c1dc231-0c3e-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010598811s
STEP: Saw pod success
Nov 21 09:06:17.608: INFO: Pod "var-expansion-2c1dc231-0c3e-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 09:06:17.609: INFO: Trying to get logs from node 192.168.0.92 pod var-expansion-2c1dc231-0c3e-11ea-a569-4e55f5a7674f container dapi-container: <nil>
STEP: delete the pod
Nov 21 09:06:17.652: INFO: Waiting for pod var-expansion-2c1dc231-0c3e-11ea-a569-4e55f5a7674f to disappear
Nov 21 09:06:17.658: INFO: Pod var-expansion-2c1dc231-0c3e-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:06:17.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1094" for this suite.
Nov 21 09:06:23.678: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:06:23.717: INFO: namespace var-expansion-1094 deletion completed in 6.052391593s

â€¢ [SLOW TEST:8.190 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:06:23.717: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-3100557f-0c3e-11ea-a569-4e55f5a7674f
STEP: Creating a pod to test consume secrets
Nov 21 09:06:23.791: INFO: Waiting up to 5m0s for pod "pod-secrets-3100980b-0c3e-11ea-a569-4e55f5a7674f" in namespace "secrets-8564" to be "success or failure"
Nov 21 09:06:23.809: INFO: Pod "pod-secrets-3100980b-0c3e-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 17.209737ms
Nov 21 09:06:25.814: INFO: Pod "pod-secrets-3100980b-0c3e-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022101897s
STEP: Saw pod success
Nov 21 09:06:25.814: INFO: Pod "pod-secrets-3100980b-0c3e-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 09:06:25.828: INFO: Trying to get logs from node 192.168.0.93 pod pod-secrets-3100980b-0c3e-11ea-a569-4e55f5a7674f container secret-volume-test: <nil>
STEP: delete the pod
Nov 21 09:06:25.843: INFO: Waiting for pod pod-secrets-3100980b-0c3e-11ea-a569-4e55f5a7674f to disappear
Nov 21 09:06:25.847: INFO: Pod pod-secrets-3100980b-0c3e-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:06:25.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8564" for this suite.
Nov 21 09:06:31.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:06:31.895: INFO: namespace secrets-8564 deletion completed in 6.045464545s

â€¢ [SLOW TEST:8.177 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:06:31.895: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-downwardapi-584r
STEP: Creating a pod to test atomic-volume-subpath
Nov 21 09:06:31.985: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-584r" in namespace "subpath-3301" to be "success or failure"
Nov 21 09:06:31.990: INFO: Pod "pod-subpath-test-downwardapi-584r": Phase="Pending", Reason="", readiness=false. Elapsed: 5.600953ms
Nov 21 09:06:33.996: INFO: Pod "pod-subpath-test-downwardapi-584r": Phase="Running", Reason="", readiness=true. Elapsed: 2.011240934s
Nov 21 09:06:35.998: INFO: Pod "pod-subpath-test-downwardapi-584r": Phase="Running", Reason="", readiness=true. Elapsed: 4.013127968s
Nov 21 09:06:38.153: INFO: Pod "pod-subpath-test-downwardapi-584r": Phase="Running", Reason="", readiness=true. Elapsed: 6.167660633s
Nov 21 09:06:40.155: INFO: Pod "pod-subpath-test-downwardapi-584r": Phase="Running", Reason="", readiness=true. Elapsed: 8.169788691s
Nov 21 09:06:42.157: INFO: Pod "pod-subpath-test-downwardapi-584r": Phase="Running", Reason="", readiness=true. Elapsed: 10.172221888s
Nov 21 09:06:44.160: INFO: Pod "pod-subpath-test-downwardapi-584r": Phase="Running", Reason="", readiness=true. Elapsed: 12.174714921s
Nov 21 09:06:46.162: INFO: Pod "pod-subpath-test-downwardapi-584r": Phase="Running", Reason="", readiness=true. Elapsed: 14.17720309s
Nov 21 09:06:48.181: INFO: Pod "pod-subpath-test-downwardapi-584r": Phase="Running", Reason="", readiness=true. Elapsed: 16.195903426s
Nov 21 09:06:50.183: INFO: Pod "pod-subpath-test-downwardapi-584r": Phase="Running", Reason="", readiness=true. Elapsed: 18.198267787s
Nov 21 09:06:52.186: INFO: Pod "pod-subpath-test-downwardapi-584r": Phase="Running", Reason="", readiness=true. Elapsed: 20.200664525s
Nov 21 09:06:54.188: INFO: Pod "pod-subpath-test-downwardapi-584r": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.202876124s
STEP: Saw pod success
Nov 21 09:06:54.188: INFO: Pod "pod-subpath-test-downwardapi-584r" satisfied condition "success or failure"
Nov 21 09:06:54.189: INFO: Trying to get logs from node 192.168.0.92 pod pod-subpath-test-downwardapi-584r container test-container-subpath-downwardapi-584r: <nil>
STEP: delete the pod
Nov 21 09:06:54.203: INFO: Waiting for pod pod-subpath-test-downwardapi-584r to disappear
Nov 21 09:06:54.208: INFO: Pod pod-subpath-test-downwardapi-584r no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-584r
Nov 21 09:06:54.208: INFO: Deleting pod "pod-subpath-test-downwardapi-584r" in namespace "subpath-3301"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:06:54.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3301" for this suite.
Nov 21 09:07:00.221: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:07:00.260: INFO: namespace subpath-3301 deletion completed in 6.048813777s

â€¢ [SLOW TEST:28.365 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:07:00.261: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-46c99e15-0c3e-11ea-a569-4e55f5a7674f
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-46c99e15-0c3e-11ea-a569-4e55f5a7674f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:08:20.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-680" for this suite.
Nov 21 09:08:42.616: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:08:42.655: INFO: namespace configmap-680 deletion completed in 22.045886228s

â€¢ [SLOW TEST:102.394 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:08:42.655: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Nov 21 09:08:42.700: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Nov 21 09:08:42.711: INFO: Pod name sample-pod: Found 0 pods out of 1
Nov 21 09:08:47.714: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov 21 09:08:47.714: INFO: Creating deployment "test-rolling-update-deployment"
Nov 21 09:08:47.717: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Nov 21 09:08:47.768: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Nov 21 09:08:49.772: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Nov 21 09:08:49.774: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709924127, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709924127, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709924127, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709924127, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-67599b4d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 21 09:08:51.776: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Nov 21 09:08:51.781: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-1070,SelfLink:/apis/apps/v1/namespaces/deployment-1070/deployments/test-rolling-update-deployment,UID:86caa1d1-0c3e-11ea-b617-0202c0a8005b,ResourceVersion:19639,Generation:1,CreationTimestamp:2019-11-21 09:08:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-11-21 09:08:47 +0000 UTC 2019-11-21 09:08:47 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-11-21 09:08:50 +0000 UTC 2019-11-21 09:08:47 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-67599b4d9" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Nov 21 09:08:51.782: INFO: New ReplicaSet "test-rolling-update-deployment-67599b4d9" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-67599b4d9,GenerateName:,Namespace:deployment-1070,SelfLink:/apis/apps/v1/namespaces/deployment-1070/replicasets/test-rolling-update-deployment-67599b4d9,UID:86d2e165-0c3e-11ea-b617-0202c0a8005b,ResourceVersion:19628,Generation:1,CreationTimestamp:2019-11-21 09:08:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 86caa1d1-0c3e-11ea-b617-0202c0a8005b 0xc00334ee70 0xc00334ee71}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Nov 21 09:08:51.782: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Nov 21 09:08:51.782: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-1070,SelfLink:/apis/apps/v1/namespaces/deployment-1070/replicasets/test-rolling-update-controller,UID:83cd7f8b-0c3e-11ea-b617-0202c0a8005b,ResourceVersion:19637,Generation:2,CreationTimestamp:2019-11-21 09:08:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 86caa1d1-0c3e-11ea-b617-0202c0a8005b 0xc00334eda7 0xc00334eda8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov 21 09:08:51.784: INFO: Pod "test-rolling-update-deployment-67599b4d9-wtfg4" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-67599b4d9-wtfg4,GenerateName:test-rolling-update-deployment-67599b4d9-,Namespace:deployment-1070,SelfLink:/api/v1/namespaces/deployment-1070/pods/test-rolling-update-deployment-67599b4d9-wtfg4,UID:86d3d5cd-0c3e-11ea-b617-0202c0a8005b,ResourceVersion:19627,Generation:0,CreationTimestamp:2019-11-21 09:08:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-67599b4d9 86d2e165-0c3e-11ea-b617-0202c0a8005b 0xc00334f6e0 0xc00334f6e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wbczq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wbczq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-wbczq true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.93,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00334f760} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00334f780}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:08:47 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:08:50 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:08:50 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:08:47 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.93,PodIP:172.49.166.160,StartTime:2019-11-21 09:08:47 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-11-21 09:08:49 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://reg.mg.hcbss/devcke/redis@sha256:9b5b1c1ec462abb4b89145a23a1fbf7eb3b2bb25927fc94e820f89a73029889f docker://a4faa3617c029c7cdb4ece01c32fb13bdc119906b3b6b9988d7d13b3ab9d5bcc}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:08:51.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1070" for this suite.
Nov 21 09:08:57.794: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:08:57.834: INFO: namespace deployment-1070 deletion completed in 6.047501966s

â€¢ [SLOW TEST:15.179 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:08:57.834: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service endpoint-test2 in namespace services-7169
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7169 to expose endpoints map[]
Nov 21 09:08:57.923: INFO: Get endpoints failed (5.793159ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Nov 21 09:08:58.925: INFO: successfully validated that service endpoint-test2 in namespace services-7169 exposes endpoints map[] (1.007838798s elapsed)
STEP: Creating pod pod1 in namespace services-7169
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7169 to expose endpoints map[pod1:[80]]
Nov 21 09:09:00.988: INFO: successfully validated that service endpoint-test2 in namespace services-7169 exposes endpoints map[pod1:[80]] (2.059051655s elapsed)
STEP: Creating pod pod2 in namespace services-7169
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7169 to expose endpoints map[pod1:[80] pod2:[80]]
Nov 21 09:09:04.023: INFO: successfully validated that service endpoint-test2 in namespace services-7169 exposes endpoints map[pod1:[80] pod2:[80]] (3.033215373s elapsed)
STEP: Deleting pod pod1 in namespace services-7169
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7169 to expose endpoints map[pod2:[80]]
Nov 21 09:09:05.056: INFO: successfully validated that service endpoint-test2 in namespace services-7169 exposes endpoints map[pod2:[80]] (1.030788882s elapsed)
STEP: Deleting pod pod2 in namespace services-7169
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7169 to expose endpoints map[]
Nov 21 09:09:06.068: INFO: successfully validated that service endpoint-test2 in namespace services-7169 exposes endpoints map[] (1.009411227s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:09:06.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7169" for this suite.
Nov 21 09:09:12.120: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:09:12.160: INFO: namespace services-7169 deletion completed in 6.054818699s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

â€¢ [SLOW TEST:14.327 seconds]
[sig-network] Services
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:09:12.161: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1108
STEP: creating the pod
Nov 21 09:09:12.221: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 create -f - --namespace=kubectl-6448'
Nov 21 09:09:13.094: INFO: stderr: ""
Nov 21 09:09:13.094: INFO: stdout: "pod/pause created\n"
Nov 21 09:09:13.094: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Nov 21 09:09:13.094: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-6448" to be "running and ready"
Nov 21 09:09:13.101: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 7.516776ms
Nov 21 09:09:15.104: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009670118s
Nov 21 09:09:17.106: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.012011844s
Nov 21 09:09:17.106: INFO: Pod "pause" satisfied condition "running and ready"
Nov 21 09:09:17.106: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: adding the label testing-label with value testing-label-value to a pod
Nov 21 09:09:17.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 label pods pause testing-label=testing-label-value --namespace=kubectl-6448'
Nov 21 09:09:17.178: INFO: stderr: ""
Nov 21 09:09:17.178: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Nov 21 09:09:17.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pod pause -L testing-label --namespace=kubectl-6448'
Nov 21 09:09:17.271: INFO: stderr: ""
Nov 21 09:09:17.271: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Nov 21 09:09:17.271: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 label pods pause testing-label- --namespace=kubectl-6448'
Nov 21 09:09:17.341: INFO: stderr: ""
Nov 21 09:09:17.341: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Nov 21 09:09:17.341: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pod pause -L testing-label --namespace=kubectl-6448'
Nov 21 09:09:17.409: INFO: stderr: ""
Nov 21 09:09:17.409: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1115
STEP: using delete to clean up resources
Nov 21 09:09:17.409: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 delete --grace-period=0 --force -f - --namespace=kubectl-6448'
Nov 21 09:09:17.520: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 21 09:09:17.520: INFO: stdout: "pod \"pause\" force deleted\n"
Nov 21 09:09:17.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get rc,svc -l name=pause --no-headers --namespace=kubectl-6448'
Nov 21 09:09:17.599: INFO: stderr: "No resources found.\n"
Nov 21 09:09:17.599: INFO: stdout: ""
Nov 21 09:09:17.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods -l name=pause --namespace=kubectl-6448 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov 21 09:09:17.677: INFO: stderr: ""
Nov 21 09:09:17.677: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:09:17.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6448" for this suite.
Nov 21 09:09:23.691: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:09:23.731: INFO: namespace kubectl-6448 deletion completed in 6.052404599s

â€¢ [SLOW TEST:11.571 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:09:23.731: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-9c50f48d-0c3e-11ea-a569-4e55f5a7674f
STEP: Creating secret with name s-test-opt-upd-9c50f4cc-0c3e-11ea-a569-4e55f5a7674f
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-9c50f48d-0c3e-11ea-a569-4e55f5a7674f
STEP: Updating secret s-test-opt-upd-9c50f4cc-0c3e-11ea-a569-4e55f5a7674f
STEP: Creating secret with name s-test-opt-create-9c50f4e8-0c3e-11ea-a569-4e55f5a7674f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:10:46.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4384" for this suite.
Nov 21 09:11:08.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:11:08.229: INFO: namespace projected-4384 deletion completed in 22.047257221s

â€¢ [SLOW TEST:104.498 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:11:08.229: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Nov 21 09:11:08.315: INFO: Waiting up to 5m0s for pod "downwardapi-volume-da9245d3-0c3e-11ea-a569-4e55f5a7674f" in namespace "downward-api-8146" to be "success or failure"
Nov 21 09:11:08.319: INFO: Pod "downwardapi-volume-da9245d3-0c3e-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.466585ms
Nov 21 09:11:10.322: INFO: Pod "downwardapi-volume-da9245d3-0c3e-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006802992s
Nov 21 09:11:12.324: INFO: Pod "downwardapi-volume-da9245d3-0c3e-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009405486s
STEP: Saw pod success
Nov 21 09:11:12.324: INFO: Pod "downwardapi-volume-da9245d3-0c3e-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 09:11:12.326: INFO: Trying to get logs from node 192.168.0.92 pod downwardapi-volume-da9245d3-0c3e-11ea-a569-4e55f5a7674f container client-container: <nil>
STEP: delete the pod
Nov 21 09:11:12.357: INFO: Waiting for pod downwardapi-volume-da9245d3-0c3e-11ea-a569-4e55f5a7674f to disappear
Nov 21 09:11:12.365: INFO: Pod downwardapi-volume-da9245d3-0c3e-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:11:12.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8146" for this suite.
Nov 21 09:11:18.373: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:11:18.434: INFO: namespace downward-api-8146 deletion completed in 6.066806045s

â€¢ [SLOW TEST:10.205 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:11:18.434: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-projected-all-test-volume-e0aa71eb-0c3e-11ea-a569-4e55f5a7674f
STEP: Creating secret with name secret-projected-all-test-volume-e0aa71d8-0c3e-11ea-a569-4e55f5a7674f
STEP: Creating a pod to test Check all projections for projected volume plugin
Nov 21 09:11:18.521: INFO: Waiting up to 5m0s for pod "projected-volume-e0aa71ab-0c3e-11ea-a569-4e55f5a7674f" in namespace "projected-5129" to be "success or failure"
Nov 21 09:11:18.539: INFO: Pod "projected-volume-e0aa71ab-0c3e-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 17.891361ms
Nov 21 09:11:20.541: INFO: Pod "projected-volume-e0aa71ab-0c3e-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019803173s
Nov 21 09:11:22.543: INFO: Pod "projected-volume-e0aa71ab-0c3e-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022263614s
STEP: Saw pod success
Nov 21 09:11:22.543: INFO: Pod "projected-volume-e0aa71ab-0c3e-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 09:11:22.545: INFO: Trying to get logs from node 192.168.0.93 pod projected-volume-e0aa71ab-0c3e-11ea-a569-4e55f5a7674f container projected-all-volume-test: <nil>
STEP: delete the pod
Nov 21 09:11:22.561: INFO: Waiting for pod projected-volume-e0aa71ab-0c3e-11ea-a569-4e55f5a7674f to disappear
Nov 21 09:11:22.565: INFO: Pod projected-volume-e0aa71ab-0c3e-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:11:22.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5129" for this suite.
Nov 21 09:11:28.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:11:28.651: INFO: namespace projected-5129 deletion completed in 6.064580115s

â€¢ [SLOW TEST:10.216 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:11:28.651: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1190
STEP: creating an rc
Nov 21 09:11:28.703: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 create -f - --namespace=kubectl-1555'
Nov 21 09:11:28.904: INFO: stderr: ""
Nov 21 09:11:28.904: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Waiting for Redis master to start.
Nov 21 09:11:29.907: INFO: Selector matched 1 pods for map[app:redis]
Nov 21 09:11:29.907: INFO: Found 0 / 1
Nov 21 09:11:30.906: INFO: Selector matched 1 pods for map[app:redis]
Nov 21 09:11:30.906: INFO: Found 0 / 1
Nov 21 09:11:31.906: INFO: Selector matched 1 pods for map[app:redis]
Nov 21 09:11:31.906: INFO: Found 1 / 1
Nov 21 09:11:31.906: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov 21 09:11:31.908: INFO: Selector matched 1 pods for map[app:redis]
Nov 21 09:11:31.908: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Nov 21 09:11:31.908: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 logs redis-master-dqd2m redis-master --namespace=kubectl-1555'
Nov 21 09:11:31.987: INFO: stderr: ""
Nov 21 09:11:31.987: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 21 Nov 09:11:30.495 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 21 Nov 09:11:30.495 # Server started, Redis version 3.2.12\n1:M 21 Nov 09:11:30.495 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Nov 21 09:11:31.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 log redis-master-dqd2m redis-master --namespace=kubectl-1555 --tail=1'
Nov 21 09:11:32.062: INFO: stderr: ""
Nov 21 09:11:32.062: INFO: stdout: "1:M 21 Nov 09:11:30.495 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Nov 21 09:11:32.062: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 log redis-master-dqd2m redis-master --namespace=kubectl-1555 --limit-bytes=1'
Nov 21 09:11:32.138: INFO: stderr: ""
Nov 21 09:11:32.138: INFO: stdout: " "
STEP: exposing timestamps
Nov 21 09:11:32.138: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 log redis-master-dqd2m redis-master --namespace=kubectl-1555 --tail=1 --timestamps'
Nov 21 09:11:32.216: INFO: stderr: ""
Nov 21 09:11:32.216: INFO: stdout: "2019-11-21T09:11:30.495754423Z 1:M 21 Nov 09:11:30.495 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Nov 21 09:11:34.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 log redis-master-dqd2m redis-master --namespace=kubectl-1555 --since=1s'
Nov 21 09:11:34.792: INFO: stderr: ""
Nov 21 09:11:34.792: INFO: stdout: ""
Nov 21 09:11:34.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 log redis-master-dqd2m redis-master --namespace=kubectl-1555 --since=24h'
Nov 21 09:11:34.879: INFO: stderr: ""
Nov 21 09:11:34.879: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 21 Nov 09:11:30.495 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 21 Nov 09:11:30.495 # Server started, Redis version 3.2.12\n1:M 21 Nov 09:11:30.495 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1196
STEP: using delete to clean up resources
Nov 21 09:11:34.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 delete --grace-period=0 --force -f - --namespace=kubectl-1555'
Nov 21 09:11:34.968: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 21 09:11:34.968: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Nov 21 09:11:34.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get rc,svc -l name=nginx --no-headers --namespace=kubectl-1555'
Nov 21 09:11:35.046: INFO: stderr: "No resources found.\n"
Nov 21 09:11:35.046: INFO: stdout: ""
Nov 21 09:11:35.046: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods -l name=nginx --namespace=kubectl-1555 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov 21 09:11:35.115: INFO: stderr: ""
Nov 21 09:11:35.116: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:11:35.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1555" for this suite.
Nov 21 09:11:41.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:11:41.168: INFO: namespace kubectl-1555 deletion completed in 6.049916738s

â€¢ [SLOW TEST:12.517 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:11:41.168: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Nov 21 09:11:41.244: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 create -f - --namespace=kubectl-1826'
Nov 21 09:11:41.445: INFO: stderr: ""
Nov 21 09:11:41.445: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov 21 09:11:41.445: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1826'
Nov 21 09:11:41.519: INFO: stderr: ""
Nov 21 09:11:41.519: INFO: stdout: "update-demo-nautilus-ppd4b update-demo-nautilus-s7fkr "
Nov 21 09:11:41.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods update-demo-nautilus-ppd4b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1826'
Nov 21 09:11:41.586: INFO: stderr: ""
Nov 21 09:11:41.586: INFO: stdout: ""
Nov 21 09:11:41.586: INFO: update-demo-nautilus-ppd4b is created but not running
Nov 21 09:11:46.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1826'
Nov 21 09:11:46.658: INFO: stderr: ""
Nov 21 09:11:46.658: INFO: stdout: "update-demo-nautilus-ppd4b update-demo-nautilus-s7fkr "
Nov 21 09:11:46.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods update-demo-nautilus-ppd4b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1826'
Nov 21 09:11:46.729: INFO: stderr: ""
Nov 21 09:11:46.729: INFO: stdout: "true"
Nov 21 09:11:46.729: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods update-demo-nautilus-ppd4b -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1826'
Nov 21 09:11:46.796: INFO: stderr: ""
Nov 21 09:11:46.796: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 21 09:11:46.796: INFO: validating pod update-demo-nautilus-ppd4b
Nov 21 09:11:46.805: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 21 09:11:46.805: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 21 09:11:46.805: INFO: update-demo-nautilus-ppd4b is verified up and running
Nov 21 09:11:46.805: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods update-demo-nautilus-s7fkr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1826'
Nov 21 09:11:46.873: INFO: stderr: ""
Nov 21 09:11:46.873: INFO: stdout: "true"
Nov 21 09:11:46.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods update-demo-nautilus-s7fkr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1826'
Nov 21 09:11:46.942: INFO: stderr: ""
Nov 21 09:11:46.942: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 21 09:11:46.942: INFO: validating pod update-demo-nautilus-s7fkr
Nov 21 09:11:46.950: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 21 09:11:46.950: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 21 09:11:46.950: INFO: update-demo-nautilus-s7fkr is verified up and running
STEP: scaling down the replication controller
Nov 21 09:11:46.952: INFO: scanned /root for discovery docs: <nil>
Nov 21 09:11:46.952: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-1826'
Nov 21 09:11:48.045: INFO: stderr: ""
Nov 21 09:11:48.045: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov 21 09:11:48.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1826'
Nov 21 09:11:48.134: INFO: stderr: ""
Nov 21 09:11:48.134: INFO: stdout: "update-demo-nautilus-ppd4b update-demo-nautilus-s7fkr "
STEP: Replicas for name=update-demo: expected=1 actual=2
Nov 21 09:11:53.134: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1826'
Nov 21 09:11:53.203: INFO: stderr: ""
Nov 21 09:11:53.203: INFO: stdout: "update-demo-nautilus-ppd4b update-demo-nautilus-s7fkr "
STEP: Replicas for name=update-demo: expected=1 actual=2
Nov 21 09:11:58.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1826'
Nov 21 09:11:58.274: INFO: stderr: ""
Nov 21 09:11:58.274: INFO: stdout: "update-demo-nautilus-ppd4b update-demo-nautilus-s7fkr "
STEP: Replicas for name=update-demo: expected=1 actual=2
Nov 21 09:12:03.274: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1826'
Nov 21 09:12:03.346: INFO: stderr: ""
Nov 21 09:12:03.346: INFO: stdout: "update-demo-nautilus-s7fkr "
Nov 21 09:12:03.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods update-demo-nautilus-s7fkr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1826'
Nov 21 09:12:03.414: INFO: stderr: ""
Nov 21 09:12:03.414: INFO: stdout: "true"
Nov 21 09:12:03.414: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods update-demo-nautilus-s7fkr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1826'
Nov 21 09:12:03.480: INFO: stderr: ""
Nov 21 09:12:03.480: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 21 09:12:03.480: INFO: validating pod update-demo-nautilus-s7fkr
Nov 21 09:12:03.483: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 21 09:12:03.483: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 21 09:12:03.483: INFO: update-demo-nautilus-s7fkr is verified up and running
STEP: scaling up the replication controller
Nov 21 09:12:03.484: INFO: scanned /root for discovery docs: <nil>
Nov 21 09:12:03.484: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-1826'
Nov 21 09:12:04.571: INFO: stderr: ""
Nov 21 09:12:04.571: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov 21 09:12:04.571: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1826'
Nov 21 09:12:04.645: INFO: stderr: ""
Nov 21 09:12:04.645: INFO: stdout: "update-demo-nautilus-f2jjz update-demo-nautilus-s7fkr "
Nov 21 09:12:04.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods update-demo-nautilus-f2jjz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1826'
Nov 21 09:12:04.713: INFO: stderr: ""
Nov 21 09:12:04.713: INFO: stdout: ""
Nov 21 09:12:04.713: INFO: update-demo-nautilus-f2jjz is created but not running
Nov 21 09:12:09.713: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1826'
Nov 21 09:12:09.784: INFO: stderr: ""
Nov 21 09:12:09.784: INFO: stdout: "update-demo-nautilus-f2jjz update-demo-nautilus-s7fkr "
Nov 21 09:12:09.784: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods update-demo-nautilus-f2jjz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1826'
Nov 21 09:12:09.850: INFO: stderr: ""
Nov 21 09:12:09.850: INFO: stdout: "true"
Nov 21 09:12:09.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods update-demo-nautilus-f2jjz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1826'
Nov 21 09:12:09.917: INFO: stderr: ""
Nov 21 09:12:09.917: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 21 09:12:09.917: INFO: validating pod update-demo-nautilus-f2jjz
Nov 21 09:12:09.919: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 21 09:12:09.919: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 21 09:12:09.919: INFO: update-demo-nautilus-f2jjz is verified up and running
Nov 21 09:12:09.919: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods update-demo-nautilus-s7fkr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1826'
Nov 21 09:12:09.987: INFO: stderr: ""
Nov 21 09:12:09.987: INFO: stdout: "true"
Nov 21 09:12:09.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods update-demo-nautilus-s7fkr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1826'
Nov 21 09:12:10.054: INFO: stderr: ""
Nov 21 09:12:10.054: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 21 09:12:10.054: INFO: validating pod update-demo-nautilus-s7fkr
Nov 21 09:12:10.058: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 21 09:12:10.058: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 21 09:12:10.058: INFO: update-demo-nautilus-s7fkr is verified up and running
STEP: using delete to clean up resources
Nov 21 09:12:10.058: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 delete --grace-period=0 --force -f - --namespace=kubectl-1826'
Nov 21 09:12:10.128: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 21 09:12:10.128: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Nov 21 09:12:10.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-1826'
Nov 21 09:12:10.197: INFO: stderr: "No resources found.\n"
Nov 21 09:12:10.197: INFO: stdout: ""
Nov 21 09:12:10.197: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods -l name=update-demo --namespace=kubectl-1826 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov 21 09:12:10.267: INFO: stderr: ""
Nov 21 09:12:10.267: INFO: stdout: "update-demo-nautilus-f2jjz\nupdate-demo-nautilus-s7fkr\n"
Nov 21 09:12:10.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-1826'
Nov 21 09:12:10.844: INFO: stderr: "No resources found.\n"
Nov 21 09:12:10.844: INFO: stdout: ""
Nov 21 09:12:10.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods -l name=update-demo --namespace=kubectl-1826 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov 21 09:12:10.917: INFO: stderr: ""
Nov 21 09:12:10.917: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:12:10.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1826" for this suite.
Nov 21 09:12:16.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:12:16.994: INFO: namespace kubectl-1826 deletion completed in 6.074117116s

â€¢ [SLOW TEST:35.826 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:12:16.995: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-03971d0b-0c3f-11ea-a569-4e55f5a7674f
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:12:21.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2603" for this suite.
Nov 21 09:12:43.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:12:43.174: INFO: namespace configmap-2603 deletion completed in 22.046513356s

â€¢ [SLOW TEST:26.180 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:12:43.174: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Nov 21 09:12:43.233: INFO: (0) /api/v1/nodes/192.168.0.92/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 3.204604ms)
Nov 21 09:12:43.251: INFO: (1) /api/v1/nodes/192.168.0.92/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 17.517949ms)
Nov 21 09:12:43.253: INFO: (2) /api/v1/nodes/192.168.0.92/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.791944ms)
Nov 21 09:12:43.254: INFO: (3) /api/v1/nodes/192.168.0.92/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.626716ms)
Nov 21 09:12:43.256: INFO: (4) /api/v1/nodes/192.168.0.92/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.703242ms)
Nov 21 09:12:43.258: INFO: (5) /api/v1/nodes/192.168.0.92/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.709878ms)
Nov 21 09:12:43.259: INFO: (6) /api/v1/nodes/192.168.0.92/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.520796ms)
Nov 21 09:12:43.261: INFO: (7) /api/v1/nodes/192.168.0.92/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.556776ms)
Nov 21 09:12:43.263: INFO: (8) /api/v1/nodes/192.168.0.92/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.56008ms)
Nov 21 09:12:43.264: INFO: (9) /api/v1/nodes/192.168.0.92/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.485421ms)
Nov 21 09:12:43.266: INFO: (10) /api/v1/nodes/192.168.0.92/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.526187ms)
Nov 21 09:12:43.267: INFO: (11) /api/v1/nodes/192.168.0.92/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.601335ms)
Nov 21 09:12:43.269: INFO: (12) /api/v1/nodes/192.168.0.92/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.831167ms)
Nov 21 09:12:43.271: INFO: (13) /api/v1/nodes/192.168.0.92/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.672838ms)
Nov 21 09:12:43.272: INFO: (14) /api/v1/nodes/192.168.0.92/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.576489ms)
Nov 21 09:12:43.274: INFO: (15) /api/v1/nodes/192.168.0.92/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.604305ms)
Nov 21 09:12:43.275: INFO: (16) /api/v1/nodes/192.168.0.92/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.56302ms)
Nov 21 09:12:43.277: INFO: (17) /api/v1/nodes/192.168.0.92/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.55982ms)
Nov 21 09:12:43.279: INFO: (18) /api/v1/nodes/192.168.0.92/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.591218ms)
Nov 21 09:12:43.280: INFO: (19) /api/v1/nodes/192.168.0.92/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.620919ms)
[AfterEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:12:43.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2535" for this suite.
Nov 21 09:12:49.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:12:49.334: INFO: namespace proxy-2535 deletion completed in 6.051477844s

â€¢ [SLOW TEST:6.159 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:12:49.334: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Nov 21 09:12:49.393: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:12:53.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7538" for this suite.
Nov 21 09:13:15.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:13:15.918: INFO: namespace init-container-7538 deletion completed in 22.061170913s

â€¢ [SLOW TEST:26.584 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:13:15.918: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1414
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov 21 09:13:15.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-129'
Nov 21 09:13:16.039: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov 21 09:13:16.039: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Nov 21 09:13:16.042: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Nov 21 09:13:16.048: INFO: scanned /root for discovery docs: <nil>
Nov 21 09:13:16.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-129'
Nov 21 09:13:31.827: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Nov 21 09:13:31.828: INFO: stdout: "Created e2e-test-nginx-rc-4d8e8f06cbb9cd06b7d7f47f0a692d07\nScaling up e2e-test-nginx-rc-4d8e8f06cbb9cd06b7d7f47f0a692d07 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-4d8e8f06cbb9cd06b7d7f47f0a692d07 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-4d8e8f06cbb9cd06b7d7f47f0a692d07 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Nov 21 09:13:31.828: INFO: stdout: "Created e2e-test-nginx-rc-4d8e8f06cbb9cd06b7d7f47f0a692d07\nScaling up e2e-test-nginx-rc-4d8e8f06cbb9cd06b7d7f47f0a692d07 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-4d8e8f06cbb9cd06b7d7f47f0a692d07 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-4d8e8f06cbb9cd06b7d7f47f0a692d07 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Nov 21 09:13:31.828: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-129'
Nov 21 09:13:31.918: INFO: stderr: ""
Nov 21 09:13:31.918: INFO: stdout: "e2e-test-nginx-rc-4d8e8f06cbb9cd06b7d7f47f0a692d07-fhh7n "
Nov 21 09:13:31.918: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods e2e-test-nginx-rc-4d8e8f06cbb9cd06b7d7f47f0a692d07-fhh7n -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-129'
Nov 21 09:13:31.987: INFO: stderr: ""
Nov 21 09:13:31.987: INFO: stdout: "true"
Nov 21 09:13:31.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pods e2e-test-nginx-rc-4d8e8f06cbb9cd06b7d7f47f0a692d07-fhh7n -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-129'
Nov 21 09:13:32.060: INFO: stderr: ""
Nov 21 09:13:32.060: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Nov 21 09:13:32.060: INFO: e2e-test-nginx-rc-4d8e8f06cbb9cd06b7d7f47f0a692d07-fhh7n is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1420
Nov 21 09:13:32.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 delete rc e2e-test-nginx-rc --namespace=kubectl-129'
Nov 21 09:13:32.135: INFO: stderr: ""
Nov 21 09:13:32.135: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:13:32.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-129" for this suite.
Nov 21 09:13:54.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:13:54.205: INFO: namespace kubectl-129 deletion completed in 22.056501131s

â€¢ [SLOW TEST:38.286 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:13:54.205: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Nov 21 09:13:54.272: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3d830217-0c3f-11ea-a569-4e55f5a7674f" in namespace "projected-574" to be "success or failure"
Nov 21 09:13:54.276: INFO: Pod "downwardapi-volume-3d830217-0c3f-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.476515ms
Nov 21 09:13:56.279: INFO: Pod "downwardapi-volume-3d830217-0c3f-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006697666s
Nov 21 09:13:58.281: INFO: Pod "downwardapi-volume-3d830217-0c3f-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008864775s
STEP: Saw pod success
Nov 21 09:13:58.281: INFO: Pod "downwardapi-volume-3d830217-0c3f-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 09:13:58.282: INFO: Trying to get logs from node 192.168.0.92 pod downwardapi-volume-3d830217-0c3f-11ea-a569-4e55f5a7674f container client-container: <nil>
STEP: delete the pod
Nov 21 09:13:58.294: INFO: Waiting for pod downwardapi-volume-3d830217-0c3f-11ea-a569-4e55f5a7674f to disappear
Nov 21 09:13:58.299: INFO: Pod downwardapi-volume-3d830217-0c3f-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:13:58.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-574" for this suite.
Nov 21 09:14:04.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:14:04.360: INFO: namespace projected-574 deletion completed in 6.059063797s

â€¢ [SLOW TEST:10.155 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:14:04.360: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-4392fd08-0c3f-11ea-a569-4e55f5a7674f
STEP: Creating a pod to test consume configMaps
Nov 21 09:14:04.477: INFO: Waiting up to 5m0s for pod "pod-configmaps-43982a12-0c3f-11ea-a569-4e55f5a7674f" in namespace "configmap-9148" to be "success or failure"
Nov 21 09:14:04.482: INFO: Pod "pod-configmaps-43982a12-0c3f-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.433103ms
Nov 21 09:14:06.484: INFO: Pod "pod-configmaps-43982a12-0c3f-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007706784s
Nov 21 09:14:08.487: INFO: Pod "pod-configmaps-43982a12-0c3f-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010042477s
STEP: Saw pod success
Nov 21 09:14:08.487: INFO: Pod "pod-configmaps-43982a12-0c3f-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 09:14:08.488: INFO: Trying to get logs from node 192.168.0.93 pod pod-configmaps-43982a12-0c3f-11ea-a569-4e55f5a7674f container configmap-volume-test: <nil>
STEP: delete the pod
Nov 21 09:14:08.506: INFO: Waiting for pod pod-configmaps-43982a12-0c3f-11ea-a569-4e55f5a7674f to disappear
Nov 21 09:14:08.511: INFO: Pod pod-configmaps-43982a12-0c3f-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:14:08.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9148" for this suite.
Nov 21 09:14:14.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:14:14.558: INFO: namespace configmap-9148 deletion completed in 6.045166579s

â€¢ [SLOW TEST:10.198 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:14:14.558: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Nov 21 09:14:14.665: INFO: Number of nodes with available pods: 0
Nov 21 09:14:14.665: INFO: Node 192.168.0.92 is running more than one daemon pod
Nov 21 09:14:15.672: INFO: Number of nodes with available pods: 0
Nov 21 09:14:15.672: INFO: Node 192.168.0.92 is running more than one daemon pod
Nov 21 09:14:16.669: INFO: Number of nodes with available pods: 0
Nov 21 09:14:16.669: INFO: Node 192.168.0.92 is running more than one daemon pod
Nov 21 09:14:17.670: INFO: Number of nodes with available pods: 1
Nov 21 09:14:17.670: INFO: Node 192.168.0.93 is running more than one daemon pod
Nov 21 09:14:18.669: INFO: Number of nodes with available pods: 1
Nov 21 09:14:18.669: INFO: Node 192.168.0.93 is running more than one daemon pod
Nov 21 09:14:19.669: INFO: Number of nodes with available pods: 1
Nov 21 09:14:19.669: INFO: Node 192.168.0.93 is running more than one daemon pod
Nov 21 09:14:20.682: INFO: Number of nodes with available pods: 1
Nov 21 09:14:20.682: INFO: Node 192.168.0.93 is running more than one daemon pod
Nov 21 09:14:21.669: INFO: Number of nodes with available pods: 1
Nov 21 09:14:21.669: INFO: Node 192.168.0.93 is running more than one daemon pod
Nov 21 09:14:22.669: INFO: Number of nodes with available pods: 1
Nov 21 09:14:22.669: INFO: Node 192.168.0.93 is running more than one daemon pod
Nov 21 09:14:23.670: INFO: Number of nodes with available pods: 1
Nov 21 09:14:23.670: INFO: Node 192.168.0.93 is running more than one daemon pod
Nov 21 09:14:24.669: INFO: Number of nodes with available pods: 1
Nov 21 09:14:24.669: INFO: Node 192.168.0.93 is running more than one daemon pod
Nov 21 09:14:25.669: INFO: Number of nodes with available pods: 1
Nov 21 09:14:25.669: INFO: Node 192.168.0.93 is running more than one daemon pod
Nov 21 09:14:26.669: INFO: Number of nodes with available pods: 1
Nov 21 09:14:26.669: INFO: Node 192.168.0.93 is running more than one daemon pod
Nov 21 09:14:27.670: INFO: Number of nodes with available pods: 1
Nov 21 09:14:27.670: INFO: Node 192.168.0.93 is running more than one daemon pod
Nov 21 09:14:28.671: INFO: Number of nodes with available pods: 1
Nov 21 09:14:28.671: INFO: Node 192.168.0.93 is running more than one daemon pod
Nov 21 09:14:29.669: INFO: Number of nodes with available pods: 1
Nov 21 09:14:29.669: INFO: Node 192.168.0.93 is running more than one daemon pod
Nov 21 09:14:30.669: INFO: Number of nodes with available pods: 1
Nov 21 09:14:30.669: INFO: Node 192.168.0.93 is running more than one daemon pod
Nov 21 09:14:31.669: INFO: Number of nodes with available pods: 1
Nov 21 09:14:31.669: INFO: Node 192.168.0.93 is running more than one daemon pod
Nov 21 09:14:32.674: INFO: Number of nodes with available pods: 1
Nov 21 09:14:32.674: INFO: Node 192.168.0.93 is running more than one daemon pod
Nov 21 09:14:33.670: INFO: Number of nodes with available pods: 1
Nov 21 09:14:33.670: INFO: Node 192.168.0.93 is running more than one daemon pod
Nov 21 09:14:34.669: INFO: Number of nodes with available pods: 1
Nov 21 09:14:34.669: INFO: Node 192.168.0.93 is running more than one daemon pod
Nov 21 09:14:35.669: INFO: Number of nodes with available pods: 2
Nov 21 09:14:35.669: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Nov 21 09:14:35.700: INFO: Number of nodes with available pods: 2
Nov 21 09:14:35.700: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9639, will wait for the garbage collector to delete the pods
Nov 21 09:14:36.803: INFO: Deleting DaemonSet.extensions daemon-set took: 2.713295ms
Nov 21 09:14:37.103: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.165098ms
Nov 21 09:14:50.705: INFO: Number of nodes with available pods: 0
Nov 21 09:14:50.705: INFO: Number of running nodes: 0, number of available pods: 0
Nov 21 09:14:50.706: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9639/daemonsets","resourceVersion":"20919"},"items":null}

Nov 21 09:14:50.707: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9639/pods","resourceVersion":"20919"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:14:50.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9639" for this suite.
Nov 21 09:14:56.725: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:14:56.774: INFO: namespace daemonsets-9639 deletion completed in 6.057693931s

â€¢ [SLOW TEST:42.217 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:14:56.775: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-1095
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Nov 21 09:14:56.877: INFO: Found 0 stateful pods, waiting for 3
Nov 21 09:15:06.880: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 21 09:15:06.880: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 21 09:15:06.880: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Nov 21 09:15:06.899: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Nov 21 09:15:16.930: INFO: Updating stateful set ss2
Nov 21 09:15:16.956: INFO: Waiting for Pod statefulset-1095/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Nov 21 09:15:27.058: INFO: Found 2 stateful pods, waiting for 3
Nov 21 09:15:37.061: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 21 09:15:37.061: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 21 09:15:37.061: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Nov 21 09:15:37.078: INFO: Updating stateful set ss2
Nov 21 09:15:37.139: INFO: Waiting for Pod statefulset-1095/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Nov 21 09:15:47.156: INFO: Updating stateful set ss2
Nov 21 09:15:47.170: INFO: Waiting for StatefulSet statefulset-1095/ss2 to complete update
Nov 21 09:15:47.170: INFO: Waiting for Pod statefulset-1095/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Nov 21 09:15:57.174: INFO: Waiting for StatefulSet statefulset-1095/ss2 to complete update
Nov 21 09:15:57.175: INFO: Waiting for Pod statefulset-1095/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Nov 21 09:16:07.175: INFO: Deleting all statefulset in ns statefulset-1095
Nov 21 09:16:07.176: INFO: Scaling statefulset ss2 to 0
Nov 21 09:16:27.201: INFO: Waiting for statefulset status.replicas updated to 0
Nov 21 09:16:27.203: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:16:27.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1095" for this suite.
Nov 21 09:16:33.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:16:33.313: INFO: namespace statefulset-1095 deletion completed in 6.081914029s

â€¢ [SLOW TEST:96.539 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:16:33.314: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:16:35.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-6417" for this suite.
Nov 21 09:16:41.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:16:41.521: INFO: namespace emptydir-wrapper-6417 deletion completed in 6.046390609s

â€¢ [SLOW TEST:8.207 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:16:41.521: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Nov 21 09:16:41.591: INFO: Waiting up to 5m0s for pod "pod-a13df7a2-0c3f-11ea-a569-4e55f5a7674f" in namespace "emptydir-2620" to be "success or failure"
Nov 21 09:16:41.609: INFO: Pod "pod-a13df7a2-0c3f-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 17.20993ms
Nov 21 09:16:43.611: INFO: Pod "pod-a13df7a2-0c3f-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019205583s
Nov 21 09:16:45.613: INFO: Pod "pod-a13df7a2-0c3f-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021283487s
STEP: Saw pod success
Nov 21 09:16:45.613: INFO: Pod "pod-a13df7a2-0c3f-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 09:16:45.614: INFO: Trying to get logs from node 192.168.0.93 pod pod-a13df7a2-0c3f-11ea-a569-4e55f5a7674f container test-container: <nil>
STEP: delete the pod
Nov 21 09:16:45.641: INFO: Waiting for pod pod-a13df7a2-0c3f-11ea-a569-4e55f5a7674f to disappear
Nov 21 09:16:45.645: INFO: Pod pod-a13df7a2-0c3f-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:16:45.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2620" for this suite.
Nov 21 09:16:51.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:16:51.691: INFO: namespace emptydir-2620 deletion completed in 6.044359947s

â€¢ [SLOW TEST:10.170 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:16:51.691: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Nov 21 09:16:51.755: INFO: Waiting up to 5m0s for pod "pod-a74c5e23-0c3f-11ea-a569-4e55f5a7674f" in namespace "emptydir-9040" to be "success or failure"
Nov 21 09:16:51.770: INFO: Pod "pod-a74c5e23-0c3f-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.921638ms
Nov 21 09:16:53.772: INFO: Pod "pod-a74c5e23-0c3f-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016747622s
Nov 21 09:16:55.774: INFO: Pod "pod-a74c5e23-0c3f-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019007145s
STEP: Saw pod success
Nov 21 09:16:55.774: INFO: Pod "pod-a74c5e23-0c3f-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 09:16:55.775: INFO: Trying to get logs from node 192.168.0.92 pod pod-a74c5e23-0c3f-11ea-a569-4e55f5a7674f container test-container: <nil>
STEP: delete the pod
Nov 21 09:16:55.818: INFO: Waiting for pod pod-a74c5e23-0c3f-11ea-a569-4e55f5a7674f to disappear
Nov 21 09:16:55.822: INFO: Pod pod-a74c5e23-0c3f-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:16:55.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9040" for this suite.
Nov 21 09:17:01.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:17:01.869: INFO: namespace emptydir-9040 deletion completed in 6.044525097s

â€¢ [SLOW TEST:10.178 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:17:01.869: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-8780/configmap-test-ad5fa04b-0c3f-11ea-a569-4e55f5a7674f
STEP: Creating a pod to test consume configMaps
Nov 21 09:17:01.955: INFO: Waiting up to 5m0s for pod "pod-configmaps-ad60abe2-0c3f-11ea-a569-4e55f5a7674f" in namespace "configmap-8780" to be "success or failure"
Nov 21 09:17:01.960: INFO: Pod "pod-configmaps-ad60abe2-0c3f-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.789364ms
Nov 21 09:17:03.962: INFO: Pod "pod-configmaps-ad60abe2-0c3f-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007218749s
Nov 21 09:17:05.964: INFO: Pod "pod-configmaps-ad60abe2-0c3f-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009064999s
STEP: Saw pod success
Nov 21 09:17:05.964: INFO: Pod "pod-configmaps-ad60abe2-0c3f-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 09:17:05.966: INFO: Trying to get logs from node 192.168.0.93 pod pod-configmaps-ad60abe2-0c3f-11ea-a569-4e55f5a7674f container env-test: <nil>
STEP: delete the pod
Nov 21 09:17:05.988: INFO: Waiting for pod pod-configmaps-ad60abe2-0c3f-11ea-a569-4e55f5a7674f to disappear
Nov 21 09:17:05.994: INFO: Pod pod-configmaps-ad60abe2-0c3f-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:17:05.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8780" for this suite.
Nov 21 09:17:12.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:17:12.041: INFO: namespace configmap-8780 deletion completed in 6.045088322s

â€¢ [SLOW TEST:10.172 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:17:12.041: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1583
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov 21 09:17:12.086: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-4478'
Nov 21 09:17:12.161: INFO: stderr: ""
Nov 21 09:17:12.161: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1588
Nov 21 09:17:12.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 delete pods e2e-test-nginx-pod --namespace=kubectl-4478'
Nov 21 09:17:20.626: INFO: stderr: ""
Nov 21 09:17:20.626: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:17:20.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4478" for this suite.
Nov 21 09:17:26.648: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:17:26.687: INFO: namespace kubectl-4478 deletion completed in 6.057696729s

â€¢ [SLOW TEST:14.646 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:17:26.687: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-8218
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov 21 09:17:26.762: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov 21 09:17:50.814: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.49.166.176:8080/dial?request=hostName&protocol=udp&host=172.49.135.183&port=8081&tries=1'] Namespace:pod-network-test-8218 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 21 09:17:50.814: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
Nov 21 09:17:50.959: INFO: Waiting for endpoints: map[]
Nov 21 09:17:50.961: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.49.166.176:8080/dial?request=hostName&protocol=udp&host=172.49.166.175&port=8081&tries=1'] Namespace:pod-network-test-8218 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 21 09:17:50.961: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
Nov 21 09:17:51.099: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:17:51.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8218" for this suite.
Nov 21 09:18:05.110: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:18:05.148: INFO: namespace pod-network-test-8218 deletion completed in 14.046688457s

â€¢ [SLOW TEST:38.461 seconds]
[sig-network] Networking
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:18:05.149: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-5780
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov 21 09:18:05.206: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov 21 09:18:29.284: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.49.166.178:8080/dial?request=hostName&protocol=http&host=172.49.135.184&port=8080&tries=1'] Namespace:pod-network-test-5780 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 21 09:18:29.284: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
Nov 21 09:18:29.416: INFO: Waiting for endpoints: map[]
Nov 21 09:18:29.418: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.49.166.178:8080/dial?request=hostName&protocol=http&host=172.49.166.177&port=8080&tries=1'] Namespace:pod-network-test-5780 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 21 09:18:29.418: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
Nov 21 09:18:29.530: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:18:29.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5780" for this suite.
Nov 21 09:18:51.560: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:18:51.600: INFO: namespace pod-network-test-5780 deletion completed in 22.067265194s

â€¢ [SLOW TEST:46.451 seconds]
[sig-network] Networking
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:18:51.600: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Nov 21 09:18:51.660: INFO: Waiting up to 5m0s for pod "downwardapi-volume-eec4729b-0c3f-11ea-a569-4e55f5a7674f" in namespace "projected-5105" to be "success or failure"
Nov 21 09:18:51.664: INFO: Pod "downwardapi-volume-eec4729b-0c3f-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.310875ms
Nov 21 09:18:53.666: INFO: Pod "downwardapi-volume-eec4729b-0c3f-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006204103s
Nov 21 09:18:55.668: INFO: Pod "downwardapi-volume-eec4729b-0c3f-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008451579s
STEP: Saw pod success
Nov 21 09:18:55.668: INFO: Pod "downwardapi-volume-eec4729b-0c3f-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 09:18:55.670: INFO: Trying to get logs from node 192.168.0.93 pod downwardapi-volume-eec4729b-0c3f-11ea-a569-4e55f5a7674f container client-container: <nil>
STEP: delete the pod
Nov 21 09:18:55.694: INFO: Waiting for pod downwardapi-volume-eec4729b-0c3f-11ea-a569-4e55f5a7674f to disappear
Nov 21 09:18:55.698: INFO: Pod downwardapi-volume-eec4729b-0c3f-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:18:55.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5105" for this suite.
Nov 21 09:19:01.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:19:01.745: INFO: namespace projected-5105 deletion completed in 6.044621475s

â€¢ [SLOW TEST:10.145 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:19:01.746: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-f4d3dc82-0c3f-11ea-a569-4e55f5a7674f
STEP: Creating a pod to test consume configMaps
Nov 21 09:19:01.852: INFO: Waiting up to 5m0s for pod "pod-configmaps-f4d52cc7-0c3f-11ea-a569-4e55f5a7674f" in namespace "configmap-1272" to be "success or failure"
Nov 21 09:19:01.859: INFO: Pod "pod-configmaps-f4d52cc7-0c3f-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.629748ms
Nov 21 09:19:03.861: INFO: Pod "pod-configmaps-f4d52cc7-0c3f-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008402019s
STEP: Saw pod success
Nov 21 09:19:03.861: INFO: Pod "pod-configmaps-f4d52cc7-0c3f-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 09:19:03.862: INFO: Trying to get logs from node 192.168.0.92 pod pod-configmaps-f4d52cc7-0c3f-11ea-a569-4e55f5a7674f container configmap-volume-test: <nil>
STEP: delete the pod
Nov 21 09:19:03.888: INFO: Waiting for pod pod-configmaps-f4d52cc7-0c3f-11ea-a569-4e55f5a7674f to disappear
Nov 21 09:19:03.893: INFO: Pod pod-configmaps-f4d52cc7-0c3f-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:19:03.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1272" for this suite.
Nov 21 09:19:09.906: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:19:09.946: INFO: namespace configmap-1272 deletion completed in 6.046640722s

â€¢ [SLOW TEST:8.200 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:19:09.946: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-1045
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-1045
STEP: Creating statefulset with conflicting port in namespace statefulset-1045
STEP: Waiting until pod test-pod will start running in namespace statefulset-1045
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-1045
Nov 21 09:19:14.086: INFO: Observed stateful pod in namespace: statefulset-1045, name: ss-0, uid: fbc5717c-0c3f-11ea-b617-0202c0a8005b, status phase: Failed. Waiting for statefulset controller to delete.
Nov 21 09:19:14.113: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-1045
STEP: Removing pod with conflicting port in namespace statefulset-1045
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-1045 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Nov 21 09:19:18.184: INFO: Deleting all statefulset in ns statefulset-1045
Nov 21 09:19:18.185: INFO: Scaling statefulset ss to 0
Nov 21 09:19:28.213: INFO: Waiting for statefulset status.replicas updated to 0
Nov 21 09:19:28.215: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:19:28.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1045" for this suite.
Nov 21 09:19:34.255: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:19:34.295: INFO: namespace statefulset-1045 deletion completed in 6.06714279s

â€¢ [SLOW TEST:24.349 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:19:34.296: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Nov 21 09:19:34.351: INFO: Pod name pod-release: Found 0 pods out of 1
Nov 21 09:19:39.353: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:19:39.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2289" for this suite.
Nov 21 09:19:45.473: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:19:45.513: INFO: namespace replication-controller-2289 deletion completed in 6.049350112s

â€¢ [SLOW TEST:11.217 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:19:45.513: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-0ee5c75b-0c40-11ea-a569-4e55f5a7674f
STEP: Creating a pod to test consume configMaps
Nov 21 09:19:45.590: INFO: Waiting up to 5m0s for pod "pod-configmaps-0ee718a2-0c40-11ea-a569-4e55f5a7674f" in namespace "configmap-1574" to be "success or failure"
Nov 21 09:19:45.597: INFO: Pod "pod-configmaps-0ee718a2-0c40-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.486968ms
Nov 21 09:19:47.600: INFO: Pod "pod-configmaps-0ee718a2-0c40-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010096927s
Nov 21 09:19:49.603: INFO: Pod "pod-configmaps-0ee718a2-0c40-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013161663s
STEP: Saw pod success
Nov 21 09:19:49.603: INFO: Pod "pod-configmaps-0ee718a2-0c40-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 09:19:49.605: INFO: Trying to get logs from node 192.168.0.93 pod pod-configmaps-0ee718a2-0c40-11ea-a569-4e55f5a7674f container configmap-volume-test: <nil>
STEP: delete the pod
Nov 21 09:19:49.622: INFO: Waiting for pod pod-configmaps-0ee718a2-0c40-11ea-a569-4e55f5a7674f to disappear
Nov 21 09:19:49.626: INFO: Pod pod-configmaps-0ee718a2-0c40-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:19:49.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1574" for this suite.
Nov 21 09:19:55.633: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:19:55.681: INFO: namespace configmap-1574 deletion completed in 6.053371913s

â€¢ [SLOW TEST:10.168 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:19:55.681: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Nov 21 09:19:55.770: INFO: Waiting up to 5m0s for pod "downwardapi-volume-14fb2f56-0c40-11ea-a569-4e55f5a7674f" in namespace "downward-api-3769" to be "success or failure"
Nov 21 09:19:55.774: INFO: Pod "downwardapi-volume-14fb2f56-0c40-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.296121ms
Nov 21 09:19:57.776: INFO: Pod "downwardapi-volume-14fb2f56-0c40-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006419115s
Nov 21 09:19:59.803: INFO: Pod "downwardapi-volume-14fb2f56-0c40-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032722147s
STEP: Saw pod success
Nov 21 09:19:59.803: INFO: Pod "downwardapi-volume-14fb2f56-0c40-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 09:19:59.804: INFO: Trying to get logs from node 192.168.0.92 pod downwardapi-volume-14fb2f56-0c40-11ea-a569-4e55f5a7674f container client-container: <nil>
STEP: delete the pod
Nov 21 09:19:59.827: INFO: Waiting for pod downwardapi-volume-14fb2f56-0c40-11ea-a569-4e55f5a7674f to disappear
Nov 21 09:19:59.839: INFO: Pod downwardapi-volume-14fb2f56-0c40-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:19:59.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3769" for this suite.
Nov 21 09:20:05.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:20:05.930: INFO: namespace downward-api-3769 deletion completed in 6.089116678s

â€¢ [SLOW TEST:10.249 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:20:05.930: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W1121 09:20:07.038238      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov 21 09:20:07.038: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:20:07.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4834" for this suite.
Nov 21 09:20:13.051: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:20:13.091: INFO: namespace gc-4834 deletion completed in 6.050848305s

â€¢ [SLOW TEST:7.161 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:20:13.091: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Nov 21 09:20:13.166: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:20:16.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4681" for this suite.
Nov 21 09:20:22.636: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:20:22.677: INFO: namespace init-container-4681 deletion completed in 6.219754565s

â€¢ [SLOW TEST:9.586 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:20:22.677: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Nov 21 09:20:22.799: INFO: Waiting up to 5m0s for pod "pod-2516b302-0c40-11ea-a569-4e55f5a7674f" in namespace "emptydir-93" to be "success or failure"
Nov 21 09:20:22.804: INFO: Pod "pod-2516b302-0c40-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.551338ms
Nov 21 09:20:24.805: INFO: Pod "pod-2516b302-0c40-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006364028s
Nov 21 09:20:26.808: INFO: Pod "pod-2516b302-0c40-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008624625s
STEP: Saw pod success
Nov 21 09:20:26.808: INFO: Pod "pod-2516b302-0c40-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 09:20:26.809: INFO: Trying to get logs from node 192.168.0.92 pod pod-2516b302-0c40-11ea-a569-4e55f5a7674f container test-container: <nil>
STEP: delete the pod
Nov 21 09:20:26.827: INFO: Waiting for pod pod-2516b302-0c40-11ea-a569-4e55f5a7674f to disappear
Nov 21 09:20:26.832: INFO: Pod pod-2516b302-0c40-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:20:26.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-93" for this suite.
Nov 21 09:20:32.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:20:32.887: INFO: namespace emptydir-93 deletion completed in 6.052895336s

â€¢ [SLOW TEST:10.209 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:20:32.887: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Nov 21 09:20:41.030: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2311 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 21 09:20:41.030: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
Nov 21 09:20:41.159: INFO: Exec stderr: ""
Nov 21 09:20:41.159: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2311 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 21 09:20:41.159: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
Nov 21 09:20:41.275: INFO: Exec stderr: ""
Nov 21 09:20:41.275: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2311 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 21 09:20:41.275: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
Nov 21 09:20:41.379: INFO: Exec stderr: ""
Nov 21 09:20:41.379: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2311 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 21 09:20:41.379: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
Nov 21 09:20:41.490: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Nov 21 09:20:41.490: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2311 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 21 09:20:41.490: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
Nov 21 09:20:41.603: INFO: Exec stderr: ""
Nov 21 09:20:41.603: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2311 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 21 09:20:41.603: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
Nov 21 09:20:41.711: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Nov 21 09:20:41.712: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2311 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 21 09:20:41.712: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
Nov 21 09:20:41.960: INFO: Exec stderr: ""
Nov 21 09:20:41.960: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2311 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 21 09:20:41.960: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
Nov 21 09:20:42.179: INFO: Exec stderr: ""
Nov 21 09:20:42.179: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2311 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 21 09:20:42.179: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
Nov 21 09:20:42.307: INFO: Exec stderr: ""
Nov 21 09:20:42.307: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2311 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 21 09:20:42.307: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
Nov 21 09:20:42.422: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:20:42.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-2311" for this suite.
Nov 21 09:21:32.497: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:21:32.537: INFO: namespace e2e-kubelet-etc-hosts-2311 deletion completed in 50.112355809s

â€¢ [SLOW TEST:59.650 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:21:32.537: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-4eb3ed3c-0c40-11ea-a569-4e55f5a7674f
STEP: Creating a pod to test consume configMaps
Nov 21 09:21:32.637: INFO: Waiting up to 5m0s for pod "pod-configmaps-4eb53988-0c40-11ea-a569-4e55f5a7674f" in namespace "configmap-73" to be "success or failure"
Nov 21 09:21:32.644: INFO: Pod "pod-configmaps-4eb53988-0c40-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.458641ms
Nov 21 09:21:34.646: INFO: Pod "pod-configmaps-4eb53988-0c40-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009631441s
Nov 21 09:21:36.649: INFO: Pod "pod-configmaps-4eb53988-0c40-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011729256s
STEP: Saw pod success
Nov 21 09:21:36.649: INFO: Pod "pod-configmaps-4eb53988-0c40-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 09:21:36.650: INFO: Trying to get logs from node 192.168.0.93 pod pod-configmaps-4eb53988-0c40-11ea-a569-4e55f5a7674f container configmap-volume-test: <nil>
STEP: delete the pod
Nov 21 09:21:36.668: INFO: Waiting for pod pod-configmaps-4eb53988-0c40-11ea-a569-4e55f5a7674f to disappear
Nov 21 09:21:36.688: INFO: Pod pod-configmaps-4eb53988-0c40-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:21:36.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-73" for this suite.
Nov 21 09:21:42.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:21:42.761: INFO: namespace configmap-73 deletion completed in 6.071308878s

â€¢ [SLOW TEST:10.224 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:21:42.762: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-secret-8g2t
STEP: Creating a pod to test atomic-volume-subpath
Nov 21 09:21:42.823: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-8g2t" in namespace "subpath-5937" to be "success or failure"
Nov 21 09:21:42.828: INFO: Pod "pod-subpath-test-secret-8g2t": Phase="Pending", Reason="", readiness=false. Elapsed: 5.060449ms
Nov 21 09:21:44.830: INFO: Pod "pod-subpath-test-secret-8g2t": Phase="Running", Reason="", readiness=true. Elapsed: 2.006766711s
Nov 21 09:21:46.832: INFO: Pod "pod-subpath-test-secret-8g2t": Phase="Running", Reason="", readiness=true. Elapsed: 4.009042378s
Nov 21 09:21:48.834: INFO: Pod "pod-subpath-test-secret-8g2t": Phase="Running", Reason="", readiness=true. Elapsed: 6.011289185s
Nov 21 09:21:50.837: INFO: Pod "pod-subpath-test-secret-8g2t": Phase="Running", Reason="", readiness=true. Elapsed: 8.013821702s
Nov 21 09:21:52.839: INFO: Pod "pod-subpath-test-secret-8g2t": Phase="Running", Reason="", readiness=true. Elapsed: 10.016118725s
Nov 21 09:21:54.842: INFO: Pod "pod-subpath-test-secret-8g2t": Phase="Running", Reason="", readiness=true. Elapsed: 12.018560857s
Nov 21 09:21:56.844: INFO: Pod "pod-subpath-test-secret-8g2t": Phase="Running", Reason="", readiness=true. Elapsed: 14.020683576s
Nov 21 09:21:58.846: INFO: Pod "pod-subpath-test-secret-8g2t": Phase="Running", Reason="", readiness=true. Elapsed: 16.02308043s
Nov 21 09:22:00.848: INFO: Pod "pod-subpath-test-secret-8g2t": Phase="Running", Reason="", readiness=true. Elapsed: 18.025141545s
Nov 21 09:22:02.850: INFO: Pod "pod-subpath-test-secret-8g2t": Phase="Running", Reason="", readiness=true. Elapsed: 20.027457167s
Nov 21 09:22:04.852: INFO: Pod "pod-subpath-test-secret-8g2t": Phase="Running", Reason="", readiness=true. Elapsed: 22.029497358s
Nov 21 09:22:06.855: INFO: Pod "pod-subpath-test-secret-8g2t": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.031819427s
STEP: Saw pod success
Nov 21 09:22:06.855: INFO: Pod "pod-subpath-test-secret-8g2t" satisfied condition "success or failure"
Nov 21 09:22:06.856: INFO: Trying to get logs from node 192.168.0.92 pod pod-subpath-test-secret-8g2t container test-container-subpath-secret-8g2t: <nil>
STEP: delete the pod
Nov 21 09:22:06.874: INFO: Waiting for pod pod-subpath-test-secret-8g2t to disappear
Nov 21 09:22:06.879: INFO: Pod pod-subpath-test-secret-8g2t no longer exists
STEP: Deleting pod pod-subpath-test-secret-8g2t
Nov 21 09:22:06.879: INFO: Deleting pod "pod-subpath-test-secret-8g2t" in namespace "subpath-5937"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:22:06.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5937" for this suite.
Nov 21 09:22:12.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:22:12.927: INFO: namespace subpath-5937 deletion completed in 6.045308743s

â€¢ [SLOW TEST:30.166 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:22:12.927: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Nov 21 09:22:12.977: INFO: Waiting up to 5m0s for pod "downwardapi-volume-66c2dca0-0c40-11ea-a569-4e55f5a7674f" in namespace "downward-api-6750" to be "success or failure"
Nov 21 09:22:12.982: INFO: Pod "downwardapi-volume-66c2dca0-0c40-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.737309ms
Nov 21 09:22:14.985: INFO: Pod "downwardapi-volume-66c2dca0-0c40-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007178403s
Nov 21 09:22:16.987: INFO: Pod "downwardapi-volume-66c2dca0-0c40-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009516579s
STEP: Saw pod success
Nov 21 09:22:16.987: INFO: Pod "downwardapi-volume-66c2dca0-0c40-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 09:22:16.989: INFO: Trying to get logs from node 192.168.0.93 pod downwardapi-volume-66c2dca0-0c40-11ea-a569-4e55f5a7674f container client-container: <nil>
STEP: delete the pod
Nov 21 09:22:17.006: INFO: Waiting for pod downwardapi-volume-66c2dca0-0c40-11ea-a569-4e55f5a7674f to disappear
Nov 21 09:22:17.039: INFO: Pod downwardapi-volume-66c2dca0-0c40-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:22:17.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6750" for this suite.
Nov 21 09:22:23.053: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:22:23.094: INFO: namespace downward-api-6750 deletion completed in 6.052574609s

â€¢ [SLOW TEST:10.166 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:22:23.094: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on node default medium
Nov 21 09:22:23.183: INFO: Waiting up to 5m0s for pod "pod-6cd863bf-0c40-11ea-a569-4e55f5a7674f" in namespace "emptydir-7691" to be "success or failure"
Nov 21 09:22:23.188: INFO: Pod "pod-6cd863bf-0c40-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.558994ms
Nov 21 09:22:25.190: INFO: Pod "pod-6cd863bf-0c40-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006962833s
Nov 21 09:22:27.193: INFO: Pod "pod-6cd863bf-0c40-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009370222s
STEP: Saw pod success
Nov 21 09:22:27.193: INFO: Pod "pod-6cd863bf-0c40-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 09:22:27.194: INFO: Trying to get logs from node 192.168.0.92 pod pod-6cd863bf-0c40-11ea-a569-4e55f5a7674f container test-container: <nil>
STEP: delete the pod
Nov 21 09:22:27.212: INFO: Waiting for pod pod-6cd863bf-0c40-11ea-a569-4e55f5a7674f to disappear
Nov 21 09:22:27.227: INFO: Pod pod-6cd863bf-0c40-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:22:27.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7691" for this suite.
Nov 21 09:22:33.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:22:33.280: INFO: namespace emptydir-7691 deletion completed in 6.051404217s

â€¢ [SLOW TEST:10.187 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:22:33.281: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-630
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-630
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-630
Nov 21 09:22:33.342: INFO: Found 0 stateful pods, waiting for 1
Nov 21 09:22:43.345: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Nov 21 09:22:43.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-630 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov 21 09:22:43.563: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Nov 21 09:22:43.563: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov 21 09:22:43.563: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov 21 09:22:43.565: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Nov 21 09:22:53.567: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov 21 09:22:53.567: INFO: Waiting for statefulset status.replicas updated to 0
Nov 21 09:22:53.577: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999793s
Nov 21 09:22:54.579: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.994932024s
Nov 21 09:22:55.581: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.992639397s
Nov 21 09:22:56.585: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.990486627s
Nov 21 09:22:57.587: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.987326138s
Nov 21 09:22:58.589: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.984808202s
Nov 21 09:22:59.592: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.982629916s
Nov 21 09:23:00.594: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.980030675s
Nov 21 09:23:01.596: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.977755526s
Nov 21 09:23:02.599: INFO: Verifying statefulset ss doesn't scale past 1 for another 975.530765ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-630
Nov 21 09:23:03.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-630 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 21 09:23:03.810: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Nov 21 09:23:03.810: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov 21 09:23:03.810: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov 21 09:23:03.812: INFO: Found 1 stateful pods, waiting for 3
Nov 21 09:23:13.815: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 21 09:23:13.815: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 21 09:23:13.815: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Nov 21 09:23:13.818: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-630 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov 21 09:23:14.029: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Nov 21 09:23:14.029: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov 21 09:23:14.029: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov 21 09:23:14.029: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-630 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov 21 09:23:14.249: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Nov 21 09:23:14.249: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov 21 09:23:14.249: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov 21 09:23:14.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-630 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov 21 09:23:14.452: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Nov 21 09:23:14.452: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov 21 09:23:14.452: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov 21 09:23:14.452: INFO: Waiting for statefulset status.replicas updated to 0
Nov 21 09:23:14.458: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Nov 21 09:23:24.462: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov 21 09:23:24.462: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Nov 21 09:23:24.462: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Nov 21 09:23:24.504: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999781s
Nov 21 09:23:25.507: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.961768351s
Nov 21 09:23:26.509: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.959034677s
Nov 21 09:23:27.511: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.956546267s
Nov 21 09:23:28.514: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.954088762s
Nov 21 09:23:29.516: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.951815101s
Nov 21 09:23:30.519: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.949345694s
Nov 21 09:23:31.521: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.946610252s
Nov 21 09:23:32.524: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.944062585s
Nov 21 09:23:33.528: INFO: Verifying statefulset ss doesn't scale past 3 for another 941.250629ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-630
Nov 21 09:23:34.531: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-630 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 21 09:23:34.781: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Nov 21 09:23:34.781: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov 21 09:23:34.781: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov 21 09:23:34.781: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-630 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 21 09:23:35.013: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Nov 21 09:23:35.013: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov 21 09:23:35.013: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov 21 09:23:35.013: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 exec --namespace=statefulset-630 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 21 09:23:35.238: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Nov 21 09:23:35.238: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov 21 09:23:35.238: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov 21 09:23:35.238: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Nov 21 09:23:55.247: INFO: Deleting all statefulset in ns statefulset-630
Nov 21 09:23:55.249: INFO: Scaling statefulset ss to 0
Nov 21 09:23:55.253: INFO: Waiting for statefulset status.replicas updated to 0
Nov 21 09:23:55.255: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:23:55.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-630" for this suite.
Nov 21 09:24:01.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:24:01.335: INFO: namespace statefulset-630 deletion completed in 6.051849022s

â€¢ [SLOW TEST:88.054 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:24:01.335: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Nov 21 09:24:01.431: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a767de5f-0c40-11ea-a569-4e55f5a7674f" in namespace "projected-3732" to be "success or failure"
Nov 21 09:24:01.435: INFO: Pod "downwardapi-volume-a767de5f-0c40-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.731641ms
Nov 21 09:24:03.438: INFO: Pod "downwardapi-volume-a767de5f-0c40-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006869564s
Nov 21 09:24:05.440: INFO: Pod "downwardapi-volume-a767de5f-0c40-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009297257s
STEP: Saw pod success
Nov 21 09:24:05.440: INFO: Pod "downwardapi-volume-a767de5f-0c40-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 09:24:05.442: INFO: Trying to get logs from node 192.168.0.92 pod downwardapi-volume-a767de5f-0c40-11ea-a569-4e55f5a7674f container client-container: <nil>
STEP: delete the pod
Nov 21 09:24:05.475: INFO: Waiting for pod downwardapi-volume-a767de5f-0c40-11ea-a569-4e55f5a7674f to disappear
Nov 21 09:24:05.481: INFO: Pod downwardapi-volume-a767de5f-0c40-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:24:05.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3732" for this suite.
Nov 21 09:24:11.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:24:11.616: INFO: namespace projected-3732 deletion completed in 6.132538591s

â€¢ [SLOW TEST:10.280 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:24:11.616: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with configMap that has name projected-configmap-test-upd-ad84c371-0c40-11ea-a569-4e55f5a7674f
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-ad84c371-0c40-11ea-a569-4e55f5a7674f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:25:44.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-812" for this suite.
Nov 21 09:26:06.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:26:06.211: INFO: namespace projected-812 deletion completed in 22.060501379s

â€¢ [SLOW TEST:114.595 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:26:06.211: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Nov 21 09:26:06.272: INFO: Waiting up to 5m0s for pod "pod-f1d085ee-0c40-11ea-a569-4e55f5a7674f" in namespace "emptydir-9653" to be "success or failure"
Nov 21 09:26:06.276: INFO: Pod "pod-f1d085ee-0c40-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.669402ms
Nov 21 09:26:08.278: INFO: Pod "pod-f1d085ee-0c40-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006400501s
Nov 21 09:26:10.280: INFO: Pod "pod-f1d085ee-0c40-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008498203s
STEP: Saw pod success
Nov 21 09:26:10.280: INFO: Pod "pod-f1d085ee-0c40-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 09:26:10.282: INFO: Trying to get logs from node 192.168.0.93 pod pod-f1d085ee-0c40-11ea-a569-4e55f5a7674f container test-container: <nil>
STEP: delete the pod
Nov 21 09:26:10.304: INFO: Waiting for pod pod-f1d085ee-0c40-11ea-a569-4e55f5a7674f to disappear
Nov 21 09:26:10.325: INFO: Pod pod-f1d085ee-0c40-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:26:10.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9653" for this suite.
Nov 21 09:26:16.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:26:16.389: INFO: namespace emptydir-9653 deletion completed in 6.06269888s

â€¢ [SLOW TEST:10.178 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:26:16.389: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-f7dfee0a-0c40-11ea-a569-4e55f5a7674f
STEP: Creating a pod to test consume configMaps
Nov 21 09:26:16.443: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f7e0d90d-0c40-11ea-a569-4e55f5a7674f" in namespace "projected-8253" to be "success or failure"
Nov 21 09:26:16.459: INFO: Pod "pod-projected-configmaps-f7e0d90d-0c40-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 15.30823ms
Nov 21 09:26:18.461: INFO: Pod "pod-projected-configmaps-f7e0d90d-0c40-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017767599s
Nov 21 09:26:20.463: INFO: Pod "pod-projected-configmaps-f7e0d90d-0c40-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020029436s
STEP: Saw pod success
Nov 21 09:26:20.464: INFO: Pod "pod-projected-configmaps-f7e0d90d-0c40-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 09:26:20.465: INFO: Trying to get logs from node 192.168.0.93 pod pod-projected-configmaps-f7e0d90d-0c40-11ea-a569-4e55f5a7674f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 21 09:26:20.484: INFO: Waiting for pod pod-projected-configmaps-f7e0d90d-0c40-11ea-a569-4e55f5a7674f to disappear
Nov 21 09:26:20.488: INFO: Pod pod-projected-configmaps-f7e0d90d-0c40-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:26:20.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8253" for this suite.
Nov 21 09:26:26.495: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:26:26.536: INFO: namespace projected-8253 deletion completed in 6.045995537s

â€¢ [SLOW TEST:10.147 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:26:26.536: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-fdecbb54-0c40-11ea-a569-4e55f5a7674f
STEP: Creating a pod to test consume secrets
Nov 21 09:26:26.592: INFO: Waiting up to 5m0s for pod "pod-secrets-fded6ffd-0c40-11ea-a569-4e55f5a7674f" in namespace "secrets-2104" to be "success or failure"
Nov 21 09:26:26.597: INFO: Pod "pod-secrets-fded6ffd-0c40-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.066582ms
Nov 21 09:26:28.602: INFO: Pod "pod-secrets-fded6ffd-0c40-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009880007s
STEP: Saw pod success
Nov 21 09:26:28.602: INFO: Pod "pod-secrets-fded6ffd-0c40-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 09:26:28.604: INFO: Trying to get logs from node 192.168.0.92 pod pod-secrets-fded6ffd-0c40-11ea-a569-4e55f5a7674f container secret-volume-test: <nil>
STEP: delete the pod
Nov 21 09:26:28.631: INFO: Waiting for pod pod-secrets-fded6ffd-0c40-11ea-a569-4e55f5a7674f to disappear
Nov 21 09:26:28.637: INFO: Pod pod-secrets-fded6ffd-0c40-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:26:28.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2104" for this suite.
Nov 21 09:26:34.681: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:26:34.728: INFO: namespace secrets-2104 deletion completed in 6.088885221s

â€¢ [SLOW TEST:8.192 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:26:34.728: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Nov 21 09:26:34.797: INFO: Pod name rollover-pod: Found 0 pods out of 1
Nov 21 09:26:39.799: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov 21 09:26:39.799: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Nov 21 09:26:41.801: INFO: Creating deployment "test-rollover-deployment"
Nov 21 09:26:41.808: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Nov 21 09:26:43.812: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Nov 21 09:26:43.815: INFO: Ensure that both replica sets have 1 created replica
Nov 21 09:26:43.818: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Nov 21 09:26:43.822: INFO: Updating deployment test-rollover-deployment
Nov 21 09:26:43.822: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Nov 21 09:26:45.839: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Nov 21 09:26:45.965: INFO: Make sure deployment "test-rollover-deployment" is complete
Nov 21 09:26:45.968: INFO: all replica sets need to contain the pod-template-hash label
Nov 21 09:26:45.968: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709925201, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709925201, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709925203, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709925201, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 21 09:26:47.972: INFO: all replica sets need to contain the pod-template-hash label
Nov 21 09:26:47.972: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709925201, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709925201, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709925206, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709925201, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 21 09:26:49.972: INFO: all replica sets need to contain the pod-template-hash label
Nov 21 09:26:49.972: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709925201, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709925201, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709925206, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709925201, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 21 09:26:51.972: INFO: all replica sets need to contain the pod-template-hash label
Nov 21 09:26:51.972: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709925201, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709925201, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709925206, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709925201, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 21 09:26:53.972: INFO: all replica sets need to contain the pod-template-hash label
Nov 21 09:26:53.972: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709925201, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709925201, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709925206, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709925201, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 21 09:26:55.972: INFO: all replica sets need to contain the pod-template-hash label
Nov 21 09:26:55.973: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709925201, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709925201, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709925206, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709925201, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 21 09:26:57.972: INFO: 
Nov 21 09:26:57.972: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Nov 21 09:26:57.976: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-8165,SelfLink:/apis/apps/v1/namespaces/deployment-8165/deployments/test-rollover-deployment,UID:06ff49cd-0c41-11ea-b617-0202c0a8005b,ResourceVersion:23770,Generation:2,CreationTimestamp:2019-11-21 09:26:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-11-21 09:26:41 +0000 UTC 2019-11-21 09:26:41 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-11-21 09:26:56 +0000 UTC 2019-11-21 09:26:41 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-766b4d6c9d" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Nov 21 09:26:57.978: INFO: New ReplicaSet "test-rollover-deployment-766b4d6c9d" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-766b4d6c9d,GenerateName:,Namespace:deployment-8165,SelfLink:/apis/apps/v1/namespaces/deployment-8165/replicasets/test-rollover-deployment-766b4d6c9d,UID:0833921a-0c41-11ea-b617-0202c0a8005b,ResourceVersion:23759,Generation:2,CreationTimestamp:2019-11-21 09:26:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 06ff49cd-0c41-11ea-b617-0202c0a8005b 0xc000b8f3b7 0xc000b8f3b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Nov 21 09:26:57.978: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Nov 21 09:26:57.978: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-8165,SelfLink:/apis/apps/v1/namespaces/deployment-8165/replicasets/test-rollover-controller,UID:02d0cc67-0c41-11ea-b617-0202c0a8005b,ResourceVersion:23768,Generation:2,CreationTimestamp:2019-11-21 09:26:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 06ff49cd-0c41-11ea-b617-0202c0a8005b 0xc000b8f207 0xc000b8f208}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov 21 09:26:57.978: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6455657675,GenerateName:,Namespace:deployment-8165,SelfLink:/apis/apps/v1/namespaces/deployment-8165/replicasets/test-rollover-deployment-6455657675,UID:0700b5bd-0c41-11ea-b617-0202c0a8005b,ResourceVersion:23730,Generation:2,CreationTimestamp:2019-11-21 09:26:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 06ff49cd-0c41-11ea-b617-0202c0a8005b 0xc000b8f2d7 0xc000b8f2d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov 21 09:26:57.980: INFO: Pod "test-rollover-deployment-766b4d6c9d-w9mbp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-766b4d6c9d-w9mbp,GenerateName:test-rollover-deployment-766b4d6c9d-,Namespace:deployment-8165,SelfLink:/api/v1/namespaces/deployment-8165/pods/test-rollover-deployment-766b4d6c9d-w9mbp,UID:083eb38c-0c41-11ea-b617-0202c0a8005b,ResourceVersion:23742,Generation:0,CreationTimestamp:2019-11-21 09:26:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-766b4d6c9d 0833921a-0c41-11ea-b617-0202c0a8005b 0xc000b8ffa7 0xc000b8ffa8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-k29mk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-k29mk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-k29mk true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.92,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c16210} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c16230}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:26:44 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:26:45 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:26:45 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:26:43 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.92,PodIP:172.49.135.137,StartTime:2019-11-21 09:26:44 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-11-21 09:26:45 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://reg.mg.hcbss/devcke/redis@sha256:9b5b1c1ec462abb4b89145a23a1fbf7eb3b2bb25927fc94e820f89a73029889f docker://32d6e144e1f2b8b64691d84b7c8d539035a0d923972f53532ddfbd8ca55f168e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:26:57.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8165" for this suite.
Nov 21 09:27:04.024: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:27:04.064: INFO: namespace deployment-8165 deletion completed in 6.081729761s

â€¢ [SLOW TEST:29.335 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:27:04.064: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:27:29.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9957" for this suite.
Nov 21 09:27:35.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:27:35.490: INFO: namespace container-runtime-9957 deletion completed in 6.056873832s

â€¢ [SLOW TEST:31.426 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  blackbox test
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:27:35.490: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:27:35.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4511" for this suite.
Nov 21 09:27:57.629: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:27:57.668: INFO: namespace kubelet-test-4511 deletion completed in 22.049460581s

â€¢ [SLOW TEST:22.178 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:27:57.668: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Nov 21 09:27:57.746: INFO: namespace kubectl-2133
Nov 21 09:27:57.746: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 create -f - --namespace=kubectl-2133'
Nov 21 09:27:58.641: INFO: stderr: ""
Nov 21 09:27:58.641: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Nov 21 09:27:59.644: INFO: Selector matched 1 pods for map[app:redis]
Nov 21 09:27:59.644: INFO: Found 0 / 1
Nov 21 09:28:00.651: INFO: Selector matched 1 pods for map[app:redis]
Nov 21 09:28:00.651: INFO: Found 0 / 1
Nov 21 09:28:01.644: INFO: Selector matched 1 pods for map[app:redis]
Nov 21 09:28:01.644: INFO: Found 1 / 1
Nov 21 09:28:01.644: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov 21 09:28:01.645: INFO: Selector matched 1 pods for map[app:redis]
Nov 21 09:28:01.645: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov 21 09:28:01.645: INFO: wait on redis-master startup in kubectl-2133 
Nov 21 09:28:01.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 logs redis-master-tgnrv redis-master --namespace=kubectl-2133'
Nov 21 09:28:01.725: INFO: stderr: ""
Nov 21 09:28:01.725: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 21 Nov 09:28:00.205 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 21 Nov 09:28:00.205 # Server started, Redis version 3.2.12\n1:M 21 Nov 09:28:00.205 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Nov 21 09:28:01.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-2133'
Nov 21 09:28:01.837: INFO: stderr: ""
Nov 21 09:28:01.837: INFO: stdout: "service/rm2 exposed\n"
Nov 21 09:28:01.844: INFO: Service rm2 in namespace kubectl-2133 found.
STEP: exposing service
Nov 21 09:28:03.848: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-2133'
Nov 21 09:28:03.946: INFO: stderr: ""
Nov 21 09:28:03.946: INFO: stdout: "service/rm3 exposed\n"
Nov 21 09:28:03.976: INFO: Service rm3 in namespace kubectl-2133 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:28:05.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2133" for this suite.
Nov 21 09:28:27.995: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:28:28.035: INFO: namespace kubectl-2133 deletion completed in 22.053365223s

â€¢ [SLOW TEST:30.367 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create services for rc  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:28:28.035: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name projected-secret-test-4659c80c-0c41-11ea-a569-4e55f5a7674f
STEP: Creating a pod to test consume secrets
Nov 21 09:28:28.132: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-465a8d93-0c41-11ea-a569-4e55f5a7674f" in namespace "projected-6212" to be "success or failure"
Nov 21 09:28:28.143: INFO: Pod "pod-projected-secrets-465a8d93-0c41-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.670513ms
Nov 21 09:28:30.145: INFO: Pod "pod-projected-secrets-465a8d93-0c41-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01309387s
Nov 21 09:28:32.148: INFO: Pod "pod-projected-secrets-465a8d93-0c41-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015424313s
STEP: Saw pod success
Nov 21 09:28:32.148: INFO: Pod "pod-projected-secrets-465a8d93-0c41-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 09:28:32.149: INFO: Trying to get logs from node 192.168.0.93 pod pod-projected-secrets-465a8d93-0c41-11ea-a569-4e55f5a7674f container secret-volume-test: <nil>
STEP: delete the pod
Nov 21 09:28:32.190: INFO: Waiting for pod pod-projected-secrets-465a8d93-0c41-11ea-a569-4e55f5a7674f to disappear
Nov 21 09:28:32.199: INFO: Pod pod-projected-secrets-465a8d93-0c41-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:28:32.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6212" for this suite.
Nov 21 09:28:38.206: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:28:38.247: INFO: namespace projected-6212 deletion completed in 6.045982448s

â€¢ [SLOW TEST:10.212 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:28:38.247: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-4c6e5c36-0c41-11ea-a569-4e55f5a7674f
STEP: Creating a pod to test consume configMaps
Nov 21 09:28:38.320: INFO: Waiting up to 5m0s for pod "pod-configmaps-4c6ef2ae-0c41-11ea-a569-4e55f5a7674f" in namespace "configmap-7666" to be "success or failure"
Nov 21 09:28:38.338: INFO: Pod "pod-configmaps-4c6ef2ae-0c41-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 17.551632ms
Nov 21 09:28:40.354: INFO: Pod "pod-configmaps-4c6ef2ae-0c41-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.033372528s
STEP: Saw pod success
Nov 21 09:28:40.354: INFO: Pod "pod-configmaps-4c6ef2ae-0c41-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 09:28:40.359: INFO: Trying to get logs from node 192.168.0.92 pod pod-configmaps-4c6ef2ae-0c41-11ea-a569-4e55f5a7674f container configmap-volume-test: <nil>
STEP: delete the pod
Nov 21 09:28:40.372: INFO: Waiting for pod pod-configmaps-4c6ef2ae-0c41-11ea-a569-4e55f5a7674f to disappear
Nov 21 09:28:40.376: INFO: Pod pod-configmaps-4c6ef2ae-0c41-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:28:40.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7666" for this suite.
Nov 21 09:28:46.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:28:46.429: INFO: namespace configmap-7666 deletion completed in 6.050010755s

â€¢ [SLOW TEST:8.182 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:28:46.429: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-369/configmap-test-515160d3-0c41-11ea-a569-4e55f5a7674f
STEP: Creating a pod to test consume configMaps
Nov 21 09:28:46.498: INFO: Waiting up to 5m0s for pod "pod-configmaps-51519f31-0c41-11ea-a569-4e55f5a7674f" in namespace "configmap-369" to be "success or failure"
Nov 21 09:28:46.514: INFO: Pod "pod-configmaps-51519f31-0c41-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 16.079047ms
Nov 21 09:28:48.516: INFO: Pod "pod-configmaps-51519f31-0c41-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018373674s
Nov 21 09:28:50.518: INFO: Pod "pod-configmaps-51519f31-0c41-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020240454s
STEP: Saw pod success
Nov 21 09:28:50.518: INFO: Pod "pod-configmaps-51519f31-0c41-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 09:28:50.519: INFO: Trying to get logs from node 192.168.0.93 pod pod-configmaps-51519f31-0c41-11ea-a569-4e55f5a7674f container env-test: <nil>
STEP: delete the pod
Nov 21 09:28:50.544: INFO: Waiting for pod pod-configmaps-51519f31-0c41-11ea-a569-4e55f5a7674f to disappear
Nov 21 09:28:50.554: INFO: Pod pod-configmaps-51519f31-0c41-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:28:50.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-369" for this suite.
Nov 21 09:28:56.561: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:28:56.600: INFO: namespace configmap-369 deletion completed in 6.044206145s

â€¢ [SLOW TEST:10.171 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:28:56.600: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Nov 21 09:28:56.688: INFO: Waiting up to 5m0s for pod "downwardapi-volume-57625eec-0c41-11ea-a569-4e55f5a7674f" in namespace "projected-2983" to be "success or failure"
Nov 21 09:28:56.697: INFO: Pod "downwardapi-volume-57625eec-0c41-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 9.002378ms
Nov 21 09:28:58.699: INFO: Pod "downwardapi-volume-57625eec-0c41-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011330857s
Nov 21 09:29:00.701: INFO: Pod "downwardapi-volume-57625eec-0c41-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013619766s
STEP: Saw pod success
Nov 21 09:29:00.701: INFO: Pod "downwardapi-volume-57625eec-0c41-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 09:29:00.703: INFO: Trying to get logs from node 192.168.0.92 pod downwardapi-volume-57625eec-0c41-11ea-a569-4e55f5a7674f container client-container: <nil>
STEP: delete the pod
Nov 21 09:29:00.727: INFO: Waiting for pod downwardapi-volume-57625eec-0c41-11ea-a569-4e55f5a7674f to disappear
Nov 21 09:29:00.731: INFO: Pod downwardapi-volume-57625eec-0c41-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:29:00.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2983" for this suite.
Nov 21 09:29:06.738: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:29:06.778: INFO: namespace projected-2983 deletion completed in 6.045087302s

â€¢ [SLOW TEST:10.178 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:29:06.778: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Nov 21 09:29:06.852: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov 21 09:29:06.859: INFO: Waiting for terminating namespaces to be deleted...
Nov 21 09:29:06.860: INFO: 
Logging pods the kubelet thinks is on node 192.168.0.92 before test
Nov 21 09:29:06.864: INFO: kubernetes-dashboard-7767bf47b6-sflp4 from kube-system started at 2019-11-21 06:54:20 +0000 UTC (1 container statuses recorded)
Nov 21 09:29:06.864: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Nov 21 09:29:06.864: INFO: ckecsi-attacher-1 from default started at 2019-11-21 06:55:05 +0000 UTC (1 container statuses recorded)
Nov 21 09:29:06.864: INFO: 	Container ckecsi-attacher ready: true, restart count 0
Nov 21 09:29:06.864: INFO: sonobuoy-e2e-job-56ce796c30644ea3 from sonobuoy started at 2019-11-21 08:10:37 +0000 UTC (2 container statuses recorded)
Nov 21 09:29:06.864: INFO: 	Container e2e ready: true, restart count 0
Nov 21 09:29:06.864: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 21 09:29:06.864: INFO: ckecsi-provisioner-0 from default started at 2019-11-21 06:54:20 +0000 UTC (1 container statuses recorded)
Nov 21 09:29:06.864: INFO: 	Container ckecsi-provisioner ready: true, restart count 0
Nov 21 09:29:06.864: INFO: ckecsi-57xl8 from default started at 2019-11-21 06:54:21 +0000 UTC (2 container statuses recorded)
Nov 21 09:29:06.864: INFO: 	Container ckecsi ready: true, restart count 0
Nov 21 09:29:06.864: INFO: 	Container driver-registrar ready: true, restart count 0
Nov 21 09:29:06.864: INFO: 
Logging pods the kubelet thinks is on node 192.168.0.93 before test
Nov 21 09:29:06.867: INFO: ckecsi-provisioner-1 from default started at 2019-11-21 06:54:25 +0000 UTC (1 container statuses recorded)
Nov 21 09:29:06.867: INFO: 	Container ckecsi-provisioner ready: true, restart count 0
Nov 21 09:29:06.867: INFO: sonobuoy from sonobuoy started at 2019-11-21 08:10:34 +0000 UTC (1 container statuses recorded)
Nov 21 09:29:06.867: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov 21 09:29:06.867: INFO: ckecsi-attacher-0 from default started at 2019-11-21 06:54:21 +0000 UTC (1 container statuses recorded)
Nov 21 09:29:06.867: INFO: 	Container ckecsi-attacher ready: true, restart count 0
Nov 21 09:29:06.867: INFO: ckecsi-gmm9x from default started at 2019-11-21 06:54:21 +0000 UTC (2 container statuses recorded)
Nov 21 09:29:06.867: INFO: 	Container ckecsi ready: true, restart count 0
Nov 21 09:29:06.867: INFO: 	Container driver-registrar ready: true, restart count 0
Nov 21 09:29:06.867: INFO: coredns-67b8c5b5d8-6lncm from kube-system started at 2019-11-21 06:54:21 +0000 UTC (1 container statuses recorded)
Nov 21 09:29:06.867: INFO: 	Container coredns ready: true, restart count 0
Nov 21 09:29:06.867: INFO: calico-kube-controllers-79fd644cdf-nj4bj from kube-system started at 2019-11-21 06:54:21 +0000 UTC (1 container statuses recorded)
Nov 21 09:29:06.867: INFO: 	Container calico-kube-controllers ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15d92378e54370ae], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:29:07.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3730" for this suite.
Nov 21 09:29:13.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:29:13.951: INFO: namespace sched-pred-3730 deletion completed in 6.055102593s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

â€¢ [SLOW TEST:7.173 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:29:13.951: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Nov 21 09:29:14.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 version'
Nov 21 09:29:14.110: INFO: stderr: ""
Nov 21 09:29:14.110: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.1\", GitCommit:\"b7394102d6ef778017f2ca4046abbaa23b88c290\", GitTreeState:\"clean\", BuildDate:\"2019-04-08T17:11:31Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.1\", GitCommit:\"b7394102d6ef778017f2ca4046abbaa23b88c290\", GitTreeState:\"clean\", BuildDate:\"2019-04-08T17:02:58Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:29:14.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8872" for this suite.
Nov 21 09:29:20.121: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:29:20.161: INFO: namespace kubectl-8872 deletion completed in 6.048502625s

â€¢ [SLOW TEST:6.210 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:29:20.162: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Nov 21 09:29:20.234: INFO: (0) /api/v1/nodes/192.168.0.92:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 3.398545ms)
Nov 21 09:29:20.236: INFO: (1) /api/v1/nodes/192.168.0.92:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.870684ms)
Nov 21 09:29:20.238: INFO: (2) /api/v1/nodes/192.168.0.92:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.775365ms)
Nov 21 09:29:20.239: INFO: (3) /api/v1/nodes/192.168.0.92:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.746219ms)
Nov 21 09:29:20.241: INFO: (4) /api/v1/nodes/192.168.0.92:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.741527ms)
Nov 21 09:29:20.243: INFO: (5) /api/v1/nodes/192.168.0.92:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.653275ms)
Nov 21 09:29:20.245: INFO: (6) /api/v1/nodes/192.168.0.92:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.786394ms)
Nov 21 09:29:20.246: INFO: (7) /api/v1/nodes/192.168.0.92:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.809461ms)
Nov 21 09:29:20.248: INFO: (8) /api/v1/nodes/192.168.0.92:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.716818ms)
Nov 21 09:29:20.250: INFO: (9) /api/v1/nodes/192.168.0.92:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.705429ms)
Nov 21 09:29:20.252: INFO: (10) /api/v1/nodes/192.168.0.92:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.788556ms)
Nov 21 09:29:20.253: INFO: (11) /api/v1/nodes/192.168.0.92:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.650074ms)
Nov 21 09:29:20.255: INFO: (12) /api/v1/nodes/192.168.0.92:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.793088ms)
Nov 21 09:29:20.257: INFO: (13) /api/v1/nodes/192.168.0.92:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.651779ms)
Nov 21 09:29:20.258: INFO: (14) /api/v1/nodes/192.168.0.92:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.725317ms)
Nov 21 09:29:20.260: INFO: (15) /api/v1/nodes/192.168.0.92:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.557279ms)
Nov 21 09:29:20.262: INFO: (16) /api/v1/nodes/192.168.0.92:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.702204ms)
Nov 21 09:29:20.263: INFO: (17) /api/v1/nodes/192.168.0.92:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.709524ms)
Nov 21 09:29:20.265: INFO: (18) /api/v1/nodes/192.168.0.92:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.670466ms)
Nov 21 09:29:20.267: INFO: (19) /api/v1/nodes/192.168.0.92:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.710754ms)
[AfterEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:29:20.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-115" for this suite.
Nov 21 09:29:26.290: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:29:26.329: INFO: namespace proxy-115 deletion completed in 6.060170004s

â€¢ [SLOW TEST:6.167 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:29:26.329: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-6917395a-0c41-11ea-a569-4e55f5a7674f
STEP: Creating a pod to test consume configMaps
Nov 21 09:29:26.390: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-69185fad-0c41-11ea-a569-4e55f5a7674f" in namespace "projected-3528" to be "success or failure"
Nov 21 09:29:26.428: INFO: Pod "pod-projected-configmaps-69185fad-0c41-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 37.977669ms
Nov 21 09:29:28.430: INFO: Pod "pod-projected-configmaps-69185fad-0c41-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040350641s
Nov 21 09:29:30.433: INFO: Pod "pod-projected-configmaps-69185fad-0c41-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.04269076s
STEP: Saw pod success
Nov 21 09:29:30.433: INFO: Pod "pod-projected-configmaps-69185fad-0c41-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 09:29:30.434: INFO: Trying to get logs from node 192.168.0.93 pod pod-projected-configmaps-69185fad-0c41-11ea-a569-4e55f5a7674f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 21 09:29:30.457: INFO: Waiting for pod pod-projected-configmaps-69185fad-0c41-11ea-a569-4e55f5a7674f to disappear
Nov 21 09:29:30.463: INFO: Pod pod-projected-configmaps-69185fad-0c41-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:29:30.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3528" for this suite.
Nov 21 09:29:36.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:29:36.533: INFO: namespace projected-3528 deletion completed in 6.068156718s

â€¢ [SLOW TEST:10.204 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:29:36.533: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-6f2b0697-0c41-11ea-a569-4e55f5a7674f
STEP: Creating a pod to test consume secrets
Nov 21 09:29:36.584: INFO: Waiting up to 5m0s for pod "pod-secrets-6f2beb50-0c41-11ea-a569-4e55f5a7674f" in namespace "secrets-4465" to be "success or failure"
Nov 21 09:29:36.589: INFO: Pod "pod-secrets-6f2beb50-0c41-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.733718ms
Nov 21 09:29:38.591: INFO: Pod "pod-secrets-6f2beb50-0c41-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006792353s
Nov 21 09:29:40.593: INFO: Pod "pod-secrets-6f2beb50-0c41-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008943572s
STEP: Saw pod success
Nov 21 09:29:40.593: INFO: Pod "pod-secrets-6f2beb50-0c41-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 09:29:40.595: INFO: Trying to get logs from node 192.168.0.93 pod pod-secrets-6f2beb50-0c41-11ea-a569-4e55f5a7674f container secret-volume-test: <nil>
STEP: delete the pod
Nov 21 09:29:40.630: INFO: Waiting for pod pod-secrets-6f2beb50-0c41-11ea-a569-4e55f5a7674f to disappear
Nov 21 09:29:40.635: INFO: Pod pod-secrets-6f2beb50-0c41-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:29:40.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4465" for this suite.
Nov 21 09:29:46.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:29:46.706: INFO: namespace secrets-4465 deletion completed in 6.069710763s

â€¢ [SLOW TEST:10.173 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:29:46.706: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Nov 21 09:29:46.817: INFO: Create a RollingUpdate DaemonSet
Nov 21 09:29:46.819: INFO: Check that daemon pods launch on every node of the cluster
Nov 21 09:29:46.829: INFO: Number of nodes with available pods: 0
Nov 21 09:29:46.829: INFO: Node 192.168.0.92 is running more than one daemon pod
Nov 21 09:29:47.833: INFO: Number of nodes with available pods: 0
Nov 21 09:29:47.833: INFO: Node 192.168.0.92 is running more than one daemon pod
Nov 21 09:29:48.834: INFO: Number of nodes with available pods: 0
Nov 21 09:29:48.834: INFO: Node 192.168.0.92 is running more than one daemon pod
Nov 21 09:29:49.833: INFO: Number of nodes with available pods: 2
Nov 21 09:29:49.833: INFO: Number of running nodes: 2, number of available pods: 2
Nov 21 09:29:49.833: INFO: Update the DaemonSet to trigger a rollout
Nov 21 09:29:49.836: INFO: Updating DaemonSet daemon-set
Nov 21 09:29:53.874: INFO: Roll back the DaemonSet before rollout is complete
Nov 21 09:29:53.878: INFO: Updating DaemonSet daemon-set
Nov 21 09:29:53.878: INFO: Make sure DaemonSet rollback is complete
Nov 21 09:29:53.886: INFO: Wrong image for pod: daemon-set-kxjln. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Nov 21 09:29:53.886: INFO: Pod daemon-set-kxjln is not available
Nov 21 09:29:54.895: INFO: Wrong image for pod: daemon-set-kxjln. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Nov 21 09:29:54.895: INFO: Pod daemon-set-kxjln is not available
Nov 21 09:29:55.895: INFO: Wrong image for pod: daemon-set-kxjln. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Nov 21 09:29:55.895: INFO: Pod daemon-set-kxjln is not available
Nov 21 09:29:56.896: INFO: Wrong image for pod: daemon-set-kxjln. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Nov 21 09:29:56.896: INFO: Pod daemon-set-kxjln is not available
Nov 21 09:29:57.895: INFO: Wrong image for pod: daemon-set-kxjln. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Nov 21 09:29:57.895: INFO: Pod daemon-set-kxjln is not available
Nov 21 09:29:58.895: INFO: Wrong image for pod: daemon-set-kxjln. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Nov 21 09:29:58.895: INFO: Pod daemon-set-kxjln is not available
Nov 21 09:29:59.895: INFO: Wrong image for pod: daemon-set-kxjln. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Nov 21 09:29:59.895: INFO: Pod daemon-set-kxjln is not available
Nov 21 09:30:00.895: INFO: Pod daemon-set-6vp8s is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5796, will wait for the garbage collector to delete the pods
Nov 21 09:30:00.954: INFO: Deleting DaemonSet.extensions daemon-set took: 2.59647ms
Nov 21 09:30:01.254: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.179584ms
Nov 21 09:30:03.155: INFO: Number of nodes with available pods: 0
Nov 21 09:30:03.155: INFO: Number of running nodes: 0, number of available pods: 0
Nov 21 09:30:03.157: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5796/daemonsets","resourceVersion":"24601"},"items":null}

Nov 21 09:30:03.158: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5796/pods","resourceVersion":"24601"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:30:03.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5796" for this suite.
Nov 21 09:30:09.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:30:09.267: INFO: namespace daemonsets-5796 deletion completed in 6.101589665s

â€¢ [SLOW TEST:22.561 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:30:09.267: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Nov 21 09:30:09.334: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7569,SelfLink:/api/v1/namespaces/watch-7569/configmaps/e2e-watch-test-label-changed,UID:82af1e5f-0c41-11ea-b617-0202c0a8005b,ResourceVersion:24647,Generation:0,CreationTimestamp:2019-11-21 09:30:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov 21 09:30:09.334: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7569,SelfLink:/api/v1/namespaces/watch-7569/configmaps/e2e-watch-test-label-changed,UID:82af1e5f-0c41-11ea-b617-0202c0a8005b,ResourceVersion:24648,Generation:0,CreationTimestamp:2019-11-21 09:30:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Nov 21 09:30:09.334: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7569,SelfLink:/api/v1/namespaces/watch-7569/configmaps/e2e-watch-test-label-changed,UID:82af1e5f-0c41-11ea-b617-0202c0a8005b,ResourceVersion:24649,Generation:0,CreationTimestamp:2019-11-21 09:30:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Nov 21 09:30:19.373: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7569,SelfLink:/api/v1/namespaces/watch-7569/configmaps/e2e-watch-test-label-changed,UID:82af1e5f-0c41-11ea-b617-0202c0a8005b,ResourceVersion:24665,Generation:0,CreationTimestamp:2019-11-21 09:30:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov 21 09:30:19.374: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7569,SelfLink:/api/v1/namespaces/watch-7569/configmaps/e2e-watch-test-label-changed,UID:82af1e5f-0c41-11ea-b617-0202c0a8005b,ResourceVersion:24666,Generation:0,CreationTimestamp:2019-11-21 09:30:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Nov 21 09:30:19.374: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7569,SelfLink:/api/v1/namespaces/watch-7569/configmaps/e2e-watch-test-label-changed,UID:82af1e5f-0c41-11ea-b617-0202c0a8005b,ResourceVersion:24667,Generation:0,CreationTimestamp:2019-11-21 09:30:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:30:19.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7569" for this suite.
Nov 21 09:30:25.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:30:25.426: INFO: namespace watch-7569 deletion completed in 6.047043513s

â€¢ [SLOW TEST:16.158 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:30:25.426: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-8c514712-0c41-11ea-a569-4e55f5a7674f
STEP: Creating a pod to test consume secrets
Nov 21 09:30:25.499: INFO: Waiting up to 5m0s for pod "pod-secrets-8c538924-0c41-11ea-a569-4e55f5a7674f" in namespace "secrets-6654" to be "success or failure"
Nov 21 09:30:25.504: INFO: Pod "pod-secrets-8c538924-0c41-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.643049ms
Nov 21 09:30:27.506: INFO: Pod "pod-secrets-8c538924-0c41-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006823894s
Nov 21 09:30:29.509: INFO: Pod "pod-secrets-8c538924-0c41-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009170209s
STEP: Saw pod success
Nov 21 09:30:29.509: INFO: Pod "pod-secrets-8c538924-0c41-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 09:30:29.510: INFO: Trying to get logs from node 192.168.0.93 pod pod-secrets-8c538924-0c41-11ea-a569-4e55f5a7674f container secret-env-test: <nil>
STEP: delete the pod
Nov 21 09:30:29.528: INFO: Waiting for pod pod-secrets-8c538924-0c41-11ea-a569-4e55f5a7674f to disappear
Nov 21 09:30:29.570: INFO: Pod pod-secrets-8c538924-0c41-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:30:29.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6654" for this suite.
Nov 21 09:30:35.580: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:30:35.620: INFO: namespace secrets-6654 deletion completed in 6.047612623s

â€¢ [SLOW TEST:10.194 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:30:35.620: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test env composition
Nov 21 09:30:35.694: INFO: Waiting up to 5m0s for pod "var-expansion-9267663a-0c41-11ea-a569-4e55f5a7674f" in namespace "var-expansion-3297" to be "success or failure"
Nov 21 09:30:35.699: INFO: Pod "var-expansion-9267663a-0c41-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.607019ms
Nov 21 09:30:37.716: INFO: Pod "var-expansion-9267663a-0c41-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022093158s
Nov 21 09:30:39.718: INFO: Pod "var-expansion-9267663a-0c41-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024461925s
STEP: Saw pod success
Nov 21 09:30:39.719: INFO: Pod "var-expansion-9267663a-0c41-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 09:30:39.720: INFO: Trying to get logs from node 192.168.0.92 pod var-expansion-9267663a-0c41-11ea-a569-4e55f5a7674f container dapi-container: <nil>
STEP: delete the pod
Nov 21 09:30:39.744: INFO: Waiting for pod var-expansion-9267663a-0c41-11ea-a569-4e55f5a7674f to disappear
Nov 21 09:30:39.750: INFO: Pod var-expansion-9267663a-0c41-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:30:39.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3297" for this suite.
Nov 21 09:30:45.758: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:30:45.797: INFO: namespace var-expansion-3297 deletion completed in 6.044448171s

â€¢ [SLOW TEST:10.177 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:30:45.797: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1619
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov 21 09:30:45.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-7088'
Nov 21 09:30:45.942: INFO: stderr: ""
Nov 21 09:30:45.942: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Nov 21 09:30:50.992: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 get pod e2e-test-nginx-pod --namespace=kubectl-7088 -o json'
Nov 21 09:30:51.090: INFO: stderr: ""
Nov 21 09:30:51.090: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-11-21T09:30:45Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-7088\",\n        \"resourceVersion\": \"24808\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-7088/pods/e2e-test-nginx-pod\",\n        \"uid\": \"98827d1e-0c41-11ea-b617-0202c0a8005b\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-kg5xb\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"192.168.0.93\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-kg5xb\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-kg5xb\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-11-21T09:30:45Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-11-21T09:30:47Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-11-21T09:30:47Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-11-21T09:30:45Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://84a3ec58f30e9709034860ac1fd40d2b12f56a7f22f644f7a723e6df6c617f80\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://reg.mg.hcbss/devcke/nginx@sha256:d78215175f4c4257d821c76a04197f4ec8bd09e8032ae4a0465604f55a8a557c\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-11-21T09:30:47Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.0.93\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.49.166.144\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-11-21T09:30:45Z\"\n    }\n}\n"
STEP: replace the image in the pod
Nov 21 09:30:51.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 replace -f - --namespace=kubectl-7088'
Nov 21 09:30:51.291: INFO: stderr: ""
Nov 21 09:30:51.291: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1624
Nov 21 09:30:51.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 delete pods e2e-test-nginx-pod --namespace=kubectl-7088'
Nov 21 09:30:53.055: INFO: stderr: ""
Nov 21 09:30:53.055: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:30:53.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7088" for this suite.
Nov 21 09:30:59.066: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:30:59.105: INFO: namespace kubectl-7088 deletion completed in 6.045900625s

â€¢ [SLOW TEST:13.308 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:30:59.106: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Nov 21 09:30:59.164: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a062ca20-0c41-11ea-a569-4e55f5a7674f" in namespace "downward-api-2053" to be "success or failure"
Nov 21 09:30:59.173: INFO: Pod "downwardapi-volume-a062ca20-0c41-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 9.40904ms
Nov 21 09:31:01.176: INFO: Pod "downwardapi-volume-a062ca20-0c41-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011730122s
Nov 21 09:31:03.178: INFO: Pod "downwardapi-volume-a062ca20-0c41-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013804338s
STEP: Saw pod success
Nov 21 09:31:03.178: INFO: Pod "downwardapi-volume-a062ca20-0c41-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 09:31:03.179: INFO: Trying to get logs from node 192.168.0.92 pod downwardapi-volume-a062ca20-0c41-11ea-a569-4e55f5a7674f container client-container: <nil>
STEP: delete the pod
Nov 21 09:31:03.208: INFO: Waiting for pod downwardapi-volume-a062ca20-0c41-11ea-a569-4e55f5a7674f to disappear
Nov 21 09:31:03.213: INFO: Pod downwardapi-volume-a062ca20-0c41-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:31:03.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2053" for this suite.
Nov 21 09:31:09.221: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:31:09.286: INFO: namespace downward-api-2053 deletion completed in 6.071283969s

â€¢ [SLOW TEST:10.181 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:31:09.286: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Nov 21 09:31:13.904: INFO: Successfully updated pod "annotationupdatea6788fc9-0c41-11ea-a569-4e55f5a7674f"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:31:15.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4747" for this suite.
Nov 21 09:31:37.946: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:31:37.987: INFO: namespace downward-api-4747 deletion completed in 22.052579002s

â€¢ [SLOW TEST:28.701 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:31:37.988: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Nov 21 09:31:38.030: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:31:40.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2937" for this suite.
Nov 21 09:32:22.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:32:22.226: INFO: namespace pods-2937 deletion completed in 42.045378925s

â€¢ [SLOW TEST:44.239 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:32:22.226: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Nov 21 09:32:22.729: INFO: Pod name wrapped-volume-race-d22cbb64-0c41-11ea-a569-4e55f5a7674f: Found 0 pods out of 5
Nov 21 09:32:27.733: INFO: Pod name wrapped-volume-race-d22cbb64-0c41-11ea-a569-4e55f5a7674f: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-d22cbb64-0c41-11ea-a569-4e55f5a7674f in namespace emptydir-wrapper-5289, will wait for the garbage collector to delete the pods
Nov 21 09:32:37.804: INFO: Deleting ReplicationController wrapped-volume-race-d22cbb64-0c41-11ea-a569-4e55f5a7674f took: 3.247224ms
Nov 21 09:32:38.104: INFO: Terminating ReplicationController wrapped-volume-race-d22cbb64-0c41-11ea-a569-4e55f5a7674f pods took: 300.11565ms
STEP: Creating RC which spawns configmap-volume pods
Nov 21 09:33:21.753: INFO: Pod name wrapped-volume-race-f55b921a-0c41-11ea-a569-4e55f5a7674f: Found 0 pods out of 5
Nov 21 09:33:26.761: INFO: Pod name wrapped-volume-race-f55b921a-0c41-11ea-a569-4e55f5a7674f: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-f55b921a-0c41-11ea-a569-4e55f5a7674f in namespace emptydir-wrapper-5289, will wait for the garbage collector to delete the pods
Nov 21 09:33:38.851: INFO: Deleting ReplicationController wrapped-volume-race-f55b921a-0c41-11ea-a569-4e55f5a7674f took: 3.174005ms
Nov 21 09:33:39.151: INFO: Terminating ReplicationController wrapped-volume-race-f55b921a-0c41-11ea-a569-4e55f5a7674f pods took: 300.153427ms
STEP: Creating RC which spawns configmap-volume pods
Nov 21 09:34:20.793: INFO: Pod name wrapped-volume-race-188d699f-0c42-11ea-a569-4e55f5a7674f: Found 0 pods out of 5
Nov 21 09:34:25.797: INFO: Pod name wrapped-volume-race-188d699f-0c42-11ea-a569-4e55f5a7674f: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-188d699f-0c42-11ea-a569-4e55f5a7674f in namespace emptydir-wrapper-5289, will wait for the garbage collector to delete the pods
Nov 21 09:34:37.871: INFO: Deleting ReplicationController wrapped-volume-race-188d699f-0c42-11ea-a569-4e55f5a7674f took: 3.679708ms
Nov 21 09:34:38.171: INFO: Terminating ReplicationController wrapped-volume-race-188d699f-0c42-11ea-a569-4e55f5a7674f pods took: 300.178851ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:35:21.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-5289" for this suite.
Nov 21 09:35:29.275: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:35:29.315: INFO: namespace emptydir-wrapper-5289 deletion completed in 8.047134047s

â€¢ [SLOW TEST:187.089 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:35:29.316: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Nov 21 09:35:29.390: INFO: Waiting up to 5m0s for pod "downward-api-4175ccbd-0c42-11ea-a569-4e55f5a7674f" in namespace "downward-api-22" to be "success or failure"
Nov 21 09:35:29.404: INFO: Pod "downward-api-4175ccbd-0c42-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.989184ms
Nov 21 09:35:31.405: INFO: Pod "downward-api-4175ccbd-0c42-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015851579s
Nov 21 09:35:33.408: INFO: Pod "downward-api-4175ccbd-0c42-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018046529s
STEP: Saw pod success
Nov 21 09:35:33.408: INFO: Pod "downward-api-4175ccbd-0c42-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 09:35:33.409: INFO: Trying to get logs from node 192.168.0.93 pod downward-api-4175ccbd-0c42-11ea-a569-4e55f5a7674f container dapi-container: <nil>
STEP: delete the pod
Nov 21 09:35:33.430: INFO: Waiting for pod downward-api-4175ccbd-0c42-11ea-a569-4e55f5a7674f to disappear
Nov 21 09:35:33.434: INFO: Pod downward-api-4175ccbd-0c42-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:35:33.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-22" for this suite.
Nov 21 09:35:39.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:35:39.487: INFO: namespace downward-api-22 deletion completed in 6.050946726s

â€¢ [SLOW TEST:10.171 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:35:39.487: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Nov 21 09:35:39.545: INFO: Waiting up to 5m0s for pod "pod-478195ff-0c42-11ea-a569-4e55f5a7674f" in namespace "emptydir-506" to be "success or failure"
Nov 21 09:35:39.554: INFO: Pod "pod-478195ff-0c42-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 9.62092ms
Nov 21 09:35:41.634: INFO: Pod "pod-478195ff-0c42-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.088998503s
STEP: Saw pod success
Nov 21 09:35:41.634: INFO: Pod "pod-478195ff-0c42-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 09:35:41.640: INFO: Trying to get logs from node 192.168.0.92 pod pod-478195ff-0c42-11ea-a569-4e55f5a7674f container test-container: <nil>
STEP: delete the pod
Nov 21 09:35:41.653: INFO: Waiting for pod pod-478195ff-0c42-11ea-a569-4e55f5a7674f to disappear
Nov 21 09:35:41.657: INFO: Pod pod-478195ff-0c42-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:35:41.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-506" for this suite.
Nov 21 09:35:47.672: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:35:47.714: INFO: namespace emptydir-506 deletion completed in 6.05463552s

â€¢ [SLOW TEST:8.227 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:35:47.714: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-4c6c7987-0c42-11ea-a569-4e55f5a7674f
STEP: Creating a pod to test consume secrets
Nov 21 09:35:47.784: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4c6cb244-0c42-11ea-a569-4e55f5a7674f" in namespace "projected-9063" to be "success or failure"
Nov 21 09:35:47.800: INFO: Pod "pod-projected-secrets-4c6cb244-0c42-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 15.610052ms
Nov 21 09:35:49.802: INFO: Pod "pod-projected-secrets-4c6cb244-0c42-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01770701s
Nov 21 09:35:51.804: INFO: Pod "pod-projected-secrets-4c6cb244-0c42-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019916915s
STEP: Saw pod success
Nov 21 09:35:51.804: INFO: Pod "pod-projected-secrets-4c6cb244-0c42-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 09:35:51.806: INFO: Trying to get logs from node 192.168.0.93 pod pod-projected-secrets-4c6cb244-0c42-11ea-a569-4e55f5a7674f container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov 21 09:35:51.824: INFO: Waiting for pod pod-projected-secrets-4c6cb244-0c42-11ea-a569-4e55f5a7674f to disappear
Nov 21 09:35:51.829: INFO: Pod pod-projected-secrets-4c6cb244-0c42-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:35:51.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9063" for this suite.
Nov 21 09:35:57.848: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:35:57.889: INFO: namespace projected-9063 deletion completed in 6.058284124s

â€¢ [SLOW TEST:10.175 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:35:57.889: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Nov 21 09:35:57.954: INFO: Waiting up to 5m0s for pod "pod-527a3162-0c42-11ea-a569-4e55f5a7674f" in namespace "emptydir-8420" to be "success or failure"
Nov 21 09:35:57.960: INFO: Pod "pod-527a3162-0c42-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.910553ms
Nov 21 09:35:59.962: INFO: Pod "pod-527a3162-0c42-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007726875s
Nov 21 09:36:01.965: INFO: Pod "pod-527a3162-0c42-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010026846s
STEP: Saw pod success
Nov 21 09:36:01.965: INFO: Pod "pod-527a3162-0c42-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 09:36:01.966: INFO: Trying to get logs from node 192.168.0.92 pod pod-527a3162-0c42-11ea-a569-4e55f5a7674f container test-container: <nil>
STEP: delete the pod
Nov 21 09:36:02.034: INFO: Waiting for pod pod-527a3162-0c42-11ea-a569-4e55f5a7674f to disappear
Nov 21 09:36:02.040: INFO: Pod pod-527a3162-0c42-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:36:02.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8420" for this suite.
Nov 21 09:36:08.048: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:36:08.090: INFO: namespace emptydir-8420 deletion completed in 6.048053026s

â€¢ [SLOW TEST:10.201 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:36:08.091: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override command
Nov 21 09:36:08.160: INFO: Waiting up to 5m0s for pod "client-containers-588eb7be-0c42-11ea-a569-4e55f5a7674f" in namespace "containers-8870" to be "success or failure"
Nov 21 09:36:08.166: INFO: Pod "client-containers-588eb7be-0c42-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.970759ms
Nov 21 09:36:10.168: INFO: Pod "client-containers-588eb7be-0c42-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008039334s
Nov 21 09:36:12.171: INFO: Pod "client-containers-588eb7be-0c42-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010404372s
Nov 21 09:36:14.173: INFO: Pod "client-containers-588eb7be-0c42-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.012810977s
STEP: Saw pod success
Nov 21 09:36:14.173: INFO: Pod "client-containers-588eb7be-0c42-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 09:36:14.175: INFO: Trying to get logs from node 192.168.0.93 pod client-containers-588eb7be-0c42-11ea-a569-4e55f5a7674f container test-container: <nil>
STEP: delete the pod
Nov 21 09:36:14.269: INFO: Waiting for pod client-containers-588eb7be-0c42-11ea-a569-4e55f5a7674f to disappear
Nov 21 09:36:14.280: INFO: Pod client-containers-588eb7be-0c42-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:36:14.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8870" for this suite.
Nov 21 09:36:20.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:36:20.377: INFO: namespace containers-8870 deletion completed in 6.094835406s

â€¢ [SLOW TEST:12.287 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:36:20.378: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-5fe2eeb9-0c42-11ea-a569-4e55f5a7674f
STEP: Creating a pod to test consume configMaps
Nov 21 09:36:20.471: INFO: Waiting up to 5m0s for pod "pod-configmaps-5fe8ae40-0c42-11ea-a569-4e55f5a7674f" in namespace "configmap-9011" to be "success or failure"
Nov 21 09:36:20.475: INFO: Pod "pod-configmaps-5fe8ae40-0c42-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.442635ms
Nov 21 09:36:22.477: INFO: Pod "pod-configmaps-5fe8ae40-0c42-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006434009s
STEP: Saw pod success
Nov 21 09:36:22.477: INFO: Pod "pod-configmaps-5fe8ae40-0c42-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 09:36:22.481: INFO: Trying to get logs from node 192.168.0.92 pod pod-configmaps-5fe8ae40-0c42-11ea-a569-4e55f5a7674f container configmap-volume-test: <nil>
STEP: delete the pod
Nov 21 09:36:22.505: INFO: Waiting for pod pod-configmaps-5fe8ae40-0c42-11ea-a569-4e55f5a7674f to disappear
Nov 21 09:36:22.525: INFO: Pod pod-configmaps-5fe8ae40-0c42-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:36:22.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9011" for this suite.
Nov 21 09:36:28.545: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:36:28.588: INFO: namespace configmap-9011 deletion completed in 6.060944332s

â€¢ [SLOW TEST:8.211 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:36:28.588: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override arguments
Nov 21 09:36:28.657: INFO: Waiting up to 5m0s for pod "client-containers-64c77583-0c42-11ea-a569-4e55f5a7674f" in namespace "containers-9989" to be "success or failure"
Nov 21 09:36:28.664: INFO: Pod "client-containers-64c77583-0c42-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.301611ms
Nov 21 09:36:30.685: INFO: Pod "client-containers-64c77583-0c42-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027566726s
STEP: Saw pod success
Nov 21 09:36:30.685: INFO: Pod "client-containers-64c77583-0c42-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 09:36:30.687: INFO: Trying to get logs from node 192.168.0.92 pod client-containers-64c77583-0c42-11ea-a569-4e55f5a7674f container test-container: <nil>
STEP: delete the pod
Nov 21 09:36:30.722: INFO: Waiting for pod client-containers-64c77583-0c42-11ea-a569-4e55f5a7674f to disappear
Nov 21 09:36:30.727: INFO: Pod client-containers-64c77583-0c42-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:36:30.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9989" for this suite.
Nov 21 09:36:36.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:36:36.773: INFO: namespace containers-9989 deletion completed in 6.044869793s

â€¢ [SLOW TEST:8.185 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:36:36.774: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W1121 09:36:46.858097      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov 21 09:36:46.858: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:36:46.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9453" for this suite.
Nov 21 09:36:52.872: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:36:52.912: INFO: namespace gc-9453 deletion completed in 6.052407656s

â€¢ [SLOW TEST:16.138 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:36:52.913: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting the proxy server
Nov 21 09:36:53.033: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-073157133 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:36:53.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7028" for this suite.
Nov 21 09:36:59.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:36:59.168: INFO: namespace kubectl-7028 deletion completed in 6.054081274s

â€¢ [SLOW TEST:6.256 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:36:59.169: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Nov 21 09:36:59.246: INFO: Waiting up to 5m0s for pod "downwardapi-volume-77012a6a-0c42-11ea-a569-4e55f5a7674f" in namespace "downward-api-5502" to be "success or failure"
Nov 21 09:36:59.253: INFO: Pod "downwardapi-volume-77012a6a-0c42-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.077838ms
Nov 21 09:37:01.270: INFO: Pod "downwardapi-volume-77012a6a-0c42-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024468637s
STEP: Saw pod success
Nov 21 09:37:01.270: INFO: Pod "downwardapi-volume-77012a6a-0c42-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 09:37:01.282: INFO: Trying to get logs from node 192.168.0.92 pod downwardapi-volume-77012a6a-0c42-11ea-a569-4e55f5a7674f container client-container: <nil>
STEP: delete the pod
Nov 21 09:37:01.294: INFO: Waiting for pod downwardapi-volume-77012a6a-0c42-11ea-a569-4e55f5a7674f to disappear
Nov 21 09:37:01.298: INFO: Pod downwardapi-volume-77012a6a-0c42-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:37:01.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5502" for this suite.
Nov 21 09:37:07.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:37:07.391: INFO: namespace downward-api-5502 deletion completed in 6.07132879s

â€¢ [SLOW TEST:8.223 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:37:07.391: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Nov 21 09:37:07.476: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8385,SelfLink:/api/v1/namespaces/watch-8385/configmaps/e2e-watch-test-configmap-a,UID:7bed06ab-0c42-11ea-b617-0202c0a8005b,ResourceVersion:26766,Generation:0,CreationTimestamp:2019-11-21 09:37:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov 21 09:37:07.476: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8385,SelfLink:/api/v1/namespaces/watch-8385/configmaps/e2e-watch-test-configmap-a,UID:7bed06ab-0c42-11ea-b617-0202c0a8005b,ResourceVersion:26766,Generation:0,CreationTimestamp:2019-11-21 09:37:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Nov 21 09:37:17.480: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8385,SelfLink:/api/v1/namespaces/watch-8385/configmaps/e2e-watch-test-configmap-a,UID:7bed06ab-0c42-11ea-b617-0202c0a8005b,ResourceVersion:26781,Generation:0,CreationTimestamp:2019-11-21 09:37:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Nov 21 09:37:17.480: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8385,SelfLink:/api/v1/namespaces/watch-8385/configmaps/e2e-watch-test-configmap-a,UID:7bed06ab-0c42-11ea-b617-0202c0a8005b,ResourceVersion:26781,Generation:0,CreationTimestamp:2019-11-21 09:37:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Nov 21 09:37:27.483: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8385,SelfLink:/api/v1/namespaces/watch-8385/configmaps/e2e-watch-test-configmap-a,UID:7bed06ab-0c42-11ea-b617-0202c0a8005b,ResourceVersion:26796,Generation:0,CreationTimestamp:2019-11-21 09:37:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov 21 09:37:27.483: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8385,SelfLink:/api/v1/namespaces/watch-8385/configmaps/e2e-watch-test-configmap-a,UID:7bed06ab-0c42-11ea-b617-0202c0a8005b,ResourceVersion:26796,Generation:0,CreationTimestamp:2019-11-21 09:37:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Nov 21 09:37:37.487: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8385,SelfLink:/api/v1/namespaces/watch-8385/configmaps/e2e-watch-test-configmap-a,UID:7bed06ab-0c42-11ea-b617-0202c0a8005b,ResourceVersion:26812,Generation:0,CreationTimestamp:2019-11-21 09:37:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov 21 09:37:37.487: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8385,SelfLink:/api/v1/namespaces/watch-8385/configmaps/e2e-watch-test-configmap-a,UID:7bed06ab-0c42-11ea-b617-0202c0a8005b,ResourceVersion:26812,Generation:0,CreationTimestamp:2019-11-21 09:37:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Nov 21 09:37:47.491: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-8385,SelfLink:/api/v1/namespaces/watch-8385/configmaps/e2e-watch-test-configmap-b,UID:93c6fffa-0c42-11ea-b617-0202c0a8005b,ResourceVersion:26827,Generation:0,CreationTimestamp:2019-11-21 09:37:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov 21 09:37:47.491: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-8385,SelfLink:/api/v1/namespaces/watch-8385/configmaps/e2e-watch-test-configmap-b,UID:93c6fffa-0c42-11ea-b617-0202c0a8005b,ResourceVersion:26827,Generation:0,CreationTimestamp:2019-11-21 09:37:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Nov 21 09:37:57.495: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-8385,SelfLink:/api/v1/namespaces/watch-8385/configmaps/e2e-watch-test-configmap-b,UID:93c6fffa-0c42-11ea-b617-0202c0a8005b,ResourceVersion:26842,Generation:0,CreationTimestamp:2019-11-21 09:37:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov 21 09:37:57.495: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-8385,SelfLink:/api/v1/namespaces/watch-8385/configmaps/e2e-watch-test-configmap-b,UID:93c6fffa-0c42-11ea-b617-0202c0a8005b,ResourceVersion:26842,Generation:0,CreationTimestamp:2019-11-21 09:37:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:38:07.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8385" for this suite.
Nov 21 09:38:13.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:38:13.555: INFO: namespace watch-8385 deletion completed in 6.057240394s

â€¢ [SLOW TEST:66.164 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:38:13.555: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:38:17.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2556" for this suite.
Nov 21 09:38:55.667: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:38:55.755: INFO: namespace kubelet-test-2556 deletion completed in 38.099119496s

â€¢ [SLOW TEST:42.200 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:38:55.755: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Nov 21 09:38:55.809: INFO: Creating deployment "nginx-deployment"
Nov 21 09:38:55.814: INFO: Waiting for observed generation 1
Nov 21 09:38:57.840: INFO: Waiting for all required pods to come up
Nov 21 09:38:57.856: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Nov 21 09:38:59.863: INFO: Waiting for deployment "nginx-deployment" to complete
Nov 21 09:38:59.867: INFO: Updating deployment "nginx-deployment" with a non-existent image
Nov 21 09:38:59.870: INFO: Updating deployment nginx-deployment
Nov 21 09:38:59.870: INFO: Waiting for observed generation 2
Nov 21 09:39:01.880: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Nov 21 09:39:01.881: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Nov 21 09:39:01.882: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Nov 21 09:39:01.886: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Nov 21 09:39:01.886: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Nov 21 09:39:01.887: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Nov 21 09:39:01.890: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Nov 21 09:39:01.890: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Nov 21 09:39:01.893: INFO: Updating deployment nginx-deployment
Nov 21 09:39:01.893: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Nov 21 09:39:01.925: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Nov 21 09:39:01.927: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Nov 21 09:39:02.073: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-5503,SelfLink:/apis/apps/v1/namespaces/deployment-5503/deployments/nginx-deployment,UID:bc7ffb92-0c42-11ea-b617-0202c0a8005b,ResourceVersion:27223,Generation:3,CreationTimestamp:2019-11-21 09:38:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Progressing True 2019-11-21 09:39:00 +0000 UTC 2019-11-21 09:38:55 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-5f9595f595" is progressing.} {Available False 2019-11-21 09:39:01 +0000 UTC 2019-11-21 09:39:01 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Nov 21 09:39:02.125: INFO: New ReplicaSet "nginx-deployment-5f9595f595" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595,GenerateName:,Namespace:deployment-5503,SelfLink:/apis/apps/v1/namespaces/deployment-5503/replicasets/nginx-deployment-5f9595f595,UID:beebb39e-0c42-11ea-b617-0202c0a8005b,ResourceVersion:27256,Generation:3,CreationTimestamp:2019-11-21 09:38:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment bc7ffb92-0c42-11ea-b617-0202c0a8005b 0xc001871b87 0xc001871b88}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov 21 09:39:02.125: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Nov 21 09:39:02.125: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8,GenerateName:,Namespace:deployment-5503,SelfLink:/apis/apps/v1/namespaces/deployment-5503/replicasets/nginx-deployment-6f478d8d8,UID:bc80c1ba-0c42-11ea-b617-0202c0a8005b,ResourceVersion:27257,Generation:3,CreationTimestamp:2019-11-21 09:38:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment bc7ffb92-0c42-11ea-b617-0202c0a8005b 0xc001871c77 0xc001871c78}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Nov 21 09:39:02.174: INFO: Pod "nginx-deployment-5f9595f595-4gdg8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-4gdg8,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-5503,SelfLink:/api/v1/namespaces/deployment-5503/pods/nginx-deployment-5f9595f595-4gdg8,UID:c0285bc3-0c42-11ea-b617-0202c0a8005b,ResourceVersion:27241,Generation:0,CreationTimestamp:2019-11-21 09:39:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 beebb39e-0c42-11ea-b617-0202c0a8005b 0xc0025caba7 0xc0025caba8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9rkdw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9rkdw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9rkdw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.93,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025cad00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025cad20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:39:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 21 09:39:02.174: INFO: Pod "nginx-deployment-5f9595f595-4kcm5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-4kcm5,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-5503,SelfLink:/api/v1/namespaces/deployment-5503/pods/nginx-deployment-5f9595f595-4kcm5,UID:c0259489-0c42-11ea-b617-0202c0a8005b,ResourceVersion:27228,Generation:0,CreationTimestamp:2019-11-21 09:39:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 beebb39e-0c42-11ea-b617-0202c0a8005b 0xc0025cae70 0xc0025cae71}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9rkdw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9rkdw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9rkdw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.92,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025caf70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025caf90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:39:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 21 09:39:02.174: INFO: Pod "nginx-deployment-5f9595f595-5qkc4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-5qkc4,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-5503,SelfLink:/api/v1/namespaces/deployment-5503/pods/nginx-deployment-5f9595f595-5qkc4,UID:c025320d-0c42-11ea-b617-0202c0a8005b,ResourceVersion:27261,Generation:0,CreationTimestamp:2019-11-21 09:39:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 beebb39e-0c42-11ea-b617-0202c0a8005b 0xc0025cb130 0xc0025cb131}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9rkdw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9rkdw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9rkdw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.93,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025cb1d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025cb260}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:39:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:39:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:39:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:39:01 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.93,PodIP:,StartTime:2019-11-21 09:39:02 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 21 09:39:02.175: INFO: Pod "nginx-deployment-5f9595f595-8rxtk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-8rxtk,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-5503,SelfLink:/api/v1/namespaces/deployment-5503/pods/nginx-deployment-5f9595f595-8rxtk,UID:beefc2f4-0c42-11ea-b617-0202c0a8005b,ResourceVersion:27168,Generation:0,CreationTimestamp:2019-11-21 09:38:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 beebb39e-0c42-11ea-b617-0202c0a8005b 0xc0025cb3f0 0xc0025cb3f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9rkdw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9rkdw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9rkdw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.92,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025cb550} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025cb570}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:39:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:39:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:39:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:38:59 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.92,PodIP:,StartTime:2019-11-21 09:39:00 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 21 09:39:02.175: INFO: Pod "nginx-deployment-5f9595f595-dm5qf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-dm5qf,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-5503,SelfLink:/api/v1/namespaces/deployment-5503/pods/nginx-deployment-5f9595f595-dm5qf,UID:c02be992-0c42-11ea-b617-0202c0a8005b,ResourceVersion:27247,Generation:0,CreationTimestamp:2019-11-21 09:39:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 beebb39e-0c42-11ea-b617-0202c0a8005b 0xc0025cb7c0 0xc0025cb7c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9rkdw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9rkdw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9rkdw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.93,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025cb880} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025cb8d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:39:02 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 21 09:39:02.175: INFO: Pod "nginx-deployment-5f9595f595-g65kr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-g65kr,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-5503,SelfLink:/api/v1/namespaces/deployment-5503/pods/nginx-deployment-5f9595f595-g65kr,UID:c0285501-0c42-11ea-b617-0202c0a8005b,ResourceVersion:27232,Generation:0,CreationTimestamp:2019-11-21 09:39:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 beebb39e-0c42-11ea-b617-0202c0a8005b 0xc0025cb9c0 0xc0025cb9c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9rkdw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9rkdw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9rkdw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.92,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025cba50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025cbad0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:39:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 21 09:39:02.175: INFO: Pod "nginx-deployment-5f9595f595-hfsxx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-hfsxx,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-5503,SelfLink:/api/v1/namespaces/deployment-5503/pods/nginx-deployment-5f9595f595-hfsxx,UID:beecc69a-0c42-11ea-b617-0202c0a8005b,ResourceVersion:27200,Generation:0,CreationTimestamp:2019-11-21 09:38:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 beebb39e-0c42-11ea-b617-0202c0a8005b 0xc0025cbc10 0xc0025cbc11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9rkdw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9rkdw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9rkdw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.92,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025cbd00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025cbd90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:38:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:38:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:38:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:38:59 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.92,PodIP:172.49.135.173,StartTime:2019-11-21 09:38:59 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: Get https://registry-1.docker.io/v2/: dial tcp: lookup registry-1.docker.io on [::1]:53: dial udp [::1]:53: connect: cannot assign requested address,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 21 09:39:02.175: INFO: Pod "nginx-deployment-5f9595f595-klbgx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-klbgx,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-5503,SelfLink:/api/v1/namespaces/deployment-5503/pods/nginx-deployment-5f9595f595-klbgx,UID:beefbe73-0c42-11ea-b617-0202c0a8005b,ResourceVersion:27151,Generation:0,CreationTimestamp:2019-11-21 09:38:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 beebb39e-0c42-11ea-b617-0202c0a8005b 0xc0025cbe80 0xc0025cbe81}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9rkdw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9rkdw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9rkdw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.93,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025cbf00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025cbf20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:38:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:38:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:38:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:38:59 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.93,PodIP:,StartTime:2019-11-21 09:38:59 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 21 09:39:02.175: INFO: Pod "nginx-deployment-5f9595f595-kv426" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-kv426,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-5503,SelfLink:/api/v1/namespaces/deployment-5503/pods/nginx-deployment-5f9595f595-kv426,UID:bf007891-0c42-11ea-b617-0202c0a8005b,ResourceVersion:27172,Generation:0,CreationTimestamp:2019-11-21 09:39:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 beebb39e-0c42-11ea-b617-0202c0a8005b 0xc0025cbff0 0xc0025cbff1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9rkdw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9rkdw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9rkdw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.93,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00334e070} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00334e090}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:39:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:39:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:39:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:39:00 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.93,PodIP:,StartTime:2019-11-21 09:39:00 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 21 09:39:02.175: INFO: Pod "nginx-deployment-5f9595f595-nz4wc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-nz4wc,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-5503,SelfLink:/api/v1/namespaces/deployment-5503/pods/nginx-deployment-5f9595f595-nz4wc,UID:c0285de1-0c42-11ea-b617-0202c0a8005b,ResourceVersion:27242,Generation:0,CreationTimestamp:2019-11-21 09:39:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 beebb39e-0c42-11ea-b617-0202c0a8005b 0xc00334e160 0xc00334e161}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9rkdw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9rkdw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9rkdw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.92,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00334e1e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00334e200}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:39:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 21 09:39:02.176: INFO: Pod "nginx-deployment-5f9595f595-r6jmj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-r6jmj,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-5503,SelfLink:/api/v1/namespaces/deployment-5503/pods/nginx-deployment-5f9595f595-r6jmj,UID:c02586ba-0c42-11ea-b617-0202c0a8005b,ResourceVersion:27226,Generation:0,CreationTimestamp:2019-11-21 09:39:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 beebb39e-0c42-11ea-b617-0202c0a8005b 0xc00334e280 0xc00334e281}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9rkdw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9rkdw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9rkdw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.93,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00334e300} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00334e320}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:39:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 21 09:39:02.176: INFO: Pod "nginx-deployment-5f9595f595-snksn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-snksn,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-5503,SelfLink:/api/v1/namespaces/deployment-5503/pods/nginx-deployment-5f9595f595-snksn,UID:c0285f48-0c42-11ea-b617-0202c0a8005b,ResourceVersion:27243,Generation:0,CreationTimestamp:2019-11-21 09:39:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 beebb39e-0c42-11ea-b617-0202c0a8005b 0xc00334e3a0 0xc00334e3a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9rkdw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9rkdw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9rkdw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.93,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00334e420} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00334e440}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:39:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 21 09:39:02.176: INFO: Pod "nginx-deployment-5f9595f595-vvbd6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-vvbd6,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-5503,SelfLink:/api/v1/namespaces/deployment-5503/pods/nginx-deployment-5f9595f595-vvbd6,UID:bf0407cd-0c42-11ea-b617-0202c0a8005b,ResourceVersion:27174,Generation:0,CreationTimestamp:2019-11-21 09:39:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 beebb39e-0c42-11ea-b617-0202c0a8005b 0xc00334e4c0 0xc00334e4c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9rkdw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9rkdw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9rkdw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.92,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00334e540} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00334e560}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:39:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:39:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:39:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:39:00 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.92,PodIP:,StartTime:2019-11-21 09:39:00 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 21 09:39:02.176: INFO: Pod "nginx-deployment-6f478d8d8-2g4jp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-2g4jp,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5503,SelfLink:/api/v1/namespaces/deployment-5503/pods/nginx-deployment-6f478d8d8-2g4jp,UID:bc898417-0c42-11ea-b617-0202c0a8005b,ResourceVersion:27101,Generation:0,CreationTimestamp:2019-11-21 09:38:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 bc80c1ba-0c42-11ea-b617-0202c0a8005b 0xc00334e630 0xc00334e631}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9rkdw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9rkdw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9rkdw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.93,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00334e6a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00334e6c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:38:55 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:38:58 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:38:58 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:38:55 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.93,PodIP:172.49.166.149,StartTime:2019-11-21 09:38:55 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-11-21 09:38:58 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://reg.mg.hcbss/devcke/nginx@sha256:d78215175f4c4257d821c76a04197f4ec8bd09e8032ae4a0465604f55a8a557c docker://12c692c9ad08039775d41943c5906586c9fdf259fb5c9f2265ead4599afdd60b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 21 09:39:02.176: INFO: Pod "nginx-deployment-6f478d8d8-67dnn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-67dnn,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5503,SelfLink:/api/v1/namespaces/deployment-5503/pods/nginx-deployment-6f478d8d8-67dnn,UID:c02beb70-0c42-11ea-b617-0202c0a8005b,ResourceVersion:27248,Generation:0,CreationTimestamp:2019-11-21 09:39:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 bc80c1ba-0c42-11ea-b617-0202c0a8005b 0xc00334e797 0xc00334e798}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9rkdw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9rkdw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9rkdw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.93,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00334e810} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00334e830}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:39:02 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 21 09:39:02.176: INFO: Pod "nginx-deployment-6f478d8d8-6ghk6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-6ghk6,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5503,SelfLink:/api/v1/namespaces/deployment-5503/pods/nginx-deployment-6f478d8d8-6ghk6,UID:bc8991cc-0c42-11ea-b617-0202c0a8005b,ResourceVersion:27120,Generation:0,CreationTimestamp:2019-11-21 09:38:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 bc80c1ba-0c42-11ea-b617-0202c0a8005b 0xc00334e8b0 0xc00334e8b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9rkdw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9rkdw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9rkdw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.92,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00334e920} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00334e940}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:38:56 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:38:58 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:38:58 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:38:55 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.92,PodIP:172.49.135.171,StartTime:2019-11-21 09:38:56 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-11-21 09:38:58 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://reg.mg.hcbss/devcke/nginx@sha256:d78215175f4c4257d821c76a04197f4ec8bd09e8032ae4a0465604f55a8a557c docker://bd72f73e3dc85e667aeb454e2a664efdd0514b921983eafa5d376824d01f2381}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 21 09:39:02.176: INFO: Pod "nginx-deployment-6f478d8d8-6hvtl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-6hvtl,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5503,SelfLink:/api/v1/namespaces/deployment-5503/pods/nginx-deployment-6f478d8d8-6hvtl,UID:c02bf43a-0c42-11ea-b617-0202c0a8005b,ResourceVersion:27249,Generation:0,CreationTimestamp:2019-11-21 09:39:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 bc80c1ba-0c42-11ea-b617-0202c0a8005b 0xc00334ea17 0xc00334ea18}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9rkdw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9rkdw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9rkdw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.93,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00334ea90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00334eab0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:39:02 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 21 09:39:02.176: INFO: Pod "nginx-deployment-6f478d8d8-c9dbf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-c9dbf,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5503,SelfLink:/api/v1/namespaces/deployment-5503/pods/nginx-deployment-6f478d8d8-c9dbf,UID:c02bff7e-0c42-11ea-b617-0202c0a8005b,ResourceVersion:27254,Generation:0,CreationTimestamp:2019-11-21 09:39:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 bc80c1ba-0c42-11ea-b617-0202c0a8005b 0xc00334eb30 0xc00334eb31}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9rkdw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9rkdw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9rkdw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.92,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00334eba0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00334ebc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:39:02 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 21 09:39:02.176: INFO: Pod "nginx-deployment-6f478d8d8-ccq6g" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-ccq6g,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5503,SelfLink:/api/v1/namespaces/deployment-5503/pods/nginx-deployment-6f478d8d8-ccq6g,UID:bc8da8b4-0c42-11ea-b617-0202c0a8005b,ResourceVersion:27097,Generation:0,CreationTimestamp:2019-11-21 09:38:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 bc80c1ba-0c42-11ea-b617-0202c0a8005b 0xc00334ec50 0xc00334ec51}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9rkdw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9rkdw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9rkdw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.93,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00334ecc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00334ece0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:38:56 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:38:58 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:38:58 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:38:55 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.93,PodIP:172.49.166.155,StartTime:2019-11-21 09:38:56 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-11-21 09:38:58 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://reg.mg.hcbss/devcke/nginx@sha256:d78215175f4c4257d821c76a04197f4ec8bd09e8032ae4a0465604f55a8a557c docker://aee4f8732440b95b0bd6a10ab38b1c0437d3139ab887b66d93e669cea5385029}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 21 09:39:02.177: INFO: Pod "nginx-deployment-6f478d8d8-dnchw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-dnchw,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5503,SelfLink:/api/v1/namespaces/deployment-5503/pods/nginx-deployment-6f478d8d8-dnchw,UID:c02850ec-0c42-11ea-b617-0202c0a8005b,ResourceVersion:27230,Generation:0,CreationTimestamp:2019-11-21 09:39:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 bc80c1ba-0c42-11ea-b617-0202c0a8005b 0xc00334edb7 0xc00334edb8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9rkdw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9rkdw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9rkdw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.93,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00334ee30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00334ee50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:39:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 21 09:39:02.177: INFO: Pod "nginx-deployment-6f478d8d8-dsmc2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-dsmc2,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5503,SelfLink:/api/v1/namespaces/deployment-5503/pods/nginx-deployment-6f478d8d8-dsmc2,UID:c02547eb-0c42-11ea-b617-0202c0a8005b,ResourceVersion:27218,Generation:0,CreationTimestamp:2019-11-21 09:39:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 bc80c1ba-0c42-11ea-b617-0202c0a8005b 0xc00334eed0 0xc00334eed1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9rkdw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9rkdw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9rkdw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.92,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00334ef40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00334ef60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:39:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 21 09:39:02.177: INFO: Pod "nginx-deployment-6f478d8d8-ljvxr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-ljvxr,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5503,SelfLink:/api/v1/namespaces/deployment-5503/pods/nginx-deployment-6f478d8d8-ljvxr,UID:c0253ee9-0c42-11ea-b617-0202c0a8005b,ResourceVersion:27215,Generation:0,CreationTimestamp:2019-11-21 09:39:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 bc80c1ba-0c42-11ea-b617-0202c0a8005b 0xc00334efe0 0xc00334efe1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9rkdw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9rkdw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9rkdw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.92,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00334f050} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00334f070}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:39:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 21 09:39:02.177: INFO: Pod "nginx-deployment-6f478d8d8-msd8t" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-msd8t,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5503,SelfLink:/api/v1/namespaces/deployment-5503/pods/nginx-deployment-6f478d8d8-msd8t,UID:bc8da0d3-0c42-11ea-b617-0202c0a8005b,ResourceVersion:27110,Generation:0,CreationTimestamp:2019-11-21 09:38:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 bc80c1ba-0c42-11ea-b617-0202c0a8005b 0xc00334f0f0 0xc00334f0f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9rkdw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9rkdw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9rkdw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.93,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00334f160} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00334f180}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:38:56 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:38:58 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:38:58 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:38:55 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.93,PodIP:172.49.166.151,StartTime:2019-11-21 09:38:56 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-11-21 09:38:58 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://reg.mg.hcbss/devcke/nginx@sha256:d78215175f4c4257d821c76a04197f4ec8bd09e8032ae4a0465604f55a8a557c docker://a7075f51b41b7cc6c6867e90b262b8857aed019189f91e6792fd47b2c0cc3ae3}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 21 09:39:02.177: INFO: Pod "nginx-deployment-6f478d8d8-mwltw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-mwltw,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5503,SelfLink:/api/v1/namespaces/deployment-5503/pods/nginx-deployment-6f478d8d8-mwltw,UID:c0209c91-0c42-11ea-b617-0202c0a8005b,ResourceVersion:27258,Generation:0,CreationTimestamp:2019-11-21 09:39:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 bc80c1ba-0c42-11ea-b617-0202c0a8005b 0xc00334f257 0xc00334f258}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9rkdw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9rkdw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9rkdw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.92,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00334f2d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00334f2f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:39:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:39:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:39:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:39:01 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.92,PodIP:,StartTime:2019-11-21 09:39:01 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 21 09:39:02.177: INFO: Pod "nginx-deployment-6f478d8d8-n9w5v" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-n9w5v,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5503,SelfLink:/api/v1/namespaces/deployment-5503/pods/nginx-deployment-6f478d8d8-n9w5v,UID:c02bf63f-0c42-11ea-b617-0202c0a8005b,ResourceVersion:27252,Generation:0,CreationTimestamp:2019-11-21 09:39:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 bc80c1ba-0c42-11ea-b617-0202c0a8005b 0xc00334f3b7 0xc00334f3b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9rkdw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9rkdw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9rkdw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.92,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00334f430} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00334f450}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:39:02 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 21 09:39:02.177: INFO: Pod "nginx-deployment-6f478d8d8-p4kz7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-p4kz7,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5503,SelfLink:/api/v1/namespaces/deployment-5503/pods/nginx-deployment-6f478d8d8-p4kz7,UID:c0285b90-0c42-11ea-b617-0202c0a8005b,ResourceVersion:27240,Generation:0,CreationTimestamp:2019-11-21 09:39:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 bc80c1ba-0c42-11ea-b617-0202c0a8005b 0xc00334f4d0 0xc00334f4d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9rkdw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9rkdw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9rkdw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.92,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00334f540} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00334f560}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:39:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 21 09:39:02.177: INFO: Pod "nginx-deployment-6f478d8d8-pfmck" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-pfmck,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5503,SelfLink:/api/v1/namespaces/deployment-5503/pods/nginx-deployment-6f478d8d8-pfmck,UID:c0285b25-0c42-11ea-b617-0202c0a8005b,ResourceVersion:27238,Generation:0,CreationTimestamp:2019-11-21 09:39:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 bc80c1ba-0c42-11ea-b617-0202c0a8005b 0xc00334f5e0 0xc00334f5e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9rkdw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9rkdw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9rkdw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.93,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00334f660} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00334f680}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:39:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 21 09:39:02.177: INFO: Pod "nginx-deployment-6f478d8d8-pfzb2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-pfzb2,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5503,SelfLink:/api/v1/namespaces/deployment-5503/pods/nginx-deployment-6f478d8d8-pfzb2,UID:c02bf8ee-0c42-11ea-b617-0202c0a8005b,ResourceVersion:27253,Generation:0,CreationTimestamp:2019-11-21 09:39:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 bc80c1ba-0c42-11ea-b617-0202c0a8005b 0xc00334f700 0xc00334f701}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9rkdw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9rkdw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9rkdw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.93,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00334f770} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00334f790}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:39:02 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 21 09:39:02.178: INFO: Pod "nginx-deployment-6f478d8d8-rzh85" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-rzh85,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5503,SelfLink:/api/v1/namespaces/deployment-5503/pods/nginx-deployment-6f478d8d8-rzh85,UID:bc898ee1-0c42-11ea-b617-0202c0a8005b,ResourceVersion:27093,Generation:0,CreationTimestamp:2019-11-21 09:38:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 bc80c1ba-0c42-11ea-b617-0202c0a8005b 0xc00334f810 0xc00334f811}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9rkdw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9rkdw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9rkdw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.93,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00334f880} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00334f8a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:38:55 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:38:58 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:38:58 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:38:55 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.93,PodIP:172.49.166.150,StartTime:2019-11-21 09:38:55 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-11-21 09:38:58 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://reg.mg.hcbss/devcke/nginx@sha256:d78215175f4c4257d821c76a04197f4ec8bd09e8032ae4a0465604f55a8a557c docker://4a3b57a11ee10bd998f19a9aa558f94a964eabfcda84c3f10dafe642f72de810}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 21 09:39:02.178: INFO: Pod "nginx-deployment-6f478d8d8-sb6j4" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-sb6j4,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5503,SelfLink:/api/v1/namespaces/deployment-5503/pods/nginx-deployment-6f478d8d8-sb6j4,UID:bc898f1b-0c42-11ea-b617-0202c0a8005b,ResourceVersion:27117,Generation:0,CreationTimestamp:2019-11-21 09:38:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 bc80c1ba-0c42-11ea-b617-0202c0a8005b 0xc00334f977 0xc00334f978}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9rkdw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9rkdw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9rkdw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.92,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00334f9f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00334fa10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:38:56 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:38:58 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:38:58 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:38:55 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.92,PodIP:172.49.135.170,StartTime:2019-11-21 09:38:56 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-11-21 09:38:58 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://reg.mg.hcbss/devcke/nginx@sha256:d78215175f4c4257d821c76a04197f4ec8bd09e8032ae4a0465604f55a8a557c docker://ab99f6c476766d5dafc914b2bc785023b6e1cdf066a2d6a30d1dc80d0bd3beac}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 21 09:39:02.178: INFO: Pod "nginx-deployment-6f478d8d8-sh7zr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-sh7zr,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5503,SelfLink:/api/v1/namespaces/deployment-5503/pods/nginx-deployment-6f478d8d8-sh7zr,UID:c0285fb1-0c42-11ea-b617-0202c0a8005b,ResourceVersion:27244,Generation:0,CreationTimestamp:2019-11-21 09:39:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 bc80c1ba-0c42-11ea-b617-0202c0a8005b 0xc00334fae7 0xc00334fae8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9rkdw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9rkdw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9rkdw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.92,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00334fb60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00334fb80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:39:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 21 09:39:02.178: INFO: Pod "nginx-deployment-6f478d8d8-tknk7" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-tknk7,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5503,SelfLink:/api/v1/namespaces/deployment-5503/pods/nginx-deployment-6f478d8d8-tknk7,UID:bc883fc4-0c42-11ea-b617-0202c0a8005b,ResourceVersion:27104,Generation:0,CreationTimestamp:2019-11-21 09:38:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 bc80c1ba-0c42-11ea-b617-0202c0a8005b 0xc00334fc00 0xc00334fc01}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9rkdw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9rkdw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9rkdw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.93,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00334fc70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00334fc90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:38:55 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:38:58 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:38:58 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:38:55 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.93,PodIP:172.49.166.148,StartTime:2019-11-21 09:38:55 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-11-21 09:38:58 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://reg.mg.hcbss/devcke/nginx@sha256:d78215175f4c4257d821c76a04197f4ec8bd09e8032ae4a0465604f55a8a557c docker://35c65f8f69bc81cea57c7daa3625f5e67ad8a850344224943e1ad0f938accf17}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 21 09:39:02.178: INFO: Pod "nginx-deployment-6f478d8d8-wn6ht" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-wn6ht,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5503,SelfLink:/api/v1/namespaces/deployment-5503/pods/nginx-deployment-6f478d8d8-wn6ht,UID:bc8da321-0c42-11ea-b617-0202c0a8005b,ResourceVersion:27108,Generation:0,CreationTimestamp:2019-11-21 09:38:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 bc80c1ba-0c42-11ea-b617-0202c0a8005b 0xc00334fd67 0xc00334fd68}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9rkdw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9rkdw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9rkdw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.92,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00334fde0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00334fe00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:38:56 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:38:58 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:38:58 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-21 09:38:55 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.92,PodIP:172.49.135.172,StartTime:2019-11-21 09:38:56 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-11-21 09:38:58 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://reg.mg.hcbss/devcke/nginx@sha256:d78215175f4c4257d821c76a04197f4ec8bd09e8032ae4a0465604f55a8a557c docker://d3393e1436f6b139755a11fde8e501122d1bf88710b0c404893b478ebabc0a10}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:39:02.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5503" for this suite.
Nov 21 09:39:10.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:39:10.399: INFO: namespace deployment-5503 deletion completed in 8.176618512s

â€¢ [SLOW TEST:14.644 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:39:10.400: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-c53da66f-0c42-11ea-a569-4e55f5a7674f
STEP: Creating a pod to test consume configMaps
Nov 21 09:39:10.482: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c53deae1-0c42-11ea-a569-4e55f5a7674f" in namespace "projected-443" to be "success or failure"
Nov 21 09:39:10.486: INFO: Pod "pod-projected-configmaps-c53deae1-0c42-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.492208ms
Nov 21 09:39:12.488: INFO: Pod "pod-projected-configmaps-c53deae1-0c42-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006287195s
Nov 21 09:39:14.490: INFO: Pod "pod-projected-configmaps-c53deae1-0c42-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008183057s
STEP: Saw pod success
Nov 21 09:39:14.490: INFO: Pod "pod-projected-configmaps-c53deae1-0c42-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 09:39:14.492: INFO: Trying to get logs from node 192.168.0.93 pod pod-projected-configmaps-c53deae1-0c42-11ea-a569-4e55f5a7674f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 21 09:39:14.566: INFO: Waiting for pod pod-projected-configmaps-c53deae1-0c42-11ea-a569-4e55f5a7674f to disappear
Nov 21 09:39:14.572: INFO: Pod pod-projected-configmaps-c53deae1-0c42-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:39:14.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-443" for this suite.
Nov 21 09:39:20.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:39:20.644: INFO: namespace projected-443 deletion completed in 6.069939496s

â€¢ [SLOW TEST:10.244 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:39:20.644: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating api versions
Nov 21 09:39:20.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 api-versions'
Nov 21 09:39:20.817: INFO: stderr: ""
Nov 21 09:39:20.818: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:39:20.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-421" for this suite.
Nov 21 09:39:26.825: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:39:26.879: INFO: namespace kubectl-421 deletion completed in 6.059474749s

â€¢ [SLOW TEST:6.235 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:39:26.879: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Nov 21 09:39:26.939: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cf0c7fd1-0c42-11ea-a569-4e55f5a7674f" in namespace "projected-7274" to be "success or failure"
Nov 21 09:39:26.944: INFO: Pod "downwardapi-volume-cf0c7fd1-0c42-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.692075ms
Nov 21 09:39:28.946: INFO: Pod "downwardapi-volume-cf0c7fd1-0c42-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006770964s
Nov 21 09:39:30.948: INFO: Pod "downwardapi-volume-cf0c7fd1-0c42-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00878525s
STEP: Saw pod success
Nov 21 09:39:30.948: INFO: Pod "downwardapi-volume-cf0c7fd1-0c42-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 09:39:30.949: INFO: Trying to get logs from node 192.168.0.93 pod downwardapi-volume-cf0c7fd1-0c42-11ea-a569-4e55f5a7674f container client-container: <nil>
STEP: delete the pod
Nov 21 09:39:30.962: INFO: Waiting for pod downwardapi-volume-cf0c7fd1-0c42-11ea-a569-4e55f5a7674f to disappear
Nov 21 09:39:30.966: INFO: Pod downwardapi-volume-cf0c7fd1-0c42-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:39:30.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7274" for this suite.
Nov 21 09:39:36.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:39:37.014: INFO: namespace projected-7274 deletion completed in 6.045426963s

â€¢ [SLOW TEST:10.134 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:39:37.014: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: executing a command with run --rm and attach with stdin
Nov 21 09:39:37.076: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-073157133 --namespace=kubectl-4568 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Nov 21 09:39:40.369: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Nov 21 09:39:40.369: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:39:42.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4568" for this suite.
Nov 21 09:39:54.387: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:39:54.428: INFO: namespace kubectl-4568 deletion completed in 12.053689368s

â€¢ [SLOW TEST:17.414 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:39:54.428: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Nov 21 09:39:54.539: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Nov 21 09:40:03.566: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:40:03.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2898" for this suite.
Nov 21 09:40:09.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:40:09.639: INFO: namespace pods-2898 deletion completed in 6.068708414s

â€¢ [SLOW TEST:15.211 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:40:09.639: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5513.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5513.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov 21 09:40:13.738: INFO: DNS probes using dns-5513/dns-test-e88815d5-0c42-11ea-a569-4e55f5a7674f succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:40:13.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5513" for this suite.
Nov 21 09:40:19.819: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:40:19.858: INFO: namespace dns-5513 deletion completed in 6.077093259s

â€¢ [SLOW TEST:10.219 seconds]
[sig-network] DNS
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:40:19.858: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-projected-s5kf
STEP: Creating a pod to test atomic-volume-subpath
Nov 21 09:40:19.939: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-s5kf" in namespace "subpath-6719" to be "success or failure"
Nov 21 09:40:19.958: INFO: Pod "pod-subpath-test-projected-s5kf": Phase="Pending", Reason="", readiness=false. Elapsed: 19.076493ms
Nov 21 09:40:21.960: INFO: Pod "pod-subpath-test-projected-s5kf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021071485s
Nov 21 09:40:23.962: INFO: Pod "pod-subpath-test-projected-s5kf": Phase="Running", Reason="", readiness=true. Elapsed: 4.023074007s
Nov 21 09:40:25.965: INFO: Pod "pod-subpath-test-projected-s5kf": Phase="Running", Reason="", readiness=true. Elapsed: 6.025248117s
Nov 21 09:40:27.967: INFO: Pod "pod-subpath-test-projected-s5kf": Phase="Running", Reason="", readiness=true. Elapsed: 8.027639585s
Nov 21 09:40:29.969: INFO: Pod "pod-subpath-test-projected-s5kf": Phase="Running", Reason="", readiness=true. Elapsed: 10.030043745s
Nov 21 09:40:31.972: INFO: Pod "pod-subpath-test-projected-s5kf": Phase="Running", Reason="", readiness=true. Elapsed: 12.032392028s
Nov 21 09:40:33.974: INFO: Pod "pod-subpath-test-projected-s5kf": Phase="Running", Reason="", readiness=true. Elapsed: 14.034863649s
Nov 21 09:40:35.976: INFO: Pod "pod-subpath-test-projected-s5kf": Phase="Running", Reason="", readiness=true. Elapsed: 16.037055685s
Nov 21 09:40:37.978: INFO: Pod "pod-subpath-test-projected-s5kf": Phase="Running", Reason="", readiness=true. Elapsed: 18.038859539s
Nov 21 09:40:39.981: INFO: Pod "pod-subpath-test-projected-s5kf": Phase="Running", Reason="", readiness=true. Elapsed: 20.041223693s
Nov 21 09:40:41.983: INFO: Pod "pod-subpath-test-projected-s5kf": Phase="Running", Reason="", readiness=true. Elapsed: 22.043566258s
Nov 21 09:40:43.985: INFO: Pod "pod-subpath-test-projected-s5kf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.045852195s
STEP: Saw pod success
Nov 21 09:40:43.985: INFO: Pod "pod-subpath-test-projected-s5kf" satisfied condition "success or failure"
Nov 21 09:40:43.987: INFO: Trying to get logs from node 192.168.0.92 pod pod-subpath-test-projected-s5kf container test-container-subpath-projected-s5kf: <nil>
STEP: delete the pod
Nov 21 09:40:44.023: INFO: Waiting for pod pod-subpath-test-projected-s5kf to disappear
Nov 21 09:40:44.030: INFO: Pod pod-subpath-test-projected-s5kf no longer exists
STEP: Deleting pod pod-subpath-test-projected-s5kf
Nov 21 09:40:44.030: INFO: Deleting pod "pod-subpath-test-projected-s5kf" in namespace "subpath-6719"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:40:44.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6719" for this suite.
Nov 21 09:40:50.043: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:40:50.092: INFO: namespace subpath-6719 deletion completed in 6.058835819s

â€¢ [SLOW TEST:30.234 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:40:50.092: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating replication controller my-hostname-basic-00a8ecba-0c43-11ea-a569-4e55f5a7674f
Nov 21 09:40:50.185: INFO: Pod name my-hostname-basic-00a8ecba-0c43-11ea-a569-4e55f5a7674f: Found 0 pods out of 1
Nov 21 09:40:55.187: INFO: Pod name my-hostname-basic-00a8ecba-0c43-11ea-a569-4e55f5a7674f: Found 1 pods out of 1
Nov 21 09:40:55.187: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-00a8ecba-0c43-11ea-a569-4e55f5a7674f" are running
Nov 21 09:40:55.188: INFO: Pod "my-hostname-basic-00a8ecba-0c43-11ea-a569-4e55f5a7674f-t2dfz" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-21 09:40:50 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-21 09:40:52 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-21 09:40:52 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-21 09:40:50 +0000 UTC Reason: Message:}])
Nov 21 09:40:55.188: INFO: Trying to dial the pod
Nov 21 09:41:00.194: INFO: Controller my-hostname-basic-00a8ecba-0c43-11ea-a569-4e55f5a7674f: Got expected result from replica 1 [my-hostname-basic-00a8ecba-0c43-11ea-a569-4e55f5a7674f-t2dfz]: "my-hostname-basic-00a8ecba-0c43-11ea-a569-4e55f5a7674f-t2dfz", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:41:00.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7437" for this suite.
Nov 21 09:41:06.204: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:41:06.244: INFO: namespace replication-controller-7437 deletion completed in 6.048576741s

â€¢ [SLOW TEST:16.152 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:41:06.245: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:41:30.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-2294" for this suite.
Nov 21 09:41:36.464: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:41:36.506: INFO: namespace namespaces-2294 deletion completed in 6.067552073s
STEP: Destroying namespace "nsdeletetest-5560" for this suite.
Nov 21 09:41:36.507: INFO: Namespace nsdeletetest-5560 was already deleted
STEP: Destroying namespace "nsdeletetest-423" for this suite.
Nov 21 09:41:42.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:41:42.557: INFO: namespace nsdeletetest-423 deletion completed in 6.04965019s

â€¢ [SLOW TEST:36.312 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:41:42.557: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Nov 21 09:42:04.643: INFO: Container started at 2019-11-21 09:41:44 +0000 UTC, pod became ready at 2019-11-21 09:42:03 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:42:04.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4924" for this suite.
Nov 21 09:42:26.656: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:42:26.698: INFO: namespace container-probe-4924 deletion completed in 22.052883241s

â€¢ [SLOW TEST:44.141 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:42:26.698: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-2783
Nov 21 09:42:28.788: INFO: Started pod liveness-http in namespace container-probe-2783
STEP: checking the pod's current state and verifying that restartCount is present
Nov 21 09:42:28.789: INFO: Initial restart count of pod liveness-http is 0
Nov 21 09:42:48.812: INFO: Restart count of pod container-probe-2783/liveness-http is now 1 (20.023097043s elapsed)
Nov 21 09:43:08.835: INFO: Restart count of pod container-probe-2783/liveness-http is now 2 (40.046045998s elapsed)
Nov 21 09:43:28.857: INFO: Restart count of pod container-probe-2783/liveness-http is now 3 (1m0.068046564s elapsed)
Nov 21 09:43:48.879: INFO: Restart count of pod container-probe-2783/liveness-http is now 4 (1m20.090061143s elapsed)
Nov 21 09:44:50.957: INFO: Restart count of pod container-probe-2783/liveness-http is now 5 (2m22.167529992s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:44:50.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2783" for this suite.
Nov 21 09:44:56.983: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:44:57.059: INFO: namespace container-probe-2783 deletion completed in 6.082922546s

â€¢ [SLOW TEST:150.361 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:44:57.060: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-8598
Nov 21 09:45:01.138: INFO: Started pod liveness-exec in namespace container-probe-8598
STEP: checking the pod's current state and verifying that restartCount is present
Nov 21 09:45:01.140: INFO: Initial restart count of pod liveness-exec is 0
Nov 21 09:45:47.195: INFO: Restart count of pod container-probe-8598/liveness-exec is now 1 (46.05500007s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:45:47.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8598" for this suite.
Nov 21 09:45:53.264: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:45:53.306: INFO: namespace container-probe-8598 deletion completed in 6.055119234s

â€¢ [SLOW TEST:56.247 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:45:53.306: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-b560aaf8-0c43-11ea-a569-4e55f5a7674f
STEP: Creating a pod to test consume secrets
Nov 21 09:45:53.372: INFO: Waiting up to 5m0s for pod "pod-secrets-b561e6b4-0c43-11ea-a569-4e55f5a7674f" in namespace "secrets-7283" to be "success or failure"
Nov 21 09:45:53.377: INFO: Pod "pod-secrets-b561e6b4-0c43-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.599562ms
Nov 21 09:45:55.379: INFO: Pod "pod-secrets-b561e6b4-0c43-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006736414s
Nov 21 09:45:57.381: INFO: Pod "pod-secrets-b561e6b4-0c43-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009065924s
STEP: Saw pod success
Nov 21 09:45:57.381: INFO: Pod "pod-secrets-b561e6b4-0c43-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 09:45:57.383: INFO: Trying to get logs from node 192.168.0.92 pod pod-secrets-b561e6b4-0c43-11ea-a569-4e55f5a7674f container secret-volume-test: <nil>
STEP: delete the pod
Nov 21 09:45:57.400: INFO: Waiting for pod pod-secrets-b561e6b4-0c43-11ea-a569-4e55f5a7674f to disappear
Nov 21 09:45:57.405: INFO: Pod pod-secrets-b561e6b4-0c43-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:45:57.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7283" for this suite.
Nov 21 09:46:03.413: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:46:03.453: INFO: namespace secrets-7283 deletion completed in 6.045772689s

â€¢ [SLOW TEST:10.146 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Nov 21 09:46:03.453: INFO: >>> kubeConfig: /tmp/kubeconfig-073157133
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-bb6dbbf7-0c43-11ea-a569-4e55f5a7674f
STEP: Creating a pod to test consume configMaps
Nov 21 09:46:03.521: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-bb6e795e-0c43-11ea-a569-4e55f5a7674f" in namespace "projected-8636" to be "success or failure"
Nov 21 09:46:03.539: INFO: Pod "pod-projected-configmaps-bb6e795e-0c43-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 17.869484ms
Nov 21 09:46:05.541: INFO: Pod "pod-projected-configmaps-bb6e795e-0c43-11ea-a569-4e55f5a7674f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019762837s
Nov 21 09:46:07.542: INFO: Pod "pod-projected-configmaps-bb6e795e-0c43-11ea-a569-4e55f5a7674f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021561707s
STEP: Saw pod success
Nov 21 09:46:07.542: INFO: Pod "pod-projected-configmaps-bb6e795e-0c43-11ea-a569-4e55f5a7674f" satisfied condition "success or failure"
Nov 21 09:46:07.544: INFO: Trying to get logs from node 192.168.0.93 pod pod-projected-configmaps-bb6e795e-0c43-11ea-a569-4e55f5a7674f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 21 09:46:07.575: INFO: Waiting for pod pod-projected-configmaps-bb6e795e-0c43-11ea-a569-4e55f5a7674f to disappear
Nov 21 09:46:07.582: INFO: Pod pod-projected-configmaps-bb6e795e-0c43-11ea-a569-4e55f5a7674f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Nov 21 09:46:07.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8636" for this suite.
Nov 21 09:46:13.605: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 21 09:46:13.644: INFO: namespace projected-8636 deletion completed in 6.059806917s

â€¢ [SLOW TEST:10.191 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSNov 21 09:46:13.644: INFO: Running AfterSuite actions on all nodes
Nov 21 09:46:13.658: INFO: Running AfterSuite actions on node 1
Nov 21 09:46:13.658: INFO: Skipping dumping logs from cluster

Ran 204 of 3584 Specs in 5731.691 seconds
SUCCESS! -- 204 Passed | 0 Failed | 0 Pending | 3380 Skipped PASS

Ginkgo ran 1 suite in 1h35m34.494693561s
Test Suite Passed
