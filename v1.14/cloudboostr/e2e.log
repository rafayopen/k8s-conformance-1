I0822 07:41:50.686254      14 test_context.go:405] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-901739697
I0822 07:41:50.687719      14 e2e.go:240] Starting e2e run "4ce19bdf-c4b0-11e9-80b5-1edf08853c25" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1566459709 - Will randomize all specs
Will run 204 of 3584 specs

Aug 22 07:41:50.867: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
Aug 22 07:41:50.878: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Aug 22 07:41:50.914: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Aug 22 07:41:50.942: INFO: 9 / 9 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Aug 22 07:41:50.942: INFO: expected 6 pod replicas in namespace 'kube-system', 6 are Running and Ready.
Aug 22 07:41:50.942: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Aug 22 07:41:50.948: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'filebeat' (0 seconds elapsed)
Aug 22 07:41:50.948: INFO: e2e test version: v1.14.1
Aug 22 07:41:50.948: INFO: kube-apiserver version: v1.14.1
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 07:41:50.949: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename daemonsets
Aug 22 07:41:50.986: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Aug 22 07:41:50.999: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-9949
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Aug 22 07:41:51.155: INFO: Number of nodes with available pods: 0
Aug 22 07:41:51.155: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Aug 22 07:41:52.161: INFO: Number of nodes with available pods: 0
Aug 22 07:41:52.161: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Aug 22 07:41:53.163: INFO: Number of nodes with available pods: 3
Aug 22 07:41:53.163: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Aug 22 07:41:53.187: INFO: Number of nodes with available pods: 2
Aug 22 07:41:53.187: INFO: Node ip-10-90-32-24.eu-west-2.compute.internal is running more than one daemon pod
Aug 22 07:41:54.193: INFO: Number of nodes with available pods: 2
Aug 22 07:41:54.193: INFO: Node ip-10-90-32-24.eu-west-2.compute.internal is running more than one daemon pod
Aug 22 07:41:55.193: INFO: Number of nodes with available pods: 3
Aug 22 07:41:55.193: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9949, will wait for the garbage collector to delete the pods
Aug 22 07:41:55.257: INFO: Deleting DaemonSet.extensions daemon-set took: 8.497541ms
Aug 22 07:41:55.558: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.248178ms
Aug 22 07:42:09.660: INFO: Number of nodes with available pods: 0
Aug 22 07:42:09.660: INFO: Number of running nodes: 0, number of available pods: 0
Aug 22 07:42:09.663: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9949/daemonsets","resourceVersion":"14693999"},"items":null}

Aug 22 07:42:09.665: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9949/pods","resourceVersion":"14693999"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 07:42:09.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9949" for this suite.
Aug 22 07:42:15.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 07:42:15.886: INFO: namespace daemonsets-9949 deletion completed in 6.201145525s

• [SLOW TEST:24.938 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 07:42:15.887: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8769
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-5cb5b9dc-c4b0-11e9-80b5-1edf08853c25
STEP: Creating a pod to test consume secrets
Aug 22 07:42:16.032: INFO: Waiting up to 5m0s for pod "pod-secrets-5cb65039-c4b0-11e9-80b5-1edf08853c25" in namespace "secrets-8769" to be "success or failure"
Aug 22 07:42:16.036: INFO: Pod "pod-secrets-5cb65039-c4b0-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 4.093566ms
Aug 22 07:42:18.040: INFO: Pod "pod-secrets-5cb65039-c4b0-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007402163s
STEP: Saw pod success
Aug 22 07:42:18.040: INFO: Pod "pod-secrets-5cb65039-c4b0-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 07:42:18.041: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-secrets-5cb65039-c4b0-11e9-80b5-1edf08853c25 container secret-volume-test: <nil>
STEP: delete the pod
Aug 22 07:42:18.061: INFO: Waiting for pod pod-secrets-5cb65039-c4b0-11e9-80b5-1edf08853c25 to disappear
Aug 22 07:42:18.063: INFO: Pod pod-secrets-5cb65039-c4b0-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 07:42:18.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8769" for this suite.
Aug 22 07:42:24.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 07:42:24.151: INFO: namespace secrets-8769 deletion completed in 6.084053878s

• [SLOW TEST:8.264 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 07:42:24.151: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-6280
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-kx9f
STEP: Creating a pod to test atomic-volume-subpath
Aug 22 07:42:24.302: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-kx9f" in namespace "subpath-6280" to be "success or failure"
Aug 22 07:42:24.306: INFO: Pod "pod-subpath-test-configmap-kx9f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.036196ms
Aug 22 07:42:26.309: INFO: Pod "pod-subpath-test-configmap-kx9f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007330016s
Aug 22 07:42:28.313: INFO: Pod "pod-subpath-test-configmap-kx9f": Phase="Running", Reason="", readiness=true. Elapsed: 4.010884292s
Aug 22 07:42:30.316: INFO: Pod "pod-subpath-test-configmap-kx9f": Phase="Running", Reason="", readiness=true. Elapsed: 6.014261942s
Aug 22 07:42:32.320: INFO: Pod "pod-subpath-test-configmap-kx9f": Phase="Running", Reason="", readiness=true. Elapsed: 8.017495323s
Aug 22 07:42:34.323: INFO: Pod "pod-subpath-test-configmap-kx9f": Phase="Running", Reason="", readiness=true. Elapsed: 10.020648894s
Aug 22 07:42:36.326: INFO: Pod "pod-subpath-test-configmap-kx9f": Phase="Running", Reason="", readiness=true. Elapsed: 12.023728377s
Aug 22 07:42:38.329: INFO: Pod "pod-subpath-test-configmap-kx9f": Phase="Running", Reason="", readiness=true. Elapsed: 14.027265054s
Aug 22 07:42:40.332: INFO: Pod "pod-subpath-test-configmap-kx9f": Phase="Running", Reason="", readiness=true. Elapsed: 16.030473399s
Aug 22 07:42:42.336: INFO: Pod "pod-subpath-test-configmap-kx9f": Phase="Running", Reason="", readiness=true. Elapsed: 18.03362621s
Aug 22 07:42:44.339: INFO: Pod "pod-subpath-test-configmap-kx9f": Phase="Running", Reason="", readiness=true. Elapsed: 20.036847512s
Aug 22 07:42:46.343: INFO: Pod "pod-subpath-test-configmap-kx9f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.040507529s
STEP: Saw pod success
Aug 22 07:42:46.343: INFO: Pod "pod-subpath-test-configmap-kx9f" satisfied condition "success or failure"
Aug 22 07:42:46.346: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-subpath-test-configmap-kx9f container test-container-subpath-configmap-kx9f: <nil>
STEP: delete the pod
Aug 22 07:42:46.363: INFO: Waiting for pod pod-subpath-test-configmap-kx9f to disappear
Aug 22 07:42:46.365: INFO: Pod pod-subpath-test-configmap-kx9f no longer exists
STEP: Deleting pod pod-subpath-test-configmap-kx9f
Aug 22 07:42:46.365: INFO: Deleting pod "pod-subpath-test-configmap-kx9f" in namespace "subpath-6280"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 07:42:46.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6280" for this suite.
Aug 22 07:42:52.480: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 07:42:52.848: INFO: namespace subpath-6280 deletion completed in 6.47727421s

• [SLOW TEST:28.697 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 07:42:52.848: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-812
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Aug 22 07:42:53.054: INFO: Waiting up to 5m0s for pod "downwardapi-volume-72c6f119-c4b0-11e9-80b5-1edf08853c25" in namespace "downward-api-812" to be "success or failure"
Aug 22 07:42:53.058: INFO: Pod "downwardapi-volume-72c6f119-c4b0-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008347ms
Aug 22 07:42:55.061: INFO: Pod "downwardapi-volume-72c6f119-c4b0-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007126151s
STEP: Saw pod success
Aug 22 07:42:55.061: INFO: Pod "downwardapi-volume-72c6f119-c4b0-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 07:42:55.063: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod downwardapi-volume-72c6f119-c4b0-11e9-80b5-1edf08853c25 container client-container: <nil>
STEP: delete the pod
Aug 22 07:42:55.084: INFO: Waiting for pod downwardapi-volume-72c6f119-c4b0-11e9-80b5-1edf08853c25 to disappear
Aug 22 07:42:55.087: INFO: Pod downwardapi-volume-72c6f119-c4b0-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 07:42:55.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-812" for this suite.
Aug 22 07:43:01.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 07:43:01.175: INFO: namespace downward-api-812 deletion completed in 6.084484965s

• [SLOW TEST:8.327 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 07:43:01.175: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8924
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Aug 22 07:43:01.318: INFO: Waiting up to 5m0s for pod "downwardapi-volume-77b47bb2-c4b0-11e9-80b5-1edf08853c25" in namespace "downward-api-8924" to be "success or failure"
Aug 22 07:43:01.328: INFO: Pod "downwardapi-volume-77b47bb2-c4b0-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 9.97059ms
Aug 22 07:43:03.333: INFO: Pod "downwardapi-volume-77b47bb2-c4b0-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0143132s
STEP: Saw pod success
Aug 22 07:43:03.333: INFO: Pod "downwardapi-volume-77b47bb2-c4b0-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 07:43:03.335: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod downwardapi-volume-77b47bb2-c4b0-11e9-80b5-1edf08853c25 container client-container: <nil>
STEP: delete the pod
Aug 22 07:43:03.352: INFO: Waiting for pod downwardapi-volume-77b47bb2-c4b0-11e9-80b5-1edf08853c25 to disappear
Aug 22 07:43:03.356: INFO: Pod downwardapi-volume-77b47bb2-c4b0-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 07:43:03.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8924" for this suite.
Aug 22 07:43:09.375: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 07:43:09.451: INFO: namespace downward-api-8924 deletion completed in 6.092001258s

• [SLOW TEST:8.276 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 07:43:09.452: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4684
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Aug 22 07:43:09.593: INFO: Waiting up to 5m0s for pod "pod-7ca31c93-c4b0-11e9-80b5-1edf08853c25" in namespace "emptydir-4684" to be "success or failure"
Aug 22 07:43:09.599: INFO: Pod "pod-7ca31c93-c4b0-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 5.627246ms
Aug 22 07:43:11.602: INFO: Pod "pod-7ca31c93-c4b0-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008678378s
Aug 22 07:43:13.605: INFO: Pod "pod-7ca31c93-c4b0-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011897893s
STEP: Saw pod success
Aug 22 07:43:13.605: INFO: Pod "pod-7ca31c93-c4b0-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 07:43:13.607: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-7ca31c93-c4b0-11e9-80b5-1edf08853c25 container test-container: <nil>
STEP: delete the pod
Aug 22 07:43:13.624: INFO: Waiting for pod pod-7ca31c93-c4b0-11e9-80b5-1edf08853c25 to disappear
Aug 22 07:43:13.626: INFO: Pod pod-7ca31c93-c4b0-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 07:43:13.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4684" for this suite.
Aug 22 07:43:19.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 07:43:19.723: INFO: namespace emptydir-4684 deletion completed in 6.094173343s

• [SLOW TEST:10.272 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 07:43:19.724: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3149
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Aug 22 07:43:19.858: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 07:43:21.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3149" for this suite.
Aug 22 07:44:11.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 07:44:12.035: INFO: namespace pods-3149 deletion completed in 50.082619055s

• [SLOW TEST:52.311 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 07:44:12.035: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-4878
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Aug 22 07:44:12.390: INFO: Pod name wrapped-volume-race-a2074e72-c4b0-11e9-80b5-1edf08853c25: Found 0 pods out of 5
Aug 22 07:44:17.397: INFO: Pod name wrapped-volume-race-a2074e72-c4b0-11e9-80b5-1edf08853c25: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-a2074e72-c4b0-11e9-80b5-1edf08853c25 in namespace emptydir-wrapper-4878, will wait for the garbage collector to delete the pods
Aug 22 07:44:27.481: INFO: Deleting ReplicationController wrapped-volume-race-a2074e72-c4b0-11e9-80b5-1edf08853c25 took: 8.888157ms
Aug 22 07:44:27.881: INFO: Terminating ReplicationController wrapped-volume-race-a2074e72-c4b0-11e9-80b5-1edf08853c25 pods took: 400.316681ms
STEP: Creating RC which spawns configmap-volume pods
Aug 22 07:45:10.399: INFO: Pod name wrapped-volume-race-c4a31212-c4b0-11e9-80b5-1edf08853c25: Found 0 pods out of 5
Aug 22 07:45:15.405: INFO: Pod name wrapped-volume-race-c4a31212-c4b0-11e9-80b5-1edf08853c25: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-c4a31212-c4b0-11e9-80b5-1edf08853c25 in namespace emptydir-wrapper-4878, will wait for the garbage collector to delete the pods
Aug 22 07:45:27.496: INFO: Deleting ReplicationController wrapped-volume-race-c4a31212-c4b0-11e9-80b5-1edf08853c25 took: 10.907081ms
Aug 22 07:45:27.896: INFO: Terminating ReplicationController wrapped-volume-race-c4a31212-c4b0-11e9-80b5-1edf08853c25 pods took: 400.349826ms
STEP: Creating RC which spawns configmap-volume pods
Aug 22 07:46:09.415: INFO: Pod name wrapped-volume-race-e7d010f0-c4b0-11e9-80b5-1edf08853c25: Found 0 pods out of 5
Aug 22 07:46:14.421: INFO: Pod name wrapped-volume-race-e7d010f0-c4b0-11e9-80b5-1edf08853c25: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-e7d010f0-c4b0-11e9-80b5-1edf08853c25 in namespace emptydir-wrapper-4878, will wait for the garbage collector to delete the pods
Aug 22 07:46:24.505: INFO: Deleting ReplicationController wrapped-volume-race-e7d010f0-c4b0-11e9-80b5-1edf08853c25 took: 11.687896ms
Aug 22 07:46:24.905: INFO: Terminating ReplicationController wrapped-volume-race-e7d010f0-c4b0-11e9-80b5-1edf08853c25 pods took: 400.201615ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 07:47:09.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-4878" for this suite.
Aug 22 07:47:15.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 07:47:15.825: INFO: namespace emptydir-wrapper-4878 deletion completed in 6.080119637s

• [SLOW TEST:183.790 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 07:47:15.825: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-5752
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-5752
Aug 22 07:47:19.980: INFO: Started pod liveness-http in namespace container-probe-5752
STEP: checking the pod's current state and verifying that restartCount is present
Aug 22 07:47:19.981: INFO: Initial restart count of pod liveness-http is 0
Aug 22 07:47:40.015: INFO: Restart count of pod container-probe-5752/liveness-http is now 1 (20.033653203s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 07:47:40.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5752" for this suite.
Aug 22 07:47:46.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 07:47:46.165: INFO: namespace container-probe-5752 deletion completed in 6.132149628s

• [SLOW TEST:30.340 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 07:47:46.166: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5959
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Aug 22 07:47:48.900: INFO: Successfully updated pod "labelsupdate2199d2f8-c4b1-11e9-80b5-1edf08853c25"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 07:47:50.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5959" for this suite.
Aug 22 07:48:12.925: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 07:48:12.994: INFO: namespace projected-5959 deletion completed in 22.0776461s

• [SLOW TEST:26.829 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 07:48:12.995: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-518
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Aug 22 07:48:15.654: INFO: Successfully updated pod "pod-update-activedeadlineseconds-318fd6da-c4b1-11e9-80b5-1edf08853c25"
Aug 22 07:48:15.654: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-318fd6da-c4b1-11e9-80b5-1edf08853c25" in namespace "pods-518" to be "terminated due to deadline exceeded"
Aug 22 07:48:15.656: INFO: Pod "pod-update-activedeadlineseconds-318fd6da-c4b1-11e9-80b5-1edf08853c25": Phase="Running", Reason="", readiness=true. Elapsed: 1.822347ms
Aug 22 07:48:17.659: INFO: Pod "pod-update-activedeadlineseconds-318fd6da-c4b1-11e9-80b5-1edf08853c25": Phase="Running", Reason="", readiness=true. Elapsed: 2.004882403s
Aug 22 07:48:19.662: INFO: Pod "pod-update-activedeadlineseconds-318fd6da-c4b1-11e9-80b5-1edf08853c25": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.00793269s
Aug 22 07:48:19.662: INFO: Pod "pod-update-activedeadlineseconds-318fd6da-c4b1-11e9-80b5-1edf08853c25" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 07:48:19.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-518" for this suite.
Aug 22 07:48:25.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 07:48:25.744: INFO: namespace pods-518 deletion completed in 6.078780985s

• [SLOW TEST:12.749 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 07:48:25.745: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7440
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name projected-secret-test-39299dd5-c4b1-11e9-80b5-1edf08853c25
STEP: Creating a pod to test consume secrets
Aug 22 07:48:25.890: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-392a337e-c4b1-11e9-80b5-1edf08853c25" in namespace "projected-7440" to be "success or failure"
Aug 22 07:48:25.897: INFO: Pod "pod-projected-secrets-392a337e-c4b1-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 7.269324ms
Aug 22 07:48:27.900: INFO: Pod "pod-projected-secrets-392a337e-c4b1-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010648803s
STEP: Saw pod success
Aug 22 07:48:27.900: INFO: Pod "pod-projected-secrets-392a337e-c4b1-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 07:48:27.903: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-projected-secrets-392a337e-c4b1-11e9-80b5-1edf08853c25 container secret-volume-test: <nil>
STEP: delete the pod
Aug 22 07:48:27.918: INFO: Waiting for pod pod-projected-secrets-392a337e-c4b1-11e9-80b5-1edf08853c25 to disappear
Aug 22 07:48:27.926: INFO: Pod pod-projected-secrets-392a337e-c4b1-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 07:48:27.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7440" for this suite.
Aug 22 07:48:33.938: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 07:48:34.011: INFO: namespace projected-7440 deletion completed in 6.081511402s

• [SLOW TEST:8.266 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 07:48:34.011: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-4179
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-4179
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-4179
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-4179
Aug 22 07:48:34.188: INFO: Found 0 stateful pods, waiting for 1
Aug 22 07:48:44.191: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Aug 22 07:48:44.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 exec --namespace=statefulset-4179 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 22 07:48:44.617: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 22 07:48:44.617: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 22 07:48:44.617: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 22 07:48:44.620: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Aug 22 07:48:54.623: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 22 07:48:54.623: INFO: Waiting for statefulset status.replicas updated to 0
Aug 22 07:48:54.637: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998647s
Aug 22 07:48:55.641: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.995414717s
Aug 22 07:48:56.644: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.992182986s
Aug 22 07:48:57.647: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.988666584s
Aug 22 07:48:58.650: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.985539137s
Aug 22 07:48:59.654: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.982347613s
Aug 22 07:49:00.657: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.979166454s
Aug 22 07:49:01.661: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.97578353s
Aug 22 07:49:02.664: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.971695262s
Aug 22 07:49:03.669: INFO: Verifying statefulset ss doesn't scale past 1 for another 968.38859ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-4179
Aug 22 07:49:04.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 exec --namespace=statefulset-4179 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 22 07:49:04.812: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 22 07:49:04.812: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 22 07:49:04.812: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 22 07:49:04.816: INFO: Found 1 stateful pods, waiting for 3
Aug 22 07:49:14.819: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 22 07:49:14.819: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 22 07:49:14.819: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Aug 22 07:49:14.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 exec --namespace=statefulset-4179 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 22 07:49:14.971: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 22 07:49:14.971: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 22 07:49:14.971: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 22 07:49:14.971: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 exec --namespace=statefulset-4179 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 22 07:49:15.138: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 22 07:49:15.138: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 22 07:49:15.138: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 22 07:49:15.138: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 exec --namespace=statefulset-4179 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 22 07:49:15.285: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 22 07:49:15.285: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 22 07:49:15.285: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 22 07:49:15.285: INFO: Waiting for statefulset status.replicas updated to 0
Aug 22 07:49:15.288: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Aug 22 07:49:25.293: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 22 07:49:25.293: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Aug 22 07:49:25.293: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Aug 22 07:49:25.309: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998608s
Aug 22 07:49:26.312: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.991956143s
Aug 22 07:49:27.316: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.988524993s
Aug 22 07:49:28.319: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.985097204s
Aug 22 07:49:29.324: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.981563559s
Aug 22 07:49:30.327: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.977115188s
Aug 22 07:49:31.331: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.973790076s
Aug 22 07:49:32.334: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.97028586s
Aug 22 07:49:33.337: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.967071159s
Aug 22 07:49:34.342: INFO: Verifying statefulset ss doesn't scale past 3 for another 963.72337ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-4179
Aug 22 07:49:35.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 exec --namespace=statefulset-4179 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 22 07:49:35.488: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 22 07:49:35.488: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 22 07:49:35.488: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 22 07:49:35.488: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 exec --namespace=statefulset-4179 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 22 07:49:35.632: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 22 07:49:35.632: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 22 07:49:35.632: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 22 07:49:35.632: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 exec --namespace=statefulset-4179 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 22 07:49:35.791: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 22 07:49:35.791: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 22 07:49:35.791: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 22 07:49:35.791: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Aug 22 07:49:45.802: INFO: Deleting all statefulset in ns statefulset-4179
Aug 22 07:49:45.804: INFO: Scaling statefulset ss to 0
Aug 22 07:49:45.811: INFO: Waiting for statefulset status.replicas updated to 0
Aug 22 07:49:45.813: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 07:49:45.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4179" for this suite.
Aug 22 07:49:51.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 07:49:51.935: INFO: namespace statefulset-4179 deletion completed in 6.083703482s

• [SLOW TEST:77.924 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 07:49:51.935: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-7621
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 07:49:52.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7621" for this suite.
Aug 22 07:50:14.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 07:50:14.186: INFO: namespace kubelet-test-7621 deletion completed in 22.094725606s

• [SLOW TEST:22.251 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 07:50:14.186: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-8357
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Aug 22 07:50:14.318: INFO: PodSpec: initContainers in spec.initContainers
Aug 22 07:50:55.478: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-79cc2464-c4b1-11e9-80b5-1edf08853c25", GenerateName:"", Namespace:"init-container-8357", SelfLink:"/api/v1/namespaces/init-container-8357/pods/pod-init-79cc2464-c4b1-11e9-80b5-1edf08853c25", UID:"79cca329-c4b1-11e9-92bb-0afbab63fbd8", ResourceVersion:"14696276", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63702057014, loc:(*time.Location)(0x8a060e0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"318813039"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-84rzq", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001d79c40), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-84rzq", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-84rzq", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-84rzq", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0003e1c98), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-10-90-32-24.eu-west-2.compute.internal", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0020756e0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0003e1fb0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0004cc130)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0004cc138), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0004cc13c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702057014, loc:(*time.Location)(0x8a060e0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702057014, loc:(*time.Location)(0x8a060e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702057014, loc:(*time.Location)(0x8a060e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702057014, loc:(*time.Location)(0x8a060e0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.90.32.24", PodIP:"10.200.40.223", StartTime:(*v1.Time)(0xc00165f860), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001cd0460)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001cd04d0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://727eeaadf7d06a288f3634ceb754198694e0387da348791d6f8bdae7d544fc83"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00165f8a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00165f880), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 07:50:55.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8357" for this suite.
Aug 22 07:51:17.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 07:51:17.573: INFO: namespace init-container-8357 deletion completed in 22.091257735s

• [SLOW TEST:63.387 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 07:51:17.573: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5997
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on node default medium
Aug 22 07:51:17.714: INFO: Waiting up to 5m0s for pod "pod-9f948698-c4b1-11e9-80b5-1edf08853c25" in namespace "emptydir-5997" to be "success or failure"
Aug 22 07:51:17.727: INFO: Pod "pod-9f948698-c4b1-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 12.690442ms
Aug 22 07:51:19.729: INFO: Pod "pod-9f948698-c4b1-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014997145s
STEP: Saw pod success
Aug 22 07:51:19.729: INFO: Pod "pod-9f948698-c4b1-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 07:51:19.731: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-9f948698-c4b1-11e9-80b5-1edf08853c25 container test-container: <nil>
STEP: delete the pod
Aug 22 07:51:19.746: INFO: Waiting for pod pod-9f948698-c4b1-11e9-80b5-1edf08853c25 to disappear
Aug 22 07:51:19.752: INFO: Pod pod-9f948698-c4b1-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 07:51:19.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5997" for this suite.
Aug 22 07:51:25.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 07:51:25.833: INFO: namespace emptydir-5997 deletion completed in 6.077457081s

• [SLOW TEST:8.259 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 07:51:25.833: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8530
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1354
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 22 07:51:25.964: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-8530'
Aug 22 07:51:26.194: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 22 07:51:26.194: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Aug 22 07:51:26.219: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-fk4b7]
Aug 22 07:51:26.220: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-fk4b7" in namespace "kubectl-8530" to be "running and ready"
Aug 22 07:51:26.227: INFO: Pod "e2e-test-nginx-rc-fk4b7": Phase="Pending", Reason="", readiness=false. Elapsed: 7.284785ms
Aug 22 07:51:28.230: INFO: Pod "e2e-test-nginx-rc-fk4b7": Phase="Running", Reason="", readiness=true. Elapsed: 2.010325773s
Aug 22 07:51:28.230: INFO: Pod "e2e-test-nginx-rc-fk4b7" satisfied condition "running and ready"
Aug 22 07:51:28.230: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-fk4b7]
Aug 22 07:51:28.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 logs rc/e2e-test-nginx-rc --namespace=kubectl-8530'
Aug 22 07:51:28.339: INFO: stderr: ""
Aug 22 07:51:28.339: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1359
Aug 22 07:51:28.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 delete rc e2e-test-nginx-rc --namespace=kubectl-8530'
Aug 22 07:51:28.412: INFO: stderr: ""
Aug 22 07:51:28.412: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 07:51:28.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8530" for this suite.
Aug 22 07:51:34.429: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 07:51:34.495: INFO: namespace kubectl-8530 deletion completed in 6.076548605s

• [SLOW TEST:8.662 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 07:51:34.495: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-4314
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 07:51:36.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-4314" for this suite.
Aug 22 07:51:42.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 07:51:42.761: INFO: namespace emptydir-wrapper-4314 deletion completed in 6.078137279s

• [SLOW TEST:8.266 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 07:51:42.762: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-8525
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Aug 22 07:51:44.911: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-ae97afd5-c4b1-11e9-80b5-1edf08853c25,GenerateName:,Namespace:events-8525,SelfLink:/api/v1/namespaces/events-8525/pods/send-events-ae97afd5-c4b1-11e9-80b5-1edf08853c25,UID:ae98161b-c4b1-11e9-92bb-0afbab63fbd8,ResourceVersion:14696472,Generation:0,CreationTimestamp:2019-08-22 07:51:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 894285801,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-hwgbs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hwgbs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-hwgbs true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-24.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0023ca420} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0023ca440}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:51:42 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:51:44 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:51:44 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:51:42 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.24,PodIP:10.200.40.228,StartTime:2019-08-22 07:51:42 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-08-22 07:51:43 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://a377cfe4336865ff0c040f7984fc60ebff89f72af63be9bcf48b87219a0b50b4}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Aug 22 07:51:46.915: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Aug 22 07:51:48.918: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 07:51:48.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-8525" for this suite.
Aug 22 07:52:30.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 07:52:31.010: INFO: namespace events-8525 deletion completed in 42.077138242s

• [SLOW TEST:48.248 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 07:52:31.010: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-702
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's command
Aug 22 07:52:31.155: INFO: Waiting up to 5m0s for pod "var-expansion-cb5aae35-c4b1-11e9-80b5-1edf08853c25" in namespace "var-expansion-702" to be "success or failure"
Aug 22 07:52:31.165: INFO: Pod "var-expansion-cb5aae35-c4b1-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 9.797596ms
Aug 22 07:52:33.168: INFO: Pod "var-expansion-cb5aae35-c4b1-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013123122s
STEP: Saw pod success
Aug 22 07:52:33.168: INFO: Pod "var-expansion-cb5aae35-c4b1-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 07:52:33.170: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod var-expansion-cb5aae35-c4b1-11e9-80b5-1edf08853c25 container dapi-container: <nil>
STEP: delete the pod
Aug 22 07:52:33.185: INFO: Waiting for pod var-expansion-cb5aae35-c4b1-11e9-80b5-1edf08853c25 to disappear
Aug 22 07:52:33.187: INFO: Pod var-expansion-cb5aae35-c4b1-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 07:52:33.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-702" for this suite.
Aug 22 07:52:39.199: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 07:52:39.269: INFO: namespace var-expansion-702 deletion completed in 6.078640319s

• [SLOW TEST:8.259 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 07:52:39.270: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5669
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Aug 22 07:52:39.417: INFO: Waiting up to 5m0s for pod "pod-d04744f6-c4b1-11e9-80b5-1edf08853c25" in namespace "emptydir-5669" to be "success or failure"
Aug 22 07:52:39.431: INFO: Pod "pod-d04744f6-c4b1-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 14.459509ms
Aug 22 07:52:41.442: INFO: Pod "pod-d04744f6-c4b1-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025318733s
STEP: Saw pod success
Aug 22 07:52:41.442: INFO: Pod "pod-d04744f6-c4b1-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 07:52:41.444: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-d04744f6-c4b1-11e9-80b5-1edf08853c25 container test-container: <nil>
STEP: delete the pod
Aug 22 07:52:41.460: INFO: Waiting for pod pod-d04744f6-c4b1-11e9-80b5-1edf08853c25 to disappear
Aug 22 07:52:41.463: INFO: Pod pod-d04744f6-c4b1-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 07:52:41.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5669" for this suite.
Aug 22 07:52:47.474: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 07:52:47.550: INFO: namespace emptydir-5669 deletion completed in 6.084227229s

• [SLOW TEST:8.281 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 07:52:47.551: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8576
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-d536d761-c4b1-11e9-80b5-1edf08853c25
STEP: Creating secret with name s-test-opt-upd-d536d7ad-c4b1-11e9-80b5-1edf08853c25
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-d536d761-c4b1-11e9-80b5-1edf08853c25
STEP: Updating secret s-test-opt-upd-d536d7ad-c4b1-11e9-80b5-1edf08853c25
STEP: Creating secret with name s-test-opt-create-d536d7cf-c4b1-11e9-80b5-1edf08853c25
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 07:52:51.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8576" for this suite.
Aug 22 07:53:13.799: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 07:53:13.874: INFO: namespace secrets-8576 deletion completed in 22.087525346s

• [SLOW TEST:26.323 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 07:53:13.874: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7369
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Aug 22 07:53:16.553: INFO: Successfully updated pod "labelsupdatee4e66667-c4b1-11e9-80b5-1edf08853c25"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 07:53:18.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7369" for this suite.
Aug 22 07:53:40.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 07:53:40.644: INFO: namespace downward-api-7369 deletion completed in 22.074340779s

• [SLOW TEST:26.770 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 07:53:40.645: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-6311
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-6311
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating stateful set ss in namespace statefulset-6311
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-6311
Aug 22 07:53:40.798: INFO: Found 0 stateful pods, waiting for 1
Aug 22 07:53:50.801: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Aug 22 07:53:50.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 exec --namespace=statefulset-6311 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 22 07:53:50.940: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 22 07:53:50.940: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 22 07:53:50.940: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 22 07:53:50.943: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Aug 22 07:54:00.947: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 22 07:54:00.947: INFO: Waiting for statefulset status.replicas updated to 0
Aug 22 07:54:00.964: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Aug 22 07:54:00.964: INFO: ss-0  ip-10-90-32-24.eu-west-2.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:53:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:53:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:53:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:53:40 +0000 UTC  }]
Aug 22 07:54:00.965: INFO: ss-1                                             Pending         []
Aug 22 07:54:00.965: INFO: 
Aug 22 07:54:00.965: INFO: StatefulSet ss has not reached scale 3, at 2
Aug 22 07:54:01.970: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.993877831s
Aug 22 07:54:02.973: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.98869286s
Aug 22 07:54:03.980: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.982863628s
Aug 22 07:54:04.985: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.978789832s
Aug 22 07:54:05.990: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.973426019s
Aug 22 07:54:06.993: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.968649719s
Aug 22 07:54:07.998: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.96518839s
Aug 22 07:54:09.001: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.960783986s
Aug 22 07:54:10.005: INFO: Verifying statefulset ss doesn't scale past 3 for another 957.022771ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-6311
Aug 22 07:54:11.009: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 exec --namespace=statefulset-6311 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 22 07:54:11.142: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 22 07:54:11.142: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 22 07:54:11.142: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 22 07:54:11.142: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 exec --namespace=statefulset-6311 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 22 07:54:11.316: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Aug 22 07:54:11.316: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 22 07:54:11.316: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 22 07:54:11.316: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 exec --namespace=statefulset-6311 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 22 07:54:11.466: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Aug 22 07:54:11.466: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 22 07:54:11.466: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 22 07:54:11.469: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Aug 22 07:54:21.473: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 22 07:54:21.473: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 22 07:54:21.473: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Aug 22 07:54:21.475: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 exec --namespace=statefulset-6311 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 22 07:54:21.618: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 22 07:54:21.618: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 22 07:54:21.618: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 22 07:54:21.618: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 exec --namespace=statefulset-6311 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 22 07:54:21.779: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 22 07:54:21.779: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 22 07:54:21.779: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 22 07:54:21.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 exec --namespace=statefulset-6311 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 22 07:54:21.916: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 22 07:54:21.916: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 22 07:54:21.916: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 22 07:54:21.916: INFO: Waiting for statefulset status.replicas updated to 0
Aug 22 07:54:21.919: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Aug 22 07:54:31.924: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 22 07:54:31.924: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Aug 22 07:54:31.924: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Aug 22 07:54:31.939: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Aug 22 07:54:31.939: INFO: ss-0  ip-10-90-32-24.eu-west-2.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:53:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:53:40 +0000 UTC  }]
Aug 22 07:54:31.939: INFO: ss-1  ip-10-90-32-24.eu-west-2.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:00 +0000 UTC  }]
Aug 22 07:54:31.939: INFO: ss-2  ip-10-90-32-24.eu-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:00 +0000 UTC  }]
Aug 22 07:54:31.939: INFO: 
Aug 22 07:54:31.939: INFO: StatefulSet ss has not reached scale 0, at 3
Aug 22 07:54:32.943: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Aug 22 07:54:32.943: INFO: ss-0  ip-10-90-32-24.eu-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:53:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:53:40 +0000 UTC  }]
Aug 22 07:54:32.943: INFO: ss-1  ip-10-90-32-24.eu-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:00 +0000 UTC  }]
Aug 22 07:54:32.943: INFO: ss-2  ip-10-90-32-24.eu-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:00 +0000 UTC  }]
Aug 22 07:54:32.943: INFO: 
Aug 22 07:54:32.943: INFO: StatefulSet ss has not reached scale 0, at 3
Aug 22 07:54:33.947: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Aug 22 07:54:33.947: INFO: ss-0  ip-10-90-32-24.eu-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:53:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:53:40 +0000 UTC  }]
Aug 22 07:54:33.947: INFO: ss-1  ip-10-90-32-24.eu-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:00 +0000 UTC  }]
Aug 22 07:54:33.947: INFO: ss-2  ip-10-90-32-24.eu-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:00 +0000 UTC  }]
Aug 22 07:54:33.947: INFO: 
Aug 22 07:54:33.947: INFO: StatefulSet ss has not reached scale 0, at 3
Aug 22 07:54:34.950: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Aug 22 07:54:34.950: INFO: ss-1  ip-10-90-32-24.eu-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:00 +0000 UTC  }]
Aug 22 07:54:34.950: INFO: ss-2  ip-10-90-32-24.eu-west-2.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:00 +0000 UTC  }]
Aug 22 07:54:34.950: INFO: 
Aug 22 07:54:34.950: INFO: StatefulSet ss has not reached scale 0, at 2
Aug 22 07:54:35.954: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Aug 22 07:54:35.954: INFO: ss-1  ip-10-90-32-24.eu-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:00 +0000 UTC  }]
Aug 22 07:54:35.954: INFO: ss-2  ip-10-90-32-24.eu-west-2.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:00 +0000 UTC  }]
Aug 22 07:54:35.954: INFO: 
Aug 22 07:54:35.954: INFO: StatefulSet ss has not reached scale 0, at 2
Aug 22 07:54:36.957: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Aug 22 07:54:36.957: INFO: ss-1  ip-10-90-32-24.eu-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:00 +0000 UTC  }]
Aug 22 07:54:36.957: INFO: ss-2  ip-10-90-32-24.eu-west-2.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:00 +0000 UTC  }]
Aug 22 07:54:36.957: INFO: 
Aug 22 07:54:36.957: INFO: StatefulSet ss has not reached scale 0, at 2
Aug 22 07:54:37.961: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Aug 22 07:54:37.961: INFO: ss-1  ip-10-90-32-24.eu-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:00 +0000 UTC  }]
Aug 22 07:54:37.961: INFO: ss-2  ip-10-90-32-24.eu-west-2.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:00 +0000 UTC  }]
Aug 22 07:54:37.961: INFO: 
Aug 22 07:54:37.961: INFO: StatefulSet ss has not reached scale 0, at 2
Aug 22 07:54:38.964: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Aug 22 07:54:38.964: INFO: ss-1  ip-10-90-32-24.eu-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:00 +0000 UTC  }]
Aug 22 07:54:38.964: INFO: ss-2  ip-10-90-32-24.eu-west-2.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 07:54:00 +0000 UTC  }]
Aug 22 07:54:38.964: INFO: 
Aug 22 07:54:38.964: INFO: StatefulSet ss has not reached scale 0, at 2
Aug 22 07:54:39.969: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.967744052s
Aug 22 07:54:40.972: INFO: Verifying statefulset ss doesn't scale past 0 for another 962.787741ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-6311
Aug 22 07:54:41.975: INFO: Scaling statefulset ss to 0
Aug 22 07:54:41.985: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Aug 22 07:54:41.988: INFO: Deleting all statefulset in ns statefulset-6311
Aug 22 07:54:41.991: INFO: Scaling statefulset ss to 0
Aug 22 07:54:42.002: INFO: Waiting for statefulset status.replicas updated to 0
Aug 22 07:54:42.004: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 07:54:42.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6311" for this suite.
Aug 22 07:54:48.032: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 07:54:48.103: INFO: namespace statefulset-6311 deletion completed in 6.081814466s

• [SLOW TEST:67.459 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 07:54:48.103: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5244
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with configMap that has name projected-configmap-test-upd-1d11271f-c4b2-11e9-80b5-1edf08853c25
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-1d11271f-c4b2-11e9-80b5-1edf08853c25
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 07:54:52.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5244" for this suite.
Aug 22 07:55:14.295: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 07:55:14.366: INFO: namespace projected-5244 deletion completed in 22.08011615s

• [SLOW TEST:26.263 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 07:55:14.366: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-3194
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 07:55:41.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3194" for this suite.
Aug 22 07:55:47.712: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 07:55:47.815: INFO: namespace container-runtime-3194 deletion completed in 6.110794496s

• [SLOW TEST:33.449 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  blackbox test
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 07:55:47.815: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3925
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-40a836bc-c4b2-11e9-80b5-1edf08853c25
STEP: Creating a pod to test consume configMaps
Aug 22 07:55:47.960: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-40a8d315-c4b2-11e9-80b5-1edf08853c25" in namespace "projected-3925" to be "success or failure"
Aug 22 07:55:47.964: INFO: Pod "pod-projected-configmaps-40a8d315-c4b2-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 3.67904ms
Aug 22 07:55:49.967: INFO: Pod "pod-projected-configmaps-40a8d315-c4b2-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006935151s
STEP: Saw pod success
Aug 22 07:55:49.967: INFO: Pod "pod-projected-configmaps-40a8d315-c4b2-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 07:55:49.970: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-projected-configmaps-40a8d315-c4b2-11e9-80b5-1edf08853c25 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 22 07:55:49.986: INFO: Waiting for pod pod-projected-configmaps-40a8d315-c4b2-11e9-80b5-1edf08853c25 to disappear
Aug 22 07:55:49.989: INFO: Pod pod-projected-configmaps-40a8d315-c4b2-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 07:55:49.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3925" for this suite.
Aug 22 07:55:56.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 07:55:56.080: INFO: namespace projected-3925 deletion completed in 6.088415647s

• [SLOW TEST:8.265 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 07:55:56.081: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1580
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Aug 22 07:56:18.234: INFO: Container started at 2019-08-22 07:55:57 +0000 UTC, pod became ready at 2019-08-22 07:56:17 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 07:56:18.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1580" for this suite.
Aug 22 07:56:40.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 07:56:40.310: INFO: namespace container-probe-1580 deletion completed in 22.073570113s

• [SLOW TEST:44.230 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 07:56:40.311: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-4600
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-4600
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 22 07:56:40.443: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug 22 07:57:02.533: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.200.40.243:8080/dial?request=hostName&protocol=http&host=10.200.40.242&port=8080&tries=1'] Namespace:pod-network-test-4600 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 22 07:57:02.533: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
Aug 22 07:57:02.608: INFO: Waiting for endpoints: map[]
Aug 22 07:57:02.611: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.200.40.243:8080/dial?request=hostName&protocol=http&host=10.200.47.149&port=8080&tries=1'] Namespace:pod-network-test-4600 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 22 07:57:02.611: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
Aug 22 07:57:02.691: INFO: Waiting for endpoints: map[]
Aug 22 07:57:02.694: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.200.40.243:8080/dial?request=hostName&protocol=http&host=10.200.87.50&port=8080&tries=1'] Namespace:pod-network-test-4600 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 22 07:57:02.694: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
Aug 22 07:57:02.769: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 07:57:02.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4600" for this suite.
Aug 22 07:57:24.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 07:57:24.893: INFO: namespace pod-network-test-4600 deletion completed in 22.119704694s

• [SLOW TEST:44.582 seconds]
[sig-network] Networking
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 07:57:24.893: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-1898
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service endpoint-test2 in namespace services-1898
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1898 to expose endpoints map[]
Aug 22 07:57:25.041: INFO: successfully validated that service endpoint-test2 in namespace services-1898 exposes endpoints map[] (2.902809ms elapsed)
STEP: Creating pod pod1 in namespace services-1898
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1898 to expose endpoints map[pod1:[80]]
Aug 22 07:57:27.066: INFO: successfully validated that service endpoint-test2 in namespace services-1898 exposes endpoints map[pod1:[80]] (2.018633985s elapsed)
STEP: Creating pod pod2 in namespace services-1898
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1898 to expose endpoints map[pod1:[80] pod2:[80]]
Aug 22 07:57:29.110: INFO: successfully validated that service endpoint-test2 in namespace services-1898 exposes endpoints map[pod1:[80] pod2:[80]] (2.038198845s elapsed)
STEP: Deleting pod pod1 in namespace services-1898
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1898 to expose endpoints map[pod2:[80]]
Aug 22 07:57:29.128: INFO: successfully validated that service endpoint-test2 in namespace services-1898 exposes endpoints map[pod2:[80]] (12.098449ms elapsed)
STEP: Deleting pod pod2 in namespace services-1898
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1898 to expose endpoints map[]
Aug 22 07:57:29.138: INFO: successfully validated that service endpoint-test2 in namespace services-1898 exposes endpoints map[] (5.015507ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 07:57:29.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1898" for this suite.
Aug 22 07:57:51.169: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 07:57:51.241: INFO: namespace services-1898 deletion completed in 22.085874493s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:26.349 seconds]
[sig-network] Services
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 07:57:51.242: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-3096
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-3096
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-3096
STEP: Creating statefulset with conflicting port in namespace statefulset-3096
STEP: Waiting until pod test-pod will start running in namespace statefulset-3096
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-3096
Aug 22 07:57:55.444: INFO: Observed stateful pod in namespace: statefulset-3096, name: ss-0, uid: 8c6862e8-c4b2-11e9-92bb-0afbab63fbd8, status phase: Pending. Waiting for statefulset controller to delete.
Aug 22 07:57:55.628: INFO: Observed stateful pod in namespace: statefulset-3096, name: ss-0, uid: 8c6862e8-c4b2-11e9-92bb-0afbab63fbd8, status phase: Failed. Waiting for statefulset controller to delete.
Aug 22 07:57:55.634: INFO: Observed stateful pod in namespace: statefulset-3096, name: ss-0, uid: 8c6862e8-c4b2-11e9-92bb-0afbab63fbd8, status phase: Failed. Waiting for statefulset controller to delete.
Aug 22 07:57:55.638: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-3096
STEP: Removing pod with conflicting port in namespace statefulset-3096
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-3096 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Aug 22 07:57:59.668: INFO: Deleting all statefulset in ns statefulset-3096
Aug 22 07:57:59.670: INFO: Scaling statefulset ss to 0
Aug 22 07:58:09.690: INFO: Waiting for statefulset status.replicas updated to 0
Aug 22 07:58:09.692: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 07:58:09.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3096" for this suite.
Aug 22 07:58:15.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 07:58:15.790: INFO: namespace statefulset-3096 deletion completed in 6.079506146s

• [SLOW TEST:24.548 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 07:58:15.791: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1801
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-1801/configmap-test-98dae6e9-c4b2-11e9-80b5-1edf08853c25
STEP: Creating a pod to test consume configMaps
Aug 22 07:58:15.931: INFO: Waiting up to 5m0s for pod "pod-configmaps-98db68f2-c4b2-11e9-80b5-1edf08853c25" in namespace "configmap-1801" to be "success or failure"
Aug 22 07:58:15.935: INFO: Pod "pod-configmaps-98db68f2-c4b2-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 4.060222ms
Aug 22 07:58:17.938: INFO: Pod "pod-configmaps-98db68f2-c4b2-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00711507s
STEP: Saw pod success
Aug 22 07:58:17.939: INFO: Pod "pod-configmaps-98db68f2-c4b2-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 07:58:17.941: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-configmaps-98db68f2-c4b2-11e9-80b5-1edf08853c25 container env-test: <nil>
STEP: delete the pod
Aug 22 07:58:17.956: INFO: Waiting for pod pod-configmaps-98db68f2-c4b2-11e9-80b5-1edf08853c25 to disappear
Aug 22 07:58:17.959: INFO: Pod pod-configmaps-98db68f2-c4b2-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 07:58:17.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1801" for this suite.
Aug 22 07:58:23.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 07:58:24.082: INFO: namespace configmap-1801 deletion completed in 6.119850385s

• [SLOW TEST:8.292 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 07:58:24.083: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-681
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating all guestbook components
Aug 22 07:58:24.230: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Aug 22 07:58:24.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 create -f - --namespace=kubectl-681'
Aug 22 07:58:24.521: INFO: stderr: ""
Aug 22 07:58:24.522: INFO: stdout: "service/redis-slave created\n"
Aug 22 07:58:24.522: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Aug 22 07:58:24.522: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 create -f - --namespace=kubectl-681'
Aug 22 07:58:24.698: INFO: stderr: ""
Aug 22 07:58:24.698: INFO: stdout: "service/redis-master created\n"
Aug 22 07:58:24.698: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Aug 22 07:58:24.698: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 create -f - --namespace=kubectl-681'
Aug 22 07:58:24.892: INFO: stderr: ""
Aug 22 07:58:24.892: INFO: stdout: "service/frontend created\n"
Aug 22 07:58:24.894: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Aug 22 07:58:24.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 create -f - --namespace=kubectl-681'
Aug 22 07:58:25.076: INFO: stderr: ""
Aug 22 07:58:25.076: INFO: stdout: "deployment.apps/frontend created\n"
Aug 22 07:58:25.076: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Aug 22 07:58:25.076: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 create -f - --namespace=kubectl-681'
Aug 22 07:58:25.299: INFO: stderr: ""
Aug 22 07:58:25.299: INFO: stdout: "deployment.apps/redis-master created\n"
Aug 22 07:58:25.299: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Aug 22 07:58:25.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 create -f - --namespace=kubectl-681'
Aug 22 07:58:25.497: INFO: stderr: ""
Aug 22 07:58:25.497: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Aug 22 07:58:25.497: INFO: Waiting for all frontend pods to be Running.
Aug 22 07:58:30.549: INFO: Waiting for frontend to serve content.
Aug 22 07:58:30.581: INFO: Trying to add a new entry to the guestbook.
Aug 22 07:58:30.595: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Aug 22 07:58:30.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 delete --grace-period=0 --force -f - --namespace=kubectl-681'
Aug 22 07:58:30.697: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 22 07:58:30.697: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Aug 22 07:58:30.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 delete --grace-period=0 --force -f - --namespace=kubectl-681'
Aug 22 07:58:30.800: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 22 07:58:30.800: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Aug 22 07:58:30.800: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 delete --grace-period=0 --force -f - --namespace=kubectl-681'
Aug 22 07:58:30.908: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 22 07:58:30.908: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Aug 22 07:58:30.908: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 delete --grace-period=0 --force -f - --namespace=kubectl-681'
Aug 22 07:58:31.008: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 22 07:58:31.008: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Aug 22 07:58:31.009: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 delete --grace-period=0 --force -f - --namespace=kubectl-681'
Aug 22 07:58:31.140: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 22 07:58:31.140: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Aug 22 07:58:31.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 delete --grace-period=0 --force -f - --namespace=kubectl-681'
Aug 22 07:58:31.318: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 22 07:58:31.318: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 07:58:31.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-681" for this suite.
Aug 22 07:59:11.372: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 07:59:11.528: INFO: namespace kubectl-681 deletion completed in 40.203363996s

• [SLOW TEST:47.446 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 07:59:11.528: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-4775
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Aug 22 07:59:11.663: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 07:59:14.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4775" for this suite.
Aug 22 07:59:20.828: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 07:59:20.898: INFO: namespace init-container-4775 deletion completed in 6.080837532s

• [SLOW TEST:9.370 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 07:59:20.898: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3607
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-bfb1bdd5-c4b2-11e9-80b5-1edf08853c25
STEP: Creating a pod to test consume configMaps
Aug 22 07:59:21.093: INFO: Waiting up to 5m0s for pod "pod-configmaps-bfb24766-c4b2-11e9-80b5-1edf08853c25" in namespace "configmap-3607" to be "success or failure"
Aug 22 07:59:21.098: INFO: Pod "pod-configmaps-bfb24766-c4b2-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 5.116647ms
Aug 22 07:59:23.101: INFO: Pod "pod-configmaps-bfb24766-c4b2-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0083993s
STEP: Saw pod success
Aug 22 07:59:23.101: INFO: Pod "pod-configmaps-bfb24766-c4b2-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 07:59:23.107: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-configmaps-bfb24766-c4b2-11e9-80b5-1edf08853c25 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 22 07:59:23.160: INFO: Waiting for pod pod-configmaps-bfb24766-c4b2-11e9-80b5-1edf08853c25 to disappear
Aug 22 07:59:23.171: INFO: Pod pod-configmaps-bfb24766-c4b2-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 07:59:23.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3607" for this suite.
Aug 22 07:59:29.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 07:59:29.268: INFO: namespace configmap-3607 deletion completed in 6.081959047s

• [SLOW TEST:8.370 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 07:59:29.268: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1889
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Aug 22 07:59:29.407: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c4a6bc47-c4b2-11e9-80b5-1edf08853c25" in namespace "projected-1889" to be "success or failure"
Aug 22 07:59:29.415: INFO: Pod "downwardapi-volume-c4a6bc47-c4b2-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 8.396767ms
Aug 22 07:59:31.419: INFO: Pod "downwardapi-volume-c4a6bc47-c4b2-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012070485s
STEP: Saw pod success
Aug 22 07:59:31.419: INFO: Pod "downwardapi-volume-c4a6bc47-c4b2-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 07:59:31.421: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod downwardapi-volume-c4a6bc47-c4b2-11e9-80b5-1edf08853c25 container client-container: <nil>
STEP: delete the pod
Aug 22 07:59:31.438: INFO: Waiting for pod downwardapi-volume-c4a6bc47-c4b2-11e9-80b5-1edf08853c25 to disappear
Aug 22 07:59:31.439: INFO: Pod downwardapi-volume-c4a6bc47-c4b2-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 07:59:31.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1889" for this suite.
Aug 22 07:59:37.454: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 07:59:37.568: INFO: namespace projected-1889 deletion completed in 6.125497732s

• [SLOW TEST:8.300 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 07:59:37.568: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-7739
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
Aug 22 07:59:38.239: INFO: created pod pod-service-account-defaultsa
Aug 22 07:59:38.239: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Aug 22 07:59:38.253: INFO: created pod pod-service-account-mountsa
Aug 22 07:59:38.253: INFO: pod pod-service-account-mountsa service account token volume mount: true
Aug 22 07:59:38.265: INFO: created pod pod-service-account-nomountsa
Aug 22 07:59:38.265: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Aug 22 07:59:38.275: INFO: created pod pod-service-account-defaultsa-mountspec
Aug 22 07:59:38.275: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Aug 22 07:59:38.285: INFO: created pod pod-service-account-mountsa-mountspec
Aug 22 07:59:38.285: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Aug 22 07:59:38.298: INFO: created pod pod-service-account-nomountsa-mountspec
Aug 22 07:59:38.298: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Aug 22 07:59:38.307: INFO: created pod pod-service-account-defaultsa-nomountspec
Aug 22 07:59:38.307: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Aug 22 07:59:38.314: INFO: created pod pod-service-account-mountsa-nomountspec
Aug 22 07:59:38.314: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Aug 22 07:59:38.325: INFO: created pod pod-service-account-nomountsa-nomountspec
Aug 22 07:59:38.325: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 07:59:38.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-7739" for this suite.
Aug 22 08:00:00.367: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:00:00.436: INFO: namespace svcaccounts-7739 deletion completed in 22.101808527s

• [SLOW TEST:22.868 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:00:00.436: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5474
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-d73d3e87-c4b2-11e9-80b5-1edf08853c25
STEP: Creating configMap with name cm-test-opt-upd-d73d3eda-c4b2-11e9-80b5-1edf08853c25
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-d73d3e87-c4b2-11e9-80b5-1edf08853c25
STEP: Updating configmap cm-test-opt-upd-d73d3eda-c4b2-11e9-80b5-1edf08853c25
STEP: Creating configMap with name cm-test-opt-create-d73d3efc-c4b2-11e9-80b5-1edf08853c25
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:01:37.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5474" for this suite.
Aug 22 08:01:59.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:01:59.144: INFO: namespace configmap-5474 deletion completed in 22.088921123s

• [SLOW TEST:118.708 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:01:59.145: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-7356
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Aug 22 08:01:59.301: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-7356,SelfLink:/api/v1/namespaces/watch-7356/configmaps/e2e-watch-test-resource-version,UID:1dfc6714-c4b3-11e9-92bb-0afbab63fbd8,ResourceVersion:14698820,Generation:0,CreationTimestamp:2019-08-22 08:01:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 22 08:01:59.301: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-7356,SelfLink:/api/v1/namespaces/watch-7356/configmaps/e2e-watch-test-resource-version,UID:1dfc6714-c4b3-11e9-92bb-0afbab63fbd8,ResourceVersion:14698821,Generation:0,CreationTimestamp:2019-08-22 08:01:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:01:59.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7356" for this suite.
Aug 22 08:02:05.312: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:02:05.383: INFO: namespace watch-7356 deletion completed in 6.079140953s

• [SLOW TEST:6.238 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:02:05.383: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6954
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-6954/configmap-test-21b44364-c4b3-11e9-80b5-1edf08853c25
STEP: Creating a pod to test consume configMaps
Aug 22 08:02:05.527: INFO: Waiting up to 5m0s for pod "pod-configmaps-21b4d0ee-c4b3-11e9-80b5-1edf08853c25" in namespace "configmap-6954" to be "success or failure"
Aug 22 08:02:05.531: INFO: Pod "pod-configmaps-21b4d0ee-c4b3-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 3.813733ms
Aug 22 08:02:07.534: INFO: Pod "pod-configmaps-21b4d0ee-c4b3-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006977138s
Aug 22 08:02:09.538: INFO: Pod "pod-configmaps-21b4d0ee-c4b3-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010473285s
STEP: Saw pod success
Aug 22 08:02:09.538: INFO: Pod "pod-configmaps-21b4d0ee-c4b3-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:02:09.544: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-configmaps-21b4d0ee-c4b3-11e9-80b5-1edf08853c25 container env-test: <nil>
STEP: delete the pod
Aug 22 08:02:09.564: INFO: Waiting for pod pod-configmaps-21b4d0ee-c4b3-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:02:09.567: INFO: Pod pod-configmaps-21b4d0ee-c4b3-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:02:09.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6954" for this suite.
Aug 22 08:02:15.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:02:15.673: INFO: namespace configmap-6954 deletion completed in 6.100330711s

• [SLOW TEST:10.290 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:02:15.674: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-3689
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:02:17.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3689" for this suite.
Aug 22 08:03:03.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:03:03.922: INFO: namespace kubelet-test-3689 deletion completed in 46.079025831s

• [SLOW TEST:48.248 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a read only busybox container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:03:03.923: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8154
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Aug 22 08:03:04.057: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:03:06.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8154" for this suite.
Aug 22 08:03:52.109: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:03:52.178: INFO: namespace pods-8154 deletion completed in 46.078569745s

• [SLOW TEST:48.256 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:03:52.178: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-5055
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Aug 22 08:03:52.321: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Aug 22 08:03:57.324: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug 22 08:03:57.324: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Aug 22 08:03:57.355: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-5055,SelfLink:/apis/apps/v1/namespaces/deployment-5055/deployments/test-cleanup-deployment,UID:64596b20-c4b3-11e9-92bb-0afbab63fbd8,ResourceVersion:14699106,Generation:1,CreationTimestamp:2019-08-22 08:03:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Aug 22 08:03:57.364: INFO: New ReplicaSet "test-cleanup-deployment-55cbfbc8f5" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55cbfbc8f5,GenerateName:,Namespace:deployment-5055,SelfLink:/apis/apps/v1/namespaces/deployment-5055/replicasets/test-cleanup-deployment-55cbfbc8f5,UID:645c4ba1-c4b3-11e9-92bb-0afbab63fbd8,ResourceVersion:14699108,Generation:1,CreationTimestamp:2019-08-22 08:03:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 64596b20-c4b3-11e9-92bb-0afbab63fbd8 0xc000a2e667 0xc000a2e668}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 22 08:03:57.364: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Aug 22 08:03:57.364: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:deployment-5055,SelfLink:/apis/apps/v1/namespaces/deployment-5055/replicasets/test-cleanup-controller,UID:615c36bb-c4b3-11e9-92bb-0afbab63fbd8,ResourceVersion:14699107,Generation:1,CreationTimestamp:2019-08-22 08:03:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 64596b20-c4b3-11e9-92bb-0afbab63fbd8 0xc000a2e2d7 0xc000a2e2d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Aug 22 08:03:57.385: INFO: Pod "test-cleanup-controller-tv2kj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-tv2kj,GenerateName:test-cleanup-controller-,Namespace:deployment-5055,SelfLink:/api/v1/namespaces/deployment-5055/pods/test-cleanup-controller-tv2kj,UID:615d872c-c4b3-11e9-92bb-0afbab63fbd8,ResourceVersion:14699100,Generation:0,CreationTimestamp:2019-08-22 08:03:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 615c36bb-c4b3-11e9-92bb-0afbab63fbd8 0xc000a2f897 0xc000a2f898}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9pthq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9pthq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9pthq true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-24.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000a2fa40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000a2fac0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:03:52 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:03:54 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:03:54 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:03:52 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.24,PodIP:10.200.40.19,StartTime:2019-08-22 08:03:52 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-22 08:03:53 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://7d67540f04cf03909eb9a2b85d210638789e30ff68ba867d75b7aa469a2f3ee3}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 22 08:03:57.385: INFO: Pod "test-cleanup-deployment-55cbfbc8f5-8k28k" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55cbfbc8f5-8k28k,GenerateName:test-cleanup-deployment-55cbfbc8f5-,Namespace:deployment-5055,SelfLink:/api/v1/namespaces/deployment-5055/pods/test-cleanup-deployment-55cbfbc8f5-8k28k,UID:645d2e10-c4b3-11e9-92bb-0afbab63fbd8,ResourceVersion:14699112,Generation:0,CreationTimestamp:2019-08-22 08:03:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-55cbfbc8f5 645c4ba1-c4b3-11e9-92bb-0afbab63fbd8 0xc000a2fca7 0xc000a2fca8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9pthq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9pthq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-9pthq true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-24.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000a2fdd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000a2fe00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:03:57 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:03:57.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5055" for this suite.
Aug 22 08:04:03.414: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:04:03.487: INFO: namespace deployment-5055 deletion completed in 6.083962864s

• [SLOW TEST:11.309 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:04:03.488: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6253
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-6821f190-c4b3-11e9-80b5-1edf08853c25
STEP: Creating a pod to test consume secrets
Aug 22 08:04:03.687: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-68227ec3-c4b3-11e9-80b5-1edf08853c25" in namespace "projected-6253" to be "success or failure"
Aug 22 08:04:03.698: INFO: Pod "pod-projected-secrets-68227ec3-c4b3-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 10.871952ms
Aug 22 08:04:05.701: INFO: Pod "pod-projected-secrets-68227ec3-c4b3-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01440978s
STEP: Saw pod success
Aug 22 08:04:05.701: INFO: Pod "pod-projected-secrets-68227ec3-c4b3-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:04:05.704: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-projected-secrets-68227ec3-c4b3-11e9-80b5-1edf08853c25 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 22 08:04:05.727: INFO: Waiting for pod pod-projected-secrets-68227ec3-c4b3-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:04:05.729: INFO: Pod pod-projected-secrets-68227ec3-c4b3-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:04:05.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6253" for this suite.
Aug 22 08:04:11.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:04:11.809: INFO: namespace projected-6253 deletion completed in 6.075721722s

• [SLOW TEST:8.320 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:04:11.809: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-9678
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:04:13.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9678" for this suite.
Aug 22 08:05:03.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:05:04.148: INFO: namespace kubelet-test-9678 deletion completed in 50.181168316s

• [SLOW TEST:52.339 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:05:04.149: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-5924
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5924.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5924.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 22 08:05:06.340: INFO: DNS probes using dns-5924/dns-test-8c43b3b5-c4b3-11e9-80b5-1edf08853c25 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:05:06.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5924" for this suite.
Aug 22 08:05:12.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:05:12.467: INFO: namespace dns-5924 deletion completed in 6.110070708s

• [SLOW TEST:8.318 seconds]
[sig-network] DNS
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:05:12.467: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2217
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: executing a command with run --rm and attach with stdin
Aug 22 08:05:12.609: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 --namespace=kubectl-2217 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Aug 22 08:05:14.316: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Aug 22 08:05:14.316: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:05:16.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2217" for this suite.
Aug 22 08:05:22.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:05:22.403: INFO: namespace kubectl-2217 deletion completed in 6.079235446s

• [SLOW TEST:9.936 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:05:22.404: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-9319
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Aug 22 08:05:26.576: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9319 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 22 08:05:26.576: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
Aug 22 08:05:26.645: INFO: Exec stderr: ""
Aug 22 08:05:26.645: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9319 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 22 08:05:26.645: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
Aug 22 08:05:26.713: INFO: Exec stderr: ""
Aug 22 08:05:26.713: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9319 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 22 08:05:26.713: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
Aug 22 08:05:26.780: INFO: Exec stderr: ""
Aug 22 08:05:26.780: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9319 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 22 08:05:26.780: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
Aug 22 08:05:26.855: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Aug 22 08:05:26.855: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9319 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 22 08:05:26.855: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
Aug 22 08:05:26.926: INFO: Exec stderr: ""
Aug 22 08:05:26.927: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9319 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 22 08:05:26.927: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
Aug 22 08:05:27.010: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Aug 22 08:05:27.010: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9319 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 22 08:05:27.010: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
Aug 22 08:05:27.090: INFO: Exec stderr: ""
Aug 22 08:05:27.090: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9319 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 22 08:05:27.090: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
Aug 22 08:05:27.162: INFO: Exec stderr: ""
Aug 22 08:05:27.162: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9319 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 22 08:05:27.162: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
Aug 22 08:05:27.230: INFO: Exec stderr: ""
Aug 22 08:05:27.230: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9319 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 22 08:05:27.230: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
Aug 22 08:05:27.299: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:05:27.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-9319" for this suite.
Aug 22 08:06:13.312: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:06:13.384: INFO: namespace e2e-kubelet-etc-hosts-9319 deletion completed in 46.080721906s

• [SLOW TEST:50.981 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:06:13.384: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-7150
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-7150
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 22 08:06:13.518: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug 22 08:06:35.630: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.200.40.28:8080/dial?request=hostName&protocol=udp&host=10.200.40.27&port=8081&tries=1'] Namespace:pod-network-test-7150 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 22 08:06:35.630: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
Aug 22 08:06:35.701: INFO: Waiting for endpoints: map[]
Aug 22 08:06:35.704: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.200.40.28:8080/dial?request=hostName&protocol=udp&host=10.200.87.51&port=8081&tries=1'] Namespace:pod-network-test-7150 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 22 08:06:35.704: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
Aug 22 08:06:35.791: INFO: Waiting for endpoints: map[]
Aug 22 08:06:35.793: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.200.40.28:8080/dial?request=hostName&protocol=udp&host=10.200.47.153&port=8081&tries=1'] Namespace:pod-network-test-7150 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 22 08:06:35.794: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
Aug 22 08:06:35.866: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:06:35.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7150" for this suite.
Aug 22 08:06:57.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:06:57.971: INFO: namespace pod-network-test-7150 deletion completed in 22.100488211s

• [SLOW TEST:44.586 seconds]
[sig-network] Networking
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:06:57.971: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9897
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Aug 22 08:06:58.115: INFO: Waiting up to 5m0s for pod "pod-d01a2f8f-c4b3-11e9-80b5-1edf08853c25" in namespace "emptydir-9897" to be "success or failure"
Aug 22 08:06:58.123: INFO: Pod "pod-d01a2f8f-c4b3-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 8.899184ms
Aug 22 08:07:00.127: INFO: Pod "pod-d01a2f8f-c4b3-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012170993s
STEP: Saw pod success
Aug 22 08:07:00.127: INFO: Pod "pod-d01a2f8f-c4b3-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:07:00.129: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-d01a2f8f-c4b3-11e9-80b5-1edf08853c25 container test-container: <nil>
STEP: delete the pod
Aug 22 08:07:00.145: INFO: Waiting for pod pod-d01a2f8f-c4b3-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:07:00.147: INFO: Pod pod-d01a2f8f-c4b3-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:07:00.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9897" for this suite.
Aug 22 08:07:06.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:07:06.237: INFO: namespace emptydir-9897 deletion completed in 6.084681386s

• [SLOW TEST:8.266 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:07:06.237: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-4616
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's args
Aug 22 08:07:06.382: INFO: Waiting up to 5m0s for pod "var-expansion-d507779b-c4b3-11e9-80b5-1edf08853c25" in namespace "var-expansion-4616" to be "success or failure"
Aug 22 08:07:06.388: INFO: Pod "var-expansion-d507779b-c4b3-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 6.173172ms
Aug 22 08:07:08.392: INFO: Pod "var-expansion-d507779b-c4b3-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009929989s
STEP: Saw pod success
Aug 22 08:07:08.392: INFO: Pod "var-expansion-d507779b-c4b3-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:07:08.394: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod var-expansion-d507779b-c4b3-11e9-80b5-1edf08853c25 container dapi-container: <nil>
STEP: delete the pod
Aug 22 08:07:08.411: INFO: Waiting for pod var-expansion-d507779b-c4b3-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:07:08.413: INFO: Pod var-expansion-d507779b-c4b3-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:07:08.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4616" for this suite.
Aug 22 08:07:14.425: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:07:14.493: INFO: namespace var-expansion-4616 deletion completed in 6.076587333s

• [SLOW TEST:8.256 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:07:14.493: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7502
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Aug 22 08:07:14.640: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d9f3adae-c4b3-11e9-80b5-1edf08853c25" in namespace "downward-api-7502" to be "success or failure"
Aug 22 08:07:14.647: INFO: Pod "downwardapi-volume-d9f3adae-c4b3-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 6.28496ms
Aug 22 08:07:16.650: INFO: Pod "downwardapi-volume-d9f3adae-c4b3-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009386481s
STEP: Saw pod success
Aug 22 08:07:16.650: INFO: Pod "downwardapi-volume-d9f3adae-c4b3-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:07:16.652: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod downwardapi-volume-d9f3adae-c4b3-11e9-80b5-1edf08853c25 container client-container: <nil>
STEP: delete the pod
Aug 22 08:07:16.669: INFO: Waiting for pod downwardapi-volume-d9f3adae-c4b3-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:07:16.672: INFO: Pod downwardapi-volume-d9f3adae-c4b3-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:07:16.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7502" for this suite.
Aug 22 08:07:22.685: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:07:22.756: INFO: namespace downward-api-7502 deletion completed in 6.080151174s

• [SLOW TEST:8.263 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:07:22.756: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9075
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-dee7c09d-c4b3-11e9-80b5-1edf08853c25
STEP: Creating a pod to test consume configMaps
Aug 22 08:07:22.954: INFO: Waiting up to 5m0s for pod "pod-configmaps-dee866cf-c4b3-11e9-80b5-1edf08853c25" in namespace "configmap-9075" to be "success or failure"
Aug 22 08:07:22.963: INFO: Pod "pod-configmaps-dee866cf-c4b3-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 9.021146ms
Aug 22 08:07:24.966: INFO: Pod "pod-configmaps-dee866cf-c4b3-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012235282s
STEP: Saw pod success
Aug 22 08:07:24.966: INFO: Pod "pod-configmaps-dee866cf-c4b3-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:07:24.968: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-configmaps-dee866cf-c4b3-11e9-80b5-1edf08853c25 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 22 08:07:24.982: INFO: Waiting for pod pod-configmaps-dee866cf-c4b3-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:07:24.986: INFO: Pod pod-configmaps-dee866cf-c4b3-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:07:24.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9075" for this suite.
Aug 22 08:07:30.997: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:07:31.066: INFO: namespace configmap-9075 deletion completed in 6.076811662s

• [SLOW TEST:8.310 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:07:31.066: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-8113
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Aug 22 08:07:31.249: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 22 08:07:31.258: INFO: Waiting for terminating namespaces to be deleted...
Aug 22 08:07:31.260: INFO: 
Logging pods the kubelet thinks is on node ip-10-90-32-22.eu-west-2.compute.internal before test
Aug 22 08:07:31.278: INFO: kubernetes-dashboard-6c68548bc9-8z59b from kube-system started at 2019-08-21 21:26:22 +0000 UTC (1 container statuses recorded)
Aug 22 08:07:31.278: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Aug 22 08:07:31.278: INFO: metrics-server-cf9d8cd8c-jtb99 from kube-system started at 2019-08-21 21:26:22 +0000 UTC (1 container statuses recorded)
Aug 22 08:07:31.278: INFO: 	Container metrics-server ready: true, restart count 0
Aug 22 08:07:31.278: INFO: rabbit-rabbitmq-ha-0 from default started at 2019-08-21 21:26:32 +0000 UTC (1 container statuses recorded)
Aug 22 08:07:31.278: INFO: 	Container rabbitmq-ha ready: true, restart count 0
Aug 22 08:07:31.278: INFO: harbor-harbor-redis-0 from default started at 2019-08-21 21:26:37 +0000 UTC (1 container statuses recorded)
Aug 22 08:07:31.278: INFO: 	Container redis ready: true, restart count 0
Aug 22 08:07:31.278: INFO: ss2-2 from statefulset-3821 started at 2019-08-21 21:27:59 +0000 UTC (1 container statuses recorded)
Aug 22 08:07:31.278: INFO: 	Container nginx ready: true, restart count 0
Aug 22 08:07:31.278: INFO: filebeat-5nfcr from kube-system started at 2019-08-21 21:26:09 +0000 UTC (1 container statuses recorded)
Aug 22 08:07:31.278: INFO: 	Container filebeat ready: true, restart count 0
Aug 22 08:07:31.278: INFO: harbor-harbor-notary-signer-5d8849d69b-q5sxq from default started at 2019-08-21 21:26:22 +0000 UTC (1 container statuses recorded)
Aug 22 08:07:31.278: INFO: 	Container notary-signer ready: true, restart count 1
Aug 22 08:07:31.278: INFO: harbor-harbor-jobservice-55d6cbcfd8-lw9hj from default started at 2019-08-21 21:26:22 +0000 UTC (1 container statuses recorded)
Aug 22 08:07:31.278: INFO: 	Container jobservice ready: true, restart count 0
Aug 22 08:07:31.278: INFO: ss2-0 from statefulset-3821 started at 2019-08-21 21:26:32 +0000 UTC (1 container statuses recorded)
Aug 22 08:07:31.278: INFO: 	Container nginx ready: true, restart count 0
Aug 22 08:07:31.278: INFO: harbor-harbor-database-0 from default started at 2019-08-21 21:26:36 +0000 UTC (1 container statuses recorded)
Aug 22 08:07:31.278: INFO: 	Container database ready: true, restart count 0
Aug 22 08:07:31.278: INFO: rabbit-rabbitmq-ha-2 from default started at 2019-08-21 21:26:54 +0000 UTC (1 container statuses recorded)
Aug 22 08:07:31.278: INFO: 	Container rabbitmq-ha ready: true, restart count 0
Aug 22 08:07:31.278: INFO: sonobuoy-systemd-logs-daemon-set-77a1f61d77c0402d-9cdch from heptio-sonobuoy started at 2019-08-22 07:41:47 +0000 UTC (2 container statuses recorded)
Aug 22 08:07:31.278: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 22 08:07:31.278: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 22 08:07:31.278: INFO: tiller-deploy-66b7dd976-9s6xn from kube-system started at 2019-08-21 21:26:22 +0000 UTC (1 container statuses recorded)
Aug 22 08:07:31.278: INFO: 	Container tiller ready: true, restart count 0
Aug 22 08:07:31.278: INFO: harbor-harbor-core-6576c89d75-d964k from default started at 2019-08-21 21:26:22 +0000 UTC (1 container statuses recorded)
Aug 22 08:07:31.278: INFO: 	Container core ready: true, restart count 1
Aug 22 08:07:31.278: INFO: coredns-54586579f6-ncd2w from kube-system started at 2019-08-21 21:26:22 +0000 UTC (1 container statuses recorded)
Aug 22 08:07:31.278: INFO: 	Container coredns ready: true, restart count 0
Aug 22 08:07:31.278: INFO: harbor-harbor-chartmuseum-6c9cfcb75-ccf7f from default started at 2019-08-21 21:26:22 +0000 UTC (1 container statuses recorded)
Aug 22 08:07:31.278: INFO: 	Container chartmuseum ready: true, restart count 0
Aug 22 08:07:31.278: INFO: traefik-ingress-controller-sqvfm from traefik-ingress started at 2019-08-22 07:35:59 +0000 UTC (1 container statuses recorded)
Aug 22 08:07:31.278: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Aug 22 08:07:31.278: INFO: 
Logging pods the kubelet thinks is on node ip-10-90-32-23.eu-west-2.compute.internal before test
Aug 22 08:07:31.294: INFO: sonobuoy-systemd-logs-daemon-set-77a1f61d77c0402d-k88tw from heptio-sonobuoy started at 2019-08-22 07:41:47 +0000 UTC (2 container statuses recorded)
Aug 22 08:07:31.294: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 22 08:07:31.294: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 22 08:07:31.294: INFO: filebeat-gdpxp from kube-system started at 2019-08-21 21:27:29 +0000 UTC (1 container statuses recorded)
Aug 22 08:07:31.294: INFO: 	Container filebeat ready: true, restart count 0
Aug 22 08:07:31.294: INFO: harbor-harbor-clair-54c47dfdfc-rxdrv from default started at 2019-08-21 21:27:38 +0000 UTC (1 container statuses recorded)
Aug 22 08:07:31.294: INFO: 	Container clair ready: true, restart count 0
Aug 22 08:07:31.294: INFO: coredns-54586579f6-29wj8 from kube-system started at 2019-08-21 21:27:39 +0000 UTC (1 container statuses recorded)
Aug 22 08:07:31.294: INFO: 	Container coredns ready: true, restart count 0
Aug 22 08:07:31.294: INFO: harbor-harbor-portal-6cbfc59497-k7qzj from default started at 2019-08-21 21:27:39 +0000 UTC (1 container statuses recorded)
Aug 22 08:07:31.294: INFO: 	Container portal ready: true, restart count 0
Aug 22 08:07:31.294: INFO: coredns-54586579f6-frkn5 from kube-system started at 2019-08-21 21:27:39 +0000 UTC (1 container statuses recorded)
Aug 22 08:07:31.294: INFO: 	Container coredns ready: true, restart count 0
Aug 22 08:07:31.294: INFO: rabbit-rabbitmq-ha-1 from default started at 2019-08-21 21:27:50 +0000 UTC (1 container statuses recorded)
Aug 22 08:07:31.294: INFO: 	Container rabbitmq-ha ready: true, restart count 0
Aug 22 08:07:31.294: INFO: petclinic-7c86cccbdc-krcsq from default started at 2019-08-21 21:27:38 +0000 UTC (1 container statuses recorded)
Aug 22 08:07:31.294: INFO: 	Container petclinic ready: true, restart count 0
Aug 22 08:07:31.294: INFO: hello-python-866d7f447b-8v4p4 from default started at 2019-08-21 21:27:38 +0000 UTC (1 container statuses recorded)
Aug 22 08:07:31.294: INFO: 	Container hello-python ready: true, restart count 0
Aug 22 08:07:31.294: INFO: tiller-deploy-775fdcb4cb-8rqxz from test started at 2019-08-21 21:27:39 +0000 UTC (1 container statuses recorded)
Aug 22 08:07:31.294: INFO: 	Container tiller ready: true, restart count 0
Aug 22 08:07:31.294: INFO: harbor-harbor-notary-server-7fd5cb4874-zm57q from default started at 2019-08-21 21:27:38 +0000 UTC (1 container statuses recorded)
Aug 22 08:07:31.294: INFO: 	Container notary-server ready: true, restart count 0
Aug 22 08:07:31.294: INFO: python-5c8bdf49c5-4gn9f from default started at 2019-08-21 21:27:39 +0000 UTC (1 container statuses recorded)
Aug 22 08:07:31.294: INFO: 	Container python ready: true, restart count 0
Aug 22 08:07:31.294: INFO: ss2-1 from statefulset-3821 started at 2019-08-21 21:27:48 +0000 UTC (1 container statuses recorded)
Aug 22 08:07:31.294: INFO: 	Container nginx ready: true, restart count 0
Aug 22 08:07:31.294: INFO: traefik-ingress-controller-w9znh from traefik-ingress started at 2019-08-22 07:35:39 +0000 UTC (1 container statuses recorded)
Aug 22 08:07:31.294: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Aug 22 08:07:31.294: INFO: harbor-harbor-registry-bffc4f6b-prl88 from default started at 2019-08-21 21:27:38 +0000 UTC (2 container statuses recorded)
Aug 22 08:07:31.294: INFO: 	Container registry ready: true, restart count 0
Aug 22 08:07:31.294: INFO: 	Container registryctl ready: true, restart count 0
Aug 22 08:07:31.294: INFO: 
Logging pods the kubelet thinks is on node ip-10-90-32-24.eu-west-2.compute.internal before test
Aug 22 08:07:31.298: INFO: sonobuoy from heptio-sonobuoy started at 2019-08-22 07:41:45 +0000 UTC (1 container statuses recorded)
Aug 22 08:07:31.298: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 22 08:07:31.298: INFO: filebeat-xvmwc from kube-system started at 2019-08-21 21:28:49 +0000 UTC (1 container statuses recorded)
Aug 22 08:07:31.298: INFO: 	Container filebeat ready: true, restart count 0
Aug 22 08:07:31.298: INFO: traefik-ingress-controller-4vj7g from traefik-ingress started at 2019-08-22 07:35:44 +0000 UTC (1 container statuses recorded)
Aug 22 08:07:31.298: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Aug 22 08:07:31.298: INFO: sonobuoy-systemd-logs-daemon-set-77a1f61d77c0402d-qnkzk from heptio-sonobuoy started at 2019-08-22 07:41:47 +0000 UTC (2 container statuses recorded)
Aug 22 08:07:31.298: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 22 08:07:31.298: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 22 08:07:31.298: INFO: sonobuoy-e2e-job-3bb06073b99141d8 from heptio-sonobuoy started at 2019-08-22 07:41:47 +0000 UTC (2 container statuses recorded)
Aug 22 08:07:31.298: INFO: 	Container e2e ready: true, restart count 0
Aug 22 08:07:31.298: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: verifying the node has the label node ip-10-90-32-22.eu-west-2.compute.internal
STEP: verifying the node has the label node ip-10-90-32-23.eu-west-2.compute.internal
STEP: verifying the node has the label node ip-10-90-32-24.eu-west-2.compute.internal
Aug 22 08:07:31.352: INFO: Pod harbor-harbor-chartmuseum-6c9cfcb75-ccf7f requesting resource cpu=0m on Node ip-10-90-32-22.eu-west-2.compute.internal
Aug 22 08:07:31.352: INFO: Pod harbor-harbor-clair-54c47dfdfc-rxdrv requesting resource cpu=0m on Node ip-10-90-32-23.eu-west-2.compute.internal
Aug 22 08:07:31.352: INFO: Pod harbor-harbor-core-6576c89d75-d964k requesting resource cpu=0m on Node ip-10-90-32-22.eu-west-2.compute.internal
Aug 22 08:07:31.352: INFO: Pod harbor-harbor-database-0 requesting resource cpu=0m on Node ip-10-90-32-22.eu-west-2.compute.internal
Aug 22 08:07:31.352: INFO: Pod harbor-harbor-jobservice-55d6cbcfd8-lw9hj requesting resource cpu=0m on Node ip-10-90-32-22.eu-west-2.compute.internal
Aug 22 08:07:31.352: INFO: Pod harbor-harbor-notary-server-7fd5cb4874-zm57q requesting resource cpu=0m on Node ip-10-90-32-23.eu-west-2.compute.internal
Aug 22 08:07:31.352: INFO: Pod harbor-harbor-notary-signer-5d8849d69b-q5sxq requesting resource cpu=0m on Node ip-10-90-32-22.eu-west-2.compute.internal
Aug 22 08:07:31.352: INFO: Pod harbor-harbor-portal-6cbfc59497-k7qzj requesting resource cpu=0m on Node ip-10-90-32-23.eu-west-2.compute.internal
Aug 22 08:07:31.352: INFO: Pod harbor-harbor-redis-0 requesting resource cpu=0m on Node ip-10-90-32-22.eu-west-2.compute.internal
Aug 22 08:07:31.352: INFO: Pod harbor-harbor-registry-bffc4f6b-prl88 requesting resource cpu=0m on Node ip-10-90-32-23.eu-west-2.compute.internal
Aug 22 08:07:31.352: INFO: Pod hello-python-866d7f447b-8v4p4 requesting resource cpu=0m on Node ip-10-90-32-23.eu-west-2.compute.internal
Aug 22 08:07:31.352: INFO: Pod petclinic-7c86cccbdc-krcsq requesting resource cpu=0m on Node ip-10-90-32-23.eu-west-2.compute.internal
Aug 22 08:07:31.352: INFO: Pod python-5c8bdf49c5-4gn9f requesting resource cpu=0m on Node ip-10-90-32-23.eu-west-2.compute.internal
Aug 22 08:07:31.352: INFO: Pod rabbit-rabbitmq-ha-0 requesting resource cpu=0m on Node ip-10-90-32-22.eu-west-2.compute.internal
Aug 22 08:07:31.352: INFO: Pod rabbit-rabbitmq-ha-1 requesting resource cpu=0m on Node ip-10-90-32-23.eu-west-2.compute.internal
Aug 22 08:07:31.352: INFO: Pod rabbit-rabbitmq-ha-2 requesting resource cpu=0m on Node ip-10-90-32-22.eu-west-2.compute.internal
Aug 22 08:07:31.352: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-10-90-32-24.eu-west-2.compute.internal
Aug 22 08:07:31.352: INFO: Pod sonobuoy-e2e-job-3bb06073b99141d8 requesting resource cpu=0m on Node ip-10-90-32-24.eu-west-2.compute.internal
Aug 22 08:07:31.352: INFO: Pod sonobuoy-systemd-logs-daemon-set-77a1f61d77c0402d-9cdch requesting resource cpu=0m on Node ip-10-90-32-22.eu-west-2.compute.internal
Aug 22 08:07:31.352: INFO: Pod sonobuoy-systemd-logs-daemon-set-77a1f61d77c0402d-k88tw requesting resource cpu=0m on Node ip-10-90-32-23.eu-west-2.compute.internal
Aug 22 08:07:31.352: INFO: Pod sonobuoy-systemd-logs-daemon-set-77a1f61d77c0402d-qnkzk requesting resource cpu=0m on Node ip-10-90-32-24.eu-west-2.compute.internal
Aug 22 08:07:31.352: INFO: Pod coredns-54586579f6-29wj8 requesting resource cpu=100m on Node ip-10-90-32-23.eu-west-2.compute.internal
Aug 22 08:07:31.352: INFO: Pod coredns-54586579f6-frkn5 requesting resource cpu=100m on Node ip-10-90-32-23.eu-west-2.compute.internal
Aug 22 08:07:31.352: INFO: Pod coredns-54586579f6-ncd2w requesting resource cpu=100m on Node ip-10-90-32-22.eu-west-2.compute.internal
Aug 22 08:07:31.352: INFO: Pod filebeat-5nfcr requesting resource cpu=100m on Node ip-10-90-32-22.eu-west-2.compute.internal
Aug 22 08:07:31.352: INFO: Pod filebeat-gdpxp requesting resource cpu=100m on Node ip-10-90-32-23.eu-west-2.compute.internal
Aug 22 08:07:31.352: INFO: Pod filebeat-xvmwc requesting resource cpu=100m on Node ip-10-90-32-24.eu-west-2.compute.internal
Aug 22 08:07:31.352: INFO: Pod kubernetes-dashboard-6c68548bc9-8z59b requesting resource cpu=50m on Node ip-10-90-32-22.eu-west-2.compute.internal
Aug 22 08:07:31.352: INFO: Pod metrics-server-cf9d8cd8c-jtb99 requesting resource cpu=0m on Node ip-10-90-32-22.eu-west-2.compute.internal
Aug 22 08:07:31.352: INFO: Pod tiller-deploy-66b7dd976-9s6xn requesting resource cpu=0m on Node ip-10-90-32-22.eu-west-2.compute.internal
Aug 22 08:07:31.352: INFO: Pod ss2-0 requesting resource cpu=0m on Node ip-10-90-32-22.eu-west-2.compute.internal
Aug 22 08:07:31.352: INFO: Pod ss2-1 requesting resource cpu=0m on Node ip-10-90-32-23.eu-west-2.compute.internal
Aug 22 08:07:31.352: INFO: Pod ss2-2 requesting resource cpu=0m on Node ip-10-90-32-22.eu-west-2.compute.internal
Aug 22 08:07:31.352: INFO: Pod tiller-deploy-775fdcb4cb-8rqxz requesting resource cpu=0m on Node ip-10-90-32-23.eu-west-2.compute.internal
Aug 22 08:07:31.352: INFO: Pod traefik-ingress-controller-4vj7g requesting resource cpu=0m on Node ip-10-90-32-24.eu-west-2.compute.internal
Aug 22 08:07:31.352: INFO: Pod traefik-ingress-controller-sqvfm requesting resource cpu=0m on Node ip-10-90-32-22.eu-west-2.compute.internal
Aug 22 08:07:31.352: INFO: Pod traefik-ingress-controller-w9znh requesting resource cpu=0m on Node ip-10-90-32-23.eu-west-2.compute.internal
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e3eb004c-c4b3-11e9-80b5-1edf08853c25.15bd30356a08cf00], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8113/filler-pod-e3eb004c-c4b3-11e9-80b5-1edf08853c25 to ip-10-90-32-22.eu-west-2.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e3eb004c-c4b3-11e9-80b5-1edf08853c25.15bd30359ccdd41f], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e3eb004c-c4b3-11e9-80b5-1edf08853c25.15bd3035a0cc846f], Reason = [Created], Message = [Created container filler-pod-e3eb004c-c4b3-11e9-80b5-1edf08853c25]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e3eb004c-c4b3-11e9-80b5-1edf08853c25.15bd3035af78f1ef], Reason = [Started], Message = [Started container filler-pod-e3eb004c-c4b3-11e9-80b5-1edf08853c25]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e3ec0933-c4b3-11e9-80b5-1edf08853c25.15bd30356ad7b116], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8113/filler-pod-e3ec0933-c4b3-11e9-80b5-1edf08853c25 to ip-10-90-32-23.eu-west-2.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e3ec0933-c4b3-11e9-80b5-1edf08853c25.15bd3035a00c7edc], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e3ec0933-c4b3-11e9-80b5-1edf08853c25.15bd3035a3d7c5c4], Reason = [Created], Message = [Created container filler-pod-e3ec0933-c4b3-11e9-80b5-1edf08853c25]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e3ec0933-c4b3-11e9-80b5-1edf08853c25.15bd3035b08eba6a], Reason = [Started], Message = [Started container filler-pod-e3ec0933-c4b3-11e9-80b5-1edf08853c25]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e3ed7525-c4b3-11e9-80b5-1edf08853c25.15bd30356b2787f9], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8113/filler-pod-e3ed7525-c4b3-11e9-80b5-1edf08853c25 to ip-10-90-32-24.eu-west-2.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e3ed7525-c4b3-11e9-80b5-1edf08853c25.15bd30359e8f55fa], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e3ed7525-c4b3-11e9-80b5-1edf08853c25.15bd3035a233eb07], Reason = [Created], Message = [Created container filler-pod-e3ed7525-c4b3-11e9-80b5-1edf08853c25]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e3ed7525-c4b3-11e9-80b5-1edf08853c25.15bd3035aa2c50c3], Reason = [Started], Message = [Started container filler-pod-e3ed7525-c4b3-11e9-80b5-1edf08853c25]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15bd30365b5778ec], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node ip-10-90-32-22.eu-west-2.compute.internal
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-10-90-32-23.eu-west-2.compute.internal
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-10-90-32-24.eu-west-2.compute.internal
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:07:36.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8113" for this suite.
Aug 22 08:07:42.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:07:42.554: INFO: namespace sched-pred-8113 deletion completed in 6.078719628s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:11.488 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:07:42.555: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8402
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Aug 22 08:07:42.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 create -f - --namespace=kubectl-8402'
Aug 22 08:07:42.843: INFO: stderr: ""
Aug 22 08:07:42.843: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug 22 08:07:43.846: INFO: Selector matched 1 pods for map[app:redis]
Aug 22 08:07:43.846: INFO: Found 0 / 1
Aug 22 08:07:44.846: INFO: Selector matched 1 pods for map[app:redis]
Aug 22 08:07:44.846: INFO: Found 1 / 1
Aug 22 08:07:44.846: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Aug 22 08:07:44.848: INFO: Selector matched 1 pods for map[app:redis]
Aug 22 08:07:44.848: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 22 08:07:44.848: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 patch pod redis-master-8g4qj --namespace=kubectl-8402 -p {"metadata":{"annotations":{"x":"y"}}}'
Aug 22 08:07:44.920: INFO: stderr: ""
Aug 22 08:07:44.920: INFO: stdout: "pod/redis-master-8g4qj patched\n"
STEP: checking annotations
Aug 22 08:07:44.922: INFO: Selector matched 1 pods for map[app:redis]
Aug 22 08:07:44.922: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:07:44.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8402" for this suite.
Aug 22 08:08:06.933: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:08:07.004: INFO: namespace kubectl-8402 deletion completed in 22.078640593s

• [SLOW TEST:24.450 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:08:07.004: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9166
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Aug 22 08:08:07.143: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f93f24f5-c4b3-11e9-80b5-1edf08853c25" in namespace "downward-api-9166" to be "success or failure"
Aug 22 08:08:07.151: INFO: Pod "downwardapi-volume-f93f24f5-c4b3-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 7.638048ms
Aug 22 08:08:09.154: INFO: Pod "downwardapi-volume-f93f24f5-c4b3-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010843405s
STEP: Saw pod success
Aug 22 08:08:09.154: INFO: Pod "downwardapi-volume-f93f24f5-c4b3-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:08:09.156: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod downwardapi-volume-f93f24f5-c4b3-11e9-80b5-1edf08853c25 container client-container: <nil>
STEP: delete the pod
Aug 22 08:08:09.174: INFO: Waiting for pod downwardapi-volume-f93f24f5-c4b3-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:08:09.176: INFO: Pod downwardapi-volume-f93f24f5-c4b3-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:08:09.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9166" for this suite.
Aug 22 08:08:15.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:08:15.258: INFO: namespace downward-api-9166 deletion completed in 6.077988387s

• [SLOW TEST:8.253 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:08:15.258: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8259
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Aug 22 08:08:15.397: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fe2a8b72-c4b3-11e9-80b5-1edf08853c25" in namespace "projected-8259" to be "success or failure"
Aug 22 08:08:15.402: INFO: Pod "downwardapi-volume-fe2a8b72-c4b3-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 4.784358ms
Aug 22 08:08:17.405: INFO: Pod "downwardapi-volume-fe2a8b72-c4b3-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007699283s
STEP: Saw pod success
Aug 22 08:08:17.405: INFO: Pod "downwardapi-volume-fe2a8b72-c4b3-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:08:17.407: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod downwardapi-volume-fe2a8b72-c4b3-11e9-80b5-1edf08853c25 container client-container: <nil>
STEP: delete the pod
Aug 22 08:08:17.423: INFO: Waiting for pod downwardapi-volume-fe2a8b72-c4b3-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:08:17.425: INFO: Pod downwardapi-volume-fe2a8b72-c4b3-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:08:17.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8259" for this suite.
Aug 22 08:08:23.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:08:23.506: INFO: namespace projected-8259 deletion completed in 6.077532682s

• [SLOW TEST:8.248 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:08:23.506: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3510
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Aug 22 08:08:23.646: INFO: Waiting up to 5m0s for pod "pod-03153ff8-c4b4-11e9-80b5-1edf08853c25" in namespace "emptydir-3510" to be "success or failure"
Aug 22 08:08:23.649: INFO: Pod "pod-03153ff8-c4b4-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 3.694043ms
Aug 22 08:08:25.652: INFO: Pod "pod-03153ff8-c4b4-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006777754s
STEP: Saw pod success
Aug 22 08:08:25.652: INFO: Pod "pod-03153ff8-c4b4-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:08:25.654: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-03153ff8-c4b4-11e9-80b5-1edf08853c25 container test-container: <nil>
STEP: delete the pod
Aug 22 08:08:25.668: INFO: Waiting for pod pod-03153ff8-c4b4-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:08:25.671: INFO: Pod pod-03153ff8-c4b4-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:08:25.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3510" for this suite.
Aug 22 08:08:31.682: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:08:31.814: INFO: namespace emptydir-3510 deletion completed in 6.139885943s

• [SLOW TEST:8.308 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:08:31.815: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-5937
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-5937
Aug 22 08:08:34.006: INFO: Started pod liveness-http in namespace container-probe-5937
STEP: checking the pod's current state and verifying that restartCount is present
Aug 22 08:08:34.009: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:12:34.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5937" for this suite.
Aug 22 08:12:40.437: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:12:40.563: INFO: namespace container-probe-5937 deletion completed in 6.137406039s

• [SLOW TEST:248.748 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:12:40.563: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-7304
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 pods, got 2 pods
STEP: expected 0 rs, got 1 rs
STEP: Gathering metrics
W0822 08:12:41.295210      14 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 22 08:12:41.295: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:12:41.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7304" for this suite.
Aug 22 08:12:47.306: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:12:47.378: INFO: namespace gc-7304 deletion completed in 6.079854299s

• [SLOW TEST:6.815 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:12:47.378: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7570
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Aug 22 08:12:47.521: INFO: Waiting up to 5m0s for pod "downward-api-a05d400c-c4b4-11e9-80b5-1edf08853c25" in namespace "downward-api-7570" to be "success or failure"
Aug 22 08:12:47.537: INFO: Pod "downward-api-a05d400c-c4b4-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 16.228965ms
Aug 22 08:12:49.541: INFO: Pod "downward-api-a05d400c-c4b4-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019723539s
STEP: Saw pod success
Aug 22 08:12:49.541: INFO: Pod "downward-api-a05d400c-c4b4-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:12:49.543: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod downward-api-a05d400c-c4b4-11e9-80b5-1edf08853c25 container dapi-container: <nil>
STEP: delete the pod
Aug 22 08:12:49.562: INFO: Waiting for pod downward-api-a05d400c-c4b4-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:12:49.564: INFO: Pod downward-api-a05d400c-c4b4-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:12:49.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7570" for this suite.
Aug 22 08:12:55.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:12:55.698: INFO: namespace downward-api-7570 deletion completed in 6.13004881s

• [SLOW TEST:8.319 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:12:55.699: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6963
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-projected-all-test-volume-a55a28aa-c4b4-11e9-80b5-1edf08853c25
STEP: Creating secret with name secret-projected-all-test-volume-a55a288b-c4b4-11e9-80b5-1edf08853c25
STEP: Creating a pod to test Check all projections for projected volume plugin
Aug 22 08:12:55.896: INFO: Waiting up to 5m0s for pod "projected-volume-a55a2846-c4b4-11e9-80b5-1edf08853c25" in namespace "projected-6963" to be "success or failure"
Aug 22 08:12:55.903: INFO: Pod "projected-volume-a55a2846-c4b4-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 7.600583ms
Aug 22 08:12:57.906: INFO: Pod "projected-volume-a55a2846-c4b4-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010708943s
STEP: Saw pod success
Aug 22 08:12:57.906: INFO: Pod "projected-volume-a55a2846-c4b4-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:12:57.908: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod projected-volume-a55a2846-c4b4-11e9-80b5-1edf08853c25 container projected-all-volume-test: <nil>
STEP: delete the pod
Aug 22 08:12:57.924: INFO: Waiting for pod projected-volume-a55a2846-c4b4-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:12:57.927: INFO: Pod projected-volume-a55a2846-c4b4-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:12:57.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6963" for this suite.
Aug 22 08:13:03.944: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:13:04.019: INFO: namespace projected-6963 deletion completed in 6.089299316s

• [SLOW TEST:8.321 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:13:04.020: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1481
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-aa483939-c4b4-11e9-80b5-1edf08853c25
STEP: Creating a pod to test consume configMaps
Aug 22 08:13:04.163: INFO: Waiting up to 5m0s for pod "pod-configmaps-aa48c22b-c4b4-11e9-80b5-1edf08853c25" in namespace "configmap-1481" to be "success or failure"
Aug 22 08:13:04.174: INFO: Pod "pod-configmaps-aa48c22b-c4b4-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 11.775392ms
Aug 22 08:13:06.178: INFO: Pod "pod-configmaps-aa48c22b-c4b4-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01510642s
STEP: Saw pod success
Aug 22 08:13:06.178: INFO: Pod "pod-configmaps-aa48c22b-c4b4-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:13:06.180: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-configmaps-aa48c22b-c4b4-11e9-80b5-1edf08853c25 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 22 08:13:06.195: INFO: Waiting for pod pod-configmaps-aa48c22b-c4b4-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:13:06.198: INFO: Pod pod-configmaps-aa48c22b-c4b4-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:13:06.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1481" for this suite.
Aug 22 08:13:12.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:13:12.315: INFO: namespace configmap-1481 deletion completed in 6.11419996s

• [SLOW TEST:8.296 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:13:12.316: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9518
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Aug 22 08:13:16.977: INFO: Successfully updated pod "pod-update-af3a5c23-c4b4-11e9-80b5-1edf08853c25"
STEP: verifying the updated pod is in kubernetes
Aug 22 08:13:16.981: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:13:16.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9518" for this suite.
Aug 22 08:13:38.992: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:13:39.163: INFO: namespace pods-9518 deletion completed in 22.178504033s

• [SLOW TEST:26.847 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:13:39.163: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3727
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-bf3b2c4f-c4b4-11e9-80b5-1edf08853c25
STEP: Creating a pod to test consume secrets
Aug 22 08:13:39.313: INFO: Waiting up to 5m0s for pod "pod-secrets-bf3bc0d2-c4b4-11e9-80b5-1edf08853c25" in namespace "secrets-3727" to be "success or failure"
Aug 22 08:13:39.322: INFO: Pod "pod-secrets-bf3bc0d2-c4b4-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 9.15906ms
Aug 22 08:13:41.325: INFO: Pod "pod-secrets-bf3bc0d2-c4b4-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012251524s
STEP: Saw pod success
Aug 22 08:13:41.325: INFO: Pod "pod-secrets-bf3bc0d2-c4b4-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:13:41.327: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-secrets-bf3bc0d2-c4b4-11e9-80b5-1edf08853c25 container secret-volume-test: <nil>
STEP: delete the pod
Aug 22 08:13:41.343: INFO: Waiting for pod pod-secrets-bf3bc0d2-c4b4-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:13:41.346: INFO: Pod pod-secrets-bf3bc0d2-c4b4-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:13:41.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3727" for this suite.
Aug 22 08:13:47.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:13:47.437: INFO: namespace secrets-3727 deletion completed in 6.087378615s

• [SLOW TEST:8.274 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:13:47.437: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-9567
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Aug 22 08:13:47.574: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 22 08:13:47.580: INFO: Waiting for terminating namespaces to be deleted...
Aug 22 08:13:47.582: INFO: 
Logging pods the kubelet thinks is on node ip-10-90-32-22.eu-west-2.compute.internal before test
Aug 22 08:13:47.590: INFO: kubernetes-dashboard-6c68548bc9-8z59b from kube-system started at 2019-08-21 21:26:22 +0000 UTC (1 container statuses recorded)
Aug 22 08:13:47.590: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Aug 22 08:13:47.590: INFO: rabbit-rabbitmq-ha-0 from default started at 2019-08-21 21:26:32 +0000 UTC (1 container statuses recorded)
Aug 22 08:13:47.590: INFO: 	Container rabbitmq-ha ready: true, restart count 0
Aug 22 08:13:47.590: INFO: harbor-harbor-redis-0 from default started at 2019-08-21 21:26:37 +0000 UTC (1 container statuses recorded)
Aug 22 08:13:47.590: INFO: 	Container redis ready: true, restart count 0
Aug 22 08:13:47.590: INFO: ss2-2 from statefulset-3821 started at 2019-08-21 21:27:59 +0000 UTC (1 container statuses recorded)
Aug 22 08:13:47.590: INFO: 	Container nginx ready: true, restart count 0
Aug 22 08:13:47.590: INFO: filebeat-5nfcr from kube-system started at 2019-08-21 21:26:09 +0000 UTC (1 container statuses recorded)
Aug 22 08:13:47.590: INFO: 	Container filebeat ready: true, restart count 0
Aug 22 08:13:47.590: INFO: harbor-harbor-notary-signer-5d8849d69b-q5sxq from default started at 2019-08-21 21:26:22 +0000 UTC (1 container statuses recorded)
Aug 22 08:13:47.590: INFO: 	Container notary-signer ready: true, restart count 1
Aug 22 08:13:47.590: INFO: harbor-harbor-jobservice-55d6cbcfd8-lw9hj from default started at 2019-08-21 21:26:22 +0000 UTC (1 container statuses recorded)
Aug 22 08:13:47.590: INFO: 	Container jobservice ready: true, restart count 0
Aug 22 08:13:47.590: INFO: metrics-server-cf9d8cd8c-jtb99 from kube-system started at 2019-08-21 21:26:22 +0000 UTC (1 container statuses recorded)
Aug 22 08:13:47.590: INFO: 	Container metrics-server ready: true, restart count 0
Aug 22 08:13:47.590: INFO: harbor-harbor-database-0 from default started at 2019-08-21 21:26:36 +0000 UTC (1 container statuses recorded)
Aug 22 08:13:47.590: INFO: 	Container database ready: true, restart count 0
Aug 22 08:13:47.590: INFO: rabbit-rabbitmq-ha-2 from default started at 2019-08-21 21:26:54 +0000 UTC (1 container statuses recorded)
Aug 22 08:13:47.590: INFO: 	Container rabbitmq-ha ready: true, restart count 0
Aug 22 08:13:47.590: INFO: sonobuoy-systemd-logs-daemon-set-77a1f61d77c0402d-9cdch from heptio-sonobuoy started at 2019-08-22 07:41:47 +0000 UTC (2 container statuses recorded)
Aug 22 08:13:47.590: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 22 08:13:47.590: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 22 08:13:47.590: INFO: tiller-deploy-66b7dd976-9s6xn from kube-system started at 2019-08-21 21:26:22 +0000 UTC (1 container statuses recorded)
Aug 22 08:13:47.590: INFO: 	Container tiller ready: true, restart count 0
Aug 22 08:13:47.590: INFO: harbor-harbor-core-6576c89d75-d964k from default started at 2019-08-21 21:26:22 +0000 UTC (1 container statuses recorded)
Aug 22 08:13:47.590: INFO: 	Container core ready: true, restart count 1
Aug 22 08:13:47.590: INFO: coredns-54586579f6-ncd2w from kube-system started at 2019-08-21 21:26:22 +0000 UTC (1 container statuses recorded)
Aug 22 08:13:47.590: INFO: 	Container coredns ready: true, restart count 0
Aug 22 08:13:47.590: INFO: ss2-0 from statefulset-3821 started at 2019-08-21 21:26:32 +0000 UTC (1 container statuses recorded)
Aug 22 08:13:47.590: INFO: 	Container nginx ready: true, restart count 0
Aug 22 08:13:47.590: INFO: harbor-harbor-chartmuseum-6c9cfcb75-ccf7f from default started at 2019-08-21 21:26:22 +0000 UTC (1 container statuses recorded)
Aug 22 08:13:47.590: INFO: 	Container chartmuseum ready: true, restart count 0
Aug 22 08:13:47.590: INFO: traefik-ingress-controller-sqvfm from traefik-ingress started at 2019-08-22 07:35:59 +0000 UTC (1 container statuses recorded)
Aug 22 08:13:47.590: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Aug 22 08:13:47.590: INFO: 
Logging pods the kubelet thinks is on node ip-10-90-32-23.eu-west-2.compute.internal before test
Aug 22 08:13:47.598: INFO: hello-python-866d7f447b-8v4p4 from default started at 2019-08-21 21:27:38 +0000 UTC (1 container statuses recorded)
Aug 22 08:13:47.598: INFO: 	Container hello-python ready: true, restart count 0
Aug 22 08:13:47.598: INFO: tiller-deploy-775fdcb4cb-8rqxz from test started at 2019-08-21 21:27:39 +0000 UTC (1 container statuses recorded)
Aug 22 08:13:47.598: INFO: 	Container tiller ready: true, restart count 0
Aug 22 08:13:47.598: INFO: harbor-harbor-registry-bffc4f6b-prl88 from default started at 2019-08-21 21:27:38 +0000 UTC (2 container statuses recorded)
Aug 22 08:13:47.598: INFO: 	Container registry ready: true, restart count 0
Aug 22 08:13:47.598: INFO: 	Container registryctl ready: true, restart count 0
Aug 22 08:13:47.598: INFO: harbor-harbor-notary-server-7fd5cb4874-zm57q from default started at 2019-08-21 21:27:38 +0000 UTC (1 container statuses recorded)
Aug 22 08:13:47.598: INFO: 	Container notary-server ready: true, restart count 0
Aug 22 08:13:47.598: INFO: python-5c8bdf49c5-4gn9f from default started at 2019-08-21 21:27:39 +0000 UTC (1 container statuses recorded)
Aug 22 08:13:47.598: INFO: 	Container python ready: true, restart count 0
Aug 22 08:13:47.598: INFO: ss2-1 from statefulset-3821 started at 2019-08-21 21:27:48 +0000 UTC (1 container statuses recorded)
Aug 22 08:13:47.598: INFO: 	Container nginx ready: true, restart count 0
Aug 22 08:13:47.598: INFO: traefik-ingress-controller-w9znh from traefik-ingress started at 2019-08-22 07:35:39 +0000 UTC (1 container statuses recorded)
Aug 22 08:13:47.598: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Aug 22 08:13:47.598: INFO: filebeat-gdpxp from kube-system started at 2019-08-21 21:27:29 +0000 UTC (1 container statuses recorded)
Aug 22 08:13:47.598: INFO: 	Container filebeat ready: true, restart count 0
Aug 22 08:13:47.598: INFO: sonobuoy-systemd-logs-daemon-set-77a1f61d77c0402d-k88tw from heptio-sonobuoy started at 2019-08-22 07:41:47 +0000 UTC (2 container statuses recorded)
Aug 22 08:13:47.598: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 22 08:13:47.598: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 22 08:13:47.598: INFO: petclinic-7c86cccbdc-krcsq from default started at 2019-08-21 21:27:38 +0000 UTC (1 container statuses recorded)
Aug 22 08:13:47.598: INFO: 	Container petclinic ready: true, restart count 0
Aug 22 08:13:47.598: INFO: harbor-harbor-clair-54c47dfdfc-rxdrv from default started at 2019-08-21 21:27:38 +0000 UTC (1 container statuses recorded)
Aug 22 08:13:47.598: INFO: 	Container clair ready: true, restart count 0
Aug 22 08:13:47.598: INFO: coredns-54586579f6-29wj8 from kube-system started at 2019-08-21 21:27:39 +0000 UTC (1 container statuses recorded)
Aug 22 08:13:47.598: INFO: 	Container coredns ready: true, restart count 0
Aug 22 08:13:47.598: INFO: harbor-harbor-portal-6cbfc59497-k7qzj from default started at 2019-08-21 21:27:39 +0000 UTC (1 container statuses recorded)
Aug 22 08:13:47.598: INFO: 	Container portal ready: true, restart count 0
Aug 22 08:13:47.598: INFO: coredns-54586579f6-frkn5 from kube-system started at 2019-08-21 21:27:39 +0000 UTC (1 container statuses recorded)
Aug 22 08:13:47.598: INFO: 	Container coredns ready: true, restart count 0
Aug 22 08:13:47.598: INFO: rabbit-rabbitmq-ha-1 from default started at 2019-08-21 21:27:50 +0000 UTC (1 container statuses recorded)
Aug 22 08:13:47.598: INFO: 	Container rabbitmq-ha ready: true, restart count 0
Aug 22 08:13:47.598: INFO: 
Logging pods the kubelet thinks is on node ip-10-90-32-24.eu-west-2.compute.internal before test
Aug 22 08:13:47.602: INFO: sonobuoy-e2e-job-3bb06073b99141d8 from heptio-sonobuoy started at 2019-08-22 07:41:47 +0000 UTC (2 container statuses recorded)
Aug 22 08:13:47.602: INFO: 	Container e2e ready: true, restart count 0
Aug 22 08:13:47.602: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 22 08:13:47.602: INFO: sonobuoy-systemd-logs-daemon-set-77a1f61d77c0402d-qnkzk from heptio-sonobuoy started at 2019-08-22 07:41:47 +0000 UTC (2 container statuses recorded)
Aug 22 08:13:47.602: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 22 08:13:47.602: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 22 08:13:47.602: INFO: sonobuoy from heptio-sonobuoy started at 2019-08-22 07:41:45 +0000 UTC (1 container statuses recorded)
Aug 22 08:13:47.602: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 22 08:13:47.602: INFO: traefik-ingress-controller-4vj7g from traefik-ingress started at 2019-08-22 07:35:44 +0000 UTC (1 container statuses recorded)
Aug 22 08:13:47.602: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Aug 22 08:13:47.602: INFO: filebeat-xvmwc from kube-system started at 2019-08-21 21:28:49 +0000 UTC (1 container statuses recorded)
Aug 22 08:13:47.602: INFO: 	Container filebeat ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-c5642213-c4b4-11e9-80b5-1edf08853c25 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-c5642213-c4b4-11e9-80b5-1edf08853c25 off the node ip-10-90-32-24.eu-west-2.compute.internal
STEP: verifying the node doesn't have the label kubernetes.io/e2e-c5642213-c4b4-11e9-80b5-1edf08853c25
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:13:51.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9567" for this suite.
Aug 22 08:14:19.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:14:19.812: INFO: namespace sched-pred-9567 deletion completed in 28.128983484s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:32.375 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:14:19.812: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-2905
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating replication controller svc-latency-rc in namespace svc-latency-2905
I0822 08:14:19.964577      14 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-2905, replica count: 1
I0822 08:14:21.015093      14 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0822 08:14:22.015416      14 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 22 08:14:22.127: INFO: Created: latency-svc-m5gwz
Aug 22 08:14:22.133: INFO: Got endpoints: latency-svc-m5gwz [17.887599ms]
Aug 22 08:14:22.156: INFO: Created: latency-svc-l85ch
Aug 22 08:14:22.161: INFO: Created: latency-svc-7gzr4
Aug 22 08:14:22.164: INFO: Got endpoints: latency-svc-l85ch [30.663738ms]
Aug 22 08:14:22.171: INFO: Created: latency-svc-724xj
Aug 22 08:14:22.175: INFO: Got endpoints: latency-svc-7gzr4 [41.334176ms]
Aug 22 08:14:22.186: INFO: Got endpoints: latency-svc-724xj [52.100254ms]
Aug 22 08:14:22.187: INFO: Created: latency-svc-2k5rn
Aug 22 08:14:22.195: INFO: Created: latency-svc-tmhwd
Aug 22 08:14:22.198: INFO: Got endpoints: latency-svc-2k5rn [63.592809ms]
Aug 22 08:14:22.203: INFO: Got endpoints: latency-svc-tmhwd [67.807195ms]
Aug 22 08:14:22.208: INFO: Created: latency-svc-hq2bq
Aug 22 08:14:22.217: INFO: Created: latency-svc-6rjnj
Aug 22 08:14:22.219: INFO: Got endpoints: latency-svc-hq2bq [84.801975ms]
Aug 22 08:14:22.225: INFO: Got endpoints: latency-svc-6rjnj [90.855192ms]
Aug 22 08:14:22.229: INFO: Created: latency-svc-8vhqc
Aug 22 08:14:22.239: INFO: Created: latency-svc-sw7q9
Aug 22 08:14:22.241: INFO: Got endpoints: latency-svc-8vhqc [106.624137ms]
Aug 22 08:14:22.247: INFO: Created: latency-svc-8wznd
Aug 22 08:14:22.252: INFO: Got endpoints: latency-svc-sw7q9 [117.752083ms]
Aug 22 08:14:22.256: INFO: Got endpoints: latency-svc-8wznd [31.133439ms]
Aug 22 08:14:22.264: INFO: Created: latency-svc-9w5xr
Aug 22 08:14:22.272: INFO: Created: latency-svc-zt7g5
Aug 22 08:14:22.278: INFO: Got endpoints: latency-svc-9w5xr [144.061884ms]
Aug 22 08:14:22.281: INFO: Created: latency-svc-q9wz8
Aug 22 08:14:22.284: INFO: Got endpoints: latency-svc-zt7g5 [149.431498ms]
Aug 22 08:14:22.290: INFO: Got endpoints: latency-svc-q9wz8 [155.038187ms]
Aug 22 08:14:22.295: INFO: Created: latency-svc-jd524
Aug 22 08:14:22.301: INFO: Got endpoints: latency-svc-jd524 [166.132462ms]
Aug 22 08:14:22.304: INFO: Created: latency-svc-xvd8b
Aug 22 08:14:22.313: INFO: Got endpoints: latency-svc-xvd8b [178.010257ms]
Aug 22 08:14:22.316: INFO: Created: latency-svc-8rbm2
Aug 22 08:14:22.323: INFO: Got endpoints: latency-svc-8rbm2 [188.303845ms]
Aug 22 08:14:22.324: INFO: Created: latency-svc-wmhvl
Aug 22 08:14:22.330: INFO: Got endpoints: latency-svc-wmhvl [165.787085ms]
Aug 22 08:14:22.335: INFO: Created: latency-svc-n4nkl
Aug 22 08:14:22.343: INFO: Got endpoints: latency-svc-n4nkl [167.940966ms]
Aug 22 08:14:22.347: INFO: Created: latency-svc-2cp6w
Aug 22 08:14:22.353: INFO: Created: latency-svc-dqnc9
Aug 22 08:14:22.355: INFO: Got endpoints: latency-svc-2cp6w [169.654258ms]
Aug 22 08:14:22.361: INFO: Got endpoints: latency-svc-dqnc9 [163.926925ms]
Aug 22 08:14:22.368: INFO: Created: latency-svc-xfjhj
Aug 22 08:14:22.374: INFO: Created: latency-svc-k57s7
Aug 22 08:14:22.376: INFO: Got endpoints: latency-svc-xfjhj [173.10304ms]
Aug 22 08:14:22.380: INFO: Got endpoints: latency-svc-k57s7 [161.376439ms]
Aug 22 08:14:22.388: INFO: Created: latency-svc-s256v
Aug 22 08:14:22.397: INFO: Created: latency-svc-jlmkd
Aug 22 08:14:22.400: INFO: Got endpoints: latency-svc-s256v [158.740168ms]
Aug 22 08:14:22.408: INFO: Created: latency-svc-kk72s
Aug 22 08:14:22.410: INFO: Got endpoints: latency-svc-jlmkd [158.249512ms]
Aug 22 08:14:22.417: INFO: Created: latency-svc-vr5td
Aug 22 08:14:22.419: INFO: Got endpoints: latency-svc-kk72s [162.902776ms]
Aug 22 08:14:22.428: INFO: Got endpoints: latency-svc-vr5td [149.455556ms]
Aug 22 08:14:22.430: INFO: Created: latency-svc-bxx8n
Aug 22 08:14:22.435: INFO: Got endpoints: latency-svc-bxx8n [151.296422ms]
Aug 22 08:14:22.443: INFO: Created: latency-svc-5fg67
Aug 22 08:14:22.450: INFO: Created: latency-svc-lhvhz
Aug 22 08:14:22.454: INFO: Got endpoints: latency-svc-5fg67 [164.427356ms]
Aug 22 08:14:22.463: INFO: Got endpoints: latency-svc-lhvhz [162.742653ms]
Aug 22 08:14:22.465: INFO: Created: latency-svc-lz2lg
Aug 22 08:14:22.471: INFO: Created: latency-svc-njxxw
Aug 22 08:14:22.473: INFO: Got endpoints: latency-svc-lz2lg [159.940382ms]
Aug 22 08:14:22.479: INFO: Got endpoints: latency-svc-njxxw [155.918621ms]
Aug 22 08:14:22.484: INFO: Created: latency-svc-xv754
Aug 22 08:14:22.492: INFO: Created: latency-svc-2bgmg
Aug 22 08:14:22.497: INFO: Got endpoints: latency-svc-xv754 [167.169904ms]
Aug 22 08:14:22.499: INFO: Got endpoints: latency-svc-2bgmg [156.002028ms]
Aug 22 08:14:22.514: INFO: Created: latency-svc-8wp4q
Aug 22 08:14:22.521: INFO: Created: latency-svc-ww6nx
Aug 22 08:14:22.521: INFO: Got endpoints: latency-svc-8wp4q [165.796639ms]
Aug 22 08:14:22.531: INFO: Got endpoints: latency-svc-ww6nx [169.141893ms]
Aug 22 08:14:22.535: INFO: Created: latency-svc-rz4mb
Aug 22 08:14:22.541: INFO: Created: latency-svc-947z8
Aug 22 08:14:22.545: INFO: Got endpoints: latency-svc-rz4mb [169.714745ms]
Aug 22 08:14:22.550: INFO: Got endpoints: latency-svc-947z8 [169.477639ms]
Aug 22 08:14:22.558: INFO: Created: latency-svc-fjnmj
Aug 22 08:14:22.570: INFO: Created: latency-svc-p9rdd
Aug 22 08:14:22.590: INFO: Created: latency-svc-5rjrq
Aug 22 08:14:22.596: INFO: Got endpoints: latency-svc-fjnmj [196.162517ms]
Aug 22 08:14:22.606: INFO: Created: latency-svc-7fxps
Aug 22 08:14:22.618: INFO: Created: latency-svc-9vgsn
Aug 22 08:14:22.632: INFO: Got endpoints: latency-svc-p9rdd [221.931733ms]
Aug 22 08:14:22.644: INFO: Created: latency-svc-7p2pr
Aug 22 08:14:22.654: INFO: Created: latency-svc-8cfzz
Aug 22 08:14:22.665: INFO: Created: latency-svc-9227z
Aug 22 08:14:22.679: INFO: Created: latency-svc-w5v7m
Aug 22 08:14:22.683: INFO: Got endpoints: latency-svc-5rjrq [264.379775ms]
Aug 22 08:14:22.691: INFO: Created: latency-svc-rbpnl
Aug 22 08:14:22.696: INFO: Created: latency-svc-rrf8d
Aug 22 08:14:22.703: INFO: Created: latency-svc-wbzwh
Aug 22 08:14:22.709: INFO: Created: latency-svc-4vgjk
Aug 22 08:14:22.716: INFO: Created: latency-svc-l7gtg
Aug 22 08:14:22.721: INFO: Created: latency-svc-spr9m
Aug 22 08:14:22.727: INFO: Created: latency-svc-qz26n
Aug 22 08:14:22.734: INFO: Got endpoints: latency-svc-7fxps [306.069217ms]
Aug 22 08:14:22.740: INFO: Created: latency-svc-wf4tw
Aug 22 08:14:22.745: INFO: Created: latency-svc-8p8r5
Aug 22 08:14:22.751: INFO: Created: latency-svc-jdmkw
Aug 22 08:14:22.780: INFO: Got endpoints: latency-svc-9vgsn [344.48379ms]
Aug 22 08:14:22.789: INFO: Created: latency-svc-d9wgn
Aug 22 08:14:22.830: INFO: Got endpoints: latency-svc-7p2pr [375.790349ms]
Aug 22 08:14:22.839: INFO: Created: latency-svc-52mbd
Aug 22 08:14:22.882: INFO: Got endpoints: latency-svc-8cfzz [418.919285ms]
Aug 22 08:14:22.893: INFO: Created: latency-svc-kp4qf
Aug 22 08:14:22.931: INFO: Got endpoints: latency-svc-9227z [458.828849ms]
Aug 22 08:14:22.940: INFO: Created: latency-svc-h5znw
Aug 22 08:14:22.983: INFO: Got endpoints: latency-svc-w5v7m [503.540103ms]
Aug 22 08:14:22.992: INFO: Created: latency-svc-tj467
Aug 22 08:14:23.032: INFO: Got endpoints: latency-svc-rbpnl [535.206631ms]
Aug 22 08:14:23.042: INFO: Created: latency-svc-zmgj7
Aug 22 08:14:23.081: INFO: Got endpoints: latency-svc-rrf8d [581.748192ms]
Aug 22 08:14:23.090: INFO: Created: latency-svc-xzsww
Aug 22 08:14:23.131: INFO: Got endpoints: latency-svc-wbzwh [609.639493ms]
Aug 22 08:14:23.140: INFO: Created: latency-svc-g5m7m
Aug 22 08:14:23.180: INFO: Got endpoints: latency-svc-4vgjk [648.945858ms]
Aug 22 08:14:23.189: INFO: Created: latency-svc-drnx7
Aug 22 08:14:23.229: INFO: Got endpoints: latency-svc-l7gtg [683.951124ms]
Aug 22 08:14:23.238: INFO: Created: latency-svc-g7fn4
Aug 22 08:14:23.281: INFO: Got endpoints: latency-svc-spr9m [731.471655ms]
Aug 22 08:14:23.289: INFO: Created: latency-svc-2vg8t
Aug 22 08:14:23.332: INFO: Got endpoints: latency-svc-qz26n [736.000736ms]
Aug 22 08:14:23.339: INFO: Created: latency-svc-flx5v
Aug 22 08:14:23.379: INFO: Got endpoints: latency-svc-wf4tw [747.137391ms]
Aug 22 08:14:23.388: INFO: Created: latency-svc-x6txs
Aug 22 08:14:23.430: INFO: Got endpoints: latency-svc-8p8r5 [746.386102ms]
Aug 22 08:14:23.437: INFO: Created: latency-svc-t7wwh
Aug 22 08:14:23.480: INFO: Got endpoints: latency-svc-jdmkw [745.886538ms]
Aug 22 08:14:23.487: INFO: Created: latency-svc-g7k7h
Aug 22 08:14:23.530: INFO: Got endpoints: latency-svc-d9wgn [750.021667ms]
Aug 22 08:14:23.537: INFO: Created: latency-svc-tv92b
Aug 22 08:14:23.579: INFO: Got endpoints: latency-svc-52mbd [749.296855ms]
Aug 22 08:14:23.587: INFO: Created: latency-svc-4gz49
Aug 22 08:14:23.631: INFO: Got endpoints: latency-svc-kp4qf [748.279874ms]
Aug 22 08:14:23.638: INFO: Created: latency-svc-ssqt9
Aug 22 08:14:23.679: INFO: Got endpoints: latency-svc-h5znw [747.740727ms]
Aug 22 08:14:23.687: INFO: Created: latency-svc-j69f7
Aug 22 08:14:23.730: INFO: Got endpoints: latency-svc-tj467 [747.065778ms]
Aug 22 08:14:23.737: INFO: Created: latency-svc-m7p68
Aug 22 08:14:23.782: INFO: Got endpoints: latency-svc-zmgj7 [749.248564ms]
Aug 22 08:14:23.789: INFO: Created: latency-svc-6c5qw
Aug 22 08:14:23.830: INFO: Got endpoints: latency-svc-xzsww [749.413763ms]
Aug 22 08:14:23.838: INFO: Created: latency-svc-x6fdc
Aug 22 08:14:23.879: INFO: Got endpoints: latency-svc-g5m7m [747.751003ms]
Aug 22 08:14:23.888: INFO: Created: latency-svc-7q7vm
Aug 22 08:14:23.930: INFO: Got endpoints: latency-svc-drnx7 [750.532884ms]
Aug 22 08:14:23.939: INFO: Created: latency-svc-7jrwm
Aug 22 08:14:23.980: INFO: Got endpoints: latency-svc-g7fn4 [750.687046ms]
Aug 22 08:14:23.988: INFO: Created: latency-svc-b62rn
Aug 22 08:14:24.030: INFO: Got endpoints: latency-svc-2vg8t [748.456619ms]
Aug 22 08:14:24.038: INFO: Created: latency-svc-2dt5d
Aug 22 08:14:24.080: INFO: Got endpoints: latency-svc-flx5v [748.374787ms]
Aug 22 08:14:24.088: INFO: Created: latency-svc-fqgqz
Aug 22 08:14:24.130: INFO: Got endpoints: latency-svc-x6txs [750.911804ms]
Aug 22 08:14:24.138: INFO: Created: latency-svc-2w65r
Aug 22 08:14:24.179: INFO: Got endpoints: latency-svc-t7wwh [749.448201ms]
Aug 22 08:14:24.187: INFO: Created: latency-svc-bd8wk
Aug 22 08:14:24.230: INFO: Got endpoints: latency-svc-g7k7h [750.50742ms]
Aug 22 08:14:24.240: INFO: Created: latency-svc-gzrfd
Aug 22 08:14:24.279: INFO: Got endpoints: latency-svc-tv92b [749.508277ms]
Aug 22 08:14:24.288: INFO: Created: latency-svc-hwxz5
Aug 22 08:14:24.330: INFO: Got endpoints: latency-svc-4gz49 [750.847101ms]
Aug 22 08:14:24.337: INFO: Created: latency-svc-nm6rg
Aug 22 08:14:24.380: INFO: Got endpoints: latency-svc-ssqt9 [749.121042ms]
Aug 22 08:14:24.388: INFO: Created: latency-svc-mj5tk
Aug 22 08:14:24.429: INFO: Got endpoints: latency-svc-j69f7 [750.082544ms]
Aug 22 08:14:24.436: INFO: Created: latency-svc-87sr6
Aug 22 08:14:24.479: INFO: Got endpoints: latency-svc-m7p68 [749.220849ms]
Aug 22 08:14:24.486: INFO: Created: latency-svc-bmt7v
Aug 22 08:14:24.529: INFO: Got endpoints: latency-svc-6c5qw [746.921248ms]
Aug 22 08:14:24.536: INFO: Created: latency-svc-dhfvs
Aug 22 08:14:24.579: INFO: Got endpoints: latency-svc-x6fdc [748.621718ms]
Aug 22 08:14:24.586: INFO: Created: latency-svc-cj45w
Aug 22 08:14:24.630: INFO: Got endpoints: latency-svc-7q7vm [751.208634ms]
Aug 22 08:14:24.637: INFO: Created: latency-svc-g7hvt
Aug 22 08:14:24.680: INFO: Got endpoints: latency-svc-7jrwm [749.731341ms]
Aug 22 08:14:24.687: INFO: Created: latency-svc-q4gxr
Aug 22 08:14:24.729: INFO: Got endpoints: latency-svc-b62rn [748.729295ms]
Aug 22 08:14:24.738: INFO: Created: latency-svc-dzv4q
Aug 22 08:14:24.779: INFO: Got endpoints: latency-svc-2dt5d [749.571255ms]
Aug 22 08:14:24.788: INFO: Created: latency-svc-gv49p
Aug 22 08:14:24.830: INFO: Got endpoints: latency-svc-fqgqz [749.175589ms]
Aug 22 08:14:24.837: INFO: Created: latency-svc-kpsqx
Aug 22 08:14:24.879: INFO: Got endpoints: latency-svc-2w65r [749.010973ms]
Aug 22 08:14:24.886: INFO: Created: latency-svc-lbs6p
Aug 22 08:14:24.930: INFO: Got endpoints: latency-svc-bd8wk [750.766806ms]
Aug 22 08:14:24.936: INFO: Created: latency-svc-lc5vh
Aug 22 08:14:24.980: INFO: Got endpoints: latency-svc-gzrfd [749.464438ms]
Aug 22 08:14:24.987: INFO: Created: latency-svc-n9x56
Aug 22 08:14:25.030: INFO: Got endpoints: latency-svc-hwxz5 [751.07286ms]
Aug 22 08:14:25.037: INFO: Created: latency-svc-h4lz6
Aug 22 08:14:25.080: INFO: Got endpoints: latency-svc-nm6rg [749.388009ms]
Aug 22 08:14:25.087: INFO: Created: latency-svc-b6mb7
Aug 22 08:14:25.129: INFO: Got endpoints: latency-svc-mj5tk [749.36093ms]
Aug 22 08:14:25.139: INFO: Created: latency-svc-9ljqt
Aug 22 08:14:25.179: INFO: Got endpoints: latency-svc-87sr6 [749.332164ms]
Aug 22 08:14:25.189: INFO: Created: latency-svc-clt7g
Aug 22 08:14:25.230: INFO: Got endpoints: latency-svc-bmt7v [751.406449ms]
Aug 22 08:14:25.238: INFO: Created: latency-svc-qt6hk
Aug 22 08:14:25.280: INFO: Got endpoints: latency-svc-dhfvs [751.825086ms]
Aug 22 08:14:25.296: INFO: Created: latency-svc-rqrth
Aug 22 08:14:25.337: INFO: Got endpoints: latency-svc-cj45w [758.373127ms]
Aug 22 08:14:25.345: INFO: Created: latency-svc-lr9jv
Aug 22 08:14:25.381: INFO: Got endpoints: latency-svc-g7hvt [751.229895ms]
Aug 22 08:14:25.392: INFO: Created: latency-svc-ff6pv
Aug 22 08:14:25.432: INFO: Got endpoints: latency-svc-q4gxr [751.367774ms]
Aug 22 08:14:25.442: INFO: Created: latency-svc-gw5v7
Aug 22 08:14:25.482: INFO: Got endpoints: latency-svc-dzv4q [752.528127ms]
Aug 22 08:14:25.490: INFO: Created: latency-svc-knpzc
Aug 22 08:14:25.532: INFO: Got endpoints: latency-svc-gv49p [752.277561ms]
Aug 22 08:14:25.541: INFO: Created: latency-svc-ccxcr
Aug 22 08:14:25.581: INFO: Got endpoints: latency-svc-kpsqx [751.847391ms]
Aug 22 08:14:25.590: INFO: Created: latency-svc-jvkhx
Aug 22 08:14:25.631: INFO: Got endpoints: latency-svc-lbs6p [751.49392ms]
Aug 22 08:14:25.645: INFO: Created: latency-svc-9vf96
Aug 22 08:14:25.681: INFO: Got endpoints: latency-svc-lc5vh [750.739751ms]
Aug 22 08:14:25.690: INFO: Created: latency-svc-nlflr
Aug 22 08:14:25.731: INFO: Got endpoints: latency-svc-n9x56 [751.178878ms]
Aug 22 08:14:25.740: INFO: Created: latency-svc-jggrd
Aug 22 08:14:25.781: INFO: Got endpoints: latency-svc-h4lz6 [750.887158ms]
Aug 22 08:14:25.791: INFO: Created: latency-svc-cpdfm
Aug 22 08:14:25.831: INFO: Got endpoints: latency-svc-b6mb7 [751.0116ms]
Aug 22 08:14:25.839: INFO: Created: latency-svc-v2jzn
Aug 22 08:14:25.879: INFO: Got endpoints: latency-svc-9ljqt [749.755692ms]
Aug 22 08:14:25.889: INFO: Created: latency-svc-4f4b9
Aug 22 08:14:25.931: INFO: Got endpoints: latency-svc-clt7g [751.814745ms]
Aug 22 08:14:25.940: INFO: Created: latency-svc-zhq6z
Aug 22 08:14:25.981: INFO: Got endpoints: latency-svc-qt6hk [750.839897ms]
Aug 22 08:14:25.992: INFO: Created: latency-svc-4rbxt
Aug 22 08:14:26.029: INFO: Got endpoints: latency-svc-rqrth [748.773132ms]
Aug 22 08:14:26.037: INFO: Created: latency-svc-zsjd8
Aug 22 08:14:26.079: INFO: Got endpoints: latency-svc-lr9jv [741.942699ms]
Aug 22 08:14:26.087: INFO: Created: latency-svc-md7q9
Aug 22 08:14:26.129: INFO: Got endpoints: latency-svc-ff6pv [747.768242ms]
Aug 22 08:14:26.137: INFO: Created: latency-svc-zrzss
Aug 22 08:14:26.179: INFO: Got endpoints: latency-svc-gw5v7 [747.445605ms]
Aug 22 08:14:26.187: INFO: Created: latency-svc-tfxnb
Aug 22 08:14:26.229: INFO: Got endpoints: latency-svc-knpzc [747.373941ms]
Aug 22 08:14:26.236: INFO: Created: latency-svc-wjtd4
Aug 22 08:14:26.279: INFO: Got endpoints: latency-svc-ccxcr [747.387913ms]
Aug 22 08:14:26.287: INFO: Created: latency-svc-lr8l6
Aug 22 08:14:26.329: INFO: Got endpoints: latency-svc-jvkhx [747.558045ms]
Aug 22 08:14:26.336: INFO: Created: latency-svc-h7mrz
Aug 22 08:14:26.379: INFO: Got endpoints: latency-svc-9vf96 [747.662704ms]
Aug 22 08:14:26.387: INFO: Created: latency-svc-btvbl
Aug 22 08:14:26.430: INFO: Got endpoints: latency-svc-nlflr [748.569897ms]
Aug 22 08:14:26.437: INFO: Created: latency-svc-rvzq2
Aug 22 08:14:26.483: INFO: Got endpoints: latency-svc-jggrd [751.33281ms]
Aug 22 08:14:26.490: INFO: Created: latency-svc-smn95
Aug 22 08:14:26.531: INFO: Got endpoints: latency-svc-cpdfm [749.35841ms]
Aug 22 08:14:26.538: INFO: Created: latency-svc-hxzxx
Aug 22 08:14:26.579: INFO: Got endpoints: latency-svc-v2jzn [748.33068ms]
Aug 22 08:14:26.587: INFO: Created: latency-svc-ntg2p
Aug 22 08:14:26.629: INFO: Got endpoints: latency-svc-4f4b9 [749.342415ms]
Aug 22 08:14:26.636: INFO: Created: latency-svc-bvgmm
Aug 22 08:14:26.679: INFO: Got endpoints: latency-svc-zhq6z [748.463817ms]
Aug 22 08:14:26.687: INFO: Created: latency-svc-4m7pp
Aug 22 08:14:26.730: INFO: Got endpoints: latency-svc-4rbxt [748.268048ms]
Aug 22 08:14:26.736: INFO: Created: latency-svc-wsws9
Aug 22 08:14:26.780: INFO: Got endpoints: latency-svc-zsjd8 [750.287333ms]
Aug 22 08:14:26.787: INFO: Created: latency-svc-nmjff
Aug 22 08:14:26.830: INFO: Got endpoints: latency-svc-md7q9 [750.124973ms]
Aug 22 08:14:26.837: INFO: Created: latency-svc-6qkxl
Aug 22 08:14:26.880: INFO: Got endpoints: latency-svc-zrzss [750.666648ms]
Aug 22 08:14:26.887: INFO: Created: latency-svc-cnjkz
Aug 22 08:14:26.930: INFO: Got endpoints: latency-svc-tfxnb [750.573257ms]
Aug 22 08:14:26.939: INFO: Created: latency-svc-c4xsk
Aug 22 08:14:26.980: INFO: Got endpoints: latency-svc-wjtd4 [751.293011ms]
Aug 22 08:14:26.988: INFO: Created: latency-svc-q6c5z
Aug 22 08:14:27.030: INFO: Got endpoints: latency-svc-lr8l6 [750.914782ms]
Aug 22 08:14:27.037: INFO: Created: latency-svc-ct898
Aug 22 08:14:27.080: INFO: Got endpoints: latency-svc-h7mrz [751.141599ms]
Aug 22 08:14:27.086: INFO: Created: latency-svc-6g6vs
Aug 22 08:14:27.130: INFO: Got endpoints: latency-svc-btvbl [751.237757ms]
Aug 22 08:14:27.137: INFO: Created: latency-svc-tvdnv
Aug 22 08:14:27.180: INFO: Got endpoints: latency-svc-rvzq2 [749.901726ms]
Aug 22 08:14:27.187: INFO: Created: latency-svc-hv945
Aug 22 08:14:27.229: INFO: Got endpoints: latency-svc-smn95 [746.542782ms]
Aug 22 08:14:27.237: INFO: Created: latency-svc-sw8sh
Aug 22 08:14:27.279: INFO: Got endpoints: latency-svc-hxzxx [748.35441ms]
Aug 22 08:14:27.286: INFO: Created: latency-svc-st67n
Aug 22 08:14:27.329: INFO: Got endpoints: latency-svc-ntg2p [750.297815ms]
Aug 22 08:14:27.345: INFO: Created: latency-svc-mbsfb
Aug 22 08:14:27.386: INFO: Got endpoints: latency-svc-bvgmm [757.252366ms]
Aug 22 08:14:27.399: INFO: Created: latency-svc-ssjjr
Aug 22 08:14:27.430: INFO: Got endpoints: latency-svc-4m7pp [750.811703ms]
Aug 22 08:14:27.439: INFO: Created: latency-svc-dlxt9
Aug 22 08:14:27.481: INFO: Got endpoints: latency-svc-wsws9 [751.4923ms]
Aug 22 08:14:27.501: INFO: Created: latency-svc-fh44j
Aug 22 08:14:27.530: INFO: Got endpoints: latency-svc-nmjff [750.196736ms]
Aug 22 08:14:27.553: INFO: Created: latency-svc-pnbbz
Aug 22 08:14:27.580: INFO: Got endpoints: latency-svc-6qkxl [750.150289ms]
Aug 22 08:14:27.601: INFO: Created: latency-svc-wzhxg
Aug 22 08:14:27.630: INFO: Got endpoints: latency-svc-cnjkz [750.378823ms]
Aug 22 08:14:27.638: INFO: Created: latency-svc-69c59
Aug 22 08:14:27.680: INFO: Got endpoints: latency-svc-c4xsk [749.850177ms]
Aug 22 08:14:27.688: INFO: Created: latency-svc-mm7rs
Aug 22 08:14:27.730: INFO: Got endpoints: latency-svc-q6c5z [750.154801ms]
Aug 22 08:14:27.737: INFO: Created: latency-svc-7557w
Aug 22 08:14:27.780: INFO: Got endpoints: latency-svc-ct898 [749.532416ms]
Aug 22 08:14:27.786: INFO: Created: latency-svc-zbwvb
Aug 22 08:14:27.831: INFO: Got endpoints: latency-svc-6g6vs [750.869012ms]
Aug 22 08:14:27.842: INFO: Created: latency-svc-l4tmd
Aug 22 08:14:27.880: INFO: Got endpoints: latency-svc-tvdnv [750.165149ms]
Aug 22 08:14:27.889: INFO: Created: latency-svc-59f4x
Aug 22 08:14:27.931: INFO: Got endpoints: latency-svc-hv945 [750.979437ms]
Aug 22 08:14:27.937: INFO: Created: latency-svc-n7x8d
Aug 22 08:14:27.984: INFO: Got endpoints: latency-svc-sw8sh [754.666207ms]
Aug 22 08:14:27.993: INFO: Created: latency-svc-s66gs
Aug 22 08:14:28.030: INFO: Got endpoints: latency-svc-st67n [750.572542ms]
Aug 22 08:14:28.038: INFO: Created: latency-svc-c42vq
Aug 22 08:14:28.080: INFO: Got endpoints: latency-svc-mbsfb [750.669028ms]
Aug 22 08:14:28.088: INFO: Created: latency-svc-x6sct
Aug 22 08:14:28.130: INFO: Got endpoints: latency-svc-ssjjr [744.354761ms]
Aug 22 08:14:28.137: INFO: Created: latency-svc-fv5wl
Aug 22 08:14:28.179: INFO: Got endpoints: latency-svc-dlxt9 [749.036867ms]
Aug 22 08:14:28.186: INFO: Created: latency-svc-fn86z
Aug 22 08:14:28.229: INFO: Got endpoints: latency-svc-fh44j [748.059492ms]
Aug 22 08:14:28.236: INFO: Created: latency-svc-d4hv5
Aug 22 08:14:28.280: INFO: Got endpoints: latency-svc-pnbbz [750.234728ms]
Aug 22 08:14:28.289: INFO: Created: latency-svc-j2mlj
Aug 22 08:14:28.331: INFO: Got endpoints: latency-svc-wzhxg [750.730591ms]
Aug 22 08:14:28.338: INFO: Created: latency-svc-qb4ss
Aug 22 08:14:28.382: INFO: Got endpoints: latency-svc-69c59 [751.886575ms]
Aug 22 08:14:28.391: INFO: Created: latency-svc-dlqr9
Aug 22 08:14:28.429: INFO: Got endpoints: latency-svc-mm7rs [749.829619ms]
Aug 22 08:14:28.436: INFO: Created: latency-svc-5qq78
Aug 22 08:14:28.480: INFO: Got endpoints: latency-svc-7557w [749.59629ms]
Aug 22 08:14:28.487: INFO: Created: latency-svc-lmk5h
Aug 22 08:14:28.531: INFO: Got endpoints: latency-svc-zbwvb [751.362637ms]
Aug 22 08:14:28.539: INFO: Created: latency-svc-sl84f
Aug 22 08:14:28.581: INFO: Got endpoints: latency-svc-l4tmd [750.232558ms]
Aug 22 08:14:28.589: INFO: Created: latency-svc-5bppv
Aug 22 08:14:28.629: INFO: Got endpoints: latency-svc-59f4x [748.894773ms]
Aug 22 08:14:28.638: INFO: Created: latency-svc-dgtmw
Aug 22 08:14:28.679: INFO: Got endpoints: latency-svc-n7x8d [748.367217ms]
Aug 22 08:14:28.688: INFO: Created: latency-svc-ggzn2
Aug 22 08:14:28.730: INFO: Got endpoints: latency-svc-s66gs [746.012361ms]
Aug 22 08:14:28.738: INFO: Created: latency-svc-6lh8p
Aug 22 08:14:28.781: INFO: Got endpoints: latency-svc-c42vq [751.25139ms]
Aug 22 08:14:28.788: INFO: Created: latency-svc-jc28p
Aug 22 08:14:28.831: INFO: Got endpoints: latency-svc-x6sct [750.663139ms]
Aug 22 08:14:28.839: INFO: Created: latency-svc-bkllc
Aug 22 08:14:28.881: INFO: Got endpoints: latency-svc-fv5wl [750.728846ms]
Aug 22 08:14:28.891: INFO: Created: latency-svc-7d2nr
Aug 22 08:14:28.934: INFO: Got endpoints: latency-svc-fn86z [754.697863ms]
Aug 22 08:14:28.945: INFO: Created: latency-svc-xxpqj
Aug 22 08:14:28.982: INFO: Got endpoints: latency-svc-d4hv5 [752.914524ms]
Aug 22 08:14:28.994: INFO: Created: latency-svc-wwtbd
Aug 22 08:14:29.032: INFO: Got endpoints: latency-svc-j2mlj [751.286092ms]
Aug 22 08:14:29.040: INFO: Created: latency-svc-z746x
Aug 22 08:14:29.079: INFO: Got endpoints: latency-svc-qb4ss [748.527775ms]
Aug 22 08:14:29.090: INFO: Created: latency-svc-fnm4b
Aug 22 08:14:29.130: INFO: Got endpoints: latency-svc-dlqr9 [748.200404ms]
Aug 22 08:14:29.138: INFO: Created: latency-svc-v6hgn
Aug 22 08:14:29.181: INFO: Got endpoints: latency-svc-5qq78 [751.131366ms]
Aug 22 08:14:29.188: INFO: Created: latency-svc-cfb5g
Aug 22 08:14:29.230: INFO: Got endpoints: latency-svc-lmk5h [750.288734ms]
Aug 22 08:14:29.243: INFO: Created: latency-svc-7bwft
Aug 22 08:14:29.279: INFO: Got endpoints: latency-svc-sl84f [748.244228ms]
Aug 22 08:14:29.287: INFO: Created: latency-svc-wm9t9
Aug 22 08:14:29.329: INFO: Got endpoints: latency-svc-5bppv [747.583604ms]
Aug 22 08:14:29.337: INFO: Created: latency-svc-vpw75
Aug 22 08:14:29.380: INFO: Got endpoints: latency-svc-dgtmw [750.180824ms]
Aug 22 08:14:29.392: INFO: Created: latency-svc-46k6x
Aug 22 08:14:29.429: INFO: Got endpoints: latency-svc-ggzn2 [749.583306ms]
Aug 22 08:14:29.438: INFO: Created: latency-svc-dkzn6
Aug 22 08:14:29.480: INFO: Got endpoints: latency-svc-6lh8p [749.805124ms]
Aug 22 08:14:29.489: INFO: Created: latency-svc-8w8ph
Aug 22 08:14:29.530: INFO: Got endpoints: latency-svc-jc28p [748.909468ms]
Aug 22 08:14:29.538: INFO: Created: latency-svc-bnwqf
Aug 22 08:14:29.580: INFO: Got endpoints: latency-svc-bkllc [749.616437ms]
Aug 22 08:14:29.594: INFO: Created: latency-svc-lzxjs
Aug 22 08:14:29.631: INFO: Got endpoints: latency-svc-7d2nr [749.418903ms]
Aug 22 08:14:29.638: INFO: Created: latency-svc-6h2gd
Aug 22 08:14:29.680: INFO: Got endpoints: latency-svc-xxpqj [746.055779ms]
Aug 22 08:14:29.687: INFO: Created: latency-svc-mph2h
Aug 22 08:14:29.729: INFO: Got endpoints: latency-svc-wwtbd [746.968428ms]
Aug 22 08:14:29.739: INFO: Created: latency-svc-4qr5s
Aug 22 08:14:29.780: INFO: Got endpoints: latency-svc-z746x [748.53778ms]
Aug 22 08:14:29.790: INFO: Created: latency-svc-4gwvn
Aug 22 08:14:29.830: INFO: Got endpoints: latency-svc-fnm4b [750.24023ms]
Aug 22 08:14:29.838: INFO: Created: latency-svc-sd8gv
Aug 22 08:14:29.879: INFO: Got endpoints: latency-svc-v6hgn [748.688408ms]
Aug 22 08:14:29.887: INFO: Created: latency-svc-44x4x
Aug 22 08:14:29.930: INFO: Got endpoints: latency-svc-cfb5g [749.045806ms]
Aug 22 08:14:29.939: INFO: Created: latency-svc-wfhqb
Aug 22 08:14:29.981: INFO: Got endpoints: latency-svc-7bwft [750.579154ms]
Aug 22 08:14:30.030: INFO: Got endpoints: latency-svc-wm9t9 [750.408913ms]
Aug 22 08:14:30.081: INFO: Got endpoints: latency-svc-vpw75 [751.864426ms]
Aug 22 08:14:30.130: INFO: Got endpoints: latency-svc-46k6x [750.006311ms]
Aug 22 08:14:30.187: INFO: Got endpoints: latency-svc-dkzn6 [757.707054ms]
Aug 22 08:14:30.230: INFO: Got endpoints: latency-svc-8w8ph [749.711129ms]
Aug 22 08:14:30.280: INFO: Got endpoints: latency-svc-bnwqf [750.074678ms]
Aug 22 08:14:30.330: INFO: Got endpoints: latency-svc-lzxjs [749.864396ms]
Aug 22 08:14:30.379: INFO: Got endpoints: latency-svc-6h2gd [748.342779ms]
Aug 22 08:14:30.430: INFO: Got endpoints: latency-svc-mph2h [750.316739ms]
Aug 22 08:14:30.480: INFO: Got endpoints: latency-svc-4qr5s [750.778059ms]
Aug 22 08:14:30.532: INFO: Got endpoints: latency-svc-4gwvn [752.135901ms]
Aug 22 08:14:30.579: INFO: Got endpoints: latency-svc-sd8gv [749.144774ms]
Aug 22 08:14:30.630: INFO: Got endpoints: latency-svc-44x4x [751.297344ms]
Aug 22 08:14:30.680: INFO: Got endpoints: latency-svc-wfhqb [750.570233ms]
Aug 22 08:14:30.680: INFO: Latencies: [30.663738ms 31.133439ms 41.334176ms 52.100254ms 63.592809ms 67.807195ms 84.801975ms 90.855192ms 106.624137ms 117.752083ms 144.061884ms 149.431498ms 149.455556ms 151.296422ms 155.038187ms 155.918621ms 156.002028ms 158.249512ms 158.740168ms 159.940382ms 161.376439ms 162.742653ms 162.902776ms 163.926925ms 164.427356ms 165.787085ms 165.796639ms 166.132462ms 167.169904ms 167.940966ms 169.141893ms 169.477639ms 169.654258ms 169.714745ms 173.10304ms 178.010257ms 188.303845ms 196.162517ms 221.931733ms 264.379775ms 306.069217ms 344.48379ms 375.790349ms 418.919285ms 458.828849ms 503.540103ms 535.206631ms 581.748192ms 609.639493ms 648.945858ms 683.951124ms 731.471655ms 736.000736ms 741.942699ms 744.354761ms 745.886538ms 746.012361ms 746.055779ms 746.386102ms 746.542782ms 746.921248ms 746.968428ms 747.065778ms 747.137391ms 747.373941ms 747.387913ms 747.445605ms 747.558045ms 747.583604ms 747.662704ms 747.740727ms 747.751003ms 747.768242ms 748.059492ms 748.200404ms 748.244228ms 748.268048ms 748.279874ms 748.33068ms 748.342779ms 748.35441ms 748.367217ms 748.374787ms 748.456619ms 748.463817ms 748.527775ms 748.53778ms 748.569897ms 748.621718ms 748.688408ms 748.729295ms 748.773132ms 748.894773ms 748.909468ms 749.010973ms 749.036867ms 749.045806ms 749.121042ms 749.144774ms 749.175589ms 749.220849ms 749.248564ms 749.296855ms 749.332164ms 749.342415ms 749.35841ms 749.36093ms 749.388009ms 749.413763ms 749.418903ms 749.448201ms 749.464438ms 749.508277ms 749.532416ms 749.571255ms 749.583306ms 749.59629ms 749.616437ms 749.711129ms 749.731341ms 749.755692ms 749.805124ms 749.829619ms 749.850177ms 749.864396ms 749.901726ms 750.006311ms 750.021667ms 750.074678ms 750.082544ms 750.124973ms 750.150289ms 750.154801ms 750.165149ms 750.180824ms 750.196736ms 750.232558ms 750.234728ms 750.24023ms 750.287333ms 750.288734ms 750.297815ms 750.316739ms 750.378823ms 750.408913ms 750.50742ms 750.532884ms 750.570233ms 750.572542ms 750.573257ms 750.579154ms 750.663139ms 750.666648ms 750.669028ms 750.687046ms 750.728846ms 750.730591ms 750.739751ms 750.766806ms 750.778059ms 750.811703ms 750.839897ms 750.847101ms 750.869012ms 750.887158ms 750.911804ms 750.914782ms 750.979437ms 751.0116ms 751.07286ms 751.131366ms 751.141599ms 751.178878ms 751.208634ms 751.229895ms 751.237757ms 751.25139ms 751.286092ms 751.293011ms 751.297344ms 751.33281ms 751.362637ms 751.367774ms 751.406449ms 751.4923ms 751.49392ms 751.814745ms 751.825086ms 751.847391ms 751.864426ms 751.886575ms 752.135901ms 752.277561ms 752.528127ms 752.914524ms 754.666207ms 754.697863ms 757.252366ms 757.707054ms 758.373127ms]
Aug 22 08:14:30.680: INFO: 50 %ile: 749.220849ms
Aug 22 08:14:30.681: INFO: 90 %ile: 751.33281ms
Aug 22 08:14:30.681: INFO: 99 %ile: 757.707054ms
Aug 22 08:14:30.681: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:14:30.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-2905" for this suite.
Aug 22 08:14:40.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:14:40.765: INFO: namespace svc-latency-2905 deletion completed in 10.08065284s

• [SLOW TEST:20.953 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:14:40.765: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2464
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-e3f37352-c4b4-11e9-80b5-1edf08853c25
STEP: Creating a pod to test consume secrets
Aug 22 08:14:40.915: INFO: Waiting up to 5m0s for pod "pod-secrets-e3f402a4-c4b4-11e9-80b5-1edf08853c25" in namespace "secrets-2464" to be "success or failure"
Aug 22 08:14:40.922: INFO: Pod "pod-secrets-e3f402a4-c4b4-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 6.986083ms
Aug 22 08:14:42.925: INFO: Pod "pod-secrets-e3f402a4-c4b4-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009736868s
STEP: Saw pod success
Aug 22 08:14:42.925: INFO: Pod "pod-secrets-e3f402a4-c4b4-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:14:42.927: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-secrets-e3f402a4-c4b4-11e9-80b5-1edf08853c25 container secret-volume-test: <nil>
STEP: delete the pod
Aug 22 08:14:42.944: INFO: Waiting for pod pod-secrets-e3f402a4-c4b4-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:14:42.946: INFO: Pod pod-secrets-e3f402a4-c4b4-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:14:42.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2464" for this suite.
Aug 22 08:14:48.961: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:14:49.079: INFO: namespace secrets-2464 deletion completed in 6.129970077s

• [SLOW TEST:8.314 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:14:49.080: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6371
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-e8e79fb5-c4b4-11e9-80b5-1edf08853c25
STEP: Creating a pod to test consume secrets
Aug 22 08:14:49.228: INFO: Waiting up to 5m0s for pod "pod-secrets-e8e8692c-c4b4-11e9-80b5-1edf08853c25" in namespace "secrets-6371" to be "success or failure"
Aug 22 08:14:49.234: INFO: Pod "pod-secrets-e8e8692c-c4b4-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 5.455869ms
Aug 22 08:14:51.237: INFO: Pod "pod-secrets-e8e8692c-c4b4-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009204564s
STEP: Saw pod success
Aug 22 08:14:51.237: INFO: Pod "pod-secrets-e8e8692c-c4b4-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:14:51.240: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-secrets-e8e8692c-c4b4-11e9-80b5-1edf08853c25 container secret-env-test: <nil>
STEP: delete the pod
Aug 22 08:14:51.256: INFO: Waiting for pod pod-secrets-e8e8692c-c4b4-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:14:51.258: INFO: Pod pod-secrets-e8e8692c-c4b4-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:14:51.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6371" for this suite.
Aug 22 08:14:57.277: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:14:57.353: INFO: namespace secrets-6371 deletion completed in 6.092166756s

• [SLOW TEST:8.274 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:14:57.354: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-4228
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-twcg7 in namespace proxy-4228
I0822 08:14:57.526233      14 runners.go:184] Created replication controller with name: proxy-service-twcg7, namespace: proxy-4228, replica count: 1
I0822 08:14:58.576776      14 runners.go:184] proxy-service-twcg7 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0822 08:14:59.577028      14 runners.go:184] proxy-service-twcg7 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0822 08:15:00.577288      14 runners.go:184] proxy-service-twcg7 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0822 08:15:01.577514      14 runners.go:184] proxy-service-twcg7 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0822 08:15:02.577756      14 runners.go:184] proxy-service-twcg7 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0822 08:15:03.578003      14 runners.go:184] proxy-service-twcg7 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0822 08:15:04.578258      14 runners.go:184] proxy-service-twcg7 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0822 08:15:05.578501      14 runners.go:184] proxy-service-twcg7 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0822 08:15:06.578752      14 runners.go:184] proxy-service-twcg7 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 22 08:15:06.581: INFO: setup took 9.074892063s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Aug 22 08:15:06.607: INFO: (0) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:162/proxy/: bar (200; 25.63322ms)
Aug 22 08:15:06.607: INFO: (0) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52/proxy/rewriteme">test</a> (200; 25.608696ms)
Aug 22 08:15:06.607: INFO: (0) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:1080/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:1080/proxy/rewriteme">... (200; 25.410328ms)
Aug 22 08:15:06.607: INFO: (0) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:1080/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:1080/proxy/rewriteme">test<... (200; 25.769363ms)
Aug 22 08:15:06.607: INFO: (0) /api/v1/namespaces/proxy-4228/services/http:proxy-service-twcg7:portname2/proxy/: bar (200; 25.649393ms)
Aug 22 08:15:06.610: INFO: (0) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:160/proxy/: foo (200; 28.893215ms)
Aug 22 08:15:06.610: INFO: (0) /api/v1/namespaces/proxy-4228/services/proxy-service-twcg7:portname1/proxy/: foo (200; 29.053048ms)
Aug 22 08:15:06.611: INFO: (0) /api/v1/namespaces/proxy-4228/services/proxy-service-twcg7:portname2/proxy/: bar (200; 29.10683ms)
Aug 22 08:15:06.611: INFO: (0) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:160/proxy/: foo (200; 29.44837ms)
Aug 22 08:15:06.611: INFO: (0) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:162/proxy/: bar (200; 29.607741ms)
Aug 22 08:15:06.612: INFO: (0) /api/v1/namespaces/proxy-4228/services/http:proxy-service-twcg7:portname1/proxy/: foo (200; 30.796982ms)
Aug 22 08:15:06.614: INFO: (0) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:460/proxy/: tls baz (200; 32.150163ms)
Aug 22 08:15:06.614: INFO: (0) /api/v1/namespaces/proxy-4228/services/https:proxy-service-twcg7:tlsportname2/proxy/: tls qux (200; 32.009927ms)
Aug 22 08:15:06.614: INFO: (0) /api/v1/namespaces/proxy-4228/services/https:proxy-service-twcg7:tlsportname1/proxy/: tls baz (200; 32.366983ms)
Aug 22 08:15:06.614: INFO: (0) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:443/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:443/proxy/tlsrewritem... (200; 32.683551ms)
Aug 22 08:15:06.615: INFO: (0) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:462/proxy/: tls qux (200; 33.012456ms)
Aug 22 08:15:06.628: INFO: (1) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:462/proxy/: tls qux (200; 12.841749ms)
Aug 22 08:15:06.630: INFO: (1) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:160/proxy/: foo (200; 15.496738ms)
Aug 22 08:15:06.630: INFO: (1) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:1080/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:1080/proxy/rewriteme">... (200; 15.623889ms)
Aug 22 08:15:06.638: INFO: (1) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:162/proxy/: bar (200; 23.134846ms)
Aug 22 08:15:06.639: INFO: (1) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:160/proxy/: foo (200; 23.568757ms)
Aug 22 08:15:06.639: INFO: (1) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:460/proxy/: tls baz (200; 23.620849ms)
Aug 22 08:15:06.639: INFO: (1) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:1080/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:1080/proxy/rewriteme">test<... (200; 23.474234ms)
Aug 22 08:15:06.639: INFO: (1) /api/v1/namespaces/proxy-4228/services/http:proxy-service-twcg7:portname2/proxy/: bar (200; 24.09312ms)
Aug 22 08:15:06.639: INFO: (1) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:443/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:443/proxy/tlsrewritem... (200; 23.973192ms)
Aug 22 08:15:06.639: INFO: (1) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52/proxy/rewriteme">test</a> (200; 24.02239ms)
Aug 22 08:15:06.640: INFO: (1) /api/v1/namespaces/proxy-4228/services/https:proxy-service-twcg7:tlsportname1/proxy/: tls baz (200; 25.081492ms)
Aug 22 08:15:06.640: INFO: (1) /api/v1/namespaces/proxy-4228/services/https:proxy-service-twcg7:tlsportname2/proxy/: tls qux (200; 25.157457ms)
Aug 22 08:15:06.641: INFO: (1) /api/v1/namespaces/proxy-4228/services/proxy-service-twcg7:portname1/proxy/: foo (200; 25.523528ms)
Aug 22 08:15:06.641: INFO: (1) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:162/proxy/: bar (200; 25.633578ms)
Aug 22 08:15:06.641: INFO: (1) /api/v1/namespaces/proxy-4228/services/proxy-service-twcg7:portname2/proxy/: bar (200; 25.905463ms)
Aug 22 08:15:06.642: INFO: (1) /api/v1/namespaces/proxy-4228/services/http:proxy-service-twcg7:portname1/proxy/: foo (200; 26.594691ms)
Aug 22 08:15:06.655: INFO: (2) /api/v1/namespaces/proxy-4228/services/https:proxy-service-twcg7:tlsportname2/proxy/: tls qux (200; 13.042263ms)
Aug 22 08:15:06.658: INFO: (2) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:160/proxy/: foo (200; 16.028062ms)
Aug 22 08:15:06.660: INFO: (2) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:443/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:443/proxy/tlsrewritem... (200; 17.826865ms)
Aug 22 08:15:06.660: INFO: (2) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:462/proxy/: tls qux (200; 17.968204ms)
Aug 22 08:15:06.661: INFO: (2) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:1080/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:1080/proxy/rewriteme">test<... (200; 18.167552ms)
Aug 22 08:15:06.661: INFO: (2) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:1080/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:1080/proxy/rewriteme">... (200; 18.275926ms)
Aug 22 08:15:06.661: INFO: (2) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52/proxy/rewriteme">test</a> (200; 19.01156ms)
Aug 22 08:15:06.662: INFO: (2) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:460/proxy/: tls baz (200; 20.387282ms)
Aug 22 08:15:06.662: INFO: (2) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:162/proxy/: bar (200; 19.590424ms)
Aug 22 08:15:06.662: INFO: (2) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:160/proxy/: foo (200; 20.232706ms)
Aug 22 08:15:06.662: INFO: (2) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:162/proxy/: bar (200; 20.232835ms)
Aug 22 08:15:06.663: INFO: (2) /api/v1/namespaces/proxy-4228/services/http:proxy-service-twcg7:portname1/proxy/: foo (200; 20.434712ms)
Aug 22 08:15:06.663: INFO: (2) /api/v1/namespaces/proxy-4228/services/proxy-service-twcg7:portname2/proxy/: bar (200; 20.705016ms)
Aug 22 08:15:06.664: INFO: (2) /api/v1/namespaces/proxy-4228/services/https:proxy-service-twcg7:tlsportname1/proxy/: tls baz (200; 21.596517ms)
Aug 22 08:15:06.664: INFO: (2) /api/v1/namespaces/proxy-4228/services/proxy-service-twcg7:portname1/proxy/: foo (200; 22.08527ms)
Aug 22 08:15:06.664: INFO: (2) /api/v1/namespaces/proxy-4228/services/http:proxy-service-twcg7:portname2/proxy/: bar (200; 21.49784ms)
Aug 22 08:15:06.681: INFO: (3) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52/proxy/rewriteme">test</a> (200; 15.933363ms)
Aug 22 08:15:06.688: INFO: (3) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:443/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:443/proxy/tlsrewritem... (200; 23.257347ms)
Aug 22 08:15:06.688: INFO: (3) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:160/proxy/: foo (200; 23.314995ms)
Aug 22 08:15:06.688: INFO: (3) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:460/proxy/: tls baz (200; 23.457046ms)
Aug 22 08:15:06.688: INFO: (3) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:162/proxy/: bar (200; 23.618117ms)
Aug 22 08:15:06.689: INFO: (3) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:160/proxy/: foo (200; 23.863204ms)
Aug 22 08:15:06.689: INFO: (3) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:1080/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:1080/proxy/rewriteme">test<... (200; 23.93908ms)
Aug 22 08:15:06.689: INFO: (3) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:462/proxy/: tls qux (200; 24.042481ms)
Aug 22 08:15:06.689: INFO: (3) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:162/proxy/: bar (200; 23.743162ms)
Aug 22 08:15:06.689: INFO: (3) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:1080/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:1080/proxy/rewriteme">... (200; 23.822665ms)
Aug 22 08:15:06.689: INFO: (3) /api/v1/namespaces/proxy-4228/services/proxy-service-twcg7:portname1/proxy/: foo (200; 23.914373ms)
Aug 22 08:15:06.689: INFO: (3) /api/v1/namespaces/proxy-4228/services/http:proxy-service-twcg7:portname1/proxy/: foo (200; 23.879908ms)
Aug 22 08:15:06.689: INFO: (3) /api/v1/namespaces/proxy-4228/services/https:proxy-service-twcg7:tlsportname1/proxy/: tls baz (200; 23.940112ms)
Aug 22 08:15:06.689: INFO: (3) /api/v1/namespaces/proxy-4228/services/http:proxy-service-twcg7:portname2/proxy/: bar (200; 24.506003ms)
Aug 22 08:15:06.689: INFO: (3) /api/v1/namespaces/proxy-4228/services/https:proxy-service-twcg7:tlsportname2/proxy/: tls qux (200; 24.284033ms)
Aug 22 08:15:06.690: INFO: (3) /api/v1/namespaces/proxy-4228/services/proxy-service-twcg7:portname2/proxy/: bar (200; 24.882139ms)
Aug 22 08:15:06.702: INFO: (4) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:162/proxy/: bar (200; 12.600835ms)
Aug 22 08:15:06.704: INFO: (4) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:1080/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:1080/proxy/rewriteme">... (200; 13.598437ms)
Aug 22 08:15:06.704: INFO: (4) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:1080/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:1080/proxy/rewriteme">test<... (200; 14.128054ms)
Aug 22 08:15:06.708: INFO: (4) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52/proxy/rewriteme">test</a> (200; 17.550974ms)
Aug 22 08:15:06.709: INFO: (4) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:460/proxy/: tls baz (200; 19.074201ms)
Aug 22 08:15:06.709: INFO: (4) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:162/proxy/: bar (200; 19.318865ms)
Aug 22 08:15:06.711: INFO: (4) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:443/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:443/proxy/tlsrewritem... (200; 20.540355ms)
Aug 22 08:15:06.711: INFO: (4) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:462/proxy/: tls qux (200; 20.85436ms)
Aug 22 08:15:06.711: INFO: (4) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:160/proxy/: foo (200; 21.001715ms)
Aug 22 08:15:06.711: INFO: (4) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:160/proxy/: foo (200; 20.801409ms)
Aug 22 08:15:06.711: INFO: (4) /api/v1/namespaces/proxy-4228/services/http:proxy-service-twcg7:portname2/proxy/: bar (200; 21.474561ms)
Aug 22 08:15:06.712: INFO: (4) /api/v1/namespaces/proxy-4228/services/proxy-service-twcg7:portname2/proxy/: bar (200; 22.146646ms)
Aug 22 08:15:06.712: INFO: (4) /api/v1/namespaces/proxy-4228/services/https:proxy-service-twcg7:tlsportname1/proxy/: tls baz (200; 22.155796ms)
Aug 22 08:15:06.713: INFO: (4) /api/v1/namespaces/proxy-4228/services/https:proxy-service-twcg7:tlsportname2/proxy/: tls qux (200; 22.517291ms)
Aug 22 08:15:06.713: INFO: (4) /api/v1/namespaces/proxy-4228/services/proxy-service-twcg7:portname1/proxy/: foo (200; 22.718111ms)
Aug 22 08:15:06.713: INFO: (4) /api/v1/namespaces/proxy-4228/services/http:proxy-service-twcg7:portname1/proxy/: foo (200; 23.39268ms)
Aug 22 08:15:06.728: INFO: (5) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:160/proxy/: foo (200; 14.289233ms)
Aug 22 08:15:06.728: INFO: (5) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:162/proxy/: bar (200; 14.296706ms)
Aug 22 08:15:06.728: INFO: (5) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:460/proxy/: tls baz (200; 14.900915ms)
Aug 22 08:15:06.738: INFO: (5) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52/proxy/rewriteme">test</a> (200; 23.893557ms)
Aug 22 08:15:06.747: INFO: (5) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:160/proxy/: foo (200; 33.074573ms)
Aug 22 08:15:06.748: INFO: (5) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:1080/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:1080/proxy/rewriteme">test<... (200; 33.962856ms)
Aug 22 08:15:06.756: INFO: (5) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:1080/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:1080/proxy/rewriteme">... (200; 42.081879ms)
Aug 22 08:15:06.757: INFO: (5) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:462/proxy/: tls qux (200; 43.258708ms)
Aug 22 08:15:06.758: INFO: (5) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:443/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:443/proxy/tlsrewritem... (200; 44.308582ms)
Aug 22 08:15:06.759: INFO: (5) /api/v1/namespaces/proxy-4228/services/https:proxy-service-twcg7:tlsportname1/proxy/: tls baz (200; 45.403609ms)
Aug 22 08:15:06.760: INFO: (5) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:162/proxy/: bar (200; 45.853295ms)
Aug 22 08:15:06.764: INFO: (5) /api/v1/namespaces/proxy-4228/services/http:proxy-service-twcg7:portname2/proxy/: bar (200; 50.446472ms)
Aug 22 08:15:06.765: INFO: (5) /api/v1/namespaces/proxy-4228/services/https:proxy-service-twcg7:tlsportname2/proxy/: tls qux (200; 51.49758ms)
Aug 22 08:15:06.766: INFO: (5) /api/v1/namespaces/proxy-4228/services/http:proxy-service-twcg7:portname1/proxy/: foo (200; 52.683843ms)
Aug 22 08:15:06.767: INFO: (5) /api/v1/namespaces/proxy-4228/services/proxy-service-twcg7:portname1/proxy/: foo (200; 53.378009ms)
Aug 22 08:15:06.769: INFO: (5) /api/v1/namespaces/proxy-4228/services/proxy-service-twcg7:portname2/proxy/: bar (200; 54.810942ms)
Aug 22 08:15:06.825: INFO: (6) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:1080/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:1080/proxy/rewriteme">... (200; 56.046875ms)
Aug 22 08:15:06.825: INFO: (6) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:160/proxy/: foo (200; 56.162356ms)
Aug 22 08:15:06.827: INFO: (6) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:462/proxy/: tls qux (200; 57.384112ms)
Aug 22 08:15:06.827: INFO: (6) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52/proxy/rewriteme">test</a> (200; 57.612871ms)
Aug 22 08:15:06.827: INFO: (6) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:1080/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:1080/proxy/rewriteme">test<... (200; 57.120352ms)
Aug 22 08:15:06.827: INFO: (6) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:162/proxy/: bar (200; 58.003242ms)
Aug 22 08:15:06.832: INFO: (6) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:162/proxy/: bar (200; 62.047609ms)
Aug 22 08:15:06.832: INFO: (6) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:160/proxy/: foo (200; 62.851735ms)
Aug 22 08:15:06.833: INFO: (6) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:460/proxy/: tls baz (200; 63.665566ms)
Aug 22 08:15:06.834: INFO: (6) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:443/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:443/proxy/tlsrewritem... (200; 64.934967ms)
Aug 22 08:15:06.839: INFO: (6) /api/v1/namespaces/proxy-4228/services/proxy-service-twcg7:portname2/proxy/: bar (200; 70.517069ms)
Aug 22 08:15:06.842: INFO: (6) /api/v1/namespaces/proxy-4228/services/http:proxy-service-twcg7:portname1/proxy/: foo (200; 72.947817ms)
Aug 22 08:15:06.843: INFO: (6) /api/v1/namespaces/proxy-4228/services/https:proxy-service-twcg7:tlsportname2/proxy/: tls qux (200; 73.445458ms)
Aug 22 08:15:06.852: INFO: (6) /api/v1/namespaces/proxy-4228/services/proxy-service-twcg7:portname1/proxy/: foo (200; 81.9731ms)
Aug 22 08:15:06.852: INFO: (6) /api/v1/namespaces/proxy-4228/services/https:proxy-service-twcg7:tlsportname1/proxy/: tls baz (200; 82.262224ms)
Aug 22 08:15:06.852: INFO: (6) /api/v1/namespaces/proxy-4228/services/http:proxy-service-twcg7:portname2/proxy/: bar (200; 82.923573ms)
Aug 22 08:15:06.890: INFO: (7) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:1080/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:1080/proxy/rewriteme">test<... (200; 37.252802ms)
Aug 22 08:15:06.891: INFO: (7) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:462/proxy/: tls qux (200; 38.060025ms)
Aug 22 08:15:06.891: INFO: (7) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:460/proxy/: tls baz (200; 38.096351ms)
Aug 22 08:15:06.891: INFO: (7) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52/proxy/rewriteme">test</a> (200; 37.985403ms)
Aug 22 08:15:06.891: INFO: (7) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:162/proxy/: bar (200; 38.32774ms)
Aug 22 08:15:06.891: INFO: (7) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:160/proxy/: foo (200; 38.328789ms)
Aug 22 08:15:06.895: INFO: (7) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:162/proxy/: bar (200; 41.807853ms)
Aug 22 08:15:06.895: INFO: (7) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:443/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:443/proxy/tlsrewritem... (200; 42.140704ms)
Aug 22 08:15:06.896: INFO: (7) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:1080/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:1080/proxy/rewriteme">... (200; 42.734729ms)
Aug 22 08:15:06.899: INFO: (7) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:160/proxy/: foo (200; 46.472858ms)
Aug 22 08:15:06.900: INFO: (7) /api/v1/namespaces/proxy-4228/services/proxy-service-twcg7:portname2/proxy/: bar (200; 47.214961ms)
Aug 22 08:15:06.902: INFO: (7) /api/v1/namespaces/proxy-4228/services/http:proxy-service-twcg7:portname1/proxy/: foo (200; 49.042342ms)
Aug 22 08:15:06.902: INFO: (7) /api/v1/namespaces/proxy-4228/services/https:proxy-service-twcg7:tlsportname1/proxy/: tls baz (200; 49.140949ms)
Aug 22 08:15:06.902: INFO: (7) /api/v1/namespaces/proxy-4228/services/https:proxy-service-twcg7:tlsportname2/proxy/: tls qux (200; 49.757144ms)
Aug 22 08:15:06.905: INFO: (7) /api/v1/namespaces/proxy-4228/services/proxy-service-twcg7:portname1/proxy/: foo (200; 51.711259ms)
Aug 22 08:15:06.905: INFO: (7) /api/v1/namespaces/proxy-4228/services/http:proxy-service-twcg7:portname2/proxy/: bar (200; 52.362085ms)
Aug 22 08:15:06.948: INFO: (8) /api/v1/namespaces/proxy-4228/services/http:proxy-service-twcg7:portname2/proxy/: bar (200; 43.224831ms)
Aug 22 08:15:06.949: INFO: (8) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:162/proxy/: bar (200; 42.984639ms)
Aug 22 08:15:06.950: INFO: (8) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:460/proxy/: tls baz (200; 44.570609ms)
Aug 22 08:15:06.951: INFO: (8) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:160/proxy/: foo (200; 45.371214ms)
Aug 22 08:15:06.951: INFO: (8) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52/proxy/rewriteme">test</a> (200; 45.845115ms)
Aug 22 08:15:06.952: INFO: (8) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:1080/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:1080/proxy/rewriteme">... (200; 46.381308ms)
Aug 22 08:15:06.958: INFO: (8) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:160/proxy/: foo (200; 52.055733ms)
Aug 22 08:15:06.959: INFO: (8) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:162/proxy/: bar (200; 53.123069ms)
Aug 22 08:15:06.963: INFO: (8) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:443/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:443/proxy/tlsrewritem... (200; 57.341913ms)
Aug 22 08:15:06.963: INFO: (8) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:1080/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:1080/proxy/rewriteme">test<... (200; 57.304114ms)
Aug 22 08:15:06.963: INFO: (8) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:462/proxy/: tls qux (200; 57.45773ms)
Aug 22 08:15:06.963: INFO: (8) /api/v1/namespaces/proxy-4228/services/proxy-service-twcg7:portname1/proxy/: foo (200; 57.957912ms)
Aug 22 08:15:06.972: INFO: (8) /api/v1/namespaces/proxy-4228/services/https:proxy-service-twcg7:tlsportname2/proxy/: tls qux (200; 65.514763ms)
Aug 22 08:15:06.972: INFO: (8) /api/v1/namespaces/proxy-4228/services/https:proxy-service-twcg7:tlsportname1/proxy/: tls baz (200; 66.067374ms)
Aug 22 08:15:06.985: INFO: (8) /api/v1/namespaces/proxy-4228/services/http:proxy-service-twcg7:portname1/proxy/: foo (200; 78.956008ms)
Aug 22 08:15:06.985: INFO: (8) /api/v1/namespaces/proxy-4228/services/proxy-service-twcg7:portname2/proxy/: bar (200; 78.967498ms)
Aug 22 08:15:07.027: INFO: (9) /api/v1/namespaces/proxy-4228/services/http:proxy-service-twcg7:portname1/proxy/: foo (200; 41.685482ms)
Aug 22 08:15:07.041: INFO: (9) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:162/proxy/: bar (200; 55.810425ms)
Aug 22 08:15:07.041: INFO: (9) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:443/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:443/proxy/tlsrewritem... (200; 55.417234ms)
Aug 22 08:15:07.041: INFO: (9) /api/v1/namespaces/proxy-4228/services/https:proxy-service-twcg7:tlsportname2/proxy/: tls qux (200; 55.16504ms)
Aug 22 08:15:07.041: INFO: (9) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:1080/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:1080/proxy/rewriteme">... (200; 55.595948ms)
Aug 22 08:15:07.041: INFO: (9) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:1080/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:1080/proxy/rewriteme">test<... (200; 55.699262ms)
Aug 22 08:15:07.041: INFO: (9) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52/proxy/rewriteme">test</a> (200; 55.337127ms)
Aug 22 08:15:07.041: INFO: (9) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:160/proxy/: foo (200; 55.717233ms)
Aug 22 08:15:07.041: INFO: (9) /api/v1/namespaces/proxy-4228/services/https:proxy-service-twcg7:tlsportname1/proxy/: tls baz (200; 55.158441ms)
Aug 22 08:15:07.042: INFO: (9) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:162/proxy/: bar (200; 55.599222ms)
Aug 22 08:15:07.042: INFO: (9) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:462/proxy/: tls qux (200; 56.188885ms)
Aug 22 08:15:07.042: INFO: (9) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:460/proxy/: tls baz (200; 55.907857ms)
Aug 22 08:15:07.042: INFO: (9) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:160/proxy/: foo (200; 56.048513ms)
Aug 22 08:15:07.046: INFO: (9) /api/v1/namespaces/proxy-4228/services/proxy-service-twcg7:portname2/proxy/: bar (200; 60.24576ms)
Aug 22 08:15:07.046: INFO: (9) /api/v1/namespaces/proxy-4228/services/http:proxy-service-twcg7:portname2/proxy/: bar (200; 60.988774ms)
Aug 22 08:15:07.047: INFO: (9) /api/v1/namespaces/proxy-4228/services/proxy-service-twcg7:portname1/proxy/: foo (200; 60.502603ms)
Aug 22 08:15:07.080: INFO: (10) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:460/proxy/: tls baz (200; 32.523337ms)
Aug 22 08:15:07.080: INFO: (10) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:160/proxy/: foo (200; 32.702049ms)
Aug 22 08:15:07.080: INFO: (10) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:1080/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:1080/proxy/rewriteme">... (200; 32.831386ms)
Aug 22 08:15:07.080: INFO: (10) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:1080/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:1080/proxy/rewriteme">test<... (200; 32.887993ms)
Aug 22 08:15:07.081: INFO: (10) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:462/proxy/: tls qux (200; 34.657279ms)
Aug 22 08:15:07.082: INFO: (10) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:160/proxy/: foo (200; 35.171383ms)
Aug 22 08:15:07.082: INFO: (10) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:162/proxy/: bar (200; 35.316539ms)
Aug 22 08:15:07.082: INFO: (10) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:443/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:443/proxy/tlsrewritem... (200; 35.075794ms)
Aug 22 08:15:07.082: INFO: (10) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52/proxy/rewriteme">test</a> (200; 35.306055ms)
Aug 22 08:15:07.082: INFO: (10) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:162/proxy/: bar (200; 35.659201ms)
Aug 22 08:15:07.086: INFO: (10) /api/v1/namespaces/proxy-4228/services/http:proxy-service-twcg7:portname2/proxy/: bar (200; 38.841164ms)
Aug 22 08:15:07.087: INFO: (10) /api/v1/namespaces/proxy-4228/services/proxy-service-twcg7:portname1/proxy/: foo (200; 39.522383ms)
Aug 22 08:15:07.087: INFO: (10) /api/v1/namespaces/proxy-4228/services/https:proxy-service-twcg7:tlsportname1/proxy/: tls baz (200; 39.59379ms)
Aug 22 08:15:07.087: INFO: (10) /api/v1/namespaces/proxy-4228/services/proxy-service-twcg7:portname2/proxy/: bar (200; 39.699389ms)
Aug 22 08:15:07.087: INFO: (10) /api/v1/namespaces/proxy-4228/services/https:proxy-service-twcg7:tlsportname2/proxy/: tls qux (200; 39.972862ms)
Aug 22 08:15:07.087: INFO: (10) /api/v1/namespaces/proxy-4228/services/http:proxy-service-twcg7:portname1/proxy/: foo (200; 40.553104ms)
Aug 22 08:15:07.100: INFO: (11) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:160/proxy/: foo (200; 12.43468ms)
Aug 22 08:15:07.107: INFO: (11) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:1080/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:1080/proxy/rewriteme">... (200; 18.893012ms)
Aug 22 08:15:07.107: INFO: (11) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:1080/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:1080/proxy/rewriteme">test<... (200; 18.991038ms)
Aug 22 08:15:07.107: INFO: (11) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:160/proxy/: foo (200; 19.595993ms)
Aug 22 08:15:07.107: INFO: (11) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:162/proxy/: bar (200; 19.244877ms)
Aug 22 08:15:07.107: INFO: (11) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:443/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:443/proxy/tlsrewritem... (200; 19.584531ms)
Aug 22 08:15:07.108: INFO: (11) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:162/proxy/: bar (200; 19.961451ms)
Aug 22 08:15:07.108: INFO: (11) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:460/proxy/: tls baz (200; 19.533956ms)
Aug 22 08:15:07.108: INFO: (11) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52/proxy/rewriteme">test</a> (200; 19.544412ms)
Aug 22 08:15:07.108: INFO: (11) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:462/proxy/: tls qux (200; 20.388021ms)
Aug 22 08:15:07.109: INFO: (11) /api/v1/namespaces/proxy-4228/services/https:proxy-service-twcg7:tlsportname1/proxy/: tls baz (200; 21.166716ms)
Aug 22 08:15:07.110: INFO: (11) /api/v1/namespaces/proxy-4228/services/http:proxy-service-twcg7:portname1/proxy/: foo (200; 21.486977ms)
Aug 22 08:15:07.110: INFO: (11) /api/v1/namespaces/proxy-4228/services/https:proxy-service-twcg7:tlsportname2/proxy/: tls qux (200; 21.210804ms)
Aug 22 08:15:07.110: INFO: (11) /api/v1/namespaces/proxy-4228/services/proxy-service-twcg7:portname1/proxy/: foo (200; 21.404912ms)
Aug 22 08:15:07.110: INFO: (11) /api/v1/namespaces/proxy-4228/services/proxy-service-twcg7:portname2/proxy/: bar (200; 22.159483ms)
Aug 22 08:15:07.111: INFO: (11) /api/v1/namespaces/proxy-4228/services/http:proxy-service-twcg7:portname2/proxy/: bar (200; 22.319868ms)
Aug 22 08:15:07.125: INFO: (12) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:162/proxy/: bar (200; 13.370678ms)
Aug 22 08:15:07.125: INFO: (12) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:443/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:443/proxy/tlsrewritem... (200; 14.285127ms)
Aug 22 08:15:07.126: INFO: (12) /api/v1/namespaces/proxy-4228/services/http:proxy-service-twcg7:portname2/proxy/: bar (200; 14.773862ms)
Aug 22 08:15:07.126: INFO: (12) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:1080/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:1080/proxy/rewriteme">... (200; 14.555587ms)
Aug 22 08:15:07.129: INFO: (12) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:462/proxy/: tls qux (200; 18.313057ms)
Aug 22 08:15:07.130: INFO: (12) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:160/proxy/: foo (200; 18.178696ms)
Aug 22 08:15:07.130: INFO: (12) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:160/proxy/: foo (200; 17.914152ms)
Aug 22 08:15:07.130: INFO: (12) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52/proxy/rewriteme">test</a> (200; 18.332088ms)
Aug 22 08:15:07.131: INFO: (12) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:460/proxy/: tls baz (200; 19.133597ms)
Aug 22 08:15:07.131: INFO: (12) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:1080/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:1080/proxy/rewriteme">test<... (200; 19.799154ms)
Aug 22 08:15:07.131: INFO: (12) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:162/proxy/: bar (200; 19.611097ms)
Aug 22 08:15:07.132: INFO: (12) /api/v1/namespaces/proxy-4228/services/proxy-service-twcg7:portname2/proxy/: bar (200; 20.769233ms)
Aug 22 08:15:07.132: INFO: (12) /api/v1/namespaces/proxy-4228/services/https:proxy-service-twcg7:tlsportname1/proxy/: tls baz (200; 20.442833ms)
Aug 22 08:15:07.133: INFO: (12) /api/v1/namespaces/proxy-4228/services/http:proxy-service-twcg7:portname1/proxy/: foo (200; 21.371074ms)
Aug 22 08:15:07.133: INFO: (12) /api/v1/namespaces/proxy-4228/services/proxy-service-twcg7:portname1/proxy/: foo (200; 21.018209ms)
Aug 22 08:15:07.133: INFO: (12) /api/v1/namespaces/proxy-4228/services/https:proxy-service-twcg7:tlsportname2/proxy/: tls qux (200; 21.273652ms)
Aug 22 08:15:07.146: INFO: (13) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:160/proxy/: foo (200; 12.817875ms)
Aug 22 08:15:07.147: INFO: (13) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:162/proxy/: bar (200; 14.071999ms)
Aug 22 08:15:07.152: INFO: (13) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:162/proxy/: bar (200; 18.088549ms)
Aug 22 08:15:07.152: INFO: (13) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52/proxy/rewriteme">test</a> (200; 18.043932ms)
Aug 22 08:15:07.152: INFO: (13) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:460/proxy/: tls baz (200; 18.199775ms)
Aug 22 08:15:07.152: INFO: (13) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:1080/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:1080/proxy/rewriteme">test<... (200; 18.817333ms)
Aug 22 08:15:07.152: INFO: (13) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:462/proxy/: tls qux (200; 19.001247ms)
Aug 22 08:15:07.152: INFO: (13) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:443/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:443/proxy/tlsrewritem... (200; 19.176683ms)
Aug 22 08:15:07.152: INFO: (13) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:160/proxy/: foo (200; 18.602919ms)
Aug 22 08:15:07.153: INFO: (13) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:1080/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:1080/proxy/rewriteme">... (200; 19.367429ms)
Aug 22 08:15:07.154: INFO: (13) /api/v1/namespaces/proxy-4228/services/https:proxy-service-twcg7:tlsportname1/proxy/: tls baz (200; 19.865681ms)
Aug 22 08:15:07.154: INFO: (13) /api/v1/namespaces/proxy-4228/services/https:proxy-service-twcg7:tlsportname2/proxy/: tls qux (200; 20.482292ms)
Aug 22 08:15:07.154: INFO: (13) /api/v1/namespaces/proxy-4228/services/proxy-service-twcg7:portname1/proxy/: foo (200; 20.390121ms)
Aug 22 08:15:07.154: INFO: (13) /api/v1/namespaces/proxy-4228/services/proxy-service-twcg7:portname2/proxy/: bar (200; 20.904533ms)
Aug 22 08:15:07.155: INFO: (13) /api/v1/namespaces/proxy-4228/services/http:proxy-service-twcg7:portname1/proxy/: foo (200; 21.546145ms)
Aug 22 08:15:07.155: INFO: (13) /api/v1/namespaces/proxy-4228/services/http:proxy-service-twcg7:portname2/proxy/: bar (200; 21.42237ms)
Aug 22 08:15:07.166: INFO: (14) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:162/proxy/: bar (200; 11.351418ms)
Aug 22 08:15:07.168: INFO: (14) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:160/proxy/: foo (200; 12.539318ms)
Aug 22 08:15:07.171: INFO: (14) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:1080/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:1080/proxy/rewriteme">test<... (200; 15.219984ms)
Aug 22 08:15:07.171: INFO: (14) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:460/proxy/: tls baz (200; 14.50523ms)
Aug 22 08:15:07.171: INFO: (14) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:443/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:443/proxy/tlsrewritem... (200; 15.34576ms)
Aug 22 08:15:07.175: INFO: (14) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:160/proxy/: foo (200; 19.057536ms)
Aug 22 08:15:07.175: INFO: (14) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:1080/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:1080/proxy/rewriteme">... (200; 19.899039ms)
Aug 22 08:15:07.175: INFO: (14) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52/proxy/rewriteme">test</a> (200; 19.270766ms)
Aug 22 08:15:07.175: INFO: (14) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:462/proxy/: tls qux (200; 19.727482ms)
Aug 22 08:15:07.176: INFO: (14) /api/v1/namespaces/proxy-4228/services/http:proxy-service-twcg7:portname1/proxy/: foo (200; 20.788403ms)
Aug 22 08:15:07.176: INFO: (14) /api/v1/namespaces/proxy-4228/services/http:proxy-service-twcg7:portname2/proxy/: bar (200; 20.297258ms)
Aug 22 08:15:07.176: INFO: (14) /api/v1/namespaces/proxy-4228/services/proxy-service-twcg7:portname1/proxy/: foo (200; 20.098181ms)
Aug 22 08:15:07.176: INFO: (14) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:162/proxy/: bar (200; 20.187545ms)
Aug 22 08:15:07.176: INFO: (14) /api/v1/namespaces/proxy-4228/services/https:proxy-service-twcg7:tlsportname1/proxy/: tls baz (200; 19.827439ms)
Aug 22 08:15:07.176: INFO: (14) /api/v1/namespaces/proxy-4228/services/https:proxy-service-twcg7:tlsportname2/proxy/: tls qux (200; 20.181093ms)
Aug 22 08:15:07.177: INFO: (14) /api/v1/namespaces/proxy-4228/services/proxy-service-twcg7:portname2/proxy/: bar (200; 21.119836ms)
Aug 22 08:15:07.189: INFO: (15) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:162/proxy/: bar (200; 12.323882ms)
Aug 22 08:15:07.191: INFO: (15) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:160/proxy/: foo (200; 13.880604ms)
Aug 22 08:15:07.191: INFO: (15) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:162/proxy/: bar (200; 13.709544ms)
Aug 22 08:15:07.191: INFO: (15) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:460/proxy/: tls baz (200; 13.94717ms)
Aug 22 08:15:07.192: INFO: (15) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:462/proxy/: tls qux (200; 13.91289ms)
Aug 22 08:15:07.193: INFO: (15) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:1080/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:1080/proxy/rewriteme">test<... (200; 15.071948ms)
Aug 22 08:15:07.193: INFO: (15) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:160/proxy/: foo (200; 14.976762ms)
Aug 22 08:15:07.194: INFO: (15) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:1080/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:1080/proxy/rewriteme">... (200; 16.819329ms)
Aug 22 08:15:07.195: INFO: (15) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52/proxy/rewriteme">test</a> (200; 17.800588ms)
Aug 22 08:15:07.195: INFO: (15) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:443/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:443/proxy/tlsrewritem... (200; 17.228078ms)
Aug 22 08:15:07.197: INFO: (15) /api/v1/namespaces/proxy-4228/services/http:proxy-service-twcg7:portname1/proxy/: foo (200; 19.292351ms)
Aug 22 08:15:07.197: INFO: (15) /api/v1/namespaces/proxy-4228/services/http:proxy-service-twcg7:portname2/proxy/: bar (200; 18.844689ms)
Aug 22 08:15:07.198: INFO: (15) /api/v1/namespaces/proxy-4228/services/https:proxy-service-twcg7:tlsportname2/proxy/: tls qux (200; 19.644496ms)
Aug 22 08:15:07.198: INFO: (15) /api/v1/namespaces/proxy-4228/services/proxy-service-twcg7:portname1/proxy/: foo (200; 20.726624ms)
Aug 22 08:15:07.198: INFO: (15) /api/v1/namespaces/proxy-4228/services/https:proxy-service-twcg7:tlsportname1/proxy/: tls baz (200; 21.121235ms)
Aug 22 08:15:07.199: INFO: (15) /api/v1/namespaces/proxy-4228/services/proxy-service-twcg7:portname2/proxy/: bar (200; 20.640473ms)
Aug 22 08:15:07.209: INFO: (16) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52/proxy/rewriteme">test</a> (200; 9.915871ms)
Aug 22 08:15:07.209: INFO: (16) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:162/proxy/: bar (200; 10.831747ms)
Aug 22 08:15:07.212: INFO: (16) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:443/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:443/proxy/tlsrewritem... (200; 12.505581ms)
Aug 22 08:15:07.212: INFO: (16) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:1080/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:1080/proxy/rewriteme">test<... (200; 12.903072ms)
Aug 22 08:15:07.214: INFO: (16) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:460/proxy/: tls baz (200; 15.241126ms)
Aug 22 08:15:07.214: INFO: (16) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:160/proxy/: foo (200; 15.484101ms)
Aug 22 08:15:07.215: INFO: (16) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:162/proxy/: bar (200; 15.346945ms)
Aug 22 08:15:07.215: INFO: (16) /api/v1/namespaces/proxy-4228/services/http:proxy-service-twcg7:portname1/proxy/: foo (200; 16.053671ms)
Aug 22 08:15:07.215: INFO: (16) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:1080/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:1080/proxy/rewriteme">... (200; 15.905453ms)
Aug 22 08:15:07.217: INFO: (16) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:462/proxy/: tls qux (200; 18.237332ms)
Aug 22 08:15:07.219: INFO: (16) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:160/proxy/: foo (200; 20.23979ms)
Aug 22 08:15:07.220: INFO: (16) /api/v1/namespaces/proxy-4228/services/https:proxy-service-twcg7:tlsportname1/proxy/: tls baz (200; 20.59953ms)
Aug 22 08:15:07.220: INFO: (16) /api/v1/namespaces/proxy-4228/services/https:proxy-service-twcg7:tlsportname2/proxy/: tls qux (200; 20.692102ms)
Aug 22 08:15:07.220: INFO: (16) /api/v1/namespaces/proxy-4228/services/proxy-service-twcg7:portname1/proxy/: foo (200; 21.437166ms)
Aug 22 08:15:07.221: INFO: (16) /api/v1/namespaces/proxy-4228/services/http:proxy-service-twcg7:portname2/proxy/: bar (200; 21.38618ms)
Aug 22 08:15:07.221: INFO: (16) /api/v1/namespaces/proxy-4228/services/proxy-service-twcg7:portname2/proxy/: bar (200; 21.724347ms)
Aug 22 08:15:07.231: INFO: (17) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:443/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:443/proxy/tlsrewritem... (200; 10.186693ms)
Aug 22 08:15:07.239: INFO: (17) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52/proxy/rewriteme">test</a> (200; 17.553711ms)
Aug 22 08:15:07.239: INFO: (17) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:160/proxy/: foo (200; 17.612035ms)
Aug 22 08:15:07.239: INFO: (17) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:1080/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:1080/proxy/rewriteme">test<... (200; 18.032941ms)
Aug 22 08:15:07.240: INFO: (17) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:460/proxy/: tls baz (200; 18.384252ms)
Aug 22 08:15:07.240: INFO: (17) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:462/proxy/: tls qux (200; 18.162589ms)
Aug 22 08:15:07.240: INFO: (17) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:162/proxy/: bar (200; 18.249495ms)
Aug 22 08:15:07.240: INFO: (17) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:160/proxy/: foo (200; 18.060717ms)
Aug 22 08:15:07.241: INFO: (17) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:1080/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:1080/proxy/rewriteme">... (200; 19.555219ms)
Aug 22 08:15:07.241: INFO: (17) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:162/proxy/: bar (200; 19.586959ms)
Aug 22 08:15:07.242: INFO: (17) /api/v1/namespaces/proxy-4228/services/proxy-service-twcg7:portname2/proxy/: bar (200; 20.78852ms)
Aug 22 08:15:07.242: INFO: (17) /api/v1/namespaces/proxy-4228/services/https:proxy-service-twcg7:tlsportname1/proxy/: tls baz (200; 20.794743ms)
Aug 22 08:15:07.242: INFO: (17) /api/v1/namespaces/proxy-4228/services/http:proxy-service-twcg7:portname2/proxy/: bar (200; 20.813559ms)
Aug 22 08:15:07.243: INFO: (17) /api/v1/namespaces/proxy-4228/services/https:proxy-service-twcg7:tlsportname2/proxy/: tls qux (200; 21.416472ms)
Aug 22 08:15:07.243: INFO: (17) /api/v1/namespaces/proxy-4228/services/proxy-service-twcg7:portname1/proxy/: foo (200; 21.779774ms)
Aug 22 08:15:07.243: INFO: (17) /api/v1/namespaces/proxy-4228/services/http:proxy-service-twcg7:portname1/proxy/: foo (200; 21.976905ms)
Aug 22 08:15:07.255: INFO: (18) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:462/proxy/: tls qux (200; 11.080818ms)
Aug 22 08:15:07.256: INFO: (18) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:1080/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:1080/proxy/rewriteme">test<... (200; 11.868586ms)
Aug 22 08:15:07.256: INFO: (18) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:460/proxy/: tls baz (200; 12.680142ms)
Aug 22 08:15:07.258: INFO: (18) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52/proxy/rewriteme">test</a> (200; 14.108898ms)
Aug 22 08:15:07.258: INFO: (18) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:160/proxy/: foo (200; 14.491725ms)
Aug 22 08:15:07.258: INFO: (18) /api/v1/namespaces/proxy-4228/services/http:proxy-service-twcg7:portname2/proxy/: bar (200; 14.86459ms)
Aug 22 08:15:07.258: INFO: (18) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:162/proxy/: bar (200; 14.506061ms)
Aug 22 08:15:07.260: INFO: (18) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:1080/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:1080/proxy/rewriteme">... (200; 15.548824ms)
Aug 22 08:15:07.260: INFO: (18) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:160/proxy/: foo (200; 15.659119ms)
Aug 22 08:15:07.260: INFO: (18) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:443/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:443/proxy/tlsrewritem... (200; 15.74872ms)
Aug 22 08:15:07.263: INFO: (18) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:162/proxy/: bar (200; 18.563112ms)
Aug 22 08:15:07.263: INFO: (18) /api/v1/namespaces/proxy-4228/services/http:proxy-service-twcg7:portname1/proxy/: foo (200; 19.211888ms)
Aug 22 08:15:07.264: INFO: (18) /api/v1/namespaces/proxy-4228/services/https:proxy-service-twcg7:tlsportname2/proxy/: tls qux (200; 19.405405ms)
Aug 22 08:15:07.264: INFO: (18) /api/v1/namespaces/proxy-4228/services/proxy-service-twcg7:portname1/proxy/: foo (200; 20.704526ms)
Aug 22 08:15:07.265: INFO: (18) /api/v1/namespaces/proxy-4228/services/https:proxy-service-twcg7:tlsportname1/proxy/: tls baz (200; 20.782272ms)
Aug 22 08:15:07.265: INFO: (18) /api/v1/namespaces/proxy-4228/services/proxy-service-twcg7:portname2/proxy/: bar (200; 20.332823ms)
Aug 22 08:15:07.290: INFO: (19) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:162/proxy/: bar (200; 24.825404ms)
Aug 22 08:15:07.290: INFO: (19) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:462/proxy/: tls qux (200; 24.913624ms)
Aug 22 08:15:07.290: INFO: (19) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52/proxy/rewriteme">test</a> (200; 25.112304ms)
Aug 22 08:15:07.292: INFO: (19) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:460/proxy/: tls baz (200; 26.600666ms)
Aug 22 08:15:07.292: INFO: (19) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:162/proxy/: bar (200; 26.795481ms)
Aug 22 08:15:07.292: INFO: (19) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:160/proxy/: foo (200; 27.076004ms)
Aug 22 08:15:07.302: INFO: (19) /api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:1080/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/http:proxy-service-twcg7-vln52:1080/proxy/rewriteme">... (200; 36.456913ms)
Aug 22 08:15:07.302: INFO: (19) /api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:443/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/https:proxy-service-twcg7-vln52:443/proxy/tlsrewritem... (200; 36.497222ms)
Aug 22 08:15:07.302: INFO: (19) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:1080/proxy/: <a href="/api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:1080/proxy/rewriteme">test<... (200; 36.859009ms)
Aug 22 08:15:07.302: INFO: (19) /api/v1/namespaces/proxy-4228/pods/proxy-service-twcg7-vln52:160/proxy/: foo (200; 37.064887ms)
Aug 22 08:15:07.307: INFO: (19) /api/v1/namespaces/proxy-4228/services/http:proxy-service-twcg7:portname2/proxy/: bar (200; 42.161645ms)
Aug 22 08:15:07.308: INFO: (19) /api/v1/namespaces/proxy-4228/services/proxy-service-twcg7:portname1/proxy/: foo (200; 42.387675ms)
Aug 22 08:15:07.308: INFO: (19) /api/v1/namespaces/proxy-4228/services/https:proxy-service-twcg7:tlsportname2/proxy/: tls qux (200; 42.193752ms)
Aug 22 08:15:07.308: INFO: (19) /api/v1/namespaces/proxy-4228/services/https:proxy-service-twcg7:tlsportname1/proxy/: tls baz (200; 42.561556ms)
Aug 22 08:15:07.308: INFO: (19) /api/v1/namespaces/proxy-4228/services/proxy-service-twcg7:portname2/proxy/: bar (200; 42.821173ms)
Aug 22 08:15:07.308: INFO: (19) /api/v1/namespaces/proxy-4228/services/http:proxy-service-twcg7:portname1/proxy/: foo (200; 42.75568ms)
STEP: deleting ReplicationController proxy-service-twcg7 in namespace proxy-4228, will wait for the garbage collector to delete the pods
Aug 22 08:15:07.370: INFO: Deleting ReplicationController proxy-service-twcg7 took: 6.645106ms
Aug 22 08:15:07.670: INFO: Terminating ReplicationController proxy-service-twcg7 pods took: 300.17857ms
[AfterEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:15:19.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-4228" for this suite.
Aug 22 08:15:25.690: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:15:25.772: INFO: namespace proxy-4228 deletion completed in 6.096177009s

• [SLOW TEST:28.418 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:15:25.773: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6183
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-fec706d2-c4b4-11e9-80b5-1edf08853c25
STEP: Creating secret with name s-test-opt-upd-fec70722-c4b4-11e9-80b5-1edf08853c25
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-fec706d2-c4b4-11e9-80b5-1edf08853c25
STEP: Updating secret s-test-opt-upd-fec70722-c4b4-11e9-80b5-1edf08853c25
STEP: Creating secret with name s-test-opt-create-fec70744-c4b4-11e9-80b5-1edf08853c25
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:15:30.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6183" for this suite.
Aug 22 08:15:52.046: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:15:52.205: INFO: namespace projected-6183 deletion completed in 22.178975962s

• [SLOW TEST:26.432 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:15:52.205: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-268
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-0e88039d-c4b5-11e9-80b5-1edf08853c25
STEP: Creating a pod to test consume configMaps
Aug 22 08:15:52.354: INFO: Waiting up to 5m0s for pod "pod-configmaps-0e88a77b-c4b5-11e9-80b5-1edf08853c25" in namespace "configmap-268" to be "success or failure"
Aug 22 08:15:52.360: INFO: Pod "pod-configmaps-0e88a77b-c4b5-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 5.494445ms
Aug 22 08:15:54.363: INFO: Pod "pod-configmaps-0e88a77b-c4b5-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008729862s
STEP: Saw pod success
Aug 22 08:15:54.363: INFO: Pod "pod-configmaps-0e88a77b-c4b5-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:15:54.365: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-configmaps-0e88a77b-c4b5-11e9-80b5-1edf08853c25 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 22 08:15:54.380: INFO: Waiting for pod pod-configmaps-0e88a77b-c4b5-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:15:54.382: INFO: Pod pod-configmaps-0e88a77b-c4b5-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:15:54.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-268" for this suite.
Aug 22 08:16:00.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:16:00.574: INFO: namespace configmap-268 deletion completed in 6.188137136s

• [SLOW TEST:8.369 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:16:00.575: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-8653
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Aug 22 08:16:00.727: INFO: Creating ReplicaSet my-hostname-basic-13876003-c4b5-11e9-80b5-1edf08853c25
Aug 22 08:16:00.741: INFO: Pod name my-hostname-basic-13876003-c4b5-11e9-80b5-1edf08853c25: Found 1 pods out of 1
Aug 22 08:16:00.741: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-13876003-c4b5-11e9-80b5-1edf08853c25" is running
Aug 22 08:16:02.758: INFO: Pod "my-hostname-basic-13876003-c4b5-11e9-80b5-1edf08853c25-4fcvb" is running (conditions: [])
Aug 22 08:16:02.758: INFO: Trying to dial the pod
Aug 22 08:16:07.766: INFO: Controller my-hostname-basic-13876003-c4b5-11e9-80b5-1edf08853c25: Got expected result from replica 1 [my-hostname-basic-13876003-c4b5-11e9-80b5-1edf08853c25-4fcvb]: "my-hostname-basic-13876003-c4b5-11e9-80b5-1edf08853c25-4fcvb", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:16:07.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-8653" for this suite.
Aug 22 08:16:13.780: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:16:13.861: INFO: namespace replicaset-8653 deletion completed in 6.090644475s

• [SLOW TEST:13.286 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:16:13.861: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-1932
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:16:17.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1932" for this suite.
Aug 22 08:16:39.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:16:39.123: INFO: namespace replication-controller-1932 deletion completed in 22.077366531s

• [SLOW TEST:25.261 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:16:39.124: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-9860
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:69
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Registering the sample API server.
Aug 22 08:16:39.865: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Aug 22 08:16:41.908: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702058599, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702058599, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702058599, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702058599, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 08:16:44.738: INFO: Waited 819.329086ms for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:60
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:16:46.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-9860" for this suite.
Aug 22 08:16:52.040: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:16:52.114: INFO: namespace aggregator-9860 deletion completed in 6.081590545s

• [SLOW TEST:12.990 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:16:52.115: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1205
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-324553df-c4b5-11e9-80b5-1edf08853c25
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-324553df-c4b5-11e9-80b5-1edf08853c25
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:16:56.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1205" for this suite.
Aug 22 08:17:18.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:17:18.426: INFO: namespace configmap-1205 deletion completed in 22.075603788s

• [SLOW TEST:26.311 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:17:18.427: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9908
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0822 08:17:28.630288      14 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 22 08:17:28.630: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:17:28.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9908" for this suite.
Aug 22 08:17:34.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:17:34.732: INFO: namespace gc-9908 deletion completed in 6.099430913s

• [SLOW TEST:16.306 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:17:34.733: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-7959
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:17:34.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7959" for this suite.
Aug 22 08:17:40.878: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:17:40.963: INFO: namespace services-7959 deletion completed in 6.093607259s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:6.231 seconds]
[sig-network] Services
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:17:40.963: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3947
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Aug 22 08:17:41.105: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4f5a91b8-c4b5-11e9-80b5-1edf08853c25" in namespace "downward-api-3947" to be "success or failure"
Aug 22 08:17:41.109: INFO: Pod "downwardapi-volume-4f5a91b8-c4b5-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 4.225859ms
Aug 22 08:17:43.112: INFO: Pod "downwardapi-volume-4f5a91b8-c4b5-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007808953s
Aug 22 08:17:45.116: INFO: Pod "downwardapi-volume-4f5a91b8-c4b5-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011092833s
STEP: Saw pod success
Aug 22 08:17:45.116: INFO: Pod "downwardapi-volume-4f5a91b8-c4b5-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:17:45.118: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod downwardapi-volume-4f5a91b8-c4b5-11e9-80b5-1edf08853c25 container client-container: <nil>
STEP: delete the pod
Aug 22 08:17:45.134: INFO: Waiting for pod downwardapi-volume-4f5a91b8-c4b5-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:17:45.137: INFO: Pod downwardapi-volume-4f5a91b8-c4b5-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:17:45.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3947" for this suite.
Aug 22 08:17:51.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:17:51.223: INFO: namespace downward-api-3947 deletion completed in 6.082082872s

• [SLOW TEST:10.259 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:17:51.223: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-289
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override all
Aug 22 08:17:51.363: INFO: Waiting up to 5m0s for pod "client-containers-5577ff05-c4b5-11e9-80b5-1edf08853c25" in namespace "containers-289" to be "success or failure"
Aug 22 08:17:51.366: INFO: Pod "client-containers-5577ff05-c4b5-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 3.603057ms
Aug 22 08:17:53.370: INFO: Pod "client-containers-5577ff05-c4b5-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007473272s
Aug 22 08:17:55.374: INFO: Pod "client-containers-5577ff05-c4b5-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011122434s
STEP: Saw pod success
Aug 22 08:17:55.374: INFO: Pod "client-containers-5577ff05-c4b5-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:17:55.377: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod client-containers-5577ff05-c4b5-11e9-80b5-1edf08853c25 container test-container: <nil>
STEP: delete the pod
Aug 22 08:17:55.394: INFO: Waiting for pod client-containers-5577ff05-c4b5-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:17:55.397: INFO: Pod client-containers-5577ff05-c4b5-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:17:55.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-289" for this suite.
Aug 22 08:18:01.412: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:18:01.491: INFO: namespace containers-289 deletion completed in 6.08890797s

• [SLOW TEST:10.268 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:18:01.491: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8523
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-5b96d936-c4b5-11e9-80b5-1edf08853c25
STEP: Creating a pod to test consume configMaps
Aug 22 08:18:01.636: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5b97632a-c4b5-11e9-80b5-1edf08853c25" in namespace "projected-8523" to be "success or failure"
Aug 22 08:18:01.640: INFO: Pod "pod-projected-configmaps-5b97632a-c4b5-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 4.273032ms
Aug 22 08:18:03.643: INFO: Pod "pod-projected-configmaps-5b97632a-c4b5-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007437302s
STEP: Saw pod success
Aug 22 08:18:03.643: INFO: Pod "pod-projected-configmaps-5b97632a-c4b5-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:18:03.645: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-projected-configmaps-5b97632a-c4b5-11e9-80b5-1edf08853c25 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 22 08:18:03.660: INFO: Waiting for pod pod-projected-configmaps-5b97632a-c4b5-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:18:03.662: INFO: Pod pod-projected-configmaps-5b97632a-c4b5-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:18:03.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8523" for this suite.
Aug 22 08:18:09.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:18:09.781: INFO: namespace projected-8523 deletion completed in 6.115315501s

• [SLOW TEST:8.290 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:18:09.781: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-4440
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Aug 22 08:18:13.971: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 22 08:18:13.974: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 22 08:18:15.974: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 22 08:18:15.977: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 22 08:18:17.974: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 22 08:18:17.979: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 22 08:18:19.974: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 22 08:18:19.977: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 22 08:18:21.974: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 22 08:18:21.977: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 22 08:18:23.974: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 22 08:18:23.978: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 22 08:18:25.974: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 22 08:18:25.977: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 22 08:18:27.974: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 22 08:18:27.978: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 22 08:18:29.974: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 22 08:18:29.977: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 22 08:18:31.974: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 22 08:18:31.977: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 22 08:18:33.974: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 22 08:18:33.977: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 22 08:18:35.974: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 22 08:18:35.977: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 22 08:18:37.974: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 22 08:18:37.977: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 22 08:18:39.974: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 22 08:18:39.977: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:18:39.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4440" for this suite.
Aug 22 08:19:02.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:19:02.149: INFO: namespace container-lifecycle-hook-4440 deletion completed in 22.15904787s

• [SLOW TEST:52.367 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:19:02.149: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7143
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-7fbf909a-c4b5-11e9-80b5-1edf08853c25
STEP: Creating configMap with name cm-test-opt-upd-7fbf90f6-c4b5-11e9-80b5-1edf08853c25
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-7fbf909a-c4b5-11e9-80b5-1edf08853c25
STEP: Updating configmap cm-test-opt-upd-7fbf90f6-c4b5-11e9-80b5-1edf08853c25
STEP: Creating configMap with name cm-test-opt-create-7fbf9115-c4b5-11e9-80b5-1edf08853c25
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:19:06.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7143" for this suite.
Aug 22 08:19:28.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:19:28.459: INFO: namespace projected-7143 deletion completed in 22.078324785s

• [SLOW TEST:26.309 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:19:28.459: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2001
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1318
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 22 08:19:28.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-2001'
Aug 22 08:19:28.824: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 22 08:19:28.824: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1324
Aug 22 08:19:30.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 delete deployment e2e-test-nginx-deployment --namespace=kubectl-2001'
Aug 22 08:19:30.905: INFO: stderr: ""
Aug 22 08:19:30.905: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:19:30.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2001" for this suite.
Aug 22 08:19:52.921: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:19:52.988: INFO: namespace kubectl-2001 deletion completed in 22.07944644s

• [SLOW TEST:24.529 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:19:52.989: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1178
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating api versions
Aug 22 08:19:53.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 api-versions'
Aug 22 08:19:53.191: INFO: stderr: ""
Aug 22 08:19:53.191: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:19:53.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1178" for this suite.
Aug 22 08:19:59.208: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:19:59.329: INFO: namespace kubectl-1178 deletion completed in 6.133723491s

• [SLOW TEST:6.340 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:19:59.329: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4093
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Aug 22 08:20:02.012: INFO: Successfully updated pod "annotationupdatea1d47e13-c4b5-11e9-80b5-1edf08853c25"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:20:06.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4093" for this suite.
Aug 22 08:20:22.047: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:20:22.121: INFO: namespace projected-4093 deletion completed in 16.082451762s

• [SLOW TEST:22.792 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:20:22.121: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-7332
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override command
Aug 22 08:20:22.312: INFO: Waiting up to 5m0s for pod "client-containers-af70fd16-c4b5-11e9-80b5-1edf08853c25" in namespace "containers-7332" to be "success or failure"
Aug 22 08:20:22.315: INFO: Pod "client-containers-af70fd16-c4b5-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 3.556767ms
Aug 22 08:20:24.318: INFO: Pod "client-containers-af70fd16-c4b5-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006541232s
STEP: Saw pod success
Aug 22 08:20:24.319: INFO: Pod "client-containers-af70fd16-c4b5-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:20:24.321: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod client-containers-af70fd16-c4b5-11e9-80b5-1edf08853c25 container test-container: <nil>
STEP: delete the pod
Aug 22 08:20:24.338: INFO: Waiting for pod client-containers-af70fd16-c4b5-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:20:24.342: INFO: Pod client-containers-af70fd16-c4b5-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:20:24.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7332" for this suite.
Aug 22 08:20:30.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:20:30.427: INFO: namespace containers-7332 deletion completed in 6.08190638s

• [SLOW TEST:8.306 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:20:30.427: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2839
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1414
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 22 08:20:30.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-2839'
Aug 22 08:20:30.633: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 22 08:20:30.633: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Aug 22 08:20:30.650: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Aug 22 08:20:30.657: INFO: scanned /root for discovery docs: <nil>
Aug 22 08:20:30.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-2839'
Aug 22 08:20:46.457: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Aug 22 08:20:46.457: INFO: stdout: "Created e2e-test-nginx-rc-e375e62a236039bafdf55352a131167c\nScaling up e2e-test-nginx-rc-e375e62a236039bafdf55352a131167c from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-e375e62a236039bafdf55352a131167c up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-e375e62a236039bafdf55352a131167c to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Aug 22 08:20:46.457: INFO: stdout: "Created e2e-test-nginx-rc-e375e62a236039bafdf55352a131167c\nScaling up e2e-test-nginx-rc-e375e62a236039bafdf55352a131167c from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-e375e62a236039bafdf55352a131167c up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-e375e62a236039bafdf55352a131167c to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Aug 22 08:20:46.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-2839'
Aug 22 08:20:46.535: INFO: stderr: ""
Aug 22 08:20:46.535: INFO: stdout: "e2e-test-nginx-rc-e375e62a236039bafdf55352a131167c-55twq "
Aug 22 08:20:46.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pods e2e-test-nginx-rc-e375e62a236039bafdf55352a131167c-55twq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2839'
Aug 22 08:20:46.612: INFO: stderr: ""
Aug 22 08:20:46.612: INFO: stdout: "true"
Aug 22 08:20:46.612: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pods e2e-test-nginx-rc-e375e62a236039bafdf55352a131167c-55twq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2839'
Aug 22 08:20:46.684: INFO: stderr: ""
Aug 22 08:20:46.684: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Aug 22 08:20:46.684: INFO: e2e-test-nginx-rc-e375e62a236039bafdf55352a131167c-55twq is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1420
Aug 22 08:20:46.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 delete rc e2e-test-nginx-rc --namespace=kubectl-2839'
Aug 22 08:20:46.762: INFO: stderr: ""
Aug 22 08:20:46.762: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:20:46.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2839" for this suite.
Aug 22 08:21:08.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:21:08.861: INFO: namespace kubectl-2839 deletion completed in 22.090410244s

• [SLOW TEST:38.433 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:21:08.861: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-7192
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Aug 22 08:21:09.003: INFO: (0) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 6.469635ms)
Aug 22 08:21:09.008: INFO: (1) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.318783ms)
Aug 22 08:21:09.011: INFO: (2) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.463023ms)
Aug 22 08:21:09.017: INFO: (3) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 5.900074ms)
Aug 22 08:21:09.022: INFO: (4) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 5.112872ms)
Aug 22 08:21:09.027: INFO: (5) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.640461ms)
Aug 22 08:21:09.032: INFO: (6) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 5.33697ms)
Aug 22 08:21:09.038: INFO: (7) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 5.854375ms)
Aug 22 08:21:09.044: INFO: (8) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 6.211758ms)
Aug 22 08:21:09.050: INFO: (9) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 5.24102ms)
Aug 22 08:21:09.055: INFO: (10) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 5.248878ms)
Aug 22 08:21:09.059: INFO: (11) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.15373ms)
Aug 22 08:21:09.063: INFO: (12) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.473783ms)
Aug 22 08:21:09.067: INFO: (13) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.740399ms)
Aug 22 08:21:09.071: INFO: (14) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.444524ms)
Aug 22 08:21:09.074: INFO: (15) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.99629ms)
Aug 22 08:21:09.077: INFO: (16) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.080817ms)
Aug 22 08:21:09.080: INFO: (17) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.237535ms)
Aug 22 08:21:09.083: INFO: (18) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.991846ms)
Aug 22 08:21:09.087: INFO: (19) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.488585ms)
[AfterEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:21:09.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-7192" for this suite.
Aug 22 08:21:15.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:21:15.169: INFO: namespace proxy-7192 deletion completed in 6.079228361s

• [SLOW TEST:6.308 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:21:15.170: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5671
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-cf07d7a4-c4b5-11e9-80b5-1edf08853c25
STEP: Creating a pod to test consume configMaps
Aug 22 08:21:15.317: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-cf086537-c4b5-11e9-80b5-1edf08853c25" in namespace "projected-5671" to be "success or failure"
Aug 22 08:21:15.326: INFO: Pod "pod-projected-configmaps-cf086537-c4b5-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 7.060967ms
Aug 22 08:21:17.329: INFO: Pod "pod-projected-configmaps-cf086537-c4b5-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010052342s
STEP: Saw pod success
Aug 22 08:21:17.329: INFO: Pod "pod-projected-configmaps-cf086537-c4b5-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:21:17.331: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-projected-configmaps-cf086537-c4b5-11e9-80b5-1edf08853c25 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 22 08:21:17.346: INFO: Waiting for pod pod-projected-configmaps-cf086537-c4b5-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:21:17.348: INFO: Pod pod-projected-configmaps-cf086537-c4b5-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:21:17.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5671" for this suite.
Aug 22 08:21:23.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:21:23.434: INFO: namespace projected-5671 deletion completed in 6.082253144s

• [SLOW TEST:8.264 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:21:23.434: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2698
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Aug 22 08:21:23.573: INFO: Waiting up to 5m0s for pod "pod-d3f4aad8-c4b5-11e9-80b5-1edf08853c25" in namespace "emptydir-2698" to be "success or failure"
Aug 22 08:21:23.577: INFO: Pod "pod-d3f4aad8-c4b5-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 3.863003ms
Aug 22 08:21:25.580: INFO: Pod "pod-d3f4aad8-c4b5-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007464225s
STEP: Saw pod success
Aug 22 08:21:25.580: INFO: Pod "pod-d3f4aad8-c4b5-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:21:25.582: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-d3f4aad8-c4b5-11e9-80b5-1edf08853c25 container test-container: <nil>
STEP: delete the pod
Aug 22 08:21:25.598: INFO: Waiting for pod pod-d3f4aad8-c4b5-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:21:25.600: INFO: Pod pod-d3f4aad8-c4b5-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:21:25.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2698" for this suite.
Aug 22 08:21:31.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:21:31.695: INFO: namespace emptydir-2698 deletion completed in 6.091303111s

• [SLOW TEST:8.261 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:21:31.695: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6008
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-d8e24026-c4b5-11e9-80b5-1edf08853c25
STEP: Creating a pod to test consume configMaps
Aug 22 08:21:31.844: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d8e2d0dc-c4b5-11e9-80b5-1edf08853c25" in namespace "projected-6008" to be "success or failure"
Aug 22 08:21:31.848: INFO: Pod "pod-projected-configmaps-d8e2d0dc-c4b5-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 3.881603ms
Aug 22 08:21:33.851: INFO: Pod "pod-projected-configmaps-d8e2d0dc-c4b5-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0070155s
STEP: Saw pod success
Aug 22 08:21:33.851: INFO: Pod "pod-projected-configmaps-d8e2d0dc-c4b5-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:21:33.853: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-projected-configmaps-d8e2d0dc-c4b5-11e9-80b5-1edf08853c25 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 22 08:21:33.868: INFO: Waiting for pod pod-projected-configmaps-d8e2d0dc-c4b5-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:21:33.871: INFO: Pod pod-projected-configmaps-d8e2d0dc-c4b5-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:21:33.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6008" for this suite.
Aug 22 08:21:39.882: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:21:39.952: INFO: namespace projected-6008 deletion completed in 6.0779749s

• [SLOW TEST:8.257 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:21:39.953: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2077
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on tmpfs
Aug 22 08:21:40.093: INFO: Waiting up to 5m0s for pod "pod-ddcd54cb-c4b5-11e9-80b5-1edf08853c25" in namespace "emptydir-2077" to be "success or failure"
Aug 22 08:21:40.104: INFO: Pod "pod-ddcd54cb-c4b5-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 11.253643ms
Aug 22 08:21:42.107: INFO: Pod "pod-ddcd54cb-c4b5-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014669532s
STEP: Saw pod success
Aug 22 08:21:42.107: INFO: Pod "pod-ddcd54cb-c4b5-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:21:42.109: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-ddcd54cb-c4b5-11e9-80b5-1edf08853c25 container test-container: <nil>
STEP: delete the pod
Aug 22 08:21:42.126: INFO: Waiting for pod pod-ddcd54cb-c4b5-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:21:42.128: INFO: Pod pod-ddcd54cb-c4b5-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:21:42.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2077" for this suite.
Aug 22 08:21:48.140: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:21:48.216: INFO: namespace emptydir-2077 deletion completed in 6.084362244s

• [SLOW TEST:8.264 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:21:48.217: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-6779
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Aug 22 08:21:48.356: INFO: (0) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.293805ms)
Aug 22 08:21:48.359: INFO: (1) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.99867ms)
Aug 22 08:21:48.363: INFO: (2) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.838467ms)
Aug 22 08:21:48.366: INFO: (3) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.667242ms)
Aug 22 08:21:48.374: INFO: (4) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 7.658389ms)
Aug 22 08:21:48.377: INFO: (5) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.935774ms)
Aug 22 08:21:48.380: INFO: (6) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.838738ms)
Aug 22 08:21:48.383: INFO: (7) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.037719ms)
Aug 22 08:21:48.386: INFO: (8) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.021032ms)
Aug 22 08:21:48.389: INFO: (9) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.937822ms)
Aug 22 08:21:48.392: INFO: (10) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.94992ms)
Aug 22 08:21:48.397: INFO: (11) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 5.012359ms)
Aug 22 08:21:48.403: INFO: (12) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 5.603705ms)
Aug 22 08:21:48.406: INFO: (13) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.919901ms)
Aug 22 08:21:48.409: INFO: (14) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.100566ms)
Aug 22 08:21:48.417: INFO: (15) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.584423ms)
Aug 22 08:21:48.428: INFO: (16) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 10.848944ms)
Aug 22 08:21:48.438: INFO: (17) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 9.452121ms)
Aug 22 08:21:48.454: INFO: (18) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 15.857104ms)
Aug 22 08:21:48.463: INFO: (19) /api/v1/nodes/ip-10-90-32-22.eu-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 9.367114ms)
[AfterEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:21:48.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6779" for this suite.
Aug 22 08:21:54.488: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:21:54.563: INFO: namespace proxy-6779 deletion completed in 6.0915099s

• [SLOW TEST:6.347 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:21:54.564: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9323
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-e682a465-c4b5-11e9-80b5-1edf08853c25
STEP: Creating a pod to test consume configMaps
Aug 22 08:21:54.706: INFO: Waiting up to 5m0s for pod "pod-configmaps-e6832e79-c4b5-11e9-80b5-1edf08853c25" in namespace "configmap-9323" to be "success or failure"
Aug 22 08:21:54.709: INFO: Pod "pod-configmaps-e6832e79-c4b5-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 3.924753ms
Aug 22 08:21:56.713: INFO: Pod "pod-configmaps-e6832e79-c4b5-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007034649s
STEP: Saw pod success
Aug 22 08:21:56.713: INFO: Pod "pod-configmaps-e6832e79-c4b5-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:21:56.715: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-configmaps-e6832e79-c4b5-11e9-80b5-1edf08853c25 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 22 08:21:56.738: INFO: Waiting for pod pod-configmaps-e6832e79-c4b5-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:21:56.740: INFO: Pod pod-configmaps-e6832e79-c4b5-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:21:56.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9323" for this suite.
Aug 22 08:22:02.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:22:02.861: INFO: namespace configmap-9323 deletion completed in 6.117529382s

• [SLOW TEST:8.297 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:22:02.861: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8229
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Aug 22 08:22:03.000: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Aug 22 08:22:10.043: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:22:10.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8229" for this suite.
Aug 22 08:22:16.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:22:16.134: INFO: namespace pods-8229 deletion completed in 6.08047378s

• [SLOW TEST:13.273 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:22:16.134: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-691
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Aug 22 08:22:21.299: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:22:21.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-691" for this suite.
Aug 22 08:22:43.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:22:43.473: INFO: namespace replicaset-691 deletion completed in 22.154376973s

• [SLOW TEST:27.339 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:22:43.474: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4358
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-03ae8f2c-c4b6-11e9-80b5-1edf08853c25
STEP: Creating a pod to test consume configMaps
Aug 22 08:22:43.648: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-03af1eb5-c4b6-11e9-80b5-1edf08853c25" in namespace "projected-4358" to be "success or failure"
Aug 22 08:22:43.654: INFO: Pod "pod-projected-configmaps-03af1eb5-c4b6-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 6.14854ms
Aug 22 08:22:45.657: INFO: Pod "pod-projected-configmaps-03af1eb5-c4b6-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009048037s
Aug 22 08:22:47.661: INFO: Pod "pod-projected-configmaps-03af1eb5-c4b6-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013524917s
STEP: Saw pod success
Aug 22 08:22:47.661: INFO: Pod "pod-projected-configmaps-03af1eb5-c4b6-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:22:47.664: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-projected-configmaps-03af1eb5-c4b6-11e9-80b5-1edf08853c25 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 22 08:22:47.682: INFO: Waiting for pod pod-projected-configmaps-03af1eb5-c4b6-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:22:47.683: INFO: Pod pod-projected-configmaps-03af1eb5-c4b6-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:22:47.683: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4358" for this suite.
Aug 22 08:22:53.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:22:53.767: INFO: namespace projected-4358 deletion completed in 6.080292489s

• [SLOW TEST:10.293 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:22:53.767: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8539
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Aug 22 08:22:53.910: INFO: Waiting up to 5m0s for pod "downward-api-09cd00cd-c4b6-11e9-80b5-1edf08853c25" in namespace "downward-api-8539" to be "success or failure"
Aug 22 08:22:53.923: INFO: Pod "downward-api-09cd00cd-c4b6-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 12.911251ms
Aug 22 08:22:55.927: INFO: Pod "downward-api-09cd00cd-c4b6-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016340693s
STEP: Saw pod success
Aug 22 08:22:55.927: INFO: Pod "downward-api-09cd00cd-c4b6-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:22:55.929: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod downward-api-09cd00cd-c4b6-11e9-80b5-1edf08853c25 container dapi-container: <nil>
STEP: delete the pod
Aug 22 08:22:55.944: INFO: Waiting for pod downward-api-09cd00cd-c4b6-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:22:55.947: INFO: Pod downward-api-09cd00cd-c4b6-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:22:55.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8539" for this suite.
Aug 22 08:23:01.962: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:23:02.042: INFO: namespace downward-api-8539 deletion completed in 6.09191698s

• [SLOW TEST:8.275 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:23:02.042: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1481
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1455
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 22 08:23:02.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=kubectl-1481'
Aug 22 08:23:02.264: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 22 08:23:02.264: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1460
Aug 22 08:23:04.283: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 delete deployment e2e-test-nginx-deployment --namespace=kubectl-1481'
Aug 22 08:23:04.356: INFO: stderr: ""
Aug 22 08:23:04.356: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:23:04.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1481" for this suite.
Aug 22 08:23:10.373: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:23:10.455: INFO: namespace kubectl-1481 deletion completed in 6.093403762s

• [SLOW TEST:8.413 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:23:10.456: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1700
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0822 08:23:20.660724      14 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 22 08:23:20.660: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:23:20.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1700" for this suite.
Aug 22 08:23:26.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:23:26.743: INFO: namespace gc-1700 deletion completed in 6.078907959s

• [SLOW TEST:16.287 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:23:26.743: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8031
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-8031
Aug 22 08:23:30.940: INFO: Started pod liveness-http in namespace container-probe-8031
STEP: checking the pod's current state and verifying that restartCount is present
Aug 22 08:23:30.942: INFO: Initial restart count of pod liveness-http is 0
Aug 22 08:23:44.966: INFO: Restart count of pod container-probe-8031/liveness-http is now 1 (14.024080638s elapsed)
Aug 22 08:24:04.998: INFO: Restart count of pod container-probe-8031/liveness-http is now 2 (34.055161555s elapsed)
Aug 22 08:24:25.029: INFO: Restart count of pod container-probe-8031/liveness-http is now 3 (54.086782363s elapsed)
Aug 22 08:24:45.062: INFO: Restart count of pod container-probe-8031/liveness-http is now 4 (1m14.11961207s elapsed)
Aug 22 08:25:45.159: INFO: Restart count of pod container-probe-8031/liveness-http is now 5 (2m14.216850647s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:25:45.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8031" for this suite.
Aug 22 08:25:51.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:25:51.257: INFO: namespace container-probe-8031 deletion completed in 6.079811863s

• [SLOW TEST:144.514 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:25:51.257: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-9891
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-9891.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-9891.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9891.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-9891.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-9891.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9891.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 22 08:25:53.441: INFO: DNS probes using dns-9891/dns-test-73980bc9-c4b6-11e9-80b5-1edf08853c25 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:25:53.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9891" for this suite.
Aug 22 08:25:59.464: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:25:59.531: INFO: namespace dns-9891 deletion completed in 6.075388778s

• [SLOW TEST:8.274 seconds]
[sig-network] DNS
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:25:59.532: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1883
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-78862e84-c4b6-11e9-80b5-1edf08853c25
STEP: Creating a pod to test consume secrets
Aug 22 08:25:59.676: INFO: Waiting up to 5m0s for pod "pod-secrets-7886c11b-c4b6-11e9-80b5-1edf08853c25" in namespace "secrets-1883" to be "success or failure"
Aug 22 08:25:59.685: INFO: Pod "pod-secrets-7886c11b-c4b6-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 8.7162ms
Aug 22 08:26:01.688: INFO: Pod "pod-secrets-7886c11b-c4b6-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011918398s
STEP: Saw pod success
Aug 22 08:26:01.688: INFO: Pod "pod-secrets-7886c11b-c4b6-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:26:01.690: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-secrets-7886c11b-c4b6-11e9-80b5-1edf08853c25 container secret-volume-test: <nil>
STEP: delete the pod
Aug 22 08:26:01.709: INFO: Waiting for pod pod-secrets-7886c11b-c4b6-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:26:01.711: INFO: Pod pod-secrets-7886c11b-c4b6-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:26:01.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1883" for this suite.
Aug 22 08:26:07.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:26:07.799: INFO: namespace secrets-1883 deletion completed in 6.084546572s

• [SLOW TEST:8.267 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:26:07.800: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-6505
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Aug 22 08:26:07.936: INFO: Creating deployment "nginx-deployment"
Aug 22 08:26:07.942: INFO: Waiting for observed generation 1
Aug 22 08:26:09.951: INFO: Waiting for all required pods to come up
Aug 22 08:26:09.958: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Aug 22 08:26:13.974: INFO: Waiting for deployment "nginx-deployment" to complete
Aug 22 08:26:13.978: INFO: Updating deployment "nginx-deployment" with a non-existent image
Aug 22 08:26:13.986: INFO: Updating deployment nginx-deployment
Aug 22 08:26:13.986: INFO: Waiting for observed generation 2
Aug 22 08:26:16.004: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Aug 22 08:26:16.007: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Aug 22 08:26:16.009: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Aug 22 08:26:16.015: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Aug 22 08:26:16.015: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Aug 22 08:26:16.017: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Aug 22 08:26:16.021: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Aug 22 08:26:16.021: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Aug 22 08:26:16.029: INFO: Updating deployment nginx-deployment
Aug 22 08:26:16.029: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Aug 22 08:26:16.053: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Aug 22 08:26:18.093: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Aug 22 08:26:18.100: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-6505,SelfLink:/apis/apps/v1/namespaces/deployment-6505/deployments/nginx-deployment,UID:7d744db8-c4b6-11e9-92bb-0afbab63fbd8,ResourceVersion:14705210,Generation:3,CreationTimestamp:2019-08-22 08:26:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-08-22 08:26:16 +0000 UTC 2019-08-22 08:26:16 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-08-22 08:26:16 +0000 UTC 2019-08-22 08:26:07 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-5f9595f595" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Aug 22 08:26:18.103: INFO: New ReplicaSet "nginx-deployment-5f9595f595" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595,GenerateName:,Namespace:deployment-6505,SelfLink:/apis/apps/v1/namespaces/deployment-6505/replicasets/nginx-deployment-5f9595f595,UID:810f4dcc-c4b6-11e9-92bb-0afbab63fbd8,ResourceVersion:14705207,Generation:3,CreationTimestamp:2019-08-22 08:26:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 7d744db8-c4b6-11e9-92bb-0afbab63fbd8 0xc0037673a7 0xc0037673a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 22 08:26:18.103: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Aug 22 08:26:18.103: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8,GenerateName:,Namespace:deployment-6505,SelfLink:/apis/apps/v1/namespaces/deployment-6505/replicasets/nginx-deployment-6f478d8d8,UID:7d751da0-c4b6-11e9-92bb-0afbab63fbd8,ResourceVersion:14705194,Generation:3,CreationTimestamp:2019-08-22 08:26:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 7d744db8-c4b6-11e9-92bb-0afbab63fbd8 0xc003767477 0xc003767478}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Aug 22 08:26:18.111: INFO: Pod "nginx-deployment-5f9595f595-262kv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-262kv,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-6505,SelfLink:/api/v1/namespaces/deployment-6505/pods/nginx-deployment-5f9595f595-262kv,UID:8255de13-c4b6-11e9-92bb-0afbab63fbd8,ResourceVersion:14705259,Generation:0,CreationTimestamp:2019-08-22 08:26:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 810f4dcc-c4b6-11e9-92bb-0afbab63fbd8 0xc003767d67 0xc003767d68}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bbbb6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bbbb6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-bbbb6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-23.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003767dd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003767df0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.23,PodIP:,StartTime:2019-08-22 08:26:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 22 08:26:18.111: INFO: Pod "nginx-deployment-5f9595f595-4tfq5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-4tfq5,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-6505,SelfLink:/api/v1/namespaces/deployment-6505/pods/nginx-deployment-5f9595f595-4tfq5,UID:824f2957-c4b6-11e9-92bb-0afbab63fbd8,ResourceVersion:14705190,Generation:0,CreationTimestamp:2019-08-22 08:26:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 810f4dcc-c4b6-11e9-92bb-0afbab63fbd8 0xc003767ed7 0xc003767ed8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bbbb6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bbbb6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-bbbb6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-23.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003767f40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003767f60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.23,PodIP:,StartTime:2019-08-22 08:26:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 22 08:26:18.112: INFO: Pod "nginx-deployment-5f9595f595-7d925" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-7d925,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-6505,SelfLink:/api/v1/namespaces/deployment-6505/pods/nginx-deployment-5f9595f595-7d925,UID:824b5a7d-c4b6-11e9-92bb-0afbab63fbd8,ResourceVersion:14705185,Generation:0,CreationTimestamp:2019-08-22 08:26:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 810f4dcc-c4b6-11e9-92bb-0afbab63fbd8 0xc003442037 0xc003442038}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bbbb6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bbbb6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-bbbb6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-22.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0034420a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0034420c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.22,PodIP:,StartTime:2019-08-22 08:26:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 22 08:26:18.112: INFO: Pod "nginx-deployment-5f9595f595-b899m" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-b899m,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-6505,SelfLink:/api/v1/namespaces/deployment-6505/pods/nginx-deployment-5f9595f595-b899m,UID:8120e44d-c4b6-11e9-92bb-0afbab63fbd8,ResourceVersion:14705283,Generation:0,CreationTimestamp:2019-08-22 08:26:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 810f4dcc-c4b6-11e9-92bb-0afbab63fbd8 0xc003442197 0xc003442198}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bbbb6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bbbb6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-bbbb6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-24.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003442200} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003442220}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:14 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.24,PodIP:10.200.40.106,StartTime:2019-08-22 08:26:14 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 22 08:26:18.112: INFO: Pod "nginx-deployment-5f9595f595-fc5vx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-fc5vx,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-6505,SelfLink:/api/v1/namespaces/deployment-6505/pods/nginx-deployment-5f9595f595-fc5vx,UID:8254356a-c4b6-11e9-92bb-0afbab63fbd8,ResourceVersion:14705231,Generation:0,CreationTimestamp:2019-08-22 08:26:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 810f4dcc-c4b6-11e9-92bb-0afbab63fbd8 0xc003442317 0xc003442318}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bbbb6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bbbb6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-bbbb6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-22.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003442380} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0034423a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.22,PodIP:,StartTime:2019-08-22 08:26:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 22 08:26:18.112: INFO: Pod "nginx-deployment-5f9595f595-fzd75" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-fzd75,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-6505,SelfLink:/api/v1/namespaces/deployment-6505/pods/nginx-deployment-5f9595f595-fzd75,UID:824ebd48-c4b6-11e9-92bb-0afbab63fbd8,ResourceVersion:14705204,Generation:0,CreationTimestamp:2019-08-22 08:26:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 810f4dcc-c4b6-11e9-92bb-0afbab63fbd8 0xc003442477 0xc003442478}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bbbb6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bbbb6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-bbbb6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-23.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0034424e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003442500}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.23,PodIP:,StartTime:2019-08-22 08:26:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 22 08:26:18.112: INFO: Pod "nginx-deployment-5f9595f595-g64cb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-g64cb,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-6505,SelfLink:/api/v1/namespaces/deployment-6505/pods/nginx-deployment-5f9595f595-g64cb,UID:81120801-c4b6-11e9-92bb-0afbab63fbd8,ResourceVersion:14705125,Generation:0,CreationTimestamp:2019-08-22 08:26:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 810f4dcc-c4b6-11e9-92bb-0afbab63fbd8 0xc0034425d7 0xc0034425d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bbbb6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bbbb6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-bbbb6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-23.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003442640} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003442660}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:14 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.23,PodIP:10.200.87.55,StartTime:2019-08-22 08:26:14 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 22 08:26:18.113: INFO: Pod "nginx-deployment-5f9595f595-h5wz5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-h5wz5,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-6505,SelfLink:/api/v1/namespaces/deployment-6505/pods/nginx-deployment-5f9595f595-h5wz5,UID:8110492f-c4b6-11e9-92bb-0afbab63fbd8,ResourceVersion:14705082,Generation:0,CreationTimestamp:2019-08-22 08:26:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 810f4dcc-c4b6-11e9-92bb-0afbab63fbd8 0xc003442757 0xc003442758}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bbbb6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bbbb6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-bbbb6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-24.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0034427c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0034427e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:14 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.24,PodIP:,StartTime:2019-08-22 08:26:14 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 22 08:26:18.113: INFO: Pod "nginx-deployment-5f9595f595-j5w79" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-j5w79,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-6505,SelfLink:/api/v1/namespaces/deployment-6505/pods/nginx-deployment-5f9595f595-j5w79,UID:8255940a-c4b6-11e9-92bb-0afbab63fbd8,ResourceVersion:14705250,Generation:0,CreationTimestamp:2019-08-22 08:26:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 810f4dcc-c4b6-11e9-92bb-0afbab63fbd8 0xc0034428b7 0xc0034428b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bbbb6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bbbb6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-bbbb6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-23.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003442920} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003442940}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.23,PodIP:,StartTime:2019-08-22 08:26:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 22 08:26:18.113: INFO: Pod "nginx-deployment-5f9595f595-jhtt4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-jhtt4,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-6505,SelfLink:/api/v1/namespaces/deployment-6505/pods/nginx-deployment-5f9595f595-jhtt4,UID:8255afef-c4b6-11e9-92bb-0afbab63fbd8,ResourceVersion:14705244,Generation:0,CreationTimestamp:2019-08-22 08:26:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 810f4dcc-c4b6-11e9-92bb-0afbab63fbd8 0xc003442a17 0xc003442a18}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bbbb6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bbbb6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-bbbb6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-24.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003442a80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003442aa0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.24,PodIP:,StartTime:2019-08-22 08:26:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 22 08:26:18.113: INFO: Pod "nginx-deployment-5f9595f595-qctw4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-qctw4,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-6505,SelfLink:/api/v1/namespaces/deployment-6505/pods/nginx-deployment-5f9595f595-qctw4,UID:825c9f0b-c4b6-11e9-92bb-0afbab63fbd8,ResourceVersion:14705257,Generation:0,CreationTimestamp:2019-08-22 08:26:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 810f4dcc-c4b6-11e9-92bb-0afbab63fbd8 0xc003442b77 0xc003442b78}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bbbb6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bbbb6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-bbbb6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-24.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003442be0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003442c00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.24,PodIP:,StartTime:2019-08-22 08:26:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 22 08:26:18.113: INFO: Pod "nginx-deployment-5f9595f595-slr29" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-slr29,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-6505,SelfLink:/api/v1/namespaces/deployment-6505/pods/nginx-deployment-5f9595f595-slr29,UID:812423cb-c4b6-11e9-92bb-0afbab63fbd8,ResourceVersion:14705268,Generation:0,CreationTimestamp:2019-08-22 08:26:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 810f4dcc-c4b6-11e9-92bb-0afbab63fbd8 0xc003442cd7 0xc003442cd8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bbbb6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bbbb6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-bbbb6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-24.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003442d40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003442d60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:14 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.24,PodIP:10.200.40.107,StartTime:2019-08-22 08:26:14 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 22 08:26:18.113: INFO: Pod "nginx-deployment-5f9595f595-wszsm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-wszsm,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-6505,SelfLink:/api/v1/namespaces/deployment-6505/pods/nginx-deployment-5f9595f595-wszsm,UID:8112bf3d-c4b6-11e9-92bb-0afbab63fbd8,ResourceVersion:14705241,Generation:0,CreationTimestamp:2019-08-22 08:26:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 810f4dcc-c4b6-11e9-92bb-0afbab63fbd8 0xc003442e67 0xc003442e68}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bbbb6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bbbb6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-bbbb6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-22.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003442ed0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003442ef0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:14 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.22,PodIP:10.200.47.157,StartTime:2019-08-22 08:26:14 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 22 08:26:18.113: INFO: Pod "nginx-deployment-6f478d8d8-2pgqq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-2pgqq,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6505,SelfLink:/api/v1/namespaces/deployment-6505/pods/nginx-deployment-6f478d8d8-2pgqq,UID:82569d8a-c4b6-11e9-92bb-0afbab63fbd8,ResourceVersion:14705214,Generation:0,CreationTimestamp:2019-08-22 08:26:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 7d751da0-c4b6-11e9-92bb-0afbab63fbd8 0xc003442ff7 0xc003442ff8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bbbb6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bbbb6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bbbb6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-24.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003443060} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003443080}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.24,PodIP:,StartTime:2019-08-22 08:26:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 22 08:26:18.113: INFO: Pod "nginx-deployment-6f478d8d8-2wr9l" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-2wr9l,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6505,SelfLink:/api/v1/namespaces/deployment-6505/pods/nginx-deployment-6f478d8d8-2wr9l,UID:7d79028e-c4b6-11e9-92bb-0afbab63fbd8,ResourceVersion:14705046,Generation:0,CreationTimestamp:2019-08-22 08:26:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 7d751da0-c4b6-11e9-92bb-0afbab63fbd8 0xc003443147 0xc003443148}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bbbb6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bbbb6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bbbb6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-24.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0034431b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0034431d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:08 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:10 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:08 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.24,PodIP:10.200.40.99,StartTime:2019-08-22 08:26:08 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-22 08:26:09 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://a6b9a92540752ce1632110fc3edb7bb6978feea22f36bbf1295c85b4ed630e59}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 22 08:26:18.114: INFO: Pod "nginx-deployment-6f478d8d8-4ggmj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-4ggmj,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6505,SelfLink:/api/v1/namespaces/deployment-6505/pods/nginx-deployment-6f478d8d8-4ggmj,UID:7d7ad981-c4b6-11e9-92bb-0afbab63fbd8,ResourceVersion:14705041,Generation:0,CreationTimestamp:2019-08-22 08:26:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 7d751da0-c4b6-11e9-92bb-0afbab63fbd8 0xc0034432c7 0xc0034432c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bbbb6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bbbb6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bbbb6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-24.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003443330} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003443350}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:08 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:10 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:08 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.24,PodIP:10.200.40.101,StartTime:2019-08-22 08:26:08 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-22 08:26:09 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://894aeaffa766ae1f18a0e4b47bb52d74619514be6ed26a8149deb08f1906cc6d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 22 08:26:18.114: INFO: Pod "nginx-deployment-6f478d8d8-6tdds" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-6tdds,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6505,SelfLink:/api/v1/namespaces/deployment-6505/pods/nginx-deployment-6f478d8d8-6tdds,UID:82560d2a-c4b6-11e9-92bb-0afbab63fbd8,ResourceVersion:14705271,Generation:0,CreationTimestamp:2019-08-22 08:26:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 7d751da0-c4b6-11e9-92bb-0afbab63fbd8 0xc003443437 0xc003443438}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bbbb6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bbbb6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bbbb6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-23.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0034434a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0034434c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.23,PodIP:,StartTime:2019-08-22 08:26:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 22 08:26:18.114: INFO: Pod "nginx-deployment-6f478d8d8-6wmhh" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-6wmhh,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6505,SelfLink:/api/v1/namespaces/deployment-6505/pods/nginx-deployment-6f478d8d8-6wmhh,UID:7d7a90b3-c4b6-11e9-92bb-0afbab63fbd8,ResourceVersion:14705015,Generation:0,CreationTimestamp:2019-08-22 08:26:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 7d751da0-c4b6-11e9-92bb-0afbab63fbd8 0xc003443597 0xc003443598}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bbbb6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bbbb6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bbbb6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-24.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003443630} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003443650}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:08 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:09 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:09 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:08 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.24,PodIP:10.200.40.97,StartTime:2019-08-22 08:26:08 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-22 08:26:09 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://399fb8d156c3c36975427f0e8916a7c392c1533bda175ae47026e0fa38be69cb}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 22 08:26:18.114: INFO: Pod "nginx-deployment-6f478d8d8-7kgqc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-7kgqc,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6505,SelfLink:/api/v1/namespaces/deployment-6505/pods/nginx-deployment-6f478d8d8-7kgqc,UID:7d7c9ddf-c4b6-11e9-92bb-0afbab63fbd8,ResourceVersion:14705022,Generation:0,CreationTimestamp:2019-08-22 08:26:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 7d751da0-c4b6-11e9-92bb-0afbab63fbd8 0xc003443727 0xc003443728}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bbbb6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bbbb6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bbbb6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-22.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003443790} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0034437b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:08 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:10 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:08 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.22,PodIP:10.200.47.156,StartTime:2019-08-22 08:26:08 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-22 08:26:09 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://6798fd0704a003c6bfdfecaa80749073546dbe8778658f3deb569b59a09c5c50}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 22 08:26:18.114: INFO: Pod "nginx-deployment-6f478d8d8-85w69" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-85w69,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6505,SelfLink:/api/v1/namespaces/deployment-6505/pods/nginx-deployment-6f478d8d8-85w69,UID:824e88eb-c4b6-11e9-92bb-0afbab63fbd8,ResourceVersion:14705211,Generation:0,CreationTimestamp:2019-08-22 08:26:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 7d751da0-c4b6-11e9-92bb-0afbab63fbd8 0xc003443887 0xc003443888}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bbbb6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bbbb6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bbbb6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-22.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0034438f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003443910}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.22,PodIP:,StartTime:2019-08-22 08:26:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 22 08:26:18.114: INFO: Pod "nginx-deployment-6f478d8d8-8kh4j" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-8kh4j,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6505,SelfLink:/api/v1/namespaces/deployment-6505/pods/nginx-deployment-6f478d8d8-8kh4j,UID:7d7cdba1-c4b6-11e9-92bb-0afbab63fbd8,ResourceVersion:14705052,Generation:0,CreationTimestamp:2019-08-22 08:26:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 7d751da0-c4b6-11e9-92bb-0afbab63fbd8 0xc0034439d7 0xc0034439d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bbbb6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bbbb6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bbbb6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-24.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003443a40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003443a60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:08 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:10 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:08 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.24,PodIP:10.200.40.104,StartTime:2019-08-22 08:26:08 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-22 08:26:10 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://edcae29c8046b90ae4f12fb4e5d66cd309da5e0947bee8e2bd6c9777eda9c135}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 22 08:26:18.114: INFO: Pod "nginx-deployment-6f478d8d8-f2b7h" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-f2b7h,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6505,SelfLink:/api/v1/namespaces/deployment-6505/pods/nginx-deployment-6f478d8d8-f2b7h,UID:824f1c00-c4b6-11e9-92bb-0afbab63fbd8,ResourceVersion:14705200,Generation:0,CreationTimestamp:2019-08-22 08:26:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 7d751da0-c4b6-11e9-92bb-0afbab63fbd8 0xc003443b47 0xc003443b48}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bbbb6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bbbb6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bbbb6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-22.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003443bb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003443bd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.22,PodIP:,StartTime:2019-08-22 08:26:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 22 08:26:18.114: INFO: Pod "nginx-deployment-6f478d8d8-g984f" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-g984f,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6505,SelfLink:/api/v1/namespaces/deployment-6505/pods/nginx-deployment-6f478d8d8-g984f,UID:7d79603e-c4b6-11e9-92bb-0afbab63fbd8,ResourceVersion:14705036,Generation:0,CreationTimestamp:2019-08-22 08:26:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 7d751da0-c4b6-11e9-92bb-0afbab63fbd8 0xc003443c97 0xc003443c98}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bbbb6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bbbb6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bbbb6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-24.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003443d00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003443d20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:08 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:10 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:08 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.24,PodIP:10.200.40.102,StartTime:2019-08-22 08:26:08 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-22 08:26:09 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://98c22331bb2fe3d5e22c3dee92effd1f608144503fac1e9e8f3749fa251e2063}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 22 08:26:18.114: INFO: Pod "nginx-deployment-6f478d8d8-jw6tx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-jw6tx,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6505,SelfLink:/api/v1/namespaces/deployment-6505/pods/nginx-deployment-6f478d8d8-jw6tx,UID:82481902-c4b6-11e9-92bb-0afbab63fbd8,ResourceVersion:14705156,Generation:0,CreationTimestamp:2019-08-22 08:26:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 7d751da0-c4b6-11e9-92bb-0afbab63fbd8 0xc003443df7 0xc003443df8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bbbb6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bbbb6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bbbb6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-24.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003443e70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003443e90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.24,PodIP:,StartTime:2019-08-22 08:26:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 22 08:26:18.114: INFO: Pod "nginx-deployment-6f478d8d8-m8q8p" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-m8q8p,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6505,SelfLink:/api/v1/namespaces/deployment-6505/pods/nginx-deployment-6f478d8d8-m8q8p,UID:8256656c-c4b6-11e9-92bb-0afbab63fbd8,ResourceVersion:14705221,Generation:0,CreationTimestamp:2019-08-22 08:26:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 7d751da0-c4b6-11e9-92bb-0afbab63fbd8 0xc003443f57 0xc003443f58}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bbbb6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bbbb6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bbbb6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-23.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003443fc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003443fe0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.23,PodIP:,StartTime:2019-08-22 08:26:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 22 08:26:18.114: INFO: Pod "nginx-deployment-6f478d8d8-ngn8k" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-ngn8k,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6505,SelfLink:/api/v1/namespaces/deployment-6505/pods/nginx-deployment-6f478d8d8-ngn8k,UID:824a80bd-c4b6-11e9-92bb-0afbab63fbd8,ResourceVersion:14705189,Generation:0,CreationTimestamp:2019-08-22 08:26:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 7d751da0-c4b6-11e9-92bb-0afbab63fbd8 0xc0024900a7 0xc0024900a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bbbb6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bbbb6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bbbb6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-24.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002490110} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002490130}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.24,PodIP:,StartTime:2019-08-22 08:26:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 22 08:26:18.115: INFO: Pod "nginx-deployment-6f478d8d8-nsw54" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-nsw54,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6505,SelfLink:/api/v1/namespaces/deployment-6505/pods/nginx-deployment-6f478d8d8-nsw54,UID:824f0016-c4b6-11e9-92bb-0afbab63fbd8,ResourceVersion:14705217,Generation:0,CreationTimestamp:2019-08-22 08:26:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 7d751da0-c4b6-11e9-92bb-0afbab63fbd8 0xc0024901f7 0xc0024901f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bbbb6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bbbb6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bbbb6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-22.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002490260} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002490280}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.22,PodIP:,StartTime:2019-08-22 08:26:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 22 08:26:18.115: INFO: Pod "nginx-deployment-6f478d8d8-qqfpq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-qqfpq,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6505,SelfLink:/api/v1/namespaces/deployment-6505/pods/nginx-deployment-6f478d8d8-qqfpq,UID:8249c6d1-c4b6-11e9-92bb-0afbab63fbd8,ResourceVersion:14705205,Generation:0,CreationTimestamp:2019-08-22 08:26:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 7d751da0-c4b6-11e9-92bb-0afbab63fbd8 0xc002490347 0xc002490348}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bbbb6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bbbb6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bbbb6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-24.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024903b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024903d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.24,PodIP:,StartTime:2019-08-22 08:26:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 22 08:26:18.115: INFO: Pod "nginx-deployment-6f478d8d8-rxsq7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-rxsq7,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6505,SelfLink:/api/v1/namespaces/deployment-6505/pods/nginx-deployment-6f478d8d8-rxsq7,UID:82563af4-c4b6-11e9-92bb-0afbab63fbd8,ResourceVersion:14705253,Generation:0,CreationTimestamp:2019-08-22 08:26:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 7d751da0-c4b6-11e9-92bb-0afbab63fbd8 0xc002490497 0xc002490498}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bbbb6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bbbb6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bbbb6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-22.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002490500} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002490520}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.22,PodIP:,StartTime:2019-08-22 08:26:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 22 08:26:18.115: INFO: Pod "nginx-deployment-6f478d8d8-vfxbt" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-vfxbt,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6505,SelfLink:/api/v1/namespaces/deployment-6505/pods/nginx-deployment-6f478d8d8-vfxbt,UID:7d7b1493-c4b6-11e9-92bb-0afbab63fbd8,ResourceVersion:14705018,Generation:0,CreationTimestamp:2019-08-22 08:26:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 7d751da0-c4b6-11e9-92bb-0afbab63fbd8 0xc0024905e7 0xc0024905e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bbbb6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bbbb6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bbbb6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-23.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002490650} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002490670}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:08 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:09 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:09 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:08 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.23,PodIP:10.200.87.54,StartTime:2019-08-22 08:26:08 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-22 08:26:09 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://4e244d6a848d28f020eeb8cea459d44d64364362e30169bebee347c5fc2a4ec3}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 22 08:26:18.115: INFO: Pod "nginx-deployment-6f478d8d8-vvcf5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-vvcf5,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6505,SelfLink:/api/v1/namespaces/deployment-6505/pods/nginx-deployment-6f478d8d8-vvcf5,UID:825536f7-c4b6-11e9-92bb-0afbab63fbd8,ResourceVersion:14705230,Generation:0,CreationTimestamp:2019-08-22 08:26:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 7d751da0-c4b6-11e9-92bb-0afbab63fbd8 0xc002490747 0xc002490748}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bbbb6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bbbb6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bbbb6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-23.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024907b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024907d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.23,PodIP:,StartTime:2019-08-22 08:26:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 22 08:26:18.115: INFO: Pod "nginx-deployment-6f478d8d8-w9mvm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-w9mvm,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6505,SelfLink:/api/v1/namespaces/deployment-6505/pods/nginx-deployment-6f478d8d8-w9mvm,UID:7d77c3b3-c4b6-11e9-92bb-0afbab63fbd8,ResourceVersion:14705049,Generation:0,CreationTimestamp:2019-08-22 08:26:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 7d751da0-c4b6-11e9-92bb-0afbab63fbd8 0xc002490897 0xc002490898}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bbbb6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bbbb6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bbbb6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-24.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002490900} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002490920}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:08 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:10 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:08 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.24,PodIP:10.200.40.103,StartTime:2019-08-22 08:26:08 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-22 08:26:10 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://aaccf9014de0ad934ad8b34cdf8ffbef8fd668c23b4db3ecdf344f54fc0112f6}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 22 08:26:18.115: INFO: Pod "nginx-deployment-6f478d8d8-x7x26" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-x7x26,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-6505,SelfLink:/api/v1/namespaces/deployment-6505/pods/nginx-deployment-6f478d8d8-x7x26,UID:824f0e60-c4b6-11e9-92bb-0afbab63fbd8,ResourceVersion:14705213,Generation:0,CreationTimestamp:2019-08-22 08:26:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 7d751da0-c4b6-11e9-92bb-0afbab63fbd8 0xc0024909f7 0xc0024909f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bbbb6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bbbb6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bbbb6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-23.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002490a60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002490a80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:26:16 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.23,PodIP:,StartTime:2019-08-22 08:26:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:26:18.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6505" for this suite.
Aug 22 08:26:26.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:26:26.232: INFO: namespace deployment-6505 deletion completed in 8.111948699s

• [SLOW TEST:18.432 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:26:26.232: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8455
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:177
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:26:26.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8455" for this suite.
Aug 22 08:26:48.401: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:26:48.486: INFO: namespace pods-8455 deletion completed in 22.096970271s

• [SLOW TEST:22.254 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:26:48.486: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9448
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-95b41ce4-c4b6-11e9-80b5-1edf08853c25
STEP: Creating a pod to test consume configMaps
Aug 22 08:26:48.633: INFO: Waiting up to 5m0s for pod "pod-configmaps-95b4c31e-c4b6-11e9-80b5-1edf08853c25" in namespace "configmap-9448" to be "success or failure"
Aug 22 08:26:48.639: INFO: Pod "pod-configmaps-95b4c31e-c4b6-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 5.41916ms
Aug 22 08:26:50.642: INFO: Pod "pod-configmaps-95b4c31e-c4b6-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009150637s
STEP: Saw pod success
Aug 22 08:26:50.642: INFO: Pod "pod-configmaps-95b4c31e-c4b6-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:26:50.646: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-configmaps-95b4c31e-c4b6-11e9-80b5-1edf08853c25 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 22 08:26:50.666: INFO: Waiting for pod pod-configmaps-95b4c31e-c4b6-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:26:50.670: INFO: Pod pod-configmaps-95b4c31e-c4b6-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:26:50.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9448" for this suite.
Aug 22 08:26:56.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:26:56.753: INFO: namespace configmap-9448 deletion completed in 6.078649114s

• [SLOW TEST:8.267 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:26:56.754: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8191
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Aug 22 08:26:56.898: INFO: Waiting up to 5m0s for pod "pod-9aa207d7-c4b6-11e9-80b5-1edf08853c25" in namespace "emptydir-8191" to be "success or failure"
Aug 22 08:26:56.904: INFO: Pod "pod-9aa207d7-c4b6-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 6.427529ms
Aug 22 08:26:58.906: INFO: Pod "pod-9aa207d7-c4b6-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008752987s
Aug 22 08:27:00.909: INFO: Pod "pod-9aa207d7-c4b6-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011187582s
STEP: Saw pod success
Aug 22 08:27:00.909: INFO: Pod "pod-9aa207d7-c4b6-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:27:00.911: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-9aa207d7-c4b6-11e9-80b5-1edf08853c25 container test-container: <nil>
STEP: delete the pod
Aug 22 08:27:00.927: INFO: Waiting for pod pod-9aa207d7-c4b6-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:27:00.930: INFO: Pod pod-9aa207d7-c4b6-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:27:00.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8191" for this suite.
Aug 22 08:27:06.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:27:07.016: INFO: namespace emptydir-8191 deletion completed in 6.081840793s

• [SLOW TEST:10.262 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:27:07.016: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3910
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Aug 22 08:27:07.157: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a0bf459e-c4b6-11e9-80b5-1edf08853c25" in namespace "downward-api-3910" to be "success or failure"
Aug 22 08:27:07.161: INFO: Pod "downwardapi-volume-a0bf459e-c4b6-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 4.080003ms
Aug 22 08:27:09.164: INFO: Pod "downwardapi-volume-a0bf459e-c4b6-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006559525s
STEP: Saw pod success
Aug 22 08:27:09.164: INFO: Pod "downwardapi-volume-a0bf459e-c4b6-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:27:09.166: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod downwardapi-volume-a0bf459e-c4b6-11e9-80b5-1edf08853c25 container client-container: <nil>
STEP: delete the pod
Aug 22 08:27:09.181: INFO: Waiting for pod downwardapi-volume-a0bf459e-c4b6-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:27:09.183: INFO: Pod downwardapi-volume-a0bf459e-c4b6-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:27:09.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3910" for this suite.
Aug 22 08:27:15.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:27:15.262: INFO: namespace downward-api-3910 deletion completed in 6.075372124s

• [SLOW TEST:8.246 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:27:15.262: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-2662
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:27:19.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2662" for this suite.
Aug 22 08:27:25.421: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:27:25.493: INFO: namespace kubelet-test-2662 deletion completed in 6.080765239s

• [SLOW TEST:10.231 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:27:25.493: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-7397
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Aug 22 08:27:29.674: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 22 08:27:29.677: INFO: Pod pod-with-poststart-http-hook still exists
Aug 22 08:27:31.677: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 22 08:27:31.680: INFO: Pod pod-with-poststart-http-hook still exists
Aug 22 08:27:33.677: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 22 08:27:33.680: INFO: Pod pod-with-poststart-http-hook still exists
Aug 22 08:27:35.677: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 22 08:27:35.680: INFO: Pod pod-with-poststart-http-hook still exists
Aug 22 08:27:37.677: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 22 08:27:37.680: INFO: Pod pod-with-poststart-http-hook still exists
Aug 22 08:27:39.677: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 22 08:27:39.680: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:27:39.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7397" for this suite.
Aug 22 08:28:01.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:28:01.789: INFO: namespace container-lifecycle-hook-7397 deletion completed in 22.10605663s

• [SLOW TEST:36.296 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:28:01.789: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-4179
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0822 08:28:41.958121      14 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 22 08:28:41.958: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:28:41.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4179" for this suite.
Aug 22 08:28:47.971: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:28:48.058: INFO: namespace gc-4179 deletion completed in 6.096827823s

• [SLOW TEST:46.269 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:28:48.058: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5162
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Starting the proxy
Aug 22 08:28:48.203: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-901739697 proxy --unix-socket=/tmp/kubectl-proxy-unix115821392/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:28:48.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5162" for this suite.
Aug 22 08:28:54.264: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:28:54.335: INFO: namespace kubectl-5162 deletion completed in 6.07839673s

• [SLOW TEST:6.277 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:28:54.335: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-2838
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating replication controller my-hostname-basic-e0b7017b-c4b6-11e9-80b5-1edf08853c25
Aug 22 08:28:54.483: INFO: Pod name my-hostname-basic-e0b7017b-c4b6-11e9-80b5-1edf08853c25: Found 0 pods out of 1
Aug 22 08:28:59.486: INFO: Pod name my-hostname-basic-e0b7017b-c4b6-11e9-80b5-1edf08853c25: Found 1 pods out of 1
Aug 22 08:28:59.486: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-e0b7017b-c4b6-11e9-80b5-1edf08853c25" are running
Aug 22 08:28:59.488: INFO: Pod "my-hostname-basic-e0b7017b-c4b6-11e9-80b5-1edf08853c25-jl6qb" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-22 08:28:54 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-22 08:28:56 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-22 08:28:56 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-22 08:28:54 +0000 UTC Reason: Message:}])
Aug 22 08:28:59.488: INFO: Trying to dial the pod
Aug 22 08:29:04.511: INFO: Controller my-hostname-basic-e0b7017b-c4b6-11e9-80b5-1edf08853c25: Got expected result from replica 1 [my-hostname-basic-e0b7017b-c4b6-11e9-80b5-1edf08853c25-jl6qb]: "my-hostname-basic-e0b7017b-c4b6-11e9-80b5-1edf08853c25-jl6qb", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:29:04.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2838" for this suite.
Aug 22 08:29:10.537: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:29:10.614: INFO: namespace replication-controller-2838 deletion completed in 6.092862712s

• [SLOW TEST:16.279 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:29:10.614: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-4104
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:29:12.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4104" for this suite.
Aug 22 08:29:50.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:29:50.851: INFO: namespace kubelet-test-4104 deletion completed in 38.077245954s

• [SLOW TEST:40.237 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:29:50.852: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3698
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1108
STEP: creating the pod
Aug 22 08:29:50.983: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 create -f - --namespace=kubectl-3698'
Aug 22 08:29:51.340: INFO: stderr: ""
Aug 22 08:29:51.340: INFO: stdout: "pod/pause created\n"
Aug 22 08:29:51.340: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Aug 22 08:29:51.340: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-3698" to be "running and ready"
Aug 22 08:29:51.345: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 5.586985ms
Aug 22 08:29:53.348: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.008654255s
Aug 22 08:29:53.349: INFO: Pod "pause" satisfied condition "running and ready"
Aug 22 08:29:53.349: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: adding the label testing-label with value testing-label-value to a pod
Aug 22 08:29:53.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 label pods pause testing-label=testing-label-value --namespace=kubectl-3698'
Aug 22 08:29:53.435: INFO: stderr: ""
Aug 22 08:29:53.435: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Aug 22 08:29:53.435: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pod pause -L testing-label --namespace=kubectl-3698'
Aug 22 08:29:53.509: INFO: stderr: ""
Aug 22 08:29:53.509: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Aug 22 08:29:53.510: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 label pods pause testing-label- --namespace=kubectl-3698'
Aug 22 08:29:53.582: INFO: stderr: ""
Aug 22 08:29:53.582: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Aug 22 08:29:53.583: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pod pause -L testing-label --namespace=kubectl-3698'
Aug 22 08:29:53.664: INFO: stderr: ""
Aug 22 08:29:53.664: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1115
STEP: using delete to clean up resources
Aug 22 08:29:53.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 delete --grace-period=0 --force -f - --namespace=kubectl-3698'
Aug 22 08:29:53.741: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 22 08:29:53.741: INFO: stdout: "pod \"pause\" force deleted\n"
Aug 22 08:29:53.741: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get rc,svc -l name=pause --no-headers --namespace=kubectl-3698'
Aug 22 08:29:53.845: INFO: stderr: "No resources found.\n"
Aug 22 08:29:53.845: INFO: stdout: ""
Aug 22 08:29:53.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pods -l name=pause --namespace=kubectl-3698 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 22 08:29:53.937: INFO: stderr: ""
Aug 22 08:29:53.937: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:29:53.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3698" for this suite.
Aug 22 08:29:59.949: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:30:00.048: INFO: namespace kubectl-3698 deletion completed in 6.107164091s

• [SLOW TEST:9.197 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:30:00.048: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6298
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1190
STEP: creating an rc
Aug 22 08:30:00.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 create -f - --namespace=kubectl-6298'
Aug 22 08:30:00.335: INFO: stderr: ""
Aug 22 08:30:00.335: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Waiting for Redis master to start.
Aug 22 08:30:01.339: INFO: Selector matched 1 pods for map[app:redis]
Aug 22 08:30:01.339: INFO: Found 0 / 1
Aug 22 08:30:02.339: INFO: Selector matched 1 pods for map[app:redis]
Aug 22 08:30:02.339: INFO: Found 1 / 1
Aug 22 08:30:02.339: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 22 08:30:02.341: INFO: Selector matched 1 pods for map[app:redis]
Aug 22 08:30:02.341: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Aug 22 08:30:02.341: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 logs redis-master-7tn8b redis-master --namespace=kubectl-6298'
Aug 22 08:30:02.419: INFO: stderr: ""
Aug 22 08:30:02.419: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 22 Aug 08:30:01.330 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 22 Aug 08:30:01.330 # Server started, Redis version 3.2.12\n1:M 22 Aug 08:30:01.330 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 22 Aug 08:30:01.330 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Aug 22 08:30:02.419: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 log redis-master-7tn8b redis-master --namespace=kubectl-6298 --tail=1'
Aug 22 08:30:02.497: INFO: stderr: ""
Aug 22 08:30:02.497: INFO: stdout: "1:M 22 Aug 08:30:01.330 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Aug 22 08:30:02.498: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 log redis-master-7tn8b redis-master --namespace=kubectl-6298 --limit-bytes=1'
Aug 22 08:30:02.600: INFO: stderr: ""
Aug 22 08:30:02.600: INFO: stdout: " "
STEP: exposing timestamps
Aug 22 08:30:02.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 log redis-master-7tn8b redis-master --namespace=kubectl-6298 --tail=1 --timestamps'
Aug 22 08:30:02.680: INFO: stderr: ""
Aug 22 08:30:02.680: INFO: stdout: "2019-08-22T08:30:01.330625177Z 1:M 22 Aug 08:30:01.330 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Aug 22 08:30:05.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 log redis-master-7tn8b redis-master --namespace=kubectl-6298 --since=1s'
Aug 22 08:30:05.264: INFO: stderr: ""
Aug 22 08:30:05.264: INFO: stdout: ""
Aug 22 08:30:05.264: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 log redis-master-7tn8b redis-master --namespace=kubectl-6298 --since=24h'
Aug 22 08:30:05.349: INFO: stderr: ""
Aug 22 08:30:05.349: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 22 Aug 08:30:01.330 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 22 Aug 08:30:01.330 # Server started, Redis version 3.2.12\n1:M 22 Aug 08:30:01.330 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 22 Aug 08:30:01.330 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1196
STEP: using delete to clean up resources
Aug 22 08:30:05.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 delete --grace-period=0 --force -f - --namespace=kubectl-6298'
Aug 22 08:30:05.427: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 22 08:30:05.427: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Aug 22 08:30:05.427: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get rc,svc -l name=nginx --no-headers --namespace=kubectl-6298'
Aug 22 08:30:05.507: INFO: stderr: "No resources found.\n"
Aug 22 08:30:05.507: INFO: stdout: ""
Aug 22 08:30:05.507: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pods -l name=nginx --namespace=kubectl-6298 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 22 08:30:05.587: INFO: stderr: ""
Aug 22 08:30:05.587: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:30:05.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6298" for this suite.
Aug 22 08:30:11.605: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:30:11.780: INFO: namespace kubectl-6298 deletion completed in 6.188550653s

• [SLOW TEST:11.732 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:30:11.780: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3702
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Aug 22 08:30:11.925: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0ee0907b-c4b7-11e9-80b5-1edf08853c25" in namespace "projected-3702" to be "success or failure"
Aug 22 08:30:11.932: INFO: Pod "downwardapi-volume-0ee0907b-c4b7-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 6.835505ms
Aug 22 08:30:13.935: INFO: Pod "downwardapi-volume-0ee0907b-c4b7-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009815433s
STEP: Saw pod success
Aug 22 08:30:13.935: INFO: Pod "downwardapi-volume-0ee0907b-c4b7-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:30:13.937: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod downwardapi-volume-0ee0907b-c4b7-11e9-80b5-1edf08853c25 container client-container: <nil>
STEP: delete the pod
Aug 22 08:30:13.953: INFO: Waiting for pod downwardapi-volume-0ee0907b-c4b7-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:30:13.956: INFO: Pod downwardapi-volume-0ee0907b-c4b7-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:30:13.956: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3702" for this suite.
Aug 22 08:30:19.968: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:30:20.038: INFO: namespace projected-3702 deletion completed in 6.078525522s

• [SLOW TEST:8.258 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:30:20.039: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-6499
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-lthn
STEP: Creating a pod to test atomic-volume-subpath
Aug 22 08:30:20.184: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-lthn" in namespace "subpath-6499" to be "success or failure"
Aug 22 08:30:20.188: INFO: Pod "pod-subpath-test-configmap-lthn": Phase="Pending", Reason="", readiness=false. Elapsed: 3.930868ms
Aug 22 08:30:22.197: INFO: Pod "pod-subpath-test-configmap-lthn": Phase="Running", Reason="", readiness=true. Elapsed: 2.013105713s
Aug 22 08:30:24.201: INFO: Pod "pod-subpath-test-configmap-lthn": Phase="Running", Reason="", readiness=true. Elapsed: 4.017122863s
Aug 22 08:30:26.204: INFO: Pod "pod-subpath-test-configmap-lthn": Phase="Running", Reason="", readiness=true. Elapsed: 6.020355117s
Aug 22 08:30:28.208: INFO: Pod "pod-subpath-test-configmap-lthn": Phase="Running", Reason="", readiness=true. Elapsed: 8.023700496s
Aug 22 08:30:30.211: INFO: Pod "pod-subpath-test-configmap-lthn": Phase="Running", Reason="", readiness=true. Elapsed: 10.026714132s
Aug 22 08:30:32.215: INFO: Pod "pod-subpath-test-configmap-lthn": Phase="Running", Reason="", readiness=true. Elapsed: 12.031163724s
Aug 22 08:30:34.218: INFO: Pod "pod-subpath-test-configmap-lthn": Phase="Running", Reason="", readiness=true. Elapsed: 14.034491539s
Aug 22 08:30:36.222: INFO: Pod "pod-subpath-test-configmap-lthn": Phase="Running", Reason="", readiness=true. Elapsed: 16.038047283s
Aug 22 08:30:38.225: INFO: Pod "pod-subpath-test-configmap-lthn": Phase="Running", Reason="", readiness=true. Elapsed: 18.04115256s
Aug 22 08:30:40.228: INFO: Pod "pod-subpath-test-configmap-lthn": Phase="Running", Reason="", readiness=true. Elapsed: 20.044440054s
Aug 22 08:30:42.232: INFO: Pod "pod-subpath-test-configmap-lthn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.047852664s
STEP: Saw pod success
Aug 22 08:30:42.232: INFO: Pod "pod-subpath-test-configmap-lthn" satisfied condition "success or failure"
Aug 22 08:30:42.234: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-subpath-test-configmap-lthn container test-container-subpath-configmap-lthn: <nil>
STEP: delete the pod
Aug 22 08:30:42.251: INFO: Waiting for pod pod-subpath-test-configmap-lthn to disappear
Aug 22 08:30:42.255: INFO: Pod pod-subpath-test-configmap-lthn no longer exists
STEP: Deleting pod pod-subpath-test-configmap-lthn
Aug 22 08:30:42.255: INFO: Deleting pod "pod-subpath-test-configmap-lthn" in namespace "subpath-6499"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:30:42.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6499" for this suite.
Aug 22 08:30:48.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:30:48.344: INFO: namespace subpath-6499 deletion completed in 6.081176948s

• [SLOW TEST:28.306 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:30:48.344: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6468
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Aug 22 08:30:48.477: INFO: namespace kubectl-6468
Aug 22 08:30:48.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 create -f - --namespace=kubectl-6468'
Aug 22 08:30:48.634: INFO: stderr: ""
Aug 22 08:30:48.634: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug 22 08:30:49.640: INFO: Selector matched 1 pods for map[app:redis]
Aug 22 08:30:49.641: INFO: Found 0 / 1
Aug 22 08:30:50.645: INFO: Selector matched 1 pods for map[app:redis]
Aug 22 08:30:50.645: INFO: Found 0 / 1
Aug 22 08:30:51.638: INFO: Selector matched 1 pods for map[app:redis]
Aug 22 08:30:51.638: INFO: Found 1 / 1
Aug 22 08:30:51.638: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 22 08:30:51.640: INFO: Selector matched 1 pods for map[app:redis]
Aug 22 08:30:51.640: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 22 08:30:51.640: INFO: wait on redis-master startup in kubectl-6468 
Aug 22 08:30:51.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 logs redis-master-66hbr redis-master --namespace=kubectl-6468'
Aug 22 08:30:51.718: INFO: stderr: ""
Aug 22 08:30:51.718: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 22 Aug 08:30:49.621 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 22 Aug 08:30:49.621 # Server started, Redis version 3.2.12\n1:M 22 Aug 08:30:49.621 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 22 Aug 08:30:49.621 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Aug 22 08:30:51.719: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-6468'
Aug 22 08:30:51.808: INFO: stderr: ""
Aug 22 08:30:51.808: INFO: stdout: "service/rm2 exposed\n"
Aug 22 08:30:51.814: INFO: Service rm2 in namespace kubectl-6468 found.
STEP: exposing service
Aug 22 08:30:53.818: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-6468'
Aug 22 08:30:53.899: INFO: stderr: ""
Aug 22 08:30:53.899: INFO: stdout: "service/rm3 exposed\n"
Aug 22 08:30:53.902: INFO: Service rm3 in namespace kubectl-6468 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:30:55.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6468" for this suite.
Aug 22 08:31:17.918: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:31:17.987: INFO: namespace kubectl-6468 deletion completed in 22.07696913s

• [SLOW TEST:29.642 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create services for rc  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:31:17.987: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2246
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating secret secrets-2246/secret-test-36565d7f-c4b7-11e9-80b5-1edf08853c25
STEP: Creating a pod to test consume secrets
Aug 22 08:31:18.130: INFO: Waiting up to 5m0s for pod "pod-configmaps-3657058d-c4b7-11e9-80b5-1edf08853c25" in namespace "secrets-2246" to be "success or failure"
Aug 22 08:31:18.138: INFO: Pod "pod-configmaps-3657058d-c4b7-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 7.280268ms
Aug 22 08:31:20.141: INFO: Pod "pod-configmaps-3657058d-c4b7-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010401927s
STEP: Saw pod success
Aug 22 08:31:20.141: INFO: Pod "pod-configmaps-3657058d-c4b7-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:31:20.143: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-configmaps-3657058d-c4b7-11e9-80b5-1edf08853c25 container env-test: <nil>
STEP: delete the pod
Aug 22 08:31:20.159: INFO: Waiting for pod pod-configmaps-3657058d-c4b7-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:31:20.162: INFO: Pod pod-configmaps-3657058d-c4b7-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:31:20.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2246" for this suite.
Aug 22 08:31:26.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:31:26.254: INFO: namespace secrets-2246 deletion completed in 6.088855667s

• [SLOW TEST:8.267 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:31:26.254: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9255
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Aug 22 08:31:28.429: INFO: Waiting up to 5m0s for pod "client-envvars-3c79ccbd-c4b7-11e9-80b5-1edf08853c25" in namespace "pods-9255" to be "success or failure"
Aug 22 08:31:28.433: INFO: Pod "client-envvars-3c79ccbd-c4b7-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 3.463454ms
Aug 22 08:31:30.436: INFO: Pod "client-envvars-3c79ccbd-c4b7-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00653398s
STEP: Saw pod success
Aug 22 08:31:30.436: INFO: Pod "client-envvars-3c79ccbd-c4b7-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:31:30.438: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod client-envvars-3c79ccbd-c4b7-11e9-80b5-1edf08853c25 container env3cont: <nil>
STEP: delete the pod
Aug 22 08:31:30.454: INFO: Waiting for pod client-envvars-3c79ccbd-c4b7-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:31:30.458: INFO: Pod client-envvars-3c79ccbd-c4b7-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:31:30.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9255" for this suite.
Aug 22 08:32:10.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:32:10.544: INFO: namespace pods-9255 deletion completed in 40.082745991s

• [SLOW TEST:44.290 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:32:10.544: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-3373
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-9464
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-8383
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:32:16.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-3373" for this suite.
Aug 22 08:32:22.987: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:32:23.063: INFO: namespace namespaces-3373 deletion completed in 6.084348748s
STEP: Destroying namespace "nsdeletetest-9464" for this suite.
Aug 22 08:32:23.065: INFO: Namespace nsdeletetest-9464 was already deleted
STEP: Destroying namespace "nsdeletetest-8383" for this suite.
Aug 22 08:32:29.073: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:32:29.145: INFO: namespace nsdeletetest-8383 deletion completed in 6.080018398s

• [SLOW TEST:18.601 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:32:29.145: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-5753
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
STEP: reading a file in the container
Aug 22 08:32:31.806: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5753 pod-service-account-610eb851-c4b7-11e9-80b5-1edf08853c25 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Aug 22 08:32:31.935: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5753 pod-service-account-610eb851-c4b7-11e9-80b5-1edf08853c25 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Aug 22 08:32:32.077: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5753 pod-service-account-610eb851-c4b7-11e9-80b5-1edf08853c25 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:32:32.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-5753" for this suite.
Aug 22 08:32:38.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:32:38.315: INFO: namespace svcaccounts-5753 deletion completed in 6.082189278s

• [SLOW TEST:9.170 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:32:38.315: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-5187
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-9438
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-857
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:33:02.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-5187" for this suite.
Aug 22 08:33:08.815: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:33:08.887: INFO: namespace namespaces-5187 deletion completed in 6.080790257s
STEP: Destroying namespace "nsdeletetest-9438" for this suite.
Aug 22 08:33:08.889: INFO: Namespace nsdeletetest-9438 was already deleted
STEP: Destroying namespace "nsdeletetest-857" for this suite.
Aug 22 08:33:14.898: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:33:14.968: INFO: namespace nsdeletetest-857 deletion completed in 6.078986164s

• [SLOW TEST:36.653 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:33:14.969: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8291
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Aug 22 08:33:15.109: INFO: Waiting up to 5m0s for pod "pod-7c107c6c-c4b7-11e9-80b5-1edf08853c25" in namespace "emptydir-8291" to be "success or failure"
Aug 22 08:33:15.124: INFO: Pod "pod-7c107c6c-c4b7-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 14.934716ms
Aug 22 08:33:17.127: INFO: Pod "pod-7c107c6c-c4b7-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017815876s
STEP: Saw pod success
Aug 22 08:33:17.127: INFO: Pod "pod-7c107c6c-c4b7-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:33:17.129: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-7c107c6c-c4b7-11e9-80b5-1edf08853c25 container test-container: <nil>
STEP: delete the pod
Aug 22 08:33:17.146: INFO: Waiting for pod pod-7c107c6c-c4b7-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:33:17.148: INFO: Pod pod-7c107c6c-c4b7-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:33:17.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8291" for this suite.
Aug 22 08:33:23.161: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:33:23.291: INFO: namespace emptydir-8291 deletion completed in 6.139611595s

• [SLOW TEST:8.322 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:33:23.291: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1119
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-810701ea-c4b7-11e9-80b5-1edf08853c25
STEP: Creating a pod to test consume secrets
Aug 22 08:33:23.440: INFO: Waiting up to 5m0s for pod "pod-secrets-8107b37e-c4b7-11e9-80b5-1edf08853c25" in namespace "secrets-1119" to be "success or failure"
Aug 22 08:33:23.452: INFO: Pod "pod-secrets-8107b37e-c4b7-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 11.526025ms
Aug 22 08:33:25.455: INFO: Pod "pod-secrets-8107b37e-c4b7-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014544039s
STEP: Saw pod success
Aug 22 08:33:25.455: INFO: Pod "pod-secrets-8107b37e-c4b7-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:33:25.457: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-secrets-8107b37e-c4b7-11e9-80b5-1edf08853c25 container secret-volume-test: <nil>
STEP: delete the pod
Aug 22 08:33:25.472: INFO: Waiting for pod pod-secrets-8107b37e-c4b7-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:33:25.474: INFO: Pod pod-secrets-8107b37e-c4b7-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:33:25.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1119" for this suite.
Aug 22 08:33:31.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:33:31.560: INFO: namespace secrets-1119 deletion completed in 6.082289099s

• [SLOW TEST:8.269 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:33:31.561: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-1350
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Aug 22 08:33:31.709: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-1350,SelfLink:/api/v1/namespaces/watch-1350/configmaps/e2e-watch-test-watch-closed,UID:85f546b6-c4b7-11e9-92bb-0afbab63fbd8,ResourceVersion:14707308,Generation:0,CreationTimestamp:2019-08-22 08:33:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 22 08:33:31.709: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-1350,SelfLink:/api/v1/namespaces/watch-1350/configmaps/e2e-watch-test-watch-closed,UID:85f546b6-c4b7-11e9-92bb-0afbab63fbd8,ResourceVersion:14707309,Generation:0,CreationTimestamp:2019-08-22 08:33:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Aug 22 08:33:31.722: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-1350,SelfLink:/api/v1/namespaces/watch-1350/configmaps/e2e-watch-test-watch-closed,UID:85f546b6-c4b7-11e9-92bb-0afbab63fbd8,ResourceVersion:14707310,Generation:0,CreationTimestamp:2019-08-22 08:33:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 22 08:33:31.722: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-1350,SelfLink:/api/v1/namespaces/watch-1350/configmaps/e2e-watch-test-watch-closed,UID:85f546b6-c4b7-11e9-92bb-0afbab63fbd8,ResourceVersion:14707311,Generation:0,CreationTimestamp:2019-08-22 08:33:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:33:31.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1350" for this suite.
Aug 22 08:33:37.737: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:33:37.803: INFO: namespace watch-1350 deletion completed in 6.075013274s

• [SLOW TEST:6.242 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:33:37.803: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-2767
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-2767
Aug 22 08:33:39.948: INFO: Started pod liveness-exec in namespace container-probe-2767
STEP: checking the pod's current state and verifying that restartCount is present
Aug 22 08:33:39.950: INFO: Initial restart count of pod liveness-exec is 0
Aug 22 08:34:34.044: INFO: Restart count of pod container-probe-2767/liveness-exec is now 1 (54.093770381s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:34:34.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2767" for this suite.
Aug 22 08:34:40.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:34:40.136: INFO: namespace container-probe-2767 deletion completed in 6.07819146s

• [SLOW TEST:62.333 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:34:40.136: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3973
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-aed49acc-c4b7-11e9-80b5-1edf08853c25
STEP: Creating a pod to test consume configMaps
Aug 22 08:34:40.283: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-aed523c3-c4b7-11e9-80b5-1edf08853c25" in namespace "projected-3973" to be "success or failure"
Aug 22 08:34:40.290: INFO: Pod "pod-projected-configmaps-aed523c3-c4b7-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 6.604417ms
Aug 22 08:34:42.293: INFO: Pod "pod-projected-configmaps-aed523c3-c4b7-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009520562s
STEP: Saw pod success
Aug 22 08:34:42.293: INFO: Pod "pod-projected-configmaps-aed523c3-c4b7-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:34:42.295: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-projected-configmaps-aed523c3-c4b7-11e9-80b5-1edf08853c25 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 22 08:34:42.311: INFO: Waiting for pod pod-projected-configmaps-aed523c3-c4b7-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:34:42.313: INFO: Pod pod-projected-configmaps-aed523c3-c4b7-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:34:42.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3973" for this suite.
Aug 22 08:34:48.326: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:34:48.394: INFO: namespace projected-3973 deletion completed in 6.077710854s

• [SLOW TEST:8.258 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:34:48.394: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1898
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-b3c000ee-c4b7-11e9-80b5-1edf08853c25
STEP: Creating a pod to test consume secrets
Aug 22 08:34:48.538: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b3c0988e-c4b7-11e9-80b5-1edf08853c25" in namespace "projected-1898" to be "success or failure"
Aug 22 08:34:48.541: INFO: Pod "pod-projected-secrets-b3c0988e-c4b7-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 3.619103ms
Aug 22 08:34:50.545: INFO: Pod "pod-projected-secrets-b3c0988e-c4b7-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006780692s
STEP: Saw pod success
Aug 22 08:34:50.545: INFO: Pod "pod-projected-secrets-b3c0988e-c4b7-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:34:50.547: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-projected-secrets-b3c0988e-c4b7-11e9-80b5-1edf08853c25 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 22 08:34:50.562: INFO: Waiting for pod pod-projected-secrets-b3c0988e-c4b7-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:34:50.564: INFO: Pod pod-projected-secrets-b3c0988e-c4b7-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:34:50.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1898" for this suite.
Aug 22 08:34:56.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:34:56.653: INFO: namespace projected-1898 deletion completed in 6.083931577s

• [SLOW TEST:8.258 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:34:56.653: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-6817
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-6817
Aug 22 08:35:00.821: INFO: Started pod liveness-exec in namespace container-probe-6817
STEP: checking the pod's current state and verifying that restartCount is present
Aug 22 08:35:00.823: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:39:01.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6817" for this suite.
Aug 22 08:39:07.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:39:07.347: INFO: namespace container-probe-6817 deletion completed in 6.102401903s

• [SLOW TEST:250.695 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:39:07.348: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-1119
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-projected-hhlz
STEP: Creating a pod to test atomic-volume-subpath
Aug 22 08:39:07.496: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-hhlz" in namespace "subpath-1119" to be "success or failure"
Aug 22 08:39:07.500: INFO: Pod "pod-subpath-test-projected-hhlz": Phase="Pending", Reason="", readiness=false. Elapsed: 3.81798ms
Aug 22 08:39:09.503: INFO: Pod "pod-subpath-test-projected-hhlz": Phase="Running", Reason="", readiness=true. Elapsed: 2.007011324s
Aug 22 08:39:11.506: INFO: Pod "pod-subpath-test-projected-hhlz": Phase="Running", Reason="", readiness=true. Elapsed: 4.01025948s
Aug 22 08:39:13.510: INFO: Pod "pod-subpath-test-projected-hhlz": Phase="Running", Reason="", readiness=true. Elapsed: 6.014322102s
Aug 22 08:39:15.514: INFO: Pod "pod-subpath-test-projected-hhlz": Phase="Running", Reason="", readiness=true. Elapsed: 8.01750727s
Aug 22 08:39:17.517: INFO: Pod "pod-subpath-test-projected-hhlz": Phase="Running", Reason="", readiness=true. Elapsed: 10.0207554s
Aug 22 08:39:19.522: INFO: Pod "pod-subpath-test-projected-hhlz": Phase="Running", Reason="", readiness=true. Elapsed: 12.025470844s
Aug 22 08:39:21.525: INFO: Pod "pod-subpath-test-projected-hhlz": Phase="Running", Reason="", readiness=true. Elapsed: 14.028711903s
Aug 22 08:39:23.529: INFO: Pod "pod-subpath-test-projected-hhlz": Phase="Running", Reason="", readiness=true. Elapsed: 16.032665762s
Aug 22 08:39:25.532: INFO: Pod "pod-subpath-test-projected-hhlz": Phase="Running", Reason="", readiness=true. Elapsed: 18.035868346s
Aug 22 08:39:27.536: INFO: Pod "pod-subpath-test-projected-hhlz": Phase="Running", Reason="", readiness=true. Elapsed: 20.040067184s
Aug 22 08:39:29.540: INFO: Pod "pod-subpath-test-projected-hhlz": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.043858895s
STEP: Saw pod success
Aug 22 08:39:29.540: INFO: Pod "pod-subpath-test-projected-hhlz" satisfied condition "success or failure"
Aug 22 08:39:29.543: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-subpath-test-projected-hhlz container test-container-subpath-projected-hhlz: <nil>
STEP: delete the pod
Aug 22 08:39:29.564: INFO: Waiting for pod pod-subpath-test-projected-hhlz to disappear
Aug 22 08:39:29.566: INFO: Pod pod-subpath-test-projected-hhlz no longer exists
STEP: Deleting pod pod-subpath-test-projected-hhlz
Aug 22 08:39:29.566: INFO: Deleting pod "pod-subpath-test-projected-hhlz" in namespace "subpath-1119"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:39:29.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1119" for this suite.
Aug 22 08:39:35.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:39:35.702: INFO: namespace subpath-1119 deletion completed in 6.120626904s

• [SLOW TEST:28.354 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:39:35.702: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-2167
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-secret-hmf2
STEP: Creating a pod to test atomic-volume-subpath
Aug 22 08:39:35.903: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-hmf2" in namespace "subpath-2167" to be "success or failure"
Aug 22 08:39:35.908: INFO: Pod "pod-subpath-test-secret-hmf2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.892094ms
Aug 22 08:39:37.911: INFO: Pod "pod-subpath-test-secret-hmf2": Phase="Running", Reason="", readiness=true. Elapsed: 2.00798735s
Aug 22 08:39:39.914: INFO: Pod "pod-subpath-test-secret-hmf2": Phase="Running", Reason="", readiness=true. Elapsed: 4.011008975s
Aug 22 08:39:41.917: INFO: Pod "pod-subpath-test-secret-hmf2": Phase="Running", Reason="", readiness=true. Elapsed: 6.01419358s
Aug 22 08:39:43.920: INFO: Pod "pod-subpath-test-secret-hmf2": Phase="Running", Reason="", readiness=true. Elapsed: 8.017255666s
Aug 22 08:39:45.923: INFO: Pod "pod-subpath-test-secret-hmf2": Phase="Running", Reason="", readiness=true. Elapsed: 10.020438756s
Aug 22 08:39:47.926: INFO: Pod "pod-subpath-test-secret-hmf2": Phase="Running", Reason="", readiness=true. Elapsed: 12.023516552s
Aug 22 08:39:49.929: INFO: Pod "pod-subpath-test-secret-hmf2": Phase="Running", Reason="", readiness=true. Elapsed: 14.02649521s
Aug 22 08:39:51.932: INFO: Pod "pod-subpath-test-secret-hmf2": Phase="Running", Reason="", readiness=true. Elapsed: 16.029436978s
Aug 22 08:39:53.936: INFO: Pod "pod-subpath-test-secret-hmf2": Phase="Running", Reason="", readiness=true. Elapsed: 18.032626869s
Aug 22 08:39:55.939: INFO: Pod "pod-subpath-test-secret-hmf2": Phase="Running", Reason="", readiness=true. Elapsed: 20.03571928s
Aug 22 08:39:57.942: INFO: Pod "pod-subpath-test-secret-hmf2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.038621318s
STEP: Saw pod success
Aug 22 08:39:57.942: INFO: Pod "pod-subpath-test-secret-hmf2" satisfied condition "success or failure"
Aug 22 08:39:57.944: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-subpath-test-secret-hmf2 container test-container-subpath-secret-hmf2: <nil>
STEP: delete the pod
Aug 22 08:39:57.959: INFO: Waiting for pod pod-subpath-test-secret-hmf2 to disappear
Aug 22 08:39:57.962: INFO: Pod pod-subpath-test-secret-hmf2 no longer exists
STEP: Deleting pod pod-subpath-test-secret-hmf2
Aug 22 08:39:57.962: INFO: Deleting pod "pod-subpath-test-secret-hmf2" in namespace "subpath-2167"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:39:57.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2167" for this suite.
Aug 22 08:40:03.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:40:04.057: INFO: namespace subpath-2167 deletion completed in 6.089810511s

• [SLOW TEST:28.355 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:40:04.058: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5892
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-6fe7318a-c4b8-11e9-80b5-1edf08853c25
STEP: Creating a pod to test consume secrets
Aug 22 08:40:04.206: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6fe7cd8e-c4b8-11e9-80b5-1edf08853c25" in namespace "projected-5892" to be "success or failure"
Aug 22 08:40:04.220: INFO: Pod "pod-projected-secrets-6fe7cd8e-c4b8-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 13.289226ms
Aug 22 08:40:06.223: INFO: Pod "pod-projected-secrets-6fe7cd8e-c4b8-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016448962s
STEP: Saw pod success
Aug 22 08:40:06.223: INFO: Pod "pod-projected-secrets-6fe7cd8e-c4b8-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:40:06.225: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-projected-secrets-6fe7cd8e-c4b8-11e9-80b5-1edf08853c25 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 22 08:40:06.240: INFO: Waiting for pod pod-projected-secrets-6fe7cd8e-c4b8-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:40:06.243: INFO: Pod pod-projected-secrets-6fe7cd8e-c4b8-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:40:06.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5892" for this suite.
Aug 22 08:40:12.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:40:12.326: INFO: namespace projected-5892 deletion completed in 6.079631445s

• [SLOW TEST:8.268 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:40:12.326: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2261
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Aug 22 08:40:12.468: INFO: Waiting up to 5m0s for pod "downwardapi-volume-74d452a6-c4b8-11e9-80b5-1edf08853c25" in namespace "downward-api-2261" to be "success or failure"
Aug 22 08:40:12.477: INFO: Pod "downwardapi-volume-74d452a6-c4b8-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 8.597829ms
Aug 22 08:40:14.480: INFO: Pod "downwardapi-volume-74d452a6-c4b8-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011960568s
STEP: Saw pod success
Aug 22 08:40:14.480: INFO: Pod "downwardapi-volume-74d452a6-c4b8-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:40:14.482: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod downwardapi-volume-74d452a6-c4b8-11e9-80b5-1edf08853c25 container client-container: <nil>
STEP: delete the pod
Aug 22 08:40:14.498: INFO: Waiting for pod downwardapi-volume-74d452a6-c4b8-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:40:14.501: INFO: Pod downwardapi-volume-74d452a6-c4b8-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:40:14.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2261" for this suite.
Aug 22 08:40:20.514: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:40:20.604: INFO: namespace downward-api-2261 deletion completed in 6.099114549s

• [SLOW TEST:8.278 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:40:20.604: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-7128
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test env composition
Aug 22 08:40:20.803: INFO: Waiting up to 5m0s for pod "var-expansion-79cc3802-c4b8-11e9-80b5-1edf08853c25" in namespace "var-expansion-7128" to be "success or failure"
Aug 22 08:40:20.810: INFO: Pod "var-expansion-79cc3802-c4b8-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 7.070465ms
Aug 22 08:40:22.813: INFO: Pod "var-expansion-79cc3802-c4b8-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01019254s
STEP: Saw pod success
Aug 22 08:40:22.813: INFO: Pod "var-expansion-79cc3802-c4b8-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:40:22.815: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod var-expansion-79cc3802-c4b8-11e9-80b5-1edf08853c25 container dapi-container: <nil>
STEP: delete the pod
Aug 22 08:40:22.831: INFO: Waiting for pod var-expansion-79cc3802-c4b8-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:40:22.833: INFO: Pod var-expansion-79cc3802-c4b8-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:40:22.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7128" for this suite.
Aug 22 08:40:28.845: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:40:28.918: INFO: namespace var-expansion-7128 deletion completed in 6.081233277s

• [SLOW TEST:8.314 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:40:28.920: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-1323
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Aug 22 08:40:29.070: INFO: Create a RollingUpdate DaemonSet
Aug 22 08:40:29.083: INFO: Check that daemon pods launch on every node of the cluster
Aug 22 08:40:29.094: INFO: Number of nodes with available pods: 0
Aug 22 08:40:29.094: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Aug 22 08:40:30.101: INFO: Number of nodes with available pods: 0
Aug 22 08:40:30.101: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Aug 22 08:40:31.100: INFO: Number of nodes with available pods: 3
Aug 22 08:40:31.100: INFO: Number of running nodes: 3, number of available pods: 3
Aug 22 08:40:31.100: INFO: Update the DaemonSet to trigger a rollout
Aug 22 08:40:31.109: INFO: Updating DaemonSet daemon-set
Aug 22 08:40:35.121: INFO: Roll back the DaemonSet before rollout is complete
Aug 22 08:40:35.132: INFO: Updating DaemonSet daemon-set
Aug 22 08:40:35.132: INFO: Make sure DaemonSet rollback is complete
Aug 22 08:40:35.138: INFO: Wrong image for pod: daemon-set-2f62x. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Aug 22 08:40:35.138: INFO: Pod daemon-set-2f62x is not available
Aug 22 08:40:36.152: INFO: Wrong image for pod: daemon-set-2f62x. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Aug 22 08:40:36.152: INFO: Pod daemon-set-2f62x is not available
Aug 22 08:40:37.152: INFO: Pod daemon-set-sd4lw is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1323, will wait for the garbage collector to delete the pods
Aug 22 08:40:37.218: INFO: Deleting DaemonSet.extensions daemon-set took: 6.202766ms
Aug 22 08:40:37.518: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.292884ms
Aug 22 08:40:49.721: INFO: Number of nodes with available pods: 0
Aug 22 08:40:49.721: INFO: Number of running nodes: 0, number of available pods: 0
Aug 22 08:40:49.722: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1323/daemonsets","resourceVersion":"14708342"},"items":null}

Aug 22 08:40:49.724: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1323/pods","resourceVersion":"14708342"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:40:49.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1323" for this suite.
Aug 22 08:40:55.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:40:55.814: INFO: namespace daemonsets-1323 deletion completed in 6.077201016s

• [SLOW TEST:26.895 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:40:55.815: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1079
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Aug 22 08:40:55.950: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 create -f - --namespace=kubectl-1079'
Aug 22 08:40:56.253: INFO: stderr: ""
Aug 22 08:40:56.253: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 22 08:40:56.253: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1079'
Aug 22 08:40:56.341: INFO: stderr: ""
Aug 22 08:40:56.341: INFO: stdout: "update-demo-nautilus-m77nw update-demo-nautilus-s4sxn "
Aug 22 08:40:56.341: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pods update-demo-nautilus-m77nw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1079'
Aug 22 08:40:56.408: INFO: stderr: ""
Aug 22 08:40:56.408: INFO: stdout: ""
Aug 22 08:40:56.408: INFO: update-demo-nautilus-m77nw is created but not running
Aug 22 08:41:01.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1079'
Aug 22 08:41:01.479: INFO: stderr: ""
Aug 22 08:41:01.479: INFO: stdout: "update-demo-nautilus-m77nw update-demo-nautilus-s4sxn "
Aug 22 08:41:01.479: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pods update-demo-nautilus-m77nw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1079'
Aug 22 08:41:01.546: INFO: stderr: ""
Aug 22 08:41:01.546: INFO: stdout: "true"
Aug 22 08:41:01.546: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pods update-demo-nautilus-m77nw -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1079'
Aug 22 08:41:01.616: INFO: stderr: ""
Aug 22 08:41:01.616: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 22 08:41:01.616: INFO: validating pod update-demo-nautilus-m77nw
Aug 22 08:41:01.635: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 22 08:41:01.635: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 22 08:41:01.635: INFO: update-demo-nautilus-m77nw is verified up and running
Aug 22 08:41:01.635: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pods update-demo-nautilus-s4sxn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1079'
Aug 22 08:41:01.702: INFO: stderr: ""
Aug 22 08:41:01.702: INFO: stdout: "true"
Aug 22 08:41:01.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pods update-demo-nautilus-s4sxn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1079'
Aug 22 08:41:01.770: INFO: stderr: ""
Aug 22 08:41:01.770: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 22 08:41:01.770: INFO: validating pod update-demo-nautilus-s4sxn
Aug 22 08:41:01.774: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 22 08:41:01.774: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 22 08:41:01.774: INFO: update-demo-nautilus-s4sxn is verified up and running
STEP: scaling down the replication controller
Aug 22 08:41:01.775: INFO: scanned /root for discovery docs: <nil>
Aug 22 08:41:01.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-1079'
Aug 22 08:41:02.893: INFO: stderr: ""
Aug 22 08:41:02.893: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 22 08:41:02.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1079'
Aug 22 08:41:02.968: INFO: stderr: ""
Aug 22 08:41:02.968: INFO: stdout: "update-demo-nautilus-m77nw update-demo-nautilus-s4sxn "
STEP: Replicas for name=update-demo: expected=1 actual=2
Aug 22 08:41:07.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1079'
Aug 22 08:41:08.039: INFO: stderr: ""
Aug 22 08:41:08.039: INFO: stdout: "update-demo-nautilus-m77nw update-demo-nautilus-s4sxn "
STEP: Replicas for name=update-demo: expected=1 actual=2
Aug 22 08:41:13.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1079'
Aug 22 08:41:13.107: INFO: stderr: ""
Aug 22 08:41:13.107: INFO: stdout: "update-demo-nautilus-m77nw "
Aug 22 08:41:13.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pods update-demo-nautilus-m77nw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1079'
Aug 22 08:41:13.173: INFO: stderr: ""
Aug 22 08:41:13.173: INFO: stdout: "true"
Aug 22 08:41:13.174: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pods update-demo-nautilus-m77nw -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1079'
Aug 22 08:41:13.240: INFO: stderr: ""
Aug 22 08:41:13.240: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 22 08:41:13.240: INFO: validating pod update-demo-nautilus-m77nw
Aug 22 08:41:13.243: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 22 08:41:13.243: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 22 08:41:13.243: INFO: update-demo-nautilus-m77nw is verified up and running
STEP: scaling up the replication controller
Aug 22 08:41:13.244: INFO: scanned /root for discovery docs: <nil>
Aug 22 08:41:13.244: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-1079'
Aug 22 08:41:14.342: INFO: stderr: ""
Aug 22 08:41:14.342: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 22 08:41:14.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1079'
Aug 22 08:41:14.430: INFO: stderr: ""
Aug 22 08:41:14.430: INFO: stdout: "update-demo-nautilus-g8pbj update-demo-nautilus-m77nw "
Aug 22 08:41:14.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pods update-demo-nautilus-g8pbj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1079'
Aug 22 08:41:14.496: INFO: stderr: ""
Aug 22 08:41:14.496: INFO: stdout: ""
Aug 22 08:41:14.496: INFO: update-demo-nautilus-g8pbj is created but not running
Aug 22 08:41:19.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1079'
Aug 22 08:41:19.574: INFO: stderr: ""
Aug 22 08:41:19.574: INFO: stdout: "update-demo-nautilus-g8pbj update-demo-nautilus-m77nw "
Aug 22 08:41:19.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pods update-demo-nautilus-g8pbj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1079'
Aug 22 08:41:19.656: INFO: stderr: ""
Aug 22 08:41:19.656: INFO: stdout: "true"
Aug 22 08:41:19.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pods update-demo-nautilus-g8pbj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1079'
Aug 22 08:41:19.721: INFO: stderr: ""
Aug 22 08:41:19.721: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 22 08:41:19.721: INFO: validating pod update-demo-nautilus-g8pbj
Aug 22 08:41:19.724: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 22 08:41:19.724: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 22 08:41:19.725: INFO: update-demo-nautilus-g8pbj is verified up and running
Aug 22 08:41:19.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pods update-demo-nautilus-m77nw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1079'
Aug 22 08:41:19.792: INFO: stderr: ""
Aug 22 08:41:19.792: INFO: stdout: "true"
Aug 22 08:41:19.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pods update-demo-nautilus-m77nw -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1079'
Aug 22 08:41:19.864: INFO: stderr: ""
Aug 22 08:41:19.864: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 22 08:41:19.864: INFO: validating pod update-demo-nautilus-m77nw
Aug 22 08:41:19.867: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 22 08:41:19.867: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 22 08:41:19.867: INFO: update-demo-nautilus-m77nw is verified up and running
STEP: using delete to clean up resources
Aug 22 08:41:19.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 delete --grace-period=0 --force -f - --namespace=kubectl-1079'
Aug 22 08:41:19.936: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 22 08:41:19.936: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Aug 22 08:41:19.937: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-1079'
Aug 22 08:41:20.006: INFO: stderr: "No resources found.\n"
Aug 22 08:41:20.006: INFO: stdout: ""
Aug 22 08:41:20.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pods -l name=update-demo --namespace=kubectl-1079 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 22 08:41:20.079: INFO: stderr: ""
Aug 22 08:41:20.079: INFO: stdout: "update-demo-nautilus-g8pbj\nupdate-demo-nautilus-m77nw\n"
Aug 22 08:41:20.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-1079'
Aug 22 08:41:20.649: INFO: stderr: "No resources found.\n"
Aug 22 08:41:20.649: INFO: stdout: ""
Aug 22 08:41:20.650: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pods -l name=update-demo --namespace=kubectl-1079 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 22 08:41:20.717: INFO: stderr: ""
Aug 22 08:41:20.717: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:41:20.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1079" for this suite.
Aug 22 08:41:42.729: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:41:42.822: INFO: namespace kubectl-1079 deletion completed in 22.101120806s

• [SLOW TEST:47.007 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:41:42.822: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-2869
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Aug 22 08:41:42.958: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 22 08:41:42.965: INFO: Waiting for terminating namespaces to be deleted...
Aug 22 08:41:42.967: INFO: 
Logging pods the kubelet thinks is on node ip-10-90-32-22.eu-west-2.compute.internal before test
Aug 22 08:41:42.976: INFO: kubernetes-dashboard-6c68548bc9-8z59b from kube-system started at 2019-08-21 21:26:22 +0000 UTC (1 container statuses recorded)
Aug 22 08:41:42.976: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Aug 22 08:41:42.976: INFO: harbor-harbor-notary-signer-5d8849d69b-q5sxq from default started at 2019-08-21 21:26:22 +0000 UTC (1 container statuses recorded)
Aug 22 08:41:42.976: INFO: 	Container notary-signer ready: true, restart count 1
Aug 22 08:41:42.976: INFO: harbor-harbor-jobservice-55d6cbcfd8-lw9hj from default started at 2019-08-21 21:26:22 +0000 UTC (1 container statuses recorded)
Aug 22 08:41:42.976: INFO: 	Container jobservice ready: true, restart count 0
Aug 22 08:41:42.976: INFO: metrics-server-cf9d8cd8c-jtb99 from kube-system started at 2019-08-21 21:26:22 +0000 UTC (1 container statuses recorded)
Aug 22 08:41:42.976: INFO: 	Container metrics-server ready: true, restart count 0
Aug 22 08:41:42.976: INFO: rabbit-rabbitmq-ha-0 from default started at 2019-08-21 21:26:32 +0000 UTC (1 container statuses recorded)
Aug 22 08:41:42.976: INFO: 	Container rabbitmq-ha ready: true, restart count 0
Aug 22 08:41:42.976: INFO: harbor-harbor-redis-0 from default started at 2019-08-21 21:26:37 +0000 UTC (1 container statuses recorded)
Aug 22 08:41:42.976: INFO: 	Container redis ready: true, restart count 0
Aug 22 08:41:42.976: INFO: ss2-2 from statefulset-3821 started at 2019-08-21 21:27:59 +0000 UTC (1 container statuses recorded)
Aug 22 08:41:42.976: INFO: 	Container nginx ready: true, restart count 0
Aug 22 08:41:42.976: INFO: filebeat-5nfcr from kube-system started at 2019-08-21 21:26:09 +0000 UTC (1 container statuses recorded)
Aug 22 08:41:42.976: INFO: 	Container filebeat ready: true, restart count 0
Aug 22 08:41:42.976: INFO: harbor-harbor-core-6576c89d75-d964k from default started at 2019-08-21 21:26:22 +0000 UTC (1 container statuses recorded)
Aug 22 08:41:42.976: INFO: 	Container core ready: true, restart count 1
Aug 22 08:41:42.976: INFO: coredns-54586579f6-ncd2w from kube-system started at 2019-08-21 21:26:22 +0000 UTC (1 container statuses recorded)
Aug 22 08:41:42.976: INFO: 	Container coredns ready: true, restart count 0
Aug 22 08:41:42.976: INFO: ss2-0 from statefulset-3821 started at 2019-08-21 21:26:32 +0000 UTC (1 container statuses recorded)
Aug 22 08:41:42.976: INFO: 	Container nginx ready: true, restart count 0
Aug 22 08:41:42.976: INFO: harbor-harbor-database-0 from default started at 2019-08-21 21:26:36 +0000 UTC (1 container statuses recorded)
Aug 22 08:41:42.976: INFO: 	Container database ready: true, restart count 0
Aug 22 08:41:42.976: INFO: rabbit-rabbitmq-ha-2 from default started at 2019-08-21 21:26:54 +0000 UTC (1 container statuses recorded)
Aug 22 08:41:42.976: INFO: 	Container rabbitmq-ha ready: true, restart count 0
Aug 22 08:41:42.976: INFO: sonobuoy-systemd-logs-daemon-set-77a1f61d77c0402d-9cdch from heptio-sonobuoy started at 2019-08-22 07:41:47 +0000 UTC (2 container statuses recorded)
Aug 22 08:41:42.976: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 22 08:41:42.976: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 22 08:41:42.976: INFO: tiller-deploy-66b7dd976-9s6xn from kube-system started at 2019-08-21 21:26:22 +0000 UTC (1 container statuses recorded)
Aug 22 08:41:42.976: INFO: 	Container tiller ready: true, restart count 0
Aug 22 08:41:42.976: INFO: traefik-ingress-controller-sqvfm from traefik-ingress started at 2019-08-22 07:35:59 +0000 UTC (1 container statuses recorded)
Aug 22 08:41:42.976: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Aug 22 08:41:42.976: INFO: harbor-harbor-chartmuseum-6c9cfcb75-ccf7f from default started at 2019-08-21 21:26:22 +0000 UTC (1 container statuses recorded)
Aug 22 08:41:42.976: INFO: 	Container chartmuseum ready: true, restart count 0
Aug 22 08:41:42.976: INFO: 
Logging pods the kubelet thinks is on node ip-10-90-32-23.eu-west-2.compute.internal before test
Aug 22 08:41:42.984: INFO: tiller-deploy-775fdcb4cb-8rqxz from test started at 2019-08-21 21:27:39 +0000 UTC (1 container statuses recorded)
Aug 22 08:41:42.984: INFO: 	Container tiller ready: true, restart count 0
Aug 22 08:41:42.984: INFO: hello-python-866d7f447b-8v4p4 from default started at 2019-08-21 21:27:38 +0000 UTC (1 container statuses recorded)
Aug 22 08:41:42.984: INFO: 	Container hello-python ready: true, restart count 0
Aug 22 08:41:42.984: INFO: python-5c8bdf49c5-4gn9f from default started at 2019-08-21 21:27:39 +0000 UTC (1 container statuses recorded)
Aug 22 08:41:42.984: INFO: 	Container python ready: true, restart count 0
Aug 22 08:41:42.984: INFO: ss2-1 from statefulset-3821 started at 2019-08-21 21:27:48 +0000 UTC (1 container statuses recorded)
Aug 22 08:41:42.984: INFO: 	Container nginx ready: true, restart count 0
Aug 22 08:41:42.984: INFO: traefik-ingress-controller-w9znh from traefik-ingress started at 2019-08-22 07:35:39 +0000 UTC (1 container statuses recorded)
Aug 22 08:41:42.984: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Aug 22 08:41:42.984: INFO: harbor-harbor-registry-bffc4f6b-prl88 from default started at 2019-08-21 21:27:38 +0000 UTC (2 container statuses recorded)
Aug 22 08:41:42.984: INFO: 	Container registry ready: true, restart count 0
Aug 22 08:41:42.984: INFO: 	Container registryctl ready: true, restart count 0
Aug 22 08:41:42.984: INFO: harbor-harbor-notary-server-7fd5cb4874-zm57q from default started at 2019-08-21 21:27:38 +0000 UTC (1 container statuses recorded)
Aug 22 08:41:42.984: INFO: 	Container notary-server ready: true, restart count 0
Aug 22 08:41:42.984: INFO: filebeat-gdpxp from kube-system started at 2019-08-21 21:27:29 +0000 UTC (1 container statuses recorded)
Aug 22 08:41:42.984: INFO: 	Container filebeat ready: true, restart count 0
Aug 22 08:41:42.984: INFO: sonobuoy-systemd-logs-daemon-set-77a1f61d77c0402d-k88tw from heptio-sonobuoy started at 2019-08-22 07:41:47 +0000 UTC (2 container statuses recorded)
Aug 22 08:41:42.984: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 22 08:41:42.984: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 22 08:41:42.984: INFO: coredns-54586579f6-29wj8 from kube-system started at 2019-08-21 21:27:39 +0000 UTC (1 container statuses recorded)
Aug 22 08:41:42.984: INFO: 	Container coredns ready: true, restart count 0
Aug 22 08:41:42.984: INFO: harbor-harbor-portal-6cbfc59497-k7qzj from default started at 2019-08-21 21:27:39 +0000 UTC (1 container statuses recorded)
Aug 22 08:41:42.984: INFO: 	Container portal ready: true, restart count 0
Aug 22 08:41:42.984: INFO: coredns-54586579f6-frkn5 from kube-system started at 2019-08-21 21:27:39 +0000 UTC (1 container statuses recorded)
Aug 22 08:41:42.984: INFO: 	Container coredns ready: true, restart count 0
Aug 22 08:41:42.984: INFO: rabbit-rabbitmq-ha-1 from default started at 2019-08-21 21:27:50 +0000 UTC (1 container statuses recorded)
Aug 22 08:41:42.984: INFO: 	Container rabbitmq-ha ready: true, restart count 0
Aug 22 08:41:42.984: INFO: petclinic-7c86cccbdc-krcsq from default started at 2019-08-21 21:27:38 +0000 UTC (1 container statuses recorded)
Aug 22 08:41:42.984: INFO: 	Container petclinic ready: true, restart count 0
Aug 22 08:41:42.984: INFO: harbor-harbor-clair-54c47dfdfc-rxdrv from default started at 2019-08-21 21:27:38 +0000 UTC (1 container statuses recorded)
Aug 22 08:41:42.984: INFO: 	Container clair ready: true, restart count 0
Aug 22 08:41:42.984: INFO: 
Logging pods the kubelet thinks is on node ip-10-90-32-24.eu-west-2.compute.internal before test
Aug 22 08:41:42.988: INFO: sonobuoy from heptio-sonobuoy started at 2019-08-22 07:41:45 +0000 UTC (1 container statuses recorded)
Aug 22 08:41:42.988: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 22 08:41:42.988: INFO: traefik-ingress-controller-4vj7g from traefik-ingress started at 2019-08-22 07:35:44 +0000 UTC (1 container statuses recorded)
Aug 22 08:41:42.988: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Aug 22 08:41:42.988: INFO: filebeat-xvmwc from kube-system started at 2019-08-21 21:28:49 +0000 UTC (1 container statuses recorded)
Aug 22 08:41:42.988: INFO: 	Container filebeat ready: true, restart count 0
Aug 22 08:41:42.988: INFO: sonobuoy-e2e-job-3bb06073b99141d8 from heptio-sonobuoy started at 2019-08-22 07:41:47 +0000 UTC (2 container statuses recorded)
Aug 22 08:41:42.988: INFO: 	Container e2e ready: true, restart count 0
Aug 22 08:41:42.988: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 22 08:41:42.988: INFO: sonobuoy-systemd-logs-daemon-set-77a1f61d77c0402d-qnkzk from heptio-sonobuoy started at 2019-08-22 07:41:47 +0000 UTC (2 container statuses recorded)
Aug 22 08:41:42.988: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 22 08:41:42.988: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15bd32131981441d], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:41:44.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2869" for this suite.
Aug 22 08:41:50.043: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:41:50.140: INFO: namespace sched-pred-2869 deletion completed in 6.115369275s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.318 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:41:50.140: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-988
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Aug 22 08:41:50.341: INFO: Number of nodes with available pods: 0
Aug 22 08:41:50.341: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Aug 22 08:41:51.353: INFO: Number of nodes with available pods: 0
Aug 22 08:41:51.353: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Aug 22 08:41:52.347: INFO: Number of nodes with available pods: 3
Aug 22 08:41:52.347: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Aug 22 08:41:52.366: INFO: Number of nodes with available pods: 2
Aug 22 08:41:52.366: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Aug 22 08:41:53.373: INFO: Number of nodes with available pods: 2
Aug 22 08:41:53.373: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Aug 22 08:41:54.373: INFO: Number of nodes with available pods: 2
Aug 22 08:41:54.373: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Aug 22 08:41:55.373: INFO: Number of nodes with available pods: 2
Aug 22 08:41:55.373: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Aug 22 08:41:56.373: INFO: Number of nodes with available pods: 2
Aug 22 08:41:56.373: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Aug 22 08:41:57.373: INFO: Number of nodes with available pods: 2
Aug 22 08:41:57.373: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Aug 22 08:41:58.373: INFO: Number of nodes with available pods: 2
Aug 22 08:41:58.373: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Aug 22 08:41:59.377: INFO: Number of nodes with available pods: 2
Aug 22 08:41:59.377: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Aug 22 08:42:00.373: INFO: Number of nodes with available pods: 2
Aug 22 08:42:00.373: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Aug 22 08:42:01.381: INFO: Number of nodes with available pods: 3
Aug 22 08:42:01.381: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-988, will wait for the garbage collector to delete the pods
Aug 22 08:42:01.445: INFO: Deleting DaemonSet.extensions daemon-set took: 7.139982ms
Aug 22 08:42:01.745: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.265138ms
Aug 22 08:42:09.448: INFO: Number of nodes with available pods: 0
Aug 22 08:42:09.448: INFO: Number of running nodes: 0, number of available pods: 0
Aug 22 08:42:09.450: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-988/daemonsets","resourceVersion":"14708714"},"items":null}

Aug 22 08:42:09.451: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-988/pods","resourceVersion":"14708714"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:42:09.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-988" for this suite.
Aug 22 08:42:15.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:42:15.630: INFO: namespace daemonsets-988 deletion completed in 6.164614337s

• [SLOW TEST:25.490 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:42:15.630: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5474
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Aug 22 08:42:15.772: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 version --client'
Aug 22 08:42:15.822: INFO: stderr: ""
Aug 22 08:42:15.822: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.1\", GitCommit:\"b7394102d6ef778017f2ca4046abbaa23b88c290\", GitTreeState:\"clean\", BuildDate:\"2019-04-08T17:11:31Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Aug 22 08:42:15.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 create -f - --namespace=kubectl-5474'
Aug 22 08:42:15.975: INFO: stderr: ""
Aug 22 08:42:15.975: INFO: stdout: "replicationcontroller/redis-master created\n"
Aug 22 08:42:15.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 create -f - --namespace=kubectl-5474'
Aug 22 08:42:16.158: INFO: stderr: ""
Aug 22 08:42:16.158: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug 22 08:42:17.161: INFO: Selector matched 1 pods for map[app:redis]
Aug 22 08:42:17.161: INFO: Found 0 / 1
Aug 22 08:42:18.161: INFO: Selector matched 1 pods for map[app:redis]
Aug 22 08:42:18.161: INFO: Found 1 / 1
Aug 22 08:42:18.161: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 22 08:42:18.164: INFO: Selector matched 1 pods for map[app:redis]
Aug 22 08:42:18.164: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 22 08:42:18.164: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 describe pod redis-master-5z7xb --namespace=kubectl-5474'
Aug 22 08:42:18.248: INFO: stderr: ""
Aug 22 08:42:18.248: INFO: stdout: "Name:               redis-master-5z7xb\nNamespace:          kubectl-5474\nPriority:           0\nPriorityClassName:  <none>\nNode:               ip-10-90-32-24.eu-west-2.compute.internal/10.90.32.24\nStart Time:         Thu, 22 Aug 2019 08:42:15 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.200.40.162\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://f0a1bfb1abbe55222ef2db8b9c377fc69cb5475743cbb5233020b4c4a7a9dee8\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Thu, 22 Aug 2019 08:42:16 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-48xq8 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-48xq8:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-48xq8\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                                Message\n  ----    ------     ----  ----                                                -------\n  Normal  Scheduled  3s    default-scheduler                                   Successfully assigned kubectl-5474/redis-master-5z7xb to ip-10-90-32-24.eu-west-2.compute.internal\n  Normal  Pulled     2s    kubelet, ip-10-90-32-24.eu-west-2.compute.internal  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, ip-10-90-32-24.eu-west-2.compute.internal  Created container redis-master\n  Normal  Started    2s    kubelet, ip-10-90-32-24.eu-west-2.compute.internal  Started container redis-master\n"
Aug 22 08:42:18.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 describe rc redis-master --namespace=kubectl-5474'
Aug 22 08:42:18.334: INFO: stderr: ""
Aug 22 08:42:18.334: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-5474\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-5z7xb\n"
Aug 22 08:42:18.334: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 describe service redis-master --namespace=kubectl-5474'
Aug 22 08:42:18.409: INFO: stderr: ""
Aug 22 08:42:18.409: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-5474\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.100.200.181\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.200.40.162:6379\nSession Affinity:  None\nEvents:            <none>\n"
Aug 22 08:42:18.413: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 describe node ip-10-90-32-22.eu-west-2.compute.internal'
Aug 22 08:42:18.513: INFO: stderr: ""
Aug 22 08:42:18.513: INFO: stdout: "Name:               ip-10-90-32-22.eu-west-2.compute.internal\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=t2.large\n                    beta.kubernetes.io/os=linux\n                    bosh.id=34437e50-3882-46f1-945a-d18a084a3edd\n                    bosh.zone=z1\n                    failure-domain.beta.kubernetes.io/region=eu-west-2\n                    failure-domain.beta.kubernetes.io/zone=eu-west-2b\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=10.90.32.22\n                    kubernetes.io/os=linux\n                    spec.ip=10.90.32.22\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 21 Aug 2019 21:25:59 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Thu, 22 Aug 2019 08:41:57 +0000   Wed, 21 Aug 2019 21:25:59 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Thu, 22 Aug 2019 08:41:57 +0000   Wed, 21 Aug 2019 21:25:59 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Thu, 22 Aug 2019 08:41:57 +0000   Wed, 21 Aug 2019 21:25:59 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Thu, 22 Aug 2019 08:41:57 +0000   Wed, 21 Aug 2019 21:26:09 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:   10.90.32.22\n  InternalDNS:  ip-10-90-32-22\n  Hostname:     10.90.32.22\nCapacity:\n attachable-volumes-aws-ebs:  39\n cpu:                         2\n ephemeral-storage:           95040332Ki\n hugepages-2Mi:               0\n memory:                      8166488Ki\n pods:                        110\nAllocatable:\n attachable-volumes-aws-ebs:  39\n cpu:                         2\n ephemeral-storage:           87589169827\n hugepages-2Mi:               0\n memory:                      8064088Ki\n pods:                        110\nSystem Info:\n Machine ID:                 72f3a7575d7fd57f5d775ff3cd1ad1c3\n System UUID:                EC2C39DE-7A91-7BE7-EF19-3B39D0AE1794\n Boot ID:                    0b78efe6-7d6d-4d94-b14a-2210c79f15c6\n Kernel Version:             4.15.0-47-generic\n OS Image:                   Ubuntu 16.04.6 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.3\n Kubelet Version:            v1.14.1\n Kube-Proxy Version:         v1.14.1\nProviderID:                  aws:///eu-west-2b/i-02415fff166b057ba\nNon-terminated Pods:         (17 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  default                    harbor-harbor-chartmuseum-6c9cfcb75-ccf7f                  0 (0%)        0 (0%)      0 (0%)           0 (0%)         11h\n  default                    harbor-harbor-core-6576c89d75-d964k                        0 (0%)        0 (0%)      0 (0%)           0 (0%)         11h\n  default                    harbor-harbor-database-0                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         11h\n  default                    harbor-harbor-jobservice-55d6cbcfd8-lw9hj                  0 (0%)        0 (0%)      0 (0%)           0 (0%)         11h\n  default                    harbor-harbor-notary-signer-5d8849d69b-q5sxq               0 (0%)        0 (0%)      0 (0%)           0 (0%)         11h\n  default                    harbor-harbor-redis-0                                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         11h\n  default                    rabbit-rabbitmq-ha-0                                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         11h\n  default                    rabbit-rabbitmq-ha-2                                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         11h\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-77a1f61d77c0402d-9cdch    0 (0%)        0 (0%)      0 (0%)           0 (0%)         60m\n  kube-system                coredns-54586579f6-ncd2w                                   100m (5%)     0 (0%)      70Mi (0%)        170Mi (2%)     11h\n  kube-system                filebeat-5nfcr                                             100m (5%)     0 (0%)      100Mi (1%)       200Mi (2%)     11h\n  kube-system                kubernetes-dashboard-6c68548bc9-8z59b                      50m (2%)      100m (5%)   100Mi (1%)       300Mi (3%)     11h\n  kube-system                metrics-server-cf9d8cd8c-jtb99                             0 (0%)        0 (0%)      0 (0%)           0 (0%)         11h\n  kube-system                tiller-deploy-66b7dd976-9s6xn                              0 (0%)        0 (0%)      0 (0%)           0 (0%)         11h\n  statefulset-3821           ss2-0                                                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         11h\n  statefulset-3821           ss2-2                                                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         11h\n  traefik-ingress            traefik-ingress-controller-sqvfm                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         66m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                    Requests    Limits\n  --------                    --------    ------\n  cpu                         250m (12%)  100m (5%)\n  memory                      270Mi (3%)  670Mi (8%)\n  ephemeral-storage           0 (0%)      0 (0%)\n  attachable-volumes-aws-ebs  0           0\nEvents:                       <none>\n"
Aug 22 08:42:18.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 describe namespace kubectl-5474'
Aug 22 08:42:18.586: INFO: stderr: ""
Aug 22 08:42:18.586: INFO: stdout: "Name:         kubectl-5474\nLabels:       e2e-framework=kubectl\n              e2e-run=4ce19bdf-c4b0-11e9-80b5-1edf08853c25\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:42:18.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5474" for this suite.
Aug 22 08:42:40.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:42:40.671: INFO: namespace kubectl-5474 deletion completed in 22.080917308s

• [SLOW TEST:25.041 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:42:40.672: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-7889
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override arguments
Aug 22 08:42:40.868: INFO: Waiting up to 5m0s for pod "client-containers-cd485ae1-c4b8-11e9-80b5-1edf08853c25" in namespace "containers-7889" to be "success or failure"
Aug 22 08:42:40.873: INFO: Pod "client-containers-cd485ae1-c4b8-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 4.782133ms
Aug 22 08:42:42.876: INFO: Pod "client-containers-cd485ae1-c4b8-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007946448s
STEP: Saw pod success
Aug 22 08:42:42.876: INFO: Pod "client-containers-cd485ae1-c4b8-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:42:42.878: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod client-containers-cd485ae1-c4b8-11e9-80b5-1edf08853c25 container test-container: <nil>
STEP: delete the pod
Aug 22 08:42:42.898: INFO: Waiting for pod client-containers-cd485ae1-c4b8-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:42:42.901: INFO: Pod client-containers-cd485ae1-c4b8-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:42:42.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7889" for this suite.
Aug 22 08:42:48.914: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:42:48.986: INFO: namespace containers-7889 deletion completed in 6.081377064s

• [SLOW TEST:8.315 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:42:48.987: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-4309
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-4309
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 22 08:42:49.122: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug 22 08:43:11.230: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.200.47.168:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4309 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 22 08:43:11.230: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
Aug 22 08:43:11.322: INFO: Found all expected endpoints: [netserver-0]
Aug 22 08:43:11.326: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.200.87.69:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4309 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 22 08:43:11.326: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
Aug 22 08:43:11.414: INFO: Found all expected endpoints: [netserver-1]
Aug 22 08:43:11.417: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.200.40.164:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4309 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 22 08:43:11.417: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
Aug 22 08:43:11.503: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:43:11.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4309" for this suite.
Aug 22 08:43:33.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:43:33.618: INFO: namespace pod-network-test-4309 deletion completed in 22.109026702s

• [SLOW TEST:44.631 seconds]
[sig-network] Networking
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:43:33.619: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9445
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Aug 22 08:43:33.779: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ecd0df7b-c4b8-11e9-80b5-1edf08853c25" in namespace "projected-9445" to be "success or failure"
Aug 22 08:43:33.797: INFO: Pod "downwardapi-volume-ecd0df7b-c4b8-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 17.178488ms
Aug 22 08:43:35.800: INFO: Pod "downwardapi-volume-ecd0df7b-c4b8-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020449083s
STEP: Saw pod success
Aug 22 08:43:35.800: INFO: Pod "downwardapi-volume-ecd0df7b-c4b8-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:43:35.802: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod downwardapi-volume-ecd0df7b-c4b8-11e9-80b5-1edf08853c25 container client-container: <nil>
STEP: delete the pod
Aug 22 08:43:35.831: INFO: Waiting for pod downwardapi-volume-ecd0df7b-c4b8-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:43:35.836: INFO: Pod downwardapi-volume-ecd0df7b-c4b8-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:43:35.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9445" for this suite.
Aug 22 08:43:41.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:43:41.922: INFO: namespace projected-9445 deletion completed in 6.082562752s

• [SLOW TEST:8.303 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:43:41.922: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-348
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Aug 22 08:43:42.059: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:43:46.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-348" for this suite.
Aug 22 08:44:08.089: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:44:08.177: INFO: namespace init-container-348 deletion completed in 22.097429836s

• [SLOW TEST:26.254 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:44:08.177: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-9850
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Aug 22 08:44:08.328: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Aug 22 08:44:08.340: INFO: Number of nodes with available pods: 0
Aug 22 08:44:08.340: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Aug 22 08:44:08.361: INFO: Number of nodes with available pods: 0
Aug 22 08:44:08.361: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Aug 22 08:44:09.365: INFO: Number of nodes with available pods: 0
Aug 22 08:44:09.365: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Aug 22 08:44:10.364: INFO: Number of nodes with available pods: 1
Aug 22 08:44:10.364: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Aug 22 08:44:10.386: INFO: Number of nodes with available pods: 0
Aug 22 08:44:10.386: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Aug 22 08:44:10.409: INFO: Number of nodes with available pods: 0
Aug 22 08:44:10.409: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Aug 22 08:44:11.412: INFO: Number of nodes with available pods: 0
Aug 22 08:44:11.412: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Aug 22 08:44:12.412: INFO: Number of nodes with available pods: 0
Aug 22 08:44:12.412: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Aug 22 08:44:13.411: INFO: Number of nodes with available pods: 0
Aug 22 08:44:13.411: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Aug 22 08:44:14.411: INFO: Number of nodes with available pods: 0
Aug 22 08:44:14.411: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Aug 22 08:44:15.412: INFO: Number of nodes with available pods: 0
Aug 22 08:44:15.412: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Aug 22 08:44:16.412: INFO: Number of nodes with available pods: 0
Aug 22 08:44:16.413: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Aug 22 08:44:17.412: INFO: Number of nodes with available pods: 0
Aug 22 08:44:17.412: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Aug 22 08:44:18.412: INFO: Number of nodes with available pods: 0
Aug 22 08:44:18.412: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Aug 22 08:44:19.413: INFO: Number of nodes with available pods: 0
Aug 22 08:44:19.413: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Aug 22 08:44:20.412: INFO: Number of nodes with available pods: 0
Aug 22 08:44:20.412: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Aug 22 08:44:21.412: INFO: Number of nodes with available pods: 1
Aug 22 08:44:21.412: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9850, will wait for the garbage collector to delete the pods
Aug 22 08:44:21.475: INFO: Deleting DaemonSet.extensions daemon-set took: 6.878113ms
Aug 22 08:44:21.775: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.230815ms
Aug 22 08:44:29.378: INFO: Number of nodes with available pods: 0
Aug 22 08:44:29.378: INFO: Number of running nodes: 0, number of available pods: 0
Aug 22 08:44:29.382: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9850/daemonsets","resourceVersion":"14709417"},"items":null}

Aug 22 08:44:29.385: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9850/pods","resourceVersion":"14709417"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:44:29.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9850" for this suite.
Aug 22 08:44:35.426: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:44:35.499: INFO: namespace daemonsets-9850 deletion completed in 6.084609285s

• [SLOW TEST:27.322 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:44:35.499: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-6981
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Aug 22 08:44:39.678: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 22 08:44:39.680: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 22 08:44:41.680: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 22 08:44:41.683: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 22 08:44:43.680: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 22 08:44:43.683: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 22 08:44:45.680: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 22 08:44:45.684: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 22 08:44:47.680: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 22 08:44:47.683: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 22 08:44:49.680: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 22 08:44:49.683: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 22 08:44:51.680: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 22 08:44:51.683: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 22 08:44:53.680: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 22 08:44:53.684: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 22 08:44:55.681: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 22 08:44:55.685: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 22 08:44:57.680: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 22 08:44:57.690: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 22 08:44:59.680: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 22 08:44:59.684: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 22 08:45:01.680: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 22 08:45:01.683: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 22 08:45:03.680: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 22 08:45:03.683: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 22 08:45:05.680: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 22 08:45:05.684: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 22 08:45:07.680: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 22 08:45:07.683: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 22 08:45:09.680: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 22 08:45:09.683: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:45:09.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6981" for this suite.
Aug 22 08:45:31.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:45:31.776: INFO: namespace container-lifecycle-hook-6981 deletion completed in 22.08846052s

• [SLOW TEST:56.277 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:45:31.777: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5082
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap that has name configmap-test-emptyKey-333c5ada-c4b9-11e9-80b5-1edf08853c25
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:45:31.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5082" for this suite.
Aug 22 08:45:37.925: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:45:37.994: INFO: namespace configmap-5082 deletion completed in 6.077716768s

• [SLOW TEST:6.217 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:45:37.995: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2203
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-36f17ee1-c4b9-11e9-80b5-1edf08853c25
STEP: Creating a pod to test consume secrets
Aug 22 08:45:38.140: INFO: Waiting up to 5m0s for pod "pod-secrets-36f217c3-c4b9-11e9-80b5-1edf08853c25" in namespace "secrets-2203" to be "success or failure"
Aug 22 08:45:38.147: INFO: Pod "pod-secrets-36f217c3-c4b9-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 6.421597ms
Aug 22 08:45:40.150: INFO: Pod "pod-secrets-36f217c3-c4b9-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009614611s
STEP: Saw pod success
Aug 22 08:45:40.150: INFO: Pod "pod-secrets-36f217c3-c4b9-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:45:40.152: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-secrets-36f217c3-c4b9-11e9-80b5-1edf08853c25 container secret-volume-test: <nil>
STEP: delete the pod
Aug 22 08:45:40.168: INFO: Waiting for pod pod-secrets-36f217c3-c4b9-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:45:40.170: INFO: Pod pod-secrets-36f217c3-c4b9-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:45:40.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2203" for this suite.
Aug 22 08:45:46.182: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:45:46.251: INFO: namespace secrets-2203 deletion completed in 6.077499819s

• [SLOW TEST:8.256 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:45:46.251: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-7542
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-downwardapi-xqqv
STEP: Creating a pod to test atomic-volume-subpath
Aug 22 08:45:46.398: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-xqqv" in namespace "subpath-7542" to be "success or failure"
Aug 22 08:45:46.408: INFO: Pod "pod-subpath-test-downwardapi-xqqv": Phase="Pending", Reason="", readiness=false. Elapsed: 9.379858ms
Aug 22 08:45:48.411: INFO: Pod "pod-subpath-test-downwardapi-xqqv": Phase="Running", Reason="", readiness=true. Elapsed: 2.012736608s
Aug 22 08:45:50.414: INFO: Pod "pod-subpath-test-downwardapi-xqqv": Phase="Running", Reason="", readiness=true. Elapsed: 4.015886652s
Aug 22 08:45:52.418: INFO: Pod "pod-subpath-test-downwardapi-xqqv": Phase="Running", Reason="", readiness=true. Elapsed: 6.019107471s
Aug 22 08:45:54.422: INFO: Pod "pod-subpath-test-downwardapi-xqqv": Phase="Running", Reason="", readiness=true. Elapsed: 8.023036869s
Aug 22 08:45:56.426: INFO: Pod "pod-subpath-test-downwardapi-xqqv": Phase="Running", Reason="", readiness=true. Elapsed: 10.027115527s
Aug 22 08:45:58.429: INFO: Pod "pod-subpath-test-downwardapi-xqqv": Phase="Running", Reason="", readiness=true. Elapsed: 12.030782958s
Aug 22 08:46:00.433: INFO: Pod "pod-subpath-test-downwardapi-xqqv": Phase="Running", Reason="", readiness=true. Elapsed: 14.034033164s
Aug 22 08:46:02.437: INFO: Pod "pod-subpath-test-downwardapi-xqqv": Phase="Running", Reason="", readiness=true. Elapsed: 16.038267455s
Aug 22 08:46:04.440: INFO: Pod "pod-subpath-test-downwardapi-xqqv": Phase="Running", Reason="", readiness=true. Elapsed: 18.041994963s
Aug 22 08:46:06.445: INFO: Pod "pod-subpath-test-downwardapi-xqqv": Phase="Running", Reason="", readiness=true. Elapsed: 20.046106771s
Aug 22 08:46:08.450: INFO: Pod "pod-subpath-test-downwardapi-xqqv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.051643995s
STEP: Saw pod success
Aug 22 08:46:08.450: INFO: Pod "pod-subpath-test-downwardapi-xqqv" satisfied condition "success or failure"
Aug 22 08:46:08.453: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-subpath-test-downwardapi-xqqv container test-container-subpath-downwardapi-xqqv: <nil>
STEP: delete the pod
Aug 22 08:46:08.472: INFO: Waiting for pod pod-subpath-test-downwardapi-xqqv to disappear
Aug 22 08:46:08.476: INFO: Pod pod-subpath-test-downwardapi-xqqv no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-xqqv
Aug 22 08:46:08.476: INFO: Deleting pod "pod-subpath-test-downwardapi-xqqv" in namespace "subpath-7542"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:46:08.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7542" for this suite.
Aug 22 08:46:14.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:46:14.619: INFO: namespace subpath-7542 deletion completed in 6.131962589s

• [SLOW TEST:28.367 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:46:14.619: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1738
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0822 08:46:44.794393      14 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 22 08:46:44.794: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:46:44.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1738" for this suite.
Aug 22 08:46:50.807: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:46:50.880: INFO: namespace gc-1738 deletion completed in 6.081257596s

• [SLOW TEST:36.261 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:46:50.880: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7431
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-7227
STEP: Creating secret with name secret-test-62629dd4-c4b9-11e9-80b5-1edf08853c25
STEP: Creating a pod to test consume secrets
Aug 22 08:46:51.158: INFO: Waiting up to 5m0s for pod "pod-secrets-6277a71d-c4b9-11e9-80b5-1edf08853c25" in namespace "secrets-7431" to be "success or failure"
Aug 22 08:46:51.164: INFO: Pod "pod-secrets-6277a71d-c4b9-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 6.462908ms
Aug 22 08:46:53.167: INFO: Pod "pod-secrets-6277a71d-c4b9-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009805506s
STEP: Saw pod success
Aug 22 08:46:53.167: INFO: Pod "pod-secrets-6277a71d-c4b9-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:46:53.169: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-secrets-6277a71d-c4b9-11e9-80b5-1edf08853c25 container secret-volume-test: <nil>
STEP: delete the pod
Aug 22 08:46:53.189: INFO: Waiting for pod pod-secrets-6277a71d-c4b9-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:46:53.192: INFO: Pod pod-secrets-6277a71d-c4b9-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:46:53.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7431" for this suite.
Aug 22 08:46:59.206: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:46:59.352: INFO: namespace secrets-7431 deletion completed in 6.155540729s
STEP: Destroying namespace "secret-namespace-7227" for this suite.
Aug 22 08:47:05.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:47:05.436: INFO: namespace secret-namespace-7227 deletion completed in 6.083536707s

• [SLOW TEST:14.556 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:47:05.436: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6495
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Aug 22 08:47:05.579: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6b100dcd-c4b9-11e9-80b5-1edf08853c25" in namespace "downward-api-6495" to be "success or failure"
Aug 22 08:47:05.593: INFO: Pod "downwardapi-volume-6b100dcd-c4b9-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 13.833798ms
Aug 22 08:47:07.596: INFO: Pod "downwardapi-volume-6b100dcd-c4b9-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016821271s
STEP: Saw pod success
Aug 22 08:47:07.596: INFO: Pod "downwardapi-volume-6b100dcd-c4b9-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:47:07.598: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod downwardapi-volume-6b100dcd-c4b9-11e9-80b5-1edf08853c25 container client-container: <nil>
STEP: delete the pod
Aug 22 08:47:07.614: INFO: Waiting for pod downwardapi-volume-6b100dcd-c4b9-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:47:07.615: INFO: Pod downwardapi-volume-6b100dcd-c4b9-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:47:07.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6495" for this suite.
Aug 22 08:47:13.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:47:13.705: INFO: namespace downward-api-6495 deletion completed in 6.08646879s

• [SLOW TEST:8.269 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:47:13.706: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3719
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1510
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 22 08:47:13.888: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-3719'
Aug 22 08:47:13.972: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 22 08:47:13.972: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1515
Aug 22 08:47:13.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 delete jobs e2e-test-nginx-job --namespace=kubectl-3719'
Aug 22 08:47:14.059: INFO: stderr: ""
Aug 22 08:47:14.059: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:47:14.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3719" for this suite.
Aug 22 08:47:20.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:47:20.144: INFO: namespace kubectl-3719 deletion completed in 6.080400454s

• [SLOW TEST:6.438 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:47:20.144: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-59
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating pod
Aug 22 08:47:22.292: INFO: Pod pod-hostip-73d3a71f-c4b9-11e9-80b5-1edf08853c25 has hostIP: 10.90.32.24
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:47:22.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-59" for this suite.
Aug 22 08:47:44.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:47:44.371: INFO: namespace pods-59 deletion completed in 22.07530217s

• [SLOW TEST:24.226 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:47:44.371: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-1720
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-1720
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Aug 22 08:47:44.531: INFO: Found 0 stateful pods, waiting for 3
Aug 22 08:47:54.535: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 22 08:47:54.535: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 22 08:47:54.535: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Aug 22 08:47:54.559: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Aug 22 08:48:04.593: INFO: Updating stateful set ss2
Aug 22 08:48:04.610: INFO: Waiting for Pod statefulset-1720/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Aug 22 08:48:14.666: INFO: Found 2 stateful pods, waiting for 3
Aug 22 08:48:24.669: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 22 08:48:24.669: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 22 08:48:24.669: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Aug 22 08:48:24.691: INFO: Updating stateful set ss2
Aug 22 08:48:24.709: INFO: Waiting for Pod statefulset-1720/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Aug 22 08:48:34.733: INFO: Updating stateful set ss2
Aug 22 08:48:34.750: INFO: Waiting for StatefulSet statefulset-1720/ss2 to complete update
Aug 22 08:48:34.750: INFO: Waiting for Pod statefulset-1720/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Aug 22 08:48:44.756: INFO: Deleting all statefulset in ns statefulset-1720
Aug 22 08:48:44.758: INFO: Scaling statefulset ss2 to 0
Aug 22 08:48:54.776: INFO: Waiting for statefulset status.replicas updated to 0
Aug 22 08:48:54.780: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:48:54.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1720" for this suite.
Aug 22 08:49:00.827: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:49:00.906: INFO: namespace statefulset-1720 deletion completed in 6.107103926s

• [SLOW TEST:76.535 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:49:00.907: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-4564
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4564.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-4564.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4564.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-4564.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4564.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-4564.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4564.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-4564.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4564.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-4564.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4564.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-4564.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4564.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 241.200.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.200.241_udp@PTR;check="$$(dig +tcp +noall +answer +search 241.200.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.200.241_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4564.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-4564.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4564.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-4564.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4564.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-4564.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4564.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-4564.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4564.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-4564.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4564.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-4564.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4564.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 241.200.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.200.241_udp@PTR;check="$$(dig +tcp +noall +answer +search 241.200.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.200.241_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 22 08:49:03.105: INFO: Unable to read wheezy_udp@dns-test-service.dns-4564.svc.cluster.local from pod dns-4564/dns-test-afe78f26-c4b9-11e9-80b5-1edf08853c25: the server could not find the requested resource (get pods dns-test-afe78f26-c4b9-11e9-80b5-1edf08853c25)
Aug 22 08:49:03.108: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4564.svc.cluster.local from pod dns-4564/dns-test-afe78f26-c4b9-11e9-80b5-1edf08853c25: the server could not find the requested resource (get pods dns-test-afe78f26-c4b9-11e9-80b5-1edf08853c25)
Aug 22 08:49:03.110: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4564.svc.cluster.local from pod dns-4564/dns-test-afe78f26-c4b9-11e9-80b5-1edf08853c25: the server could not find the requested resource (get pods dns-test-afe78f26-c4b9-11e9-80b5-1edf08853c25)
Aug 22 08:49:03.113: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4564.svc.cluster.local from pod dns-4564/dns-test-afe78f26-c4b9-11e9-80b5-1edf08853c25: the server could not find the requested resource (get pods dns-test-afe78f26-c4b9-11e9-80b5-1edf08853c25)
Aug 22 08:49:03.134: INFO: Unable to read jessie_udp@dns-test-service.dns-4564.svc.cluster.local from pod dns-4564/dns-test-afe78f26-c4b9-11e9-80b5-1edf08853c25: the server could not find the requested resource (get pods dns-test-afe78f26-c4b9-11e9-80b5-1edf08853c25)
Aug 22 08:49:03.137: INFO: Unable to read jessie_tcp@dns-test-service.dns-4564.svc.cluster.local from pod dns-4564/dns-test-afe78f26-c4b9-11e9-80b5-1edf08853c25: the server could not find the requested resource (get pods dns-test-afe78f26-c4b9-11e9-80b5-1edf08853c25)
Aug 22 08:49:03.140: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4564.svc.cluster.local from pod dns-4564/dns-test-afe78f26-c4b9-11e9-80b5-1edf08853c25: the server could not find the requested resource (get pods dns-test-afe78f26-c4b9-11e9-80b5-1edf08853c25)
Aug 22 08:49:03.143: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4564.svc.cluster.local from pod dns-4564/dns-test-afe78f26-c4b9-11e9-80b5-1edf08853c25: the server could not find the requested resource (get pods dns-test-afe78f26-c4b9-11e9-80b5-1edf08853c25)
Aug 22 08:49:03.164: INFO: Lookups using dns-4564/dns-test-afe78f26-c4b9-11e9-80b5-1edf08853c25 failed for: [wheezy_udp@dns-test-service.dns-4564.svc.cluster.local wheezy_tcp@dns-test-service.dns-4564.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4564.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4564.svc.cluster.local jessie_udp@dns-test-service.dns-4564.svc.cluster.local jessie_tcp@dns-test-service.dns-4564.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4564.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4564.svc.cluster.local]

Aug 22 08:49:08.225: INFO: DNS probes using dns-4564/dns-test-afe78f26-c4b9-11e9-80b5-1edf08853c25 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:49:08.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4564" for this suite.
Aug 22 08:49:14.311: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:49:14.451: INFO: namespace dns-4564 deletion completed in 6.150980965s

• [SLOW TEST:13.544 seconds]
[sig-network] DNS
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:49:14.452: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5627
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1619
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 22 08:49:14.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-5627'
Aug 22 08:49:14.719: INFO: stderr: ""
Aug 22 08:49:14.719: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Aug 22 08:49:19.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pod e2e-test-nginx-pod --namespace=kubectl-5627 -o json'
Aug 22 08:49:19.836: INFO: stderr: ""
Aug 22 08:49:19.836: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-08-22T08:49:14Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-5627\",\n        \"resourceVersion\": \"14710502\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-5627/pods/e2e-test-nginx-pod\",\n        \"uid\": \"b8083ae4-c4b9-11e9-92bb-0afbab63fbd8\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-cfrbr\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-10-90-32-24.eu-west-2.compute.internal\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-cfrbr\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-cfrbr\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-22T08:49:14Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-22T08:49:15Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-22T08:49:15Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-22T08:49:14Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://226d0c011af5a4e49ac2141438d88bdecc4e661b8cfd073bde547ab93a80cfe2\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-08-22T08:49:15Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.90.32.24\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.200.40.191\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-08-22T08:49:14Z\"\n    }\n}\n"
STEP: replace the image in the pod
Aug 22 08:49:19.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 replace -f - --namespace=kubectl-5627'
Aug 22 08:49:19.989: INFO: stderr: ""
Aug 22 08:49:19.989: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1624
Aug 22 08:49:19.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 delete pods e2e-test-nginx-pod --namespace=kubectl-5627'
Aug 22 08:49:22.039: INFO: stderr: ""
Aug 22 08:49:22.040: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:49:22.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5627" for this suite.
Aug 22 08:49:28.053: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:49:28.120: INFO: namespace kubectl-5627 deletion completed in 6.077456682s

• [SLOW TEST:13.669 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:49:28.121: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6126
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating cluster-info
Aug 22 08:49:28.252: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 cluster-info'
Aug 22 08:49:28.358: INFO: stderr: ""
Aug 22 08:49:28.358: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.100.200.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.100.200.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:49:28.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6126" for this suite.
Aug 22 08:49:34.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:49:34.438: INFO: namespace kubectl-6126 deletion completed in 6.076536248s

• [SLOW TEST:6.318 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:49:34.439: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-3236
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-3236
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 22 08:49:34.579: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug 22 08:49:56.683: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.200.47.171 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3236 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 22 08:49:56.683: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
Aug 22 08:49:57.755: INFO: Found all expected endpoints: [netserver-0]
Aug 22 08:49:57.758: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.200.40.192 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3236 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 22 08:49:57.758: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
Aug 22 08:49:58.825: INFO: Found all expected endpoints: [netserver-1]
Aug 22 08:49:58.828: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.200.87.70 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3236 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 22 08:49:58.828: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
Aug 22 08:49:59.899: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:49:59.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3236" for this suite.
Aug 22 08:50:17.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:50:17.988: INFO: namespace pod-network-test-3236 deletion completed in 18.08431511s

• [SLOW TEST:43.549 seconds]
[sig-network] Networking
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:50:17.988: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7721
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Aug 22 08:50:18.184: INFO: Waiting up to 5m0s for pod "pod-dddd5561-c4b9-11e9-80b5-1edf08853c25" in namespace "emptydir-7721" to be "success or failure"
Aug 22 08:50:18.198: INFO: Pod "pod-dddd5561-c4b9-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 13.937324ms
Aug 22 08:50:20.201: INFO: Pod "pod-dddd5561-c4b9-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01694541s
STEP: Saw pod success
Aug 22 08:50:20.201: INFO: Pod "pod-dddd5561-c4b9-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:50:20.203: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-dddd5561-c4b9-11e9-80b5-1edf08853c25 container test-container: <nil>
STEP: delete the pod
Aug 22 08:50:20.219: INFO: Waiting for pod pod-dddd5561-c4b9-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:50:20.222: INFO: Pod pod-dddd5561-c4b9-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:50:20.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7721" for this suite.
Aug 22 08:50:26.233: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:50:26.307: INFO: namespace emptydir-7721 deletion completed in 6.082375818s

• [SLOW TEST:8.319 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:50:26.308: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8620
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Aug 22 08:50:28.983: INFO: Successfully updated pod "annotationupdatee2ca8e26-c4b9-11e9-80b5-1edf08853c25"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:50:33.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8620" for this suite.
Aug 22 08:50:55.018: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:50:55.157: INFO: namespace downward-api-8620 deletion completed in 22.1504274s

• [SLOW TEST:28.849 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:50:55.158: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8561
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Aug 22 08:50:55.301: INFO: Waiting up to 5m0s for pod "pod-f3fcec7b-c4b9-11e9-80b5-1edf08853c25" in namespace "emptydir-8561" to be "success or failure"
Aug 22 08:50:55.305: INFO: Pod "pod-f3fcec7b-c4b9-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 3.99144ms
Aug 22 08:50:57.313: INFO: Pod "pod-f3fcec7b-c4b9-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012453275s
STEP: Saw pod success
Aug 22 08:50:57.313: INFO: Pod "pod-f3fcec7b-c4b9-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:50:57.316: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-f3fcec7b-c4b9-11e9-80b5-1edf08853c25 container test-container: <nil>
STEP: delete the pod
Aug 22 08:50:57.331: INFO: Waiting for pod pod-f3fcec7b-c4b9-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:50:57.334: INFO: Pod pod-f3fcec7b-c4b9-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:50:57.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8561" for this suite.
Aug 22 08:51:03.346: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:51:03.436: INFO: namespace emptydir-8561 deletion completed in 6.098297192s

• [SLOW TEST:8.278 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:51:03.437: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-7527
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating server pod server in namespace prestop-7527
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-7527
STEP: Deleting pre-stop pod
Aug 22 08:51:12.621: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:51:12.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-7527" for this suite.
Aug 22 08:51:50.647: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:51:50.735: INFO: namespace prestop-7527 deletion completed in 38.098947425s

• [SLOW TEST:47.299 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:51:50.736: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2033
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-151e6aed-c4ba-11e9-80b5-1edf08853c25
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:51:52.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2033" for this suite.
Aug 22 08:52:14.925: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:52:14.993: INFO: namespace configmap-2033 deletion completed in 22.077121278s

• [SLOW TEST:24.257 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:52:14.994: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1168
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Aug 22 08:52:15.177: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 version'
Aug 22 08:52:15.237: INFO: stderr: ""
Aug 22 08:52:15.237: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.1\", GitCommit:\"b7394102d6ef778017f2ca4046abbaa23b88c290\", GitTreeState:\"clean\", BuildDate:\"2019-04-08T17:11:31Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.1\", GitCommit:\"b7394102d6ef778017f2ca4046abbaa23b88c290\", GitTreeState:\"clean\", BuildDate:\"2019-04-08T17:02:58Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:52:15.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1168" for this suite.
Aug 22 08:52:21.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:52:21.328: INFO: namespace kubectl-1168 deletion completed in 6.086857259s

• [SLOW TEST:6.334 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:52:21.328: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-2588
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Aug 22 08:52:21.462: INFO: Creating deployment "test-recreate-deployment"
Aug 22 08:52:21.467: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Aug 22 08:52:21.485: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Aug 22 08:52:23.491: INFO: Waiting deployment "test-recreate-deployment" to complete
Aug 22 08:52:23.492: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Aug 22 08:52:23.500: INFO: Updating deployment test-recreate-deployment
Aug 22 08:52:23.500: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Aug 22 08:52:23.590: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-2588,SelfLink:/apis/apps/v1/namespaces/deployment-2588/deployments/test-recreate-deployment,UID:27592b4c-c4ba-11e9-92bb-0afbab63fbd8,ResourceVersion:14711125,Generation:2,CreationTimestamp:2019-08-22 08:52:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-08-22 08:52:23 +0000 UTC 2019-08-22 08:52:23 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-08-22 08:52:23 +0000 UTC 2019-08-22 08:52:21 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-c9cbd8684" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Aug 22 08:52:23.592: INFO: New ReplicaSet "test-recreate-deployment-c9cbd8684" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-c9cbd8684,GenerateName:,Namespace:deployment-2588,SelfLink:/apis/apps/v1/namespaces/deployment-2588/replicasets/test-recreate-deployment-c9cbd8684,UID:28959cdf-c4ba-11e9-92bb-0afbab63fbd8,ResourceVersion:14711122,Generation:1,CreationTimestamp:2019-08-22 08:52:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 27592b4c-c4ba-11e9-92bb-0afbab63fbd8 0xc001039280 0xc001039281}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 22 08:52:23.592: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Aug 22 08:52:23.592: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7d57d5ff7c,GenerateName:,Namespace:deployment-2588,SelfLink:/apis/apps/v1/namespaces/deployment-2588/replicasets/test-recreate-deployment-7d57d5ff7c,UID:275a0964-c4ba-11e9-92bb-0afbab63fbd8,ResourceVersion:14711114,Generation:2,CreationTimestamp:2019-08-22 08:52:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 27592b4c-c4ba-11e9-92bb-0afbab63fbd8 0xc001039017 0xc001039018}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 22 08:52:23.594: INFO: Pod "test-recreate-deployment-c9cbd8684-wzcf9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-c9cbd8684-wzcf9,GenerateName:test-recreate-deployment-c9cbd8684-,Namespace:deployment-2588,SelfLink:/api/v1/namespaces/deployment-2588/pods/test-recreate-deployment-c9cbd8684-wzcf9,UID:28966460-c4ba-11e9-92bb-0afbab63fbd8,ResourceVersion:14711126,Generation:0,CreationTimestamp:2019-08-22 08:52:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-c9cbd8684 28959cdf-c4ba-11e9-92bb-0afbab63fbd8 0xc001039c50 0xc001039c51}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6vwzg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6vwzg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6vwzg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-24.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001039cb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001039cd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:52:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:52:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:52:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:52:23 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.24,PodIP:,StartTime:2019-08-22 08:52:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:52:23.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2588" for this suite.
Aug 22 08:52:29.605: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:52:29.676: INFO: namespace deployment-2588 deletion completed in 6.079036179s

• [SLOW TEST:8.349 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:52:29.677: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-822
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Aug 22 08:52:29.830: INFO: Waiting up to 5m0s for pod "downward-api-2c53f334-c4ba-11e9-80b5-1edf08853c25" in namespace "downward-api-822" to be "success or failure"
Aug 22 08:52:29.843: INFO: Pod "downward-api-2c53f334-c4ba-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 12.546004ms
Aug 22 08:52:31.846: INFO: Pod "downward-api-2c53f334-c4ba-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015910061s
STEP: Saw pod success
Aug 22 08:52:31.846: INFO: Pod "downward-api-2c53f334-c4ba-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:52:31.848: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod downward-api-2c53f334-c4ba-11e9-80b5-1edf08853c25 container dapi-container: <nil>
STEP: delete the pod
Aug 22 08:52:31.866: INFO: Waiting for pod downward-api-2c53f334-c4ba-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:52:31.868: INFO: Pod downward-api-2c53f334-c4ba-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:52:31.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-822" for this suite.
Aug 22 08:52:37.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:52:37.950: INFO: namespace downward-api-822 deletion completed in 6.078134114s

• [SLOW TEST:8.273 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:52:37.950: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8269
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Aug 22 08:52:38.093: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3141b016-c4ba-11e9-80b5-1edf08853c25" in namespace "projected-8269" to be "success or failure"
Aug 22 08:52:38.097: INFO: Pod "downwardapi-volume-3141b016-c4ba-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 4.11257ms
Aug 22 08:52:40.100: INFO: Pod "downwardapi-volume-3141b016-c4ba-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007271012s
STEP: Saw pod success
Aug 22 08:52:40.100: INFO: Pod "downwardapi-volume-3141b016-c4ba-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:52:40.102: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod downwardapi-volume-3141b016-c4ba-11e9-80b5-1edf08853c25 container client-container: <nil>
STEP: delete the pod
Aug 22 08:52:40.117: INFO: Waiting for pod downwardapi-volume-3141b016-c4ba-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:52:40.120: INFO: Pod downwardapi-volume-3141b016-c4ba-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:52:40.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8269" for this suite.
Aug 22 08:52:46.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:52:46.199: INFO: namespace projected-8269 deletion completed in 6.076221761s

• [SLOW TEST:8.249 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:52:46.199: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5503
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-362c2116-c4ba-11e9-80b5-1edf08853c25
STEP: Creating a pod to test consume secrets
Aug 22 08:52:46.344: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-362cb95d-c4ba-11e9-80b5-1edf08853c25" in namespace "projected-5503" to be "success or failure"
Aug 22 08:52:46.348: INFO: Pod "pod-projected-secrets-362cb95d-c4ba-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 4.100179ms
Aug 22 08:52:48.352: INFO: Pod "pod-projected-secrets-362cb95d-c4ba-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007973088s
STEP: Saw pod success
Aug 22 08:52:48.352: INFO: Pod "pod-projected-secrets-362cb95d-c4ba-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:52:48.355: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-projected-secrets-362cb95d-c4ba-11e9-80b5-1edf08853c25 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 22 08:52:48.373: INFO: Waiting for pod pod-projected-secrets-362cb95d-c4ba-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:52:48.377: INFO: Pod pod-projected-secrets-362cb95d-c4ba-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:52:48.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5503" for this suite.
Aug 22 08:52:54.398: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:52:54.465: INFO: namespace projected-5503 deletion completed in 6.081992311s

• [SLOW TEST:8.266 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:52:54.465: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1170
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Aug 22 08:52:54.603: INFO: Waiting up to 5m0s for pod "pod-3b191ce8-c4ba-11e9-80b5-1edf08853c25" in namespace "emptydir-1170" to be "success or failure"
Aug 22 08:52:54.610: INFO: Pod "pod-3b191ce8-c4ba-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 6.99786ms
Aug 22 08:52:56.614: INFO: Pod "pod-3b191ce8-c4ba-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01005622s
STEP: Saw pod success
Aug 22 08:52:56.614: INFO: Pod "pod-3b191ce8-c4ba-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:52:56.616: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-3b191ce8-c4ba-11e9-80b5-1edf08853c25 container test-container: <nil>
STEP: delete the pod
Aug 22 08:52:56.632: INFO: Waiting for pod pod-3b191ce8-c4ba-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:52:56.634: INFO: Pod pod-3b191ce8-c4ba-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:52:56.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1170" for this suite.
Aug 22 08:53:02.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:53:02.733: INFO: namespace emptydir-1170 deletion completed in 6.0959879s

• [SLOW TEST:8.268 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:53:02.733: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-5643
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test use defaults
Aug 22 08:53:02.880: INFO: Waiting up to 5m0s for pod "client-containers-4007db18-c4ba-11e9-80b5-1edf08853c25" in namespace "containers-5643" to be "success or failure"
Aug 22 08:53:02.888: INFO: Pod "client-containers-4007db18-c4ba-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 7.996365ms
Aug 22 08:53:04.891: INFO: Pod "client-containers-4007db18-c4ba-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011641077s
STEP: Saw pod success
Aug 22 08:53:04.891: INFO: Pod "client-containers-4007db18-c4ba-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:53:04.894: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod client-containers-4007db18-c4ba-11e9-80b5-1edf08853c25 container test-container: <nil>
STEP: delete the pod
Aug 22 08:53:04.931: INFO: Waiting for pod client-containers-4007db18-c4ba-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:53:04.939: INFO: Pod client-containers-4007db18-c4ba-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:53:04.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5643" for this suite.
Aug 22 08:53:10.973: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:53:11.065: INFO: namespace containers-5643 deletion completed in 6.111101172s

• [SLOW TEST:8.332 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:53:11.065: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-5072
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Aug 22 08:53:11.208: INFO: Pod name rollover-pod: Found 0 pods out of 1
Aug 22 08:53:16.211: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug 22 08:53:16.211: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Aug 22 08:53:18.214: INFO: Creating deployment "test-rollover-deployment"
Aug 22 08:53:18.242: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Aug 22 08:53:20.265: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Aug 22 08:53:20.269: INFO: Ensure that both replica sets have 1 created replica
Aug 22 08:53:20.273: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Aug 22 08:53:20.280: INFO: Updating deployment test-rollover-deployment
Aug 22 08:53:20.280: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Aug 22 08:53:22.290: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Aug 22 08:53:22.294: INFO: Make sure deployment "test-rollover-deployment" is complete
Aug 22 08:53:22.298: INFO: all replica sets need to contain the pod-template-hash label
Aug 22 08:53:22.298: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702060798, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702060798, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702060802, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702060798, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 08:53:24.303: INFO: all replica sets need to contain the pod-template-hash label
Aug 22 08:53:24.303: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702060798, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702060798, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702060802, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702060798, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 08:53:26.303: INFO: all replica sets need to contain the pod-template-hash label
Aug 22 08:53:26.303: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702060798, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702060798, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702060802, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702060798, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 08:53:28.303: INFO: all replica sets need to contain the pod-template-hash label
Aug 22 08:53:28.303: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702060798, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702060798, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702060802, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702060798, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 08:53:30.304: INFO: all replica sets need to contain the pod-template-hash label
Aug 22 08:53:30.304: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702060798, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702060798, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63702060802, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702060798, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 08:53:32.306: INFO: 
Aug 22 08:53:32.306: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Aug 22 08:53:32.312: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-5072,SelfLink:/apis/apps/v1/namespaces/deployment-5072/deployments/test-rollover-deployment,UID:492cd86a-c4ba-11e9-92bb-0afbab63fbd8,ResourceVersion:14711466,Generation:2,CreationTimestamp:2019-08-22 08:53:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-08-22 08:53:18 +0000 UTC 2019-08-22 08:53:18 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-08-22 08:53:32 +0000 UTC 2019-08-22 08:53:18 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-766b4d6c9d" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Aug 22 08:53:32.314: INFO: New ReplicaSet "test-rollover-deployment-766b4d6c9d" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-766b4d6c9d,GenerateName:,Namespace:deployment-5072,SelfLink:/apis/apps/v1/namespaces/deployment-5072/replicasets/test-rollover-deployment-766b4d6c9d,UID:4a681778-c4ba-11e9-92bb-0afbab63fbd8,ResourceVersion:14711455,Generation:2,CreationTimestamp:2019-08-22 08:53:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 492cd86a-c4ba-11e9-92bb-0afbab63fbd8 0xc00208f4d7 0xc00208f4d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Aug 22 08:53:32.314: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Aug 22 08:53:32.314: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-5072,SelfLink:/apis/apps/v1/namespaces/deployment-5072/replicasets/test-rollover-controller,UID:44fe3e83-c4ba-11e9-92bb-0afbab63fbd8,ResourceVersion:14711464,Generation:2,CreationTimestamp:2019-08-22 08:53:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 492cd86a-c4ba-11e9-92bb-0afbab63fbd8 0xc00208f327 0xc00208f328}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 22 08:53:32.314: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6455657675,GenerateName:,Namespace:deployment-5072,SelfLink:/apis/apps/v1/namespaces/deployment-5072/replicasets/test-rollover-deployment-6455657675,UID:4931c57e-c4ba-11e9-92bb-0afbab63fbd8,ResourceVersion:14711423,Generation:2,CreationTimestamp:2019-08-22 08:53:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 492cd86a-c4ba-11e9-92bb-0afbab63fbd8 0xc00208f3f7 0xc00208f3f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 22 08:53:32.317: INFO: Pod "test-rollover-deployment-766b4d6c9d-5c8v5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-766b4d6c9d-5c8v5,GenerateName:test-rollover-deployment-766b4d6c9d-,Namespace:deployment-5072,SelfLink:/api/v1/namespaces/deployment-5072/pods/test-rollover-deployment-766b4d6c9d-5c8v5,UID:4a6d75fd-c4ba-11e9-92bb-0afbab63fbd8,ResourceVersion:14711437,Generation:0,CreationTimestamp:2019-08-22 08:53:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-766b4d6c9d 4a681778-c4ba-11e9-92bb-0afbab63fbd8 0xc001fefae7 0xc001fefae8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-p58mf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-p58mf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-p58mf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-24.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001fefb50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001fefb70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:53:20 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:53:22 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:53:22 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 08:53:20 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.24,PodIP:10.200.40.212,StartTime:2019-08-22 08:53:20 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-08-22 08:53:21 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://1def30874e07a9b719eeb08681dc718e5dd72676345150d5f9995feb6ca8ac09}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:53:32.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5072" for this suite.
Aug 22 08:53:38.329: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:53:38.480: INFO: namespace deployment-5072 deletion completed in 6.159949769s

• [SLOW TEST:27.415 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:53:38.480: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9185
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Aug 22 08:53:38.627: INFO: Waiting up to 5m0s for pod "downwardapi-volume-55565356-c4ba-11e9-80b5-1edf08853c25" in namespace "projected-9185" to be "success or failure"
Aug 22 08:53:38.637: INFO: Pod "downwardapi-volume-55565356-c4ba-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 9.892327ms
Aug 22 08:53:40.641: INFO: Pod "downwardapi-volume-55565356-c4ba-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0132702s
STEP: Saw pod success
Aug 22 08:53:40.641: INFO: Pod "downwardapi-volume-55565356-c4ba-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:53:40.643: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod downwardapi-volume-55565356-c4ba-11e9-80b5-1edf08853c25 container client-container: <nil>
STEP: delete the pod
Aug 22 08:53:40.661: INFO: Waiting for pod downwardapi-volume-55565356-c4ba-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:53:40.664: INFO: Pod downwardapi-volume-55565356-c4ba-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:53:40.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9185" for this suite.
Aug 22 08:53:46.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:53:46.749: INFO: namespace projected-9185 deletion completed in 6.081310305s

• [SLOW TEST:8.269 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:53:46.749: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-750
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:54:46.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-750" for this suite.
Aug 22 08:55:08.918: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:55:09.019: INFO: namespace container-probe-750 deletion completed in 22.113587017s

• [SLOW TEST:82.270 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:55:09.020: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2884
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Aug 22 08:55:09.167: INFO: Waiting up to 5m0s for pod "pod-8b4dc7d4-c4ba-11e9-80b5-1edf08853c25" in namespace "emptydir-2884" to be "success or failure"
Aug 22 08:55:09.171: INFO: Pod "pod-8b4dc7d4-c4ba-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 3.889477ms
Aug 22 08:55:11.174: INFO: Pod "pod-8b4dc7d4-c4ba-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007026069s
STEP: Saw pod success
Aug 22 08:55:11.175: INFO: Pod "pod-8b4dc7d4-c4ba-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:55:11.177: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-8b4dc7d4-c4ba-11e9-80b5-1edf08853c25 container test-container: <nil>
STEP: delete the pod
Aug 22 08:55:11.193: INFO: Waiting for pod pod-8b4dc7d4-c4ba-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:55:11.195: INFO: Pod pod-8b4dc7d4-c4ba-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:55:11.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2884" for this suite.
Aug 22 08:55:17.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:55:17.286: INFO: namespace emptydir-2884 deletion completed in 6.088175196s

• [SLOW TEST:8.266 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:55:17.287: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3874
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Aug 22 08:55:17.429: INFO: Waiting up to 5m0s for pod "downward-api-903a66ad-c4ba-11e9-80b5-1edf08853c25" in namespace "downward-api-3874" to be "success or failure"
Aug 22 08:55:17.433: INFO: Pod "downward-api-903a66ad-c4ba-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 4.419257ms
Aug 22 08:55:19.439: INFO: Pod "downward-api-903a66ad-c4ba-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009990505s
Aug 22 08:55:21.442: INFO: Pod "downward-api-903a66ad-c4ba-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013337507s
STEP: Saw pod success
Aug 22 08:55:21.442: INFO: Pod "downward-api-903a66ad-c4ba-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:55:21.444: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod downward-api-903a66ad-c4ba-11e9-80b5-1edf08853c25 container dapi-container: <nil>
STEP: delete the pod
Aug 22 08:55:21.465: INFO: Waiting for pod downward-api-903a66ad-c4ba-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:55:21.469: INFO: Pod downward-api-903a66ad-c4ba-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:55:21.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3874" for this suite.
Aug 22 08:55:27.490: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:55:27.578: INFO: namespace downward-api-3874 deletion completed in 6.102118546s

• [SLOW TEST:10.291 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:55:27.579: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-6080
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Aug 22 08:55:27.720: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-6080,SelfLink:/api/v1/namespaces/watch-6080/configmaps/e2e-watch-test-configmap-a,UID:965d4c0d-c4ba-11e9-92bb-0afbab63fbd8,ResourceVersion:14711798,Generation:0,CreationTimestamp:2019-08-22 08:55:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 22 08:55:27.720: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-6080,SelfLink:/api/v1/namespaces/watch-6080/configmaps/e2e-watch-test-configmap-a,UID:965d4c0d-c4ba-11e9-92bb-0afbab63fbd8,ResourceVersion:14711798,Generation:0,CreationTimestamp:2019-08-22 08:55:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Aug 22 08:55:37.726: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-6080,SelfLink:/api/v1/namespaces/watch-6080/configmaps/e2e-watch-test-configmap-a,UID:965d4c0d-c4ba-11e9-92bb-0afbab63fbd8,ResourceVersion:14711814,Generation:0,CreationTimestamp:2019-08-22 08:55:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Aug 22 08:55:37.726: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-6080,SelfLink:/api/v1/namespaces/watch-6080/configmaps/e2e-watch-test-configmap-a,UID:965d4c0d-c4ba-11e9-92bb-0afbab63fbd8,ResourceVersion:14711814,Generation:0,CreationTimestamp:2019-08-22 08:55:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Aug 22 08:55:47.733: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-6080,SelfLink:/api/v1/namespaces/watch-6080/configmaps/e2e-watch-test-configmap-a,UID:965d4c0d-c4ba-11e9-92bb-0afbab63fbd8,ResourceVersion:14711830,Generation:0,CreationTimestamp:2019-08-22 08:55:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 22 08:55:47.733: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-6080,SelfLink:/api/v1/namespaces/watch-6080/configmaps/e2e-watch-test-configmap-a,UID:965d4c0d-c4ba-11e9-92bb-0afbab63fbd8,ResourceVersion:14711830,Generation:0,CreationTimestamp:2019-08-22 08:55:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Aug 22 08:55:57.740: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-6080,SelfLink:/api/v1/namespaces/watch-6080/configmaps/e2e-watch-test-configmap-a,UID:965d4c0d-c4ba-11e9-92bb-0afbab63fbd8,ResourceVersion:14711847,Generation:0,CreationTimestamp:2019-08-22 08:55:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 22 08:55:57.741: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-6080,SelfLink:/api/v1/namespaces/watch-6080/configmaps/e2e-watch-test-configmap-a,UID:965d4c0d-c4ba-11e9-92bb-0afbab63fbd8,ResourceVersion:14711847,Generation:0,CreationTimestamp:2019-08-22 08:55:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Aug 22 08:56:07.748: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-6080,SelfLink:/api/v1/namespaces/watch-6080/configmaps/e2e-watch-test-configmap-b,UID:ae38a693-c4ba-11e9-92bb-0afbab63fbd8,ResourceVersion:14711864,Generation:0,CreationTimestamp:2019-08-22 08:56:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 22 08:56:07.748: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-6080,SelfLink:/api/v1/namespaces/watch-6080/configmaps/e2e-watch-test-configmap-b,UID:ae38a693-c4ba-11e9-92bb-0afbab63fbd8,ResourceVersion:14711864,Generation:0,CreationTimestamp:2019-08-22 08:56:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Aug 22 08:56:17.753: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-6080,SelfLink:/api/v1/namespaces/watch-6080/configmaps/e2e-watch-test-configmap-b,UID:ae38a693-c4ba-11e9-92bb-0afbab63fbd8,ResourceVersion:14711880,Generation:0,CreationTimestamp:2019-08-22 08:56:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 22 08:56:17.754: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-6080,SelfLink:/api/v1/namespaces/watch-6080/configmaps/e2e-watch-test-configmap-b,UID:ae38a693-c4ba-11e9-92bb-0afbab63fbd8,ResourceVersion:14711880,Generation:0,CreationTimestamp:2019-08-22 08:56:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:56:27.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6080" for this suite.
Aug 22 08:56:33.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:56:33.881: INFO: namespace watch-6080 deletion completed in 6.123244629s

• [SLOW TEST:66.302 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:56:33.882: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-5242
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Aug 22 08:56:34.025: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:56:35.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-5242" for this suite.
Aug 22 08:56:41.132: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:56:41.202: INFO: namespace custom-resource-definition-5242 deletion completed in 6.079216168s

• [SLOW TEST:7.320 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:56:41.202: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-1291
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Aug 22 08:56:41.339: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:56:45.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1291" for this suite.
Aug 22 08:56:51.174: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:56:51.255: INFO: namespace init-container-1291 deletion completed in 6.093048622s

• [SLOW TEST:10.053 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:56:51.255: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3941
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-c83e1ba9-c4ba-11e9-80b5-1edf08853c25
STEP: Creating a pod to test consume secrets
Aug 22 08:56:51.409: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c83eb4a9-c4ba-11e9-80b5-1edf08853c25" in namespace "projected-3941" to be "success or failure"
Aug 22 08:56:51.413: INFO: Pod "pod-projected-secrets-c83eb4a9-c4ba-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 4.113368ms
Aug 22 08:56:53.415: INFO: Pod "pod-projected-secrets-c83eb4a9-c4ba-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00669223s
STEP: Saw pod success
Aug 22 08:56:53.415: INFO: Pod "pod-projected-secrets-c83eb4a9-c4ba-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:56:53.417: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-projected-secrets-c83eb4a9-c4ba-11e9-80b5-1edf08853c25 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 22 08:56:53.433: INFO: Waiting for pod pod-projected-secrets-c83eb4a9-c4ba-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:56:53.435: INFO: Pod pod-projected-secrets-c83eb4a9-c4ba-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:56:53.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3941" for this suite.
Aug 22 08:56:59.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:56:59.524: INFO: namespace projected-3941 deletion completed in 6.08613913s

• [SLOW TEST:8.269 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:56:59.524: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-883
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1583
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 22 08:56:59.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-883'
Aug 22 08:56:59.878: INFO: stderr: ""
Aug 22 08:56:59.878: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1588
Aug 22 08:56:59.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 delete pods e2e-test-nginx-pod --namespace=kubectl-883'
Aug 22 08:57:09.641: INFO: stderr: ""
Aug 22 08:57:09.641: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:57:09.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-883" for this suite.
Aug 22 08:57:15.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:57:15.731: INFO: namespace kubectl-883 deletion completed in 6.085800865s

• [SLOW TEST:16.207 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:57:15.731: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3252
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Aug 22 08:57:15.872: INFO: Waiting up to 5m0s for pod "pod-d6d3701c-c4ba-11e9-80b5-1edf08853c25" in namespace "emptydir-3252" to be "success or failure"
Aug 22 08:57:15.877: INFO: Pod "pod-d6d3701c-c4ba-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 4.710295ms
Aug 22 08:57:17.881: INFO: Pod "pod-d6d3701c-c4ba-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008463761s
STEP: Saw pod success
Aug 22 08:57:17.881: INFO: Pod "pod-d6d3701c-c4ba-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 08:57:17.884: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-d6d3701c-c4ba-11e9-80b5-1edf08853c25 container test-container: <nil>
STEP: delete the pod
Aug 22 08:57:17.903: INFO: Waiting for pod pod-d6d3701c-c4ba-11e9-80b5-1edf08853c25 to disappear
Aug 22 08:57:17.906: INFO: Pod pod-d6d3701c-c4ba-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:57:17.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3252" for this suite.
Aug 22 08:57:23.923: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:57:24.015: INFO: namespace emptydir-3252 deletion completed in 6.103760255s

• [SLOW TEST:8.284 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:57:24.016: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-3311
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-3311
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Aug 22 08:57:24.180: INFO: Found 0 stateful pods, waiting for 3
Aug 22 08:57:34.184: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 22 08:57:34.184: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 22 08:57:34.184: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Aug 22 08:57:34.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 exec --namespace=statefulset-3311 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 22 08:57:34.361: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 22 08:57:34.361: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 22 08:57:34.361: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Aug 22 08:57:44.389: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Aug 22 08:57:54.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 exec --namespace=statefulset-3311 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 22 08:57:54.588: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 22 08:57:54.588: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 22 08:57:54.588: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 22 08:58:04.605: INFO: Waiting for StatefulSet statefulset-3311/ss2 to complete update
Aug 22 08:58:04.605: INFO: Waiting for Pod statefulset-3311/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Aug 22 08:58:14.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 exec --namespace=statefulset-3311 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 22 08:58:14.762: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 22 08:58:14.762: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 22 08:58:14.762: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 22 08:58:24.790: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Aug 22 08:58:34.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 exec --namespace=statefulset-3311 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 22 08:58:34.959: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 22 08:58:34.959: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 22 08:58:34.959: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 22 08:58:54.977: INFO: Waiting for StatefulSet statefulset-3311/ss2 to complete update
Aug 22 08:58:54.977: INFO: Waiting for Pod statefulset-3311/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Aug 22 08:59:04.982: INFO: Deleting all statefulset in ns statefulset-3311
Aug 22 08:59:04.988: INFO: Scaling statefulset ss2 to 0
Aug 22 08:59:15.011: INFO: Waiting for statefulset status.replicas updated to 0
Aug 22 08:59:15.015: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:59:15.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3311" for this suite.
Aug 22 08:59:21.053: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 08:59:21.155: INFO: namespace statefulset-3311 deletion completed in 6.118253517s

• [SLOW TEST:117.139 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 08:59:21.155: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-1121
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Aug 22 08:59:21.312: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Aug 22 08:59:21.332: INFO: Number of nodes with available pods: 0
Aug 22 08:59:21.332: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Aug 22 08:59:22.340: INFO: Number of nodes with available pods: 0
Aug 22 08:59:22.340: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Aug 22 08:59:23.343: INFO: Number of nodes with available pods: 2
Aug 22 08:59:23.343: INFO: Node ip-10-90-32-22.eu-west-2.compute.internal is running more than one daemon pod
Aug 22 08:59:24.339: INFO: Number of nodes with available pods: 3
Aug 22 08:59:24.339: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Aug 22 08:59:24.363: INFO: Wrong image for pod: daemon-set-5ckmj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 22 08:59:24.363: INFO: Wrong image for pod: daemon-set-64k7v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 22 08:59:24.363: INFO: Wrong image for pod: daemon-set-slzcf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 22 08:59:25.380: INFO: Wrong image for pod: daemon-set-5ckmj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 22 08:59:25.380: INFO: Wrong image for pod: daemon-set-64k7v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 22 08:59:25.380: INFO: Wrong image for pod: daemon-set-slzcf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 22 08:59:26.381: INFO: Wrong image for pod: daemon-set-5ckmj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 22 08:59:26.381: INFO: Wrong image for pod: daemon-set-64k7v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 22 08:59:26.381: INFO: Wrong image for pod: daemon-set-slzcf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 22 08:59:27.382: INFO: Wrong image for pod: daemon-set-5ckmj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 22 08:59:27.382: INFO: Wrong image for pod: daemon-set-64k7v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 22 08:59:27.382: INFO: Wrong image for pod: daemon-set-slzcf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 22 08:59:27.382: INFO: Pod daemon-set-slzcf is not available
Aug 22 08:59:28.379: INFO: Wrong image for pod: daemon-set-5ckmj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 22 08:59:28.379: INFO: Wrong image for pod: daemon-set-64k7v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 22 08:59:28.379: INFO: Pod daemon-set-dftpp is not available
Aug 22 08:59:29.379: INFO: Wrong image for pod: daemon-set-5ckmj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 22 08:59:29.380: INFO: Wrong image for pod: daemon-set-64k7v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 22 08:59:29.380: INFO: Pod daemon-set-dftpp is not available
Aug 22 08:59:30.379: INFO: Wrong image for pod: daemon-set-5ckmj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 22 08:59:30.380: INFO: Pod daemon-set-5ckmj is not available
Aug 22 08:59:30.380: INFO: Wrong image for pod: daemon-set-64k7v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 22 08:59:31.380: INFO: Wrong image for pod: daemon-set-5ckmj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 22 08:59:31.380: INFO: Pod daemon-set-5ckmj is not available
Aug 22 08:59:31.380: INFO: Wrong image for pod: daemon-set-64k7v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 22 08:59:32.379: INFO: Wrong image for pod: daemon-set-5ckmj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 22 08:59:32.379: INFO: Pod daemon-set-5ckmj is not available
Aug 22 08:59:32.379: INFO: Wrong image for pod: daemon-set-64k7v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 22 08:59:33.379: INFO: Wrong image for pod: daemon-set-5ckmj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 22 08:59:33.379: INFO: Pod daemon-set-5ckmj is not available
Aug 22 08:59:33.379: INFO: Wrong image for pod: daemon-set-64k7v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 22 08:59:34.379: INFO: Wrong image for pod: daemon-set-5ckmj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 22 08:59:34.379: INFO: Pod daemon-set-5ckmj is not available
Aug 22 08:59:34.379: INFO: Wrong image for pod: daemon-set-64k7v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 22 08:59:35.379: INFO: Wrong image for pod: daemon-set-5ckmj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 22 08:59:35.379: INFO: Pod daemon-set-5ckmj is not available
Aug 22 08:59:35.379: INFO: Wrong image for pod: daemon-set-64k7v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 22 08:59:36.380: INFO: Wrong image for pod: daemon-set-5ckmj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 22 08:59:36.380: INFO: Pod daemon-set-5ckmj is not available
Aug 22 08:59:36.380: INFO: Wrong image for pod: daemon-set-64k7v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 22 08:59:37.379: INFO: Wrong image for pod: daemon-set-5ckmj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 22 08:59:37.379: INFO: Pod daemon-set-5ckmj is not available
Aug 22 08:59:37.379: INFO: Wrong image for pod: daemon-set-64k7v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 22 08:59:38.379: INFO: Wrong image for pod: daemon-set-5ckmj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 22 08:59:38.379: INFO: Pod daemon-set-5ckmj is not available
Aug 22 08:59:38.379: INFO: Wrong image for pod: daemon-set-64k7v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 22 08:59:39.380: INFO: Wrong image for pod: daemon-set-5ckmj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 22 08:59:39.380: INFO: Pod daemon-set-5ckmj is not available
Aug 22 08:59:39.380: INFO: Wrong image for pod: daemon-set-64k7v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 22 08:59:40.379: INFO: Pod daemon-set-4ffr4 is not available
Aug 22 08:59:40.383: INFO: Wrong image for pod: daemon-set-64k7v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 22 08:59:41.379: INFO: Pod daemon-set-4ffr4 is not available
Aug 22 08:59:41.380: INFO: Wrong image for pod: daemon-set-64k7v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 22 08:59:42.379: INFO: Wrong image for pod: daemon-set-64k7v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 22 08:59:43.379: INFO: Wrong image for pod: daemon-set-64k7v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 22 08:59:43.379: INFO: Pod daemon-set-64k7v is not available
Aug 22 08:59:44.379: INFO: Pod daemon-set-nclrz is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Aug 22 08:59:44.393: INFO: Number of nodes with available pods: 2
Aug 22 08:59:44.393: INFO: Node ip-10-90-32-23.eu-west-2.compute.internal is running more than one daemon pod
Aug 22 08:59:45.399: INFO: Number of nodes with available pods: 2
Aug 22 08:59:45.399: INFO: Node ip-10-90-32-23.eu-west-2.compute.internal is running more than one daemon pod
Aug 22 08:59:46.399: INFO: Number of nodes with available pods: 3
Aug 22 08:59:46.399: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1121, will wait for the garbage collector to delete the pods
Aug 22 08:59:46.468: INFO: Deleting DaemonSet.extensions daemon-set took: 6.795977ms
Aug 22 08:59:46.768: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.25521ms
Aug 22 08:59:59.471: INFO: Number of nodes with available pods: 0
Aug 22 08:59:59.471: INFO: Number of running nodes: 0, number of available pods: 0
Aug 22 08:59:59.473: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1121/daemonsets","resourceVersion":"14712995"},"items":null}

Aug 22 08:59:59.475: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1121/pods","resourceVersion":"14712995"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 08:59:59.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1121" for this suite.
Aug 22 09:00:05.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 09:00:05.597: INFO: namespace daemonsets-1121 deletion completed in 6.10784877s

• [SLOW TEST:44.441 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 09:00:05.597: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-5334
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Aug 22 09:00:05.737: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Aug 22 09:00:05.755: INFO: Pod name sample-pod: Found 0 pods out of 1
Aug 22 09:00:10.758: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug 22 09:00:10.759: INFO: Creating deployment "test-rolling-update-deployment"
Aug 22 09:00:10.767: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Aug 22 09:00:10.781: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Aug 22 09:00:12.787: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Aug 22 09:00:12.789: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Aug 22 09:00:12.795: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-5334,SelfLink:/apis/apps/v1/namespaces/deployment-5334/deployments/test-rolling-update-deployment,UID:3f1239e0-c4bb-11e9-92bb-0afbab63fbd8,ResourceVersion:14713113,Generation:1,CreationTimestamp:2019-08-22 09:00:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-08-22 09:00:10 +0000 UTC 2019-08-22 09:00:10 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-08-22 09:00:12 +0000 UTC 2019-08-22 09:00:10 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-67599b4d9" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Aug 22 09:00:12.797: INFO: New ReplicaSet "test-rolling-update-deployment-67599b4d9" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-67599b4d9,GenerateName:,Namespace:deployment-5334,SelfLink:/apis/apps/v1/namespaces/deployment-5334/replicasets/test-rolling-update-deployment-67599b4d9,UID:3f1522b9-c4bb-11e9-92bb-0afbab63fbd8,ResourceVersion:14713102,Generation:1,CreationTimestamp:2019-08-22 09:00:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 3f1239e0-c4bb-11e9-92bb-0afbab63fbd8 0xc002ae4800 0xc002ae4801}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Aug 22 09:00:12.797: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Aug 22 09:00:12.797: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-5334,SelfLink:/apis/apps/v1/namespaces/deployment-5334/replicasets/test-rolling-update-controller,UID:3c1400ea-c4bb-11e9-92bb-0afbab63fbd8,ResourceVersion:14713111,Generation:2,CreationTimestamp:2019-08-22 09:00:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 3f1239e0-c4bb-11e9-92bb-0afbab63fbd8 0xc002ae4737 0xc002ae4738}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 22 09:00:12.800: INFO: Pod "test-rolling-update-deployment-67599b4d9-fckdg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-67599b4d9-fckdg,GenerateName:test-rolling-update-deployment-67599b4d9-,Namespace:deployment-5334,SelfLink:/api/v1/namespaces/deployment-5334/pods/test-rolling-update-deployment-67599b4d9-fckdg,UID:3f162def-c4bb-11e9-92bb-0afbab63fbd8,ResourceVersion:14713101,Generation:0,CreationTimestamp:2019-08-22 09:00:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-67599b4d9 3f1522b9-c4bb-11e9-92bb-0afbab63fbd8 0xc002ae5120 0xc002ae5121}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-rwdv9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rwdv9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-rwdv9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-90-32-24.eu-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002ae5180} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002ae51a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 09:00:10 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 09:00:12 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 09:00:12 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-22 09:00:10 +0000 UTC  }],Message:,Reason:,HostIP:10.90.32.24,PodIP:10.200.40.235,StartTime:2019-08-22 09:00:10 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-08-22 09:00:11 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://415b2a79b87563343ff17b8af9e60043838b5a08d715043ef03d892f9b083ab2}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 09:00:12.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5334" for this suite.
Aug 22 09:00:18.813: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 09:00:18.892: INFO: namespace deployment-5334 deletion completed in 6.088982749s

• [SLOW TEST:13.295 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 09:00:18.892: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7933
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-43ffa55b-c4bb-11e9-80b5-1edf08853c25
STEP: Creating a pod to test consume configMaps
Aug 22 09:00:19.037: INFO: Waiting up to 5m0s for pod "pod-configmaps-44003271-c4bb-11e9-80b5-1edf08853c25" in namespace "configmap-7933" to be "success or failure"
Aug 22 09:00:19.041: INFO: Pod "pod-configmaps-44003271-c4bb-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 4.127352ms
Aug 22 09:00:21.046: INFO: Pod "pod-configmaps-44003271-c4bb-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00912863s
STEP: Saw pod success
Aug 22 09:00:21.046: INFO: Pod "pod-configmaps-44003271-c4bb-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 09:00:21.054: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-configmaps-44003271-c4bb-11e9-80b5-1edf08853c25 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 22 09:00:21.073: INFO: Waiting for pod pod-configmaps-44003271-c4bb-11e9-80b5-1edf08853c25 to disappear
Aug 22 09:00:21.077: INFO: Pod pod-configmaps-44003271-c4bb-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 09:00:21.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7933" for this suite.
Aug 22 09:00:27.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 09:00:27.173: INFO: namespace configmap-7933 deletion completed in 6.092315537s

• [SLOW TEST:8.281 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 09:00:27.174: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3578
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Aug 22 09:00:27.306: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 create -f - --namespace=kubectl-3578'
Aug 22 09:00:27.470: INFO: stderr: ""
Aug 22 09:00:27.470: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 22 09:00:27.470: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3578'
Aug 22 09:00:27.555: INFO: stderr: ""
Aug 22 09:00:27.555: INFO: stdout: "update-demo-nautilus-cf8hr update-demo-nautilus-g4gbc "
Aug 22 09:00:27.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pods update-demo-nautilus-cf8hr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3578'
Aug 22 09:00:27.621: INFO: stderr: ""
Aug 22 09:00:27.621: INFO: stdout: ""
Aug 22 09:00:27.621: INFO: update-demo-nautilus-cf8hr is created but not running
Aug 22 09:00:32.621: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3578'
Aug 22 09:00:32.689: INFO: stderr: ""
Aug 22 09:00:32.689: INFO: stdout: "update-demo-nautilus-cf8hr update-demo-nautilus-g4gbc "
Aug 22 09:00:32.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pods update-demo-nautilus-cf8hr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3578'
Aug 22 09:00:32.752: INFO: stderr: ""
Aug 22 09:00:32.752: INFO: stdout: "true"
Aug 22 09:00:32.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pods update-demo-nautilus-cf8hr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3578'
Aug 22 09:00:32.816: INFO: stderr: ""
Aug 22 09:00:32.816: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 22 09:00:32.816: INFO: validating pod update-demo-nautilus-cf8hr
Aug 22 09:00:32.823: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 22 09:00:32.823: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 22 09:00:32.823: INFO: update-demo-nautilus-cf8hr is verified up and running
Aug 22 09:00:32.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pods update-demo-nautilus-g4gbc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3578'
Aug 22 09:00:32.911: INFO: stderr: ""
Aug 22 09:00:32.911: INFO: stdout: "true"
Aug 22 09:00:32.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pods update-demo-nautilus-g4gbc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3578'
Aug 22 09:00:32.979: INFO: stderr: ""
Aug 22 09:00:32.979: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 22 09:00:32.979: INFO: validating pod update-demo-nautilus-g4gbc
Aug 22 09:00:32.984: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 22 09:00:32.984: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 22 09:00:32.984: INFO: update-demo-nautilus-g4gbc is verified up and running
STEP: using delete to clean up resources
Aug 22 09:00:32.984: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 delete --grace-period=0 --force -f - --namespace=kubectl-3578'
Aug 22 09:00:33.061: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 22 09:00:33.061: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Aug 22 09:00:33.061: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-3578'
Aug 22 09:00:33.232: INFO: stderr: "No resources found.\n"
Aug 22 09:00:33.232: INFO: stdout: ""
Aug 22 09:00:33.232: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pods -l name=update-demo --namespace=kubectl-3578 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 22 09:00:33.357: INFO: stderr: ""
Aug 22 09:00:33.357: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 09:00:33.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3578" for this suite.
Aug 22 09:00:55.372: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 09:00:55.508: INFO: namespace kubectl-3578 deletion completed in 22.147368029s

• [SLOW TEST:28.334 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 09:00:55.508: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8348
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-59da2ee7-c4bb-11e9-80b5-1edf08853c25
STEP: Creating a pod to test consume configMaps
Aug 22 09:00:55.704: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-59dabb6a-c4bb-11e9-80b5-1edf08853c25" in namespace "projected-8348" to be "success or failure"
Aug 22 09:00:55.708: INFO: Pod "pod-projected-configmaps-59dabb6a-c4bb-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 4.279907ms
Aug 22 09:00:57.711: INFO: Pod "pod-projected-configmaps-59dabb6a-c4bb-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00774909s
STEP: Saw pod success
Aug 22 09:00:57.711: INFO: Pod "pod-projected-configmaps-59dabb6a-c4bb-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 09:00:57.714: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-projected-configmaps-59dabb6a-c4bb-11e9-80b5-1edf08853c25 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 22 09:00:57.737: INFO: Waiting for pod pod-projected-configmaps-59dabb6a-c4bb-11e9-80b5-1edf08853c25 to disappear
Aug 22 09:00:57.742: INFO: Pod pod-projected-configmaps-59dabb6a-c4bb-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 09:00:57.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8348" for this suite.
Aug 22 09:01:03.757: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 09:01:03.833: INFO: namespace projected-8348 deletion completed in 6.086783023s

• [SLOW TEST:8.325 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 09:01:03.834: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-9343
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Aug 22 09:01:08.008: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 22 09:01:08.010: INFO: Pod pod-with-prestop-http-hook still exists
Aug 22 09:01:10.011: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 22 09:01:10.014: INFO: Pod pod-with-prestop-http-hook still exists
Aug 22 09:01:12.011: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 22 09:01:12.014: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 09:01:12.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9343" for this suite.
Aug 22 09:01:34.035: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 09:01:34.125: INFO: namespace container-lifecycle-hook-9343 deletion completed in 22.101725227s

• [SLOW TEST:30.292 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 09:01:34.126: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-520
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting the proxy server
Aug 22 09:01:34.260: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-901739697 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 09:01:34.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-520" for this suite.
Aug 22 09:01:40.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 09:01:40.472: INFO: namespace kubectl-520 deletion completed in 6.150269972s

• [SLOW TEST:6.346 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 09:01:40.472: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1127
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Aug 22 09:01:40.662: INFO: Waiting up to 5m0s for pod "downwardapi-volume-74a724e8-c4bb-11e9-80b5-1edf08853c25" in namespace "projected-1127" to be "success or failure"
Aug 22 09:01:40.670: INFO: Pod "downwardapi-volume-74a724e8-c4bb-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 7.96793ms
Aug 22 09:01:42.673: INFO: Pod "downwardapi-volume-74a724e8-c4bb-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01123232s
STEP: Saw pod success
Aug 22 09:01:42.673: INFO: Pod "downwardapi-volume-74a724e8-c4bb-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 09:01:42.675: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod downwardapi-volume-74a724e8-c4bb-11e9-80b5-1edf08853c25 container client-container: <nil>
STEP: delete the pod
Aug 22 09:01:42.691: INFO: Waiting for pod downwardapi-volume-74a724e8-c4bb-11e9-80b5-1edf08853c25 to disappear
Aug 22 09:01:42.694: INFO: Pod downwardapi-volume-74a724e8-c4bb-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 09:01:42.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1127" for this suite.
Aug 22 09:01:48.708: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 09:01:48.792: INFO: namespace projected-1127 deletion completed in 6.094688178s

• [SLOW TEST:8.320 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 09:01:48.792: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-4002
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0822 09:01:54.965590      14 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 22 09:01:54.965: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 09:01:54.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4002" for this suite.
Aug 22 09:02:00.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 09:02:01.114: INFO: namespace gc-4002 deletion completed in 6.145034013s

• [SLOW TEST:12.321 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 09:02:01.114: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8750
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Aug 22 09:02:01.327: INFO: Waiting up to 5m0s for pod "downwardapi-volume-80f8044f-c4bb-11e9-80b5-1edf08853c25" in namespace "downward-api-8750" to be "success or failure"
Aug 22 09:02:01.349: INFO: Pod "downwardapi-volume-80f8044f-c4bb-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 22.09672ms
Aug 22 09:02:03.352: INFO: Pod "downwardapi-volume-80f8044f-c4bb-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025242015s
STEP: Saw pod success
Aug 22 09:02:03.352: INFO: Pod "downwardapi-volume-80f8044f-c4bb-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 09:02:03.354: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod downwardapi-volume-80f8044f-c4bb-11e9-80b5-1edf08853c25 container client-container: <nil>
STEP: delete the pod
Aug 22 09:02:03.370: INFO: Waiting for pod downwardapi-volume-80f8044f-c4bb-11e9-80b5-1edf08853c25 to disappear
Aug 22 09:02:03.375: INFO: Pod downwardapi-volume-80f8044f-c4bb-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 09:02:03.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8750" for this suite.
Aug 22 09:02:09.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 09:02:09.463: INFO: namespace downward-api-8750 deletion completed in 6.084217135s

• [SLOW TEST:8.349 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 09:02:09.463: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8807
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Aug 22 09:02:09.606: INFO: Waiting up to 5m0s for pod "downward-api-85e7b26f-c4bb-11e9-80b5-1edf08853c25" in namespace "downward-api-8807" to be "success or failure"
Aug 22 09:02:09.614: INFO: Pod "downward-api-85e7b26f-c4bb-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 8.091185ms
Aug 22 09:02:11.617: INFO: Pod "downward-api-85e7b26f-c4bb-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011100808s
STEP: Saw pod success
Aug 22 09:02:11.617: INFO: Pod "downward-api-85e7b26f-c4bb-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 09:02:11.619: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod downward-api-85e7b26f-c4bb-11e9-80b5-1edf08853c25 container dapi-container: <nil>
STEP: delete the pod
Aug 22 09:02:11.636: INFO: Waiting for pod downward-api-85e7b26f-c4bb-11e9-80b5-1edf08853c25 to disappear
Aug 22 09:02:11.639: INFO: Pod downward-api-85e7b26f-c4bb-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 09:02:11.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8807" for this suite.
Aug 22 09:02:17.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 09:02:17.722: INFO: namespace downward-api-8807 deletion completed in 6.080336921s

• [SLOW TEST:8.259 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 09:02:17.723: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-3987
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Aug 22 09:02:17.869: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3987,SelfLink:/api/v1/namespaces/watch-3987/configmaps/e2e-watch-test-label-changed,UID:8ad3be74-c4bb-11e9-92bb-0afbab63fbd8,ResourceVersion:14713798,Generation:0,CreationTimestamp:2019-08-22 09:02:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 22 09:02:17.870: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3987,SelfLink:/api/v1/namespaces/watch-3987/configmaps/e2e-watch-test-label-changed,UID:8ad3be74-c4bb-11e9-92bb-0afbab63fbd8,ResourceVersion:14713799,Generation:0,CreationTimestamp:2019-08-22 09:02:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Aug 22 09:02:17.870: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3987,SelfLink:/api/v1/namespaces/watch-3987/configmaps/e2e-watch-test-label-changed,UID:8ad3be74-c4bb-11e9-92bb-0afbab63fbd8,ResourceVersion:14713800,Generation:0,CreationTimestamp:2019-08-22 09:02:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Aug 22 09:02:27.889: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3987,SelfLink:/api/v1/namespaces/watch-3987/configmaps/e2e-watch-test-label-changed,UID:8ad3be74-c4bb-11e9-92bb-0afbab63fbd8,ResourceVersion:14713817,Generation:0,CreationTimestamp:2019-08-22 09:02:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 22 09:02:27.890: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3987,SelfLink:/api/v1/namespaces/watch-3987/configmaps/e2e-watch-test-label-changed,UID:8ad3be74-c4bb-11e9-92bb-0afbab63fbd8,ResourceVersion:14713818,Generation:0,CreationTimestamp:2019-08-22 09:02:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Aug 22 09:02:27.890: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3987,SelfLink:/api/v1/namespaces/watch-3987/configmaps/e2e-watch-test-label-changed,UID:8ad3be74-c4bb-11e9-92bb-0afbab63fbd8,ResourceVersion:14713819,Generation:0,CreationTimestamp:2019-08-22 09:02:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 09:02:27.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3987" for this suite.
Aug 22 09:02:33.906: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 09:02:33.981: INFO: namespace watch-3987 deletion completed in 6.087595759s

• [SLOW TEST:16.258 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 09:02:33.982: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-9157
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test hostPath mode
Aug 22 09:02:34.129: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-9157" to be "success or failure"
Aug 22 09:02:34.133: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.004182ms
Aug 22 09:02:36.137: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007524102s
Aug 22 09:02:38.140: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010849504s
STEP: Saw pod success
Aug 22 09:02:38.140: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Aug 22 09:02:38.142: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Aug 22 09:02:38.160: INFO: Waiting for pod pod-host-path-test to disappear
Aug 22 09:02:38.167: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 09:02:38.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-9157" for this suite.
Aug 22 09:02:44.180: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 09:02:44.267: INFO: namespace hostpath-9157 deletion completed in 6.095477175s

• [SLOW TEST:10.286 seconds]
[sig-storage] HostPath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 09:02:44.267: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5222
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the initial replication controller
Aug 22 09:02:44.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 create -f - --namespace=kubectl-5222'
Aug 22 09:02:44.557: INFO: stderr: ""
Aug 22 09:02:44.557: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 22 09:02:44.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5222'
Aug 22 09:02:44.650: INFO: stderr: ""
Aug 22 09:02:44.650: INFO: stdout: "update-demo-nautilus-462rr update-demo-nautilus-hl8p9 "
Aug 22 09:02:44.650: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pods update-demo-nautilus-462rr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5222'
Aug 22 09:02:44.718: INFO: stderr: ""
Aug 22 09:02:44.718: INFO: stdout: ""
Aug 22 09:02:44.718: INFO: update-demo-nautilus-462rr is created but not running
Aug 22 09:02:49.718: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5222'
Aug 22 09:02:49.785: INFO: stderr: ""
Aug 22 09:02:49.785: INFO: stdout: "update-demo-nautilus-462rr update-demo-nautilus-hl8p9 "
Aug 22 09:02:49.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pods update-demo-nautilus-462rr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5222'
Aug 22 09:02:49.853: INFO: stderr: ""
Aug 22 09:02:49.853: INFO: stdout: "true"
Aug 22 09:02:49.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pods update-demo-nautilus-462rr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5222'
Aug 22 09:02:49.919: INFO: stderr: ""
Aug 22 09:02:49.919: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 22 09:02:49.919: INFO: validating pod update-demo-nautilus-462rr
Aug 22 09:02:49.922: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 22 09:02:49.922: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 22 09:02:49.922: INFO: update-demo-nautilus-462rr is verified up and running
Aug 22 09:02:49.923: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pods update-demo-nautilus-hl8p9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5222'
Aug 22 09:02:49.988: INFO: stderr: ""
Aug 22 09:02:49.988: INFO: stdout: "true"
Aug 22 09:02:49.988: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pods update-demo-nautilus-hl8p9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5222'
Aug 22 09:02:50.054: INFO: stderr: ""
Aug 22 09:02:50.055: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 22 09:02:50.055: INFO: validating pod update-demo-nautilus-hl8p9
Aug 22 09:02:50.058: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 22 09:02:50.058: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 22 09:02:50.058: INFO: update-demo-nautilus-hl8p9 is verified up and running
STEP: rolling-update to new replication controller
Aug 22 09:02:50.060: INFO: scanned /root for discovery docs: <nil>
Aug 22 09:02:50.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-5222'
Aug 22 09:03:12.417: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Aug 22 09:03:12.417: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 22 09:03:12.417: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5222'
Aug 22 09:03:12.485: INFO: stderr: ""
Aug 22 09:03:12.486: INFO: stdout: "update-demo-kitten-mxljh update-demo-kitten-xv5xn "
Aug 22 09:03:12.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pods update-demo-kitten-mxljh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5222'
Aug 22 09:03:12.551: INFO: stderr: ""
Aug 22 09:03:12.551: INFO: stdout: "true"
Aug 22 09:03:12.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pods update-demo-kitten-mxljh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5222'
Aug 22 09:03:12.622: INFO: stderr: ""
Aug 22 09:03:12.622: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Aug 22 09:03:12.622: INFO: validating pod update-demo-kitten-mxljh
Aug 22 09:03:12.626: INFO: got data: {
  "image": "kitten.jpg"
}

Aug 22 09:03:12.626: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Aug 22 09:03:12.626: INFO: update-demo-kitten-mxljh is verified up and running
Aug 22 09:03:12.626: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pods update-demo-kitten-xv5xn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5222'
Aug 22 09:03:12.694: INFO: stderr: ""
Aug 22 09:03:12.694: INFO: stdout: "true"
Aug 22 09:03:12.695: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-901739697 get pods update-demo-kitten-xv5xn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5222'
Aug 22 09:03:12.760: INFO: stderr: ""
Aug 22 09:03:12.760: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Aug 22 09:03:12.760: INFO: validating pod update-demo-kitten-xv5xn
Aug 22 09:03:12.763: INFO: got data: {
  "image": "kitten.jpg"
}

Aug 22 09:03:12.763: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Aug 22 09:03:12.763: INFO: update-demo-kitten-xv5xn is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 09:03:12.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5222" for this suite.
Aug 22 09:03:34.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 09:03:34.871: INFO: namespace kubectl-5222 deletion completed in 22.103988797s

• [SLOW TEST:50.603 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 09:03:34.871: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-4895
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Aug 22 09:03:35.021: INFO: Pod name pod-release: Found 0 pods out of 1
Aug 22 09:03:40.024: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 09:03:40.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4895" for this suite.
Aug 22 09:03:46.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 09:03:46.163: INFO: namespace replication-controller-4895 deletion completed in 6.101002608s

• [SLOW TEST:11.291 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 09:03:46.163: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9909
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Aug 22 09:03:46.303: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bf8a6716-c4bb-11e9-80b5-1edf08853c25" in namespace "projected-9909" to be "success or failure"
Aug 22 09:03:46.311: INFO: Pod "downwardapi-volume-bf8a6716-c4bb-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 8.458803ms
Aug 22 09:03:48.315: INFO: Pod "downwardapi-volume-bf8a6716-c4bb-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011842725s
STEP: Saw pod success
Aug 22 09:03:48.315: INFO: Pod "downwardapi-volume-bf8a6716-c4bb-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 09:03:48.317: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod downwardapi-volume-bf8a6716-c4bb-11e9-80b5-1edf08853c25 container client-container: <nil>
STEP: delete the pod
Aug 22 09:03:48.333: INFO: Waiting for pod downwardapi-volume-bf8a6716-c4bb-11e9-80b5-1edf08853c25 to disappear
Aug 22 09:03:48.336: INFO: Pod downwardapi-volume-bf8a6716-c4bb-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 09:03:48.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9909" for this suite.
Aug 22 09:03:54.349: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 09:03:54.415: INFO: namespace projected-9909 deletion completed in 6.07431453s

• [SLOW TEST:8.253 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 09:03:54.416: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-3861
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service multi-endpoint-test in namespace services-3861
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3861 to expose endpoints map[]
Aug 22 09:03:54.564: INFO: successfully validated that service multi-endpoint-test in namespace services-3861 exposes endpoints map[] (3.674737ms elapsed)
STEP: Creating pod pod1 in namespace services-3861
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3861 to expose endpoints map[pod1:[100]]
Aug 22 09:03:56.604: INFO: successfully validated that service multi-endpoint-test in namespace services-3861 exposes endpoints map[pod1:[100]] (2.031713991s elapsed)
STEP: Creating pod pod2 in namespace services-3861
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3861 to expose endpoints map[pod1:[100] pod2:[101]]
Aug 22 09:03:59.647: INFO: successfully validated that service multi-endpoint-test in namespace services-3861 exposes endpoints map[pod1:[100] pod2:[101]] (3.037419023s elapsed)
STEP: Deleting pod pod1 in namespace services-3861
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3861 to expose endpoints map[pod2:[101]]
Aug 22 09:03:59.665: INFO: successfully validated that service multi-endpoint-test in namespace services-3861 exposes endpoints map[pod2:[101]] (11.572071ms elapsed)
STEP: Deleting pod pod2 in namespace services-3861
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3861 to expose endpoints map[]
Aug 22 09:03:59.681: INFO: successfully validated that service multi-endpoint-test in namespace services-3861 exposes endpoints map[] (3.635492ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 09:03:59.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3861" for this suite.
Aug 22 09:04:21.710: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 09:04:21.776: INFO: namespace services-3861 deletion completed in 22.076908409s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:27.361 seconds]
[sig-network] Services
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 09:04:21.777: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-8211
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Aug 22 09:04:21.938: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"d4c69146-c4bb-11e9-92bb-0afbab63fbd8", Controller:(*bool)(0xc000918232), BlockOwnerDeletion:(*bool)(0xc000918233)}}
Aug 22 09:04:21.952: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"d4c4cecd-c4bb-11e9-92bb-0afbab63fbd8", Controller:(*bool)(0xc0009183ea), BlockOwnerDeletion:(*bool)(0xc0009183eb)}}
Aug 22 09:04:21.960: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"d4c5c0a5-c4bb-11e9-92bb-0afbab63fbd8", Controller:(*bool)(0xc001bcc1ea), BlockOwnerDeletion:(*bool)(0xc001bcc1eb)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 09:04:26.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8211" for this suite.
Aug 22 09:04:32.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 09:04:33.068: INFO: namespace gc-8211 deletion completed in 6.093912504s

• [SLOW TEST:11.292 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Aug 22 09:04:33.069: INFO: >>> kubeConfig: /tmp/kubeconfig-901739697
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1540
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Aug 22 09:04:33.223: INFO: Waiting up to 5m0s for pod "downwardapi-volume-db81c130-c4bb-11e9-80b5-1edf08853c25" in namespace "projected-1540" to be "success or failure"
Aug 22 09:04:33.229: INFO: Pod "downwardapi-volume-db81c130-c4bb-11e9-80b5-1edf08853c25": Phase="Pending", Reason="", readiness=false. Elapsed: 5.843717ms
Aug 22 09:04:35.232: INFO: Pod "downwardapi-volume-db81c130-c4bb-11e9-80b5-1edf08853c25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008987929s
STEP: Saw pod success
Aug 22 09:04:35.232: INFO: Pod "downwardapi-volume-db81c130-c4bb-11e9-80b5-1edf08853c25" satisfied condition "success or failure"
Aug 22 09:04:35.234: INFO: Trying to get logs from node ip-10-90-32-24.eu-west-2.compute.internal pod downwardapi-volume-db81c130-c4bb-11e9-80b5-1edf08853c25 container client-container: <nil>
STEP: delete the pod
Aug 22 09:04:35.253: INFO: Waiting for pod downwardapi-volume-db81c130-c4bb-11e9-80b5-1edf08853c25 to disappear
Aug 22 09:04:35.255: INFO: Pod downwardapi-volume-db81c130-c4bb-11e9-80b5-1edf08853c25 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Aug 22 09:04:35.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1540" for this suite.
Aug 22 09:04:41.273: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 22 09:04:41.344: INFO: namespace projected-1540 deletion completed in 6.085888752s

• [SLOW TEST:8.275 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSAug 22 09:04:41.344: INFO: Running AfterSuite actions on all nodes
Aug 22 09:04:41.345: INFO: Running AfterSuite actions on node 1
Aug 22 09:04:41.345: INFO: Skipping dumping logs from cluster

Ran 204 of 3584 Specs in 4970.479 seconds
SUCCESS! -- 204 Passed | 0 Failed | 0 Pending | 3380 Skipped PASS

Ginkgo ran 1 suite in 1h22m52.354685227s
Test Suite Passed
