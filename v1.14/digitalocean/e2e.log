I0430 13:56:00.547601      15 test_context.go:405] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-566523788
I0430 13:56:00.552315      15 e2e.go:240] Starting e2e run "ade54de6-6b4f-11e9-b570-225b9ad5bed0" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1556632557 - Will randomize all specs
Will run 204 of 3584 specs

Apr 30 13:56:01.007: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
Apr 30 13:56:01.014: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Apr 30 13:56:01.038: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Apr 30 13:56:01.077: INFO: 15 / 15 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Apr 30 13:56:01.077: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
Apr 30 13:56:01.077: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Apr 30 13:56:01.090: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'cilium' (0 seconds elapsed)
Apr 30 13:56:01.090: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'csi-do-node' (0 seconds elapsed)
Apr 30 13:56:01.090: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'do-node-agent' (0 seconds elapsed)
Apr 30 13:56:01.090: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Apr 30 13:56:01.090: INFO: e2e test version: v1.14.1
Apr 30 13:56:01.092: INFO: kube-apiserver version: v1.14.1
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 13:56:01.092: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename svc-latency
Apr 30 13:56:01.135: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating replication controller svc-latency-rc in namespace svc-latency-6031
I0430 13:56:01.140387      15 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-6031, replica count: 1
I0430 13:56:02.190752      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0430 13:56:03.190932      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0430 13:56:04.191113      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 30 13:56:04.309: INFO: Created: latency-svc-snv6z
Apr 30 13:56:04.313: INFO: Got endpoints: latency-svc-snv6z [22.519989ms]
Apr 30 13:56:04.367: INFO: Created: latency-svc-szlvr
Apr 30 13:56:04.376: INFO: Got endpoints: latency-svc-szlvr [61.930437ms]
Apr 30 13:56:04.393: INFO: Created: latency-svc-wf82c
Apr 30 13:56:04.406: INFO: Created: latency-svc-29gtp
Apr 30 13:56:04.409: INFO: Got endpoints: latency-svc-wf82c [94.818722ms]
Apr 30 13:56:04.423: INFO: Got endpoints: latency-svc-29gtp [108.612363ms]
Apr 30 13:56:04.428: INFO: Created: latency-svc-z8cbb
Apr 30 13:56:04.445: INFO: Got endpoints: latency-svc-z8cbb [130.02098ms]
Apr 30 13:56:04.449: INFO: Created: latency-svc-jchnv
Apr 30 13:56:04.463: INFO: Got endpoints: latency-svc-jchnv [146.984398ms]
Apr 30 13:56:04.469: INFO: Created: latency-svc-sb59m
Apr 30 13:56:04.480: INFO: Got endpoints: latency-svc-sb59m [164.781022ms]
Apr 30 13:56:04.492: INFO: Created: latency-svc-ngrqw
Apr 30 13:56:04.513: INFO: Created: latency-svc-sph8q
Apr 30 13:56:04.515: INFO: Got endpoints: latency-svc-ngrqw [70.45485ms]
Apr 30 13:56:04.530: INFO: Created: latency-svc-bcfrc
Apr 30 13:56:04.538: INFO: Got endpoints: latency-svc-sph8q [222.825307ms]
Apr 30 13:56:04.551: INFO: Got endpoints: latency-svc-bcfrc [236.073817ms]
Apr 30 13:56:04.563: INFO: Created: latency-svc-fj64h
Apr 30 13:56:04.576: INFO: Got endpoints: latency-svc-fj64h [259.922411ms]
Apr 30 13:56:04.583: INFO: Created: latency-svc-xw98b
Apr 30 13:56:04.605: INFO: Got endpoints: latency-svc-xw98b [288.723957ms]
Apr 30 13:56:04.612: INFO: Created: latency-svc-nmjtz
Apr 30 13:56:04.639: INFO: Got endpoints: latency-svc-nmjtz [322.655303ms]
Apr 30 13:56:04.646: INFO: Created: latency-svc-f9fsm
Apr 30 13:56:04.657: INFO: Created: latency-svc-qlc9q
Apr 30 13:56:04.665: INFO: Got endpoints: latency-svc-f9fsm [348.443736ms]
Apr 30 13:56:04.672: INFO: Got endpoints: latency-svc-qlc9q [352.385236ms]
Apr 30 13:56:04.681: INFO: Created: latency-svc-p9mh2
Apr 30 13:56:04.697: INFO: Got endpoints: latency-svc-p9mh2 [377.962921ms]
Apr 30 13:56:04.704: INFO: Created: latency-svc-z64qk
Apr 30 13:56:04.712: INFO: Got endpoints: latency-svc-z64qk [392.097928ms]
Apr 30 13:56:04.719: INFO: Created: latency-svc-nktp9
Apr 30 13:56:04.727: INFO: Got endpoints: latency-svc-nktp9 [350.688824ms]
Apr 30 13:56:04.747: INFO: Created: latency-svc-qnbkk
Apr 30 13:56:04.756: INFO: Created: latency-svc-zqctf
Apr 30 13:56:04.760: INFO: Got endpoints: latency-svc-qnbkk [350.303265ms]
Apr 30 13:56:04.770: INFO: Got endpoints: latency-svc-zqctf [347.316416ms]
Apr 30 13:56:04.783: INFO: Created: latency-svc-4jtvr
Apr 30 13:56:04.786: INFO: Got endpoints: latency-svc-4jtvr [322.01244ms]
Apr 30 13:56:04.800: INFO: Created: latency-svc-hzl58
Apr 30 13:56:04.819: INFO: Created: latency-svc-n6ws5
Apr 30 13:56:04.819: INFO: Got endpoints: latency-svc-hzl58 [339.154529ms]
Apr 30 13:56:04.831: INFO: Got endpoints: latency-svc-n6ws5 [315.454727ms]
Apr 30 13:56:04.838: INFO: Created: latency-svc-6gj6b
Apr 30 13:56:04.848: INFO: Got endpoints: latency-svc-6gj6b [309.885153ms]
Apr 30 13:56:04.860: INFO: Created: latency-svc-4488x
Apr 30 13:56:04.868: INFO: Created: latency-svc-cqb2v
Apr 30 13:56:04.888: INFO: Got endpoints: latency-svc-cqb2v [312.019156ms]
Apr 30 13:56:04.888: INFO: Got endpoints: latency-svc-4488x [337.120785ms]
Apr 30 13:56:04.900: INFO: Created: latency-svc-6k949
Apr 30 13:56:04.921: INFO: Created: latency-svc-mthml
Apr 30 13:56:04.923: INFO: Got endpoints: latency-svc-6k949 [318.428671ms]
Apr 30 13:56:04.939: INFO: Created: latency-svc-hpjh5
Apr 30 13:56:04.950: INFO: Got endpoints: latency-svc-mthml [310.51087ms]
Apr 30 13:56:04.963: INFO: Got endpoints: latency-svc-hpjh5 [297.512804ms]
Apr 30 13:56:04.966: INFO: Created: latency-svc-4bthh
Apr 30 13:56:04.979: INFO: Got endpoints: latency-svc-4bthh [306.947758ms]
Apr 30 13:56:04.988: INFO: Created: latency-svc-f4kwr
Apr 30 13:56:05.001: INFO: Created: latency-svc-n4d8k
Apr 30 13:56:05.004: INFO: Got endpoints: latency-svc-f4kwr [306.098176ms]
Apr 30 13:56:05.021: INFO: Got endpoints: latency-svc-n4d8k [309.223011ms]
Apr 30 13:56:05.022: INFO: Created: latency-svc-vdz5v
Apr 30 13:56:05.027: INFO: Got endpoints: latency-svc-vdz5v [300.687158ms]
Apr 30 13:56:05.045: INFO: Created: latency-svc-f4hbg
Apr 30 13:56:05.056: INFO: Created: latency-svc-488hx
Apr 30 13:56:05.064: INFO: Got endpoints: latency-svc-f4hbg [303.775202ms]
Apr 30 13:56:05.073: INFO: Created: latency-svc-hnphb
Apr 30 13:56:05.080: INFO: Got endpoints: latency-svc-488hx [309.196097ms]
Apr 30 13:56:05.089: INFO: Got endpoints: latency-svc-hnphb [303.136833ms]
Apr 30 13:56:05.100: INFO: Created: latency-svc-wqmrq
Apr 30 13:56:05.107: INFO: Got endpoints: latency-svc-wqmrq [288.518636ms]
Apr 30 13:56:05.112: INFO: Created: latency-svc-2xt4w
Apr 30 13:56:05.134: INFO: Got endpoints: latency-svc-2xt4w [301.184904ms]
Apr 30 13:56:05.140: INFO: Created: latency-svc-qwkjw
Apr 30 13:56:05.150: INFO: Created: latency-svc-xs8v9
Apr 30 13:56:05.153: INFO: Got endpoints: latency-svc-qwkjw [304.992018ms]
Apr 30 13:56:05.168: INFO: Created: latency-svc-n94xt
Apr 30 13:56:05.180: INFO: Got endpoints: latency-svc-xs8v9 [292.083105ms]
Apr 30 13:56:05.204: INFO: Got endpoints: latency-svc-n94xt [308.354796ms]
Apr 30 13:56:05.218: INFO: Created: latency-svc-7g55c
Apr 30 13:56:05.238: INFO: Got endpoints: latency-svc-7g55c [314.222332ms]
Apr 30 13:56:05.258: INFO: Created: latency-svc-hxtqr
Apr 30 13:56:05.271: INFO: Got endpoints: latency-svc-hxtqr [321.186215ms]
Apr 30 13:56:05.280: INFO: Created: latency-svc-lhhjh
Apr 30 13:56:05.290: INFO: Got endpoints: latency-svc-lhhjh [326.906203ms]
Apr 30 13:56:05.298: INFO: Created: latency-svc-6qqdm
Apr 30 13:56:05.308: INFO: Got endpoints: latency-svc-6qqdm [328.108858ms]
Apr 30 13:56:05.318: INFO: Created: latency-svc-7kq7t
Apr 30 13:56:05.331: INFO: Got endpoints: latency-svc-7kq7t [327.582142ms]
Apr 30 13:56:05.336: INFO: Created: latency-svc-vm2j8
Apr 30 13:56:05.370: INFO: Got endpoints: latency-svc-vm2j8 [349.047113ms]
Apr 30 13:56:05.377: INFO: Created: latency-svc-s8k74
Apr 30 13:56:05.382: INFO: Got endpoints: latency-svc-s8k74 [354.277685ms]
Apr 30 13:56:05.408: INFO: Created: latency-svc-wt9cd
Apr 30 13:56:05.440: INFO: Got endpoints: latency-svc-wt9cd [375.956458ms]
Apr 30 13:56:05.443: INFO: Created: latency-svc-mdn5r
Apr 30 13:56:05.462: INFO: Created: latency-svc-s69kp
Apr 30 13:56:05.462: INFO: Got endpoints: latency-svc-mdn5r [382.584946ms]
Apr 30 13:56:05.481: INFO: Got endpoints: latency-svc-s69kp [391.871486ms]
Apr 30 13:56:05.481: INFO: Created: latency-svc-67fpq
Apr 30 13:56:05.498: INFO: Got endpoints: latency-svc-67fpq [389.777614ms]
Apr 30 13:56:05.505: INFO: Created: latency-svc-bmgls
Apr 30 13:56:05.525: INFO: Got endpoints: latency-svc-bmgls [390.663623ms]
Apr 30 13:56:05.525: INFO: Created: latency-svc-5bmxw
Apr 30 13:56:05.533: INFO: Got endpoints: latency-svc-5bmxw [380.180749ms]
Apr 30 13:56:05.540: INFO: Created: latency-svc-mg4mx
Apr 30 13:56:05.554: INFO: Created: latency-svc-td9l2
Apr 30 13:56:05.571: INFO: Created: latency-svc-d9hcw
Apr 30 13:56:05.580: INFO: Got endpoints: latency-svc-mg4mx [399.339871ms]
Apr 30 13:56:05.580: INFO: Created: latency-svc-jwkrc
Apr 30 13:56:05.597: INFO: Created: latency-svc-5b2cz
Apr 30 13:56:05.612: INFO: Created: latency-svc-qs7hz
Apr 30 13:56:05.624: INFO: Created: latency-svc-786gd
Apr 30 13:56:05.636: INFO: Got endpoints: latency-svc-td9l2 [431.674225ms]
Apr 30 13:56:05.647: INFO: Created: latency-svc-p8qfv
Apr 30 13:56:05.661: INFO: Created: latency-svc-sc8t5
Apr 30 13:56:05.680: INFO: Created: latency-svc-dbzr4
Apr 30 13:56:05.684: INFO: Got endpoints: latency-svc-d9hcw [445.787029ms]
Apr 30 13:56:05.694: INFO: Created: latency-svc-fhrd5
Apr 30 13:56:05.706: INFO: Created: latency-svc-tclp4
Apr 30 13:56:05.724: INFO: Created: latency-svc-sfwzf
Apr 30 13:56:05.749: INFO: Got endpoints: latency-svc-jwkrc [477.838012ms]
Apr 30 13:56:05.777: INFO: Created: latency-svc-cgg74
Apr 30 13:56:05.800: INFO: Got endpoints: latency-svc-5b2cz [509.183534ms]
Apr 30 13:56:05.826: INFO: Created: latency-svc-scdk7
Apr 30 13:56:05.853: INFO: Created: latency-svc-2b6hv
Apr 30 13:56:05.862: INFO: Got endpoints: latency-svc-qs7hz [553.693322ms]
Apr 30 13:56:05.887: INFO: Got endpoints: latency-svc-786gd [555.415867ms]
Apr 30 13:56:05.889: INFO: Created: latency-svc-2bbnj
Apr 30 13:56:05.906: INFO: Created: latency-svc-c4jvg
Apr 30 13:56:05.940: INFO: Got endpoints: latency-svc-p8qfv [569.063474ms]
Apr 30 13:56:05.967: INFO: Created: latency-svc-7d72p
Apr 30 13:56:05.977: INFO: Got endpoints: latency-svc-sc8t5 [594.811147ms]
Apr 30 13:56:05.992: INFO: Created: latency-svc-tb4v5
Apr 30 13:56:06.005: INFO: Created: latency-svc-p4vz4
Apr 30 13:56:06.044: INFO: Got endpoints: latency-svc-dbzr4 [603.493354ms]
Apr 30 13:56:06.049: INFO: Created: latency-svc-gxv4h
Apr 30 13:56:06.064: INFO: Created: latency-svc-fljvq
Apr 30 13:56:06.082: INFO: Got endpoints: latency-svc-fhrd5 [618.560094ms]
Apr 30 13:56:06.084: INFO: Created: latency-svc-9hhnk
Apr 30 13:56:06.110: INFO: Created: latency-svc-nqfns
Apr 30 13:56:06.131: INFO: Created: latency-svc-4bjjn
Apr 30 13:56:06.146: INFO: Got endpoints: latency-svc-tclp4 [665.113168ms]
Apr 30 13:56:06.174: INFO: Got endpoints: latency-svc-sfwzf [676.774775ms]
Apr 30 13:56:06.177: INFO: Created: latency-svc-2rqxn
Apr 30 13:56:06.204: INFO: Created: latency-svc-ggd4g
Apr 30 13:56:06.225: INFO: Got endpoints: latency-svc-cgg74 [699.748559ms]
Apr 30 13:56:06.263: INFO: Created: latency-svc-vjqvk
Apr 30 13:56:06.282: INFO: Got endpoints: latency-svc-scdk7 [749.099818ms]
Apr 30 13:56:06.306: INFO: Created: latency-svc-txkjh
Apr 30 13:56:06.325: INFO: Got endpoints: latency-svc-2b6hv [745.314667ms]
Apr 30 13:56:06.376: INFO: Created: latency-svc-gj4sc
Apr 30 13:56:06.393: INFO: Got endpoints: latency-svc-2bbnj [757.473937ms]
Apr 30 13:56:06.423: INFO: Got endpoints: latency-svc-c4jvg [739.291722ms]
Apr 30 13:56:06.431: INFO: Created: latency-svc-gh2gn
Apr 30 13:56:06.477: INFO: Created: latency-svc-qvnvg
Apr 30 13:56:06.503: INFO: Got endpoints: latency-svc-7d72p [753.484294ms]
Apr 30 13:56:06.525: INFO: Got endpoints: latency-svc-tb4v5 [725.292569ms]
Apr 30 13:56:06.547: INFO: Created: latency-svc-2glhn
Apr 30 13:56:06.555: INFO: Created: latency-svc-p86nl
Apr 30 13:56:06.571: INFO: Got endpoints: latency-svc-p4vz4 [709.133745ms]
Apr 30 13:56:06.591: INFO: Created: latency-svc-pgkhx
Apr 30 13:56:06.624: INFO: Got endpoints: latency-svc-gxv4h [736.282796ms]
Apr 30 13:56:06.651: INFO: Created: latency-svc-9hbth
Apr 30 13:56:06.671: INFO: Got endpoints: latency-svc-fljvq [731.340748ms]
Apr 30 13:56:06.691: INFO: Created: latency-svc-vtf7h
Apr 30 13:56:06.723: INFO: Got endpoints: latency-svc-9hhnk [745.646502ms]
Apr 30 13:56:06.752: INFO: Created: latency-svc-vk6qz
Apr 30 13:56:06.769: INFO: Got endpoints: latency-svc-nqfns [725.188787ms]
Apr 30 13:56:06.790: INFO: Created: latency-svc-t9m6p
Apr 30 13:56:06.820: INFO: Got endpoints: latency-svc-4bjjn [737.784021ms]
Apr 30 13:56:06.841: INFO: Created: latency-svc-6vmnn
Apr 30 13:56:06.870: INFO: Got endpoints: latency-svc-2rqxn [723.937521ms]
Apr 30 13:56:06.900: INFO: Created: latency-svc-2nzm2
Apr 30 13:56:06.924: INFO: Got endpoints: latency-svc-ggd4g [749.130102ms]
Apr 30 13:56:06.944: INFO: Created: latency-svc-9g5jj
Apr 30 13:56:06.974: INFO: Got endpoints: latency-svc-vjqvk [749.160888ms]
Apr 30 13:56:06.992: INFO: Created: latency-svc-rrxv5
Apr 30 13:56:07.020: INFO: Got endpoints: latency-svc-txkjh [737.231453ms]
Apr 30 13:56:07.048: INFO: Created: latency-svc-b5qbm
Apr 30 13:56:07.084: INFO: Got endpoints: latency-svc-gj4sc [758.117762ms]
Apr 30 13:56:07.136: INFO: Created: latency-svc-wpvkt
Apr 30 13:56:07.136: INFO: Got endpoints: latency-svc-gh2gn [742.424808ms]
Apr 30 13:56:07.153: INFO: Created: latency-svc-4j47p
Apr 30 13:56:07.172: INFO: Got endpoints: latency-svc-qvnvg [748.202656ms]
Apr 30 13:56:07.197: INFO: Created: latency-svc-m2rfz
Apr 30 13:56:07.226: INFO: Got endpoints: latency-svc-2glhn [723.113522ms]
Apr 30 13:56:07.259: INFO: Created: latency-svc-9mhlr
Apr 30 13:56:07.273: INFO: Got endpoints: latency-svc-p86nl [747.849523ms]
Apr 30 13:56:07.296: INFO: Created: latency-svc-5w6lm
Apr 30 13:56:07.324: INFO: Got endpoints: latency-svc-pgkhx [752.537589ms]
Apr 30 13:56:07.346: INFO: Created: latency-svc-7tmkw
Apr 30 13:56:07.370: INFO: Got endpoints: latency-svc-9hbth [746.404909ms]
Apr 30 13:56:07.409: INFO: Created: latency-svc-5j6dj
Apr 30 13:56:07.424: INFO: Got endpoints: latency-svc-vtf7h [752.271165ms]
Apr 30 13:56:07.480: INFO: Got endpoints: latency-svc-vk6qz [756.381277ms]
Apr 30 13:56:07.491: INFO: Created: latency-svc-hp54c
Apr 30 13:56:07.509: INFO: Created: latency-svc-8s2dl
Apr 30 13:56:07.519: INFO: Got endpoints: latency-svc-t9m6p [749.904559ms]
Apr 30 13:56:07.576: INFO: Created: latency-svc-49d5z
Apr 30 13:56:07.595: INFO: Got endpoints: latency-svc-6vmnn [775.206867ms]
Apr 30 13:56:07.619: INFO: Created: latency-svc-5w5rc
Apr 30 13:56:07.630: INFO: Got endpoints: latency-svc-2nzm2 [759.318527ms]
Apr 30 13:56:07.656: INFO: Created: latency-svc-dtgtc
Apr 30 13:56:07.677: INFO: Got endpoints: latency-svc-9g5jj [753.28645ms]
Apr 30 13:56:07.857: INFO: Created: latency-svc-g8x45
Apr 30 13:56:07.857: INFO: Got endpoints: latency-svc-wpvkt [773.163738ms]
Apr 30 13:56:07.857: INFO: Got endpoints: latency-svc-rrxv5 [883.151221ms]
Apr 30 13:56:07.858: INFO: Got endpoints: latency-svc-b5qbm [837.519769ms]
Apr 30 13:56:07.956: INFO: Got endpoints: latency-svc-4j47p [819.26007ms]
Apr 30 13:56:08.025: INFO: Got endpoints: latency-svc-m2rfz [853.044275ms]
Apr 30 13:56:08.098: INFO: Created: latency-svc-9jdfd
Apr 30 13:56:08.108: INFO: Got endpoints: latency-svc-9mhlr [881.153401ms]
Apr 30 13:56:08.158: INFO: Got endpoints: latency-svc-5w6lm [884.570636ms]
Apr 30 13:56:08.164: INFO: Got endpoints: latency-svc-7tmkw [839.721954ms]
Apr 30 13:56:08.199: INFO: Created: latency-svc-zhhrv
Apr 30 13:56:08.200: INFO: Got endpoints: latency-svc-hp54c [776.386594ms]
Apr 30 13:56:08.201: INFO: Got endpoints: latency-svc-5j6dj [830.075908ms]
Apr 30 13:56:08.241: INFO: Got endpoints: latency-svc-8s2dl [759.988735ms]
Apr 30 13:56:08.246: INFO: Created: latency-svc-rckz2
Apr 30 13:56:08.448: INFO: Got endpoints: latency-svc-49d5z [928.261275ms]
Apr 30 13:56:09.060: INFO: Got endpoints: latency-svc-rckz2 [1.202209416s]
Apr 30 13:56:09.104: INFO: Created: latency-svc-t9pb8
Apr 30 13:56:09.104: INFO: Got endpoints: latency-svc-t9pb8 [946.127495ms]
Apr 30 13:56:08.968: INFO: Got endpoints: latency-svc-5w5rc [1.373079263s]
Apr 30 13:56:09.107: INFO: Created: latency-svc-25hdz
Apr 30 13:56:09.108: INFO: Got endpoints: latency-svc-25hdz [943.715203ms]
Apr 30 13:56:08.916: INFO: Created: latency-svc-pbxqc
Apr 30 13:56:09.108: INFO: Got endpoints: latency-svc-pbxqc [1.152570147s]
Apr 30 13:56:09.109: INFO: Created: latency-svc-z9d2v
Apr 30 13:56:09.109: INFO: Got endpoints: latency-svc-z9d2v [908.404776ms]
Apr 30 13:56:08.969: INFO: Created: latency-svc-88slt
Apr 30 13:56:09.109: INFO: Got endpoints: latency-svc-88slt [868.370325ms]
Apr 30 13:56:09.110: INFO: Created: latency-svc-h4j6r
Apr 30 13:56:09.110: INFO: Got endpoints: latency-svc-h4j6r [909.10289ms]
Apr 30 13:56:08.969: INFO: Created: latency-svc-5jxrr
Apr 30 13:56:09.112: INFO: Got endpoints: latency-svc-5jxrr [1.086572375s]
Apr 30 13:56:08.970: INFO: Created: latency-svc-5mnhs
Apr 30 13:56:09.112: INFO: Got endpoints: latency-svc-5mnhs [1.004204704s]
Apr 30 13:56:09.084: INFO: Got endpoints: latency-svc-dtgtc [1.453503842s]
Apr 30 13:56:09.084: INFO: Got endpoints: latency-svc-g8x45 [1.406483007s]
Apr 30 13:56:09.084: INFO: Got endpoints: latency-svc-9jdfd [1.226542376s]
Apr 30 13:56:09.084: INFO: Got endpoints: latency-svc-zhhrv [1.225976188s]
Apr 30 13:56:09.121: INFO: Created: latency-svc-rp9l5
Apr 30 13:56:09.142: INFO: Got endpoints: latency-svc-rp9l5 [38.722976ms]
Apr 30 13:56:09.147: INFO: Created: latency-svc-7js8m
Apr 30 13:56:09.164: INFO: Got endpoints: latency-svc-7js8m [59.957345ms]
Apr 30 13:56:09.168: INFO: Created: latency-svc-pnqfk
Apr 30 13:56:09.183: INFO: Got endpoints: latency-svc-pnqfk [78.356178ms]
Apr 30 13:56:09.195: INFO: Created: latency-svc-498zs
Apr 30 13:56:09.222: INFO: Got endpoints: latency-svc-498zs [114.424129ms]
Apr 30 13:56:09.231: INFO: Created: latency-svc-xs7nq
Apr 30 13:56:09.247: INFO: Got endpoints: latency-svc-xs7nq [82.982588ms]
Apr 30 13:56:09.256: INFO: Created: latency-svc-s8n88
Apr 30 13:56:09.272: INFO: Created: latency-svc-nrvcl
Apr 30 13:56:09.287: INFO: Got endpoints: latency-svc-s8n88 [178.651042ms]
Apr 30 13:56:09.292: INFO: Created: latency-svc-6fw4k
Apr 30 13:56:09.302: INFO: Created: latency-svc-ccdcj
Apr 30 13:56:09.316: INFO: Created: latency-svc-l6cdd
Apr 30 13:56:09.337: INFO: Created: latency-svc-2szp8
Apr 30 13:56:09.342: INFO: Got endpoints: latency-svc-nrvcl [233.346598ms]
Apr 30 13:56:09.358: INFO: Created: latency-svc-w6dk2
Apr 30 13:56:09.372: INFO: Created: latency-svc-2xsnl
Apr 30 13:56:09.379: INFO: Got endpoints: latency-svc-6fw4k [269.576125ms]
Apr 30 13:56:09.381: INFO: Created: latency-svc-fd82w
Apr 30 13:56:09.399: INFO: Created: latency-svc-pkrzn
Apr 30 13:56:09.411: INFO: Created: latency-svc-88cch
Apr 30 13:56:09.428: INFO: Got endpoints: latency-svc-ccdcj [318.331307ms]
Apr 30 13:56:09.436: INFO: Created: latency-svc-88mr5
Apr 30 13:56:09.459: INFO: Created: latency-svc-grpm9
Apr 30 13:56:09.480: INFO: Created: latency-svc-gg5qc
Apr 30 13:56:09.484: INFO: Got endpoints: latency-svc-l6cdd [374.888889ms]
Apr 30 13:56:09.523: INFO: Created: latency-svc-2vdnv
Apr 30 13:56:09.532: INFO: Got endpoints: latency-svc-2szp8 [419.970401ms]
Apr 30 13:56:09.552: INFO: Created: latency-svc-tllg5
Apr 30 13:56:09.575: INFO: Created: latency-svc-5c4xs
Apr 30 13:56:09.579: INFO: Got endpoints: latency-svc-w6dk2 [466.578363ms]
Apr 30 13:56:09.598: INFO: Created: latency-svc-qx9rp
Apr 30 13:56:09.610: INFO: Created: latency-svc-dstqb
Apr 30 13:56:09.623: INFO: Created: latency-svc-z4hjn
Apr 30 13:56:09.630: INFO: Got endpoints: latency-svc-2xsnl [517.510585ms]
Apr 30 13:56:09.643: INFO: Created: latency-svc-snsqd
Apr 30 13:56:09.654: INFO: Created: latency-svc-m6dg7
Apr 30 13:56:09.661: INFO: Created: latency-svc-zxkz2
Apr 30 13:56:09.690: INFO: Got endpoints: latency-svc-fd82w [577.276828ms]
Apr 30 13:56:09.714: INFO: Created: latency-svc-sb99d
Apr 30 13:56:09.724: INFO: Got endpoints: latency-svc-pkrzn [611.005009ms]
Apr 30 13:56:09.745: INFO: Created: latency-svc-56mg7
Apr 30 13:56:09.773: INFO: Got endpoints: latency-svc-88cch [658.138951ms]
Apr 30 13:56:09.804: INFO: Created: latency-svc-f4chj
Apr 30 13:56:09.822: INFO: Got endpoints: latency-svc-88mr5 [680.493736ms]
Apr 30 13:56:09.846: INFO: Created: latency-svc-cj99r
Apr 30 13:56:09.874: INFO: Got endpoints: latency-svc-grpm9 [691.184523ms]
Apr 30 13:56:09.893: INFO: Created: latency-svc-g652n
Apr 30 13:56:09.924: INFO: Got endpoints: latency-svc-gg5qc [702.658309ms]
Apr 30 13:56:09.943: INFO: Created: latency-svc-8bvz9
Apr 30 13:56:10.140: INFO: Got endpoints: latency-svc-qx9rp [761.083192ms]
Apr 30 13:56:10.140: INFO: Got endpoints: latency-svc-2vdnv [892.990794ms]
Apr 30 13:56:10.141: INFO: Got endpoints: latency-svc-tllg5 [853.817279ms]
Apr 30 13:56:10.141: INFO: Got endpoints: latency-svc-5c4xs [798.171405ms]
Apr 30 13:56:10.163: INFO: Created: latency-svc-6mxzq
Apr 30 13:56:10.175: INFO: Created: latency-svc-cnwzm
Apr 30 13:56:10.175: INFO: Got endpoints: latency-svc-dstqb [746.606228ms]
Apr 30 13:56:10.187: INFO: Created: latency-svc-296vj
Apr 30 13:56:10.198: INFO: Created: latency-svc-wzt84
Apr 30 13:56:10.212: INFO: Created: latency-svc-89k9x
Apr 30 13:56:10.226: INFO: Got endpoints: latency-svc-z4hjn [742.095283ms]
Apr 30 13:56:10.253: INFO: Created: latency-svc-fnscz
Apr 30 13:56:10.279: INFO: Got endpoints: latency-svc-snsqd [746.63008ms]
Apr 30 13:56:10.300: INFO: Created: latency-svc-xk89x
Apr 30 13:56:10.322: INFO: Got endpoints: latency-svc-m6dg7 [743.076117ms]
Apr 30 13:56:10.346: INFO: Created: latency-svc-fqb6n
Apr 30 13:56:10.385: INFO: Got endpoints: latency-svc-zxkz2 [755.27896ms]
Apr 30 13:56:10.402: INFO: Created: latency-svc-7mqs9
Apr 30 13:56:10.423: INFO: Got endpoints: latency-svc-sb99d [731.736273ms]
Apr 30 13:56:10.443: INFO: Created: latency-svc-qqqt8
Apr 30 13:56:10.472: INFO: Got endpoints: latency-svc-56mg7 [747.078016ms]
Apr 30 13:56:10.503: INFO: Created: latency-svc-wv7hz
Apr 30 13:56:10.524: INFO: Got endpoints: latency-svc-f4chj [750.479814ms]
Apr 30 13:56:10.542: INFO: Created: latency-svc-85w88
Apr 30 13:56:10.575: INFO: Got endpoints: latency-svc-cj99r [752.751634ms]
Apr 30 13:56:10.598: INFO: Created: latency-svc-d2zt4
Apr 30 13:56:10.623: INFO: Got endpoints: latency-svc-g652n [748.093547ms]
Apr 30 13:56:10.639: INFO: Created: latency-svc-w62jb
Apr 30 13:56:10.676: INFO: Got endpoints: latency-svc-8bvz9 [751.201161ms]
Apr 30 13:56:10.699: INFO: Created: latency-svc-wxqpx
Apr 30 13:56:10.736: INFO: Got endpoints: latency-svc-6mxzq [595.730409ms]
Apr 30 13:56:10.756: INFO: Created: latency-svc-cg6d9
Apr 30 13:56:10.773: INFO: Got endpoints: latency-svc-cnwzm [632.724106ms]
Apr 30 13:56:10.793: INFO: Created: latency-svc-szc84
Apr 30 13:56:10.820: INFO: Got endpoints: latency-svc-296vj [679.47709ms]
Apr 30 13:56:10.858: INFO: Created: latency-svc-bq8pb
Apr 30 13:56:10.871: INFO: Got endpoints: latency-svc-wzt84 [729.710975ms]
Apr 30 13:56:10.896: INFO: Created: latency-svc-4v86f
Apr 30 13:56:10.921: INFO: Got endpoints: latency-svc-89k9x [746.218136ms]
Apr 30 13:56:10.944: INFO: Created: latency-svc-cwm2d
Apr 30 13:56:10.980: INFO: Got endpoints: latency-svc-fnscz [753.635197ms]
Apr 30 13:56:11.004: INFO: Created: latency-svc-j7bvx
Apr 30 13:56:11.023: INFO: Got endpoints: latency-svc-xk89x [744.709414ms]
Apr 30 13:56:11.045: INFO: Created: latency-svc-779dg
Apr 30 13:56:11.069: INFO: Got endpoints: latency-svc-fqb6n [746.900682ms]
Apr 30 13:56:11.101: INFO: Created: latency-svc-l9g7n
Apr 30 13:56:11.120: INFO: Got endpoints: latency-svc-7mqs9 [734.582814ms]
Apr 30 13:56:11.143: INFO: Created: latency-svc-2xxg5
Apr 30 13:56:11.171: INFO: Got endpoints: latency-svc-qqqt8 [748.666099ms]
Apr 30 13:56:11.206: INFO: Created: latency-svc-8pmx5
Apr 30 13:56:11.224: INFO: Got endpoints: latency-svc-wv7hz [752.068112ms]
Apr 30 13:56:11.239: INFO: Created: latency-svc-4vck6
Apr 30 13:56:11.272: INFO: Got endpoints: latency-svc-85w88 [747.753104ms]
Apr 30 13:56:11.306: INFO: Created: latency-svc-fbzj6
Apr 30 13:56:11.322: INFO: Got endpoints: latency-svc-d2zt4 [746.194954ms]
Apr 30 13:56:11.350: INFO: Created: latency-svc-826g4
Apr 30 13:56:11.371: INFO: Got endpoints: latency-svc-w62jb [748.414939ms]
Apr 30 13:56:11.389: INFO: Created: latency-svc-j2gh4
Apr 30 13:56:11.424: INFO: Got endpoints: latency-svc-wxqpx [747.812551ms]
Apr 30 13:56:11.458: INFO: Created: latency-svc-jw7d8
Apr 30 13:56:11.470: INFO: Got endpoints: latency-svc-cg6d9 [734.061563ms]
Apr 30 13:56:11.496: INFO: Created: latency-svc-wlrgr
Apr 30 13:56:11.522: INFO: Got endpoints: latency-svc-szc84 [748.078808ms]
Apr 30 13:56:11.538: INFO: Created: latency-svc-b5jpj
Apr 30 13:56:11.572: INFO: Got endpoints: latency-svc-bq8pb [751.572182ms]
Apr 30 13:56:11.593: INFO: Created: latency-svc-2v7p7
Apr 30 13:56:11.622: INFO: Got endpoints: latency-svc-4v86f [751.266504ms]
Apr 30 13:56:11.663: INFO: Created: latency-svc-6w5b5
Apr 30 13:56:11.694: INFO: Got endpoints: latency-svc-cwm2d [772.085711ms]
Apr 30 13:56:11.720: INFO: Got endpoints: latency-svc-j7bvx [738.09582ms]
Apr 30 13:56:11.721: INFO: Created: latency-svc-sd7ss
Apr 30 13:56:11.743: INFO: Created: latency-svc-dzgqv
Apr 30 13:56:11.772: INFO: Got endpoints: latency-svc-779dg [748.203532ms]
Apr 30 13:56:11.800: INFO: Created: latency-svc-9ljz8
Apr 30 13:56:11.823: INFO: Got endpoints: latency-svc-l9g7n [752.93195ms]
Apr 30 13:56:11.844: INFO: Created: latency-svc-vbd2z
Apr 30 13:56:11.873: INFO: Got endpoints: latency-svc-2xxg5 [752.942631ms]
Apr 30 13:56:11.892: INFO: Created: latency-svc-qcbmn
Apr 30 13:56:11.920: INFO: Got endpoints: latency-svc-8pmx5 [748.214309ms]
Apr 30 13:56:11.943: INFO: Created: latency-svc-nklpn
Apr 30 13:56:11.971: INFO: Got endpoints: latency-svc-4vck6 [746.796855ms]
Apr 30 13:56:11.992: INFO: Created: latency-svc-vzstv
Apr 30 13:56:12.019: INFO: Got endpoints: latency-svc-fbzj6 [747.422141ms]
Apr 30 13:56:12.041: INFO: Created: latency-svc-mdd4t
Apr 30 13:56:12.079: INFO: Got endpoints: latency-svc-826g4 [757.014911ms]
Apr 30 13:56:12.103: INFO: Created: latency-svc-99btx
Apr 30 13:56:12.124: INFO: Got endpoints: latency-svc-j2gh4 [752.393299ms]
Apr 30 13:56:12.165: INFO: Created: latency-svc-6dbjv
Apr 30 13:56:12.171: INFO: Got endpoints: latency-svc-jw7d8 [746.830066ms]
Apr 30 13:56:12.221: INFO: Got endpoints: latency-svc-wlrgr [750.912124ms]
Apr 30 13:56:12.346: INFO: Got endpoints: latency-svc-2v7p7 [774.230637ms]
Apr 30 13:56:12.346: INFO: Got endpoints: latency-svc-b5jpj [824.40226ms]
Apr 30 13:56:12.382: INFO: Got endpoints: latency-svc-6w5b5 [759.372311ms]
Apr 30 13:56:12.431: INFO: Got endpoints: latency-svc-sd7ss [737.023744ms]
Apr 30 13:56:12.477: INFO: Got endpoints: latency-svc-dzgqv [755.947882ms]
Apr 30 13:56:12.540: INFO: Got endpoints: latency-svc-9ljz8 [767.800891ms]
Apr 30 13:56:12.585: INFO: Got endpoints: latency-svc-vbd2z [762.415266ms]
Apr 30 13:56:12.627: INFO: Got endpoints: latency-svc-qcbmn [753.311665ms]
Apr 30 13:56:12.688: INFO: Got endpoints: latency-svc-nklpn [767.885888ms]
Apr 30 13:56:12.914: INFO: Got endpoints: latency-svc-6dbjv [790.202301ms]
Apr 30 13:56:12.914: INFO: Got endpoints: latency-svc-vzstv [943.139175ms]
Apr 30 13:56:12.914: INFO: Got endpoints: latency-svc-mdd4t [894.927472ms]
Apr 30 13:56:12.914: INFO: Got endpoints: latency-svc-99btx [834.983369ms]
Apr 30 13:56:12.914: INFO: Latencies: [38.722976ms 59.957345ms 61.930437ms 70.45485ms 78.356178ms 82.982588ms 94.818722ms 108.612363ms 114.424129ms 130.02098ms 146.984398ms 164.781022ms 178.651042ms 222.825307ms 233.346598ms 236.073817ms 259.922411ms 269.576125ms 288.518636ms 288.723957ms 292.083105ms 297.512804ms 300.687158ms 301.184904ms 303.136833ms 303.775202ms 304.992018ms 306.098176ms 306.947758ms 308.354796ms 309.196097ms 309.223011ms 309.885153ms 310.51087ms 312.019156ms 314.222332ms 315.454727ms 318.331307ms 318.428671ms 321.186215ms 322.01244ms 322.655303ms 326.906203ms 327.582142ms 328.108858ms 337.120785ms 339.154529ms 347.316416ms 348.443736ms 349.047113ms 350.303265ms 350.688824ms 352.385236ms 354.277685ms 374.888889ms 375.956458ms 377.962921ms 380.180749ms 382.584946ms 389.777614ms 390.663623ms 391.871486ms 392.097928ms 399.339871ms 419.970401ms 431.674225ms 445.787029ms 466.578363ms 477.838012ms 509.183534ms 517.510585ms 553.693322ms 555.415867ms 569.063474ms 577.276828ms 594.811147ms 595.730409ms 603.493354ms 611.005009ms 618.560094ms 632.724106ms 658.138951ms 665.113168ms 676.774775ms 679.47709ms 680.493736ms 691.184523ms 699.748559ms 702.658309ms 709.133745ms 723.113522ms 723.937521ms 725.188787ms 725.292569ms 729.710975ms 731.340748ms 731.736273ms 734.061563ms 734.582814ms 736.282796ms 737.023744ms 737.231453ms 737.784021ms 738.09582ms 739.291722ms 742.095283ms 742.424808ms 743.076117ms 744.709414ms 745.314667ms 745.646502ms 746.194954ms 746.218136ms 746.404909ms 746.606228ms 746.63008ms 746.796855ms 746.830066ms 746.900682ms 747.078016ms 747.422141ms 747.753104ms 747.812551ms 747.849523ms 748.078808ms 748.093547ms 748.202656ms 748.203532ms 748.214309ms 748.414939ms 748.666099ms 749.099818ms 749.130102ms 749.160888ms 749.904559ms 750.479814ms 750.912124ms 751.201161ms 751.266504ms 751.572182ms 752.068112ms 752.271165ms 752.393299ms 752.537589ms 752.751634ms 752.93195ms 752.942631ms 753.28645ms 753.311665ms 753.484294ms 753.635197ms 755.27896ms 755.947882ms 756.381277ms 757.014911ms 757.473937ms 758.117762ms 759.318527ms 759.372311ms 759.988735ms 761.083192ms 762.415266ms 767.800891ms 767.885888ms 772.085711ms 773.163738ms 774.230637ms 775.206867ms 776.386594ms 790.202301ms 798.171405ms 819.26007ms 824.40226ms 830.075908ms 834.983369ms 837.519769ms 839.721954ms 853.044275ms 853.817279ms 868.370325ms 881.153401ms 883.151221ms 884.570636ms 892.990794ms 894.927472ms 908.404776ms 909.10289ms 928.261275ms 943.139175ms 943.715203ms 946.127495ms 1.004204704s 1.086572375s 1.152570147s 1.202209416s 1.225976188s 1.226542376s 1.373079263s 1.406483007s 1.453503842s]
Apr 30 13:56:12.915: INFO: 50 %ile: 737.023744ms
Apr 30 13:56:12.915: INFO: 90 %ile: 881.153401ms
Apr 30 13:56:12.915: INFO: 99 %ile: 1.406483007s
Apr 30 13:56:12.915: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 13:56:12.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-6031" for this suite.
Apr 30 13:56:30.983: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 13:56:31.063: INFO: namespace svc-latency-6031 deletion completed in 18.111119315s

• [SLOW TEST:29.971 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 13:56:31.070: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 30 13:56:31.120: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c1e50088-6b4f-11e9-b570-225b9ad5bed0" in namespace "projected-9002" to be "success or failure"
Apr 30 13:56:31.132: INFO: Pod "downwardapi-volume-c1e50088-6b4f-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 11.299157ms
Apr 30 13:56:33.135: INFO: Pod "downwardapi-volume-c1e50088-6b4f-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015012996s
Apr 30 13:56:35.140: INFO: Pod "downwardapi-volume-c1e50088-6b4f-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019859003s
STEP: Saw pod success
Apr 30 13:56:35.140: INFO: Pod "downwardapi-volume-c1e50088-6b4f-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 13:56:35.143: INFO: Trying to get logs from node fatih-test-default-pool-qlpd pod downwardapi-volume-c1e50088-6b4f-11e9-b570-225b9ad5bed0 container client-container: <nil>
STEP: delete the pod
Apr 30 13:56:35.202: INFO: Waiting for pod downwardapi-volume-c1e50088-6b4f-11e9-b570-225b9ad5bed0 to disappear
Apr 30 13:56:35.204: INFO: Pod downwardapi-volume-c1e50088-6b4f-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 13:56:35.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9002" for this suite.
Apr 30 13:56:41.218: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 13:56:41.306: INFO: namespace projected-9002 deletion completed in 6.098383339s

• [SLOW TEST:10.236 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 13:56:41.310: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 30 13:56:41.349: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c7fdec57-6b4f-11e9-b570-225b9ad5bed0" in namespace "projected-8760" to be "success or failure"
Apr 30 13:56:41.359: INFO: Pod "downwardapi-volume-c7fdec57-6b4f-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 10.25365ms
Apr 30 13:56:43.382: INFO: Pod "downwardapi-volume-c7fdec57-6b4f-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032993819s
Apr 30 13:56:45.386: INFO: Pod "downwardapi-volume-c7fdec57-6b4f-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037268037s
STEP: Saw pod success
Apr 30 13:56:45.386: INFO: Pod "downwardapi-volume-c7fdec57-6b4f-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 13:56:45.389: INFO: Trying to get logs from node fatih-test-default-pool-qlp0 pod downwardapi-volume-c7fdec57-6b4f-11e9-b570-225b9ad5bed0 container client-container: <nil>
STEP: delete the pod
Apr 30 13:56:45.424: INFO: Waiting for pod downwardapi-volume-c7fdec57-6b4f-11e9-b570-225b9ad5bed0 to disappear
Apr 30 13:56:45.427: INFO: Pod downwardapi-volume-c7fdec57-6b4f-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 13:56:45.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8760" for this suite.
Apr 30 13:56:51.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 13:56:51.508: INFO: namespace projected-8760 deletion completed in 6.078915182s

• [SLOW TEST:10.198 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 13:56:51.512: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
STEP: reading a file in the container
Apr 30 13:56:56.064: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-7452 pod-service-account-ce5f6577-6b4f-11e9-b570-225b9ad5bed0 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Apr 30 13:56:56.411: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-7452 pod-service-account-ce5f6577-6b4f-11e9-b570-225b9ad5bed0 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Apr 30 13:56:56.695: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-7452 pod-service-account-ce5f6577-6b4f-11e9-b570-225b9ad5bed0 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 13:56:56.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-7452" for this suite.
Apr 30 13:57:03.005: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 13:57:03.082: INFO: namespace svcaccounts-7452 deletion completed in 6.08899458s

• [SLOW TEST:11.571 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 13:57:03.085: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Starting the proxy
Apr 30 13:57:03.116: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-566523788 proxy --unix-socket=/tmp/kubectl-proxy-unix427050363/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 13:57:03.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6939" for this suite.
Apr 30 13:57:09.208: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 13:57:09.288: INFO: namespace kubectl-6939 deletion completed in 6.08857146s

• [SLOW TEST:6.204 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 13:57:09.292: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating secret secrets-4341/secret-test-d8aba02b-6b4f-11e9-b570-225b9ad5bed0
STEP: Creating a pod to test consume secrets
Apr 30 13:57:09.330: INFO: Waiting up to 5m0s for pod "pod-configmaps-d8ac0d0d-6b4f-11e9-b570-225b9ad5bed0" in namespace "secrets-4341" to be "success or failure"
Apr 30 13:57:09.353: INFO: Pod "pod-configmaps-d8ac0d0d-6b4f-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 22.679981ms
Apr 30 13:57:11.360: INFO: Pod "pod-configmaps-d8ac0d0d-6b4f-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029380111s
Apr 30 13:57:13.365: INFO: Pod "pod-configmaps-d8ac0d0d-6b4f-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035124311s
STEP: Saw pod success
Apr 30 13:57:13.366: INFO: Pod "pod-configmaps-d8ac0d0d-6b4f-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 13:57:13.368: INFO: Trying to get logs from node fatih-test-default-pool-qlpd pod pod-configmaps-d8ac0d0d-6b4f-11e9-b570-225b9ad5bed0 container env-test: <nil>
STEP: delete the pod
Apr 30 13:57:13.391: INFO: Waiting for pod pod-configmaps-d8ac0d0d-6b4f-11e9-b570-225b9ad5bed0 to disappear
Apr 30 13:57:13.393: INFO: Pod pod-configmaps-d8ac0d0d-6b4f-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 13:57:13.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4341" for this suite.
Apr 30 13:57:19.406: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 13:57:19.482: INFO: namespace secrets-4341 deletion completed in 6.087165986s

• [SLOW TEST:10.191 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 13:57:19.486: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 30 13:57:19.614: INFO: Waiting up to 5m0s for pod "downwardapi-volume-decd2f56-6b4f-11e9-b570-225b9ad5bed0" in namespace "downward-api-172" to be "success or failure"
Apr 30 13:57:19.620: INFO: Pod "downwardapi-volume-decd2f56-6b4f-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 5.911129ms
Apr 30 13:57:21.623: INFO: Pod "downwardapi-volume-decd2f56-6b4f-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009846391s
Apr 30 13:57:23.628: INFO: Pod "downwardapi-volume-decd2f56-6b4f-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013966789s
STEP: Saw pod success
Apr 30 13:57:23.628: INFO: Pod "downwardapi-volume-decd2f56-6b4f-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 13:57:23.631: INFO: Trying to get logs from node fatih-test-default-pool-qlp0 pod downwardapi-volume-decd2f56-6b4f-11e9-b570-225b9ad5bed0 container client-container: <nil>
STEP: delete the pod
Apr 30 13:57:23.659: INFO: Waiting for pod downwardapi-volume-decd2f56-6b4f-11e9-b570-225b9ad5bed0 to disappear
Apr 30 13:57:23.661: INFO: Pod downwardapi-volume-decd2f56-6b4f-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 13:57:23.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-172" for this suite.
Apr 30 13:57:29.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 13:57:29.750: INFO: namespace downward-api-172 deletion completed in 6.08588011s

• [SLOW TEST:10.265 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 13:57:29.754: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 30 13:57:29.793: INFO: (0) /api/v1/nodes/fatih-test-default-pool-qlp0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 8.973228ms)
Apr 30 13:57:29.797: INFO: (1) /api/v1/nodes/fatih-test-default-pool-qlp0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.492269ms)
Apr 30 13:57:29.801: INFO: (2) /api/v1/nodes/fatih-test-default-pool-qlp0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.043201ms)
Apr 30 13:57:29.805: INFO: (3) /api/v1/nodes/fatih-test-default-pool-qlp0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.709447ms)
Apr 30 13:57:29.814: INFO: (4) /api/v1/nodes/fatih-test-default-pool-qlp0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 6.570332ms)
Apr 30 13:57:29.817: INFO: (5) /api/v1/nodes/fatih-test-default-pool-qlp0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.418694ms)
Apr 30 13:57:29.820: INFO: (6) /api/v1/nodes/fatih-test-default-pool-qlp0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.996954ms)
Apr 30 13:57:29.823: INFO: (7) /api/v1/nodes/fatih-test-default-pool-qlp0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.75588ms)
Apr 30 13:57:29.826: INFO: (8) /api/v1/nodes/fatih-test-default-pool-qlp0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.0518ms)
Apr 30 13:57:29.833: INFO: (9) /api/v1/nodes/fatih-test-default-pool-qlp0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 6.441655ms)
Apr 30 13:57:29.836: INFO: (10) /api/v1/nodes/fatih-test-default-pool-qlp0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.978256ms)
Apr 30 13:57:29.838: INFO: (11) /api/v1/nodes/fatih-test-default-pool-qlp0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.602452ms)
Apr 30 13:57:29.841: INFO: (12) /api/v1/nodes/fatih-test-default-pool-qlp0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.645009ms)
Apr 30 13:57:29.844: INFO: (13) /api/v1/nodes/fatih-test-default-pool-qlp0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.58722ms)
Apr 30 13:57:29.847: INFO: (14) /api/v1/nodes/fatih-test-default-pool-qlp0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.691185ms)
Apr 30 13:57:29.850: INFO: (15) /api/v1/nodes/fatih-test-default-pool-qlp0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.947265ms)
Apr 30 13:57:29.852: INFO: (16) /api/v1/nodes/fatih-test-default-pool-qlp0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.868526ms)
Apr 30 13:57:29.862: INFO: (17) /api/v1/nodes/fatih-test-default-pool-qlp0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 9.646597ms)
Apr 30 13:57:29.865: INFO: (18) /api/v1/nodes/fatih-test-default-pool-qlp0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.110345ms)
Apr 30 13:57:29.868: INFO: (19) /api/v1/nodes/fatih-test-default-pool-qlp0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.986787ms)
[AfterEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 13:57:29.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-9657" for this suite.
Apr 30 13:57:35.881: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 13:57:36.023: INFO: namespace proxy-9657 deletion completed in 6.152022264s

• [SLOW TEST:6.269 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 13:57:36.026: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 13:57:40.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7589" for this suite.
Apr 30 13:57:46.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 13:57:46.242: INFO: namespace kubelet-test-7589 deletion completed in 6.098461999s

• [SLOW TEST:10.216 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 13:57:46.246: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating replication controller my-hostname-basic-eeb1a7db-6b4f-11e9-b570-225b9ad5bed0
Apr 30 13:57:46.279: INFO: Pod name my-hostname-basic-eeb1a7db-6b4f-11e9-b570-225b9ad5bed0: Found 0 pods out of 1
Apr 30 13:57:51.285: INFO: Pod name my-hostname-basic-eeb1a7db-6b4f-11e9-b570-225b9ad5bed0: Found 1 pods out of 1
Apr 30 13:57:51.285: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-eeb1a7db-6b4f-11e9-b570-225b9ad5bed0" are running
Apr 30 13:57:51.288: INFO: Pod "my-hostname-basic-eeb1a7db-6b4f-11e9-b570-225b9ad5bed0-65pcw" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-30 13:57:46 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-30 13:57:49 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-30 13:57:49 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-30 13:57:46 +0000 UTC Reason: Message:}])
Apr 30 13:57:51.288: INFO: Trying to dial the pod
Apr 30 13:57:56.304: INFO: Controller my-hostname-basic-eeb1a7db-6b4f-11e9-b570-225b9ad5bed0: Got expected result from replica 1 [my-hostname-basic-eeb1a7db-6b4f-11e9-b570-225b9ad5bed0-65pcw]: "my-hostname-basic-eeb1a7db-6b4f-11e9-b570-225b9ad5bed0-65pcw", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 13:57:56.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5946" for this suite.
Apr 30 13:58:02.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 13:58:02.436: INFO: namespace replication-controller-5946 deletion completed in 6.128061005s

• [SLOW TEST:16.190 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 13:58:02.439: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-f85d86bb-6b4f-11e9-b570-225b9ad5bed0
STEP: Creating secret with name s-test-opt-upd-f85d86f3-6b4f-11e9-b570-225b9ad5bed0
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-f85d86bb-6b4f-11e9-b570-225b9ad5bed0
STEP: Updating secret s-test-opt-upd-f85d86f3-6b4f-11e9-b570-225b9ad5bed0
STEP: Creating secret with name s-test-opt-create-f85d8709-6b4f-11e9-b570-225b9ad5bed0
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 13:58:08.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5445" for this suite.
Apr 30 13:58:30.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 13:58:30.777: INFO: namespace projected-5445 deletion completed in 22.113658619s

• [SLOW TEST:28.338 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 13:58:30.778: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-5245
Apr 30 13:58:34.829: INFO: Started pod liveness-exec in namespace container-probe-5245
STEP: checking the pod's current state and verifying that restartCount is present
Apr 30 13:58:34.833: INFO: Initial restart count of pod liveness-exec is 0
Apr 30 13:59:24.956: INFO: Restart count of pod container-probe-5245/liveness-exec is now 1 (50.122324351s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 13:59:24.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5245" for this suite.
Apr 30 13:59:30.979: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 13:59:31.090: INFO: namespace container-probe-5245 deletion completed in 6.122572916s

• [SLOW TEST:60.313 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 13:59:31.097: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 30 13:59:31.221: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Apr 30 13:59:36.226: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr 30 13:59:36.226: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr 30 13:59:42.285: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-4778,SelfLink:/apis/apps/v1/namespaces/deployment-4778/deployments/test-cleanup-deployment,UID:303965b7-6b50-11e9-a241-32cef6bf8510,ResourceVersion:4174,Generation:1,CreationTimestamp:2019-04-30 13:59:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-04-30 13:59:36 +0000 UTC 2019-04-30 13:59:36 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-04-30 13:59:40 +0000 UTC 2019-04-30 13:59:36 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-55cbfbc8f5" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Apr 30 13:59:42.288: INFO: New ReplicaSet "test-cleanup-deployment-55cbfbc8f5" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55cbfbc8f5,GenerateName:,Namespace:deployment-4778,SelfLink:/apis/apps/v1/namespaces/deployment-4778/replicasets/test-cleanup-deployment-55cbfbc8f5,UID:303b5ac5-6b50-11e9-a241-32cef6bf8510,ResourceVersion:4164,Generation:1,CreationTimestamp:2019-04-30 13:59:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 303965b7-6b50-11e9-a241-32cef6bf8510 0xc0010600c7 0xc0010600c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Apr 30 13:59:42.291: INFO: Pod "test-cleanup-deployment-55cbfbc8f5-zvcb5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55cbfbc8f5-zvcb5,GenerateName:test-cleanup-deployment-55cbfbc8f5-,Namespace:deployment-4778,SelfLink:/api/v1/namespaces/deployment-4778/pods/test-cleanup-deployment-55cbfbc8f5-zvcb5,UID:30405e50-6b50-11e9-a241-32cef6bf8510,ResourceVersion:4163,Generation:0,CreationTimestamp:2019-04-30 13:59:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-55cbfbc8f5 303b5ac5-6b50-11e9-a241-32cef6bf8510 0xc001060bb7 0xc001060bb8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-p4cbs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-p4cbs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-p4cbs true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:fatih-test-default-pool-qlp0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001060c20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001060d30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 13:59:36 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 13:59:40 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 13:59:40 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 13:59:36 +0000 UTC  }],Message:,Reason:,HostIP:10.136.184.227,PodIP:10.244.2.133,StartTime:2019-04-30 13:59:36 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-04-30 13:59:39 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://10bb3bdb269dc5384dd9c9cfedecf03afda7b27640307e229a565fe56d7c0806}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 13:59:42.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4778" for this suite.
Apr 30 13:59:48.308: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 13:59:48.377: INFO: namespace deployment-4778 deletion completed in 6.083109271s

• [SLOW TEST:17.281 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 13:59:48.378: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-7721
Apr 30 13:59:54.487: INFO: Started pod liveness-http in namespace container-probe-7721
STEP: checking the pod's current state and verifying that restartCount is present
Apr 30 13:59:54.490: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:03:55.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7721" for this suite.
Apr 30 14:04:01.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:04:01.320: INFO: namespace container-probe-7721 deletion completed in 6.084565829s

• [SLOW TEST:252.942 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:04:01.323: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Apr 30 14:04:01.355: INFO: Pod name pod-release: Found 0 pods out of 1
Apr 30 14:04:06.359: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:04:06.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9712" for this suite.
Apr 30 14:04:12.428: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:04:12.683: INFO: namespace replication-controller-9712 deletion completed in 6.282495745s

• [SLOW TEST:11.361 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:04:12.684: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's command
Apr 30 14:04:12.753: INFO: Waiting up to 5m0s for pod "var-expansion-d50b7ee6-6b50-11e9-b570-225b9ad5bed0" in namespace "var-expansion-702" to be "success or failure"
Apr 30 14:04:13.053: INFO: Pod "var-expansion-d50b7ee6-6b50-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 300.149958ms
Apr 30 14:04:15.056: INFO: Pod "var-expansion-d50b7ee6-6b50-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.303642634s
Apr 30 14:04:17.061: INFO: Pod "var-expansion-d50b7ee6-6b50-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.308013495s
STEP: Saw pod success
Apr 30 14:04:17.061: INFO: Pod "var-expansion-d50b7ee6-6b50-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 14:04:17.064: INFO: Trying to get logs from node fatih-test-default-pool-qlp1 pod var-expansion-d50b7ee6-6b50-11e9-b570-225b9ad5bed0 container dapi-container: <nil>
STEP: delete the pod
Apr 30 14:04:17.099: INFO: Waiting for pod var-expansion-d50b7ee6-6b50-11e9-b570-225b9ad5bed0 to disappear
Apr 30 14:04:17.102: INFO: Pod var-expansion-d50b7ee6-6b50-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:04:17.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-702" for this suite.
Apr 30 14:04:23.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:04:23.225: INFO: namespace var-expansion-702 deletion completed in 6.12040562s

• [SLOW TEST:10.541 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:04:23.229: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-db592f07-6b50-11e9-b570-225b9ad5bed0
STEP: Creating a pod to test consume secrets
Apr 30 14:04:23.323: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-db59bad0-6b50-11e9-b570-225b9ad5bed0" in namespace "projected-3797" to be "success or failure"
Apr 30 14:04:23.331: INFO: Pod "pod-projected-secrets-db59bad0-6b50-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 8.140332ms
Apr 30 14:04:25.336: INFO: Pod "pod-projected-secrets-db59bad0-6b50-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013015939s
Apr 30 14:04:27.341: INFO: Pod "pod-projected-secrets-db59bad0-6b50-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018661694s
STEP: Saw pod success
Apr 30 14:04:27.342: INFO: Pod "pod-projected-secrets-db59bad0-6b50-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 14:04:27.344: INFO: Trying to get logs from node fatih-test-default-pool-qlpd pod pod-projected-secrets-db59bad0-6b50-11e9-b570-225b9ad5bed0 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 30 14:04:27.375: INFO: Waiting for pod pod-projected-secrets-db59bad0-6b50-11e9-b570-225b9ad5bed0 to disappear
Apr 30 14:04:27.385: INFO: Pod pod-projected-secrets-db59bad0-6b50-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:04:27.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3797" for this suite.
Apr 30 14:04:33.406: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:04:33.532: INFO: namespace projected-3797 deletion completed in 6.143908358s

• [SLOW TEST:10.303 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:04:33.539: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-e17e9fa3-6b50-11e9-b570-225b9ad5bed0
STEP: Creating a pod to test consume configMaps
Apr 30 14:04:33.633: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e17f1a13-6b50-11e9-b570-225b9ad5bed0" in namespace "projected-8706" to be "success or failure"
Apr 30 14:04:33.641: INFO: Pod "pod-projected-configmaps-e17f1a13-6b50-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 7.526489ms
Apr 30 14:04:35.646: INFO: Pod "pod-projected-configmaps-e17f1a13-6b50-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012934691s
Apr 30 14:04:37.820: INFO: Pod "pod-projected-configmaps-e17f1a13-6b50-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.186717631s
STEP: Saw pod success
Apr 30 14:04:37.820: INFO: Pod "pod-projected-configmaps-e17f1a13-6b50-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 14:04:37.824: INFO: Trying to get logs from node fatih-test-default-pool-qlp0 pod pod-projected-configmaps-e17f1a13-6b50-11e9-b570-225b9ad5bed0 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 30 14:04:37.847: INFO: Waiting for pod pod-projected-configmaps-e17f1a13-6b50-11e9-b570-225b9ad5bed0 to disappear
Apr 30 14:04:37.849: INFO: Pod pod-projected-configmaps-e17f1a13-6b50-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:04:37.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8706" for this suite.
Apr 30 14:04:43.869: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:04:43.952: INFO: namespace projected-8706 deletion completed in 6.100017235s

• [SLOW TEST:10.413 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:04:43.953: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1389.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-1389.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1389.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-1389.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1389.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-1389.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1389.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-1389.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1389.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-1389.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1389.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-1389.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1389.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 137.4.245.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.245.4.137_udp@PTR;check="$$(dig +tcp +noall +answer +search 137.4.245.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.245.4.137_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1389.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-1389.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1389.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-1389.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1389.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-1389.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1389.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-1389.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1389.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-1389.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1389.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-1389.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1389.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 137.4.245.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.245.4.137_udp@PTR;check="$$(dig +tcp +noall +answer +search 137.4.245.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.245.4.137_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 30 14:04:58.068: INFO: Unable to read wheezy_udp@dns-test-service.dns-1389.svc.cluster.local from pod dns-1389/dns-test-e7b035bd-6b50-11e9-b570-225b9ad5bed0: the server could not find the requested resource (get pods dns-test-e7b035bd-6b50-11e9-b570-225b9ad5bed0)
Apr 30 14:04:58.071: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1389.svc.cluster.local from pod dns-1389/dns-test-e7b035bd-6b50-11e9-b570-225b9ad5bed0: the server could not find the requested resource (get pods dns-test-e7b035bd-6b50-11e9-b570-225b9ad5bed0)
Apr 30 14:04:58.074: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1389.svc.cluster.local from pod dns-1389/dns-test-e7b035bd-6b50-11e9-b570-225b9ad5bed0: the server could not find the requested resource (get pods dns-test-e7b035bd-6b50-11e9-b570-225b9ad5bed0)
Apr 30 14:04:58.077: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1389.svc.cluster.local from pod dns-1389/dns-test-e7b035bd-6b50-11e9-b570-225b9ad5bed0: the server could not find the requested resource (get pods dns-test-e7b035bd-6b50-11e9-b570-225b9ad5bed0)
Apr 30 14:04:58.096: INFO: Unable to read jessie_udp@dns-test-service.dns-1389.svc.cluster.local from pod dns-1389/dns-test-e7b035bd-6b50-11e9-b570-225b9ad5bed0: the server could not find the requested resource (get pods dns-test-e7b035bd-6b50-11e9-b570-225b9ad5bed0)
Apr 30 14:04:58.102: INFO: Unable to read jessie_tcp@dns-test-service.dns-1389.svc.cluster.local from pod dns-1389/dns-test-e7b035bd-6b50-11e9-b570-225b9ad5bed0: the server could not find the requested resource (get pods dns-test-e7b035bd-6b50-11e9-b570-225b9ad5bed0)
Apr 30 14:04:58.105: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1389.svc.cluster.local from pod dns-1389/dns-test-e7b035bd-6b50-11e9-b570-225b9ad5bed0: the server could not find the requested resource (get pods dns-test-e7b035bd-6b50-11e9-b570-225b9ad5bed0)
Apr 30 14:04:58.108: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1389.svc.cluster.local from pod dns-1389/dns-test-e7b035bd-6b50-11e9-b570-225b9ad5bed0: the server could not find the requested resource (get pods dns-test-e7b035bd-6b50-11e9-b570-225b9ad5bed0)
Apr 30 14:04:58.124: INFO: Lookups using dns-1389/dns-test-e7b035bd-6b50-11e9-b570-225b9ad5bed0 failed for: [wheezy_udp@dns-test-service.dns-1389.svc.cluster.local wheezy_tcp@dns-test-service.dns-1389.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1389.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1389.svc.cluster.local jessie_udp@dns-test-service.dns-1389.svc.cluster.local jessie_tcp@dns-test-service.dns-1389.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1389.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1389.svc.cluster.local]

Apr 30 14:05:03.203: INFO: DNS probes using dns-1389/dns-test-e7b035bd-6b50-11e9-b570-225b9ad5bed0 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:05:03.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1389" for this suite.
Apr 30 14:05:09.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:05:09.415: INFO: namespace dns-1389 deletion completed in 6.090388412s

• [SLOW TEST:25.462 seconds]
[sig-network] DNS
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:05:09.418: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name projected-secret-test-f6dc7ba3-6b50-11e9-b570-225b9ad5bed0
STEP: Creating a pod to test consume secrets
Apr 30 14:05:09.479: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f6dce7a6-6b50-11e9-b570-225b9ad5bed0" in namespace "projected-1747" to be "success or failure"
Apr 30 14:05:09.490: INFO: Pod "pod-projected-secrets-f6dce7a6-6b50-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 10.858731ms
Apr 30 14:05:11.495: INFO: Pod "pod-projected-secrets-f6dce7a6-6b50-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015930764s
Apr 30 14:05:13.501: INFO: Pod "pod-projected-secrets-f6dce7a6-6b50-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021643165s
STEP: Saw pod success
Apr 30 14:05:13.501: INFO: Pod "pod-projected-secrets-f6dce7a6-6b50-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 14:05:13.507: INFO: Trying to get logs from node fatih-test-default-pool-qlpd pod pod-projected-secrets-f6dce7a6-6b50-11e9-b570-225b9ad5bed0 container secret-volume-test: <nil>
STEP: delete the pod
Apr 30 14:05:13.533: INFO: Waiting for pod pod-projected-secrets-f6dce7a6-6b50-11e9-b570-225b9ad5bed0 to disappear
Apr 30 14:05:13.536: INFO: Pod pod-projected-secrets-f6dce7a6-6b50-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:05:13.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1747" for this suite.
Apr 30 14:05:19.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:05:19.626: INFO: namespace projected-1747 deletion completed in 6.085101724s

• [SLOW TEST:10.208 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:05:19.630: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Apr 30 14:05:19.676: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 30 14:05:19.680: INFO: Waiting for terminating namespaces to be deleted...
Apr 30 14:05:19.683: INFO: 
Logging pods the kubelet thinks is on node fatih-test-default-pool-qlp0 before test
Apr 30 14:05:19.694: INFO: csi-do-node-88qtw from kube-system started at 2019-04-30 13:45:15 +0000 UTC (2 container statuses recorded)
Apr 30 14:05:19.694: INFO: 	Container csi-do-plugin ready: true, restart count 0
Apr 30 14:05:19.694: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Apr 30 14:05:19.694: INFO: do-node-agent-mk55q from kube-system started at 2019-04-30 13:45:15 +0000 UTC (1 container statuses recorded)
Apr 30 14:05:19.694: INFO: 	Container do-node-agent ready: true, restart count 0
Apr 30 14:05:19.695: INFO: sonobuoy-e2e-job-92ad9d5c6b2f41f9 from heptio-sonobuoy started at 2019-04-30 13:55:40 +0000 UTC (2 container statuses recorded)
Apr 30 14:05:19.695: INFO: 	Container e2e ready: true, restart count 0
Apr 30 14:05:19.695: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 30 14:05:19.695: INFO: sonobuoy-systemd-logs-daemon-set-21faf258562f426d-9dw9m from heptio-sonobuoy started at 2019-04-30 13:55:40 +0000 UTC (2 container statuses recorded)
Apr 30 14:05:19.695: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 30 14:05:19.695: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 30 14:05:19.695: INFO: cilium-v95q2 from kube-system started at 2019-04-30 13:44:45 +0000 UTC (1 container statuses recorded)
Apr 30 14:05:19.696: INFO: 	Container cilium-agent ready: true, restart count 0
Apr 30 14:05:19.696: INFO: kube-proxy-spjdh from kube-system started at 2019-04-30 13:44:45 +0000 UTC (1 container statuses recorded)
Apr 30 14:05:19.696: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 30 14:05:19.696: INFO: 
Logging pods the kubelet thinks is on node fatih-test-default-pool-qlp1 before test
Apr 30 14:05:19.704: INFO: kube-proxy-rk9gr from kube-system started at 2019-04-30 13:44:25 +0000 UTC (1 container statuses recorded)
Apr 30 14:05:19.704: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 30 14:05:19.704: INFO: do-node-agent-n65gv from kube-system started at 2019-04-30 13:44:55 +0000 UTC (1 container statuses recorded)
Apr 30 14:05:19.704: INFO: 	Container do-node-agent ready: true, restart count 0
Apr 30 14:05:19.705: INFO: coredns-5f44b47f5f-lvrnq from kube-system started at 2019-04-30 13:44:56 +0000 UTC (1 container statuses recorded)
Apr 30 14:05:19.705: INFO: 	Container coredns ready: true, restart count 0
Apr 30 14:05:19.705: INFO: coredns-5f44b47f5f-76mdx from kube-system started at 2019-04-30 13:45:00 +0000 UTC (1 container statuses recorded)
Apr 30 14:05:19.705: INFO: 	Container coredns ready: true, restart count 0
Apr 30 14:05:19.705: INFO: cilium-b6pth from kube-system started at 2019-04-30 13:44:25 +0000 UTC (1 container statuses recorded)
Apr 30 14:05:19.705: INFO: 	Container cilium-agent ready: true, restart count 0
Apr 30 14:05:19.705: INFO: csi-do-node-hlf2r from kube-system started at 2019-04-30 13:44:55 +0000 UTC (2 container statuses recorded)
Apr 30 14:05:19.705: INFO: 	Container csi-do-plugin ready: true, restart count 0
Apr 30 14:05:19.706: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Apr 30 14:05:19.706: INFO: cilium-operator-5469488bbb-7xnvh from kube-system started at 2019-04-30 13:44:56 +0000 UTC (1 container statuses recorded)
Apr 30 14:05:19.706: INFO: 	Container cilium-operator ready: true, restart count 0
Apr 30 14:05:19.706: INFO: sonobuoy-systemd-logs-daemon-set-21faf258562f426d-9t7b6 from heptio-sonobuoy started at 2019-04-30 13:55:40 +0000 UTC (2 container statuses recorded)
Apr 30 14:05:19.706: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 30 14:05:19.706: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 30 14:05:19.706: INFO: 
Logging pods the kubelet thinks is on node fatih-test-default-pool-qlpd before test
Apr 30 14:05:19.714: INFO: kube-proxy-vtjjw from kube-system started at 2019-04-30 13:44:32 +0000 UTC (1 container statuses recorded)
Apr 30 14:05:19.715: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 30 14:05:19.715: INFO: cilium-s9mvd from kube-system started at 2019-04-30 13:44:32 +0000 UTC (1 container statuses recorded)
Apr 30 14:05:19.715: INFO: 	Container cilium-agent ready: true, restart count 0
Apr 30 14:05:19.715: INFO: do-node-agent-hmckj from kube-system started at 2019-04-30 13:45:02 +0000 UTC (1 container statuses recorded)
Apr 30 14:05:19.715: INFO: 	Container do-node-agent ready: true, restart count 0
Apr 30 14:05:19.715: INFO: csi-do-node-jp2pr from kube-system started at 2019-04-30 13:45:02 +0000 UTC (2 container statuses recorded)
Apr 30 14:05:19.716: INFO: 	Container csi-do-plugin ready: true, restart count 0
Apr 30 14:05:19.716: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Apr 30 14:05:19.716: INFO: sonobuoy from heptio-sonobuoy started at 2019-04-30 13:55:34 +0000 UTC (1 container statuses recorded)
Apr 30 14:05:19.716: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 30 14:05:19.716: INFO: sonobuoy-systemd-logs-daemon-set-21faf258562f426d-rrmss from heptio-sonobuoy started at 2019-04-30 13:55:41 +0000 UTC (2 container statuses recorded)
Apr 30 14:05:19.716: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 30 14:05:19.717: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-ff5f5dc8-6b50-11e9-b570-225b9ad5bed0 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-ff5f5dc8-6b50-11e9-b570-225b9ad5bed0 off the node fatih-test-default-pool-qlp0
STEP: verifying the node doesn't have the label kubernetes.io/e2e-ff5f5dc8-6b50-11e9-b570-225b9ad5bed0
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:05:27.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-19" for this suite.
Apr 30 14:05:35.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:05:36.020: INFO: namespace sched-pred-19 deletion completed in 8.176916852s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:16.391 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:05:36.023: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Apr 30 14:05:40.096: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-06b7360f-6b51-11e9-b570-225b9ad5bed0,GenerateName:,Namespace:events-5205,SelfLink:/api/v1/namespaces/events-5205/pods/send-events-06b7360f-6b51-11e9-b570-225b9ad5bed0,UID:06b64ee7-6b51-11e9-a241-32cef6bf8510,ResourceVersion:5259,Generation:0,CreationTimestamp:2019-04-30 14:05:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 70440629,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nx8bj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nx8bj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-nx8bj true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:fatih-test-default-pool-qlp1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c87030} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c87050}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:05:36 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:05:40 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:05:40 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:05:36 +0000 UTC  }],Message:,Reason:,HostIP:10.136.184.8,PodIP:10.244.0.132,StartTime:2019-04-30 14:05:36 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-04-30 14:05:39 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://05dbe67c85c96f7a60a5f46b3558ef36cc9a50f8fb23950905f51f03bb7bb432}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Apr 30 14:05:42.100: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Apr 30 14:05:44.105: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:05:44.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-5205" for this suite.
Apr 30 14:06:24.135: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:06:24.208: INFO: namespace events-5205 deletion completed in 40.092086232s

• [SLOW TEST:48.186 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:06:24.211: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-7881
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-7881
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-7881
Apr 30 14:06:24.267: INFO: Found 0 stateful pods, waiting for 1
Apr 30 14:06:34.274: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Apr 30 14:06:34.279: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 exec --namespace=statefulset-7881 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 30 14:06:34.590: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 30 14:06:34.590: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 30 14:06:34.590: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 30 14:06:34.593: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr 30 14:06:44.599: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 30 14:06:44.599: INFO: Waiting for statefulset status.replicas updated to 0
Apr 30 14:06:44.613: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999674s
Apr 30 14:06:45.618: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.995927365s
Apr 30 14:06:46.622: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.991053539s
Apr 30 14:06:47.626: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.986710212s
Apr 30 14:06:48.630: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.982819879s
Apr 30 14:06:49.660: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.978876662s
Apr 30 14:06:50.666: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.948569353s
Apr 30 14:06:51.673: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.942974452s
Apr 30 14:06:52.832: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.781523344s
Apr 30 14:06:53.837: INFO: Verifying statefulset ss doesn't scale past 1 for another 776.949773ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-7881
Apr 30 14:06:54.841: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 exec --namespace=statefulset-7881 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 30 14:06:55.125: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr 30 14:06:55.125: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 30 14:06:55.125: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 30 14:06:55.129: INFO: Found 1 stateful pods, waiting for 3
Apr 30 14:07:05.134: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 30 14:07:05.134: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 30 14:07:05.134: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Apr 30 14:07:05.141: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 exec --namespace=statefulset-7881 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 30 14:07:05.425: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 30 14:07:05.425: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 30 14:07:05.425: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 30 14:07:05.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 exec --namespace=statefulset-7881 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 30 14:07:05.710: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 30 14:07:05.710: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 30 14:07:05.710: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 30 14:07:05.711: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 exec --namespace=statefulset-7881 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 30 14:07:06.156: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 30 14:07:06.156: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 30 14:07:06.156: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 30 14:07:06.156: INFO: Waiting for statefulset status.replicas updated to 0
Apr 30 14:07:06.159: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Apr 30 14:07:16.168: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 30 14:07:16.168: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr 30 14:07:16.168: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr 30 14:07:16.185: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999724s
Apr 30 14:07:17.189: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.992061466s
Apr 30 14:07:18.194: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.988092965s
Apr 30 14:07:19.198: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.982805679s
Apr 30 14:07:20.203: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.979210691s
Apr 30 14:07:21.207: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.974363772s
Apr 30 14:07:22.211: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.970164381s
Apr 30 14:07:23.215: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.965829593s
Apr 30 14:07:24.220: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.962057842s
Apr 30 14:07:25.223: INFO: Verifying statefulset ss doesn't scale past 3 for another 957.158543ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-7881
Apr 30 14:07:26.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 exec --namespace=statefulset-7881 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 30 14:07:26.513: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr 30 14:07:26.513: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 30 14:07:26.513: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 30 14:07:26.513: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 exec --namespace=statefulset-7881 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 30 14:07:26.878: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr 30 14:07:26.878: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 30 14:07:26.878: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 30 14:07:26.878: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 exec --namespace=statefulset-7881 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 30 14:07:27.222: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr 30 14:07:27.222: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 30 14:07:27.222: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 30 14:07:27.222: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr 30 14:07:47.239: INFO: Deleting all statefulset in ns statefulset-7881
Apr 30 14:07:47.243: INFO: Scaling statefulset ss to 0
Apr 30 14:07:47.251: INFO: Waiting for statefulset status.replicas updated to 0
Apr 30 14:07:47.253: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:07:47.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7881" for this suite.
Apr 30 14:07:53.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:07:53.365: INFO: namespace statefulset-7881 deletion completed in 6.091192561s

• [SLOW TEST:89.154 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:07:53.368: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-projected-all-test-volume-58916c0b-6b51-11e9-b570-225b9ad5bed0
STEP: Creating secret with name secret-projected-all-test-volume-58916bf3-6b51-11e9-b570-225b9ad5bed0
STEP: Creating a pod to test Check all projections for projected volume plugin
Apr 30 14:07:53.409: INFO: Waiting up to 5m0s for pod "projected-volume-58916acd-6b51-11e9-b570-225b9ad5bed0" in namespace "projected-6173" to be "success or failure"
Apr 30 14:07:53.414: INFO: Pod "projected-volume-58916acd-6b51-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.845729ms
Apr 30 14:07:55.420: INFO: Pod "projected-volume-58916acd-6b51-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010513644s
STEP: Saw pod success
Apr 30 14:07:55.420: INFO: Pod "projected-volume-58916acd-6b51-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 14:07:55.424: INFO: Trying to get logs from node fatih-test-default-pool-qlpd pod projected-volume-58916acd-6b51-11e9-b570-225b9ad5bed0 container projected-all-volume-test: <nil>
STEP: delete the pod
Apr 30 14:07:55.447: INFO: Waiting for pod projected-volume-58916acd-6b51-11e9-b570-225b9ad5bed0 to disappear
Apr 30 14:07:55.452: INFO: Pod projected-volume-58916acd-6b51-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:07:55.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6173" for this suite.
Apr 30 14:08:01.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:08:01.548: INFO: namespace projected-6173 deletion completed in 6.091937036s

• [SLOW TEST:8.180 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:08:01.551: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Apr 30 14:08:01.581: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:08:12.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-789" for this suite.
Apr 30 14:08:18.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:08:18.993: INFO: namespace pods-789 deletion completed in 6.081555839s

• [SLOW TEST:17.442 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:08:18.998: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's args
Apr 30 14:08:19.028: INFO: Waiting up to 5m0s for pod "var-expansion-67d7da1b-6b51-11e9-b570-225b9ad5bed0" in namespace "var-expansion-4563" to be "success or failure"
Apr 30 14:08:19.035: INFO: Pod "var-expansion-67d7da1b-6b51-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.412899ms
Apr 30 14:08:21.039: INFO: Pod "var-expansion-67d7da1b-6b51-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011044926s
Apr 30 14:08:23.044: INFO: Pod "var-expansion-67d7da1b-6b51-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015355763s
STEP: Saw pod success
Apr 30 14:08:23.044: INFO: Pod "var-expansion-67d7da1b-6b51-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 14:08:23.047: INFO: Trying to get logs from node fatih-test-default-pool-qlp1 pod var-expansion-67d7da1b-6b51-11e9-b570-225b9ad5bed0 container dapi-container: <nil>
STEP: delete the pod
Apr 30 14:08:23.071: INFO: Waiting for pod var-expansion-67d7da1b-6b51-11e9-b570-225b9ad5bed0 to disappear
Apr 30 14:08:23.073: INFO: Pod var-expansion-67d7da1b-6b51-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:08:23.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4563" for this suite.
Apr 30 14:08:29.085: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:08:29.175: INFO: namespace var-expansion-4563 deletion completed in 6.098071044s

• [SLOW TEST:10.177 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:08:29.177: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-6de94fe3-6b51-11e9-b570-225b9ad5bed0
STEP: Creating a pod to test consume configMaps
Apr 30 14:08:29.213: INFO: Waiting up to 5m0s for pod "pod-configmaps-6de9bf88-6b51-11e9-b570-225b9ad5bed0" in namespace "configmap-1948" to be "success or failure"
Apr 30 14:08:29.217: INFO: Pod "pod-configmaps-6de9bf88-6b51-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029176ms
Apr 30 14:08:31.221: INFO: Pod "pod-configmaps-6de9bf88-6b51-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008429837s
Apr 30 14:08:33.226: INFO: Pod "pod-configmaps-6de9bf88-6b51-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012974957s
STEP: Saw pod success
Apr 30 14:08:33.226: INFO: Pod "pod-configmaps-6de9bf88-6b51-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 14:08:33.229: INFO: Trying to get logs from node fatih-test-default-pool-qlpd pod pod-configmaps-6de9bf88-6b51-11e9-b570-225b9ad5bed0 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 30 14:08:33.248: INFO: Waiting for pod pod-configmaps-6de9bf88-6b51-11e9-b570-225b9ad5bed0 to disappear
Apr 30 14:08:33.250: INFO: Pod pod-configmaps-6de9bf88-6b51-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:08:33.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1948" for this suite.
Apr 30 14:08:39.262: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:08:39.347: INFO: namespace configmap-1948 deletion completed in 6.093454948s

• [SLOW TEST:10.170 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:08:39.350: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Apr 30 14:08:39.392: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 30 14:08:39.397: INFO: Waiting for terminating namespaces to be deleted...
Apr 30 14:08:39.399: INFO: 
Logging pods the kubelet thinks is on node fatih-test-default-pool-qlp0 before test
Apr 30 14:08:39.408: INFO: do-node-agent-mk55q from kube-system started at 2019-04-30 13:45:15 +0000 UTC (1 container statuses recorded)
Apr 30 14:08:39.408: INFO: 	Container do-node-agent ready: true, restart count 0
Apr 30 14:08:39.408: INFO: sonobuoy-e2e-job-92ad9d5c6b2f41f9 from heptio-sonobuoy started at 2019-04-30 13:55:40 +0000 UTC (2 container statuses recorded)
Apr 30 14:08:39.408: INFO: 	Container e2e ready: true, restart count 0
Apr 30 14:08:39.409: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 30 14:08:39.409: INFO: sonobuoy-systemd-logs-daemon-set-21faf258562f426d-9dw9m from heptio-sonobuoy started at 2019-04-30 13:55:40 +0000 UTC (2 container statuses recorded)
Apr 30 14:08:39.409: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 30 14:08:39.409: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 30 14:08:39.409: INFO: cilium-v95q2 from kube-system started at 2019-04-30 13:44:45 +0000 UTC (1 container statuses recorded)
Apr 30 14:08:39.409: INFO: 	Container cilium-agent ready: true, restart count 0
Apr 30 14:08:39.409: INFO: kube-proxy-spjdh from kube-system started at 2019-04-30 13:44:45 +0000 UTC (1 container statuses recorded)
Apr 30 14:08:39.409: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 30 14:08:39.409: INFO: csi-do-node-88qtw from kube-system started at 2019-04-30 13:45:15 +0000 UTC (2 container statuses recorded)
Apr 30 14:08:39.410: INFO: 	Container csi-do-plugin ready: true, restart count 0
Apr 30 14:08:39.410: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Apr 30 14:08:39.410: INFO: 
Logging pods the kubelet thinks is on node fatih-test-default-pool-qlp1 before test
Apr 30 14:08:39.421: INFO: csi-do-node-hlf2r from kube-system started at 2019-04-30 13:44:55 +0000 UTC (2 container statuses recorded)
Apr 30 14:08:39.422: INFO: 	Container csi-do-plugin ready: true, restart count 0
Apr 30 14:08:39.422: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Apr 30 14:08:39.422: INFO: cilium-operator-5469488bbb-7xnvh from kube-system started at 2019-04-30 13:44:56 +0000 UTC (1 container statuses recorded)
Apr 30 14:08:39.422: INFO: 	Container cilium-operator ready: true, restart count 0
Apr 30 14:08:39.422: INFO: sonobuoy-systemd-logs-daemon-set-21faf258562f426d-9t7b6 from heptio-sonobuoy started at 2019-04-30 13:55:40 +0000 UTC (2 container statuses recorded)
Apr 30 14:08:39.422: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 30 14:08:39.422: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 30 14:08:39.422: INFO: cilium-b6pth from kube-system started at 2019-04-30 13:44:25 +0000 UTC (1 container statuses recorded)
Apr 30 14:08:39.423: INFO: 	Container cilium-agent ready: true, restart count 0
Apr 30 14:08:39.423: INFO: do-node-agent-n65gv from kube-system started at 2019-04-30 13:44:55 +0000 UTC (1 container statuses recorded)
Apr 30 14:08:39.423: INFO: 	Container do-node-agent ready: true, restart count 0
Apr 30 14:08:39.423: INFO: coredns-5f44b47f5f-lvrnq from kube-system started at 2019-04-30 13:44:56 +0000 UTC (1 container statuses recorded)
Apr 30 14:08:39.423: INFO: 	Container coredns ready: true, restart count 0
Apr 30 14:08:39.423: INFO: coredns-5f44b47f5f-76mdx from kube-system started at 2019-04-30 13:45:00 +0000 UTC (1 container statuses recorded)
Apr 30 14:08:39.423: INFO: 	Container coredns ready: true, restart count 0
Apr 30 14:08:39.423: INFO: kube-proxy-rk9gr from kube-system started at 2019-04-30 13:44:25 +0000 UTC (1 container statuses recorded)
Apr 30 14:08:39.423: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 30 14:08:39.424: INFO: 
Logging pods the kubelet thinks is on node fatih-test-default-pool-qlpd before test
Apr 30 14:08:39.432: INFO: do-node-agent-hmckj from kube-system started at 2019-04-30 13:45:02 +0000 UTC (1 container statuses recorded)
Apr 30 14:08:39.432: INFO: 	Container do-node-agent ready: true, restart count 0
Apr 30 14:08:39.433: INFO: csi-do-node-jp2pr from kube-system started at 2019-04-30 13:45:02 +0000 UTC (2 container statuses recorded)
Apr 30 14:08:39.433: INFO: 	Container csi-do-plugin ready: true, restart count 0
Apr 30 14:08:39.433: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Apr 30 14:08:39.433: INFO: sonobuoy from heptio-sonobuoy started at 2019-04-30 13:55:34 +0000 UTC (1 container statuses recorded)
Apr 30 14:08:39.433: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 30 14:08:39.433: INFO: sonobuoy-systemd-logs-daemon-set-21faf258562f426d-rrmss from heptio-sonobuoy started at 2019-04-30 13:55:41 +0000 UTC (2 container statuses recorded)
Apr 30 14:08:39.433: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 30 14:08:39.434: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 30 14:08:39.434: INFO: kube-proxy-vtjjw from kube-system started at 2019-04-30 13:44:32 +0000 UTC (1 container statuses recorded)
Apr 30 14:08:39.434: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 30 14:08:39.434: INFO: cilium-s9mvd from kube-system started at 2019-04-30 13:44:32 +0000 UTC (1 container statuses recorded)
Apr 30 14:08:39.434: INFO: 	Container cilium-agent ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: verifying the node has the label node fatih-test-default-pool-qlp0
STEP: verifying the node has the label node fatih-test-default-pool-qlp1
STEP: verifying the node has the label node fatih-test-default-pool-qlpd
Apr 30 14:08:39.499: INFO: Pod sonobuoy requesting resource cpu=0m on Node fatih-test-default-pool-qlpd
Apr 30 14:08:39.499: INFO: Pod sonobuoy-e2e-job-92ad9d5c6b2f41f9 requesting resource cpu=0m on Node fatih-test-default-pool-qlp0
Apr 30 14:08:39.499: INFO: Pod sonobuoy-systemd-logs-daemon-set-21faf258562f426d-9dw9m requesting resource cpu=0m on Node fatih-test-default-pool-qlp0
Apr 30 14:08:39.500: INFO: Pod sonobuoy-systemd-logs-daemon-set-21faf258562f426d-9t7b6 requesting resource cpu=0m on Node fatih-test-default-pool-qlp1
Apr 30 14:08:39.500: INFO: Pod sonobuoy-systemd-logs-daemon-set-21faf258562f426d-rrmss requesting resource cpu=0m on Node fatih-test-default-pool-qlpd
Apr 30 14:08:39.500: INFO: Pod cilium-b6pth requesting resource cpu=300m on Node fatih-test-default-pool-qlp1
Apr 30 14:08:39.500: INFO: Pod cilium-operator-5469488bbb-7xnvh requesting resource cpu=0m on Node fatih-test-default-pool-qlp1
Apr 30 14:08:39.500: INFO: Pod cilium-s9mvd requesting resource cpu=300m on Node fatih-test-default-pool-qlpd
Apr 30 14:08:39.500: INFO: Pod cilium-v95q2 requesting resource cpu=300m on Node fatih-test-default-pool-qlp0
Apr 30 14:08:39.501: INFO: Pod coredns-5f44b47f5f-76mdx requesting resource cpu=100m on Node fatih-test-default-pool-qlp1
Apr 30 14:08:39.501: INFO: Pod coredns-5f44b47f5f-lvrnq requesting resource cpu=100m on Node fatih-test-default-pool-qlp1
Apr 30 14:08:39.501: INFO: Pod csi-do-node-88qtw requesting resource cpu=0m on Node fatih-test-default-pool-qlp0
Apr 30 14:08:39.501: INFO: Pod csi-do-node-hlf2r requesting resource cpu=0m on Node fatih-test-default-pool-qlp1
Apr 30 14:08:39.501: INFO: Pod csi-do-node-jp2pr requesting resource cpu=0m on Node fatih-test-default-pool-qlpd
Apr 30 14:08:39.501: INFO: Pod do-node-agent-hmckj requesting resource cpu=102m on Node fatih-test-default-pool-qlpd
Apr 30 14:08:39.501: INFO: Pod do-node-agent-mk55q requesting resource cpu=102m on Node fatih-test-default-pool-qlp0
Apr 30 14:08:39.502: INFO: Pod do-node-agent-n65gv requesting resource cpu=102m on Node fatih-test-default-pool-qlp1
Apr 30 14:08:39.502: INFO: Pod kube-proxy-rk9gr requesting resource cpu=0m on Node fatih-test-default-pool-qlp1
Apr 30 14:08:39.502: INFO: Pod kube-proxy-spjdh requesting resource cpu=0m on Node fatih-test-default-pool-qlp0
Apr 30 14:08:39.502: INFO: Pod kube-proxy-vtjjw requesting resource cpu=0m on Node fatih-test-default-pool-qlpd
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-740cc382-6b51-11e9-b570-225b9ad5bed0.159a45c1b6828fbe], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7041/filler-pod-740cc382-6b51-11e9-b570-225b9ad5bed0 to fatih-test-default-pool-qlp0]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-740cc382-6b51-11e9-b570-225b9ad5bed0.159a45c22ffaae78], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-740cc382-6b51-11e9-b570-225b9ad5bed0.159a45c2323ff45b], Reason = [Created], Message = [Created container filler-pod-740cc382-6b51-11e9-b570-225b9ad5bed0]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-740cc382-6b51-11e9-b570-225b9ad5bed0.159a45c23c2f0191], Reason = [Started], Message = [Started container filler-pod-740cc382-6b51-11e9-b570-225b9ad5bed0]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-740db281-6b51-11e9-b570-225b9ad5bed0.159a45c1b6ff748a], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7041/filler-pod-740db281-6b51-11e9-b570-225b9ad5bed0 to fatih-test-default-pool-qlp1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-740db281-6b51-11e9-b570-225b9ad5bed0.159a45c21c94b714], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-740db281-6b51-11e9-b570-225b9ad5bed0.159a45c21eab3f10], Reason = [Created], Message = [Created container filler-pod-740db281-6b51-11e9-b570-225b9ad5bed0]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-740db281-6b51-11e9-b570-225b9ad5bed0.159a45c22912b6f9], Reason = [Started], Message = [Started container filler-pod-740db281-6b51-11e9-b570-225b9ad5bed0]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-740fb369-6b51-11e9-b570-225b9ad5bed0.159a45c1b7edc6d1], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7041/filler-pod-740fb369-6b51-11e9-b570-225b9ad5bed0 to fatih-test-default-pool-qlpd]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-740fb369-6b51-11e9-b570-225b9ad5bed0.159a45c208deccfe], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-740fb369-6b51-11e9-b570-225b9ad5bed0.159a45c20aeada78], Reason = [Created], Message = [Created container filler-pod-740fb369-6b51-11e9-b570-225b9ad5bed0]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-740fb369-6b51-11e9-b570-225b9ad5bed0.159a45c2133c1aa0], Reason = [Started], Message = [Started container filler-pod-740fb369-6b51-11e9-b570-225b9ad5bed0]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.159a45c2aa1d1526], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node fatih-test-default-pool-qlpd
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node fatih-test-default-pool-qlp0
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node fatih-test-default-pool-qlp1
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:08:44.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7041" for this suite.
Apr 30 14:08:50.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:08:50.762: INFO: namespace sched-pred-7041 deletion completed in 6.105679046s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:11.413 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:08:50.766: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr 30 14:08:50.861: INFO: Waiting up to 5m0s for pod "downward-api-7ad10fa8-6b51-11e9-b570-225b9ad5bed0" in namespace "downward-api-3189" to be "success or failure"
Apr 30 14:08:50.869: INFO: Pod "downward-api-7ad10fa8-6b51-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 8.086818ms
Apr 30 14:08:52.876: INFO: Pod "downward-api-7ad10fa8-6b51-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014485017s
Apr 30 14:08:54.879: INFO: Pod "downward-api-7ad10fa8-6b51-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017793385s
STEP: Saw pod success
Apr 30 14:08:54.879: INFO: Pod "downward-api-7ad10fa8-6b51-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 14:08:54.881: INFO: Trying to get logs from node fatih-test-default-pool-qlp0 pod downward-api-7ad10fa8-6b51-11e9-b570-225b9ad5bed0 container dapi-container: <nil>
STEP: delete the pod
Apr 30 14:08:54.903: INFO: Waiting for pod downward-api-7ad10fa8-6b51-11e9-b570-225b9ad5bed0 to disappear
Apr 30 14:08:54.906: INFO: Pod downward-api-7ad10fa8-6b51-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:08:54.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3189" for this suite.
Apr 30 14:09:00.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:09:01.020: INFO: namespace downward-api-3189 deletion completed in 6.109822673s

• [SLOW TEST:10.254 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:09:01.025: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Apr 30 14:09:05.645: INFO: Successfully updated pod "pod-update-activedeadlineseconds-80ee0710-6b51-11e9-b570-225b9ad5bed0"
Apr 30 14:09:05.645: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-80ee0710-6b51-11e9-b570-225b9ad5bed0" in namespace "pods-5420" to be "terminated due to deadline exceeded"
Apr 30 14:09:05.648: INFO: Pod "pod-update-activedeadlineseconds-80ee0710-6b51-11e9-b570-225b9ad5bed0": Phase="Running", Reason="", readiness=true. Elapsed: 2.798543ms
Apr 30 14:09:07.826: INFO: Pod "pod-update-activedeadlineseconds-80ee0710-6b51-11e9-b570-225b9ad5bed0": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.181162891s
Apr 30 14:09:07.826: INFO: Pod "pod-update-activedeadlineseconds-80ee0710-6b51-11e9-b570-225b9ad5bed0" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:09:07.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5420" for this suite.
Apr 30 14:09:13.842: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:09:13.933: INFO: namespace pods-5420 deletion completed in 6.101308167s

• [SLOW TEST:12.909 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:09:13.937: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-zjwf
STEP: Creating a pod to test atomic-volume-subpath
Apr 30 14:09:13.982: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-zjwf" in namespace "subpath-7962" to be "success or failure"
Apr 30 14:09:13.987: INFO: Pod "pod-subpath-test-configmap-zjwf": Phase="Pending", Reason="", readiness=false. Elapsed: 5.482687ms
Apr 30 14:09:15.990: INFO: Pod "pod-subpath-test-configmap-zjwf": Phase="Running", Reason="", readiness=true. Elapsed: 2.008851234s
Apr 30 14:09:17.994: INFO: Pod "pod-subpath-test-configmap-zjwf": Phase="Running", Reason="", readiness=true. Elapsed: 4.012204065s
Apr 30 14:09:20.111: INFO: Pod "pod-subpath-test-configmap-zjwf": Phase="Running", Reason="", readiness=true. Elapsed: 6.129844945s
Apr 30 14:09:22.117: INFO: Pod "pod-subpath-test-configmap-zjwf": Phase="Running", Reason="", readiness=true. Elapsed: 8.135045146s
Apr 30 14:09:24.121: INFO: Pod "pod-subpath-test-configmap-zjwf": Phase="Running", Reason="", readiness=true. Elapsed: 10.139612281s
Apr 30 14:09:26.125: INFO: Pod "pod-subpath-test-configmap-zjwf": Phase="Running", Reason="", readiness=true. Elapsed: 12.143555225s
Apr 30 14:09:28.130: INFO: Pod "pod-subpath-test-configmap-zjwf": Phase="Running", Reason="", readiness=true. Elapsed: 14.147945708s
Apr 30 14:09:30.134: INFO: Pod "pod-subpath-test-configmap-zjwf": Phase="Running", Reason="", readiness=true. Elapsed: 16.152463037s
Apr 30 14:09:32.139: INFO: Pod "pod-subpath-test-configmap-zjwf": Phase="Running", Reason="", readiness=true. Elapsed: 18.157181294s
Apr 30 14:09:34.144: INFO: Pod "pod-subpath-test-configmap-zjwf": Phase="Running", Reason="", readiness=true. Elapsed: 20.16197997s
Apr 30 14:09:36.151: INFO: Pod "pod-subpath-test-configmap-zjwf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.169122034s
STEP: Saw pod success
Apr 30 14:09:36.151: INFO: Pod "pod-subpath-test-configmap-zjwf" satisfied condition "success or failure"
Apr 30 14:09:36.154: INFO: Trying to get logs from node fatih-test-default-pool-qlpd pod pod-subpath-test-configmap-zjwf container test-container-subpath-configmap-zjwf: <nil>
STEP: delete the pod
Apr 30 14:09:36.174: INFO: Waiting for pod pod-subpath-test-configmap-zjwf to disappear
Apr 30 14:09:36.177: INFO: Pod pod-subpath-test-configmap-zjwf no longer exists
STEP: Deleting pod pod-subpath-test-configmap-zjwf
Apr 30 14:09:36.177: INFO: Deleting pod "pod-subpath-test-configmap-zjwf" in namespace "subpath-7962"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:09:36.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7962" for this suite.
Apr 30 14:09:42.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:09:42.285: INFO: namespace subpath-7962 deletion completed in 6.100713424s

• [SLOW TEST:28.348 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:09:42.286: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-997d0fb9-6b51-11e9-b570-225b9ad5bed0
STEP: Creating a pod to test consume secrets
Apr 30 14:09:42.323: INFO: Waiting up to 5m0s for pod "pod-secrets-997dac3b-6b51-11e9-b570-225b9ad5bed0" in namespace "secrets-1978" to be "success or failure"
Apr 30 14:09:42.330: INFO: Pod "pod-secrets-997dac3b-6b51-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.843334ms
Apr 30 14:09:44.335: INFO: Pod "pod-secrets-997dac3b-6b51-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01140184s
Apr 30 14:09:46.339: INFO: Pod "pod-secrets-997dac3b-6b51-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015878696s
STEP: Saw pod success
Apr 30 14:09:46.339: INFO: Pod "pod-secrets-997dac3b-6b51-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 14:09:46.343: INFO: Trying to get logs from node fatih-test-default-pool-qlp0 pod pod-secrets-997dac3b-6b51-11e9-b570-225b9ad5bed0 container secret-volume-test: <nil>
STEP: delete the pod
Apr 30 14:09:46.377: INFO: Waiting for pod pod-secrets-997dac3b-6b51-11e9-b570-225b9ad5bed0 to disappear
Apr 30 14:09:46.380: INFO: Pod pod-secrets-997dac3b-6b51-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:09:46.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1978" for this suite.
Apr 30 14:09:52.395: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:09:52.603: INFO: namespace secrets-1978 deletion completed in 6.220269937s

• [SLOW TEST:10.318 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:09:52.604: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 30 14:09:52.834: INFO: Pod name rollover-pod: Found 0 pods out of 1
Apr 30 14:09:57.838: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr 30 14:09:57.838: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Apr 30 14:09:59.843: INFO: Creating deployment "test-rollover-deployment"
Apr 30 14:09:59.851: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Apr 30 14:10:01.864: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Apr 30 14:10:01.871: INFO: Ensure that both replica sets have 1 created replica
Apr 30 14:10:01.877: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Apr 30 14:10:01.888: INFO: Updating deployment test-rollover-deployment
Apr 30 14:10:01.888: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Apr 30 14:10:04.016: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Apr 30 14:10:04.029: INFO: Make sure deployment "test-rollover-deployment" is complete
Apr 30 14:10:04.036: INFO: all replica sets need to contain the pod-template-hash label
Apr 30 14:10:04.036: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692230199, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692230199, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692230202, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692230199, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 30 14:10:06.044: INFO: all replica sets need to contain the pod-template-hash label
Apr 30 14:10:06.045: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692230199, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692230199, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692230205, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692230199, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 30 14:10:08.044: INFO: all replica sets need to contain the pod-template-hash label
Apr 30 14:10:08.044: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692230199, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692230199, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692230205, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692230199, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 30 14:10:10.093: INFO: all replica sets need to contain the pod-template-hash label
Apr 30 14:10:10.093: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692230199, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692230199, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692230205, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692230199, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 30 14:10:12.041: INFO: all replica sets need to contain the pod-template-hash label
Apr 30 14:10:12.042: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692230199, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692230199, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692230205, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692230199, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 30 14:10:14.047: INFO: all replica sets need to contain the pod-template-hash label
Apr 30 14:10:14.047: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692230199, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692230199, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692230205, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692230199, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 30 14:10:16.044: INFO: 
Apr 30 14:10:16.044: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr 30 14:10:16.052: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-7826,SelfLink:/apis/apps/v1/namespaces/deployment-7826/deployments/test-rollover-deployment,UID:a3ee8ac9-6b51-11e9-a241-32cef6bf8510,ResourceVersion:6409,Generation:2,CreationTimestamp:2019-04-30 14:09:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-04-30 14:09:59 +0000 UTC 2019-04-30 14:09:59 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-04-30 14:10:15 +0000 UTC 2019-04-30 14:09:59 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-766b4d6c9d" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Apr 30 14:10:16.055: INFO: New ReplicaSet "test-rollover-deployment-766b4d6c9d" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-766b4d6c9d,GenerateName:,Namespace:deployment-7826,SelfLink:/apis/apps/v1/namespaces/deployment-7826/replicasets/test-rollover-deployment-766b4d6c9d,UID:a5267447-6b51-11e9-a241-32cef6bf8510,ResourceVersion:6398,Generation:2,CreationTimestamp:2019-04-30 14:10:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment a3ee8ac9-6b51-11e9-a241-32cef6bf8510 0xc003216687 0xc003216688}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Apr 30 14:10:16.055: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Apr 30 14:10:16.055: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-7826,SelfLink:/apis/apps/v1/namespaces/deployment-7826/replicasets/test-rollover-controller,UID:9fbfc918-6b51-11e9-a241-32cef6bf8510,ResourceVersion:6408,Generation:2,CreationTimestamp:2019-04-30 14:09:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment a3ee8ac9-6b51-11e9-a241-32cef6bf8510 0xc0032164df 0xc0032164f0}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 30 14:10:16.055: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6455657675,GenerateName:,Namespace:deployment-7826,SelfLink:/apis/apps/v1/namespaces/deployment-7826/replicasets/test-rollover-deployment-6455657675,UID:a3f07043-6b51-11e9-a241-32cef6bf8510,ResourceVersion:6353,Generation:2,CreationTimestamp:2019-04-30 14:09:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment a3ee8ac9-6b51-11e9-a241-32cef6bf8510 0xc0032165b7 0xc0032165b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 30 14:10:16.058: INFO: Pod "test-rollover-deployment-766b4d6c9d-twmq5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-766b4d6c9d-twmq5,GenerateName:test-rollover-deployment-766b4d6c9d-,Namespace:deployment-7826,SelfLink:/api/v1/namespaces/deployment-7826/pods/test-rollover-deployment-766b4d6c9d-twmq5,UID:a52c71ad-6b51-11e9-a241-32cef6bf8510,ResourceVersion:6375,Generation:0,CreationTimestamp:2019-04-30 14:10:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-766b4d6c9d a5267447-6b51-11e9-a241-32cef6bf8510 0xc0032171a7 0xc0032171a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-fcxq6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fcxq6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-fcxq6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:fatih-test-default-pool-qlp0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003217210} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003217230}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:10:02 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:10:05 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:10:05 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:10:01 +0000 UTC  }],Message:,Reason:,HostIP:10.136.184.227,PodIP:10.244.2.49,StartTime:2019-04-30 14:10:02 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-04-30 14:10:04 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://0cd48088b9edb33c4c2ea5220d590b62cc6112c84df1dcaffd52aa25445f0ac9}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:10:16.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7826" for this suite.
Apr 30 14:10:22.071: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:10:22.158: INFO: namespace deployment-7826 deletion completed in 6.097192736s

• [SLOW TEST:29.554 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:10:22.162: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-8727
Apr 30 14:10:26.211: INFO: Started pod liveness-http in namespace container-probe-8727
STEP: checking the pod's current state and verifying that restartCount is present
Apr 30 14:10:26.214: INFO: Initial restart count of pod liveness-http is 0
Apr 30 14:10:50.277: INFO: Restart count of pod container-probe-8727/liveness-http is now 1 (24.062410762s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:10:50.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8727" for this suite.
Apr 30 14:10:56.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:10:56.398: INFO: namespace container-probe-8727 deletion completed in 6.089345125s

• [SLOW TEST:34.237 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:10:56.404: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-c5aa5cf9-6b51-11e9-b570-225b9ad5bed0
STEP: Creating a pod to test consume secrets
Apr 30 14:10:56.472: INFO: Waiting up to 5m0s for pod "pod-secrets-c5af9da9-6b51-11e9-b570-225b9ad5bed0" in namespace "secrets-2100" to be "success or failure"
Apr 30 14:10:56.476: INFO: Pod "pod-secrets-c5af9da9-6b51-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 3.893582ms
Apr 30 14:10:58.481: INFO: Pod "pod-secrets-c5af9da9-6b51-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008728198s
Apr 30 14:11:00.486: INFO: Pod "pod-secrets-c5af9da9-6b51-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014010732s
STEP: Saw pod success
Apr 30 14:11:00.486: INFO: Pod "pod-secrets-c5af9da9-6b51-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 14:11:00.488: INFO: Trying to get logs from node fatih-test-default-pool-qlpd pod pod-secrets-c5af9da9-6b51-11e9-b570-225b9ad5bed0 container secret-volume-test: <nil>
STEP: delete the pod
Apr 30 14:11:00.504: INFO: Waiting for pod pod-secrets-c5af9da9-6b51-11e9-b570-225b9ad5bed0 to disappear
Apr 30 14:11:00.507: INFO: Pod pod-secrets-c5af9da9-6b51-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:11:00.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2100" for this suite.
Apr 30 14:11:06.536: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:11:06.608: INFO: namespace secrets-2100 deletion completed in 6.083046537s
STEP: Destroying namespace "secret-namespace-3" for this suite.
Apr 30 14:11:12.623: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:11:12.889: INFO: namespace secret-namespace-3 deletion completed in 6.280068243s

• [SLOW TEST:16.485 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:11:12.890: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Apr 30 14:11:12.955: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:11:18.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3220" for this suite.
Apr 30 14:11:40.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:11:40.485: INFO: namespace init-container-3220 deletion completed in 22.161143141s

• [SLOW TEST:27.596 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:11:40.487: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1619
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 30 14:11:40.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-7587'
Apr 30 14:11:40.807: INFO: stderr: ""
Apr 30 14:11:40.807: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Apr 30 14:11:45.859: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pod e2e-test-nginx-pod --namespace=kubectl-7587 -o json'
Apr 30 14:11:45.985: INFO: stderr: ""
Apr 30 14:11:45.985: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-04-30T14:11:40Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-7587\",\n        \"resourceVersion\": \"6738\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-7587/pods/e2e-test-nginx-pod\",\n        \"uid\": \"e01a7905-6b51-11e9-a241-32cef6bf8510\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-7z687\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"fatih-test-default-pool-qlp1\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-7z687\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-7z687\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-30T14:11:40Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-30T14:11:43Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-30T14:11:43Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-30T14:11:40Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://b86d9a6d04f46c93d8738c67e2d5a615eb678c1e11ff08b6d32c6de33fc9096d\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-04-30T14:11:42Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.136.184.8\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.0.80\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-04-30T14:11:40Z\"\n    }\n}\n"
STEP: replace the image in the pod
Apr 30 14:11:45.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 replace -f - --namespace=kubectl-7587'
Apr 30 14:11:46.276: INFO: stderr: ""
Apr 30 14:11:46.276: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1624
Apr 30 14:11:46.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 delete pods e2e-test-nginx-pod --namespace=kubectl-7587'
Apr 30 14:11:52.876: INFO: stderr: ""
Apr 30 14:11:52.876: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:11:52.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7587" for this suite.
Apr 30 14:11:58.890: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:11:58.974: INFO: namespace kubectl-7587 deletion completed in 6.094308487s

• [SLOW TEST:18.487 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:11:58.981: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Apr 30 14:11:59.013: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 30 14:11:59.184: INFO: Waiting for terminating namespaces to be deleted...
Apr 30 14:11:59.191: INFO: 
Logging pods the kubelet thinks is on node fatih-test-default-pool-qlp0 before test
Apr 30 14:11:59.200: INFO: kube-proxy-spjdh from kube-system started at 2019-04-30 13:44:45 +0000 UTC (1 container statuses recorded)
Apr 30 14:11:59.200: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 30 14:11:59.200: INFO: csi-do-node-88qtw from kube-system started at 2019-04-30 13:45:15 +0000 UTC (2 container statuses recorded)
Apr 30 14:11:59.200: INFO: 	Container csi-do-plugin ready: true, restart count 0
Apr 30 14:11:59.200: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Apr 30 14:11:59.200: INFO: do-node-agent-mk55q from kube-system started at 2019-04-30 13:45:15 +0000 UTC (1 container statuses recorded)
Apr 30 14:11:59.200: INFO: 	Container do-node-agent ready: true, restart count 0
Apr 30 14:11:59.200: INFO: sonobuoy-e2e-job-92ad9d5c6b2f41f9 from heptio-sonobuoy started at 2019-04-30 13:55:40 +0000 UTC (2 container statuses recorded)
Apr 30 14:11:59.200: INFO: 	Container e2e ready: true, restart count 0
Apr 30 14:11:59.200: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 30 14:11:59.200: INFO: sonobuoy-systemd-logs-daemon-set-21faf258562f426d-9dw9m from heptio-sonobuoy started at 2019-04-30 13:55:40 +0000 UTC (2 container statuses recorded)
Apr 30 14:11:59.200: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 30 14:11:59.200: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 30 14:11:59.200: INFO: cilium-v95q2 from kube-system started at 2019-04-30 13:44:45 +0000 UTC (1 container statuses recorded)
Apr 30 14:11:59.200: INFO: 	Container cilium-agent ready: true, restart count 0
Apr 30 14:11:59.200: INFO: 
Logging pods the kubelet thinks is on node fatih-test-default-pool-qlp1 before test
Apr 30 14:11:59.213: INFO: kube-proxy-rk9gr from kube-system started at 2019-04-30 13:44:25 +0000 UTC (1 container statuses recorded)
Apr 30 14:11:59.213: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 30 14:11:59.213: INFO: do-node-agent-n65gv from kube-system started at 2019-04-30 13:44:55 +0000 UTC (1 container statuses recorded)
Apr 30 14:11:59.213: INFO: 	Container do-node-agent ready: true, restart count 0
Apr 30 14:11:59.213: INFO: coredns-5f44b47f5f-lvrnq from kube-system started at 2019-04-30 13:44:56 +0000 UTC (1 container statuses recorded)
Apr 30 14:11:59.213: INFO: 	Container coredns ready: true, restart count 0
Apr 30 14:11:59.213: INFO: coredns-5f44b47f5f-76mdx from kube-system started at 2019-04-30 13:45:00 +0000 UTC (1 container statuses recorded)
Apr 30 14:11:59.213: INFO: 	Container coredns ready: true, restart count 0
Apr 30 14:11:59.213: INFO: cilium-b6pth from kube-system started at 2019-04-30 13:44:25 +0000 UTC (1 container statuses recorded)
Apr 30 14:11:59.213: INFO: 	Container cilium-agent ready: true, restart count 0
Apr 30 14:11:59.213: INFO: csi-do-node-hlf2r from kube-system started at 2019-04-30 13:44:55 +0000 UTC (2 container statuses recorded)
Apr 30 14:11:59.213: INFO: 	Container csi-do-plugin ready: true, restart count 0
Apr 30 14:11:59.213: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Apr 30 14:11:59.213: INFO: cilium-operator-5469488bbb-7xnvh from kube-system started at 2019-04-30 13:44:56 +0000 UTC (1 container statuses recorded)
Apr 30 14:11:59.213: INFO: 	Container cilium-operator ready: true, restart count 0
Apr 30 14:11:59.213: INFO: sonobuoy-systemd-logs-daemon-set-21faf258562f426d-9t7b6 from heptio-sonobuoy started at 2019-04-30 13:55:40 +0000 UTC (2 container statuses recorded)
Apr 30 14:11:59.213: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 30 14:11:59.213: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 30 14:11:59.213: INFO: 
Logging pods the kubelet thinks is on node fatih-test-default-pool-qlpd before test
Apr 30 14:11:59.222: INFO: kube-proxy-vtjjw from kube-system started at 2019-04-30 13:44:32 +0000 UTC (1 container statuses recorded)
Apr 30 14:11:59.222: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 30 14:11:59.222: INFO: cilium-s9mvd from kube-system started at 2019-04-30 13:44:32 +0000 UTC (1 container statuses recorded)
Apr 30 14:11:59.223: INFO: 	Container cilium-agent ready: true, restart count 0
Apr 30 14:11:59.223: INFO: do-node-agent-hmckj from kube-system started at 2019-04-30 13:45:02 +0000 UTC (1 container statuses recorded)
Apr 30 14:11:59.223: INFO: 	Container do-node-agent ready: true, restart count 0
Apr 30 14:11:59.223: INFO: csi-do-node-jp2pr from kube-system started at 2019-04-30 13:45:02 +0000 UTC (2 container statuses recorded)
Apr 30 14:11:59.223: INFO: 	Container csi-do-plugin ready: true, restart count 0
Apr 30 14:11:59.223: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Apr 30 14:11:59.223: INFO: sonobuoy from heptio-sonobuoy started at 2019-04-30 13:55:34 +0000 UTC (1 container statuses recorded)
Apr 30 14:11:59.223: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 30 14:11:59.224: INFO: sonobuoy-systemd-logs-daemon-set-21faf258562f426d-rrmss from heptio-sonobuoy started at 2019-04-30 13:55:41 +0000 UTC (2 container statuses recorded)
Apr 30 14:11:59.224: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 30 14:11:59.224: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.159a45f03720e9a4], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:12:00.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-444" for this suite.
Apr 30 14:12:06.261: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:12:06.339: INFO: namespace sched-pred-444 deletion completed in 6.094186706s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.359 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:12:06.343: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap that has name configmap-test-emptyKey-ef59e4d6-6b51-11e9-b570-225b9ad5bed0
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:12:06.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-128" for this suite.
Apr 30 14:12:12.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:12:12.523: INFO: namespace configmap-128 deletion completed in 6.151249382s

• [SLOW TEST:6.181 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:12:12.527: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Apr 30 14:12:12.652: INFO: Number of nodes with available pods: 0
Apr 30 14:12:12.652: INFO: Node fatih-test-default-pool-qlp0 is running more than one daemon pod
Apr 30 14:12:14.064: INFO: Number of nodes with available pods: 0
Apr 30 14:12:14.111: INFO: Node fatih-test-default-pool-qlp0 is running more than one daemon pod
Apr 30 14:12:14.661: INFO: Number of nodes with available pods: 1
Apr 30 14:12:14.661: INFO: Node fatih-test-default-pool-qlp0 is running more than one daemon pod
Apr 30 14:12:15.668: INFO: Number of nodes with available pods: 3
Apr 30 14:12:15.668: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Apr 30 14:12:15.682: INFO: Number of nodes with available pods: 2
Apr 30 14:12:15.683: INFO: Node fatih-test-default-pool-qlpd is running more than one daemon pod
Apr 30 14:12:16.690: INFO: Number of nodes with available pods: 2
Apr 30 14:12:16.690: INFO: Node fatih-test-default-pool-qlpd is running more than one daemon pod
Apr 30 14:12:17.811: INFO: Number of nodes with available pods: 2
Apr 30 14:12:17.811: INFO: Node fatih-test-default-pool-qlpd is running more than one daemon pod
Apr 30 14:12:18.689: INFO: Number of nodes with available pods: 2
Apr 30 14:12:18.689: INFO: Node fatih-test-default-pool-qlpd is running more than one daemon pod
Apr 30 14:12:19.692: INFO: Number of nodes with available pods: 2
Apr 30 14:12:19.692: INFO: Node fatih-test-default-pool-qlpd is running more than one daemon pod
Apr 30 14:12:20.692: INFO: Number of nodes with available pods: 3
Apr 30 14:12:20.692: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8473, will wait for the garbage collector to delete the pods
Apr 30 14:12:20.757: INFO: Deleting DaemonSet.extensions daemon-set took: 7.886635ms
Apr 30 14:12:21.157: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.194692ms
Apr 30 14:12:32.961: INFO: Number of nodes with available pods: 0
Apr 30 14:12:32.961: INFO: Number of running nodes: 0, number of available pods: 0
Apr 30 14:12:32.966: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8473/daemonsets","resourceVersion":"6965"},"items":null}

Apr 30 14:12:32.971: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8473/pods","resourceVersion":"6965"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:12:32.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8473" for this suite.
Apr 30 14:12:39.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:12:39.081: INFO: namespace daemonsets-8473 deletion completed in 6.096119769s

• [SLOW TEST:26.555 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:12:39.086: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-174
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 30 14:12:39.137: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr 30 14:13:01.243: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.1.117 8081 | grep -v '^\s*$'] Namespace:pod-network-test-174 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 30 14:13:01.243: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
Apr 30 14:13:02.441: INFO: Found all expected endpoints: [netserver-0]
Apr 30 14:13:02.452: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.0.202 8081 | grep -v '^\s*$'] Namespace:pod-network-test-174 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 30 14:13:02.452: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
Apr 30 14:13:03.725: INFO: Found all expected endpoints: [netserver-1]
Apr 30 14:13:03.728: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.2.132 8081 | grep -v '^\s*$'] Namespace:pod-network-test-174 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 30 14:13:03.728: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
Apr 30 14:13:04.964: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:13:04.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-174" for this suite.
Apr 30 14:13:28.981: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:13:29.078: INFO: namespace pod-network-test-174 deletion completed in 24.109160014s

• [SLOW TEST:49.993 seconds]
[sig-network] Networking
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:13:29.084: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Apr 30 14:13:29.430: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-9179,SelfLink:/api/v1/namespaces/watch-9179/configmaps/e2e-watch-test-resource-version,UID:20d852fc-6b52-11e9-a241-32cef6bf8510,ResourceVersion:7219,Generation:0,CreationTimestamp:2019-04-30 14:13:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr 30 14:13:29.431: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-9179,SelfLink:/api/v1/namespaces/watch-9179/configmaps/e2e-watch-test-resource-version,UID:20d852fc-6b52-11e9-a241-32cef6bf8510,ResourceVersion:7220,Generation:0,CreationTimestamp:2019-04-30 14:13:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:13:29.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9179" for this suite.
Apr 30 14:13:35.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:13:35.523: INFO: namespace watch-9179 deletion completed in 6.088402598s

• [SLOW TEST:6.440 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:13:35.529: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Apr 30 14:13:43.606: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 30 14:13:43.609: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 30 14:13:45.609: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 30 14:13:45.613: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 30 14:13:47.609: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 30 14:13:47.612: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 30 14:13:49.609: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 30 14:13:49.612: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 30 14:13:51.609: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 30 14:13:51.612: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 30 14:13:53.609: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 30 14:13:53.614: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 30 14:13:55.609: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 30 14:13:55.613: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 30 14:13:57.609: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 30 14:13:57.613: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 30 14:13:59.609: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 30 14:13:59.614: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 30 14:14:01.609: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 30 14:14:01.612: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 30 14:14:03.609: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 30 14:14:03.612: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 30 14:14:05.609: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 30 14:14:05.614: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 30 14:14:07.609: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 30 14:14:07.619: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 30 14:14:09.609: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 30 14:14:09.612: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:14:09.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6532" for this suite.
Apr 30 14:14:31.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:14:31.754: INFO: namespace container-lifecycle-hook-6532 deletion completed in 22.128922869s

• [SLOW TEST:56.226 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:14:31.757: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:177
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:14:31.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2123" for this suite.
Apr 30 14:14:53.820: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:14:53.913: INFO: namespace pods-2123 deletion completed in 22.105665516s

• [SLOW TEST:22.156 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:14:53.916: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1108
STEP: creating the pod
Apr 30 14:14:53.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 create -f - --namespace=kubectl-4182'
Apr 30 14:14:54.148: INFO: stderr: ""
Apr 30 14:14:54.148: INFO: stdout: "pod/pause created\n"
Apr 30 14:14:54.148: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Apr 30 14:14:54.149: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-4182" to be "running and ready"
Apr 30 14:14:54.155: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 6.896387ms
Apr 30 14:14:56.160: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011475368s
Apr 30 14:14:58.163: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.014649928s
Apr 30 14:14:58.163: INFO: Pod "pause" satisfied condition "running and ready"
Apr 30 14:14:58.163: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: adding the label testing-label with value testing-label-value to a pod
Apr 30 14:14:58.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 label pods pause testing-label=testing-label-value --namespace=kubectl-4182'
Apr 30 14:14:58.265: INFO: stderr: ""
Apr 30 14:14:58.265: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Apr 30 14:14:58.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pod pause -L testing-label --namespace=kubectl-4182'
Apr 30 14:14:58.377: INFO: stderr: ""
Apr 30 14:14:58.377: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Apr 30 14:14:58.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 label pods pause testing-label- --namespace=kubectl-4182'
Apr 30 14:14:58.480: INFO: stderr: ""
Apr 30 14:14:58.480: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Apr 30 14:14:58.480: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pod pause -L testing-label --namespace=kubectl-4182'
Apr 30 14:14:58.574: INFO: stderr: ""
Apr 30 14:14:58.574: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1115
STEP: using delete to clean up resources
Apr 30 14:14:58.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 delete --grace-period=0 --force -f - --namespace=kubectl-4182'
Apr 30 14:14:58.675: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 30 14:14:58.675: INFO: stdout: "pod \"pause\" force deleted\n"
Apr 30 14:14:58.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get rc,svc -l name=pause --no-headers --namespace=kubectl-4182'
Apr 30 14:14:58.786: INFO: stderr: "No resources found.\n"
Apr 30 14:14:58.786: INFO: stdout: ""
Apr 30 14:14:58.786: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods -l name=pause --namespace=kubectl-4182 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 30 14:14:58.876: INFO: stderr: ""
Apr 30 14:14:58.876: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:14:58.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4182" for this suite.
Apr 30 14:15:04.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:15:04.971: INFO: namespace kubectl-4182 deletion completed in 6.087257725s

• [SLOW TEST:11.056 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:15:04.976: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 30 14:15:05.036: INFO: Create a RollingUpdate DaemonSet
Apr 30 14:15:05.040: INFO: Check that daemon pods launch on every node of the cluster
Apr 30 14:15:05.059: INFO: Number of nodes with available pods: 0
Apr 30 14:15:05.059: INFO: Node fatih-test-default-pool-qlp0 is running more than one daemon pod
Apr 30 14:15:06.649: INFO: Number of nodes with available pods: 0
Apr 30 14:15:06.649: INFO: Node fatih-test-default-pool-qlp0 is running more than one daemon pod
Apr 30 14:15:07.067: INFO: Number of nodes with available pods: 1
Apr 30 14:15:07.067: INFO: Node fatih-test-default-pool-qlp0 is running more than one daemon pod
Apr 30 14:15:08.072: INFO: Number of nodes with available pods: 3
Apr 30 14:15:08.072: INFO: Number of running nodes: 3, number of available pods: 3
Apr 30 14:15:08.072: INFO: Update the DaemonSet to trigger a rollout
Apr 30 14:15:08.078: INFO: Updating DaemonSet daemon-set
Apr 30 14:15:12.673: INFO: Roll back the DaemonSet before rollout is complete
Apr 30 14:15:12.964: INFO: Updating DaemonSet daemon-set
Apr 30 14:15:13.013: INFO: Make sure DaemonSet rollback is complete
Apr 30 14:15:13.020: INFO: Wrong image for pod: daemon-set-ng48v. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr 30 14:15:13.020: INFO: Pod daemon-set-ng48v is not available
Apr 30 14:15:14.032: INFO: Wrong image for pod: daemon-set-ng48v. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr 30 14:15:14.033: INFO: Pod daemon-set-ng48v is not available
Apr 30 14:15:15.040: INFO: Wrong image for pod: daemon-set-ng48v. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr 30 14:15:15.041: INFO: Pod daemon-set-ng48v is not available
Apr 30 14:15:16.484: INFO: Pod daemon-set-6jjng is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4473, will wait for the garbage collector to delete the pods
Apr 30 14:15:16.799: INFO: Deleting DaemonSet.extensions daemon-set took: 6.490796ms
Apr 30 14:15:17.500: INFO: Terminating DaemonSet.extensions daemon-set pods took: 700.282653ms
Apr 30 14:15:21.302: INFO: Number of nodes with available pods: 0
Apr 30 14:15:21.302: INFO: Number of running nodes: 0, number of available pods: 0
Apr 30 14:15:21.304: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4473/daemonsets","resourceVersion":"7797"},"items":null}

Apr 30 14:15:21.306: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4473/pods","resourceVersion":"7797"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:15:21.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4473" for this suite.
Apr 30 14:15:27.331: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:15:27.505: INFO: namespace daemonsets-4473 deletion completed in 6.187762715s

• [SLOW TEST:22.530 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:15:27.510: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating cluster-info
Apr 30 14:15:27.582: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 cluster-info'
Apr 30 14:15:27.955: INFO: stderr: ""
Apr 30 14:15:27.955: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.245.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.245.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:15:27.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3074" for this suite.
Apr 30 14:15:33.968: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:15:34.048: INFO: namespace kubectl-3074 deletion completed in 6.089746593s

• [SLOW TEST:6.538 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:15:34.051: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-6b28aad6-6b52-11e9-b570-225b9ad5bed0
STEP: Creating a pod to test consume configMaps
Apr 30 14:15:34.090: INFO: Waiting up to 5m0s for pod "pod-configmaps-6b2915ec-6b52-11e9-b570-225b9ad5bed0" in namespace "configmap-7501" to be "success or failure"
Apr 30 14:15:34.098: INFO: Pod "pod-configmaps-6b2915ec-6b52-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 8.015176ms
Apr 30 14:15:36.103: INFO: Pod "pod-configmaps-6b2915ec-6b52-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012592724s
Apr 30 14:15:38.111: INFO: Pod "pod-configmaps-6b2915ec-6b52-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020800712s
STEP: Saw pod success
Apr 30 14:15:38.112: INFO: Pod "pod-configmaps-6b2915ec-6b52-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 14:15:38.115: INFO: Trying to get logs from node fatih-test-default-pool-qlpd pod pod-configmaps-6b2915ec-6b52-11e9-b570-225b9ad5bed0 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 30 14:15:38.135: INFO: Waiting for pod pod-configmaps-6b2915ec-6b52-11e9-b570-225b9ad5bed0 to disappear
Apr 30 14:15:38.138: INFO: Pod pod-configmaps-6b2915ec-6b52-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:15:38.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7501" for this suite.
Apr 30 14:15:44.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:15:44.253: INFO: namespace configmap-7501 deletion completed in 6.11089323s

• [SLOW TEST:10.202 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:15:44.258: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-6842
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-6842
STEP: Creating statefulset with conflicting port in namespace statefulset-6842
STEP: Waiting until pod test-pod will start running in namespace statefulset-6842
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-6842
Apr 30 14:15:48.370: INFO: Observed stateful pod in namespace: statefulset-6842, name: ss-0, uid: 7367dd25-6b52-11e9-a241-32cef6bf8510, status phase: Pending. Waiting for statefulset controller to delete.
Apr 30 14:15:48.515: INFO: Observed stateful pod in namespace: statefulset-6842, name: ss-0, uid: 7367dd25-6b52-11e9-a241-32cef6bf8510, status phase: Failed. Waiting for statefulset controller to delete.
Apr 30 14:15:48.522: INFO: Observed stateful pod in namespace: statefulset-6842, name: ss-0, uid: 7367dd25-6b52-11e9-a241-32cef6bf8510, status phase: Failed. Waiting for statefulset controller to delete.
Apr 30 14:15:48.525: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-6842
STEP: Removing pod with conflicting port in namespace statefulset-6842
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-6842 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr 30 14:15:52.572: INFO: Deleting all statefulset in ns statefulset-6842
Apr 30 14:15:52.582: INFO: Scaling statefulset ss to 0
Apr 30 14:16:02.608: INFO: Waiting for statefulset status.replicas updated to 0
Apr 30 14:16:02.613: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:16:02.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6842" for this suite.
Apr 30 14:16:08.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:16:08.913: INFO: namespace statefulset-6842 deletion completed in 6.278004877s

• [SLOW TEST:24.656 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:16:08.915: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test env composition
Apr 30 14:16:08.949: INFO: Waiting up to 5m0s for pod "var-expansion-7ff01655-6b52-11e9-b570-225b9ad5bed0" in namespace "var-expansion-1506" to be "success or failure"
Apr 30 14:16:08.955: INFO: Pod "var-expansion-7ff01655-6b52-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.442538ms
Apr 30 14:16:10.959: INFO: Pod "var-expansion-7ff01655-6b52-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010188421s
Apr 30 14:16:12.965: INFO: Pod "var-expansion-7ff01655-6b52-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016162058s
STEP: Saw pod success
Apr 30 14:16:12.965: INFO: Pod "var-expansion-7ff01655-6b52-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 14:16:12.969: INFO: Trying to get logs from node fatih-test-default-pool-qlp0 pod var-expansion-7ff01655-6b52-11e9-b570-225b9ad5bed0 container dapi-container: <nil>
STEP: delete the pod
Apr 30 14:16:12.991: INFO: Waiting for pod var-expansion-7ff01655-6b52-11e9-b570-225b9ad5bed0 to disappear
Apr 30 14:16:12.994: INFO: Pod var-expansion-7ff01655-6b52-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:16:12.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1506" for this suite.
Apr 30 14:16:19.012: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:16:19.084: INFO: namespace var-expansion-1506 deletion completed in 6.086978163s

• [SLOW TEST:10.169 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:16:19.087: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Apr 30 14:16:23.673: INFO: Successfully updated pod "annotationupdate860146dd-6b52-11e9-b570-225b9ad5bed0"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:16:27.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-21" for this suite.
Apr 30 14:16:49.860: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:16:50.109: INFO: namespace downward-api-21 deletion completed in 22.259692801s

• [SLOW TEST:31.022 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:16:50.110: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating pod
Apr 30 14:16:52.159: INFO: Pod pod-hostip-987dc406-6b52-11e9-b570-225b9ad5bed0 has hostIP: 10.136.141.126
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:16:52.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3872" for this suite.
Apr 30 14:17:14.172: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:17:14.248: INFO: namespace pods-3872 deletion completed in 22.08611777s

• [SLOW TEST:24.138 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:17:14.251: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override command
Apr 30 14:17:14.280: INFO: Waiting up to 5m0s for pod "client-containers-a6e0fdaa-6b52-11e9-b570-225b9ad5bed0" in namespace "containers-8666" to be "success or failure"
Apr 30 14:17:14.295: INFO: Pod "client-containers-a6e0fdaa-6b52-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 13.848381ms
Apr 30 14:17:16.298: INFO: Pod "client-containers-a6e0fdaa-6b52-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017430371s
Apr 30 14:17:18.303: INFO: Pod "client-containers-a6e0fdaa-6b52-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022585877s
STEP: Saw pod success
Apr 30 14:17:18.303: INFO: Pod "client-containers-a6e0fdaa-6b52-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 14:17:18.308: INFO: Trying to get logs from node fatih-test-default-pool-qlp0 pod client-containers-a6e0fdaa-6b52-11e9-b570-225b9ad5bed0 container test-container: <nil>
STEP: delete the pod
Apr 30 14:17:18.337: INFO: Waiting for pod client-containers-a6e0fdaa-6b52-11e9-b570-225b9ad5bed0 to disappear
Apr 30 14:17:18.340: INFO: Pod client-containers-a6e0fdaa-6b52-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:17:18.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8666" for this suite.
Apr 30 14:17:24.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:17:24.433: INFO: namespace containers-8666 deletion completed in 6.090664719s

• [SLOW TEST:10.182 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:17:24.436: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Apr 30 14:17:24.519: INFO: Waiting up to 5m0s for pod "pod-acfb3c93-6b52-11e9-b570-225b9ad5bed0" in namespace "emptydir-678" to be "success or failure"
Apr 30 14:17:24.525: INFO: Pod "pod-acfb3c93-6b52-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 5.977803ms
Apr 30 14:17:26.530: INFO: Pod "pod-acfb3c93-6b52-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010666347s
Apr 30 14:17:28.534: INFO: Pod "pod-acfb3c93-6b52-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015243115s
STEP: Saw pod success
Apr 30 14:17:28.535: INFO: Pod "pod-acfb3c93-6b52-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 14:17:28.538: INFO: Trying to get logs from node fatih-test-default-pool-qlp1 pod pod-acfb3c93-6b52-11e9-b570-225b9ad5bed0 container test-container: <nil>
STEP: delete the pod
Apr 30 14:17:28.560: INFO: Waiting for pod pod-acfb3c93-6b52-11e9-b570-225b9ad5bed0 to disappear
Apr 30 14:17:28.569: INFO: Pod pod-acfb3c93-6b52-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:17:28.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-678" for this suite.
Apr 30 14:17:34.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:17:34.664: INFO: namespace emptydir-678 deletion completed in 6.091209498s

• [SLOW TEST:10.229 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:17:34.669: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Apr 30 14:17:40.766: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 30 14:17:40.769: INFO: Pod pod-with-prestop-http-hook still exists
Apr 30 14:17:42.784: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 30 14:17:42.828: INFO: Pod pod-with-prestop-http-hook still exists
Apr 30 14:17:44.769: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 30 14:17:44.774: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:17:44.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9494" for this suite.
Apr 30 14:18:06.803: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:18:06.891: INFO: namespace container-lifecycle-hook-9494 deletion completed in 22.098672721s

• [SLOW TEST:32.222 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:18:06.892: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Apr 30 14:18:06.993: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-1579,SelfLink:/api/v1/namespaces/watch-1579/configmaps/e2e-watch-test-watch-closed,UID:c64a8739-6b52-11e9-a241-32cef6bf8510,ResourceVersion:8527,Generation:0,CreationTimestamp:2019-04-30 14:18:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr 30 14:18:06.993: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-1579,SelfLink:/api/v1/namespaces/watch-1579/configmaps/e2e-watch-test-watch-closed,UID:c64a8739-6b52-11e9-a241-32cef6bf8510,ResourceVersion:8528,Generation:0,CreationTimestamp:2019-04-30 14:18:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Apr 30 14:18:07.003: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-1579,SelfLink:/api/v1/namespaces/watch-1579/configmaps/e2e-watch-test-watch-closed,UID:c64a8739-6b52-11e9-a241-32cef6bf8510,ResourceVersion:8529,Generation:0,CreationTimestamp:2019-04-30 14:18:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr 30 14:18:07.004: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-1579,SelfLink:/api/v1/namespaces/watch-1579/configmaps/e2e-watch-test-watch-closed,UID:c64a8739-6b52-11e9-a241-32cef6bf8510,ResourceVersion:8530,Generation:0,CreationTimestamp:2019-04-30 14:18:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:18:07.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1579" for this suite.
Apr 30 14:18:13.025: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:18:13.113: INFO: namespace watch-1579 deletion completed in 6.103199409s

• [SLOW TEST:6.222 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:18:13.116: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-c9fc5b8e-6b52-11e9-b570-225b9ad5bed0
STEP: Creating a pod to test consume secrets
Apr 30 14:18:13.187: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c9fd50e1-6b52-11e9-b570-225b9ad5bed0" in namespace "projected-849" to be "success or failure"
Apr 30 14:18:13.193: INFO: Pod "pod-projected-secrets-c9fd50e1-6b52-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.001121ms
Apr 30 14:18:15.201: INFO: Pod "pod-projected-secrets-c9fd50e1-6b52-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013605027s
Apr 30 14:18:17.205: INFO: Pod "pod-projected-secrets-c9fd50e1-6b52-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017900874s
STEP: Saw pod success
Apr 30 14:18:17.205: INFO: Pod "pod-projected-secrets-c9fd50e1-6b52-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 14:18:17.209: INFO: Trying to get logs from node fatih-test-default-pool-qlp1 pod pod-projected-secrets-c9fd50e1-6b52-11e9-b570-225b9ad5bed0 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 30 14:18:17.240: INFO: Waiting for pod pod-projected-secrets-c9fd50e1-6b52-11e9-b570-225b9ad5bed0 to disappear
Apr 30 14:18:17.243: INFO: Pod pod-projected-secrets-c9fd50e1-6b52-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:18:17.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-849" for this suite.
Apr 30 14:18:23.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:18:23.329: INFO: namespace projected-849 deletion completed in 6.082018066s

• [SLOW TEST:10.214 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:18:23.331: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-2658/configmap-test-d0196183-6b52-11e9-b570-225b9ad5bed0
STEP: Creating a pod to test consume configMaps
Apr 30 14:18:23.452: INFO: Waiting up to 5m0s for pod "pod-configmaps-d01b7f25-6b52-11e9-b570-225b9ad5bed0" in namespace "configmap-2658" to be "success or failure"
Apr 30 14:18:23.459: INFO: Pod "pod-configmaps-d01b7f25-6b52-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.247583ms
Apr 30 14:18:25.464: INFO: Pod "pod-configmaps-d01b7f25-6b52-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011305577s
STEP: Saw pod success
Apr 30 14:18:25.464: INFO: Pod "pod-configmaps-d01b7f25-6b52-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 14:18:25.468: INFO: Trying to get logs from node fatih-test-default-pool-qlpd pod pod-configmaps-d01b7f25-6b52-11e9-b570-225b9ad5bed0 container env-test: <nil>
STEP: delete the pod
Apr 30 14:18:25.488: INFO: Waiting for pod pod-configmaps-d01b7f25-6b52-11e9-b570-225b9ad5bed0 to disappear
Apr 30 14:18:25.490: INFO: Pod pod-configmaps-d01b7f25-6b52-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:18:25.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2658" for this suite.
Apr 30 14:18:31.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:18:31.576: INFO: namespace configmap-2658 deletion completed in 6.08216384s

• [SLOW TEST:8.245 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:18:31.581: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:69
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Registering the sample API server.
Apr 30 14:18:31.979: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Apr 30 14:18:34.444: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692230711, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692230711, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692230712, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692230711, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 30 14:18:36.449: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692230711, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692230711, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692230712, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692230711, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 30 14:18:38.464: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692230711, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692230711, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692230712, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692230711, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 30 14:18:40.448: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692230711, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692230711, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692230712, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692230711, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 30 14:18:43.493: INFO: Waited 1.023691163s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:60
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:18:44.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-7452" for this suite.
Apr 30 14:18:50.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:18:50.783: INFO: namespace aggregator-7452 deletion completed in 6.15795144s

• [SLOW TEST:19.203 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:18:50.788: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 30 14:18:50.820: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 version --client'
Apr 30 14:18:50.928: INFO: stderr: ""
Apr 30 14:18:50.928: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.1\", GitCommit:\"b7394102d6ef778017f2ca4046abbaa23b88c290\", GitTreeState:\"clean\", BuildDate:\"2019-04-08T17:11:31Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Apr 30 14:18:50.930: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 create -f - --namespace=kubectl-192'
Apr 30 14:18:51.192: INFO: stderr: ""
Apr 30 14:18:51.192: INFO: stdout: "replicationcontroller/redis-master created\n"
Apr 30 14:18:51.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 create -f - --namespace=kubectl-192'
Apr 30 14:18:51.413: INFO: stderr: ""
Apr 30 14:18:51.413: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Apr 30 14:18:52.417: INFO: Selector matched 1 pods for map[app:redis]
Apr 30 14:18:52.417: INFO: Found 0 / 1
Apr 30 14:18:53.418: INFO: Selector matched 1 pods for map[app:redis]
Apr 30 14:18:53.418: INFO: Found 0 / 1
Apr 30 14:18:54.418: INFO: Selector matched 1 pods for map[app:redis]
Apr 30 14:18:54.418: INFO: Found 0 / 1
Apr 30 14:18:55.418: INFO: Selector matched 1 pods for map[app:redis]
Apr 30 14:18:55.418: INFO: Found 1 / 1
Apr 30 14:18:55.418: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 30 14:18:55.421: INFO: Selector matched 1 pods for map[app:redis]
Apr 30 14:18:55.421: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 30 14:18:55.421: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 describe pod redis-master-b5887 --namespace=kubectl-192'
Apr 30 14:18:55.537: INFO: stderr: ""
Apr 30 14:18:55.537: INFO: stdout: "Name:               redis-master-b5887\nNamespace:          kubectl-192\nPriority:           0\nPriorityClassName:  <none>\nNode:               fatih-test-default-pool-qlp1/10.136.184.8\nStart Time:         Tue, 30 Apr 2019 14:18:51 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.244.0.95\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://308f153a20e4e63134196597732f318dcd088afa4512f0504f2234b4a5eed7f2\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 30 Apr 2019 14:18:54 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-fg8f7 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-fg8f7:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-fg8f7\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                   Message\n  ----    ------     ----  ----                                   -------\n  Normal  Scheduled  4s    default-scheduler                      Successfully assigned kubectl-192/redis-master-b5887 to fatih-test-default-pool-qlp1\n  Normal  Pulling    2s    kubelet, fatih-test-default-pool-qlp1  Pulling image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\"\n  Normal  Pulled     1s    kubelet, fatih-test-default-pool-qlp1  Successfully pulled image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\"\n  Normal  Created    1s    kubelet, fatih-test-default-pool-qlp1  Created container redis-master\n  Normal  Started    1s    kubelet, fatih-test-default-pool-qlp1  Started container redis-master\n"
Apr 30 14:18:55.537: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 describe rc redis-master --namespace=kubectl-192'
Apr 30 14:18:55.665: INFO: stderr: ""
Apr 30 14:18:55.665: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-192\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  4s    replication-controller  Created pod: redis-master-b5887\n"
Apr 30 14:18:55.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 describe service redis-master --namespace=kubectl-192'
Apr 30 14:18:55.789: INFO: stderr: ""
Apr 30 14:18:55.789: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-192\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.245.218.188\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.244.0.95:6379\nSession Affinity:  None\nEvents:            <none>\n"
Apr 30 14:18:55.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 describe node fatih-test-default-pool-qlp0'
Apr 30 14:18:55.943: INFO: stderr: ""
Apr 30 14:18:55.943: INFO: stdout: "Name:               fatih-test-default-pool-qlp0\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=s-1vcpu-2gb\n                    beta.kubernetes.io/os=linux\n                    doks.digitalocean.com/node-pool=fatih-test-default-pool\n                    doks.digitalocean.com/node-pool-id=82d6e009-db93-474e-83dc-f4cc738e6a27\n                    failure-domain.beta.kubernetes.io/region=nyc1\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=fatih-test-default-pool-qlp0\n                    kubernetes.io/os=linux\n                    region=nyc1\nAnnotations:        csi.volume.kubernetes.io/nodeid: {\"dobs.csi.digitalocean.com\":\"142093326\"}\n                    io.cilium.network.ipv4-cilium-host: 10.244.2.1\n                    io.cilium.network.ipv4-health-ip: 10.244.2.182\n                    io.cilium.network.ipv4-pod-cidr: 10.244.2.0/24\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 30 Apr 2019 13:44:45 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Tue, 30 Apr 2019 14:18:38 +0000   Tue, 30 Apr 2019 13:44:45 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Tue, 30 Apr 2019 14:18:38 +0000   Tue, 30 Apr 2019 13:44:45 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Tue, 30 Apr 2019 14:18:38 +0000   Tue, 30 Apr 2019 13:44:45 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Tue, 30 Apr 2019 14:18:38 +0000   Tue, 30 Apr 2019 13:45:15 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  Hostname:    fatih-test-default-pool-qlp0\n  InternalIP:  10.136.184.227\n  ExternalIP:  134.209.211.69\nCapacity:\n attachable-volumes-csi-dobs.csi.digitalocean.com:  7\n cpu:                                               1\n ephemeral-storage:                                 51572172Ki\n hugepages-1Gi:                                     0\n hugepages-2Mi:                                     0\n memory:                                            2043368Ki\n pods:                                              110\nAllocatable:\n attachable-volumes-csi-dobs.csi.digitalocean.com:  7\n cpu:                                               1\n ephemeral-storage:                                 47528913637\n hugepages-1Gi:                                     0\n hugepages-2Mi:                                     0\n memory:                                            1940968Ki\n pods:                                              110\nSystem Info:\n Machine ID:                 9a12d6142cff422c9ed86d6fac9594a3\n System UUID:                9a12d614-2cff-422c-9ed8-6d6fac9594a3\n Boot ID:                    e795901b-bfb4-402c-b33f-b29136c1bb58\n Kernel Version:             4.19.0-0.bpo.4-amd64\n OS Image:                   Debian GNU/Linux 9 (stretch)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.9.2\n Kubelet Version:            v1.14.1\n Kube-Proxy Version:         v1.14.1\nPodCIDR:                     10.244.2.0/24\nProviderID:                  digitalocean://142093326\nNon-terminated Pods:         (6 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  heptio-sonobuoy            sonobuoy-e2e-job-92ad9d5c6b2f41f9                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         23m\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-21faf258562f426d-9dw9m    0 (0%)        0 (0%)      0 (0%)           0 (0%)         23m\n  kube-system                cilium-v95q2                                               300m (30%)    0 (0%)      0 (0%)           0 (0%)         34m\n  kube-system                csi-do-node-88qtw                                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         33m\n  kube-system                do-node-agent-mk55q                                        102m (10%)    102m (10%)  80Mi (4%)        100Mi (5%)     33m\n  kube-system                kube-proxy-spjdh                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         34m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                                          Requests    Limits\n  --------                                          --------    ------\n  cpu                                               402m (40%)  102m (10%)\n  memory                                            80Mi (4%)   100Mi (5%)\n  ephemeral-storage                                 0 (0%)      0 (0%)\n  attachable-volumes-csi-dobs.csi.digitalocean.com  0           0\nEvents:\n  Type    Reason    Age   From                                      Message\n  ----    ------    ----  ----                                      -------\n  Normal  Starting  34m   kube-proxy, fatih-test-default-pool-qlp0  Starting kube-proxy.\n"
Apr 30 14:18:55.943: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 describe namespace kubectl-192'
Apr 30 14:18:56.057: INFO: stderr: ""
Apr 30 14:18:56.057: INFO: stdout: "Name:         kubectl-192\nLabels:       e2e-framework=kubectl\n              e2e-run=ade54de6-6b4f-11e9-b570-225b9ad5bed0\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:18:56.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-192" for this suite.
Apr 30 14:19:18.076: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:19:18.157: INFO: namespace kubectl-192 deletion completed in 22.097333253s

• [SLOW TEST:27.370 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:19:18.161: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-9104
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Apr 30 14:19:18.250: INFO: Found 0 stateful pods, waiting for 3
Apr 30 14:19:28.255: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 30 14:19:28.255: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 30 14:19:28.255: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Apr 30 14:19:28.263: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 exec --namespace=statefulset-9104 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 30 14:19:28.613: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 30 14:19:28.613: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 30 14:19:28.613: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Apr 30 14:19:38.650: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Apr 30 14:19:48.683: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 exec --namespace=statefulset-9104 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 30 14:19:49.278: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr 30 14:19:49.278: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 30 14:19:49.278: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 30 14:19:59.298: INFO: Waiting for StatefulSet statefulset-9104/ss2 to complete update
Apr 30 14:19:59.298: INFO: Waiting for Pod statefulset-9104/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 30 14:19:59.298: INFO: Waiting for Pod statefulset-9104/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 30 14:19:59.298: INFO: Waiting for Pod statefulset-9104/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 30 14:20:09.306: INFO: Waiting for StatefulSet statefulset-9104/ss2 to complete update
Apr 30 14:20:09.307: INFO: Waiting for Pod statefulset-9104/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 30 14:20:09.307: INFO: Waiting for Pod statefulset-9104/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 30 14:20:19.306: INFO: Waiting for StatefulSet statefulset-9104/ss2 to complete update
STEP: Rolling back to a previous revision
Apr 30 14:20:29.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 exec --namespace=statefulset-9104 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 30 14:20:29.602: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 30 14:20:29.602: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 30 14:20:29.602: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 30 14:20:39.648: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Apr 30 14:20:49.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 exec --namespace=statefulset-9104 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 30 14:20:50.077: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr 30 14:20:50.077: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 30 14:20:50.077: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr 30 14:21:10.098: INFO: Deleting all statefulset in ns statefulset-9104
Apr 30 14:21:10.100: INFO: Scaling statefulset ss2 to 0
Apr 30 14:21:40.115: INFO: Waiting for statefulset status.replicas updated to 0
Apr 30 14:21:40.118: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:21:40.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9104" for this suite.
Apr 30 14:21:46.148: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:21:46.243: INFO: namespace statefulset-9104 deletion completed in 6.105173292s

• [SLOW TEST:148.083 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:21:46.249: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-secret-7pdt
STEP: Creating a pod to test atomic-volume-subpath
Apr 30 14:21:46.362: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-7pdt" in namespace "subpath-4696" to be "success or failure"
Apr 30 14:21:46.404: INFO: Pod "pod-subpath-test-secret-7pdt": Phase="Pending", Reason="", readiness=false. Elapsed: 41.579563ms
Apr 30 14:21:48.408: INFO: Pod "pod-subpath-test-secret-7pdt": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045970736s
Apr 30 14:21:50.413: INFO: Pod "pod-subpath-test-secret-7pdt": Phase="Running", Reason="", readiness=true. Elapsed: 4.050441286s
Apr 30 14:21:52.416: INFO: Pod "pod-subpath-test-secret-7pdt": Phase="Running", Reason="", readiness=true. Elapsed: 6.053769142s
Apr 30 14:21:54.420: INFO: Pod "pod-subpath-test-secret-7pdt": Phase="Running", Reason="", readiness=true. Elapsed: 8.05805843s
Apr 30 14:21:56.425: INFO: Pod "pod-subpath-test-secret-7pdt": Phase="Running", Reason="", readiness=true. Elapsed: 10.06328119s
Apr 30 14:21:58.429: INFO: Pod "pod-subpath-test-secret-7pdt": Phase="Running", Reason="", readiness=true. Elapsed: 12.066767841s
Apr 30 14:22:00.434: INFO: Pod "pod-subpath-test-secret-7pdt": Phase="Running", Reason="", readiness=true. Elapsed: 14.071445855s
Apr 30 14:22:02.438: INFO: Pod "pod-subpath-test-secret-7pdt": Phase="Running", Reason="", readiness=true. Elapsed: 16.075700665s
Apr 30 14:22:04.444: INFO: Pod "pod-subpath-test-secret-7pdt": Phase="Running", Reason="", readiness=true. Elapsed: 18.081380464s
Apr 30 14:22:06.447: INFO: Pod "pod-subpath-test-secret-7pdt": Phase="Running", Reason="", readiness=true. Elapsed: 20.08513987s
Apr 30 14:22:08.452: INFO: Pod "pod-subpath-test-secret-7pdt": Phase="Running", Reason="", readiness=true. Elapsed: 22.089724057s
Apr 30 14:22:10.456: INFO: Pod "pod-subpath-test-secret-7pdt": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.094139818s
STEP: Saw pod success
Apr 30 14:22:10.456: INFO: Pod "pod-subpath-test-secret-7pdt" satisfied condition "success or failure"
Apr 30 14:22:10.460: INFO: Trying to get logs from node fatih-test-default-pool-qlpd pod pod-subpath-test-secret-7pdt container test-container-subpath-secret-7pdt: <nil>
STEP: delete the pod
Apr 30 14:22:10.484: INFO: Waiting for pod pod-subpath-test-secret-7pdt to disappear
Apr 30 14:22:10.488: INFO: Pod pod-subpath-test-secret-7pdt no longer exists
STEP: Deleting pod pod-subpath-test-secret-7pdt
Apr 30 14:22:10.488: INFO: Deleting pod "pod-subpath-test-secret-7pdt" in namespace "subpath-4696"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:22:10.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4696" for this suite.
Apr 30 14:22:16.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:22:16.576: INFO: namespace subpath-4696 deletion completed in 6.083212712s

• [SLOW TEST:30.327 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:22:16.579: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 30 14:22:16.617: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5b14e5fd-6b53-11e9-b570-225b9ad5bed0" in namespace "projected-5101" to be "success or failure"
Apr 30 14:22:16.627: INFO: Pod "downwardapi-volume-5b14e5fd-6b53-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 9.396256ms
Apr 30 14:22:18.640: INFO: Pod "downwardapi-volume-5b14e5fd-6b53-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022618934s
Apr 30 14:22:20.644: INFO: Pod "downwardapi-volume-5b14e5fd-6b53-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026647284s
STEP: Saw pod success
Apr 30 14:22:20.644: INFO: Pod "downwardapi-volume-5b14e5fd-6b53-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 14:22:20.647: INFO: Trying to get logs from node fatih-test-default-pool-qlp0 pod downwardapi-volume-5b14e5fd-6b53-11e9-b570-225b9ad5bed0 container client-container: <nil>
STEP: delete the pod
Apr 30 14:22:20.672: INFO: Waiting for pod downwardapi-volume-5b14e5fd-6b53-11e9-b570-225b9ad5bed0 to disappear
Apr 30 14:22:20.675: INFO: Pod downwardapi-volume-5b14e5fd-6b53-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:22:20.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5101" for this suite.
Apr 30 14:22:26.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:22:26.782: INFO: namespace projected-5101 deletion completed in 6.104013109s

• [SLOW TEST:10.204 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:22:26.784: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-612a1f93-6b53-11e9-b570-225b9ad5bed0
STEP: Creating a pod to test consume configMaps
Apr 30 14:22:26.820: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-612a98c3-6b53-11e9-b570-225b9ad5bed0" in namespace "projected-8262" to be "success or failure"
Apr 30 14:22:26.828: INFO: Pod "pod-projected-configmaps-612a98c3-6b53-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.909126ms
Apr 30 14:22:28.832: INFO: Pod "pod-projected-configmaps-612a98c3-6b53-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011201607s
Apr 30 14:22:30.835: INFO: Pod "pod-projected-configmaps-612a98c3-6b53-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014755671s
STEP: Saw pod success
Apr 30 14:22:30.836: INFO: Pod "pod-projected-configmaps-612a98c3-6b53-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 14:22:30.838: INFO: Trying to get logs from node fatih-test-default-pool-qlp1 pod pod-projected-configmaps-612a98c3-6b53-11e9-b570-225b9ad5bed0 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 30 14:22:30.867: INFO: Waiting for pod pod-projected-configmaps-612a98c3-6b53-11e9-b570-225b9ad5bed0 to disappear
Apr 30 14:22:30.871: INFO: Pod pod-projected-configmaps-612a98c3-6b53-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:22:30.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8262" for this suite.
Apr 30 14:22:36.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:22:36.956: INFO: namespace projected-8262 deletion completed in 6.081724868s

• [SLOW TEST:10.172 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:22:36.962: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-673b4df7-6b53-11e9-b570-225b9ad5bed0
STEP: Creating a pod to test consume configMaps
Apr 30 14:22:37.004: INFO: Waiting up to 5m0s for pod "pod-configmaps-673c1820-6b53-11e9-b570-225b9ad5bed0" in namespace "configmap-5858" to be "success or failure"
Apr 30 14:22:37.016: INFO: Pod "pod-configmaps-673c1820-6b53-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 11.150444ms
Apr 30 14:22:39.021: INFO: Pod "pod-configmaps-673c1820-6b53-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016475565s
Apr 30 14:22:41.025: INFO: Pod "pod-configmaps-673c1820-6b53-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02096677s
STEP: Saw pod success
Apr 30 14:22:41.031: INFO: Pod "pod-configmaps-673c1820-6b53-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 14:22:41.035: INFO: Trying to get logs from node fatih-test-default-pool-qlpd pod pod-configmaps-673c1820-6b53-11e9-b570-225b9ad5bed0 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 30 14:22:41.072: INFO: Waiting for pod pod-configmaps-673c1820-6b53-11e9-b570-225b9ad5bed0 to disappear
Apr 30 14:22:41.075: INFO: Pod pod-configmaps-673c1820-6b53-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:22:41.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5858" for this suite.
Apr 30 14:22:47.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:22:47.204: INFO: namespace configmap-5858 deletion completed in 6.119259888s

• [SLOW TEST:10.243 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:22:47.210: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Apr 30 14:22:47.243: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 create -f - --namespace=kubectl-2817'
Apr 30 14:22:47.538: INFO: stderr: ""
Apr 30 14:22:47.538: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 30 14:22:47.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2817'
Apr 30 14:22:47.919: INFO: stderr: ""
Apr 30 14:22:47.919: INFO: stdout: "update-demo-nautilus-4ht2z update-demo-nautilus-lhd9z "
Apr 30 14:22:47.919: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods update-demo-nautilus-4ht2z -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2817'
Apr 30 14:22:48.095: INFO: stderr: ""
Apr 30 14:22:48.095: INFO: stdout: ""
Apr 30 14:22:48.095: INFO: update-demo-nautilus-4ht2z is created but not running
Apr 30 14:22:53.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2817'
Apr 30 14:22:53.200: INFO: stderr: ""
Apr 30 14:22:53.200: INFO: stdout: "update-demo-nautilus-4ht2z update-demo-nautilus-lhd9z "
Apr 30 14:22:53.200: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods update-demo-nautilus-4ht2z -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2817'
Apr 30 14:22:53.297: INFO: stderr: ""
Apr 30 14:22:53.297: INFO: stdout: "true"
Apr 30 14:22:53.297: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods update-demo-nautilus-4ht2z -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2817'
Apr 30 14:22:53.401: INFO: stderr: ""
Apr 30 14:22:53.401: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 30 14:22:53.401: INFO: validating pod update-demo-nautilus-4ht2z
Apr 30 14:22:53.411: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 30 14:22:53.411: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 30 14:22:53.411: INFO: update-demo-nautilus-4ht2z is verified up and running
Apr 30 14:22:53.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods update-demo-nautilus-lhd9z -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2817'
Apr 30 14:22:53.510: INFO: stderr: ""
Apr 30 14:22:53.510: INFO: stdout: "true"
Apr 30 14:22:53.510: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods update-demo-nautilus-lhd9z -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2817'
Apr 30 14:22:53.609: INFO: stderr: ""
Apr 30 14:22:53.609: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 30 14:22:53.609: INFO: validating pod update-demo-nautilus-lhd9z
Apr 30 14:22:53.617: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 30 14:22:53.617: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 30 14:22:53.617: INFO: update-demo-nautilus-lhd9z is verified up and running
STEP: using delete to clean up resources
Apr 30 14:22:53.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 delete --grace-period=0 --force -f - --namespace=kubectl-2817'
Apr 30 14:22:53.714: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 30 14:22:53.714: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr 30 14:22:53.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-2817'
Apr 30 14:22:53.815: INFO: stderr: "No resources found.\n"
Apr 30 14:22:53.815: INFO: stdout: ""
Apr 30 14:22:53.815: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods -l name=update-demo --namespace=kubectl-2817 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 30 14:22:53.917: INFO: stderr: ""
Apr 30 14:22:53.917: INFO: stdout: "update-demo-nautilus-4ht2z\nupdate-demo-nautilus-lhd9z\n"
Apr 30 14:22:54.417: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-2817'
Apr 30 14:22:54.531: INFO: stderr: "No resources found.\n"
Apr 30 14:22:54.531: INFO: stdout: ""
Apr 30 14:22:54.531: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods -l name=update-demo --namespace=kubectl-2817 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 30 14:22:54.634: INFO: stderr: ""
Apr 30 14:22:54.634: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:22:54.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2817" for this suite.
Apr 30 14:23:16.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:23:16.759: INFO: namespace kubectl-2817 deletion completed in 22.120109003s

• [SLOW TEST:29.550 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:23:16.767: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-7ef54334-6b53-11e9-b570-225b9ad5bed0
STEP: Creating a pod to test consume secrets
Apr 30 14:23:16.810: INFO: Waiting up to 5m0s for pod "pod-secrets-7ef5cfc7-6b53-11e9-b570-225b9ad5bed0" in namespace "secrets-7578" to be "success or failure"
Apr 30 14:23:16.822: INFO: Pod "pod-secrets-7ef5cfc7-6b53-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 11.195018ms
Apr 30 14:23:18.828: INFO: Pod "pod-secrets-7ef5cfc7-6b53-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018129616s
Apr 30 14:23:20.832: INFO: Pod "pod-secrets-7ef5cfc7-6b53-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021551014s
STEP: Saw pod success
Apr 30 14:23:20.832: INFO: Pod "pod-secrets-7ef5cfc7-6b53-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 14:23:20.834: INFO: Trying to get logs from node fatih-test-default-pool-qlpd pod pod-secrets-7ef5cfc7-6b53-11e9-b570-225b9ad5bed0 container secret-volume-test: <nil>
STEP: delete the pod
Apr 30 14:23:20.857: INFO: Waiting for pod pod-secrets-7ef5cfc7-6b53-11e9-b570-225b9ad5bed0 to disappear
Apr 30 14:23:20.860: INFO: Pod pod-secrets-7ef5cfc7-6b53-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:23:20.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7578" for this suite.
Apr 30 14:23:26.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:23:26.959: INFO: namespace secrets-7578 deletion completed in 6.093834888s

• [SLOW TEST:10.192 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:23:26.962: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-850aee05-6b53-11e9-b570-225b9ad5bed0
STEP: Creating a pod to test consume configMaps
Apr 30 14:23:27.014: INFO: Waiting up to 5m0s for pod "pod-configmaps-850b5fff-6b53-11e9-b570-225b9ad5bed0" in namespace "configmap-9144" to be "success or failure"
Apr 30 14:23:27.022: INFO: Pod "pod-configmaps-850b5fff-6b53-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 7.992162ms
Apr 30 14:23:29.070: INFO: Pod "pod-configmaps-850b5fff-6b53-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.055818342s
Apr 30 14:23:31.074: INFO: Pod "pod-configmaps-850b5fff-6b53-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.059733379s
STEP: Saw pod success
Apr 30 14:23:31.074: INFO: Pod "pod-configmaps-850b5fff-6b53-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 14:23:31.077: INFO: Trying to get logs from node fatih-test-default-pool-qlp0 pod pod-configmaps-850b5fff-6b53-11e9-b570-225b9ad5bed0 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 30 14:23:31.104: INFO: Waiting for pod pod-configmaps-850b5fff-6b53-11e9-b570-225b9ad5bed0 to disappear
Apr 30 14:23:31.108: INFO: Pod pod-configmaps-850b5fff-6b53-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:23:31.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9144" for this suite.
Apr 30 14:23:37.122: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:23:37.212: INFO: namespace configmap-9144 deletion completed in 6.100579671s

• [SLOW TEST:10.251 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:23:37.218: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-8b2593c8-6b53-11e9-b570-225b9ad5bed0
STEP: Creating a pod to test consume configMaps
Apr 30 14:23:37.254: INFO: Waiting up to 5m0s for pod "pod-configmaps-8b260045-6b53-11e9-b570-225b9ad5bed0" in namespace "configmap-260" to be "success or failure"
Apr 30 14:23:37.269: INFO: Pod "pod-configmaps-8b260045-6b53-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 14.68238ms
Apr 30 14:23:39.274: INFO: Pod "pod-configmaps-8b260045-6b53-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019728994s
Apr 30 14:23:41.279: INFO: Pod "pod-configmaps-8b260045-6b53-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02487418s
STEP: Saw pod success
Apr 30 14:23:41.279: INFO: Pod "pod-configmaps-8b260045-6b53-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 14:23:41.282: INFO: Trying to get logs from node fatih-test-default-pool-qlp1 pod pod-configmaps-8b260045-6b53-11e9-b570-225b9ad5bed0 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 30 14:23:41.318: INFO: Waiting for pod pod-configmaps-8b260045-6b53-11e9-b570-225b9ad5bed0 to disappear
Apr 30 14:23:41.320: INFO: Pod pod-configmaps-8b260045-6b53-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:23:41.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-260" for this suite.
Apr 30 14:23:47.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:23:47.439: INFO: namespace configmap-260 deletion completed in 6.115262472s

• [SLOW TEST:10.222 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:23:47.445: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-projected-zp7w
STEP: Creating a pod to test atomic-volume-subpath
Apr 30 14:23:47.626: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-zp7w" in namespace "subpath-4542" to be "success or failure"
Apr 30 14:23:47.649: INFO: Pod "pod-subpath-test-projected-zp7w": Phase="Pending", Reason="", readiness=false. Elapsed: 22.129424ms
Apr 30 14:23:49.653: INFO: Pod "pod-subpath-test-projected-zp7w": Phase="Running", Reason="", readiness=true. Elapsed: 2.027056654s
Apr 30 14:23:51.657: INFO: Pod "pod-subpath-test-projected-zp7w": Phase="Running", Reason="", readiness=true. Elapsed: 4.031086388s
Apr 30 14:23:53.662: INFO: Pod "pod-subpath-test-projected-zp7w": Phase="Running", Reason="", readiness=true. Elapsed: 6.035932377s
Apr 30 14:23:55.667: INFO: Pod "pod-subpath-test-projected-zp7w": Phase="Running", Reason="", readiness=true. Elapsed: 8.040741924s
Apr 30 14:23:57.819: INFO: Pod "pod-subpath-test-projected-zp7w": Phase="Running", Reason="", readiness=true. Elapsed: 10.192850713s
Apr 30 14:23:59.823: INFO: Pod "pod-subpath-test-projected-zp7w": Phase="Running", Reason="", readiness=true. Elapsed: 12.196389112s
Apr 30 14:24:01.828: INFO: Pod "pod-subpath-test-projected-zp7w": Phase="Running", Reason="", readiness=true. Elapsed: 14.201127716s
Apr 30 14:24:03.832: INFO: Pod "pod-subpath-test-projected-zp7w": Phase="Running", Reason="", readiness=true. Elapsed: 16.205287476s
Apr 30 14:24:05.844: INFO: Pod "pod-subpath-test-projected-zp7w": Phase="Running", Reason="", readiness=true. Elapsed: 18.217268177s
Apr 30 14:24:07.848: INFO: Pod "pod-subpath-test-projected-zp7w": Phase="Running", Reason="", readiness=true. Elapsed: 20.221657807s
Apr 30 14:24:09.853: INFO: Pod "pod-subpath-test-projected-zp7w": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.226160964s
STEP: Saw pod success
Apr 30 14:24:09.853: INFO: Pod "pod-subpath-test-projected-zp7w" satisfied condition "success or failure"
Apr 30 14:24:09.856: INFO: Trying to get logs from node fatih-test-default-pool-qlpd pod pod-subpath-test-projected-zp7w container test-container-subpath-projected-zp7w: <nil>
STEP: delete the pod
Apr 30 14:24:09.877: INFO: Waiting for pod pod-subpath-test-projected-zp7w to disappear
Apr 30 14:24:09.882: INFO: Pod pod-subpath-test-projected-zp7w no longer exists
STEP: Deleting pod pod-subpath-test-projected-zp7w
Apr 30 14:24:09.882: INFO: Deleting pod "pod-subpath-test-projected-zp7w" in namespace "subpath-4542"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:24:09.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4542" for this suite.
Apr 30 14:24:15.905: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:24:16.044: INFO: namespace subpath-4542 deletion completed in 6.155177313s

• [SLOW TEST:28.600 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:24:16.047: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 30 14:24:16.096: INFO: Creating deployment "nginx-deployment"
Apr 30 14:24:16.104: INFO: Waiting for observed generation 1
Apr 30 14:24:18.432: INFO: Waiting for all required pods to come up
Apr 30 14:24:18.438: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Apr 30 14:24:26.475: INFO: Waiting for deployment "nginx-deployment" to complete
Apr 30 14:24:26.481: INFO: Updating deployment "nginx-deployment" with a non-existent image
Apr 30 14:24:26.487: INFO: Updating deployment nginx-deployment
Apr 30 14:24:26.487: INFO: Waiting for observed generation 2
Apr 30 14:24:28.496: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Apr 30 14:24:28.498: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Apr 30 14:24:28.499: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Apr 30 14:24:28.505: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Apr 30 14:24:28.505: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Apr 30 14:24:28.507: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Apr 30 14:24:28.510: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Apr 30 14:24:28.510: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Apr 30 14:24:28.515: INFO: Updating deployment nginx-deployment
Apr 30 14:24:28.515: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Apr 30 14:24:28.532: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Apr 30 14:24:31.864: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr 30 14:24:31.895: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-5481,SelfLink:/apis/apps/v1/namespaces/deployment-5481/deployments/nginx-deployment,UID:a24c3a4a-6b53-11e9-a241-32cef6bf8510,ResourceVersion:10511,Generation:3,CreationTimestamp:2019-04-30 14:24:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-04-30 14:24:28 +0000 UTC 2019-04-30 14:24:28 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-04-30 14:24:28 +0000 UTC 2019-04-30 14:24:16 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-5f9595f595" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Apr 30 14:24:31.904: INFO: New ReplicaSet "nginx-deployment-5f9595f595" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595,GenerateName:,Namespace:deployment-5481,SelfLink:/apis/apps/v1/namespaces/deployment-5481/replicasets/nginx-deployment-5f9595f595,UID:a87dc913-6b53-11e9-a241-32cef6bf8510,ResourceVersion:10510,Generation:3,CreationTimestamp:2019-04-30 14:24:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment a24c3a4a-6b53-11e9-a241-32cef6bf8510 0xc00388d8b7 0xc00388d8b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 30 14:24:31.904: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Apr 30 14:24:31.904: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8,GenerateName:,Namespace:deployment-5481,SelfLink:/apis/apps/v1/namespaces/deployment-5481/replicasets/nginx-deployment-6f478d8d8,UID:a24d71dd-6b53-11e9-a241-32cef6bf8510,ResourceVersion:10499,Generation:3,CreationTimestamp:2019-04-30 14:24:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment a24c3a4a-6b53-11e9-a241-32cef6bf8510 0xc00388d987 0xc00388d988}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Apr 30 14:24:31.944: INFO: Pod "nginx-deployment-5f9595f595-5hxxn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-5hxxn,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-5481,SelfLink:/api/v1/namespaces/deployment-5481/pods/nginx-deployment-5f9595f595-5hxxn,UID:a9c4869c-6b53-11e9-a241-32cef6bf8510,ResourceVersion:10549,Generation:0,CreationTimestamp:2019-04-30 14:24:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 a87dc913-6b53-11e9-a241-32cef6bf8510 0xc0018ea297 0xc0018ea298}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nwk7g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwk7g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nwk7g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:fatih-test-default-pool-qlp1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018ea300} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018ea320}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC  }],Message:,Reason:,HostIP:10.136.184.8,PodIP:,StartTime:2019-04-30 14:24:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 14:24:31.944: INFO: Pod "nginx-deployment-5f9595f595-6bl6n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-6bl6n,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-5481,SelfLink:/api/v1/namespaces/deployment-5481/pods/nginx-deployment-5f9595f595-6bl6n,UID:a9b8ed4c-6b53-11e9-a241-32cef6bf8510,ResourceVersion:10515,Generation:0,CreationTimestamp:2019-04-30 14:24:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 a87dc913-6b53-11e9-a241-32cef6bf8510 0xc0018ea3f0 0xc0018ea3f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nwk7g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwk7g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nwk7g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:fatih-test-default-pool-qlpd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018ea460} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018ea480}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC  }],Message:,Reason:,HostIP:10.136.141.126,PodIP:,StartTime:2019-04-30 14:24:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 14:24:31.944: INFO: Pod "nginx-deployment-5f9595f595-7xmlw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-7xmlw,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-5481,SelfLink:/api/v1/namespaces/deployment-5481/pods/nginx-deployment-5f9595f595-7xmlw,UID:a9bc30d5-6b53-11e9-a241-32cef6bf8510,ResourceVersion:10551,Generation:0,CreationTimestamp:2019-04-30 14:24:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 a87dc913-6b53-11e9-a241-32cef6bf8510 0xc0018ea570 0xc0018ea571}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nwk7g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwk7g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nwk7g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:fatih-test-default-pool-qlp0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018ea5f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018ea610}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC  }],Message:,Reason:,HostIP:10.136.184.227,PodIP:,StartTime:2019-04-30 14:24:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 14:24:31.944: INFO: Pod "nginx-deployment-5f9595f595-8xwkw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-8xwkw,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-5481,SelfLink:/api/v1/namespaces/deployment-5481/pods/nginx-deployment-5f9595f595-8xwkw,UID:a87eb478-6b53-11e9-a241-32cef6bf8510,ResourceVersion:10382,Generation:0,CreationTimestamp:2019-04-30 14:24:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 a87dc913-6b53-11e9-a241-32cef6bf8510 0xc0018ea6e0 0xc0018ea6e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nwk7g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwk7g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nwk7g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:fatih-test-default-pool-qlp1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018ea750} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018ea770}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:26 +0000 UTC  }],Message:,Reason:,HostIP:10.136.184.8,PodIP:,StartTime:2019-04-30 14:24:26 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 14:24:31.962: INFO: Pod "nginx-deployment-5f9595f595-djzl5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-djzl5,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-5481,SelfLink:/api/v1/namespaces/deployment-5481/pods/nginx-deployment-5f9595f595-djzl5,UID:a893c703-6b53-11e9-a241-32cef6bf8510,ResourceVersion:10413,Generation:0,CreationTimestamp:2019-04-30 14:24:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 a87dc913-6b53-11e9-a241-32cef6bf8510 0xc0018ea880 0xc0018ea881}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nwk7g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwk7g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nwk7g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:fatih-test-default-pool-qlp0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018ea8f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018ea910}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:26 +0000 UTC  }],Message:,Reason:,HostIP:10.136.184.227,PodIP:,StartTime:2019-04-30 14:24:26 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 14:24:31.962: INFO: Pod "nginx-deployment-5f9595f595-f9nvr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-f9nvr,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-5481,SelfLink:/api/v1/namespaces/deployment-5481/pods/nginx-deployment-5f9595f595-f9nvr,UID:a9bc8955-6b53-11e9-a241-32cef6bf8510,ResourceVersion:10527,Generation:0,CreationTimestamp:2019-04-30 14:24:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 a87dc913-6b53-11e9-a241-32cef6bf8510 0xc0018ea9e0 0xc0018ea9e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nwk7g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwk7g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nwk7g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:fatih-test-default-pool-qlpd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018eaa60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018eaa80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC  }],Message:,Reason:,HostIP:10.136.141.126,PodIP:,StartTime:2019-04-30 14:24:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 14:24:31.963: INFO: Pod "nginx-deployment-5f9595f595-j9mlb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-j9mlb,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-5481,SelfLink:/api/v1/namespaces/deployment-5481/pods/nginx-deployment-5f9595f595-j9mlb,UID:a9b65842-6b53-11e9-a241-32cef6bf8510,ResourceVersion:10495,Generation:0,CreationTimestamp:2019-04-30 14:24:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 a87dc913-6b53-11e9-a241-32cef6bf8510 0xc0018eab50 0xc0018eab51}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nwk7g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwk7g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nwk7g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:fatih-test-default-pool-qlpd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018eabc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018eabe0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC  }],Message:,Reason:,HostIP:10.136.141.126,PodIP:,StartTime:2019-04-30 14:24:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 14:24:31.963: INFO: Pod "nginx-deployment-5f9595f595-l2l5g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-l2l5g,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-5481,SelfLink:/api/v1/namespaces/deployment-5481/pods/nginx-deployment-5f9595f595-l2l5g,UID:a9b8d953-6b53-11e9-a241-32cef6bf8510,ResourceVersion:10518,Generation:0,CreationTimestamp:2019-04-30 14:24:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 a87dc913-6b53-11e9-a241-32cef6bf8510 0xc0018eacb0 0xc0018eacb1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nwk7g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwk7g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nwk7g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:fatih-test-default-pool-qlp1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018ead20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018ead40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC  }],Message:,Reason:,HostIP:10.136.184.8,PodIP:,StartTime:2019-04-30 14:24:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 14:24:31.994: INFO: Pod "nginx-deployment-5f9595f595-ncb4f" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-ncb4f,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-5481,SelfLink:/api/v1/namespaces/deployment-5481/pods/nginx-deployment-5f9595f595-ncb4f,UID:a9bddfda-6b53-11e9-a241-32cef6bf8510,ResourceVersion:10533,Generation:0,CreationTimestamp:2019-04-30 14:24:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 a87dc913-6b53-11e9-a241-32cef6bf8510 0xc0018eae10 0xc0018eae11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nwk7g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwk7g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nwk7g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:fatih-test-default-pool-qlp1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018eaea0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018eaec0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC  }],Message:,Reason:,HostIP:10.136.184.8,PodIP:,StartTime:2019-04-30 14:24:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 14:24:31.994: INFO: Pod "nginx-deployment-5f9595f595-pqwp5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-pqwp5,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-5481,SelfLink:/api/v1/namespaces/deployment-5481/pods/nginx-deployment-5f9595f595-pqwp5,UID:a8808ab8-6b53-11e9-a241-32cef6bf8510,ResourceVersion:10572,Generation:0,CreationTimestamp:2019-04-30 14:24:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 a87dc913-6b53-11e9-a241-32cef6bf8510 0xc0018eafc0 0xc0018eafc1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nwk7g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwk7g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nwk7g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:fatih-test-default-pool-qlpd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018eb040} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018eb060}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:26 +0000 UTC  }],Message:,Reason:,HostIP:10.136.141.126,PodIP:,StartTime:2019-04-30 14:24:26 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 14:24:31.994: INFO: Pod "nginx-deployment-5f9595f595-r68xs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-r68xs,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-5481,SelfLink:/api/v1/namespaces/deployment-5481/pods/nginx-deployment-5f9595f595-r68xs,UID:a9bded19-6b53-11e9-a241-32cef6bf8510,ResourceVersion:10561,Generation:0,CreationTimestamp:2019-04-30 14:24:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 a87dc913-6b53-11e9-a241-32cef6bf8510 0xc0018eb140 0xc0018eb141}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nwk7g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwk7g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nwk7g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:fatih-test-default-pool-qlp0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018eb1e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018eb230}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC  }],Message:,Reason:,HostIP:10.136.184.227,PodIP:,StartTime:2019-04-30 14:24:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 14:24:31.995: INFO: Pod "nginx-deployment-5f9595f595-xldbf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-xldbf,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-5481,SelfLink:/api/v1/namespaces/deployment-5481/pods/nginx-deployment-5f9595f595-xldbf,UID:a880a43a-6b53-11e9-a241-32cef6bf8510,ResourceVersion:10395,Generation:0,CreationTimestamp:2019-04-30 14:24:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 a87dc913-6b53-11e9-a241-32cef6bf8510 0xc0018eb320 0xc0018eb321}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nwk7g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwk7g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nwk7g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:fatih-test-default-pool-qlp0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018eb390} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018eb3b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:26 +0000 UTC  }],Message:,Reason:,HostIP:10.136.184.227,PodIP:,StartTime:2019-04-30 14:24:26 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 14:24:32.019: INFO: Pod "nginx-deployment-5f9595f595-zs5kj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-zs5kj,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-5481,SelfLink:/api/v1/namespaces/deployment-5481/pods/nginx-deployment-5f9595f595-zs5kj,UID:a8921fef-6b53-11e9-a241-32cef6bf8510,ResourceVersion:10411,Generation:0,CreationTimestamp:2019-04-30 14:24:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 a87dc913-6b53-11e9-a241-32cef6bf8510 0xc0018eb4a0 0xc0018eb4a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nwk7g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwk7g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nwk7g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:fatih-test-default-pool-qlp1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018eb510} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018eb530}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:26 +0000 UTC  }],Message:,Reason:,HostIP:10.136.184.8,PodIP:,StartTime:2019-04-30 14:24:26 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 14:24:32.019: INFO: Pod "nginx-deployment-6f478d8d8-2v8gc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-2v8gc,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5481,SelfLink:/api/v1/namespaces/deployment-5481/pods/nginx-deployment-6f478d8d8-2v8gc,UID:a25d5793-6b53-11e9-a241-32cef6bf8510,ResourceVersion:10331,Generation:0,CreationTimestamp:2019-04-30 14:24:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 a24d71dd-6b53-11e9-a241-32cef6bf8510 0xc0018eb600 0xc0018eb601}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nwk7g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwk7g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwk7g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:fatih-test-default-pool-qlp1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018eb660} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018eb680}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:16 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:22 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:22 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:16 +0000 UTC  }],Message:,Reason:,HostIP:10.136.184.8,PodIP:10.244.0.175,StartTime:2019-04-30 14:24:16 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-30 14:24:21 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://d9b15877fd0df12dcaab88fa57ef5b85516c65ee2f85ae8c2d13255d403aef12}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 14:24:32.019: INFO: Pod "nginx-deployment-6f478d8d8-5qbln" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-5qbln,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5481,SelfLink:/api/v1/namespaces/deployment-5481/pods/nginx-deployment-6f478d8d8-5qbln,UID:a9be3770-6b53-11e9-a241-32cef6bf8510,ResourceVersion:10537,Generation:0,CreationTimestamp:2019-04-30 14:24:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 a24d71dd-6b53-11e9-a241-32cef6bf8510 0xc0018eb757 0xc0018eb758}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nwk7g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwk7g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwk7g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:fatih-test-default-pool-qlp1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018eb7c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018eb7e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC  }],Message:,Reason:,HostIP:10.136.184.8,PodIP:,StartTime:2019-04-30 14:24:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 14:24:32.025: INFO: Pod "nginx-deployment-6f478d8d8-67rp5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-67rp5,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5481,SelfLink:/api/v1/namespaces/deployment-5481/pods/nginx-deployment-6f478d8d8-67rp5,UID:a25b53dc-6b53-11e9-a241-32cef6bf8510,ResourceVersion:10337,Generation:0,CreationTimestamp:2019-04-30 14:24:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 a24d71dd-6b53-11e9-a241-32cef6bf8510 0xc0018eb8a7 0xc0018eb8a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nwk7g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwk7g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwk7g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:fatih-test-default-pool-qlp1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018eb910} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018eb930}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:16 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:22 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:22 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:16 +0000 UTC  }],Message:,Reason:,HostIP:10.136.184.8,PodIP:10.244.0.204,StartTime:2019-04-30 14:24:16 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-30 14:24:21 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://3f66caa969e0bbc00cb05cd7a9d155843e6f6264300d2d2e83ff850682b6f618}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 14:24:32.028: INFO: Pod "nginx-deployment-6f478d8d8-9fmhg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-9fmhg,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5481,SelfLink:/api/v1/namespaces/deployment-5481/pods/nginx-deployment-6f478d8d8-9fmhg,UID:a2539df1-6b53-11e9-a241-32cef6bf8510,ResourceVersion:10334,Generation:0,CreationTimestamp:2019-04-30 14:24:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 a24d71dd-6b53-11e9-a241-32cef6bf8510 0xc0018eba07 0xc0018eba08}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nwk7g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwk7g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwk7g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:fatih-test-default-pool-qlp1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018eba70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018eba90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:16 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:22 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:22 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:16 +0000 UTC  }],Message:,Reason:,HostIP:10.136.184.8,PodIP:10.244.0.29,StartTime:2019-04-30 14:24:16 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-30 14:24:21 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://fde2e86aaa2fbb98dae8775d750a7d1721721ce2e97e1b4bb8f56f7fb7b49794}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 14:24:32.028: INFO: Pod "nginx-deployment-6f478d8d8-c25cp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-c25cp,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5481,SelfLink:/api/v1/namespaces/deployment-5481/pods/nginx-deployment-6f478d8d8-c25cp,UID:a9b9a903-6b53-11e9-a241-32cef6bf8510,ResourceVersion:10547,Generation:0,CreationTimestamp:2019-04-30 14:24:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 a24d71dd-6b53-11e9-a241-32cef6bf8510 0xc0018ebb60 0xc0018ebb61}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nwk7g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwk7g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwk7g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:fatih-test-default-pool-qlp0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018ebbc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018ebbe0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC  }],Message:,Reason:,HostIP:10.136.184.227,PodIP:,StartTime:2019-04-30 14:24:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 14:24:32.028: INFO: Pod "nginx-deployment-6f478d8d8-cst6b" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-cst6b,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5481,SelfLink:/api/v1/namespaces/deployment-5481/pods/nginx-deployment-6f478d8d8-cst6b,UID:a25d62ef-6b53-11e9-a241-32cef6bf8510,ResourceVersion:10350,Generation:0,CreationTimestamp:2019-04-30 14:24:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 a24d71dd-6b53-11e9-a241-32cef6bf8510 0xc0018ebca7 0xc0018ebca8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nwk7g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwk7g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwk7g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:fatih-test-default-pool-qlp0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018ebd10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018ebd30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:16 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:16 +0000 UTC  }],Message:,Reason:,HostIP:10.136.184.227,PodIP:10.244.2.144,StartTime:2019-04-30 14:24:16 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-30 14:24:24 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://b87cd465f300881598ef586b79a3203ed42e7a6a021fb93805014da90292928d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 14:24:32.028: INFO: Pod "nginx-deployment-6f478d8d8-fq2sd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-fq2sd,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5481,SelfLink:/api/v1/namespaces/deployment-5481/pods/nginx-deployment-6f478d8d8-fq2sd,UID:a25d47c2-6b53-11e9-a241-32cef6bf8510,ResourceVersion:10318,Generation:0,CreationTimestamp:2019-04-30 14:24:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 a24d71dd-6b53-11e9-a241-32cef6bf8510 0xc0018ebe07 0xc0018ebe08}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nwk7g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwk7g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwk7g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:fatih-test-default-pool-qlpd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018ebe70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018ebe90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:16 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:21 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:21 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:16 +0000 UTC  }],Message:,Reason:,HostIP:10.136.141.126,PodIP:10.244.1.20,StartTime:2019-04-30 14:24:16 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-30 14:24:20 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://9b88a804cf86f3d773d41c7f310e8c6435bcc51e4c66afa569c479ffd066a1de}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 14:24:32.029: INFO: Pod "nginx-deployment-6f478d8d8-g4j5p" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-g4j5p,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5481,SelfLink:/api/v1/namespaces/deployment-5481/pods/nginx-deployment-6f478d8d8-g4j5p,UID:a9be436f-6b53-11e9-a241-32cef6bf8510,ResourceVersion:10569,Generation:0,CreationTimestamp:2019-04-30 14:24:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 a24d71dd-6b53-11e9-a241-32cef6bf8510 0xc0018ebf60 0xc0018ebf61}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nwk7g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwk7g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwk7g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:fatih-test-default-pool-qlpd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018ebfc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018ebfe0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC  }],Message:,Reason:,HostIP:10.136.141.126,PodIP:,StartTime:2019-04-30 14:24:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 14:24:32.068: INFO: Pod "nginx-deployment-6f478d8d8-hlxnb" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-hlxnb,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5481,SelfLink:/api/v1/namespaces/deployment-5481/pods/nginx-deployment-6f478d8d8-hlxnb,UID:a2538b04-6b53-11e9-a241-32cef6bf8510,ResourceVersion:10315,Generation:0,CreationTimestamp:2019-04-30 14:24:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 a24d71dd-6b53-11e9-a241-32cef6bf8510 0xc002c020a7 0xc002c020a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nwk7g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwk7g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwk7g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:fatih-test-default-pool-qlpd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c02110} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c02130}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:16 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:21 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:21 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:16 +0000 UTC  }],Message:,Reason:,HostIP:10.136.141.126,PodIP:10.244.1.164,StartTime:2019-04-30 14:24:16 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-30 14:24:20 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://1c34383d973f58c8830011ed0698f9663597372f77281c86a1723f46ab604583}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 14:24:32.068: INFO: Pod "nginx-deployment-6f478d8d8-hxltv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-hxltv,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5481,SelfLink:/api/v1/namespaces/deployment-5481/pods/nginx-deployment-6f478d8d8-hxltv,UID:a9b93d30-6b53-11e9-a241-32cef6bf8510,ResourceVersion:10522,Generation:0,CreationTimestamp:2019-04-30 14:24:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 a24d71dd-6b53-11e9-a241-32cef6bf8510 0xc002c02207 0xc002c02208}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nwk7g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwk7g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwk7g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:fatih-test-default-pool-qlpd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c02270} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c02290}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC  }],Message:,Reason:,HostIP:10.136.141.126,PodIP:,StartTime:2019-04-30 14:24:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 14:24:32.068: INFO: Pod "nginx-deployment-6f478d8d8-l7qkq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-l7qkq,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5481,SelfLink:/api/v1/namespaces/deployment-5481/pods/nginx-deployment-6f478d8d8-l7qkq,UID:a9b998fe-6b53-11e9-a241-32cef6bf8510,ResourceVersion:10507,Generation:0,CreationTimestamp:2019-04-30 14:24:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 a24d71dd-6b53-11e9-a241-32cef6bf8510 0xc002c02357 0xc002c02358}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nwk7g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwk7g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwk7g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:fatih-test-default-pool-qlpd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c023c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c023e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC  }],Message:,Reason:,HostIP:10.136.141.126,PodIP:,StartTime:2019-04-30 14:24:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 14:24:32.068: INFO: Pod "nginx-deployment-6f478d8d8-l9xcr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-l9xcr,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5481,SelfLink:/api/v1/namespaces/deployment-5481/pods/nginx-deployment-6f478d8d8-l9xcr,UID:a9be507e-6b53-11e9-a241-32cef6bf8510,ResourceVersion:10568,Generation:0,CreationTimestamp:2019-04-30 14:24:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 a24d71dd-6b53-11e9-a241-32cef6bf8510 0xc002c024a7 0xc002c024a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nwk7g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwk7g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwk7g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:fatih-test-default-pool-qlp0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c02510} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c02530}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC  }],Message:,Reason:,HostIP:10.136.184.227,PodIP:,StartTime:2019-04-30 14:24:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 14:24:32.069: INFO: Pod "nginx-deployment-6f478d8d8-p2mtn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-p2mtn,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5481,SelfLink:/api/v1/namespaces/deployment-5481/pods/nginx-deployment-6f478d8d8-p2mtn,UID:a9b91d52-6b53-11e9-a241-32cef6bf8510,ResourceVersion:10529,Generation:0,CreationTimestamp:2019-04-30 14:24:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 a24d71dd-6b53-11e9-a241-32cef6bf8510 0xc002c025f7 0xc002c025f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nwk7g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwk7g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwk7g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:fatih-test-default-pool-qlp1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c02660} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c02680}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC  }],Message:,Reason:,HostIP:10.136.184.8,PodIP:,StartTime:2019-04-30 14:24:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 14:24:32.069: INFO: Pod "nginx-deployment-6f478d8d8-pmxg2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-pmxg2,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5481,SelfLink:/api/v1/namespaces/deployment-5481/pods/nginx-deployment-6f478d8d8-pmxg2,UID:a9b41943-6b53-11e9-a241-32cef6bf8510,ResourceVersion:10489,Generation:0,CreationTimestamp:2019-04-30 14:24:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 a24d71dd-6b53-11e9-a241-32cef6bf8510 0xc002c02747 0xc002c02748}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nwk7g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwk7g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwk7g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:fatih-test-default-pool-qlp0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c027b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c027d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC  }],Message:,Reason:,HostIP:10.136.184.227,PodIP:,StartTime:2019-04-30 14:24:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 14:24:32.069: INFO: Pod "nginx-deployment-6f478d8d8-qhcld" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-qhcld,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5481,SelfLink:/api/v1/namespaces/deployment-5481/pods/nginx-deployment-6f478d8d8-qhcld,UID:a9be83e7-6b53-11e9-a241-32cef6bf8510,ResourceVersion:10552,Generation:0,CreationTimestamp:2019-04-30 14:24:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 a24d71dd-6b53-11e9-a241-32cef6bf8510 0xc002c02897 0xc002c02898}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nwk7g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwk7g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwk7g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:fatih-test-default-pool-qlpd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c02900} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c02920}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC  }],Message:,Reason:,HostIP:10.136.141.126,PodIP:,StartTime:2019-04-30 14:24:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 14:24:32.069: INFO: Pod "nginx-deployment-6f478d8d8-rl52h" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-rl52h,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5481,SelfLink:/api/v1/namespaces/deployment-5481/pods/nginx-deployment-6f478d8d8-rl52h,UID:a9b6332c-6b53-11e9-a241-32cef6bf8510,ResourceVersion:10542,Generation:0,CreationTimestamp:2019-04-30 14:24:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 a24d71dd-6b53-11e9-a241-32cef6bf8510 0xc002c029e7 0xc002c029e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nwk7g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwk7g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwk7g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:fatih-test-default-pool-qlp0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c02a50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c02a70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC  }],Message:,Reason:,HostIP:10.136.184.227,PodIP:,StartTime:2019-04-30 14:24:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 14:24:32.069: INFO: Pod "nginx-deployment-6f478d8d8-vhsch" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-vhsch,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5481,SelfLink:/api/v1/namespaces/deployment-5481/pods/nginx-deployment-6f478d8d8-vhsch,UID:a251c8e5-6b53-11e9-a241-32cef6bf8510,ResourceVersion:10327,Generation:0,CreationTimestamp:2019-04-30 14:24:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 a24d71dd-6b53-11e9-a241-32cef6bf8510 0xc002c02b37 0xc002c02b38}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nwk7g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwk7g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwk7g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:fatih-test-default-pool-qlp0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c02ba0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c02bc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:16 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:21 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:21 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:16 +0000 UTC  }],Message:,Reason:,HostIP:10.136.184.227,PodIP:10.244.2.158,StartTime:2019-04-30 14:24:16 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-30 14:24:20 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://19ac8d085bb3cd7df7cddd27d7c93133121f4345a819206c7babe3cc67c10722}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 14:24:32.069: INFO: Pod "nginx-deployment-6f478d8d8-vwn6s" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-vwn6s,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5481,SelfLink:/api/v1/namespaces/deployment-5481/pods/nginx-deployment-6f478d8d8-vwn6s,UID:a25b0fb2-6b53-11e9-a241-32cef6bf8510,ResourceVersion:10321,Generation:0,CreationTimestamp:2019-04-30 14:24:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 a24d71dd-6b53-11e9-a241-32cef6bf8510 0xc002c02c97 0xc002c02c98}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nwk7g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwk7g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwk7g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:fatih-test-default-pool-qlpd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c02d00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c02d20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:16 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:21 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:21 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:16 +0000 UTC  }],Message:,Reason:,HostIP:10.136.141.126,PodIP:10.244.1.154,StartTime:2019-04-30 14:24:16 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-30 14:24:20 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://b40113928c187b301646dfa15812bcd255384ec541b30eb550b22ee4acbe02e1}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 14:24:32.069: INFO: Pod "nginx-deployment-6f478d8d8-x5zhv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-x5zhv,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5481,SelfLink:/api/v1/namespaces/deployment-5481/pods/nginx-deployment-6f478d8d8-x5zhv,UID:a9bd9ab8-6b53-11e9-a241-32cef6bf8510,ResourceVersion:10557,Generation:0,CreationTimestamp:2019-04-30 14:24:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 a24d71dd-6b53-11e9-a241-32cef6bf8510 0xc002c02df7 0xc002c02df8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nwk7g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwk7g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwk7g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:fatih-test-default-pool-qlp0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c02e60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c02e80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC  }],Message:,Reason:,HostIP:10.136.184.227,PodIP:,StartTime:2019-04-30 14:24:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 14:24:32.072: INFO: Pod "nginx-deployment-6f478d8d8-xgghc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-xgghc,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-5481,SelfLink:/api/v1/namespaces/deployment-5481/pods/nginx-deployment-6f478d8d8-xgghc,UID:a9b602ab-6b53-11e9-a241-32cef6bf8510,ResourceVersion:10488,Generation:0,CreationTimestamp:2019-04-30 14:24:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 a24d71dd-6b53-11e9-a241-32cef6bf8510 0xc002c02f47 0xc002c02f48}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nwk7g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwk7g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwk7g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:fatih-test-default-pool-qlp1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c02fb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c02fd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:24:28 +0000 UTC  }],Message:,Reason:,HostIP:10.136.184.8,PodIP:,StartTime:2019-04-30 14:24:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:24:32.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5481" for this suite.
Apr 30 14:24:45.833: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:24:46.188: INFO: namespace deployment-5481 deletion completed in 14.100547584s

• [SLOW TEST:30.141 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:24:46.191: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 30 14:24:46.265: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b447663a-6b53-11e9-b570-225b9ad5bed0" in namespace "projected-1019" to be "success or failure"
Apr 30 14:24:46.289: INFO: Pod "downwardapi-volume-b447663a-6b53-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 24.141554ms
Apr 30 14:24:48.294: INFO: Pod "downwardapi-volume-b447663a-6b53-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028884562s
Apr 30 14:24:50.299: INFO: Pod "downwardapi-volume-b447663a-6b53-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033426434s
STEP: Saw pod success
Apr 30 14:24:50.299: INFO: Pod "downwardapi-volume-b447663a-6b53-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 14:24:50.302: INFO: Trying to get logs from node fatih-test-default-pool-qlpd pod downwardapi-volume-b447663a-6b53-11e9-b570-225b9ad5bed0 container client-container: <nil>
STEP: delete the pod
Apr 30 14:24:50.329: INFO: Waiting for pod downwardapi-volume-b447663a-6b53-11e9-b570-225b9ad5bed0 to disappear
Apr 30 14:24:50.364: INFO: Pod downwardapi-volume-b447663a-6b53-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:24:50.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1019" for this suite.
Apr 30 14:24:56.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:24:56.463: INFO: namespace projected-1019 deletion completed in 6.096253446s

• [SLOW TEST:10.273 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:24:56.467: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating all guestbook components
Apr 30 14:24:56.494: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Apr 30 14:24:56.495: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 create -f - --namespace=kubectl-4301'
Apr 30 14:24:56.711: INFO: stderr: ""
Apr 30 14:24:56.711: INFO: stdout: "service/redis-slave created\n"
Apr 30 14:24:56.711: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Apr 30 14:24:56.711: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 create -f - --namespace=kubectl-4301'
Apr 30 14:24:57.008: INFO: stderr: ""
Apr 30 14:24:57.008: INFO: stdout: "service/redis-master created\n"
Apr 30 14:24:57.008: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Apr 30 14:24:57.008: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 create -f - --namespace=kubectl-4301'
Apr 30 14:24:57.299: INFO: stderr: ""
Apr 30 14:24:57.299: INFO: stdout: "service/frontend created\n"
Apr 30 14:24:57.299: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Apr 30 14:24:57.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 create -f - --namespace=kubectl-4301'
Apr 30 14:24:57.636: INFO: stderr: ""
Apr 30 14:24:57.636: INFO: stdout: "deployment.apps/frontend created\n"
Apr 30 14:24:57.636: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Apr 30 14:24:57.636: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 create -f - --namespace=kubectl-4301'
Apr 30 14:24:58.219: INFO: stderr: ""
Apr 30 14:24:58.219: INFO: stdout: "deployment.apps/redis-master created\n"
Apr 30 14:24:58.219: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Apr 30 14:24:58.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 create -f - --namespace=kubectl-4301'
Apr 30 14:24:58.464: INFO: stderr: ""
Apr 30 14:24:58.465: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Apr 30 14:24:58.465: INFO: Waiting for all frontend pods to be Running.
Apr 30 14:25:23.515: INFO: Waiting for frontend to serve content.
Apr 30 14:25:23.535: INFO: Trying to add a new entry to the guestbook.
Apr 30 14:25:23.553: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Apr 30 14:25:23.568: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 delete --grace-period=0 --force -f - --namespace=kubectl-4301'
Apr 30 14:25:23.740: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 30 14:25:23.740: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Apr 30 14:25:23.740: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 delete --grace-period=0 --force -f - --namespace=kubectl-4301'
Apr 30 14:25:23.883: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 30 14:25:23.883: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Apr 30 14:25:23.883: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 delete --grace-period=0 --force -f - --namespace=kubectl-4301'
Apr 30 14:25:24.043: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 30 14:25:24.044: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Apr 30 14:25:24.044: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 delete --grace-period=0 --force -f - --namespace=kubectl-4301'
Apr 30 14:25:24.174: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 30 14:25:24.174: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Apr 30 14:25:24.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 delete --grace-period=0 --force -f - --namespace=kubectl-4301'
Apr 30 14:25:24.271: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 30 14:25:24.271: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Apr 30 14:25:24.271: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 delete --grace-period=0 --force -f - --namespace=kubectl-4301'
Apr 30 14:25:24.381: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 30 14:25:24.381: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:25:24.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4301" for this suite.
Apr 30 14:26:04.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:26:04.468: INFO: namespace kubectl-4301 deletion completed in 40.083747291s

• [SLOW TEST:68.002 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:26:04.473: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 30 14:26:04.555: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:26:08.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2113" for this suite.
Apr 30 14:26:58.820: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:26:59.048: INFO: namespace pods-2113 deletion completed in 50.237083264s

• [SLOW TEST:54.575 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:26:59.049: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Apr 30 14:27:03.719: INFO: Successfully updated pod "labelsupdate037f57d6-6b54-11e9-b570-225b9ad5bed0"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:27:05.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1173" for this suite.
Apr 30 14:27:27.803: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:27:27.894: INFO: namespace downward-api-1173 deletion completed in 22.131019365s

• [SLOW TEST:28.845 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:27:27.894: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-2449
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 30 14:27:27.929: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr 30 14:27:52.141: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.2.123:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2449 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 30 14:27:52.141: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
Apr 30 14:27:52.353: INFO: Found all expected endpoints: [netserver-0]
Apr 30 14:27:52.356: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.0.231:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2449 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 30 14:27:52.356: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
Apr 30 14:27:52.640: INFO: Found all expected endpoints: [netserver-1]
Apr 30 14:27:52.643: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.1.94:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2449 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 30 14:27:52.643: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
Apr 30 14:27:53.202: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:27:53.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2449" for this suite.
Apr 30 14:28:15.216: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:28:15.287: INFO: namespace pod-network-test-2449 deletion completed in 22.080467128s

• [SLOW TEST:47.394 seconds]
[sig-network] Networking
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:28:15.291: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with configMap that has name projected-configmap-test-upd-30e4f3ae-6b54-11e9-b570-225b9ad5bed0
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-30e4f3ae-6b54-11e9-b570-225b9ad5bed0
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:29:40.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3412" for this suite.
Apr 30 14:30:02.135: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:30:02.219: INFO: namespace projected-3412 deletion completed in 22.094874562s

• [SLOW TEST:106.929 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:30:02.223: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:30:07.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8432" for this suite.
Apr 30 14:30:29.298: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:30:29.376: INFO: namespace replication-controller-8432 deletion completed in 22.09179151s

• [SLOW TEST:27.153 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:30:29.380: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 30 14:30:29.425: INFO: Waiting up to 5m0s for pod "downwardapi-volume-80d21c42-6b54-11e9-b570-225b9ad5bed0" in namespace "downward-api-2975" to be "success or failure"
Apr 30 14:30:29.429: INFO: Pod "downwardapi-volume-80d21c42-6b54-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.232262ms
Apr 30 14:30:31.434: INFO: Pod "downwardapi-volume-80d21c42-6b54-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008880377s
Apr 30 14:30:33.439: INFO: Pod "downwardapi-volume-80d21c42-6b54-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013966562s
STEP: Saw pod success
Apr 30 14:30:33.439: INFO: Pod "downwardapi-volume-80d21c42-6b54-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 14:30:33.443: INFO: Trying to get logs from node fatih-test-default-pool-qlpd pod downwardapi-volume-80d21c42-6b54-11e9-b570-225b9ad5bed0 container client-container: <nil>
STEP: delete the pod
Apr 30 14:30:33.459: INFO: Waiting for pod downwardapi-volume-80d21c42-6b54-11e9-b570-225b9ad5bed0 to disappear
Apr 30 14:30:33.461: INFO: Pod downwardapi-volume-80d21c42-6b54-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:30:33.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2975" for this suite.
Apr 30 14:30:39.478: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:30:39.563: INFO: namespace downward-api-2975 deletion completed in 6.097786921s

• [SLOW TEST:10.184 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:30:39.571: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on node default medium
Apr 30 14:30:39.608: INFO: Waiting up to 5m0s for pod "pod-86e37d24-6b54-11e9-b570-225b9ad5bed0" in namespace "emptydir-5332" to be "success or failure"
Apr 30 14:30:39.614: INFO: Pod "pod-86e37d24-6b54-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 5.718114ms
Apr 30 14:30:41.618: INFO: Pod "pod-86e37d24-6b54-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009437783s
Apr 30 14:30:43.622: INFO: Pod "pod-86e37d24-6b54-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014259474s
STEP: Saw pod success
Apr 30 14:30:43.622: INFO: Pod "pod-86e37d24-6b54-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 14:30:43.626: INFO: Trying to get logs from node fatih-test-default-pool-qlp1 pod pod-86e37d24-6b54-11e9-b570-225b9ad5bed0 container test-container: <nil>
STEP: delete the pod
Apr 30 14:30:43.648: INFO: Waiting for pod pod-86e37d24-6b54-11e9-b570-225b9ad5bed0 to disappear
Apr 30 14:30:43.652: INFO: Pod pod-86e37d24-6b54-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:30:43.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5332" for this suite.
Apr 30 14:30:49.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:30:49.737: INFO: namespace emptydir-5332 deletion completed in 6.081419948s

• [SLOW TEST:10.166 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:30:49.739: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Apr 30 14:30:54.312: INFO: Successfully updated pod "annotationupdate8cf316ea-6b54-11e9-b570-225b9ad5bed0"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:30:56.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8954" for this suite.
Apr 30 14:31:18.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:31:18.427: INFO: namespace projected-8954 deletion completed in 22.081629876s

• [SLOW TEST:28.688 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:31:18.432: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the initial replication controller
Apr 30 14:31:18.466: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 create -f - --namespace=kubectl-9328'
Apr 30 14:31:18.673: INFO: stderr: ""
Apr 30 14:31:18.673: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 30 14:31:18.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9328'
Apr 30 14:31:18.790: INFO: stderr: ""
Apr 30 14:31:18.790: INFO: stdout: "update-demo-nautilus-6jmcw update-demo-nautilus-w5trh "
Apr 30 14:31:18.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods update-demo-nautilus-6jmcw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9328'
Apr 30 14:31:18.896: INFO: stderr: ""
Apr 30 14:31:18.896: INFO: stdout: ""
Apr 30 14:31:18.896: INFO: update-demo-nautilus-6jmcw is created but not running
Apr 30 14:31:23.897: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9328'
Apr 30 14:31:23.996: INFO: stderr: ""
Apr 30 14:31:23.996: INFO: stdout: "update-demo-nautilus-6jmcw update-demo-nautilus-w5trh "
Apr 30 14:31:23.996: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods update-demo-nautilus-6jmcw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9328'
Apr 30 14:31:24.093: INFO: stderr: ""
Apr 30 14:31:24.093: INFO: stdout: "true"
Apr 30 14:31:24.093: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods update-demo-nautilus-6jmcw -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9328'
Apr 30 14:31:24.189: INFO: stderr: ""
Apr 30 14:31:24.189: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 30 14:31:24.189: INFO: validating pod update-demo-nautilus-6jmcw
Apr 30 14:31:24.199: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 30 14:31:24.199: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 30 14:31:24.199: INFO: update-demo-nautilus-6jmcw is verified up and running
Apr 30 14:31:24.199: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods update-demo-nautilus-w5trh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9328'
Apr 30 14:31:24.294: INFO: stderr: ""
Apr 30 14:31:24.294: INFO: stdout: "true"
Apr 30 14:31:24.294: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods update-demo-nautilus-w5trh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9328'
Apr 30 14:31:24.396: INFO: stderr: ""
Apr 30 14:31:24.396: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 30 14:31:24.396: INFO: validating pod update-demo-nautilus-w5trh
Apr 30 14:31:24.407: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 30 14:31:24.407: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 30 14:31:24.407: INFO: update-demo-nautilus-w5trh is verified up and running
STEP: rolling-update to new replication controller
Apr 30 14:31:24.409: INFO: scanned /root for discovery docs: <nil>
Apr 30 14:31:24.409: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-9328'
Apr 30 14:31:47.005: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Apr 30 14:31:47.005: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 30 14:31:47.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9328'
Apr 30 14:31:47.110: INFO: stderr: ""
Apr 30 14:31:47.110: INFO: stdout: "update-demo-kitten-nxnxb update-demo-kitten-q56g9 "
Apr 30 14:31:47.110: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods update-demo-kitten-nxnxb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9328'
Apr 30 14:31:47.208: INFO: stderr: ""
Apr 30 14:31:47.208: INFO: stdout: "true"
Apr 30 14:31:47.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods update-demo-kitten-nxnxb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9328'
Apr 30 14:31:47.303: INFO: stderr: ""
Apr 30 14:31:47.303: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Apr 30 14:31:47.303: INFO: validating pod update-demo-kitten-nxnxb
Apr 30 14:31:47.311: INFO: got data: {
  "image": "kitten.jpg"
}

Apr 30 14:31:47.312: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Apr 30 14:31:47.312: INFO: update-demo-kitten-nxnxb is verified up and running
Apr 30 14:31:47.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods update-demo-kitten-q56g9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9328'
Apr 30 14:31:47.407: INFO: stderr: ""
Apr 30 14:31:47.407: INFO: stdout: "true"
Apr 30 14:31:47.407: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods update-demo-kitten-q56g9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9328'
Apr 30 14:31:47.532: INFO: stderr: ""
Apr 30 14:31:47.532: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Apr 30 14:31:47.532: INFO: validating pod update-demo-kitten-q56g9
Apr 30 14:31:47.548: INFO: got data: {
  "image": "kitten.jpg"
}

Apr 30 14:31:47.548: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Apr 30 14:31:47.548: INFO: update-demo-kitten-q56g9 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:31:47.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9328" for this suite.
Apr 30 14:32:09.576: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:32:09.649: INFO: namespace kubectl-9328 deletion completed in 22.095870581s

• [SLOW TEST:51.218 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:32:09.657: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Apr 30 14:32:09.709: INFO: namespace kubectl-5558
Apr 30 14:32:09.709: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 create -f - --namespace=kubectl-5558'
Apr 30 14:32:10.162: INFO: stderr: ""
Apr 30 14:32:10.162: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Apr 30 14:32:11.177: INFO: Selector matched 1 pods for map[app:redis]
Apr 30 14:32:11.177: INFO: Found 0 / 1
Apr 30 14:32:12.168: INFO: Selector matched 1 pods for map[app:redis]
Apr 30 14:32:12.168: INFO: Found 0 / 1
Apr 30 14:32:13.166: INFO: Selector matched 1 pods for map[app:redis]
Apr 30 14:32:13.166: INFO: Found 1 / 1
Apr 30 14:32:13.166: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 30 14:32:13.173: INFO: Selector matched 1 pods for map[app:redis]
Apr 30 14:32:13.173: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 30 14:32:13.173: INFO: wait on redis-master startup in kubectl-5558 
Apr 30 14:32:13.173: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 logs redis-master-sbshb redis-master --namespace=kubectl-5558'
Apr 30 14:32:13.281: INFO: stderr: ""
Apr 30 14:32:13.281: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 30 Apr 14:32:12.152 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 30 Apr 14:32:12.156 # Server started, Redis version 3.2.12\n1:M 30 Apr 14:32:12.156 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 30 Apr 14:32:12.156 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Apr 30 14:32:13.281: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-5558'
Apr 30 14:32:13.432: INFO: stderr: ""
Apr 30 14:32:13.433: INFO: stdout: "service/rm2 exposed\n"
Apr 30 14:32:13.452: INFO: Service rm2 in namespace kubectl-5558 found.
STEP: exposing service
Apr 30 14:32:15.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-5558'
Apr 30 14:32:15.584: INFO: stderr: ""
Apr 30 14:32:15.584: INFO: stdout: "service/rm3 exposed\n"
Apr 30 14:32:15.591: INFO: Service rm3 in namespace kubectl-5558 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:32:17.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5558" for this suite.
Apr 30 14:32:39.632: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:32:39.730: INFO: namespace kubectl-5558 deletion completed in 22.12403007s

• [SLOW TEST:30.074 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create services for rc  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:32:39.737: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:32:43.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-9362" for this suite.
Apr 30 14:32:49.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:32:50.117: INFO: namespace emptydir-wrapper-9362 deletion completed in 6.292950919s

• [SLOW TEST:10.380 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:32:50.117: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-downwardapi-ktm4
STEP: Creating a pod to test atomic-volume-subpath
Apr 30 14:32:50.208: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-ktm4" in namespace "subpath-3728" to be "success or failure"
Apr 30 14:32:50.214: INFO: Pod "pod-subpath-test-downwardapi-ktm4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.140082ms
Apr 30 14:32:52.219: INFO: Pod "pod-subpath-test-downwardapi-ktm4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010670383s
Apr 30 14:32:54.222: INFO: Pod "pod-subpath-test-downwardapi-ktm4": Phase="Running", Reason="", readiness=true. Elapsed: 4.013702959s
Apr 30 14:32:56.226: INFO: Pod "pod-subpath-test-downwardapi-ktm4": Phase="Running", Reason="", readiness=true. Elapsed: 6.017661506s
Apr 30 14:32:58.230: INFO: Pod "pod-subpath-test-downwardapi-ktm4": Phase="Running", Reason="", readiness=true. Elapsed: 8.02249246s
Apr 30 14:33:00.235: INFO: Pod "pod-subpath-test-downwardapi-ktm4": Phase="Running", Reason="", readiness=true. Elapsed: 10.027125886s
Apr 30 14:33:02.239: INFO: Pod "pod-subpath-test-downwardapi-ktm4": Phase="Running", Reason="", readiness=true. Elapsed: 12.031384061s
Apr 30 14:33:04.243: INFO: Pod "pod-subpath-test-downwardapi-ktm4": Phase="Running", Reason="", readiness=true. Elapsed: 14.035168761s
Apr 30 14:33:06.248: INFO: Pod "pod-subpath-test-downwardapi-ktm4": Phase="Running", Reason="", readiness=true. Elapsed: 16.039843017s
Apr 30 14:33:08.253: INFO: Pod "pod-subpath-test-downwardapi-ktm4": Phase="Running", Reason="", readiness=true. Elapsed: 18.044651705s
Apr 30 14:33:10.257: INFO: Pod "pod-subpath-test-downwardapi-ktm4": Phase="Running", Reason="", readiness=true. Elapsed: 20.049185655s
Apr 30 14:33:12.262: INFO: Pod "pod-subpath-test-downwardapi-ktm4": Phase="Running", Reason="", readiness=true. Elapsed: 22.054213405s
Apr 30 14:33:14.267: INFO: Pod "pod-subpath-test-downwardapi-ktm4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.058973551s
STEP: Saw pod success
Apr 30 14:33:14.267: INFO: Pod "pod-subpath-test-downwardapi-ktm4" satisfied condition "success or failure"
Apr 30 14:33:14.270: INFO: Trying to get logs from node fatih-test-default-pool-qlp0 pod pod-subpath-test-downwardapi-ktm4 container test-container-subpath-downwardapi-ktm4: <nil>
STEP: delete the pod
Apr 30 14:33:14.296: INFO: Waiting for pod pod-subpath-test-downwardapi-ktm4 to disappear
Apr 30 14:33:14.299: INFO: Pod pod-subpath-test-downwardapi-ktm4 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-ktm4
Apr 30 14:33:14.299: INFO: Deleting pod "pod-subpath-test-downwardapi-ktm4" in namespace "subpath-3728"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:33:14.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3728" for this suite.
Apr 30 14:33:20.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:33:20.384: INFO: namespace subpath-3728 deletion completed in 6.080522657s

• [SLOW TEST:30.268 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:33:20.389: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Apr 30 14:33:20.427: INFO: Waiting up to 5m0s for pod "pod-e6bf3345-6b54-11e9-b570-225b9ad5bed0" in namespace "emptydir-8961" to be "success or failure"
Apr 30 14:33:20.433: INFO: Pod "pod-e6bf3345-6b54-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.224273ms
Apr 30 14:33:22.438: INFO: Pod "pod-e6bf3345-6b54-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010525108s
Apr 30 14:33:24.443: INFO: Pod "pod-e6bf3345-6b54-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015275618s
STEP: Saw pod success
Apr 30 14:33:24.443: INFO: Pod "pod-e6bf3345-6b54-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 14:33:24.446: INFO: Trying to get logs from node fatih-test-default-pool-qlp1 pod pod-e6bf3345-6b54-11e9-b570-225b9ad5bed0 container test-container: <nil>
STEP: delete the pod
Apr 30 14:33:24.474: INFO: Waiting for pod pod-e6bf3345-6b54-11e9-b570-225b9ad5bed0 to disappear
Apr 30 14:33:24.477: INFO: Pod pod-e6bf3345-6b54-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:33:24.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8961" for this suite.
Apr 30 14:33:30.495: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:33:30.576: INFO: namespace emptydir-8961 deletion completed in 6.095353448s

• [SLOW TEST:10.187 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:33:30.580: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test use defaults
Apr 30 14:33:30.620: INFO: Waiting up to 5m0s for pod "client-containers-ecd287c3-6b54-11e9-b570-225b9ad5bed0" in namespace "containers-8503" to be "success or failure"
Apr 30 14:33:30.624: INFO: Pod "client-containers-ecd287c3-6b54-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.360195ms
Apr 30 14:33:32.629: INFO: Pod "client-containers-ecd287c3-6b54-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009187765s
Apr 30 14:33:34.634: INFO: Pod "client-containers-ecd287c3-6b54-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013744362s
Apr 30 14:33:36.638: INFO: Pod "client-containers-ecd287c3-6b54-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.018010221s
STEP: Saw pod success
Apr 30 14:33:36.638: INFO: Pod "client-containers-ecd287c3-6b54-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 14:33:36.642: INFO: Trying to get logs from node fatih-test-default-pool-qlpd pod client-containers-ecd287c3-6b54-11e9-b570-225b9ad5bed0 container test-container: <nil>
STEP: delete the pod
Apr 30 14:33:36.665: INFO: Waiting for pod client-containers-ecd287c3-6b54-11e9-b570-225b9ad5bed0 to disappear
Apr 30 14:33:36.690: INFO: Pod client-containers-ecd287c3-6b54-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:33:36.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8503" for this suite.
Apr 30 14:33:42.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:33:42.886: INFO: namespace containers-8503 deletion completed in 6.192081457s

• [SLOW TEST:12.307 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:33:42.887: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 30 14:33:42.922: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f4279526-6b54-11e9-b570-225b9ad5bed0" in namespace "downward-api-1050" to be "success or failure"
Apr 30 14:33:42.928: INFO: Pod "downwardapi-volume-f4279526-6b54-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.100187ms
Apr 30 14:33:44.933: INFO: Pod "downwardapi-volume-f4279526-6b54-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011105581s
Apr 30 14:33:46.937: INFO: Pod "downwardapi-volume-f4279526-6b54-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015621776s
STEP: Saw pod success
Apr 30 14:33:46.937: INFO: Pod "downwardapi-volume-f4279526-6b54-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 14:33:46.941: INFO: Trying to get logs from node fatih-test-default-pool-qlpd pod downwardapi-volume-f4279526-6b54-11e9-b570-225b9ad5bed0 container client-container: <nil>
STEP: delete the pod
Apr 30 14:33:46.980: INFO: Waiting for pod downwardapi-volume-f4279526-6b54-11e9-b570-225b9ad5bed0 to disappear
Apr 30 14:33:46.985: INFO: Pod downwardapi-volume-f4279526-6b54-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:33:46.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1050" for this suite.
Apr 30 14:33:53.005: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:33:53.104: INFO: namespace downward-api-1050 deletion completed in 6.116101619s

• [SLOW TEST:10.217 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:33:53.107: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 30 14:33:53.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 version'
Apr 30 14:33:53.258: INFO: stderr: ""
Apr 30 14:33:53.258: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.1\", GitCommit:\"b7394102d6ef778017f2ca4046abbaa23b88c290\", GitTreeState:\"clean\", BuildDate:\"2019-04-08T17:11:31Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.1\", GitCommit:\"b7394102d6ef778017f2ca4046abbaa23b88c290\", GitTreeState:\"clean\", BuildDate:\"2019-04-08T17:02:58Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:33:53.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2773" for this suite.
Apr 30 14:33:59.279: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:33:59.358: INFO: namespace kubectl-2773 deletion completed in 6.09645263s

• [SLOW TEST:6.251 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:33:59.358: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0430 14:34:40.193855      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 30 14:34:40.193: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:34:40.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2188" for this suite.
Apr 30 14:34:46.255: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:34:46.373: INFO: namespace gc-2188 deletion completed in 6.176711483s

• [SLOW TEST:47.015 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:34:46.374: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override arguments
Apr 30 14:34:46.426: INFO: Waiting up to 5m0s for pod "client-containers-19fe6161-6b55-11e9-b570-225b9ad5bed0" in namespace "containers-9986" to be "success or failure"
Apr 30 14:34:46.432: INFO: Pod "client-containers-19fe6161-6b55-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 5.780441ms
Apr 30 14:34:48.439: INFO: Pod "client-containers-19fe6161-6b55-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013228264s
Apr 30 14:34:50.444: INFO: Pod "client-containers-19fe6161-6b55-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018309517s
STEP: Saw pod success
Apr 30 14:34:50.444: INFO: Pod "client-containers-19fe6161-6b55-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 14:34:50.447: INFO: Trying to get logs from node fatih-test-default-pool-qlpd pod client-containers-19fe6161-6b55-11e9-b570-225b9ad5bed0 container test-container: <nil>
STEP: delete the pod
Apr 30 14:34:50.464: INFO: Waiting for pod client-containers-19fe6161-6b55-11e9-b570-225b9ad5bed0 to disappear
Apr 30 14:34:50.468: INFO: Pod client-containers-19fe6161-6b55-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:34:50.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9986" for this suite.
Apr 30 14:34:56.479: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:34:56.571: INFO: namespace containers-9986 deletion completed in 6.100813392s

• [SLOW TEST:10.198 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:34:56.578: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:35:00.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7744" for this suite.
Apr 30 14:35:46.705: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:35:46.782: INFO: namespace kubelet-test-7744 deletion completed in 46.088400206s

• [SLOW TEST:50.205 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a read only busybox container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:35:46.785: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 30 14:35:47.099: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3e2b5851-6b55-11e9-b570-225b9ad5bed0" in namespace "downward-api-567" to be "success or failure"
Apr 30 14:35:47.474: INFO: Pod "downwardapi-volume-3e2b5851-6b55-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 374.839672ms
Apr 30 14:35:49.576: INFO: Pod "downwardapi-volume-3e2b5851-6b55-11e9-b570-225b9ad5bed0": Phase="Running", Reason="", readiness=true. Elapsed: 2.476757461s
Apr 30 14:35:51.581: INFO: Pod "downwardapi-volume-3e2b5851-6b55-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.481439952s
STEP: Saw pod success
Apr 30 14:35:51.581: INFO: Pod "downwardapi-volume-3e2b5851-6b55-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 14:35:51.584: INFO: Trying to get logs from node fatih-test-default-pool-qlp1 pod downwardapi-volume-3e2b5851-6b55-11e9-b570-225b9ad5bed0 container client-container: <nil>
STEP: delete the pod
Apr 30 14:35:52.125: INFO: Waiting for pod downwardapi-volume-3e2b5851-6b55-11e9-b570-225b9ad5bed0 to disappear
Apr 30 14:35:52.130: INFO: Pod downwardapi-volume-3e2b5851-6b55-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:35:52.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-567" for this suite.
Apr 30 14:35:58.144: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:35:58.251: INFO: namespace downward-api-567 deletion completed in 6.11700734s

• [SLOW TEST:11.467 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:35:58.254: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 30 14:35:58.409: INFO: Waiting up to 5m0s for pod "downwardapi-volume-44e9335f-6b55-11e9-b570-225b9ad5bed0" in namespace "projected-1957" to be "success or failure"
Apr 30 14:35:58.416: INFO: Pod "downwardapi-volume-44e9335f-6b55-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.548482ms
Apr 30 14:36:00.420: INFO: Pod "downwardapi-volume-44e9335f-6b55-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011012756s
Apr 30 14:36:02.424: INFO: Pod "downwardapi-volume-44e9335f-6b55-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014584005s
STEP: Saw pod success
Apr 30 14:36:02.424: INFO: Pod "downwardapi-volume-44e9335f-6b55-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 14:36:02.431: INFO: Trying to get logs from node fatih-test-default-pool-qlpd pod downwardapi-volume-44e9335f-6b55-11e9-b570-225b9ad5bed0 container client-container: <nil>
STEP: delete the pod
Apr 30 14:36:05.803: INFO: Waiting for pod downwardapi-volume-44e9335f-6b55-11e9-b570-225b9ad5bed0 to disappear
Apr 30 14:36:05.829: INFO: Pod downwardapi-volume-44e9335f-6b55-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:36:05.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1957" for this suite.
Apr 30 14:36:12.079: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:36:12.152: INFO: namespace projected-1957 deletion completed in 6.082409428s

• [SLOW TEST:13.898 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:36:12.159: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:36:47.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6027" for this suite.
Apr 30 14:36:55.311: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:36:55.407: INFO: namespace container-runtime-6027 deletion completed in 8.103441331s

• [SLOW TEST:43.248 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  blackbox test
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:36:55.411: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-672a3fce-6b55-11e9-b570-225b9ad5bed0
STEP: Creating a pod to test consume configMaps
Apr 30 14:36:55.896: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-672bf8a4-6b55-11e9-b570-225b9ad5bed0" in namespace "projected-2010" to be "success or failure"
Apr 30 14:36:56.223: INFO: Pod "pod-projected-configmaps-672bf8a4-6b55-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 326.618169ms
Apr 30 14:36:58.227: INFO: Pod "pod-projected-configmaps-672bf8a4-6b55-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.330537124s
Apr 30 14:37:00.493: INFO: Pod "pod-projected-configmaps-672bf8a4-6b55-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.596705964s
STEP: Saw pod success
Apr 30 14:37:00.493: INFO: Pod "pod-projected-configmaps-672bf8a4-6b55-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 14:37:00.498: INFO: Trying to get logs from node fatih-test-default-pool-qlp0 pod pod-projected-configmaps-672bf8a4-6b55-11e9-b570-225b9ad5bed0 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 30 14:37:00.746: INFO: Waiting for pod pod-projected-configmaps-672bf8a4-6b55-11e9-b570-225b9ad5bed0 to disappear
Apr 30 14:37:00.751: INFO: Pod pod-projected-configmaps-672bf8a4-6b55-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:37:00.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2010" for this suite.
Apr 30 14:37:20.765: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:37:20.836: INFO: namespace projected-2010 deletion completed in 20.081435654s

• [SLOW TEST:25.425 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:37:20.839: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 30 14:37:21.019: INFO: Waiting up to 5m0s for pod "downwardapi-volume-762669b4-6b55-11e9-b570-225b9ad5bed0" in namespace "projected-4377" to be "success or failure"
Apr 30 14:37:21.130: INFO: Pod "downwardapi-volume-762669b4-6b55-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 110.960621ms
Apr 30 14:37:23.135: INFO: Pod "downwardapi-volume-762669b4-6b55-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.115956484s
Apr 30 14:37:25.141: INFO: Pod "downwardapi-volume-762669b4-6b55-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.121744585s
STEP: Saw pod success
Apr 30 14:37:25.141: INFO: Pod "downwardapi-volume-762669b4-6b55-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 14:37:25.145: INFO: Trying to get logs from node fatih-test-default-pool-qlpd pod downwardapi-volume-762669b4-6b55-11e9-b570-225b9ad5bed0 container client-container: <nil>
STEP: delete the pod
Apr 30 14:37:25.259: INFO: Waiting for pod downwardapi-volume-762669b4-6b55-11e9-b570-225b9ad5bed0 to disappear
Apr 30 14:37:25.270: INFO: Pod downwardapi-volume-762669b4-6b55-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:37:25.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4377" for this suite.
Apr 30 14:37:31.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:37:31.376: INFO: namespace projected-4377 deletion completed in 6.096470845s

• [SLOW TEST:10.538 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:37:31.382: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Apr 30 14:37:31.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 create -f - --namespace=kubectl-1139'
Apr 30 14:37:32.239: INFO: stderr: ""
Apr 30 14:37:32.239: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Apr 30 14:37:33.247: INFO: Selector matched 1 pods for map[app:redis]
Apr 30 14:37:33.247: INFO: Found 0 / 1
Apr 30 14:37:34.244: INFO: Selector matched 1 pods for map[app:redis]
Apr 30 14:37:34.244: INFO: Found 0 / 1
Apr 30 14:37:35.243: INFO: Selector matched 1 pods for map[app:redis]
Apr 30 14:37:35.243: INFO: Found 0 / 1
Apr 30 14:37:36.243: INFO: Selector matched 1 pods for map[app:redis]
Apr 30 14:37:36.243: INFO: Found 1 / 1
Apr 30 14:37:36.244: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Apr 30 14:37:36.248: INFO: Selector matched 1 pods for map[app:redis]
Apr 30 14:37:36.248: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 30 14:37:36.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 patch pod redis-master-894tj --namespace=kubectl-1139 -p {"metadata":{"annotations":{"x":"y"}}}'
Apr 30 14:37:36.359: INFO: stderr: ""
Apr 30 14:37:36.359: INFO: stdout: "pod/redis-master-894tj patched\n"
STEP: checking annotations
Apr 30 14:37:36.361: INFO: Selector matched 1 pods for map[app:redis]
Apr 30 14:37:36.361: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:37:36.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1139" for this suite.
Apr 30 14:37:58.806: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:37:58.892: INFO: namespace kubectl-1139 deletion completed in 22.528043297s

• [SLOW TEST:27.510 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:37:58.892: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:38:06.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-9521" for this suite.
Apr 30 14:38:12.510: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:38:12.844: INFO: namespace namespaces-9521 deletion completed in 6.350248827s
STEP: Destroying namespace "nsdeletetest-307" for this suite.
Apr 30 14:38:12.847: INFO: Namespace nsdeletetest-307 was already deleted
STEP: Destroying namespace "nsdeletetest-8083" for this suite.
Apr 30 14:38:18.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:38:18.937: INFO: namespace nsdeletetest-8083 deletion completed in 6.089942986s

• [SLOW TEST:20.045 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:38:18.938: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Apr 30 14:38:19.127: INFO: Waiting up to 5m0s for pod "pod-98c8cc71-6b55-11e9-b570-225b9ad5bed0" in namespace "emptydir-9494" to be "success or failure"
Apr 30 14:38:19.153: INFO: Pod "pod-98c8cc71-6b55-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 26.121064ms
Apr 30 14:38:21.182: INFO: Pod "pod-98c8cc71-6b55-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.055368661s
Apr 30 14:38:23.185: INFO: Pod "pod-98c8cc71-6b55-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.058750738s
Apr 30 14:38:28.189: INFO: Pod "pod-98c8cc71-6b55-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 9.062734003s
STEP: Saw pod success
Apr 30 14:38:28.190: INFO: Pod "pod-98c8cc71-6b55-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 14:38:28.230: INFO: Trying to get logs from node fatih-test-default-pool-qlp0 pod pod-98c8cc71-6b55-11e9-b570-225b9ad5bed0 container test-container: <nil>
STEP: delete the pod
Apr 30 14:38:28.338: INFO: Waiting for pod pod-98c8cc71-6b55-11e9-b570-225b9ad5bed0 to disappear
Apr 30 14:38:28.342: INFO: Pod pod-98c8cc71-6b55-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:38:28.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9494" for this suite.
Apr 30 14:38:38.357: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:38:38.446: INFO: namespace emptydir-9494 deletion completed in 10.100727914s

• [SLOW TEST:19.508 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:38:38.451: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 30 14:38:38.916: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a4948972-6b55-11e9-b570-225b9ad5bed0" in namespace "projected-9263" to be "success or failure"
Apr 30 14:38:39.042: INFO: Pod "downwardapi-volume-a4948972-6b55-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 126.602907ms
Apr 30 14:38:41.046: INFO: Pod "downwardapi-volume-a4948972-6b55-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.129666427s
Apr 30 14:38:43.078: INFO: Pod "downwardapi-volume-a4948972-6b55-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.162371696s
STEP: Saw pod success
Apr 30 14:38:43.078: INFO: Pod "downwardapi-volume-a4948972-6b55-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 14:38:43.084: INFO: Trying to get logs from node fatih-test-default-pool-qlp1 pod downwardapi-volume-a4948972-6b55-11e9-b570-225b9ad5bed0 container client-container: <nil>
STEP: delete the pod
Apr 30 14:38:43.306: INFO: Waiting for pod downwardapi-volume-a4948972-6b55-11e9-b570-225b9ad5bed0 to disappear
Apr 30 14:38:43.310: INFO: Pod downwardapi-volume-a4948972-6b55-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:38:43.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9263" for this suite.
Apr 30 14:38:49.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:38:49.420: INFO: namespace projected-9263 deletion completed in 6.106593822s

• [SLOW TEST:10.970 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:38:49.426: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-aae6597f-6b55-11e9-b570-225b9ad5bed0
STEP: Creating a pod to test consume secrets
Apr 30 14:38:49.623: INFO: Waiting up to 5m0s for pod "pod-secrets-aae6d180-6b55-11e9-b570-225b9ad5bed0" in namespace "secrets-4244" to be "success or failure"
Apr 30 14:38:49.629: INFO: Pod "pod-secrets-aae6d180-6b55-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 5.524781ms
Apr 30 14:38:51.632: INFO: Pod "pod-secrets-aae6d180-6b55-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008949946s
STEP: Saw pod success
Apr 30 14:38:51.632: INFO: Pod "pod-secrets-aae6d180-6b55-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 14:38:51.637: INFO: Trying to get logs from node fatih-test-default-pool-qlpd pod pod-secrets-aae6d180-6b55-11e9-b570-225b9ad5bed0 container secret-volume-test: <nil>
STEP: delete the pod
Apr 30 14:38:51.704: INFO: Waiting for pod pod-secrets-aae6d180-6b55-11e9-b570-225b9ad5bed0 to disappear
Apr 30 14:38:51.706: INFO: Pod pod-secrets-aae6d180-6b55-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:38:51.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4244" for this suite.
Apr 30 14:38:57.812: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:38:57.887: INFO: namespace secrets-4244 deletion completed in 6.17719285s

• [SLOW TEST:8.461 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:38:57.887: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1414
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 30 14:38:58.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-1788'
Apr 30 14:38:58.119: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr 30 14:38:58.119: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Apr 30 14:38:58.169: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Apr 30 14:38:58.188: INFO: scanned /root for discovery docs: <nil>
Apr 30 14:38:58.189: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-1788'
Apr 30 14:39:17.006: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Apr 30 14:39:17.006: INFO: stdout: "Created e2e-test-nginx-rc-83cda2891b545f33130f59a6e4f3982c\nScaling up e2e-test-nginx-rc-83cda2891b545f33130f59a6e4f3982c from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-83cda2891b545f33130f59a6e4f3982c up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-83cda2891b545f33130f59a6e4f3982c to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Apr 30 14:39:17.006: INFO: stdout: "Created e2e-test-nginx-rc-83cda2891b545f33130f59a6e4f3982c\nScaling up e2e-test-nginx-rc-83cda2891b545f33130f59a6e4f3982c from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-83cda2891b545f33130f59a6e4f3982c up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-83cda2891b545f33130f59a6e4f3982c to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Apr 30 14:39:17.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-1788'
Apr 30 14:39:17.106: INFO: stderr: ""
Apr 30 14:39:17.106: INFO: stdout: "e2e-test-nginx-rc-83cda2891b545f33130f59a6e4f3982c-dw4rk "
Apr 30 14:39:17.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods e2e-test-nginx-rc-83cda2891b545f33130f59a6e4f3982c-dw4rk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1788'
Apr 30 14:39:17.203: INFO: stderr: ""
Apr 30 14:39:17.203: INFO: stdout: "true"
Apr 30 14:39:17.203: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods e2e-test-nginx-rc-83cda2891b545f33130f59a6e4f3982c-dw4rk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1788'
Apr 30 14:39:17.302: INFO: stderr: ""
Apr 30 14:39:17.302: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Apr 30 14:39:17.302: INFO: e2e-test-nginx-rc-83cda2891b545f33130f59a6e4f3982c-dw4rk is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1420
Apr 30 14:39:17.302: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 delete rc e2e-test-nginx-rc --namespace=kubectl-1788'
Apr 30 14:39:17.406: INFO: stderr: ""
Apr 30 14:39:17.406: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:39:17.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1788" for this suite.
Apr 30 14:39:25.457: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:39:25.552: INFO: namespace kubectl-1788 deletion completed in 8.132734964s

• [SLOW TEST:27.665 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:39:25.559: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-2m9c
STEP: Creating a pod to test atomic-volume-subpath
Apr 30 14:39:25.614: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-2m9c" in namespace "subpath-6784" to be "success or failure"
Apr 30 14:39:25.674: INFO: Pod "pod-subpath-test-configmap-2m9c": Phase="Pending", Reason="", readiness=false. Elapsed: 59.495112ms
Apr 30 14:39:27.803: INFO: Pod "pod-subpath-test-configmap-2m9c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.188061502s
Apr 30 14:39:29.806: INFO: Pod "pod-subpath-test-configmap-2m9c": Phase="Running", Reason="", readiness=true. Elapsed: 4.191594166s
Apr 30 14:39:31.811: INFO: Pod "pod-subpath-test-configmap-2m9c": Phase="Running", Reason="", readiness=true. Elapsed: 6.195953453s
Apr 30 14:39:33.815: INFO: Pod "pod-subpath-test-configmap-2m9c": Phase="Running", Reason="", readiness=true. Elapsed: 8.200563575s
Apr 30 14:39:36.042: INFO: Pod "pod-subpath-test-configmap-2m9c": Phase="Running", Reason="", readiness=true. Elapsed: 10.427430785s
Apr 30 14:39:38.047: INFO: Pod "pod-subpath-test-configmap-2m9c": Phase="Running", Reason="", readiness=true. Elapsed: 12.432339992s
Apr 30 14:39:40.091: INFO: Pod "pod-subpath-test-configmap-2m9c": Phase="Running", Reason="", readiness=true. Elapsed: 14.475818867s
Apr 30 14:39:42.102: INFO: Pod "pod-subpath-test-configmap-2m9c": Phase="Running", Reason="", readiness=true. Elapsed: 16.4872865s
Apr 30 14:39:44.106: INFO: Pod "pod-subpath-test-configmap-2m9c": Phase="Running", Reason="", readiness=true. Elapsed: 18.491212272s
Apr 30 14:39:46.110: INFO: Pod "pod-subpath-test-configmap-2m9c": Phase="Running", Reason="", readiness=true. Elapsed: 20.495137677s
Apr 30 14:39:48.113: INFO: Pod "pod-subpath-test-configmap-2m9c": Phase="Running", Reason="", readiness=true. Elapsed: 22.498729271s
Apr 30 14:39:50.117: INFO: Pod "pod-subpath-test-configmap-2m9c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.502176495s
STEP: Saw pod success
Apr 30 14:39:50.117: INFO: Pod "pod-subpath-test-configmap-2m9c" satisfied condition "success or failure"
Apr 30 14:39:50.119: INFO: Trying to get logs from node fatih-test-default-pool-qlpd pod pod-subpath-test-configmap-2m9c container test-container-subpath-configmap-2m9c: <nil>
STEP: delete the pod
Apr 30 14:39:50.141: INFO: Waiting for pod pod-subpath-test-configmap-2m9c to disappear
Apr 30 14:39:50.144: INFO: Pod pod-subpath-test-configmap-2m9c no longer exists
STEP: Deleting pod pod-subpath-test-configmap-2m9c
Apr 30 14:39:50.144: INFO: Deleting pod "pod-subpath-test-configmap-2m9c" in namespace "subpath-6784"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:39:50.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6784" for this suite.
Apr 30 14:39:56.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:39:56.276: INFO: namespace subpath-6784 deletion completed in 6.097246436s

• [SLOW TEST:30.717 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:39:56.279: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Apr 30 14:39:56.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 create -f - --namespace=kubectl-4340'
Apr 30 14:39:56.561: INFO: stderr: ""
Apr 30 14:39:56.561: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 30 14:39:56.561: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4340'
Apr 30 14:39:56.677: INFO: stderr: ""
Apr 30 14:39:56.677: INFO: stdout: "update-demo-nautilus-4tmzh update-demo-nautilus-kvhc6 "
Apr 30 14:39:56.677: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods update-demo-nautilus-4tmzh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4340'
Apr 30 14:39:56.775: INFO: stderr: ""
Apr 30 14:39:56.775: INFO: stdout: ""
Apr 30 14:39:56.775: INFO: update-demo-nautilus-4tmzh is created but not running
Apr 30 14:40:01.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4340'
Apr 30 14:40:01.891: INFO: stderr: ""
Apr 30 14:40:01.891: INFO: stdout: "update-demo-nautilus-4tmzh update-demo-nautilus-kvhc6 "
Apr 30 14:40:01.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods update-demo-nautilus-4tmzh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4340'
Apr 30 14:40:01.998: INFO: stderr: ""
Apr 30 14:40:01.998: INFO: stdout: "true"
Apr 30 14:40:01.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods update-demo-nautilus-4tmzh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4340'
Apr 30 14:40:02.108: INFO: stderr: ""
Apr 30 14:40:02.108: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 30 14:40:02.108: INFO: validating pod update-demo-nautilus-4tmzh
Apr 30 14:40:02.117: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 30 14:40:02.117: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 30 14:40:02.117: INFO: update-demo-nautilus-4tmzh is verified up and running
Apr 30 14:40:02.117: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods update-demo-nautilus-kvhc6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4340'
Apr 30 14:40:02.249: INFO: stderr: ""
Apr 30 14:40:02.249: INFO: stdout: "true"
Apr 30 14:40:02.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods update-demo-nautilus-kvhc6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4340'
Apr 30 14:40:02.354: INFO: stderr: ""
Apr 30 14:40:02.354: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 30 14:40:02.354: INFO: validating pod update-demo-nautilus-kvhc6
Apr 30 14:40:02.372: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 30 14:40:02.372: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 30 14:40:02.372: INFO: update-demo-nautilus-kvhc6 is verified up and running
STEP: scaling down the replication controller
Apr 30 14:40:02.373: INFO: scanned /root for discovery docs: <nil>
Apr 30 14:40:02.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-4340'
Apr 30 14:40:03.642: INFO: stderr: ""
Apr 30 14:40:03.642: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 30 14:40:03.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4340'
Apr 30 14:40:03.742: INFO: stderr: ""
Apr 30 14:40:03.743: INFO: stdout: "update-demo-nautilus-4tmzh update-demo-nautilus-kvhc6 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Apr 30 14:40:08.743: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4340'
Apr 30 14:40:08.835: INFO: stderr: ""
Apr 30 14:40:08.835: INFO: stdout: "update-demo-nautilus-4tmzh "
Apr 30 14:40:08.835: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods update-demo-nautilus-4tmzh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4340'
Apr 30 14:40:08.938: INFO: stderr: ""
Apr 30 14:40:08.938: INFO: stdout: "true"
Apr 30 14:40:08.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods update-demo-nautilus-4tmzh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4340'
Apr 30 14:40:09.032: INFO: stderr: ""
Apr 30 14:40:09.032: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 30 14:40:09.032: INFO: validating pod update-demo-nautilus-4tmzh
Apr 30 14:40:09.036: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 30 14:40:09.036: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 30 14:40:09.036: INFO: update-demo-nautilus-4tmzh is verified up and running
STEP: scaling up the replication controller
Apr 30 14:40:09.038: INFO: scanned /root for discovery docs: <nil>
Apr 30 14:40:09.038: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-4340'
Apr 30 14:40:10.188: INFO: stderr: ""
Apr 30 14:40:10.188: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 30 14:40:10.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4340'
Apr 30 14:40:10.482: INFO: stderr: ""
Apr 30 14:40:10.482: INFO: stdout: "update-demo-nautilus-4tmzh update-demo-nautilus-9mlk2 "
Apr 30 14:40:10.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods update-demo-nautilus-4tmzh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4340'
Apr 30 14:40:10.588: INFO: stderr: ""
Apr 30 14:40:10.588: INFO: stdout: "true"
Apr 30 14:40:10.588: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods update-demo-nautilus-4tmzh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4340'
Apr 30 14:40:10.723: INFO: stderr: ""
Apr 30 14:40:10.723: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 30 14:40:10.723: INFO: validating pod update-demo-nautilus-4tmzh
Apr 30 14:40:10.730: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 30 14:40:10.730: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 30 14:40:10.730: INFO: update-demo-nautilus-4tmzh is verified up and running
Apr 30 14:40:10.730: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods update-demo-nautilus-9mlk2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4340'
Apr 30 14:40:10.827: INFO: stderr: ""
Apr 30 14:40:10.827: INFO: stdout: ""
Apr 30 14:40:10.827: INFO: update-demo-nautilus-9mlk2 is created but not running
Apr 30 14:40:15.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4340'
Apr 30 14:40:15.950: INFO: stderr: ""
Apr 30 14:40:15.950: INFO: stdout: "update-demo-nautilus-4tmzh update-demo-nautilus-9mlk2 "
Apr 30 14:40:15.950: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods update-demo-nautilus-4tmzh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4340'
Apr 30 14:40:16.046: INFO: stderr: ""
Apr 30 14:40:16.046: INFO: stdout: "true"
Apr 30 14:40:16.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods update-demo-nautilus-4tmzh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4340'
Apr 30 14:40:16.140: INFO: stderr: ""
Apr 30 14:40:16.140: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 30 14:40:16.140: INFO: validating pod update-demo-nautilus-4tmzh
Apr 30 14:40:16.144: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 30 14:40:16.144: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 30 14:40:16.144: INFO: update-demo-nautilus-4tmzh is verified up and running
Apr 30 14:40:16.144: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods update-demo-nautilus-9mlk2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4340'
Apr 30 14:40:16.245: INFO: stderr: ""
Apr 30 14:40:16.245: INFO: stdout: "true"
Apr 30 14:40:16.245: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods update-demo-nautilus-9mlk2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4340'
Apr 30 14:40:16.340: INFO: stderr: ""
Apr 30 14:40:16.340: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 30 14:40:16.340: INFO: validating pod update-demo-nautilus-9mlk2
Apr 30 14:40:16.346: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 30 14:40:16.346: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 30 14:40:16.346: INFO: update-demo-nautilus-9mlk2 is verified up and running
STEP: using delete to clean up resources
Apr 30 14:40:16.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 delete --grace-period=0 --force -f - --namespace=kubectl-4340'
Apr 30 14:40:16.455: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 30 14:40:16.455: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr 30 14:40:16.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-4340'
Apr 30 14:40:16.563: INFO: stderr: "No resources found.\n"
Apr 30 14:40:16.563: INFO: stdout: ""
Apr 30 14:40:16.563: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods -l name=update-demo --namespace=kubectl-4340 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 30 14:40:16.661: INFO: stderr: ""
Apr 30 14:40:16.661: INFO: stdout: "update-demo-nautilus-4tmzh\nupdate-demo-nautilus-9mlk2\n"
Apr 30 14:40:17.162: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-4340'
Apr 30 14:40:17.276: INFO: stderr: "No resources found.\n"
Apr 30 14:40:17.276: INFO: stdout: ""
Apr 30 14:40:17.276: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods -l name=update-demo --namespace=kubectl-4340 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 30 14:40:17.382: INFO: stderr: ""
Apr 30 14:40:17.382: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:40:17.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4340" for this suite.
Apr 30 14:40:39.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:40:39.476: INFO: namespace kubectl-4340 deletion completed in 22.090248901s

• [SLOW TEST:43.197 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:40:39.481: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Apr 30 14:40:39.517: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:40:44.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1101" for this suite.
Apr 30 14:40:50.697: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:40:50.802: INFO: namespace init-container-1101 deletion completed in 6.118372829s

• [SLOW TEST:11.322 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:40:50.804: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:41:16.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-4302" for this suite.
Apr 30 14:41:22.930: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:41:23.014: INFO: namespace namespaces-4302 deletion completed in 6.095635698s
STEP: Destroying namespace "nsdeletetest-8797" for this suite.
Apr 30 14:41:23.017: INFO: Namespace nsdeletetest-8797 was already deleted
STEP: Destroying namespace "nsdeletetest-1814" for this suite.
Apr 30 14:41:29.026: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:41:29.103: INFO: namespace nsdeletetest-1814 deletion completed in 6.086010018s

• [SLOW TEST:38.299 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:41:29.107: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-4371
Apr 30 14:41:31.163: INFO: Started pod liveness-exec in namespace container-probe-4371
STEP: checking the pod's current state and verifying that restartCount is present
Apr 30 14:41:31.167: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:45:31.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4371" for this suite.
Apr 30 14:45:37.905: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:45:37.982: INFO: namespace container-probe-4371 deletion completed in 6.088217336s

• [SLOW TEST:248.876 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:45:37.984: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 30 14:45:38.037: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9e649950-6b56-11e9-b570-225b9ad5bed0" in namespace "downward-api-5245" to be "success or failure"
Apr 30 14:45:38.045: INFO: Pod "downwardapi-volume-9e649950-6b56-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 7.884955ms
Apr 30 14:45:40.283: INFO: Pod "downwardapi-volume-9e649950-6b56-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.245782187s
Apr 30 14:45:42.288: INFO: Pod "downwardapi-volume-9e649950-6b56-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.250404269s
STEP: Saw pod success
Apr 30 14:45:42.288: INFO: Pod "downwardapi-volume-9e649950-6b56-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 14:45:42.291: INFO: Trying to get logs from node fatih-test-default-pool-qlp0 pod downwardapi-volume-9e649950-6b56-11e9-b570-225b9ad5bed0 container client-container: <nil>
STEP: delete the pod
Apr 30 14:45:42.319: INFO: Waiting for pod downwardapi-volume-9e649950-6b56-11e9-b570-225b9ad5bed0 to disappear
Apr 30 14:45:42.329: INFO: Pod downwardapi-volume-9e649950-6b56-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:45:42.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5245" for this suite.
Apr 30 14:45:48.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:45:48.429: INFO: namespace downward-api-5245 deletion completed in 6.097293735s

• [SLOW TEST:10.445 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:45:48.431: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on tmpfs
Apr 30 14:45:48.474: INFO: Waiting up to 5m0s for pod "pod-a49d7799-6b56-11e9-b570-225b9ad5bed0" in namespace "emptydir-6897" to be "success or failure"
Apr 30 14:45:48.485: INFO: Pod "pod-a49d7799-6b56-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 10.424747ms
Apr 30 14:45:50.490: INFO: Pod "pod-a49d7799-6b56-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015984481s
Apr 30 14:45:52.497: INFO: Pod "pod-a49d7799-6b56-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022869926s
STEP: Saw pod success
Apr 30 14:45:52.497: INFO: Pod "pod-a49d7799-6b56-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 14:45:52.502: INFO: Trying to get logs from node fatih-test-default-pool-qlp1 pod pod-a49d7799-6b56-11e9-b570-225b9ad5bed0 container test-container: <nil>
STEP: delete the pod
Apr 30 14:45:52.534: INFO: Waiting for pod pod-a49d7799-6b56-11e9-b570-225b9ad5bed0 to disappear
Apr 30 14:45:52.565: INFO: Pod pod-a49d7799-6b56-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:45:52.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6897" for this suite.
Apr 30 14:45:58.586: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:45:58.660: INFO: namespace emptydir-6897 deletion completed in 6.089126149s

• [SLOW TEST:10.229 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:45:58.664: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Apr 30 14:45:58.731: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:46:01.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7704" for this suite.
Apr 30 14:46:07.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:46:07.986: INFO: namespace init-container-7704 deletion completed in 6.088499308s

• [SLOW TEST:9.323 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:46:07.989: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating api versions
Apr 30 14:46:08.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 api-versions'
Apr 30 14:46:08.108: INFO: stderr: ""
Apr 30 14:46:08.108: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncilium.io/v2\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nsnapshot.storage.k8s.io/v1alpha1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:46:08.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1016" for this suite.
Apr 30 14:46:14.121: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:46:14.196: INFO: namespace kubectl-1016 deletion completed in 6.084968104s

• [SLOW TEST:6.207 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:46:14.200: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 30 14:46:18.366: INFO: Waiting up to 5m0s for pod "client-envvars-b66ec661-6b56-11e9-b570-225b9ad5bed0" in namespace "pods-9665" to be "success or failure"
Apr 30 14:46:18.380: INFO: Pod "client-envvars-b66ec661-6b56-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 14.266798ms
Apr 30 14:46:20.385: INFO: Pod "client-envvars-b66ec661-6b56-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019000165s
Apr 30 14:46:22.388: INFO: Pod "client-envvars-b66ec661-6b56-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02226383s
STEP: Saw pod success
Apr 30 14:46:22.388: INFO: Pod "client-envvars-b66ec661-6b56-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 14:46:22.391: INFO: Trying to get logs from node fatih-test-default-pool-qlp1 pod client-envvars-b66ec661-6b56-11e9-b570-225b9ad5bed0 container env3cont: <nil>
STEP: delete the pod
Apr 30 14:46:22.416: INFO: Waiting for pod client-envvars-b66ec661-6b56-11e9-b570-225b9ad5bed0 to disappear
Apr 30 14:46:22.422: INFO: Pod client-envvars-b66ec661-6b56-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:46:22.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9665" for this suite.
Apr 30 14:47:04.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:47:04.520: INFO: namespace pods-9665 deletion completed in 42.092101743s

• [SLOW TEST:50.321 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:47:04.526: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Apr 30 14:47:04.621: INFO: Waiting up to 5m0s for pod "pod-d20116b8-6b56-11e9-b570-225b9ad5bed0" in namespace "emptydir-8375" to be "success or failure"
Apr 30 14:47:04.632: INFO: Pod "pod-d20116b8-6b56-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 11.308278ms
Apr 30 14:47:06.636: INFO: Pod "pod-d20116b8-6b56-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015460911s
STEP: Saw pod success
Apr 30 14:47:06.636: INFO: Pod "pod-d20116b8-6b56-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 14:47:06.639: INFO: Trying to get logs from node fatih-test-default-pool-qlpd pod pod-d20116b8-6b56-11e9-b570-225b9ad5bed0 container test-container: <nil>
STEP: delete the pod
Apr 30 14:47:06.659: INFO: Waiting for pod pod-d20116b8-6b56-11e9-b570-225b9ad5bed0 to disappear
Apr 30 14:47:06.663: INFO: Pod pod-d20116b8-6b56-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:47:06.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8375" for this suite.
Apr 30 14:47:12.796: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:47:12.871: INFO: namespace emptydir-8375 deletion completed in 6.203806804s

• [SLOW TEST:8.346 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:47:12.871: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-1432
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Apr 30 14:47:12.930: INFO: Found 0 stateful pods, waiting for 3
Apr 30 14:47:22.935: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 30 14:47:22.935: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 30 14:47:22.935: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Apr 30 14:47:22.961: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Apr 30 14:47:32.998: INFO: Updating stateful set ss2
Apr 30 14:47:33.017: INFO: Waiting for Pod statefulset-1432/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Apr 30 14:47:43.146: INFO: Found 2 stateful pods, waiting for 3
Apr 30 14:47:53.151: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 30 14:47:53.151: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 30 14:47:53.151: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Apr 30 14:47:53.217: INFO: Updating stateful set ss2
Apr 30 14:47:53.268: INFO: Waiting for Pod statefulset-1432/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 30 14:48:03.294: INFO: Updating stateful set ss2
Apr 30 14:48:03.312: INFO: Waiting for StatefulSet statefulset-1432/ss2 to complete update
Apr 30 14:48:03.312: INFO: Waiting for Pod statefulset-1432/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr 30 14:48:13.322: INFO: Deleting all statefulset in ns statefulset-1432
Apr 30 14:48:13.326: INFO: Scaling statefulset ss2 to 0
Apr 30 14:48:23.345: INFO: Waiting for statefulset status.replicas updated to 0
Apr 30 14:48:23.348: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:48:23.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1432" for this suite.
Apr 30 14:48:29.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:48:29.458: INFO: namespace statefulset-1432 deletion completed in 6.094258848s

• [SLOW TEST:76.587 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:48:29.464: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-8569/configmap-test-04990bd7-6b57-11e9-b570-225b9ad5bed0
STEP: Creating a pod to test consume configMaps
Apr 30 14:48:29.505: INFO: Waiting up to 5m0s for pod "pod-configmaps-049977c6-6b57-11e9-b570-225b9ad5bed0" in namespace "configmap-8569" to be "success or failure"
Apr 30 14:48:29.518: INFO: Pod "pod-configmaps-049977c6-6b57-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 13.260082ms
Apr 30 14:48:31.523: INFO: Pod "pod-configmaps-049977c6-6b57-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017685253s
Apr 30 14:48:33.527: INFO: Pod "pod-configmaps-049977c6-6b57-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021995844s
STEP: Saw pod success
Apr 30 14:48:33.527: INFO: Pod "pod-configmaps-049977c6-6b57-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 14:48:33.538: INFO: Trying to get logs from node fatih-test-default-pool-qlpd pod pod-configmaps-049977c6-6b57-11e9-b570-225b9ad5bed0 container env-test: <nil>
STEP: delete the pod
Apr 30 14:48:33.563: INFO: Waiting for pod pod-configmaps-049977c6-6b57-11e9-b570-225b9ad5bed0 to disappear
Apr 30 14:48:33.566: INFO: Pod pod-configmaps-049977c6-6b57-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:48:33.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8569" for this suite.
Apr 30 14:48:39.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:48:39.661: INFO: namespace configmap-8569 deletion completed in 6.092278379s

• [SLOW TEST:10.197 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:48:39.664: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Apr 30 14:48:39.746: INFO: PodSpec: initContainers in spec.initContainers
Apr 30 14:49:23.624: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-0ab4e80e-6b57-11e9-b570-225b9ad5bed0", GenerateName:"", Namespace:"init-container-4648", SelfLink:"/api/v1/namespaces/init-container-4648/pods/pod-init-0ab4e80e-6b57-11e9-b570-225b9ad5bed0", UID:"0ab33bd4-6b57-11e9-a241-32cef6bf8510", ResourceVersion:"16205", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63692232519, loc:(*time.Location)(0x8a060e0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"746566963"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-t6h5j", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001704980), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-t6h5j", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-t6h5j", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-t6h5j", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001796478), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"fatih-test-default-pool-qlp0", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00205a180), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0017964f0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001796510)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001796518), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00179651c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692232519, loc:(*time.Location)(0x8a060e0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692232519, loc:(*time.Location)(0x8a060e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692232519, loc:(*time.Location)(0x8a060e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692232519, loc:(*time.Location)(0x8a060e0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.136.184.227", PodIP:"10.244.2.106", StartTime:(*v1.Time)(0xc00235cec0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001076850)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0010768c0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://d3a37cec083ea131dae8c7e7bb0788dac567aa06c61ca04fe660dbb218dc719e"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00235d120), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00235cfe0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:49:23.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4648" for this suite.
Apr 30 14:49:45.641: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:49:45.743: INFO: namespace init-container-4648 deletion completed in 22.112599161s

• [SLOW TEST:66.079 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:49:45.747: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-3223126b-6b57-11e9-b570-225b9ad5bed0
STEP: Creating a pod to test consume configMaps
Apr 30 14:49:45.917: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-32240e7e-6b57-11e9-b570-225b9ad5bed0" in namespace "projected-8463" to be "success or failure"
Apr 30 14:49:45.924: INFO: Pod "pod-projected-configmaps-32240e7e-6b57-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 7.084119ms
Apr 30 14:49:47.929: INFO: Pod "pod-projected-configmaps-32240e7e-6b57-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011761943s
Apr 30 14:49:50.076: INFO: Pod "pod-projected-configmaps-32240e7e-6b57-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.158616132s
STEP: Saw pod success
Apr 30 14:49:50.076: INFO: Pod "pod-projected-configmaps-32240e7e-6b57-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 14:49:50.082: INFO: Trying to get logs from node fatih-test-default-pool-qlp1 pod pod-projected-configmaps-32240e7e-6b57-11e9-b570-225b9ad5bed0 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 30 14:49:50.108: INFO: Waiting for pod pod-projected-configmaps-32240e7e-6b57-11e9-b570-225b9ad5bed0 to disappear
Apr 30 14:49:50.144: INFO: Pod pod-projected-configmaps-32240e7e-6b57-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:49:50.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8463" for this suite.
Apr 30 14:49:56.161: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:49:56.255: INFO: namespace projected-8463 deletion completed in 6.104169281s

• [SLOW TEST:10.509 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:49:56.257: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Apr 30 14:49:56.519: INFO: Pod name wrapped-volume-race-3875b04f-6b57-11e9-b570-225b9ad5bed0: Found 0 pods out of 5
Apr 30 14:50:01.525: INFO: Pod name wrapped-volume-race-3875b04f-6b57-11e9-b570-225b9ad5bed0: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-3875b04f-6b57-11e9-b570-225b9ad5bed0 in namespace emptydir-wrapper-5314, will wait for the garbage collector to delete the pods
Apr 30 14:50:15.624: INFO: Deleting ReplicationController wrapped-volume-race-3875b04f-6b57-11e9-b570-225b9ad5bed0 took: 25.829305ms
Apr 30 14:50:16.125: INFO: Terminating ReplicationController wrapped-volume-race-3875b04f-6b57-11e9-b570-225b9ad5bed0 pods took: 500.273251ms
STEP: Creating RC which spawns configmap-volume pods
Apr 30 14:51:03.045: INFO: Pod name wrapped-volume-race-601b7df0-6b57-11e9-b570-225b9ad5bed0: Found 0 pods out of 5
Apr 30 14:51:08.063: INFO: Pod name wrapped-volume-race-601b7df0-6b57-11e9-b570-225b9ad5bed0: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-601b7df0-6b57-11e9-b570-225b9ad5bed0 in namespace emptydir-wrapper-5314, will wait for the garbage collector to delete the pods
Apr 30 14:51:26.248: INFO: Deleting ReplicationController wrapped-volume-race-601b7df0-6b57-11e9-b570-225b9ad5bed0 took: 11.13287ms
Apr 30 14:51:26.648: INFO: Terminating ReplicationController wrapped-volume-race-601b7df0-6b57-11e9-b570-225b9ad5bed0 pods took: 400.498642ms
STEP: Creating RC which spawns configmap-volume pods
Apr 30 14:52:13.067: INFO: Pod name wrapped-volume-race-89d84681-6b57-11e9-b570-225b9ad5bed0: Found 0 pods out of 5
Apr 30 14:52:18.073: INFO: Pod name wrapped-volume-race-89d84681-6b57-11e9-b570-225b9ad5bed0: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-89d84681-6b57-11e9-b570-225b9ad5bed0 in namespace emptydir-wrapper-5314, will wait for the garbage collector to delete the pods
Apr 30 14:52:38.163: INFO: Deleting ReplicationController wrapped-volume-race-89d84681-6b57-11e9-b570-225b9ad5bed0 took: 11.50195ms
Apr 30 14:52:38.581: INFO: Terminating ReplicationController wrapped-volume-race-89d84681-6b57-11e9-b570-225b9ad5bed0 pods took: 418.549963ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:53:15.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-5314" for this suite.
Apr 30 14:53:23.568: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:53:23.648: INFO: namespace emptydir-wrapper-5314 deletion completed in 8.090433971s

• [SLOW TEST:207.392 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:53:23.653: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1510
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 30 14:53:23.685: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-8983'
Apr 30 14:53:23.987: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr 30 14:53:23.987: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1515
Apr 30 14:53:23.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 delete jobs e2e-test-nginx-job --namespace=kubectl-8983'
Apr 30 14:53:24.095: INFO: stderr: ""
Apr 30 14:53:24.095: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:53:24.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8983" for this suite.
Apr 30 14:53:30.109: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:53:30.183: INFO: namespace kubectl-8983 deletion completed in 6.085260711s

• [SLOW TEST:6.530 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:53:30.184: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Apr 30 14:53:30.217: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-9102,SelfLink:/api/v1/namespaces/watch-9102/configmaps/e2e-watch-test-configmap-a,UID:b7d48f94-6b57-11e9-a241-32cef6bf8510,ResourceVersion:17634,Generation:0,CreationTimestamp:2019-04-30 14:53:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr 30 14:53:30.217: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-9102,SelfLink:/api/v1/namespaces/watch-9102/configmaps/e2e-watch-test-configmap-a,UID:b7d48f94-6b57-11e9-a241-32cef6bf8510,ResourceVersion:17634,Generation:0,CreationTimestamp:2019-04-30 14:53:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Apr 30 14:53:40.226: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-9102,SelfLink:/api/v1/namespaces/watch-9102/configmaps/e2e-watch-test-configmap-a,UID:b7d48f94-6b57-11e9-a241-32cef6bf8510,ResourceVersion:17649,Generation:0,CreationTimestamp:2019-04-30 14:53:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Apr 30 14:53:40.226: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-9102,SelfLink:/api/v1/namespaces/watch-9102/configmaps/e2e-watch-test-configmap-a,UID:b7d48f94-6b57-11e9-a241-32cef6bf8510,ResourceVersion:17649,Generation:0,CreationTimestamp:2019-04-30 14:53:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Apr 30 14:53:50.232: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-9102,SelfLink:/api/v1/namespaces/watch-9102/configmaps/e2e-watch-test-configmap-a,UID:b7d48f94-6b57-11e9-a241-32cef6bf8510,ResourceVersion:17666,Generation:0,CreationTimestamp:2019-04-30 14:53:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr 30 14:53:50.232: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-9102,SelfLink:/api/v1/namespaces/watch-9102/configmaps/e2e-watch-test-configmap-a,UID:b7d48f94-6b57-11e9-a241-32cef6bf8510,ResourceVersion:17666,Generation:0,CreationTimestamp:2019-04-30 14:53:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Apr 30 14:54:00.237: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-9102,SelfLink:/api/v1/namespaces/watch-9102/configmaps/e2e-watch-test-configmap-a,UID:b7d48f94-6b57-11e9-a241-32cef6bf8510,ResourceVersion:17683,Generation:0,CreationTimestamp:2019-04-30 14:53:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr 30 14:54:00.237: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-9102,SelfLink:/api/v1/namespaces/watch-9102/configmaps/e2e-watch-test-configmap-a,UID:b7d48f94-6b57-11e9-a241-32cef6bf8510,ResourceVersion:17683,Generation:0,CreationTimestamp:2019-04-30 14:53:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Apr 30 14:54:10.246: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-9102,SelfLink:/api/v1/namespaces/watch-9102/configmaps/e2e-watch-test-configmap-b,UID:cfafafcd-6b57-11e9-a241-32cef6bf8510,ResourceVersion:17698,Generation:0,CreationTimestamp:2019-04-30 14:54:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr 30 14:54:10.246: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-9102,SelfLink:/api/v1/namespaces/watch-9102/configmaps/e2e-watch-test-configmap-b,UID:cfafafcd-6b57-11e9-a241-32cef6bf8510,ResourceVersion:17698,Generation:0,CreationTimestamp:2019-04-30 14:54:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Apr 30 14:54:20.255: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-9102,SelfLink:/api/v1/namespaces/watch-9102/configmaps/e2e-watch-test-configmap-b,UID:cfafafcd-6b57-11e9-a241-32cef6bf8510,ResourceVersion:17770,Generation:0,CreationTimestamp:2019-04-30 14:54:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr 30 14:54:20.255: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-9102,SelfLink:/api/v1/namespaces/watch-9102/configmaps/e2e-watch-test-configmap-b,UID:cfafafcd-6b57-11e9-a241-32cef6bf8510,ResourceVersion:17770,Generation:0,CreationTimestamp:2019-04-30 14:54:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:54:30.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9102" for this suite.
Apr 30 14:54:36.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:54:36.349: INFO: namespace watch-9102 deletion completed in 6.08899796s

• [SLOW TEST:66.165 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:54:36.354: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-df48a777-6b57-11e9-b570-225b9ad5bed0
STEP: Creating a pod to test consume secrets
Apr 30 14:54:36.400: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-df49292a-6b57-11e9-b570-225b9ad5bed0" in namespace "projected-6235" to be "success or failure"
Apr 30 14:54:36.420: INFO: Pod "pod-projected-secrets-df49292a-6b57-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 19.838249ms
Apr 30 14:54:38.424: INFO: Pod "pod-projected-secrets-df49292a-6b57-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024411538s
Apr 30 14:54:40.429: INFO: Pod "pod-projected-secrets-df49292a-6b57-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028837942s
STEP: Saw pod success
Apr 30 14:54:40.429: INFO: Pod "pod-projected-secrets-df49292a-6b57-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 14:54:40.432: INFO: Trying to get logs from node fatih-test-default-pool-qlp0 pod pod-projected-secrets-df49292a-6b57-11e9-b570-225b9ad5bed0 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 30 14:54:40.450: INFO: Waiting for pod pod-projected-secrets-df49292a-6b57-11e9-b570-225b9ad5bed0 to disappear
Apr 30 14:54:40.460: INFO: Pod pod-projected-secrets-df49292a-6b57-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:54:40.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6235" for this suite.
Apr 30 14:54:46.473: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:54:46.562: INFO: namespace projected-6235 deletion completed in 6.098961157s

• [SLOW TEST:10.209 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:54:46.565: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-e56053b4-6b57-11e9-b570-225b9ad5bed0
STEP: Creating a pod to test consume configMaps
Apr 30 14:54:46.651: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e563ca01-6b57-11e9-b570-225b9ad5bed0" in namespace "projected-6442" to be "success or failure"
Apr 30 14:54:46.683: INFO: Pod "pod-projected-configmaps-e563ca01-6b57-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 31.972828ms
Apr 30 14:54:48.688: INFO: Pod "pod-projected-configmaps-e563ca01-6b57-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036760497s
Apr 30 14:54:50.692: INFO: Pod "pod-projected-configmaps-e563ca01-6b57-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040647093s
STEP: Saw pod success
Apr 30 14:54:50.692: INFO: Pod "pod-projected-configmaps-e563ca01-6b57-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 14:54:50.695: INFO: Trying to get logs from node fatih-test-default-pool-qlp1 pod pod-projected-configmaps-e563ca01-6b57-11e9-b570-225b9ad5bed0 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 30 14:54:50.717: INFO: Waiting for pod pod-projected-configmaps-e563ca01-6b57-11e9-b570-225b9ad5bed0 to disappear
Apr 30 14:54:50.719: INFO: Pod pod-projected-configmaps-e563ca01-6b57-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:54:50.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6442" for this suite.
Apr 30 14:54:56.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:54:56.836: INFO: namespace projected-6442 deletion completed in 6.112739932s

• [SLOW TEST:10.271 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:54:56.843: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-eb8d3f40-6b57-11e9-b570-225b9ad5bed0
STEP: Creating a pod to test consume secrets
Apr 30 14:54:56.986: INFO: Waiting up to 5m0s for pod "pod-secrets-eb8e0b2f-6b57-11e9-b570-225b9ad5bed0" in namespace "secrets-1110" to be "success or failure"
Apr 30 14:54:56.992: INFO: Pod "pod-secrets-eb8e0b2f-6b57-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 5.865546ms
Apr 30 14:54:58.997: INFO: Pod "pod-secrets-eb8e0b2f-6b57-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010550146s
Apr 30 14:55:01.001: INFO: Pod "pod-secrets-eb8e0b2f-6b57-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014415008s
STEP: Saw pod success
Apr 30 14:55:01.001: INFO: Pod "pod-secrets-eb8e0b2f-6b57-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 14:55:01.003: INFO: Trying to get logs from node fatih-test-default-pool-qlpd pod pod-secrets-eb8e0b2f-6b57-11e9-b570-225b9ad5bed0 container secret-volume-test: <nil>
STEP: delete the pod
Apr 30 14:55:01.042: INFO: Waiting for pod pod-secrets-eb8e0b2f-6b57-11e9-b570-225b9ad5bed0 to disappear
Apr 30 14:55:01.057: INFO: Pod pod-secrets-eb8e0b2f-6b57-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:55:01.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1110" for this suite.
Apr 30 14:55:07.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:55:07.161: INFO: namespace secrets-1110 deletion completed in 6.092789046s

• [SLOW TEST:10.318 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:55:07.164: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0430 14:55:14.952225      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 30 14:55:14.952: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:55:14.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3398" for this suite.
Apr 30 14:55:20.982: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:55:21.112: INFO: namespace gc-3398 deletion completed in 6.14781037s

• [SLOW TEST:13.949 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:55:21.115: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Apr 30 14:55:21.172: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7231,SelfLink:/api/v1/namespaces/watch-7231/configmaps/e2e-watch-test-label-changed,UID:f9f4f7d9-6b57-11e9-a241-32cef6bf8510,ResourceVersion:18253,Generation:0,CreationTimestamp:2019-04-30 14:55:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr 30 14:55:21.173: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7231,SelfLink:/api/v1/namespaces/watch-7231/configmaps/e2e-watch-test-label-changed,UID:f9f4f7d9-6b57-11e9-a241-32cef6bf8510,ResourceVersion:18254,Generation:0,CreationTimestamp:2019-04-30 14:55:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Apr 30 14:55:21.173: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7231,SelfLink:/api/v1/namespaces/watch-7231/configmaps/e2e-watch-test-label-changed,UID:f9f4f7d9-6b57-11e9-a241-32cef6bf8510,ResourceVersion:18255,Generation:0,CreationTimestamp:2019-04-30 14:55:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Apr 30 14:55:31.203: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7231,SelfLink:/api/v1/namespaces/watch-7231/configmaps/e2e-watch-test-label-changed,UID:f9f4f7d9-6b57-11e9-a241-32cef6bf8510,ResourceVersion:18271,Generation:0,CreationTimestamp:2019-04-30 14:55:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr 30 14:55:31.203: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7231,SelfLink:/api/v1/namespaces/watch-7231/configmaps/e2e-watch-test-label-changed,UID:f9f4f7d9-6b57-11e9-a241-32cef6bf8510,ResourceVersion:18272,Generation:0,CreationTimestamp:2019-04-30 14:55:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Apr 30 14:55:31.204: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7231,SelfLink:/api/v1/namespaces/watch-7231/configmaps/e2e-watch-test-label-changed,UID:f9f4f7d9-6b57-11e9-a241-32cef6bf8510,ResourceVersion:18273,Generation:0,CreationTimestamp:2019-04-30 14:55:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:55:31.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7231" for this suite.
Apr 30 14:55:37.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:55:37.329: INFO: namespace watch-7231 deletion completed in 6.101916007s

• [SLOW TEST:16.214 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:55:37.334: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
Apr 30 14:55:37.949: INFO: created pod pod-service-account-defaultsa
Apr 30 14:55:37.949: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Apr 30 14:55:37.957: INFO: created pod pod-service-account-mountsa
Apr 30 14:55:37.957: INFO: pod pod-service-account-mountsa service account token volume mount: true
Apr 30 14:55:37.999: INFO: created pod pod-service-account-nomountsa
Apr 30 14:55:38.000: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Apr 30 14:55:38.019: INFO: created pod pod-service-account-defaultsa-mountspec
Apr 30 14:55:38.019: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Apr 30 14:55:38.087: INFO: created pod pod-service-account-mountsa-mountspec
Apr 30 14:55:38.087: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Apr 30 14:55:38.134: INFO: created pod pod-service-account-nomountsa-mountspec
Apr 30 14:55:38.134: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Apr 30 14:55:38.169: INFO: created pod pod-service-account-defaultsa-nomountspec
Apr 30 14:55:38.169: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Apr 30 14:55:38.180: INFO: created pod pod-service-account-mountsa-nomountspec
Apr 30 14:55:38.180: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Apr 30 14:55:38.206: INFO: created pod pod-service-account-nomountsa-nomountspec
Apr 30 14:55:38.206: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:55:38.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-3058" for this suite.
Apr 30 14:56:00.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:56:00.380: INFO: namespace svcaccounts-3058 deletion completed in 22.099131126s

• [SLOW TEST:23.046 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:56:00.383: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override all
Apr 30 14:56:00.419: INFO: Waiting up to 5m0s for pod "client-containers-115c90a3-6b58-11e9-b570-225b9ad5bed0" in namespace "containers-9070" to be "success or failure"
Apr 30 14:56:00.424: INFO: Pod "client-containers-115c90a3-6b58-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 5.198814ms
Apr 30 14:56:02.428: INFO: Pod "client-containers-115c90a3-6b58-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008887044s
Apr 30 14:56:04.432: INFO: Pod "client-containers-115c90a3-6b58-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012440671s
STEP: Saw pod success
Apr 30 14:56:04.432: INFO: Pod "client-containers-115c90a3-6b58-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 14:56:04.434: INFO: Trying to get logs from node fatih-test-default-pool-qlp1 pod client-containers-115c90a3-6b58-11e9-b570-225b9ad5bed0 container test-container: <nil>
STEP: delete the pod
Apr 30 14:56:04.464: INFO: Waiting for pod client-containers-115c90a3-6b58-11e9-b570-225b9ad5bed0 to disappear
Apr 30 14:56:04.466: INFO: Pod client-containers-115c90a3-6b58-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:56:04.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9070" for this suite.
Apr 30 14:56:10.480: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:56:10.562: INFO: namespace containers-9070 deletion completed in 6.093246763s

• [SLOW TEST:10.180 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:56:10.565: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1318
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 30 14:56:10.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-2861'
Apr 30 14:56:10.714: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr 30 14:56:10.714: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1324
Apr 30 14:56:12.800: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 delete deployment e2e-test-nginx-deployment --namespace=kubectl-2861'
Apr 30 14:56:12.997: INFO: stderr: ""
Apr 30 14:56:12.997: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:56:12.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2861" for this suite.
Apr 30 14:57:35.012: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:57:35.102: INFO: namespace kubectl-2861 deletion completed in 1m22.102193569s

• [SLOW TEST:84.537 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:57:35.108: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-49e9a835-6b58-11e9-b570-225b9ad5bed0
STEP: Creating a pod to test consume configMaps
Apr 30 14:57:35.293: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-49ea098a-6b58-11e9-b570-225b9ad5bed0" in namespace "projected-7975" to be "success or failure"
Apr 30 14:57:35.315: INFO: Pod "pod-projected-configmaps-49ea098a-6b58-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 22.297999ms
Apr 30 14:57:37.321: INFO: Pod "pod-projected-configmaps-49ea098a-6b58-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028077691s
Apr 30 14:57:39.325: INFO: Pod "pod-projected-configmaps-49ea098a-6b58-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032166957s
STEP: Saw pod success
Apr 30 14:57:39.325: INFO: Pod "pod-projected-configmaps-49ea098a-6b58-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 14:57:39.328: INFO: Trying to get logs from node fatih-test-default-pool-qlp0 pod pod-projected-configmaps-49ea098a-6b58-11e9-b570-225b9ad5bed0 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 30 14:57:39.365: INFO: Waiting for pod pod-projected-configmaps-49ea098a-6b58-11e9-b570-225b9ad5bed0 to disappear
Apr 30 14:57:39.369: INFO: Pod pod-projected-configmaps-49ea098a-6b58-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:57:39.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7975" for this suite.
Apr 30 14:57:45.396: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:57:45.475: INFO: namespace projected-7975 deletion completed in 6.102205963s

• [SLOW TEST:10.368 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:57:45.478: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-2860
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating stateful set ss in namespace statefulset-2860
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-2860
Apr 30 14:57:45.621: INFO: Found 0 stateful pods, waiting for 1
Apr 30 14:57:55.626: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Apr 30 14:57:55.630: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 exec --namespace=statefulset-2860 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 30 14:57:55.926: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 30 14:57:55.926: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 30 14:57:55.926: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 30 14:57:55.933: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr 30 14:58:05.939: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 30 14:58:05.939: INFO: Waiting for statefulset status.replicas updated to 0
Apr 30 14:58:05.986: INFO: POD   NODE                          PHASE    GRACE  CONDITIONS
Apr 30 14:58:05.986: INFO: ss-0  fatih-test-default-pool-qlp1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:57:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:57:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:57:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:57:45 +0000 UTC  }]
Apr 30 14:58:05.986: INFO: ss-1                                Pending         []
Apr 30 14:58:05.986: INFO: 
Apr 30 14:58:05.986: INFO: StatefulSet ss has not reached scale 3, at 2
Apr 30 14:58:07.224: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.745977263s
Apr 30 14:58:08.229: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.737716162s
Apr 30 14:58:09.234: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.733067077s
Apr 30 14:58:10.239: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.728007507s
Apr 30 14:58:11.244: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.722787034s
Apr 30 14:58:12.248: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.717997128s
Apr 30 14:58:13.254: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.713126413s
Apr 30 14:58:14.260: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.707262025s
Apr 30 14:58:15.265: INFO: Verifying statefulset ss doesn't scale past 3 for another 701.610768ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-2860
Apr 30 14:58:16.271: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 exec --namespace=statefulset-2860 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 30 14:58:16.554: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr 30 14:58:16.554: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 30 14:58:16.554: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 30 14:58:16.554: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 exec --namespace=statefulset-2860 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 30 14:58:16.814: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr 30 14:58:16.815: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 30 14:58:16.815: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 30 14:58:16.815: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 exec --namespace=statefulset-2860 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 30 14:58:17.184: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr 30 14:58:17.184: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 30 14:58:17.184: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 30 14:58:17.187: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 30 14:58:17.187: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 30 14:58:17.187: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Apr 30 14:58:17.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 exec --namespace=statefulset-2860 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 30 14:58:17.561: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 30 14:58:17.561: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 30 14:58:17.561: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 30 14:58:17.561: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 exec --namespace=statefulset-2860 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 30 14:58:18.173: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 30 14:58:18.173: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 30 14:58:18.173: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 30 14:58:18.173: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 exec --namespace=statefulset-2860 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 30 14:58:18.495: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 30 14:58:18.495: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 30 14:58:18.495: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 30 14:58:18.495: INFO: Waiting for statefulset status.replicas updated to 0
Apr 30 14:58:18.499: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Apr 30 14:58:28.508: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 30 14:58:28.508: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr 30 14:58:28.508: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr 30 14:58:28.518: INFO: POD   NODE                          PHASE    GRACE  CONDITIONS
Apr 30 14:58:28.518: INFO: ss-0  fatih-test-default-pool-qlp1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:57:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:57:45 +0000 UTC  }]
Apr 30 14:58:28.518: INFO: ss-1  fatih-test-default-pool-qlpd  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:05 +0000 UTC  }]
Apr 30 14:58:28.518: INFO: ss-2  fatih-test-default-pool-qlp0  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:05 +0000 UTC  }]
Apr 30 14:58:28.523: INFO: 
Apr 30 14:58:28.523: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 30 14:58:29.528: INFO: POD   NODE                          PHASE    GRACE  CONDITIONS
Apr 30 14:58:29.528: INFO: ss-0  fatih-test-default-pool-qlp1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:57:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:57:45 +0000 UTC  }]
Apr 30 14:58:29.528: INFO: ss-1  fatih-test-default-pool-qlpd  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:05 +0000 UTC  }]
Apr 30 14:58:29.528: INFO: ss-2  fatih-test-default-pool-qlp0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:05 +0000 UTC  }]
Apr 30 14:58:29.528: INFO: 
Apr 30 14:58:29.528: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 30 14:58:30.533: INFO: POD   NODE                          PHASE    GRACE  CONDITIONS
Apr 30 14:58:30.533: INFO: ss-0  fatih-test-default-pool-qlp1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:57:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:57:45 +0000 UTC  }]
Apr 30 14:58:30.533: INFO: ss-1  fatih-test-default-pool-qlpd  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:05 +0000 UTC  }]
Apr 30 14:58:30.533: INFO: ss-2  fatih-test-default-pool-qlp0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:05 +0000 UTC  }]
Apr 30 14:58:30.533: INFO: 
Apr 30 14:58:30.533: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 30 14:58:31.538: INFO: POD   NODE                          PHASE    GRACE  CONDITIONS
Apr 30 14:58:31.538: INFO: ss-1  fatih-test-default-pool-qlpd  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:05 +0000 UTC  }]
Apr 30 14:58:31.539: INFO: ss-2  fatih-test-default-pool-qlp0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:05 +0000 UTC  }]
Apr 30 14:58:31.539: INFO: 
Apr 30 14:58:31.539: INFO: StatefulSet ss has not reached scale 0, at 2
Apr 30 14:58:32.546: INFO: POD   NODE                          PHASE    GRACE  CONDITIONS
Apr 30 14:58:32.546: INFO: ss-1  fatih-test-default-pool-qlpd  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:05 +0000 UTC  }]
Apr 30 14:58:32.546: INFO: ss-2  fatih-test-default-pool-qlp0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:05 +0000 UTC  }]
Apr 30 14:58:32.546: INFO: 
Apr 30 14:58:32.546: INFO: StatefulSet ss has not reached scale 0, at 2
Apr 30 14:58:33.551: INFO: POD   NODE                          PHASE    GRACE  CONDITIONS
Apr 30 14:58:33.551: INFO: ss-1  fatih-test-default-pool-qlpd  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:05 +0000 UTC  }]
Apr 30 14:58:33.551: INFO: 
Apr 30 14:58:33.551: INFO: StatefulSet ss has not reached scale 0, at 1
Apr 30 14:58:34.555: INFO: POD   NODE                          PHASE    GRACE  CONDITIONS
Apr 30 14:58:34.555: INFO: ss-1  fatih-test-default-pool-qlpd  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:05 +0000 UTC  }]
Apr 30 14:58:34.555: INFO: 
Apr 30 14:58:34.555: INFO: StatefulSet ss has not reached scale 0, at 1
Apr 30 14:58:35.561: INFO: POD   NODE                          PHASE    GRACE  CONDITIONS
Apr 30 14:58:35.561: INFO: ss-1  fatih-test-default-pool-qlpd  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:05 +0000 UTC  }]
Apr 30 14:58:35.561: INFO: 
Apr 30 14:58:35.561: INFO: StatefulSet ss has not reached scale 0, at 1
Apr 30 14:58:36.565: INFO: POD   NODE                          PHASE    GRACE  CONDITIONS
Apr 30 14:58:36.565: INFO: ss-1  fatih-test-default-pool-qlpd  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:05 +0000 UTC  }]
Apr 30 14:58:36.565: INFO: 
Apr 30 14:58:36.565: INFO: StatefulSet ss has not reached scale 0, at 1
Apr 30 14:58:37.577: INFO: POD   NODE                          PHASE    GRACE  CONDITIONS
Apr 30 14:58:37.577: INFO: ss-1  fatih-test-default-pool-qlpd  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 14:58:05 +0000 UTC  }]
Apr 30 14:58:37.577: INFO: 
Apr 30 14:58:37.577: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-2860
Apr 30 14:58:38.581: INFO: Scaling statefulset ss to 0
Apr 30 14:58:38.587: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr 30 14:58:38.590: INFO: Deleting all statefulset in ns statefulset-2860
Apr 30 14:58:38.592: INFO: Scaling statefulset ss to 0
Apr 30 14:58:38.600: INFO: Waiting for statefulset status.replicas updated to 0
Apr 30 14:58:38.602: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:58:38.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2860" for this suite.
Apr 30 14:58:44.646: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 14:58:44.733: INFO: namespace statefulset-2860 deletion completed in 6.101202302s

• [SLOW TEST:59.256 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 14:58:44.740: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 14:59:44.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3415" for this suite.
Apr 30 15:00:06.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:00:06.889: INFO: namespace container-probe-3415 deletion completed in 22.106575287s

• [SLOW TEST:82.149 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:00:06.889: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-a453fd20-6b58-11e9-b570-225b9ad5bed0
STEP: Creating a pod to test consume secrets
Apr 30 15:00:06.987: INFO: Waiting up to 5m0s for pod "pod-secrets-a4545faa-6b58-11e9-b570-225b9ad5bed0" in namespace "secrets-925" to be "success or failure"
Apr 30 15:00:06.992: INFO: Pod "pod-secrets-a4545faa-6b58-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 5.605197ms
Apr 30 15:00:08.997: INFO: Pod "pod-secrets-a4545faa-6b58-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009665286s
Apr 30 15:00:11.000: INFO: Pod "pod-secrets-a4545faa-6b58-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013063563s
STEP: Saw pod success
Apr 30 15:00:11.000: INFO: Pod "pod-secrets-a4545faa-6b58-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 15:00:11.002: INFO: Trying to get logs from node fatih-test-default-pool-qlpd pod pod-secrets-a4545faa-6b58-11e9-b570-225b9ad5bed0 container secret-volume-test: <nil>
STEP: delete the pod
Apr 30 15:00:11.024: INFO: Waiting for pod pod-secrets-a4545faa-6b58-11e9-b570-225b9ad5bed0 to disappear
Apr 30 15:00:11.027: INFO: Pod pod-secrets-a4545faa-6b58-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:00:11.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-925" for this suite.
Apr 30 15:00:17.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:00:17.120: INFO: namespace secrets-925 deletion completed in 6.089383506s

• [SLOW TEST:10.231 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:00:17.126: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating server pod server in namespace prestop-6620
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-6620
STEP: Deleting pre-stop pod
Apr 30 15:00:32.280: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:00:32.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-6620" for this suite.
Apr 30 15:01:10.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:01:10.391: INFO: namespace prestop-6620 deletion completed in 38.086598177s

• [SLOW TEST:53.266 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:01:10.394: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1190
STEP: creating an rc
Apr 30 15:01:10.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 create -f - --namespace=kubectl-1177'
Apr 30 15:01:10.641: INFO: stderr: ""
Apr 30 15:01:10.641: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Waiting for Redis master to start.
Apr 30 15:01:11.645: INFO: Selector matched 1 pods for map[app:redis]
Apr 30 15:01:11.645: INFO: Found 0 / 1
Apr 30 15:01:12.748: INFO: Selector matched 1 pods for map[app:redis]
Apr 30 15:01:12.748: INFO: Found 0 / 1
Apr 30 15:01:13.646: INFO: Selector matched 1 pods for map[app:redis]
Apr 30 15:01:13.646: INFO: Found 1 / 1
Apr 30 15:01:13.646: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 30 15:01:13.649: INFO: Selector matched 1 pods for map[app:redis]
Apr 30 15:01:13.649: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Apr 30 15:01:13.649: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 logs redis-master-nv9t4 redis-master --namespace=kubectl-1177'
Apr 30 15:01:13.759: INFO: stderr: ""
Apr 30 15:01:13.759: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 30 Apr 15:01:12.534 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 30 Apr 15:01:12.535 # Server started, Redis version 3.2.12\n1:M 30 Apr 15:01:12.535 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 30 Apr 15:01:12.535 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Apr 30 15:01:13.759: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 log redis-master-nv9t4 redis-master --namespace=kubectl-1177 --tail=1'
Apr 30 15:01:13.869: INFO: stderr: ""
Apr 30 15:01:13.869: INFO: stdout: "1:M 30 Apr 15:01:12.535 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Apr 30 15:01:13.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 log redis-master-nv9t4 redis-master --namespace=kubectl-1177 --limit-bytes=1'
Apr 30 15:01:13.993: INFO: stderr: ""
Apr 30 15:01:13.993: INFO: stdout: " "
STEP: exposing timestamps
Apr 30 15:01:13.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 log redis-master-nv9t4 redis-master --namespace=kubectl-1177 --tail=1 --timestamps'
Apr 30 15:01:14.143: INFO: stderr: ""
Apr 30 15:01:14.143: INFO: stdout: "2019-04-30T15:01:12.535175327Z 1:M 30 Apr 15:01:12.535 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Apr 30 15:01:16.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 log redis-master-nv9t4 redis-master --namespace=kubectl-1177 --since=1s'
Apr 30 15:01:16.750: INFO: stderr: ""
Apr 30 15:01:16.750: INFO: stdout: ""
Apr 30 15:01:16.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 log redis-master-nv9t4 redis-master --namespace=kubectl-1177 --since=24h'
Apr 30 15:01:16.855: INFO: stderr: ""
Apr 30 15:01:16.855: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 30 Apr 15:01:12.534 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 30 Apr 15:01:12.535 # Server started, Redis version 3.2.12\n1:M 30 Apr 15:01:12.535 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 30 Apr 15:01:12.535 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1196
STEP: using delete to clean up resources
Apr 30 15:01:16.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 delete --grace-period=0 --force -f - --namespace=kubectl-1177'
Apr 30 15:01:16.959: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 30 15:01:16.959: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Apr 30 15:01:16.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get rc,svc -l name=nginx --no-headers --namespace=kubectl-1177'
Apr 30 15:01:17.065: INFO: stderr: "No resources found.\n"
Apr 30 15:01:17.065: INFO: stdout: ""
Apr 30 15:01:17.065: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 get pods -l name=nginx --namespace=kubectl-1177 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 30 15:01:17.172: INFO: stderr: ""
Apr 30 15:01:17.172: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:01:17.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1177" for this suite.
Apr 30 15:01:23.203: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:01:23.285: INFO: namespace kubectl-1177 deletion completed in 6.104237218s

• [SLOW TEST:12.892 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:01:23.290: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test hostPath mode
Apr 30 15:01:23.326: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-8348" to be "success or failure"
Apr 30 15:01:23.335: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 8.122802ms
Apr 30 15:01:25.351: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02390586s
Apr 30 15:01:27.355: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028114996s
STEP: Saw pod success
Apr 30 15:01:27.355: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Apr 30 15:01:27.358: INFO: Trying to get logs from node fatih-test-default-pool-qlp0 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Apr 30 15:01:27.389: INFO: Waiting for pod pod-host-path-test to disappear
Apr 30 15:01:27.395: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:01:27.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-8348" for this suite.
Apr 30 15:01:33.411: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:01:33.488: INFO: namespace hostpath-8348 deletion completed in 6.089473039s

• [SLOW TEST:10.199 seconds]
[sig-storage] HostPath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:01:33.493: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0430 15:02:03.583662      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 30 15:02:03.583: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:02:03.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8744" for this suite.
Apr 30 15:02:09.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:02:09.683: INFO: namespace gc-8744 deletion completed in 6.095826101s

• [SLOW TEST:36.191 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:02:09.691: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0430 15:02:21.306409      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 30 15:02:21.306: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:02:21.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9269" for this suite.
Apr 30 15:02:27.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:02:27.471: INFO: namespace gc-9269 deletion completed in 6.155533415s

• [SLOW TEST:17.781 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:02:27.472: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Apr 30 15:02:32.099: INFO: Successfully updated pod "pod-update-f81db2d2-6b58-11e9-b570-225b9ad5bed0"
STEP: verifying the updated pod is in kubernetes
Apr 30 15:02:32.108: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:02:32.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2468" for this suite.
Apr 30 15:02:54.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:02:54.208: INFO: namespace pods-2468 deletion completed in 22.096895696s

• [SLOW TEST:26.736 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:02:54.214: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:02:54.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7471" for this suite.
Apr 30 15:03:00.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:03:00.340: INFO: namespace services-7471 deletion completed in 6.092033943s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:6.127 seconds]
[sig-network] Services
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:03:00.345: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 30 15:03:00.375: INFO: Creating deployment "test-recreate-deployment"
Apr 30 15:03:00.379: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Apr 30 15:03:00.396: INFO: Waiting deployment "test-recreate-deployment" to complete
Apr 30 15:03:00.434: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692233380, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692233380, loc:(*time.Location)(0x8a060e0)}}, Reason:"NewReplicaSetCreated", Message:"Created new replica set \"test-recreate-deployment-7d57d5ff7c\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692233380, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692233380, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
Apr 30 15:03:02.442: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692233380, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692233380, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692233380, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692233380, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d57d5ff7c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 30 15:03:04.439: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692233380, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692233380, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692233380, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692233380, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d57d5ff7c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 30 15:03:06.438: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Apr 30 15:03:06.447: INFO: Updating deployment test-recreate-deployment
Apr 30 15:03:06.447: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr 30 15:03:06.544: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-4257,SelfLink:/apis/apps/v1/namespaces/deployment-4257/deployments/test-recreate-deployment,UID:0bac5453-6b59-11e9-a241-32cef6bf8510,ResourceVersion:20128,Generation:2,CreationTimestamp:2019-04-30 15:03:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-04-30 15:03:06 +0000 UTC 2019-04-30 15:03:06 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-04-30 15:03:06 +0000 UTC 2019-04-30 15:03:00 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-c9cbd8684" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Apr 30 15:03:06.554: INFO: New ReplicaSet "test-recreate-deployment-c9cbd8684" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-c9cbd8684,GenerateName:,Namespace:deployment-4257,SelfLink:/apis/apps/v1/namespaces/deployment-4257/replicasets/test-recreate-deployment-c9cbd8684,UID:0f52f802-6b59-11e9-a241-32cef6bf8510,ResourceVersion:20127,Generation:1,CreationTimestamp:2019-04-30 15:03:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 0bac5453-6b59-11e9-a241-32cef6bf8510 0xc002077a60 0xc002077a61}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 30 15:03:06.554: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Apr 30 15:03:06.554: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7d57d5ff7c,GenerateName:,Namespace:deployment-4257,SelfLink:/apis/apps/v1/namespaces/deployment-4257/replicasets/test-recreate-deployment-7d57d5ff7c,UID:0bacc90e-6b59-11e9-a241-32cef6bf8510,ResourceVersion:20117,Generation:2,CreationTimestamp:2019-04-30 15:03:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 0bac5453-6b59-11e9-a241-32cef6bf8510 0xc002077807 0xc002077808}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 30 15:03:06.556: INFO: Pod "test-recreate-deployment-c9cbd8684-qwk85" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-c9cbd8684-qwk85,GenerateName:test-recreate-deployment-c9cbd8684-,Namespace:deployment-4257,SelfLink:/api/v1/namespaces/deployment-4257/pods/test-recreate-deployment-c9cbd8684-qwk85,UID:0f53ce50-6b59-11e9-a241-32cef6bf8510,ResourceVersion:20129,Generation:0,CreationTimestamp:2019-04-30 15:03:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-c9cbd8684 0f52f802-6b59-11e9-a241-32cef6bf8510 0xc001f22c50 0xc001f22c51}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-fnr5v {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fnr5v,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fnr5v true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:fatih-test-default-pool-qlp0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001f22d10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001f22d80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 15:03:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 15:03:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 15:03:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 15:03:06 +0000 UTC  }],Message:,Reason:,HostIP:10.136.184.227,PodIP:,StartTime:2019-04-30 15:03:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:03:06.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4257" for this suite.
Apr 30 15:03:12.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:03:12.865: INFO: namespace deployment-4257 deletion completed in 6.305247283s

• [SLOW TEST:12.520 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:03:12.865: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0430 15:03:13.499517      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 30 15:03:13.499: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:03:13.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5370" for this suite.
Apr 30 15:03:19.514: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:03:19.590: INFO: namespace gc-5370 deletion completed in 6.087209576s

• [SLOW TEST:6.725 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:03:19.594: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting the proxy server
Apr 30 15:03:19.631: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-566523788 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:03:19.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9215" for this suite.
Apr 30 15:03:25.738: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:03:25.918: INFO: namespace kubectl-9215 deletion completed in 6.189072284s

• [SLOW TEST:6.325 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:03:25.925: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 30 15:03:25.996: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1af13c08-6b59-11e9-b570-225b9ad5bed0" in namespace "downward-api-6876" to be "success or failure"
Apr 30 15:03:26.009: INFO: Pod "downwardapi-volume-1af13c08-6b59-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 12.58518ms
Apr 30 15:03:28.171: INFO: Pod "downwardapi-volume-1af13c08-6b59-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.174364408s
Apr 30 15:03:30.176: INFO: Pod "downwardapi-volume-1af13c08-6b59-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.178846047s
STEP: Saw pod success
Apr 30 15:03:30.176: INFO: Pod "downwardapi-volume-1af13c08-6b59-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 15:03:30.178: INFO: Trying to get logs from node fatih-test-default-pool-qlp0 pod downwardapi-volume-1af13c08-6b59-11e9-b570-225b9ad5bed0 container client-container: <nil>
STEP: delete the pod
Apr 30 15:03:30.198: INFO: Waiting for pod downwardapi-volume-1af13c08-6b59-11e9-b570-225b9ad5bed0 to disappear
Apr 30 15:03:30.202: INFO: Pod downwardapi-volume-1af13c08-6b59-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:03:30.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6876" for this suite.
Apr 30 15:03:36.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:03:36.288: INFO: namespace downward-api-6876 deletion completed in 6.083783041s

• [SLOW TEST:10.364 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:03:36.293: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-4904
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 30 15:03:36.323: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr 30 15:04:00.402: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.0.18:8080/dial?request=hostName&protocol=udp&host=10.244.1.100&port=8081&tries=1'] Namespace:pod-network-test-4904 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 30 15:04:00.402: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
Apr 30 15:04:00.609: INFO: Waiting for endpoints: map[]
Apr 30 15:04:00.614: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.0.18:8080/dial?request=hostName&protocol=udp&host=10.244.0.168&port=8081&tries=1'] Namespace:pod-network-test-4904 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 30 15:04:00.614: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
Apr 30 15:04:00.839: INFO: Waiting for endpoints: map[]
Apr 30 15:04:00.843: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.0.18:8080/dial?request=hostName&protocol=udp&host=10.244.2.184&port=8081&tries=1'] Namespace:pod-network-test-4904 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 30 15:04:00.844: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
Apr 30 15:04:01.050: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:04:01.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4904" for this suite.
Apr 30 15:04:17.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:04:17.141: INFO: namespace pod-network-test-4904 deletion completed in 16.087219458s

• [SLOW TEST:40.849 seconds]
[sig-network] Networking
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:04:17.146: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 30 15:04:17.197: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3976a2a8-6b59-11e9-b570-225b9ad5bed0" in namespace "projected-1124" to be "success or failure"
Apr 30 15:04:17.215: INFO: Pod "downwardapi-volume-3976a2a8-6b59-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 17.279266ms
Apr 30 15:04:19.218: INFO: Pod "downwardapi-volume-3976a2a8-6b59-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020905706s
Apr 30 15:04:21.223: INFO: Pod "downwardapi-volume-3976a2a8-6b59-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025692566s
STEP: Saw pod success
Apr 30 15:04:21.223: INFO: Pod "downwardapi-volume-3976a2a8-6b59-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 15:04:21.226: INFO: Trying to get logs from node fatih-test-default-pool-qlp0 pod downwardapi-volume-3976a2a8-6b59-11e9-b570-225b9ad5bed0 container client-container: <nil>
STEP: delete the pod
Apr 30 15:04:21.245: INFO: Waiting for pod downwardapi-volume-3976a2a8-6b59-11e9-b570-225b9ad5bed0 to disappear
Apr 30 15:04:21.248: INFO: Pod downwardapi-volume-3976a2a8-6b59-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:04:21.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1124" for this suite.
Apr 30 15:04:27.262: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:04:27.340: INFO: namespace projected-1124 deletion completed in 6.089483641s

• [SLOW TEST:10.195 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:04:27.344: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-jvf4p in namespace proxy-7086
I0430 15:04:27.481735      15 runners.go:184] Created replication controller with name: proxy-service-jvf4p, namespace: proxy-7086, replica count: 1
I0430 15:04:28.532328      15 runners.go:184] proxy-service-jvf4p Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0430 15:04:29.532475      15 runners.go:184] proxy-service-jvf4p Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0430 15:04:30.532685      15 runners.go:184] proxy-service-jvf4p Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0430 15:04:31.532927      15 runners.go:184] proxy-service-jvf4p Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0430 15:04:32.533115      15 runners.go:184] proxy-service-jvf4p Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0430 15:04:33.533341      15 runners.go:184] proxy-service-jvf4p Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 30 15:04:33.537: INFO: setup took 6.100378998s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Apr 30 15:04:33.555: INFO: (0) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:160/proxy/: foo (200; 17.649355ms)
Apr 30 15:04:33.555: INFO: (0) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n/proxy/rewriteme">test</a> (200; 18.577038ms)
Apr 30 15:04:33.556: INFO: (0) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:1080/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:1080/proxy/rewriteme">test<... (200; 18.460147ms)
Apr 30 15:04:33.559: INFO: (0) /api/v1/namespaces/proxy-7086/services/http:proxy-service-jvf4p:portname1/proxy/: foo (200; 20.302941ms)
Apr 30 15:04:33.559: INFO: (0) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:162/proxy/: bar (200; 21.146134ms)
Apr 30 15:04:33.559: INFO: (0) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:160/proxy/: foo (200; 22.045084ms)
Apr 30 15:04:33.560: INFO: (0) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:1080/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:1080/proxy/rewriteme">... (200; 21.48402ms)
Apr 30 15:04:33.580: INFO: (0) /api/v1/namespaces/proxy-7086/services/proxy-service-jvf4p:portname1/proxy/: foo (200; 42.740623ms)
Apr 30 15:04:33.582: INFO: (0) /api/v1/namespaces/proxy-7086/services/proxy-service-jvf4p:portname2/proxy/: bar (200; 44.045492ms)
Apr 30 15:04:33.583: INFO: (0) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:162/proxy/: bar (200; 44.496338ms)
Apr 30 15:04:33.583: INFO: (0) /api/v1/namespaces/proxy-7086/services/http:proxy-service-jvf4p:portname2/proxy/: bar (200; 44.416144ms)
Apr 30 15:04:33.584: INFO: (0) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:462/proxy/: tls qux (200; 46.111639ms)
Apr 30 15:04:33.584: INFO: (0) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:443/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:443/proxy/tlsrewritem... (200; 46.098937ms)
Apr 30 15:04:33.585: INFO: (0) /api/v1/namespaces/proxy-7086/services/https:proxy-service-jvf4p:tlsportname1/proxy/: tls baz (200; 47.211192ms)
Apr 30 15:04:33.585: INFO: (0) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:460/proxy/: tls baz (200; 47.628326ms)
Apr 30 15:04:33.586: INFO: (0) /api/v1/namespaces/proxy-7086/services/https:proxy-service-jvf4p:tlsportname2/proxy/: tls qux (200; 47.363196ms)
Apr 30 15:04:33.598: INFO: (1) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:160/proxy/: foo (200; 11.841484ms)
Apr 30 15:04:33.598: INFO: (1) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:460/proxy/: tls baz (200; 11.568202ms)
Apr 30 15:04:33.599: INFO: (1) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:160/proxy/: foo (200; 12.677921ms)
Apr 30 15:04:33.600: INFO: (1) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:462/proxy/: tls qux (200; 13.997109ms)
Apr 30 15:04:33.601: INFO: (1) /api/v1/namespaces/proxy-7086/services/http:proxy-service-jvf4p:portname1/proxy/: foo (200; 14.758563ms)
Apr 30 15:04:33.601: INFO: (1) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:162/proxy/: bar (200; 13.967806ms)
Apr 30 15:04:33.601: INFO: (1) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:162/proxy/: bar (200; 14.090941ms)
Apr 30 15:04:33.601: INFO: (1) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:1080/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:1080/proxy/rewriteme">test<... (200; 14.280471ms)
Apr 30 15:04:33.602: INFO: (1) /api/v1/namespaces/proxy-7086/services/proxy-service-jvf4p:portname1/proxy/: foo (200; 14.94211ms)
Apr 30 15:04:33.604: INFO: (1) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:1080/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:1080/proxy/rewriteme">... (200; 16.674098ms)
Apr 30 15:04:33.604: INFO: (1) /api/v1/namespaces/proxy-7086/services/https:proxy-service-jvf4p:tlsportname1/proxy/: tls baz (200; 17.714822ms)
Apr 30 15:04:33.605: INFO: (1) /api/v1/namespaces/proxy-7086/services/https:proxy-service-jvf4p:tlsportname2/proxy/: tls qux (200; 17.590284ms)
Apr 30 15:04:33.605: INFO: (1) /api/v1/namespaces/proxy-7086/services/http:proxy-service-jvf4p:portname2/proxy/: bar (200; 17.201052ms)
Apr 30 15:04:33.605: INFO: (1) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:443/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:443/proxy/tlsrewritem... (200; 17.862361ms)
Apr 30 15:04:33.605: INFO: (1) /api/v1/namespaces/proxy-7086/services/proxy-service-jvf4p:portname2/proxy/: bar (200; 18.148599ms)
Apr 30 15:04:33.605: INFO: (1) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n/proxy/rewriteme">test</a> (200; 17.90045ms)
Apr 30 15:04:33.612: INFO: (2) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:443/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:443/proxy/tlsrewritem... (200; 6.545575ms)
Apr 30 15:04:33.621: INFO: (2) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:1080/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:1080/proxy/rewriteme">... (200; 14.368336ms)
Apr 30 15:04:33.626: INFO: (2) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:160/proxy/: foo (200; 20.198327ms)
Apr 30 15:04:33.627: INFO: (2) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:462/proxy/: tls qux (200; 20.513454ms)
Apr 30 15:04:33.627: INFO: (2) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n/proxy/rewriteme">test</a> (200; 20.995929ms)
Apr 30 15:04:33.627: INFO: (2) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:460/proxy/: tls baz (200; 20.765856ms)
Apr 30 15:04:33.628: INFO: (2) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:162/proxy/: bar (200; 21.274302ms)
Apr 30 15:04:33.628: INFO: (2) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:162/proxy/: bar (200; 21.246579ms)
Apr 30 15:04:33.628: INFO: (2) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:1080/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:1080/proxy/rewriteme">test<... (200; 21.769511ms)
Apr 30 15:04:33.628: INFO: (2) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:160/proxy/: foo (200; 22.260193ms)
Apr 30 15:04:33.637: INFO: (2) /api/v1/namespaces/proxy-7086/services/http:proxy-service-jvf4p:portname2/proxy/: bar (200; 31.029225ms)
Apr 30 15:04:33.638: INFO: (2) /api/v1/namespaces/proxy-7086/services/http:proxy-service-jvf4p:portname1/proxy/: foo (200; 31.909076ms)
Apr 30 15:04:33.638: INFO: (2) /api/v1/namespaces/proxy-7086/services/https:proxy-service-jvf4p:tlsportname1/proxy/: tls baz (200; 31.573316ms)
Apr 30 15:04:33.638: INFO: (2) /api/v1/namespaces/proxy-7086/services/https:proxy-service-jvf4p:tlsportname2/proxy/: tls qux (200; 31.303675ms)
Apr 30 15:04:33.638: INFO: (2) /api/v1/namespaces/proxy-7086/services/proxy-service-jvf4p:portname1/proxy/: foo (200; 32.031591ms)
Apr 30 15:04:33.638: INFO: (2) /api/v1/namespaces/proxy-7086/services/proxy-service-jvf4p:portname2/proxy/: bar (200; 31.773735ms)
Apr 30 15:04:33.654: INFO: (3) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:443/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:443/proxy/tlsrewritem... (200; 15.007222ms)
Apr 30 15:04:33.655: INFO: (3) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n/proxy/rewriteme">test</a> (200; 15.336866ms)
Apr 30 15:04:33.655: INFO: (3) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:1080/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:1080/proxy/rewriteme">... (200; 15.979558ms)
Apr 30 15:04:33.655: INFO: (3) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:462/proxy/: tls qux (200; 15.360981ms)
Apr 30 15:04:33.656: INFO: (3) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:160/proxy/: foo (200; 15.628651ms)
Apr 30 15:04:33.656: INFO: (3) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:162/proxy/: bar (200; 17.154974ms)
Apr 30 15:04:33.656: INFO: (3) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:1080/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:1080/proxy/rewriteme">test<... (200; 15.862374ms)
Apr 30 15:04:33.657: INFO: (3) /api/v1/namespaces/proxy-7086/services/https:proxy-service-jvf4p:tlsportname2/proxy/: tls qux (200; 16.987886ms)
Apr 30 15:04:33.657: INFO: (3) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:160/proxy/: foo (200; 18.424785ms)
Apr 30 15:04:33.657: INFO: (3) /api/v1/namespaces/proxy-7086/services/https:proxy-service-jvf4p:tlsportname1/proxy/: tls baz (200; 17.947575ms)
Apr 30 15:04:33.658: INFO: (3) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:162/proxy/: bar (200; 18.737836ms)
Apr 30 15:04:33.658: INFO: (3) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:460/proxy/: tls baz (200; 19.02603ms)
Apr 30 15:04:33.658: INFO: (3) /api/v1/namespaces/proxy-7086/services/proxy-service-jvf4p:portname2/proxy/: bar (200; 18.746556ms)
Apr 30 15:04:33.659: INFO: (3) /api/v1/namespaces/proxy-7086/services/http:proxy-service-jvf4p:portname1/proxy/: foo (200; 18.769357ms)
Apr 30 15:04:33.659: INFO: (3) /api/v1/namespaces/proxy-7086/services/proxy-service-jvf4p:portname1/proxy/: foo (200; 19.666102ms)
Apr 30 15:04:33.659: INFO: (3) /api/v1/namespaces/proxy-7086/services/http:proxy-service-jvf4p:portname2/proxy/: bar (200; 18.880047ms)
Apr 30 15:04:33.668: INFO: (4) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:460/proxy/: tls baz (200; 9.013542ms)
Apr 30 15:04:33.670: INFO: (4) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:443/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:443/proxy/tlsrewritem... (200; 10.390428ms)
Apr 30 15:04:33.670: INFO: (4) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:1080/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:1080/proxy/rewriteme">... (200; 10.894138ms)
Apr 30 15:04:33.674: INFO: (4) /api/v1/namespaces/proxy-7086/services/proxy-service-jvf4p:portname2/proxy/: bar (200; 15.163809ms)
Apr 30 15:04:33.675: INFO: (4) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:1080/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:1080/proxy/rewriteme">test<... (200; 14.626679ms)
Apr 30 15:04:33.675: INFO: (4) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:160/proxy/: foo (200; 14.59872ms)
Apr 30 15:04:33.676: INFO: (4) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n/proxy/rewriteme">test</a> (200; 15.622781ms)
Apr 30 15:04:33.676: INFO: (4) /api/v1/namespaces/proxy-7086/services/http:proxy-service-jvf4p:portname1/proxy/: foo (200; 16.187181ms)
Apr 30 15:04:33.676: INFO: (4) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:162/proxy/: bar (200; 15.396669ms)
Apr 30 15:04:33.677: INFO: (4) /api/v1/namespaces/proxy-7086/services/https:proxy-service-jvf4p:tlsportname2/proxy/: tls qux (200; 17.467685ms)
Apr 30 15:04:33.677: INFO: (4) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:462/proxy/: tls qux (200; 16.633136ms)
Apr 30 15:04:33.677: INFO: (4) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:162/proxy/: bar (200; 16.593452ms)
Apr 30 15:04:33.678: INFO: (4) /api/v1/namespaces/proxy-7086/services/proxy-service-jvf4p:portname1/proxy/: foo (200; 17.604487ms)
Apr 30 15:04:33.678: INFO: (4) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:160/proxy/: foo (200; 17.841479ms)
Apr 30 15:04:33.678: INFO: (4) /api/v1/namespaces/proxy-7086/services/https:proxy-service-jvf4p:tlsportname1/proxy/: tls baz (200; 17.62497ms)
Apr 30 15:04:33.678: INFO: (4) /api/v1/namespaces/proxy-7086/services/http:proxy-service-jvf4p:portname2/proxy/: bar (200; 18.599198ms)
Apr 30 15:04:33.688: INFO: (5) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:162/proxy/: bar (200; 9.117327ms)
Apr 30 15:04:33.689: INFO: (5) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:1080/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:1080/proxy/rewriteme">test<... (200; 10.131927ms)
Apr 30 15:04:33.689: INFO: (5) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:460/proxy/: tls baz (200; 9.712869ms)
Apr 30 15:04:33.689: INFO: (5) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:162/proxy/: bar (200; 10.1118ms)
Apr 30 15:04:33.693: INFO: (5) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:462/proxy/: tls qux (200; 11.871437ms)
Apr 30 15:04:33.694: INFO: (5) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n/proxy/rewriteme">test</a> (200; 13.773099ms)
Apr 30 15:04:33.694: INFO: (5) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:160/proxy/: foo (200; 13.299275ms)
Apr 30 15:04:33.694: INFO: (5) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:160/proxy/: foo (200; 13.624313ms)
Apr 30 15:04:33.694: INFO: (5) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:1080/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:1080/proxy/rewriteme">... (200; 14.86011ms)
Apr 30 15:04:33.695: INFO: (5) /api/v1/namespaces/proxy-7086/services/http:proxy-service-jvf4p:portname2/proxy/: bar (200; 15.025489ms)
Apr 30 15:04:33.695: INFO: (5) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:443/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:443/proxy/tlsrewritem... (200; 15.858791ms)
Apr 30 15:04:33.696: INFO: (5) /api/v1/namespaces/proxy-7086/services/https:proxy-service-jvf4p:tlsportname1/proxy/: tls baz (200; 16.93136ms)
Apr 30 15:04:33.696: INFO: (5) /api/v1/namespaces/proxy-7086/services/https:proxy-service-jvf4p:tlsportname2/proxy/: tls qux (200; 16.872574ms)
Apr 30 15:04:33.696: INFO: (5) /api/v1/namespaces/proxy-7086/services/proxy-service-jvf4p:portname1/proxy/: foo (200; 17.26163ms)
Apr 30 15:04:33.697: INFO: (5) /api/v1/namespaces/proxy-7086/services/proxy-service-jvf4p:portname2/proxy/: bar (200; 17.021935ms)
Apr 30 15:04:33.697: INFO: (5) /api/v1/namespaces/proxy-7086/services/http:proxy-service-jvf4p:portname1/proxy/: foo (200; 16.867112ms)
Apr 30 15:04:33.707: INFO: (6) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:462/proxy/: tls qux (200; 9.562974ms)
Apr 30 15:04:33.709: INFO: (6) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:460/proxy/: tls baz (200; 11.509923ms)
Apr 30 15:04:33.709: INFO: (6) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:160/proxy/: foo (200; 12.051812ms)
Apr 30 15:04:33.710: INFO: (6) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:1080/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:1080/proxy/rewriteme">test<... (200; 12.295726ms)
Apr 30 15:04:33.710: INFO: (6) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:162/proxy/: bar (200; 12.202932ms)
Apr 30 15:04:33.710: INFO: (6) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n/proxy/rewriteme">test</a> (200; 12.987658ms)
Apr 30 15:04:33.710: INFO: (6) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:160/proxy/: foo (200; 12.723132ms)
Apr 30 15:04:33.712: INFO: (6) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:162/proxy/: bar (200; 14.079341ms)
Apr 30 15:04:33.713: INFO: (6) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:443/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:443/proxy/tlsrewritem... (200; 14.473424ms)
Apr 30 15:04:33.713: INFO: (6) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:1080/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:1080/proxy/rewriteme">... (200; 14.398824ms)
Apr 30 15:04:33.714: INFO: (6) /api/v1/namespaces/proxy-7086/services/http:proxy-service-jvf4p:portname2/proxy/: bar (200; 15.350015ms)
Apr 30 15:04:33.714: INFO: (6) /api/v1/namespaces/proxy-7086/services/https:proxy-service-jvf4p:tlsportname1/proxy/: tls baz (200; 16.424022ms)
Apr 30 15:04:33.715: INFO: (6) /api/v1/namespaces/proxy-7086/services/proxy-service-jvf4p:portname2/proxy/: bar (200; 16.338823ms)
Apr 30 15:04:33.715: INFO: (6) /api/v1/namespaces/proxy-7086/services/http:proxy-service-jvf4p:portname1/proxy/: foo (200; 16.525366ms)
Apr 30 15:04:33.715: INFO: (6) /api/v1/namespaces/proxy-7086/services/https:proxy-service-jvf4p:tlsportname2/proxy/: tls qux (200; 16.88756ms)
Apr 30 15:04:33.715: INFO: (6) /api/v1/namespaces/proxy-7086/services/proxy-service-jvf4p:portname1/proxy/: foo (200; 17.627203ms)
Apr 30 15:04:33.726: INFO: (7) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:160/proxy/: foo (200; 10.583378ms)
Apr 30 15:04:33.727: INFO: (7) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:160/proxy/: foo (200; 11.133426ms)
Apr 30 15:04:33.728: INFO: (7) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:1080/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:1080/proxy/rewriteme">... (200; 10.746398ms)
Apr 30 15:04:33.728: INFO: (7) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n/proxy/rewriteme">test</a> (200; 10.54295ms)
Apr 30 15:04:33.728: INFO: (7) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:162/proxy/: bar (200; 11.771135ms)
Apr 30 15:04:33.728: INFO: (7) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:1080/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:1080/proxy/rewriteme">test<... (200; 11.958143ms)
Apr 30 15:04:33.730: INFO: (7) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:460/proxy/: tls baz (200; 13.210992ms)
Apr 30 15:04:33.730: INFO: (7) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:443/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:443/proxy/tlsrewritem... (200; 12.779479ms)
Apr 30 15:04:33.730: INFO: (7) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:462/proxy/: tls qux (200; 13.746166ms)
Apr 30 15:04:33.731: INFO: (7) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:162/proxy/: bar (200; 14.576106ms)
Apr 30 15:04:33.731: INFO: (7) /api/v1/namespaces/proxy-7086/services/http:proxy-service-jvf4p:portname1/proxy/: foo (200; 15.412074ms)
Apr 30 15:04:33.732: INFO: (7) /api/v1/namespaces/proxy-7086/services/proxy-service-jvf4p:portname2/proxy/: bar (200; 14.949813ms)
Apr 30 15:04:33.733: INFO: (7) /api/v1/namespaces/proxy-7086/services/proxy-service-jvf4p:portname1/proxy/: foo (200; 16.022219ms)
Apr 30 15:04:33.733: INFO: (7) /api/v1/namespaces/proxy-7086/services/http:proxy-service-jvf4p:portname2/proxy/: bar (200; 15.847126ms)
Apr 30 15:04:33.734: INFO: (7) /api/v1/namespaces/proxy-7086/services/https:proxy-service-jvf4p:tlsportname1/proxy/: tls baz (200; 17.486671ms)
Apr 30 15:04:33.734: INFO: (7) /api/v1/namespaces/proxy-7086/services/https:proxy-service-jvf4p:tlsportname2/proxy/: tls qux (200; 17.207195ms)
Apr 30 15:04:33.744: INFO: (8) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:443/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:443/proxy/tlsrewritem... (200; 10.15256ms)
Apr 30 15:04:33.753: INFO: (8) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:162/proxy/: bar (200; 17.658953ms)
Apr 30 15:04:33.754: INFO: (8) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:160/proxy/: foo (200; 18.602778ms)
Apr 30 15:04:33.754: INFO: (8) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:1080/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:1080/proxy/rewriteme">test<... (200; 18.779179ms)
Apr 30 15:04:33.754: INFO: (8) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:462/proxy/: tls qux (200; 18.606555ms)
Apr 30 15:04:33.754: INFO: (8) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:162/proxy/: bar (200; 18.466239ms)
Apr 30 15:04:33.754: INFO: (8) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:160/proxy/: foo (200; 18.797282ms)
Apr 30 15:04:33.754: INFO: (8) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n/proxy/rewriteme">test</a> (200; 19.138599ms)
Apr 30 15:04:33.754: INFO: (8) /api/v1/namespaces/proxy-7086/services/http:proxy-service-jvf4p:portname2/proxy/: bar (200; 19.396487ms)
Apr 30 15:04:33.756: INFO: (8) /api/v1/namespaces/proxy-7086/services/http:proxy-service-jvf4p:portname1/proxy/: foo (200; 21.141279ms)
Apr 30 15:04:33.756: INFO: (8) /api/v1/namespaces/proxy-7086/services/https:proxy-service-jvf4p:tlsportname2/proxy/: tls qux (200; 20.003862ms)
Apr 30 15:04:33.756: INFO: (8) /api/v1/namespaces/proxy-7086/services/https:proxy-service-jvf4p:tlsportname1/proxy/: tls baz (200; 20.661078ms)
Apr 30 15:04:33.756: INFO: (8) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:460/proxy/: tls baz (200; 20.524623ms)
Apr 30 15:04:33.756: INFO: (8) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:1080/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:1080/proxy/rewriteme">... (200; 20.348301ms)
Apr 30 15:04:33.756: INFO: (8) /api/v1/namespaces/proxy-7086/services/proxy-service-jvf4p:portname1/proxy/: foo (200; 21.19477ms)
Apr 30 15:04:33.757: INFO: (8) /api/v1/namespaces/proxy-7086/services/proxy-service-jvf4p:portname2/proxy/: bar (200; 20.880797ms)
Apr 30 15:04:33.766: INFO: (9) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:162/proxy/: bar (200; 9.376729ms)
Apr 30 15:04:33.767: INFO: (9) /api/v1/namespaces/proxy-7086/services/proxy-service-jvf4p:portname2/proxy/: bar (200; 10.449896ms)
Apr 30 15:04:33.770: INFO: (9) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:1080/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:1080/proxy/rewriteme">... (200; 12.414482ms)
Apr 30 15:04:33.771: INFO: (9) /api/v1/namespaces/proxy-7086/services/https:proxy-service-jvf4p:tlsportname2/proxy/: tls qux (200; 13.858644ms)
Apr 30 15:04:33.771: INFO: (9) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n/proxy/rewriteme">test</a> (200; 12.448936ms)
Apr 30 15:04:33.771: INFO: (9) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:1080/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:1080/proxy/rewriteme">test<... (200; 12.378699ms)
Apr 30 15:04:33.772: INFO: (9) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:443/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:443/proxy/tlsrewritem... (200; 13.838505ms)
Apr 30 15:04:33.773: INFO: (9) /api/v1/namespaces/proxy-7086/services/http:proxy-service-jvf4p:portname2/proxy/: bar (200; 14.338104ms)
Apr 30 15:04:33.773: INFO: (9) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:462/proxy/: tls qux (200; 13.950799ms)
Apr 30 15:04:33.773: INFO: (9) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:160/proxy/: foo (200; 14.29785ms)
Apr 30 15:04:33.773: INFO: (9) /api/v1/namespaces/proxy-7086/services/http:proxy-service-jvf4p:portname1/proxy/: foo (200; 15.033397ms)
Apr 30 15:04:33.774: INFO: (9) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:162/proxy/: bar (200; 14.228246ms)
Apr 30 15:04:33.774: INFO: (9) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:460/proxy/: tls baz (200; 14.942168ms)
Apr 30 15:04:33.774: INFO: (9) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:160/proxy/: foo (200; 15.641174ms)
Apr 30 15:04:33.775: INFO: (9) /api/v1/namespaces/proxy-7086/services/proxy-service-jvf4p:portname1/proxy/: foo (200; 15.394642ms)
Apr 30 15:04:33.775: INFO: (9) /api/v1/namespaces/proxy-7086/services/https:proxy-service-jvf4p:tlsportname1/proxy/: tls baz (200; 15.546214ms)
Apr 30 15:04:33.784: INFO: (10) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:443/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:443/proxy/tlsrewritem... (200; 8.653468ms)
Apr 30 15:04:33.784: INFO: (10) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n/proxy/rewriteme">test</a> (200; 8.662633ms)
Apr 30 15:04:33.784: INFO: (10) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:1080/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:1080/proxy/rewriteme">test<... (200; 8.67843ms)
Apr 30 15:04:33.790: INFO: (10) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:160/proxy/: foo (200; 14.309072ms)
Apr 30 15:04:33.791: INFO: (10) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:462/proxy/: tls qux (200; 14.935479ms)
Apr 30 15:04:33.791: INFO: (10) /api/v1/namespaces/proxy-7086/services/http:proxy-service-jvf4p:portname1/proxy/: foo (200; 16.170746ms)
Apr 30 15:04:33.792: INFO: (10) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:460/proxy/: tls baz (200; 15.625954ms)
Apr 30 15:04:33.792: INFO: (10) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:162/proxy/: bar (200; 15.38939ms)
Apr 30 15:04:33.792: INFO: (10) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:162/proxy/: bar (200; 15.756838ms)
Apr 30 15:04:33.792: INFO: (10) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:1080/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:1080/proxy/rewriteme">... (200; 15.311391ms)
Apr 30 15:04:33.792: INFO: (10) /api/v1/namespaces/proxy-7086/services/proxy-service-jvf4p:portname1/proxy/: foo (200; 16.11929ms)
Apr 30 15:04:33.792: INFO: (10) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:160/proxy/: foo (200; 16.494254ms)
Apr 30 15:04:33.793: INFO: (10) /api/v1/namespaces/proxy-7086/services/proxy-service-jvf4p:portname2/proxy/: bar (200; 16.461898ms)
Apr 30 15:04:33.793: INFO: (10) /api/v1/namespaces/proxy-7086/services/https:proxy-service-jvf4p:tlsportname1/proxy/: tls baz (200; 16.783996ms)
Apr 30 15:04:33.793: INFO: (10) /api/v1/namespaces/proxy-7086/services/https:proxy-service-jvf4p:tlsportname2/proxy/: tls qux (200; 16.425373ms)
Apr 30 15:04:33.794: INFO: (10) /api/v1/namespaces/proxy-7086/services/http:proxy-service-jvf4p:portname2/proxy/: bar (200; 18.441496ms)
Apr 30 15:04:33.802: INFO: (11) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:462/proxy/: tls qux (200; 8.215073ms)
Apr 30 15:04:33.805: INFO: (11) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:460/proxy/: tls baz (200; 10.111548ms)
Apr 30 15:04:33.806: INFO: (11) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:162/proxy/: bar (200; 11.240999ms)
Apr 30 15:04:33.806: INFO: (11) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:162/proxy/: bar (200; 11.468729ms)
Apr 30 15:04:33.808: INFO: (11) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:1080/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:1080/proxy/rewriteme">... (200; 13.106897ms)
Apr 30 15:04:33.808: INFO: (11) /api/v1/namespaces/proxy-7086/services/https:proxy-service-jvf4p:tlsportname1/proxy/: tls baz (200; 14.072599ms)
Apr 30 15:04:33.810: INFO: (11) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:1080/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:1080/proxy/rewriteme">test<... (200; 14.859126ms)
Apr 30 15:04:33.811: INFO: (11) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n/proxy/rewriteme">test</a> (200; 15.411428ms)
Apr 30 15:04:33.811: INFO: (11) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:160/proxy/: foo (200; 15.815265ms)
Apr 30 15:04:33.812: INFO: (11) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:160/proxy/: foo (200; 16.176424ms)
Apr 30 15:04:33.812: INFO: (11) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:443/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:443/proxy/tlsrewritem... (200; 16.954917ms)
Apr 30 15:04:33.812: INFO: (11) /api/v1/namespaces/proxy-7086/services/proxy-service-jvf4p:portname1/proxy/: foo (200; 17.844564ms)
Apr 30 15:04:33.813: INFO: (11) /api/v1/namespaces/proxy-7086/services/proxy-service-jvf4p:portname2/proxy/: bar (200; 17.849541ms)
Apr 30 15:04:33.813: INFO: (11) /api/v1/namespaces/proxy-7086/services/https:proxy-service-jvf4p:tlsportname2/proxy/: tls qux (200; 17.760205ms)
Apr 30 15:04:33.813: INFO: (11) /api/v1/namespaces/proxy-7086/services/http:proxy-service-jvf4p:portname1/proxy/: foo (200; 17.92963ms)
Apr 30 15:04:33.813: INFO: (11) /api/v1/namespaces/proxy-7086/services/http:proxy-service-jvf4p:portname2/proxy/: bar (200; 17.832683ms)
Apr 30 15:04:33.824: INFO: (12) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:1080/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:1080/proxy/rewriteme">... (200; 10.186313ms)
Apr 30 15:04:33.824: INFO: (12) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:462/proxy/: tls qux (200; 10.162484ms)
Apr 30 15:04:33.824: INFO: (12) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n/proxy/rewriteme">test</a> (200; 10.32028ms)
Apr 30 15:04:33.827: INFO: (12) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:1080/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:1080/proxy/rewriteme">test<... (200; 12.562531ms)
Apr 30 15:04:33.827: INFO: (12) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:160/proxy/: foo (200; 12.596603ms)
Apr 30 15:04:33.827: INFO: (12) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:460/proxy/: tls baz (200; 12.637866ms)
Apr 30 15:04:33.828: INFO: (12) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:162/proxy/: bar (200; 12.737223ms)
Apr 30 15:04:33.828: INFO: (12) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:160/proxy/: foo (200; 13.627771ms)
Apr 30 15:04:33.828: INFO: (12) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:443/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:443/proxy/tlsrewritem... (200; 13.071772ms)
Apr 30 15:04:33.829: INFO: (12) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:162/proxy/: bar (200; 13.942664ms)
Apr 30 15:04:33.831: INFO: (12) /api/v1/namespaces/proxy-7086/services/https:proxy-service-jvf4p:tlsportname1/proxy/: tls baz (200; 15.898674ms)
Apr 30 15:04:33.831: INFO: (12) /api/v1/namespaces/proxy-7086/services/https:proxy-service-jvf4p:tlsportname2/proxy/: tls qux (200; 15.902548ms)
Apr 30 15:04:33.832: INFO: (12) /api/v1/namespaces/proxy-7086/services/http:proxy-service-jvf4p:portname1/proxy/: foo (200; 18.061262ms)
Apr 30 15:04:33.832: INFO: (12) /api/v1/namespaces/proxy-7086/services/http:proxy-service-jvf4p:portname2/proxy/: bar (200; 18.349278ms)
Apr 30 15:04:33.832: INFO: (12) /api/v1/namespaces/proxy-7086/services/proxy-service-jvf4p:portname2/proxy/: bar (200; 17.05439ms)
Apr 30 15:04:33.833: INFO: (12) /api/v1/namespaces/proxy-7086/services/proxy-service-jvf4p:portname1/proxy/: foo (200; 17.654759ms)
Apr 30 15:04:33.844: INFO: (13) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n/proxy/rewriteme">test</a> (200; 11.066293ms)
Apr 30 15:04:33.844: INFO: (13) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:1080/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:1080/proxy/rewriteme">test<... (200; 11.151572ms)
Apr 30 15:04:33.844: INFO: (13) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:160/proxy/: foo (200; 11.151712ms)
Apr 30 15:04:33.844: INFO: (13) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:160/proxy/: foo (200; 11.422875ms)
Apr 30 15:04:33.845: INFO: (13) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:462/proxy/: tls qux (200; 11.396179ms)
Apr 30 15:04:33.845: INFO: (13) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:460/proxy/: tls baz (200; 11.508319ms)
Apr 30 15:04:33.846: INFO: (13) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:162/proxy/: bar (200; 12.083761ms)
Apr 30 15:04:33.847: INFO: (13) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:162/proxy/: bar (200; 12.952009ms)
Apr 30 15:04:33.847: INFO: (13) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:1080/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:1080/proxy/rewriteme">... (200; 12.890522ms)
Apr 30 15:04:33.847: INFO: (13) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:443/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:443/proxy/tlsrewritem... (200; 13.047516ms)
Apr 30 15:04:33.850: INFO: (13) /api/v1/namespaces/proxy-7086/services/proxy-service-jvf4p:portname1/proxy/: foo (200; 16.887236ms)
Apr 30 15:04:33.851: INFO: (13) /api/v1/namespaces/proxy-7086/services/http:proxy-service-jvf4p:portname1/proxy/: foo (200; 16.489171ms)
Apr 30 15:04:33.851: INFO: (13) /api/v1/namespaces/proxy-7086/services/https:proxy-service-jvf4p:tlsportname1/proxy/: tls baz (200; 17.598464ms)
Apr 30 15:04:33.851: INFO: (13) /api/v1/namespaces/proxy-7086/services/http:proxy-service-jvf4p:portname2/proxy/: bar (200; 17.027806ms)
Apr 30 15:04:33.852: INFO: (13) /api/v1/namespaces/proxy-7086/services/https:proxy-service-jvf4p:tlsportname2/proxy/: tls qux (200; 17.846429ms)
Apr 30 15:04:33.852: INFO: (13) /api/v1/namespaces/proxy-7086/services/proxy-service-jvf4p:portname2/proxy/: bar (200; 17.970015ms)
Apr 30 15:04:33.858: INFO: (14) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:162/proxy/: bar (200; 6.551486ms)
Apr 30 15:04:33.865: INFO: (14) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:160/proxy/: foo (200; 12.051718ms)
Apr 30 15:04:33.866: INFO: (14) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:443/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:443/proxy/tlsrewritem... (200; 13.848165ms)
Apr 30 15:04:33.866: INFO: (14) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:460/proxy/: tls baz (200; 13.180959ms)
Apr 30 15:04:33.866: INFO: (14) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n/proxy/rewriteme">test</a> (200; 13.653281ms)
Apr 30 15:04:33.866: INFO: (14) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:1080/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:1080/proxy/rewriteme">... (200; 13.885598ms)
Apr 30 15:04:33.866: INFO: (14) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:462/proxy/: tls qux (200; 13.639032ms)
Apr 30 15:04:33.867: INFO: (14) /api/v1/namespaces/proxy-7086/services/https:proxy-service-jvf4p:tlsportname2/proxy/: tls qux (200; 14.923031ms)
Apr 30 15:04:33.868: INFO: (14) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:160/proxy/: foo (200; 15.046966ms)
Apr 30 15:04:33.868: INFO: (14) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:1080/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:1080/proxy/rewriteme">test<... (200; 15.367149ms)
Apr 30 15:04:33.868: INFO: (14) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:162/proxy/: bar (200; 15.311061ms)
Apr 30 15:04:33.869: INFO: (14) /api/v1/namespaces/proxy-7086/services/http:proxy-service-jvf4p:portname1/proxy/: foo (200; 16.487041ms)
Apr 30 15:04:33.869: INFO: (14) /api/v1/namespaces/proxy-7086/services/https:proxy-service-jvf4p:tlsportname1/proxy/: tls baz (200; 15.888661ms)
Apr 30 15:04:33.869: INFO: (14) /api/v1/namespaces/proxy-7086/services/proxy-service-jvf4p:portname2/proxy/: bar (200; 17.218317ms)
Apr 30 15:04:33.870: INFO: (14) /api/v1/namespaces/proxy-7086/services/http:proxy-service-jvf4p:portname2/proxy/: bar (200; 17.164268ms)
Apr 30 15:04:33.870: INFO: (14) /api/v1/namespaces/proxy-7086/services/proxy-service-jvf4p:portname1/proxy/: foo (200; 16.844076ms)
Apr 30 15:04:33.876: INFO: (15) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n/proxy/rewriteme">test</a> (200; 5.863965ms)
Apr 30 15:04:33.881: INFO: (15) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:462/proxy/: tls qux (200; 11.107256ms)
Apr 30 15:04:33.882: INFO: (15) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:160/proxy/: foo (200; 11.264174ms)
Apr 30 15:04:33.882: INFO: (15) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:1080/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:1080/proxy/rewriteme">... (200; 10.597047ms)
Apr 30 15:04:33.883: INFO: (15) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:160/proxy/: foo (200; 12.139666ms)
Apr 30 15:04:33.883: INFO: (15) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:162/proxy/: bar (200; 12.262401ms)
Apr 30 15:04:33.883: INFO: (15) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:162/proxy/: bar (200; 12.190612ms)
Apr 30 15:04:33.884: INFO: (15) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:443/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:443/proxy/tlsrewritem... (200; 12.451434ms)
Apr 30 15:04:33.884: INFO: (15) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:1080/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:1080/proxy/rewriteme">test<... (200; 13.527755ms)
Apr 30 15:04:33.884: INFO: (15) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:460/proxy/: tls baz (200; 13.303904ms)
Apr 30 15:04:33.888: INFO: (15) /api/v1/namespaces/proxy-7086/services/https:proxy-service-jvf4p:tlsportname2/proxy/: tls qux (200; 16.422557ms)
Apr 30 15:04:33.888: INFO: (15) /api/v1/namespaces/proxy-7086/services/proxy-service-jvf4p:portname2/proxy/: bar (200; 17.056126ms)
Apr 30 15:04:33.889: INFO: (15) /api/v1/namespaces/proxy-7086/services/http:proxy-service-jvf4p:portname1/proxy/: foo (200; 16.898707ms)
Apr 30 15:04:33.889: INFO: (15) /api/v1/namespaces/proxy-7086/services/https:proxy-service-jvf4p:tlsportname1/proxy/: tls baz (200; 18.065848ms)
Apr 30 15:04:33.889: INFO: (15) /api/v1/namespaces/proxy-7086/services/http:proxy-service-jvf4p:portname2/proxy/: bar (200; 17.499352ms)
Apr 30 15:04:33.889: INFO: (15) /api/v1/namespaces/proxy-7086/services/proxy-service-jvf4p:portname1/proxy/: foo (200; 18.619611ms)
Apr 30 15:04:33.896: INFO: (16) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:460/proxy/: tls baz (200; 6.292897ms)
Apr 30 15:04:33.908: INFO: (16) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:160/proxy/: foo (200; 17.626439ms)
Apr 30 15:04:33.909: INFO: (16) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:1080/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:1080/proxy/rewriteme">test<... (200; 18.565396ms)
Apr 30 15:04:33.909: INFO: (16) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n/proxy/rewriteme">test</a> (200; 18.887895ms)
Apr 30 15:04:33.909: INFO: (16) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:1080/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:1080/proxy/rewriteme">... (200; 19.445075ms)
Apr 30 15:04:33.910: INFO: (16) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:162/proxy/: bar (200; 18.324979ms)
Apr 30 15:04:33.910: INFO: (16) /api/v1/namespaces/proxy-7086/services/https:proxy-service-jvf4p:tlsportname1/proxy/: tls baz (200; 19.361224ms)
Apr 30 15:04:33.911: INFO: (16) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:162/proxy/: bar (200; 19.763138ms)
Apr 30 15:04:33.911: INFO: (16) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:160/proxy/: foo (200; 20.3595ms)
Apr 30 15:04:33.911: INFO: (16) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:443/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:443/proxy/tlsrewritem... (200; 20.836805ms)
Apr 30 15:04:33.911: INFO: (16) /api/v1/namespaces/proxy-7086/services/https:proxy-service-jvf4p:tlsportname2/proxy/: tls qux (200; 21.052718ms)
Apr 30 15:04:33.911: INFO: (16) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:462/proxy/: tls qux (200; 20.460552ms)
Apr 30 15:04:33.912: INFO: (16) /api/v1/namespaces/proxy-7086/services/http:proxy-service-jvf4p:portname1/proxy/: foo (200; 21.439871ms)
Apr 30 15:04:33.912: INFO: (16) /api/v1/namespaces/proxy-7086/services/proxy-service-jvf4p:portname1/proxy/: foo (200; 21.448616ms)
Apr 30 15:04:33.912: INFO: (16) /api/v1/namespaces/proxy-7086/services/http:proxy-service-jvf4p:portname2/proxy/: bar (200; 22.149321ms)
Apr 30 15:04:33.912: INFO: (16) /api/v1/namespaces/proxy-7086/services/proxy-service-jvf4p:portname2/proxy/: bar (200; 22.646344ms)
Apr 30 15:04:33.923: INFO: (17) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:460/proxy/: tls baz (200; 9.898224ms)
Apr 30 15:04:33.923: INFO: (17) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:462/proxy/: tls qux (200; 10.864327ms)
Apr 30 15:04:33.924: INFO: (17) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:162/proxy/: bar (200; 10.502262ms)
Apr 30 15:04:33.924: INFO: (17) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:162/proxy/: bar (200; 10.756387ms)
Apr 30 15:04:33.925: INFO: (17) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:1080/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:1080/proxy/rewriteme">... (200; 11.950471ms)
Apr 30 15:04:33.926: INFO: (17) /api/v1/namespaces/proxy-7086/services/https:proxy-service-jvf4p:tlsportname1/proxy/: tls baz (200; 13.554329ms)
Apr 30 15:04:33.927: INFO: (17) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n/proxy/rewriteme">test</a> (200; 12.713584ms)
Apr 30 15:04:33.928: INFO: (17) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:160/proxy/: foo (200; 13.963887ms)
Apr 30 15:04:33.930: INFO: (17) /api/v1/namespaces/proxy-7086/services/proxy-service-jvf4p:portname1/proxy/: foo (200; 16.835375ms)
Apr 30 15:04:33.930: INFO: (17) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:443/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:443/proxy/tlsrewritem... (200; 16.295008ms)
Apr 30 15:04:33.930: INFO: (17) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:1080/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:1080/proxy/rewriteme">test<... (200; 16.160706ms)
Apr 30 15:04:33.930: INFO: (17) /api/v1/namespaces/proxy-7086/services/http:proxy-service-jvf4p:portname2/proxy/: bar (200; 16.528952ms)
Apr 30 15:04:33.931: INFO: (17) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:160/proxy/: foo (200; 16.826608ms)
Apr 30 15:04:33.931: INFO: (17) /api/v1/namespaces/proxy-7086/services/http:proxy-service-jvf4p:portname1/proxy/: foo (200; 17.620124ms)
Apr 30 15:04:33.931: INFO: (17) /api/v1/namespaces/proxy-7086/services/proxy-service-jvf4p:portname2/proxy/: bar (200; 18.22453ms)
Apr 30 15:04:33.932: INFO: (17) /api/v1/namespaces/proxy-7086/services/https:proxy-service-jvf4p:tlsportname2/proxy/: tls qux (200; 18.69569ms)
Apr 30 15:04:33.941: INFO: (18) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:1080/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:1080/proxy/rewriteme">... (200; 8.746703ms)
Apr 30 15:04:33.944: INFO: (18) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:162/proxy/: bar (200; 11.475575ms)
Apr 30 15:04:33.944: INFO: (18) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:443/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:443/proxy/tlsrewritem... (200; 11.479698ms)
Apr 30 15:04:33.948: INFO: (18) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:160/proxy/: foo (200; 14.540172ms)
Apr 30 15:04:33.949: INFO: (18) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:460/proxy/: tls baz (200; 15.344692ms)
Apr 30 15:04:33.949: INFO: (18) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:462/proxy/: tls qux (200; 15.520714ms)
Apr 30 15:04:33.949: INFO: (18) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n/proxy/rewriteme">test</a> (200; 16.016588ms)
Apr 30 15:04:33.950: INFO: (18) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:162/proxy/: bar (200; 15.60525ms)
Apr 30 15:04:33.950: INFO: (18) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:1080/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:1080/proxy/rewriteme">test<... (200; 16.358698ms)
Apr 30 15:04:33.950: INFO: (18) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:160/proxy/: foo (200; 16.272433ms)
Apr 30 15:04:33.950: INFO: (18) /api/v1/namespaces/proxy-7086/services/https:proxy-service-jvf4p:tlsportname1/proxy/: tls baz (200; 16.246367ms)
Apr 30 15:04:33.951: INFO: (18) /api/v1/namespaces/proxy-7086/services/proxy-service-jvf4p:portname1/proxy/: foo (200; 17.131234ms)
Apr 30 15:04:33.951: INFO: (18) /api/v1/namespaces/proxy-7086/services/http:proxy-service-jvf4p:portname2/proxy/: bar (200; 18.065361ms)
Apr 30 15:04:33.951: INFO: (18) /api/v1/namespaces/proxy-7086/services/https:proxy-service-jvf4p:tlsportname2/proxy/: tls qux (200; 18.640839ms)
Apr 30 15:04:33.952: INFO: (18) /api/v1/namespaces/proxy-7086/services/http:proxy-service-jvf4p:portname1/proxy/: foo (200; 18.750674ms)
Apr 30 15:04:33.952: INFO: (18) /api/v1/namespaces/proxy-7086/services/proxy-service-jvf4p:portname2/proxy/: bar (200; 19.43086ms)
Apr 30 15:04:33.965: INFO: (19) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:162/proxy/: bar (200; 12.603537ms)
Apr 30 15:04:33.965: INFO: (19) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:443/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:443/proxy/tlsrewritem... (200; 12.892845ms)
Apr 30 15:04:33.966: INFO: (19) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:460/proxy/: tls baz (200; 12.585441ms)
Apr 30 15:04:33.968: INFO: (19) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:1080/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:1080/proxy/rewriteme">... (200; 15.652905ms)
Apr 30 15:04:33.968: INFO: (19) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:160/proxy/: foo (200; 14.943844ms)
Apr 30 15:04:33.970: INFO: (19) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:160/proxy/: foo (200; 16.240902ms)
Apr 30 15:04:33.970: INFO: (19) /api/v1/namespaces/proxy-7086/pods/http:proxy-service-jvf4p-g478n:162/proxy/: bar (200; 16.260141ms)
Apr 30 15:04:33.970: INFO: (19) /api/v1/namespaces/proxy-7086/pods/https:proxy-service-jvf4p-g478n:462/proxy/: tls qux (200; 16.774114ms)
Apr 30 15:04:33.970: INFO: (19) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:1080/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n:1080/proxy/rewriteme">test<... (200; 16.680708ms)
Apr 30 15:04:33.970: INFO: (19) /api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n/proxy/: <a href="/api/v1/namespaces/proxy-7086/pods/proxy-service-jvf4p-g478n/proxy/rewriteme">test</a> (200; 17.032887ms)
Apr 30 15:04:33.971: INFO: (19) /api/v1/namespaces/proxy-7086/services/http:proxy-service-jvf4p:portname2/proxy/: bar (200; 18.177469ms)
Apr 30 15:04:33.972: INFO: (19) /api/v1/namespaces/proxy-7086/services/proxy-service-jvf4p:portname2/proxy/: bar (200; 19.200282ms)
Apr 30 15:04:33.972: INFO: (19) /api/v1/namespaces/proxy-7086/services/http:proxy-service-jvf4p:portname1/proxy/: foo (200; 19.233237ms)
Apr 30 15:04:33.972: INFO: (19) /api/v1/namespaces/proxy-7086/services/https:proxy-service-jvf4p:tlsportname1/proxy/: tls baz (200; 18.192902ms)
Apr 30 15:04:33.972: INFO: (19) /api/v1/namespaces/proxy-7086/services/proxy-service-jvf4p:portname1/proxy/: foo (200; 18.607346ms)
Apr 30 15:04:33.973: INFO: (19) /api/v1/namespaces/proxy-7086/services/https:proxy-service-jvf4p:tlsportname2/proxy/: tls qux (200; 20.389267ms)
STEP: deleting ReplicationController proxy-service-jvf4p in namespace proxy-7086, will wait for the garbage collector to delete the pods
Apr 30 15:04:34.033: INFO: Deleting ReplicationController proxy-service-jvf4p took: 7.543032ms
Apr 30 15:04:34.433: INFO: Terminating ReplicationController proxy-service-jvf4p pods took: 400.200459ms
[AfterEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:04:42.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-7086" for this suite.
Apr 30 15:04:48.958: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:04:49.056: INFO: namespace proxy-7086 deletion completed in 6.117228119s

• [SLOW TEST:21.713 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:04:49.060: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 30 15:04:49.153: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4c835049-6b59-11e9-b570-225b9ad5bed0" in namespace "downward-api-5242" to be "success or failure"
Apr 30 15:04:49.164: INFO: Pod "downwardapi-volume-4c835049-6b59-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 9.993512ms
Apr 30 15:04:51.169: INFO: Pod "downwardapi-volume-4c835049-6b59-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014873783s
Apr 30 15:04:53.178: INFO: Pod "downwardapi-volume-4c835049-6b59-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024088881s
STEP: Saw pod success
Apr 30 15:04:53.178: INFO: Pod "downwardapi-volume-4c835049-6b59-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 15:04:53.187: INFO: Trying to get logs from node fatih-test-default-pool-qlpd pod downwardapi-volume-4c835049-6b59-11e9-b570-225b9ad5bed0 container client-container: <nil>
STEP: delete the pod
Apr 30 15:04:53.228: INFO: Waiting for pod downwardapi-volume-4c835049-6b59-11e9-b570-225b9ad5bed0 to disappear
Apr 30 15:04:53.231: INFO: Pod downwardapi-volume-4c835049-6b59-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:04:53.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5242" for this suite.
Apr 30 15:04:59.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:04:59.327: INFO: namespace downward-api-5242 deletion completed in 6.092463369s

• [SLOW TEST:10.269 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:04:59.333: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1583
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 30 15:04:59.368: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-8430'
Apr 30 15:04:59.698: INFO: stderr: ""
Apr 30 15:04:59.698: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1588
Apr 30 15:04:59.703: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 delete pods e2e-test-nginx-pod --namespace=kubectl-8430'
Apr 30 15:05:02.941: INFO: stderr: ""
Apr 30 15:05:02.941: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:05:02.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8430" for this suite.
Apr 30 15:05:08.972: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:05:09.045: INFO: namespace kubectl-8430 deletion completed in 6.090128614s

• [SLOW TEST:9.713 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:05:09.048: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Apr 30 15:05:09.097: INFO: Waiting up to 5m0s for pod "pod-58671a7d-6b59-11e9-b570-225b9ad5bed0" in namespace "emptydir-5812" to be "success or failure"
Apr 30 15:05:09.104: INFO: Pod "pod-58671a7d-6b59-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.669514ms
Apr 30 15:05:11.108: INFO: Pod "pod-58671a7d-6b59-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01081913s
Apr 30 15:05:13.113: INFO: Pod "pod-58671a7d-6b59-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015735689s
STEP: Saw pod success
Apr 30 15:05:13.113: INFO: Pod "pod-58671a7d-6b59-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 15:05:13.117: INFO: Trying to get logs from node fatih-test-default-pool-qlp1 pod pod-58671a7d-6b59-11e9-b570-225b9ad5bed0 container test-container: <nil>
STEP: delete the pod
Apr 30 15:05:13.139: INFO: Waiting for pod pod-58671a7d-6b59-11e9-b570-225b9ad5bed0 to disappear
Apr 30 15:05:13.142: INFO: Pod pod-58671a7d-6b59-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:05:13.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5812" for this suite.
Apr 30 15:05:19.158: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:05:19.286: INFO: namespace emptydir-5812 deletion completed in 6.140905891s

• [SLOW TEST:10.238 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:05:19.289: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-5e7ef819-6b59-11e9-b570-225b9ad5bed0
STEP: Creating a pod to test consume configMaps
Apr 30 15:05:19.324: INFO: Waiting up to 5m0s for pod "pod-configmaps-5e7f6b66-6b59-11e9-b570-225b9ad5bed0" in namespace "configmap-1103" to be "success or failure"
Apr 30 15:05:19.328: INFO: Pod "pod-configmaps-5e7f6b66-6b59-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 3.484058ms
Apr 30 15:05:21.332: INFO: Pod "pod-configmaps-5e7f6b66-6b59-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007374776s
Apr 30 15:05:23.336: INFO: Pod "pod-configmaps-5e7f6b66-6b59-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011686249s
STEP: Saw pod success
Apr 30 15:05:23.336: INFO: Pod "pod-configmaps-5e7f6b66-6b59-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 15:05:23.341: INFO: Trying to get logs from node fatih-test-default-pool-qlpd pod pod-configmaps-5e7f6b66-6b59-11e9-b570-225b9ad5bed0 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 30 15:05:23.357: INFO: Waiting for pod pod-configmaps-5e7f6b66-6b59-11e9-b570-225b9ad5bed0 to disappear
Apr 30 15:05:23.360: INFO: Pod pod-configmaps-5e7f6b66-6b59-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:05:23.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1103" for this suite.
Apr 30 15:05:29.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:05:29.472: INFO: namespace configmap-1103 deletion completed in 6.108951124s

• [SLOW TEST:10.183 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:05:29.475: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Apr 30 15:05:29.530: INFO: Number of nodes with available pods: 0
Apr 30 15:05:29.530: INFO: Node fatih-test-default-pool-qlp0 is running more than one daemon pod
Apr 30 15:05:30.567: INFO: Number of nodes with available pods: 0
Apr 30 15:05:30.567: INFO: Node fatih-test-default-pool-qlp0 is running more than one daemon pod
Apr 30 15:05:31.547: INFO: Number of nodes with available pods: 0
Apr 30 15:05:31.547: INFO: Node fatih-test-default-pool-qlp0 is running more than one daemon pod
Apr 30 15:05:32.543: INFO: Number of nodes with available pods: 1
Apr 30 15:05:32.543: INFO: Node fatih-test-default-pool-qlp0 is running more than one daemon pod
Apr 30 15:05:33.540: INFO: Number of nodes with available pods: 3
Apr 30 15:05:33.540: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Apr 30 15:05:33.562: INFO: Number of nodes with available pods: 2
Apr 30 15:05:33.562: INFO: Node fatih-test-default-pool-qlpd is running more than one daemon pod
Apr 30 15:05:34.569: INFO: Number of nodes with available pods: 2
Apr 30 15:05:34.570: INFO: Node fatih-test-default-pool-qlpd is running more than one daemon pod
Apr 30 15:05:35.580: INFO: Number of nodes with available pods: 2
Apr 30 15:05:35.580: INFO: Node fatih-test-default-pool-qlpd is running more than one daemon pod
Apr 30 15:05:36.572: INFO: Number of nodes with available pods: 3
Apr 30 15:05:36.572: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7796, will wait for the garbage collector to delete the pods
Apr 30 15:05:36.645: INFO: Deleting DaemonSet.extensions daemon-set took: 8.994377ms
Apr 30 15:05:37.045: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.196272ms
Apr 30 15:05:48.449: INFO: Number of nodes with available pods: 0
Apr 30 15:05:48.449: INFO: Number of running nodes: 0, number of available pods: 0
Apr 30 15:05:48.452: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7796/daemonsets","resourceVersion":"21032"},"items":null}

Apr 30 15:05:48.455: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7796/pods","resourceVersion":"21032"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:05:48.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7796" for this suite.
Apr 30 15:05:54.479: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:05:54.566: INFO: namespace daemonsets-7796 deletion completed in 6.098965555s

• [SLOW TEST:25.092 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:05:54.571: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-73868e4e-6b59-11e9-b570-225b9ad5bed0
STEP: Creating a pod to test consume secrets
Apr 30 15:05:54.604: INFO: Waiting up to 5m0s for pod "pod-secrets-7386f2ad-6b59-11e9-b570-225b9ad5bed0" in namespace "secrets-8983" to be "success or failure"
Apr 30 15:05:54.612: INFO: Pod "pod-secrets-7386f2ad-6b59-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 7.657781ms
Apr 30 15:05:56.617: INFO: Pod "pod-secrets-7386f2ad-6b59-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013049665s
Apr 30 15:05:58.623: INFO: Pod "pod-secrets-7386f2ad-6b59-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018687835s
STEP: Saw pod success
Apr 30 15:05:58.623: INFO: Pod "pod-secrets-7386f2ad-6b59-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 15:05:58.630: INFO: Trying to get logs from node fatih-test-default-pool-qlp0 pod pod-secrets-7386f2ad-6b59-11e9-b570-225b9ad5bed0 container secret-env-test: <nil>
STEP: delete the pod
Apr 30 15:05:58.668: INFO: Waiting for pod pod-secrets-7386f2ad-6b59-11e9-b570-225b9ad5bed0 to disappear
Apr 30 15:05:58.672: INFO: Pod pod-secrets-7386f2ad-6b59-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:05:58.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8983" for this suite.
Apr 30 15:06:04.685: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:06:04.761: INFO: namespace secrets-8983 deletion completed in 6.085853676s

• [SLOW TEST:10.190 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:06:04.764: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Apr 30 15:06:04.797: INFO: Waiting up to 5m0s for pod "pod-799a4c32-6b59-11e9-b570-225b9ad5bed0" in namespace "emptydir-5913" to be "success or failure"
Apr 30 15:06:04.806: INFO: Pod "pod-799a4c32-6b59-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 8.44047ms
Apr 30 15:06:06.810: INFO: Pod "pod-799a4c32-6b59-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013258695s
Apr 30 15:06:08.815: INFO: Pod "pod-799a4c32-6b59-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01810343s
STEP: Saw pod success
Apr 30 15:06:08.815: INFO: Pod "pod-799a4c32-6b59-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 15:06:08.820: INFO: Trying to get logs from node fatih-test-default-pool-qlp1 pod pod-799a4c32-6b59-11e9-b570-225b9ad5bed0 container test-container: <nil>
STEP: delete the pod
Apr 30 15:06:08.842: INFO: Waiting for pod pod-799a4c32-6b59-11e9-b570-225b9ad5bed0 to disappear
Apr 30 15:06:08.845: INFO: Pod pod-799a4c32-6b59-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:06:08.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5913" for this suite.
Apr 30 15:06:14.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:06:14.941: INFO: namespace emptydir-5913 deletion completed in 6.092856435s

• [SLOW TEST:10.177 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:06:14.945: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1219.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1219.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 30 15:06:27.022: INFO: DNS probes using dns-1219/dns-test-7faba2d7-6b59-11e9-b570-225b9ad5bed0 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:06:27.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1219" for this suite.
Apr 30 15:06:33.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:06:33.313: INFO: namespace dns-1219 deletion completed in 6.218622342s

• [SLOW TEST:18.368 seconds]
[sig-network] DNS
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:06:33.315: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-8abfd0c5-6b59-11e9-b570-225b9ad5bed0
STEP: Creating a pod to test consume secrets
Apr 30 15:06:33.692: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8ad1cba8-6b59-11e9-b570-225b9ad5bed0" in namespace "projected-4126" to be "success or failure"
Apr 30 15:06:33.744: INFO: Pod "pod-projected-secrets-8ad1cba8-6b59-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 51.814931ms
Apr 30 15:06:36.112: INFO: Pod "pod-projected-secrets-8ad1cba8-6b59-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.419689976s
Apr 30 15:06:38.116: INFO: Pod "pod-projected-secrets-8ad1cba8-6b59-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.423860484s
STEP: Saw pod success
Apr 30 15:06:38.116: INFO: Pod "pod-projected-secrets-8ad1cba8-6b59-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 15:06:38.119: INFO: Trying to get logs from node fatih-test-default-pool-qlp0 pod pod-projected-secrets-8ad1cba8-6b59-11e9-b570-225b9ad5bed0 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 30 15:06:38.206: INFO: Waiting for pod pod-projected-secrets-8ad1cba8-6b59-11e9-b570-225b9ad5bed0 to disappear
Apr 30 15:06:38.220: INFO: Pod pod-projected-secrets-8ad1cba8-6b59-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:06:38.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4126" for this suite.
Apr 30 15:06:44.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:06:44.317: INFO: namespace projected-4126 deletion completed in 6.092925885s

• [SLOW TEST:11.002 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:06:44.320: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 30 15:06:44.712: INFO: Creating ReplicaSet my-hostname-basic-91659645-6b59-11e9-b570-225b9ad5bed0
Apr 30 15:06:44.826: INFO: Pod name my-hostname-basic-91659645-6b59-11e9-b570-225b9ad5bed0: Found 0 pods out of 1
Apr 30 15:06:49.844: INFO: Pod name my-hostname-basic-91659645-6b59-11e9-b570-225b9ad5bed0: Found 1 pods out of 1
Apr 30 15:06:49.844: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-91659645-6b59-11e9-b570-225b9ad5bed0" is running
Apr 30 15:06:49.847: INFO: Pod "my-hostname-basic-91659645-6b59-11e9-b570-225b9ad5bed0-m6956" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-30 15:06:45 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-30 15:06:47 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-30 15:06:47 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-30 15:06:44 +0000 UTC Reason: Message:}])
Apr 30 15:06:49.847: INFO: Trying to dial the pod
Apr 30 15:06:54.864: INFO: Controller my-hostname-basic-91659645-6b59-11e9-b570-225b9ad5bed0: Got expected result from replica 1 [my-hostname-basic-91659645-6b59-11e9-b570-225b9ad5bed0-m6956]: "my-hostname-basic-91659645-6b59-11e9-b570-225b9ad5bed0-m6956", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:06:54.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-2116" for this suite.
Apr 30 15:07:07.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:07:07.815: INFO: namespace replicaset-2116 deletion completed in 12.947543276s

• [SLOW TEST:23.495 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:07:07.816: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Apr 30 15:07:17.219: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:07:17.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-3551" for this suite.
Apr 30 15:07:40.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:07:40.136: INFO: namespace replicaset-3551 deletion completed in 22.315416818s

• [SLOW TEST:32.320 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:07:40.136: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 30 15:07:40.201: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:07:41.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-6804" for this suite.
Apr 30 15:07:47.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:07:47.875: INFO: namespace custom-resource-definition-6804 deletion completed in 6.388140353s

• [SLOW TEST:7.739 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:07:47.876: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-b74fdfc4-6b59-11e9-b570-225b9ad5bed0
STEP: Creating a pod to test consume secrets
Apr 30 15:07:48.528: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b75686e9-6b59-11e9-b570-225b9ad5bed0" in namespace "projected-1886" to be "success or failure"
Apr 30 15:07:48.535: INFO: Pod "pod-projected-secrets-b75686e9-6b59-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.846567ms
Apr 30 15:07:50.539: INFO: Pod "pod-projected-secrets-b75686e9-6b59-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011539075s
Apr 30 15:07:52.545: INFO: Pod "pod-projected-secrets-b75686e9-6b59-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017556241s
STEP: Saw pod success
Apr 30 15:07:52.545: INFO: Pod "pod-projected-secrets-b75686e9-6b59-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 15:07:52.552: INFO: Trying to get logs from node fatih-test-default-pool-qlp1 pod pod-projected-secrets-b75686e9-6b59-11e9-b570-225b9ad5bed0 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 30 15:07:52.608: INFO: Waiting for pod pod-projected-secrets-b75686e9-6b59-11e9-b570-225b9ad5bed0 to disappear
Apr 30 15:07:52.962: INFO: Pod pod-projected-secrets-b75686e9-6b59-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:07:52.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1886" for this suite.
Apr 30 15:08:01.170: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:08:01.249: INFO: namespace projected-1886 deletion completed in 8.279979519s

• [SLOW TEST:13.373 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:08:01.252: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-3568
Apr 30 15:08:05.980: INFO: Started pod liveness-http in namespace container-probe-3568
STEP: checking the pod's current state and verifying that restartCount is present
Apr 30 15:08:05.983: INFO: Initial restart count of pod liveness-http is 0
Apr 30 15:08:21.593: INFO: Restart count of pod container-probe-3568/liveness-http is now 1 (15.610167743s elapsed)
Apr 30 15:08:41.842: INFO: Restart count of pod container-probe-3568/liveness-http is now 2 (35.858924153s elapsed)
Apr 30 15:09:01.267: INFO: Restart count of pod container-probe-3568/liveness-http is now 3 (55.2842109s elapsed)
Apr 30 15:09:21.309: INFO: Restart count of pod container-probe-3568/liveness-http is now 4 (1m15.326461024s elapsed)
Apr 30 15:10:23.436: INFO: Restart count of pod container-probe-3568/liveness-http is now 5 (2m17.453464964s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:10:23.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3568" for this suite.
Apr 30 15:10:29.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:10:29.811: INFO: namespace container-probe-3568 deletion completed in 6.192524468s

• [SLOW TEST:148.560 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:10:29.815: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Apr 30 15:10:30.095: INFO: Waiting up to 5m0s for pod "pod-17baa252-6b5a-11e9-b570-225b9ad5bed0" in namespace "emptydir-4353" to be "success or failure"
Apr 30 15:10:30.117: INFO: Pod "pod-17baa252-6b5a-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 21.129541ms
Apr 30 15:10:32.126: INFO: Pod "pod-17baa252-6b5a-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03050095s
Apr 30 15:10:34.130: INFO: Pod "pod-17baa252-6b5a-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035087903s
STEP: Saw pod success
Apr 30 15:10:34.131: INFO: Pod "pod-17baa252-6b5a-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 15:10:34.157: INFO: Trying to get logs from node fatih-test-default-pool-qlp0 pod pod-17baa252-6b5a-11e9-b570-225b9ad5bed0 container test-container: <nil>
STEP: delete the pod
Apr 30 15:10:34.214: INFO: Waiting for pod pod-17baa252-6b5a-11e9-b570-225b9ad5bed0 to disappear
Apr 30 15:10:34.242: INFO: Pod pod-17baa252-6b5a-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:10:34.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4353" for this suite.
Apr 30 15:10:40.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:10:40.410: INFO: namespace emptydir-4353 deletion completed in 6.163036402s

• [SLOW TEST:10.596 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:10:40.416: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 30 15:10:40.535: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1df1545f-6b5a-11e9-b570-225b9ad5bed0" in namespace "downward-api-7016" to be "success or failure"
Apr 30 15:10:40.558: INFO: Pod "downwardapi-volume-1df1545f-6b5a-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 22.535303ms
Apr 30 15:10:42.562: INFO: Pod "downwardapi-volume-1df1545f-6b5a-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026175904s
Apr 30 15:10:44.566: INFO: Pod "downwardapi-volume-1df1545f-6b5a-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029912414s
STEP: Saw pod success
Apr 30 15:10:44.566: INFO: Pod "downwardapi-volume-1df1545f-6b5a-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 15:10:44.569: INFO: Trying to get logs from node fatih-test-default-pool-qlp1 pod downwardapi-volume-1df1545f-6b5a-11e9-b570-225b9ad5bed0 container client-container: <nil>
STEP: delete the pod
Apr 30 15:10:44.645: INFO: Waiting for pod downwardapi-volume-1df1545f-6b5a-11e9-b570-225b9ad5bed0 to disappear
Apr 30 15:10:44.674: INFO: Pod downwardapi-volume-1df1545f-6b5a-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:10:44.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7016" for this suite.
Apr 30 15:10:52.805: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:10:52.891: INFO: namespace downward-api-7016 deletion completed in 8.210227563s

• [SLOW TEST:12.476 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:10:52.892: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Apr 30 15:10:52.982: INFO: Waiting up to 5m0s for pod "pod-255e6f4b-6b5a-11e9-b570-225b9ad5bed0" in namespace "emptydir-2947" to be "success or failure"
Apr 30 15:10:52.998: INFO: Pod "pod-255e6f4b-6b5a-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 15.734153ms
Apr 30 15:10:55.001: INFO: Pod "pod-255e6f4b-6b5a-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019199553s
Apr 30 15:10:57.006: INFO: Pod "pod-255e6f4b-6b5a-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024118971s
STEP: Saw pod success
Apr 30 15:10:57.006: INFO: Pod "pod-255e6f4b-6b5a-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 15:10:57.010: INFO: Trying to get logs from node fatih-test-default-pool-qlpd pod pod-255e6f4b-6b5a-11e9-b570-225b9ad5bed0 container test-container: <nil>
STEP: delete the pod
Apr 30 15:10:57.032: INFO: Waiting for pod pod-255e6f4b-6b5a-11e9-b570-225b9ad5bed0 to disappear
Apr 30 15:10:57.034: INFO: Pod pod-255e6f4b-6b5a-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:10:57.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2947" for this suite.
Apr 30 15:11:03.046: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:11:03.116: INFO: namespace emptydir-2947 deletion completed in 6.078226844s

• [SLOW TEST:10.225 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:11:03.122: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8838.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-8838.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8838.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8838.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-8838.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8838.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 30 15:11:07.226: INFO: DNS probes using dns-8838/dns-test-2b701f61-6b5a-11e9-b570-225b9ad5bed0 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:11:07.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8838" for this suite.
Apr 30 15:11:13.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:11:13.323: INFO: namespace dns-8838 deletion completed in 6.082120566s

• [SLOW TEST:10.202 seconds]
[sig-network] DNS
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:11:13.325: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr 30 15:11:13.369: INFO: Waiting up to 5m0s for pod "downward-api-31868075-6b5a-11e9-b570-225b9ad5bed0" in namespace "downward-api-2626" to be "success or failure"
Apr 30 15:11:13.374: INFO: Pod "downward-api-31868075-6b5a-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 5.450747ms
Apr 30 15:11:15.379: INFO: Pod "downward-api-31868075-6b5a-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01025988s
Apr 30 15:11:17.385: INFO: Pod "downward-api-31868075-6b5a-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016426538s
STEP: Saw pod success
Apr 30 15:11:17.385: INFO: Pod "downward-api-31868075-6b5a-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 15:11:17.388: INFO: Trying to get logs from node fatih-test-default-pool-qlpd pod downward-api-31868075-6b5a-11e9-b570-225b9ad5bed0 container dapi-container: <nil>
STEP: delete the pod
Apr 30 15:11:17.420: INFO: Waiting for pod downward-api-31868075-6b5a-11e9-b570-225b9ad5bed0 to disappear
Apr 30 15:11:17.427: INFO: Pod downward-api-31868075-6b5a-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:11:17.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2626" for this suite.
Apr 30 15:11:23.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:11:23.514: INFO: namespace downward-api-2626 deletion completed in 6.080223776s

• [SLOW TEST:10.189 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:11:23.517: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-3798089a-6b5a-11e9-b570-225b9ad5bed0
STEP: Creating configMap with name cm-test-opt-upd-37980967-6b5a-11e9-b570-225b9ad5bed0
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-3798089a-6b5a-11e9-b570-225b9ad5bed0
STEP: Updating configmap cm-test-opt-upd-37980967-6b5a-11e9-b570-225b9ad5bed0
STEP: Creating configMap with name cm-test-opt-create-3798097e-6b5a-11e9-b570-225b9ad5bed0
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:12:58.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5819" for this suite.
Apr 30 15:13:20.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:13:20.542: INFO: namespace configmap-5819 deletion completed in 22.081455202s

• [SLOW TEST:117.025 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:13:20.545: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr 30 15:13:20.578: INFO: Waiting up to 5m0s for pod "downward-api-7d591c7c-6b5a-11e9-b570-225b9ad5bed0" in namespace "downward-api-2805" to be "success or failure"
Apr 30 15:13:20.588: INFO: Pod "downward-api-7d591c7c-6b5a-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 10.031138ms
Apr 30 15:13:22.596: INFO: Pod "downward-api-7d591c7c-6b5a-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01819523s
Apr 30 15:13:24.599: INFO: Pod "downward-api-7d591c7c-6b5a-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021521641s
Apr 30 15:13:26.604: INFO: Pod "downward-api-7d591c7c-6b5a-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.02592402s
STEP: Saw pod success
Apr 30 15:13:26.604: INFO: Pod "downward-api-7d591c7c-6b5a-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 15:13:26.607: INFO: Trying to get logs from node fatih-test-default-pool-qlpd pod downward-api-7d591c7c-6b5a-11e9-b570-225b9ad5bed0 container dapi-container: <nil>
STEP: delete the pod
Apr 30 15:13:26.632: INFO: Waiting for pod downward-api-7d591c7c-6b5a-11e9-b570-225b9ad5bed0 to disappear
Apr 30 15:13:26.635: INFO: Pod downward-api-7d591c7c-6b5a-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:13:26.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2805" for this suite.
Apr 30 15:13:32.844: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:13:32.923: INFO: namespace downward-api-2805 deletion completed in 6.285113559s

• [SLOW TEST:12.379 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:13:32.923: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 30 15:13:32.960: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Apr 30 15:13:32.973: INFO: Number of nodes with available pods: 0
Apr 30 15:13:32.973: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Apr 30 15:13:32.994: INFO: Number of nodes with available pods: 0
Apr 30 15:13:32.994: INFO: Node fatih-test-default-pool-qlp0 is running more than one daemon pod
Apr 30 15:13:34.220: INFO: Number of nodes with available pods: 0
Apr 30 15:13:34.220: INFO: Node fatih-test-default-pool-qlp0 is running more than one daemon pod
Apr 30 15:13:34.998: INFO: Number of nodes with available pods: 0
Apr 30 15:13:34.998: INFO: Node fatih-test-default-pool-qlp0 is running more than one daemon pod
Apr 30 15:13:35.997: INFO: Number of nodes with available pods: 1
Apr 30 15:13:35.997: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Apr 30 15:13:36.025: INFO: Number of nodes with available pods: 1
Apr 30 15:13:36.025: INFO: Number of running nodes: 0, number of available pods: 1
Apr 30 15:13:37.028: INFO: Number of nodes with available pods: 0
Apr 30 15:13:37.028: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Apr 30 15:13:37.043: INFO: Number of nodes with available pods: 0
Apr 30 15:13:37.043: INFO: Node fatih-test-default-pool-qlp0 is running more than one daemon pod
Apr 30 15:13:38.047: INFO: Number of nodes with available pods: 0
Apr 30 15:13:38.047: INFO: Node fatih-test-default-pool-qlp0 is running more than one daemon pod
Apr 30 15:13:39.048: INFO: Number of nodes with available pods: 0
Apr 30 15:13:39.048: INFO: Node fatih-test-default-pool-qlp0 is running more than one daemon pod
Apr 30 15:13:40.564: INFO: Number of nodes with available pods: 0
Apr 30 15:13:40.564: INFO: Node fatih-test-default-pool-qlp0 is running more than one daemon pod
Apr 30 15:13:41.190: INFO: Number of nodes with available pods: 0
Apr 30 15:13:41.190: INFO: Node fatih-test-default-pool-qlp0 is running more than one daemon pod
Apr 30 15:13:42.047: INFO: Number of nodes with available pods: 0
Apr 30 15:13:42.047: INFO: Node fatih-test-default-pool-qlp0 is running more than one daemon pod
Apr 30 15:13:43.049: INFO: Number of nodes with available pods: 1
Apr 30 15:13:43.049: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2623, will wait for the garbage collector to delete the pods
Apr 30 15:13:43.113: INFO: Deleting DaemonSet.extensions daemon-set took: 6.652535ms
Apr 30 15:13:43.513: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.338784ms
Apr 30 15:13:53.018: INFO: Number of nodes with available pods: 0
Apr 30 15:13:53.018: INFO: Number of running nodes: 0, number of available pods: 0
Apr 30 15:13:53.021: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2623/daemonsets","resourceVersion":"22487"},"items":null}

Apr 30 15:13:53.022: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2623/pods","resourceVersion":"22487"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:13:53.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2623" for this suite.
Apr 30 15:13:59.056: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:13:59.150: INFO: namespace daemonsets-2623 deletion completed in 6.107669585s

• [SLOW TEST:26.227 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:13:59.153: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 30 15:13:59.193: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Apr 30 15:13:59.202: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr 30 15:14:04.206: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr 30 15:14:04.206: INFO: Creating deployment "test-rolling-update-deployment"
Apr 30 15:14:04.212: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Apr 30 15:14:04.221: INFO: deployment "test-rolling-update-deployment" doesn't have the required revision set
Apr 30 15:14:06.228: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Apr 30 15:14:06.231: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr 30 15:14:06.238: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-3441,SelfLink:/apis/apps/v1/namespaces/deployment-3441/deployments/test-rolling-update-deployment,UID:9758fd96-6b5a-11e9-a241-32cef6bf8510,ResourceVersion:22580,Generation:1,CreationTimestamp:2019-04-30 15:14:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-04-30 15:14:04 +0000 UTC 2019-04-30 15:14:04 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-04-30 15:14:06 +0000 UTC 2019-04-30 15:14:04 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-67599b4d9" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Apr 30 15:14:06.240: INFO: New ReplicaSet "test-rolling-update-deployment-67599b4d9" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-67599b4d9,GenerateName:,Namespace:deployment-3441,SelfLink:/apis/apps/v1/namespaces/deployment-3441/replicasets/test-rolling-update-deployment-67599b4d9,UID:975ab2d0-6b5a-11e9-a241-32cef6bf8510,ResourceVersion:22570,Generation:1,CreationTimestamp:2019-04-30 15:14:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 9758fd96-6b5a-11e9-a241-32cef6bf8510 0xc002ad01b0 0xc002ad01b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Apr 30 15:14:06.240: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Apr 30 15:14:06.241: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-3441,SelfLink:/apis/apps/v1/namespaces/deployment-3441/replicasets/test-rolling-update-controller,UID:945c14dd-6b5a-11e9-a241-32cef6bf8510,ResourceVersion:22579,Generation:2,CreationTimestamp:2019-04-30 15:13:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 9758fd96-6b5a-11e9-a241-32cef6bf8510 0xc002ad00e7 0xc002ad00e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 30 15:14:06.243: INFO: Pod "test-rolling-update-deployment-67599b4d9-sgdbg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-67599b4d9-sgdbg,GenerateName:test-rolling-update-deployment-67599b4d9-,Namespace:deployment-3441,SelfLink:/api/v1/namespaces/deployment-3441/pods/test-rolling-update-deployment-67599b4d9-sgdbg,UID:975b566a-6b5a-11e9-a241-32cef6bf8510,ResourceVersion:22569,Generation:0,CreationTimestamp:2019-04-30 15:14:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-67599b4d9 975ab2d0-6b5a-11e9-a241-32cef6bf8510 0xc002ad0a90 0xc002ad0a91}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vqnn7 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vqnn7,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-vqnn7 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:fatih-test-default-pool-qlpd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002ad0af0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002ad0b10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 15:14:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 15:14:06 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 15:14:06 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 15:14:04 +0000 UTC  }],Message:,Reason:,HostIP:10.136.141.126,PodIP:10.244.1.203,StartTime:2019-04-30 15:14:04 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-04-30 15:14:05 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://b1f4b6823130bd6c6dc2c454eeb37467384157f60155aa655657395b17a84795}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:14:06.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3441" for this suite.
Apr 30 15:14:12.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:14:12.333: INFO: namespace deployment-3441 deletion completed in 6.087320761s

• [SLOW TEST:13.180 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:14:12.339: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Apr 30 15:14:12.392: INFO: Waiting up to 5m0s for pod "pod-9c3a7a51-6b5a-11e9-b570-225b9ad5bed0" in namespace "emptydir-7766" to be "success or failure"
Apr 30 15:14:12.404: INFO: Pod "pod-9c3a7a51-6b5a-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 11.680156ms
Apr 30 15:14:14.408: INFO: Pod "pod-9c3a7a51-6b5a-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01596409s
Apr 30 15:14:16.413: INFO: Pod "pod-9c3a7a51-6b5a-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020308918s
STEP: Saw pod success
Apr 30 15:14:16.413: INFO: Pod "pod-9c3a7a51-6b5a-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 15:14:16.416: INFO: Trying to get logs from node fatih-test-default-pool-qlp0 pod pod-9c3a7a51-6b5a-11e9-b570-225b9ad5bed0 container test-container: <nil>
STEP: delete the pod
Apr 30 15:14:16.435: INFO: Waiting for pod pod-9c3a7a51-6b5a-11e9-b570-225b9ad5bed0 to disappear
Apr 30 15:14:16.441: INFO: Pod pod-9c3a7a51-6b5a-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:14:16.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7766" for this suite.
Apr 30 15:14:22.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:14:22.619: INFO: namespace emptydir-7766 deletion completed in 6.175776511s

• [SLOW TEST:10.281 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:14:22.622: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:14:26.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8079" for this suite.
Apr 30 15:15:16.868: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:15:16.958: INFO: namespace kubelet-test-8079 deletion completed in 50.101438319s

• [SLOW TEST:54.337 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:15:16.964: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:15:21.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2171" for this suite.
Apr 30 15:16:11.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:16:11.106: INFO: namespace kubelet-test-2171 deletion completed in 50.07786816s

• [SLOW TEST:54.142 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:16:11.110: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Apr 30 15:16:19.202: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 30 15:16:19.212: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 30 15:16:21.212: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 30 15:16:21.216: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 30 15:16:23.212: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 30 15:16:23.216: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 30 15:16:25.212: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 30 15:16:25.216: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 30 15:16:27.212: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 30 15:16:27.216: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 30 15:16:29.212: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 30 15:16:29.216: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 30 15:16:31.212: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 30 15:16:31.216: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 30 15:16:33.212: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 30 15:16:33.215: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 30 15:16:35.212: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 30 15:16:35.216: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 30 15:16:37.212: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 30 15:16:37.215: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 30 15:16:39.212: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 30 15:16:39.216: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 30 15:16:41.212: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 30 15:16:41.216: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 30 15:16:43.212: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 30 15:16:43.217: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:16:43.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5424" for this suite.
Apr 30 15:17:05.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:17:05.303: INFO: namespace container-lifecycle-hook-5424 deletion completed in 22.08135974s

• [SLOW TEST:54.193 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:17:05.306: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1455
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 30 15:17:05.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=kubectl-5939'
Apr 30 15:17:05.549: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr 30 15:17:05.549: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1460
Apr 30 15:17:07.568: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 delete deployment e2e-test-nginx-deployment --namespace=kubectl-5939'
Apr 30 15:17:07.938: INFO: stderr: ""
Apr 30 15:17:07.938: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:17:07.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5939" for this suite.
Apr 30 15:17:30.085: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:17:30.156: INFO: namespace kubectl-5939 deletion completed in 22.215204543s

• [SLOW TEST:24.851 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:17:30.157: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0430 15:17:40.203238      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 30 15:17:40.203: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:17:40.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5837" for this suite.
Apr 30 15:17:46.216: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:17:46.295: INFO: namespace gc-5837 deletion completed in 6.089321111s

• [SLOW TEST:16.138 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:17:46.304: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Apr 30 15:17:46.333: INFO: Waiting up to 5m0s for pod "pod-1bc01525-6b5b-11e9-b570-225b9ad5bed0" in namespace "emptydir-4050" to be "success or failure"
Apr 30 15:17:46.430: INFO: Pod "pod-1bc01525-6b5b-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 96.656071ms
Apr 30 15:17:48.434: INFO: Pod "pod-1bc01525-6b5b-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.100777785s
Apr 30 15:17:50.439: INFO: Pod "pod-1bc01525-6b5b-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.105070012s
STEP: Saw pod success
Apr 30 15:17:50.439: INFO: Pod "pod-1bc01525-6b5b-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 15:17:50.442: INFO: Trying to get logs from node fatih-test-default-pool-qlpd pod pod-1bc01525-6b5b-11e9-b570-225b9ad5bed0 container test-container: <nil>
STEP: delete the pod
Apr 30 15:17:50.488: INFO: Waiting for pod pod-1bc01525-6b5b-11e9-b570-225b9ad5bed0 to disappear
Apr 30 15:17:50.491: INFO: Pod pod-1bc01525-6b5b-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:17:50.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4050" for this suite.
Apr 30 15:17:56.507: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:17:56.577: INFO: namespace emptydir-4050 deletion completed in 6.083532416s

• [SLOW TEST:10.274 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:17:56.586: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1354
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 30 15:17:56.633: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-5004'
Apr 30 15:17:56.751: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr 30 15:17:56.751: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Apr 30 15:17:56.812: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-6rstm]
Apr 30 15:17:56.812: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-6rstm" in namespace "kubectl-5004" to be "running and ready"
Apr 30 15:17:56.818: INFO: Pod "e2e-test-nginx-rc-6rstm": Phase="Pending", Reason="", readiness=false. Elapsed: 6.198171ms
Apr 30 15:17:58.825: INFO: Pod "e2e-test-nginx-rc-6rstm": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013144277s
Apr 30 15:18:00.830: INFO: Pod "e2e-test-nginx-rc-6rstm": Phase="Running", Reason="", readiness=true. Elapsed: 4.017939498s
Apr 30 15:18:00.830: INFO: Pod "e2e-test-nginx-rc-6rstm" satisfied condition "running and ready"
Apr 30 15:18:00.830: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-6rstm]
Apr 30 15:18:00.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 logs rc/e2e-test-nginx-rc --namespace=kubectl-5004'
Apr 30 15:18:00.968: INFO: stderr: ""
Apr 30 15:18:00.968: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1359
Apr 30 15:18:00.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 delete rc e2e-test-nginx-rc --namespace=kubectl-5004'
Apr 30 15:18:01.108: INFO: stderr: ""
Apr 30 15:18:01.108: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:18:01.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5004" for this suite.
Apr 30 15:18:07.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:18:07.198: INFO: namespace kubectl-5004 deletion completed in 6.086399928s

• [SLOW TEST:10.613 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:18:07.201: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 30 15:18:07.233: INFO: Waiting up to 5m0s for pod "downwardapi-volume-28355118-6b5b-11e9-b570-225b9ad5bed0" in namespace "projected-428" to be "success or failure"
Apr 30 15:18:07.237: INFO: Pod "downwardapi-volume-28355118-6b5b-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 3.668371ms
Apr 30 15:18:09.242: INFO: Pod "downwardapi-volume-28355118-6b5b-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007840892s
Apr 30 15:18:11.245: INFO: Pod "downwardapi-volume-28355118-6b5b-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01155494s
STEP: Saw pod success
Apr 30 15:18:11.245: INFO: Pod "downwardapi-volume-28355118-6b5b-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 15:18:11.248: INFO: Trying to get logs from node fatih-test-default-pool-qlpd pod downwardapi-volume-28355118-6b5b-11e9-b570-225b9ad5bed0 container client-container: <nil>
STEP: delete the pod
Apr 30 15:18:11.276: INFO: Waiting for pod downwardapi-volume-28355118-6b5b-11e9-b570-225b9ad5bed0 to disappear
Apr 30 15:18:11.279: INFO: Pod downwardapi-volume-28355118-6b5b-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:18:11.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-428" for this suite.
Apr 30 15:18:17.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:18:17.377: INFO: namespace projected-428 deletion completed in 6.094786141s

• [SLOW TEST:10.177 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:18:17.380: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr 30 15:18:17.461: INFO: Waiting up to 5m0s for pod "downward-api-2e4a3292-6b5b-11e9-b570-225b9ad5bed0" in namespace "downward-api-2012" to be "success or failure"
Apr 30 15:18:17.480: INFO: Pod "downward-api-2e4a3292-6b5b-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 18.388583ms
Apr 30 15:18:19.521: INFO: Pod "downward-api-2e4a3292-6b5b-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.059617888s
STEP: Saw pod success
Apr 30 15:18:19.521: INFO: Pod "downward-api-2e4a3292-6b5b-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 15:18:19.526: INFO: Trying to get logs from node fatih-test-default-pool-qlpd pod downward-api-2e4a3292-6b5b-11e9-b570-225b9ad5bed0 container dapi-container: <nil>
STEP: delete the pod
Apr 30 15:18:19.561: INFO: Waiting for pod downward-api-2e4a3292-6b5b-11e9-b570-225b9ad5bed0 to disappear
Apr 30 15:18:19.564: INFO: Pod downward-api-2e4a3292-6b5b-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:18:19.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2012" for this suite.
Apr 30 15:18:25.575: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:18:25.659: INFO: namespace downward-api-2012 deletion completed in 6.092351664s

• [SLOW TEST:8.280 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:18:25.666: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 30 15:18:53.730: INFO: Container started at 2019-04-30 15:18:28 +0000 UTC, pod became ready at 2019-04-30 15:18:52 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:18:53.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4762" for this suite.
Apr 30 15:19:15.747: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:19:15.914: INFO: namespace container-probe-4762 deletion completed in 22.178612583s

• [SLOW TEST:50.249 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:19:15.918: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Apr 30 15:19:24.099: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 30 15:19:24.105: INFO: Pod pod-with-poststart-http-hook still exists
Apr 30 15:19:26.105: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 30 15:19:26.108: INFO: Pod pod-with-poststart-http-hook still exists
Apr 30 15:19:28.105: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 30 15:19:28.110: INFO: Pod pod-with-poststart-http-hook still exists
Apr 30 15:19:30.105: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 30 15:19:30.109: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:19:30.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9131" for this suite.
Apr 30 15:19:52.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:19:52.198: INFO: namespace container-lifecycle-hook-9131 deletion completed in 22.084090259s

• [SLOW TEST:36.281 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:19:52.202: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service endpoint-test2 in namespace services-5639
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5639 to expose endpoints map[]
Apr 30 15:19:52.256: INFO: successfully validated that service endpoint-test2 in namespace services-5639 exposes endpoints map[] (8.659536ms elapsed)
STEP: Creating pod pod1 in namespace services-5639
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5639 to expose endpoints map[pod1:[80]]
Apr 30 15:19:56.357: INFO: successfully validated that service endpoint-test2 in namespace services-5639 exposes endpoints map[pod1:[80]] (4.091110173s elapsed)
STEP: Creating pod pod2 in namespace services-5639
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5639 to expose endpoints map[pod1:[80] pod2:[80]]
Apr 30 15:19:59.404: INFO: successfully validated that service endpoint-test2 in namespace services-5639 exposes endpoints map[pod1:[80] pod2:[80]] (3.041851317s elapsed)
STEP: Deleting pod pod1 in namespace services-5639
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5639 to expose endpoints map[pod2:[80]]
Apr 30 15:19:59.435: INFO: successfully validated that service endpoint-test2 in namespace services-5639 exposes endpoints map[pod2:[80]] (18.757245ms elapsed)
STEP: Deleting pod pod2 in namespace services-5639
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5639 to expose endpoints map[]
Apr 30 15:19:59.455: INFO: successfully validated that service endpoint-test2 in namespace services-5639 exposes endpoints map[] (7.967297ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:19:59.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5639" for this suite.
Apr 30 15:20:05.520: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:20:05.603: INFO: namespace services-5639 deletion completed in 6.102095099s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:13.401 seconds]
[sig-network] Services
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:20:05.604: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr 30 15:20:05.645: INFO: Waiting up to 5m0s for pod "downward-api-6ec92b84-6b5b-11e9-b570-225b9ad5bed0" in namespace "downward-api-151" to be "success or failure"
Apr 30 15:20:05.655: INFO: Pod "downward-api-6ec92b84-6b5b-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 10.087995ms
Apr 30 15:20:07.822: INFO: Pod "downward-api-6ec92b84-6b5b-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.177056694s
STEP: Saw pod success
Apr 30 15:20:07.822: INFO: Pod "downward-api-6ec92b84-6b5b-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 15:20:07.826: INFO: Trying to get logs from node fatih-test-default-pool-qlpd pod downward-api-6ec92b84-6b5b-11e9-b570-225b9ad5bed0 container dapi-container: <nil>
STEP: delete the pod
Apr 30 15:20:07.849: INFO: Waiting for pod downward-api-6ec92b84-6b5b-11e9-b570-225b9ad5bed0 to disappear
Apr 30 15:20:07.851: INFO: Pod downward-api-6ec92b84-6b5b-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:20:07.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-151" for this suite.
Apr 30 15:20:13.863: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:20:13.931: INFO: namespace downward-api-151 deletion completed in 6.07656247s

• [SLOW TEST:8.327 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:20:13.934: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-73bf7c32-6b5b-11e9-b570-225b9ad5bed0
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-73bf7c32-6b5b-11e9-b570-225b9ad5bed0
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:20:18.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5097" for this suite.
Apr 30 15:20:40.083: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:20:40.169: INFO: namespace configmap-5097 deletion completed in 22.142228679s

• [SLOW TEST:26.236 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:20:40.170: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Apr 30 15:20:42.828: INFO: Successfully updated pod "labelsupdate836311ef-6b5b-11e9-b570-225b9ad5bed0"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:20:44.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2084" for this suite.
Apr 30 15:21:06.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:21:06.988: INFO: namespace projected-2084 deletion completed in 22.10368018s

• [SLOW TEST:26.818 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:21:06.991: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-9362343b-6b5b-11e9-b570-225b9ad5bed0
STEP: Creating a pod to test consume configMaps
Apr 30 15:21:07.049: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9362f0fa-6b5b-11e9-b570-225b9ad5bed0" in namespace "projected-3435" to be "success or failure"
Apr 30 15:21:07.054: INFO: Pod "pod-projected-configmaps-9362f0fa-6b5b-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.251731ms
Apr 30 15:21:09.058: INFO: Pod "pod-projected-configmaps-9362f0fa-6b5b-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00844588s
Apr 30 15:21:11.063: INFO: Pod "pod-projected-configmaps-9362f0fa-6b5b-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013406924s
STEP: Saw pod success
Apr 30 15:21:11.063: INFO: Pod "pod-projected-configmaps-9362f0fa-6b5b-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 15:21:11.066: INFO: Trying to get logs from node fatih-test-default-pool-qlpd pod pod-projected-configmaps-9362f0fa-6b5b-11e9-b570-225b9ad5bed0 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 30 15:21:11.089: INFO: Waiting for pod pod-projected-configmaps-9362f0fa-6b5b-11e9-b570-225b9ad5bed0 to disappear
Apr 30 15:21:11.092: INFO: Pod pod-projected-configmaps-9362f0fa-6b5b-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:21:11.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3435" for this suite.
Apr 30 15:21:17.107: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:21:17.188: INFO: namespace projected-3435 deletion completed in 6.092551519s

• [SLOW TEST:10.197 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:21:17.188: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-997409c3-6b5b-11e9-b570-225b9ad5bed0
STEP: Creating configMap with name cm-test-opt-upd-99740a10-6b5b-11e9-b570-225b9ad5bed0
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-997409c3-6b5b-11e9-b570-225b9ad5bed0
STEP: Updating configmap cm-test-opt-upd-99740a10-6b5b-11e9-b570-225b9ad5bed0
STEP: Creating configMap with name cm-test-opt-create-99740a2c-6b5b-11e9-b570-225b9ad5bed0
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:21:25.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3700" for this suite.
Apr 30 15:21:47.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:21:47.448: INFO: namespace projected-3700 deletion completed in 22.115268815s

• [SLOW TEST:30.260 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:21:47.454: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Apr 30 15:21:47.847: INFO: Waiting up to 5m0s for pod "pod-abb3ad8c-6b5b-11e9-b570-225b9ad5bed0" in namespace "emptydir-6993" to be "success or failure"
Apr 30 15:21:47.854: INFO: Pod "pod-abb3ad8c-6b5b-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.912389ms
Apr 30 15:21:49.858: INFO: Pod "pod-abb3ad8c-6b5b-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010406862s
Apr 30 15:21:51.862: INFO: Pod "pod-abb3ad8c-6b5b-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014752364s
STEP: Saw pod success
Apr 30 15:21:51.862: INFO: Pod "pod-abb3ad8c-6b5b-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 15:21:51.865: INFO: Trying to get logs from node fatih-test-default-pool-qlp1 pod pod-abb3ad8c-6b5b-11e9-b570-225b9ad5bed0 container test-container: <nil>
STEP: delete the pod
Apr 30 15:21:51.890: INFO: Waiting for pod pod-abb3ad8c-6b5b-11e9-b570-225b9ad5bed0 to disappear
Apr 30 15:21:51.892: INFO: Pod pod-abb3ad8c-6b5b-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:21:51.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6993" for this suite.
Apr 30 15:21:57.907: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:21:57.980: INFO: namespace emptydir-6993 deletion completed in 6.083029382s

• [SLOW TEST:10.526 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:21:57.987: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 30 15:21:58.034: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Apr 30 15:21:58.045: INFO: Number of nodes with available pods: 0
Apr 30 15:21:58.045: INFO: Node fatih-test-default-pool-qlp0 is running more than one daemon pod
Apr 30 15:21:59.468: INFO: Number of nodes with available pods: 0
Apr 30 15:21:59.532: INFO: Node fatih-test-default-pool-qlp0 is running more than one daemon pod
Apr 30 15:22:00.204: INFO: Number of nodes with available pods: 1
Apr 30 15:22:00.204: INFO: Node fatih-test-default-pool-qlp0 is running more than one daemon pod
Apr 30 15:22:01.054: INFO: Number of nodes with available pods: 2
Apr 30 15:22:01.054: INFO: Node fatih-test-default-pool-qlp1 is running more than one daemon pod
Apr 30 15:22:02.051: INFO: Number of nodes with available pods: 3
Apr 30 15:22:02.052: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Apr 30 15:22:02.086: INFO: Wrong image for pod: daemon-set-g6fdt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:02.086: INFO: Wrong image for pod: daemon-set-qxwst. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:02.086: INFO: Wrong image for pod: daemon-set-v8jmw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:03.098: INFO: Wrong image for pod: daemon-set-g6fdt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:03.098: INFO: Wrong image for pod: daemon-set-qxwst. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:03.098: INFO: Wrong image for pod: daemon-set-v8jmw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:04.096: INFO: Wrong image for pod: daemon-set-g6fdt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:04.096: INFO: Wrong image for pod: daemon-set-qxwst. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:04.096: INFO: Wrong image for pod: daemon-set-v8jmw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:04.096: INFO: Pod daemon-set-v8jmw is not available
Apr 30 15:22:05.096: INFO: Wrong image for pod: daemon-set-g6fdt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:05.096: INFO: Wrong image for pod: daemon-set-qxwst. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:05.096: INFO: Wrong image for pod: daemon-set-v8jmw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:05.096: INFO: Pod daemon-set-v8jmw is not available
Apr 30 15:22:06.097: INFO: Wrong image for pod: daemon-set-g6fdt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:06.097: INFO: Wrong image for pod: daemon-set-qxwst. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:06.097: INFO: Wrong image for pod: daemon-set-v8jmw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:06.097: INFO: Pod daemon-set-v8jmw is not available
Apr 30 15:22:07.097: INFO: Wrong image for pod: daemon-set-g6fdt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:07.097: INFO: Wrong image for pod: daemon-set-qxwst. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:07.097: INFO: Wrong image for pod: daemon-set-v8jmw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:07.097: INFO: Pod daemon-set-v8jmw is not available
Apr 30 15:22:08.097: INFO: Wrong image for pod: daemon-set-g6fdt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:08.097: INFO: Wrong image for pod: daemon-set-qxwst. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:08.097: INFO: Wrong image for pod: daemon-set-v8jmw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:08.097: INFO: Pod daemon-set-v8jmw is not available
Apr 30 15:22:09.097: INFO: Wrong image for pod: daemon-set-g6fdt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:09.097: INFO: Wrong image for pod: daemon-set-qxwst. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:09.097: INFO: Wrong image for pod: daemon-set-v8jmw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:09.097: INFO: Pod daemon-set-v8jmw is not available
Apr 30 15:22:10.096: INFO: Wrong image for pod: daemon-set-g6fdt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:10.096: INFO: Wrong image for pod: daemon-set-qxwst. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:10.096: INFO: Wrong image for pod: daemon-set-v8jmw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:10.096: INFO: Pod daemon-set-v8jmw is not available
Apr 30 15:22:11.096: INFO: Wrong image for pod: daemon-set-g6fdt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:11.096: INFO: Wrong image for pod: daemon-set-qxwst. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:11.096: INFO: Wrong image for pod: daemon-set-v8jmw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:11.096: INFO: Pod daemon-set-v8jmw is not available
Apr 30 15:22:12.096: INFO: Wrong image for pod: daemon-set-g6fdt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:12.096: INFO: Wrong image for pod: daemon-set-qxwst. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:12.096: INFO: Wrong image for pod: daemon-set-v8jmw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:12.096: INFO: Pod daemon-set-v8jmw is not available
Apr 30 15:22:13.099: INFO: Pod daemon-set-692mc is not available
Apr 30 15:22:13.099: INFO: Wrong image for pod: daemon-set-g6fdt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:13.099: INFO: Wrong image for pod: daemon-set-qxwst. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:14.388: INFO: Pod daemon-set-692mc is not available
Apr 30 15:22:14.388: INFO: Wrong image for pod: daemon-set-g6fdt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:14.388: INFO: Wrong image for pod: daemon-set-qxwst. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:15.105: INFO: Pod daemon-set-692mc is not available
Apr 30 15:22:15.105: INFO: Wrong image for pod: daemon-set-g6fdt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:15.105: INFO: Wrong image for pod: daemon-set-qxwst. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:16.097: INFO: Wrong image for pod: daemon-set-g6fdt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:16.097: INFO: Wrong image for pod: daemon-set-qxwst. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:17.095: INFO: Wrong image for pod: daemon-set-g6fdt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:17.095: INFO: Pod daemon-set-g6fdt is not available
Apr 30 15:22:17.095: INFO: Wrong image for pod: daemon-set-qxwst. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:18.095: INFO: Pod daemon-set-mjf6z is not available
Apr 30 15:22:18.095: INFO: Wrong image for pod: daemon-set-qxwst. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:19.095: INFO: Pod daemon-set-mjf6z is not available
Apr 30 15:22:19.095: INFO: Wrong image for pod: daemon-set-qxwst. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:20.105: INFO: Pod daemon-set-mjf6z is not available
Apr 30 15:22:20.105: INFO: Wrong image for pod: daemon-set-qxwst. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:21.095: INFO: Wrong image for pod: daemon-set-qxwst. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:22.098: INFO: Wrong image for pod: daemon-set-qxwst. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:22.098: INFO: Pod daemon-set-qxwst is not available
Apr 30 15:22:23.098: INFO: Wrong image for pod: daemon-set-qxwst. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:23.098: INFO: Pod daemon-set-qxwst is not available
Apr 30 15:22:24.097: INFO: Wrong image for pod: daemon-set-qxwst. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:24.097: INFO: Pod daemon-set-qxwst is not available
Apr 30 15:22:25.097: INFO: Wrong image for pod: daemon-set-qxwst. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:25.098: INFO: Pod daemon-set-qxwst is not available
Apr 30 15:22:26.098: INFO: Wrong image for pod: daemon-set-qxwst. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:26.098: INFO: Pod daemon-set-qxwst is not available
Apr 30 15:22:27.101: INFO: Wrong image for pod: daemon-set-qxwst. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:27.101: INFO: Pod daemon-set-qxwst is not available
Apr 30 15:22:28.096: INFO: Wrong image for pod: daemon-set-qxwst. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 15:22:28.096: INFO: Pod daemon-set-qxwst is not available
Apr 30 15:22:29.096: INFO: Pod daemon-set-x88n6 is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Apr 30 15:22:29.110: INFO: Number of nodes with available pods: 2
Apr 30 15:22:29.110: INFO: Node fatih-test-default-pool-qlpd is running more than one daemon pod
Apr 30 15:22:30.117: INFO: Number of nodes with available pods: 2
Apr 30 15:22:30.117: INFO: Node fatih-test-default-pool-qlpd is running more than one daemon pod
Apr 30 15:22:31.118: INFO: Number of nodes with available pods: 3
Apr 30 15:22:31.118: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9331, will wait for the garbage collector to delete the pods
Apr 30 15:22:31.197: INFO: Deleting DaemonSet.extensions daemon-set took: 7.270669ms
Apr 30 15:22:31.697: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.224286ms
Apr 30 15:22:43.010: INFO: Number of nodes with available pods: 0
Apr 30 15:22:43.011: INFO: Number of running nodes: 0, number of available pods: 0
Apr 30 15:22:43.016: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9331/daemonsets","resourceVersion":"24503"},"items":null}

Apr 30 15:22:43.029: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9331/pods","resourceVersion":"24504"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:22:43.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9331" for this suite.
Apr 30 15:22:49.077: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:22:49.155: INFO: namespace daemonsets-9331 deletion completed in 6.111296003s

• [SLOW TEST:51.169 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:22:49.160: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Apr 30 15:22:55.281: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4442 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 30 15:22:55.281: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
Apr 30 15:22:55.484: INFO: Exec stderr: ""
Apr 30 15:22:55.484: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4442 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 30 15:22:55.484: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
Apr 30 15:22:55.692: INFO: Exec stderr: ""
Apr 30 15:22:55.692: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4442 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 30 15:22:55.692: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
Apr 30 15:22:55.890: INFO: Exec stderr: ""
Apr 30 15:22:55.890: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4442 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 30 15:22:55.891: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
Apr 30 15:22:56.100: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Apr 30 15:22:56.100: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4442 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 30 15:22:56.100: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
Apr 30 15:22:56.296: INFO: Exec stderr: ""
Apr 30 15:22:56.297: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4442 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 30 15:22:56.297: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
Apr 30 15:22:56.522: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Apr 30 15:22:56.522: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4442 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 30 15:22:56.522: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
Apr 30 15:22:56.713: INFO: Exec stderr: ""
Apr 30 15:22:56.713: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4442 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 30 15:22:56.713: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
Apr 30 15:22:56.956: INFO: Exec stderr: ""
Apr 30 15:22:56.956: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4442 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 30 15:22:56.956: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
Apr 30 15:22:57.224: INFO: Exec stderr: ""
Apr 30 15:22:57.224: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4442 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 30 15:22:57.224: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
Apr 30 15:22:57.465: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:22:57.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-4442" for this suite.
Apr 30 15:23:35.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:23:35.570: INFO: namespace e2e-kubelet-etc-hosts-4442 deletion completed in 38.09900501s

• [SLOW TEST:46.410 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:23:35.574: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:23:35.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3065" for this suite.
Apr 30 15:23:57.816: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:23:57.913: INFO: namespace kubelet-test-3065 deletion completed in 22.263981778s

• [SLOW TEST:22.339 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:23:57.913: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 30 15:23:57.950: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:24:02.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5720" for this suite.
Apr 30 15:24:40.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:24:40.150: INFO: namespace pods-5720 deletion completed in 38.144618837s

• [SLOW TEST:42.237 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:24:40.150: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-7268
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 30 15:24:40.179: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr 30 15:25:02.302: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.2.126:8080/dial?request=hostName&protocol=http&host=10.244.1.229&port=8080&tries=1'] Namespace:pod-network-test-7268 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 30 15:25:02.302: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
Apr 30 15:25:02.612: INFO: Waiting for endpoints: map[]
Apr 30 15:25:02.614: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.2.126:8080/dial?request=hostName&protocol=http&host=10.244.0.136&port=8080&tries=1'] Namespace:pod-network-test-7268 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 30 15:25:02.615: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
Apr 30 15:25:03.037: INFO: Waiting for endpoints: map[]
Apr 30 15:25:03.042: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.2.126:8080/dial?request=hostName&protocol=http&host=10.244.2.133&port=8080&tries=1'] Namespace:pod-network-test-7268 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 30 15:25:03.042: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
Apr 30 15:25:03.310: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:25:03.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7268" for this suite.
Apr 30 15:25:25.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:25:25.398: INFO: namespace pod-network-test-7268 deletion completed in 22.080768955s

• [SLOW TEST:45.249 seconds]
[sig-network] Networking
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:25:25.407: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-2d6679f2-6b5c-11e9-b570-225b9ad5bed0
STEP: Creating a pod to test consume configMaps
Apr 30 15:25:25.456: INFO: Waiting up to 5m0s for pod "pod-configmaps-2d6865db-6b5c-11e9-b570-225b9ad5bed0" in namespace "configmap-6860" to be "success or failure"
Apr 30 15:25:25.469: INFO: Pod "pod-configmaps-2d6865db-6b5c-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 11.872744ms
Apr 30 15:25:27.476: INFO: Pod "pod-configmaps-2d6865db-6b5c-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019249239s
STEP: Saw pod success
Apr 30 15:25:27.476: INFO: Pod "pod-configmaps-2d6865db-6b5c-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 15:25:27.482: INFO: Trying to get logs from node fatih-test-default-pool-qlpd pod pod-configmaps-2d6865db-6b5c-11e9-b570-225b9ad5bed0 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 30 15:25:27.509: INFO: Waiting for pod pod-configmaps-2d6865db-6b5c-11e9-b570-225b9ad5bed0 to disappear
Apr 30 15:25:27.515: INFO: Pod pod-configmaps-2d6865db-6b5c-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:25:27.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6860" for this suite.
Apr 30 15:25:33.534: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:25:33.601: INFO: namespace configmap-6860 deletion completed in 6.080591943s

• [SLOW TEST:8.194 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:25:33.607: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: executing a command with run --rm and attach with stdin
Apr 30 15:25:33.637: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-566523788 --namespace=kubectl-6227 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Apr 30 15:25:36.278: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Apr 30 15:25:36.279: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:25:38.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6227" for this suite.
Apr 30 15:25:44.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:25:44.367: INFO: namespace kubectl-6227 deletion completed in 6.079454805s

• [SLOW TEST:10.761 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:25:44.371: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 30 15:25:44.401: INFO: (0) /api/v1/nodes/fatih-test-default-pool-qlp0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.036111ms)
Apr 30 15:25:44.404: INFO: (1) /api/v1/nodes/fatih-test-default-pool-qlp0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.582285ms)
Apr 30 15:25:44.406: INFO: (2) /api/v1/nodes/fatih-test-default-pool-qlp0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.565103ms)
Apr 30 15:25:44.409: INFO: (3) /api/v1/nodes/fatih-test-default-pool-qlp0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.844168ms)
Apr 30 15:25:44.412: INFO: (4) /api/v1/nodes/fatih-test-default-pool-qlp0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.741349ms)
Apr 30 15:25:44.415: INFO: (5) /api/v1/nodes/fatih-test-default-pool-qlp0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.697922ms)
Apr 30 15:25:44.418: INFO: (6) /api/v1/nodes/fatih-test-default-pool-qlp0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.664133ms)
Apr 30 15:25:44.421: INFO: (7) /api/v1/nodes/fatih-test-default-pool-qlp0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.766353ms)
Apr 30 15:25:44.424: INFO: (8) /api/v1/nodes/fatih-test-default-pool-qlp0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.724736ms)
Apr 30 15:25:44.427: INFO: (9) /api/v1/nodes/fatih-test-default-pool-qlp0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.706444ms)
Apr 30 15:25:44.430: INFO: (10) /api/v1/nodes/fatih-test-default-pool-qlp0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.699793ms)
Apr 30 15:25:44.433: INFO: (11) /api/v1/nodes/fatih-test-default-pool-qlp0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.745428ms)
Apr 30 15:25:44.436: INFO: (12) /api/v1/nodes/fatih-test-default-pool-qlp0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.164908ms)
Apr 30 15:25:44.445: INFO: (13) /api/v1/nodes/fatih-test-default-pool-qlp0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 8.126456ms)
Apr 30 15:25:44.447: INFO: (14) /api/v1/nodes/fatih-test-default-pool-qlp0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.587832ms)
Apr 30 15:25:44.450: INFO: (15) /api/v1/nodes/fatih-test-default-pool-qlp0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.644174ms)
Apr 30 15:25:44.453: INFO: (16) /api/v1/nodes/fatih-test-default-pool-qlp0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.488519ms)
Apr 30 15:25:44.457: INFO: (17) /api/v1/nodes/fatih-test-default-pool-qlp0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.4274ms)
Apr 30 15:25:44.459: INFO: (18) /api/v1/nodes/fatih-test-default-pool-qlp0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.685047ms)
Apr 30 15:25:44.462: INFO: (19) /api/v1/nodes/fatih-test-default-pool-qlp0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.573313ms)
[AfterEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:25:44.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-4062" for this suite.
Apr 30 15:25:50.478: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:25:50.545: INFO: namespace proxy-4062 deletion completed in 6.07984649s

• [SLOW TEST:6.174 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:25:50.551: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Apr 30 15:25:50.658: INFO: Waiting up to 5m0s for pod "pod-3c6e217b-6b5c-11e9-b570-225b9ad5bed0" in namespace "emptydir-5246" to be "success or failure"
Apr 30 15:25:50.663: INFO: Pod "pod-3c6e217b-6b5c-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.56613ms
Apr 30 15:25:52.745: INFO: Pod "pod-3c6e217b-6b5c-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.086564119s
Apr 30 15:25:54.749: INFO: Pod "pod-3c6e217b-6b5c-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.091178059s
STEP: Saw pod success
Apr 30 15:25:54.749: INFO: Pod "pod-3c6e217b-6b5c-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 15:25:54.754: INFO: Trying to get logs from node fatih-test-default-pool-qlp1 pod pod-3c6e217b-6b5c-11e9-b570-225b9ad5bed0 container test-container: <nil>
STEP: delete the pod
Apr 30 15:25:54.773: INFO: Waiting for pod pod-3c6e217b-6b5c-11e9-b570-225b9ad5bed0 to disappear
Apr 30 15:25:54.776: INFO: Pod pod-3c6e217b-6b5c-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:25:54.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5246" for this suite.
Apr 30 15:26:00.798: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:26:00.868: INFO: namespace emptydir-5246 deletion completed in 6.088642177s

• [SLOW TEST:10.318 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:26:00.870: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 30 15:26:00.981: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"428b4255-6b5c-11e9-a241-32cef6bf8510", Controller:(*bool)(0xc0004bb476), BlockOwnerDeletion:(*bool)(0xc0004bb477)}}
Apr 30 15:26:00.992: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"42889e4b-6b5c-11e9-a241-32cef6bf8510", Controller:(*bool)(0xc0004bb6ee), BlockOwnerDeletion:(*bool)(0xc0004bb6ef)}}
Apr 30 15:26:00.995: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"42892a7d-6b5c-11e9-a241-32cef6bf8510", Controller:(*bool)(0xc0004bb93e), BlockOwnerDeletion:(*bool)(0xc0004bb93f)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:26:06.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6695" for this suite.
Apr 30 15:26:12.018: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:26:12.102: INFO: namespace gc-6695 deletion completed in 6.094695674s

• [SLOW TEST:11.232 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:26:12.105: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-493b9b29-6b5c-11e9-b570-225b9ad5bed0
STEP: Creating a pod to test consume secrets
Apr 30 15:26:12.140: INFO: Waiting up to 5m0s for pod "pod-secrets-493c17fd-6b5c-11e9-b570-225b9ad5bed0" in namespace "secrets-5888" to be "success or failure"
Apr 30 15:26:12.153: INFO: Pod "pod-secrets-493c17fd-6b5c-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 13.343932ms
Apr 30 15:26:14.158: INFO: Pod "pod-secrets-493c17fd-6b5c-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017995491s
Apr 30 15:26:16.162: INFO: Pod "pod-secrets-493c17fd-6b5c-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021891236s
STEP: Saw pod success
Apr 30 15:26:16.162: INFO: Pod "pod-secrets-493c17fd-6b5c-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 15:26:16.165: INFO: Trying to get logs from node fatih-test-default-pool-qlpd pod pod-secrets-493c17fd-6b5c-11e9-b570-225b9ad5bed0 container secret-volume-test: <nil>
STEP: delete the pod
Apr 30 15:26:16.187: INFO: Waiting for pod pod-secrets-493c17fd-6b5c-11e9-b570-225b9ad5bed0 to disappear
Apr 30 15:26:16.199: INFO: Pod pod-secrets-493c17fd-6b5c-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:26:16.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5888" for this suite.
Apr 30 15:26:22.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:26:22.281: INFO: namespace secrets-5888 deletion completed in 6.077371154s

• [SLOW TEST:10.176 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:26:22.286: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service multi-endpoint-test in namespace services-6982
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-6982 to expose endpoints map[]
Apr 30 15:26:22.334: INFO: successfully validated that service multi-endpoint-test in namespace services-6982 exposes endpoints map[] (10.062771ms elapsed)
STEP: Creating pod pod1 in namespace services-6982
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-6982 to expose endpoints map[pod1:[100]]
Apr 30 15:26:25.389: INFO: successfully validated that service multi-endpoint-test in namespace services-6982 exposes endpoints map[pod1:[100]] (3.04567851s elapsed)
STEP: Creating pod pod2 in namespace services-6982
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-6982 to expose endpoints map[pod1:[100] pod2:[101]]
Apr 30 15:26:29.449: INFO: successfully validated that service multi-endpoint-test in namespace services-6982 exposes endpoints map[pod1:[100] pod2:[101]] (4.050629193s elapsed)
STEP: Deleting pod pod1 in namespace services-6982
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-6982 to expose endpoints map[pod2:[101]]
Apr 30 15:26:29.478: INFO: successfully validated that service multi-endpoint-test in namespace services-6982 exposes endpoints map[pod2:[101]] (23.106282ms elapsed)
STEP: Deleting pod pod2 in namespace services-6982
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-6982 to expose endpoints map[]
Apr 30 15:26:29.500: INFO: successfully validated that service multi-endpoint-test in namespace services-6982 exposes endpoints map[] (13.498251ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:26:29.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6982" for this suite.
Apr 30 15:26:51.566: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:26:51.636: INFO: namespace services-6982 deletion completed in 22.084339798s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:29.351 seconds]
[sig-network] Services
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:26:51.639: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 30 15:26:51.678: INFO: Waiting up to 5m0s for pod "downwardapi-volume-60ccb05b-6b5c-11e9-b570-225b9ad5bed0" in namespace "downward-api-3426" to be "success or failure"
Apr 30 15:26:51.685: INFO: Pod "downwardapi-volume-60ccb05b-6b5c-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 7.026638ms
Apr 30 15:26:53.689: INFO: Pod "downwardapi-volume-60ccb05b-6b5c-11e9-b570-225b9ad5bed0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010669272s
Apr 30 15:26:55.692: INFO: Pod "downwardapi-volume-60ccb05b-6b5c-11e9-b570-225b9ad5bed0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014320073s
STEP: Saw pod success
Apr 30 15:26:55.692: INFO: Pod "downwardapi-volume-60ccb05b-6b5c-11e9-b570-225b9ad5bed0" satisfied condition "success or failure"
Apr 30 15:26:55.696: INFO: Trying to get logs from node fatih-test-default-pool-qlpd pod downwardapi-volume-60ccb05b-6b5c-11e9-b570-225b9ad5bed0 container client-container: <nil>
STEP: delete the pod
Apr 30 15:26:55.725: INFO: Waiting for pod downwardapi-volume-60ccb05b-6b5c-11e9-b570-225b9ad5bed0 to disappear
Apr 30 15:26:55.732: INFO: Pod downwardapi-volume-60ccb05b-6b5c-11e9-b570-225b9ad5bed0 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:26:55.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3426" for this suite.
Apr 30 15:27:01.746: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:27:01.823: INFO: namespace downward-api-3426 deletion completed in 6.087618334s

• [SLOW TEST:10.185 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:27:01.826: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-66def910-6b5c-11e9-b570-225b9ad5bed0
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:27:05.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8792" for this suite.
Apr 30 15:27:27.932: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:27:27.997: INFO: namespace configmap-8792 deletion completed in 22.077391248s

• [SLOW TEST:26.171 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 15:27:28.000: INFO: >>> kubeConfig: /tmp/kubeconfig-566523788
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-7678b0ed-6b5c-11e9-b570-225b9ad5bed0
STEP: Creating secret with name s-test-opt-upd-7678b12b-6b5c-11e9-b570-225b9ad5bed0
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-7678b0ed-6b5c-11e9-b570-225b9ad5bed0
STEP: Updating secret s-test-opt-upd-7678b12b-6b5c-11e9-b570-225b9ad5bed0
STEP: Creating secret with name s-test-opt-create-7678b142-6b5c-11e9-b570-225b9ad5bed0
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 15:27:36.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-149" for this suite.
Apr 30 15:27:58.151: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 15:27:58.220: INFO: namespace secrets-149 deletion completed in 22.079163508s

• [SLOW TEST:30.221 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSApr 30 15:27:58.224: INFO: Running AfterSuite actions on all nodes
Apr 30 15:27:58.225: INFO: Running AfterSuite actions on node 1
Apr 30 15:27:58.225: INFO: Skipping dumping logs from cluster

Ran 204 of 3584 Specs in 5517.218 seconds
SUCCESS! -- 204 Passed | 0 Failed | 0 Pending | 3380 Skipped PASS

Ginkgo ran 1 suite in 1h32m0.802353584s
Test Suite Passed
