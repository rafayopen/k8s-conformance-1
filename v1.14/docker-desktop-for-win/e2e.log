I0503 12:07:19.603803      15 test_context.go:405] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-343589126
I0503 12:07:19.604009      15 e2e.go:240] Starting e2e run "ff92cc19-6d9b-11e9-a622-a62f37ba3446" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1556885238 - Will randomize all specs
Will run 204 of 3584 specs

May  3 12:07:19.774: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
May  3 12:07:19.776: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
May  3 12:07:19.784: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
May  3 12:07:19.809: INFO: 7 / 7 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
May  3 12:07:19.809: INFO: expected 2 pod replicas in namespace 'kube-system', 2 are Running and Ready.
May  3 12:07:19.809: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
May  3 12:07:19.814: INFO: 1 / 1 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
May  3 12:07:19.814: INFO: e2e test version: v1.14.1
May  3 12:07:19.815: INFO: kube-apiserver version: v1.14.1
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:07:19.816: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename svcaccounts
May  3 12:07:19.848: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
May  3 12:07:20.390: INFO: created pod pod-service-account-defaultsa
May  3 12:07:20.391: INFO: pod pod-service-account-defaultsa service account token volume mount: true
May  3 12:07:20.414: INFO: created pod pod-service-account-mountsa
May  3 12:07:20.416: INFO: pod pod-service-account-mountsa service account token volume mount: true
May  3 12:07:20.422: INFO: created pod pod-service-account-nomountsa
May  3 12:07:20.422: INFO: pod pod-service-account-nomountsa service account token volume mount: false
May  3 12:07:20.439: INFO: created pod pod-service-account-defaultsa-mountspec
May  3 12:07:20.439: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
May  3 12:07:20.457: INFO: created pod pod-service-account-mountsa-mountspec
May  3 12:07:20.457: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
May  3 12:07:20.474: INFO: created pod pod-service-account-nomountsa-mountspec
May  3 12:07:20.474: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
May  3 12:07:20.499: INFO: created pod pod-service-account-defaultsa-nomountspec
May  3 12:07:20.500: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
May  3 12:07:20.513: INFO: created pod pod-service-account-mountsa-nomountspec
May  3 12:07:20.513: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
May  3 12:07:20.533: INFO: created pod pod-service-account-nomountsa-nomountspec
May  3 12:07:20.533: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:07:20.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-8614" for this suite.
May  3 12:07:42.602: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:07:42.702: INFO: namespace svcaccounts-8614 deletion completed in 22.1391927s

• [SLOW TEST:22.886 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:07:42.702: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May  3 12:07:42.733: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0de9c53c-6d9c-11e9-a622-a62f37ba3446" in namespace "downward-api-8662" to be "success or failure"
May  3 12:07:42.736: INFO: Pod "downwardapi-volume-0de9c53c-6d9c-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 2.9751ms
May  3 12:07:44.757: INFO: Pod "downwardapi-volume-0de9c53c-6d9c-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0239396s
STEP: Saw pod success
May  3 12:07:44.757: INFO: Pod "downwardapi-volume-0de9c53c-6d9c-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 12:07:44.759: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-0de9c53c-6d9c-11e9-a622-a62f37ba3446 container client-container: <nil>
STEP: delete the pod
May  3 12:07:44.790: INFO: Waiting for pod downwardapi-volume-0de9c53c-6d9c-11e9-a622-a62f37ba3446 to disappear
May  3 12:07:44.793: INFO: Pod downwardapi-volume-0de9c53c-6d9c-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:07:44.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8662" for this suite.
May  3 12:07:50.809: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:07:50.895: INFO: namespace downward-api-8662 deletion completed in 6.0995802s

• [SLOW TEST:8.193 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:07:50.896: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-projected-jfcr
STEP: Creating a pod to test atomic-volume-subpath
May  3 12:07:50.931: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-jfcr" in namespace "subpath-5591" to be "success or failure"
May  3 12:07:50.938: INFO: Pod "pod-subpath-test-projected-jfcr": Phase="Pending", Reason="", readiness=false. Elapsed: 6.6668ms
May  3 12:07:52.940: INFO: Pod "pod-subpath-test-projected-jfcr": Phase="Running", Reason="", readiness=true. Elapsed: 2.0090288s
May  3 12:07:54.948: INFO: Pod "pod-subpath-test-projected-jfcr": Phase="Running", Reason="", readiness=true. Elapsed: 4.016891s
May  3 12:07:56.952: INFO: Pod "pod-subpath-test-projected-jfcr": Phase="Running", Reason="", readiness=true. Elapsed: 6.0209205s
May  3 12:07:58.957: INFO: Pod "pod-subpath-test-projected-jfcr": Phase="Running", Reason="", readiness=true. Elapsed: 8.025539s
May  3 12:08:00.964: INFO: Pod "pod-subpath-test-projected-jfcr": Phase="Running", Reason="", readiness=true. Elapsed: 10.0330951s
May  3 12:08:02.968: INFO: Pod "pod-subpath-test-projected-jfcr": Phase="Running", Reason="", readiness=true. Elapsed: 12.0372781s
May  3 12:08:04.971: INFO: Pod "pod-subpath-test-projected-jfcr": Phase="Running", Reason="", readiness=true. Elapsed: 14.0401031s
May  3 12:08:06.976: INFO: Pod "pod-subpath-test-projected-jfcr": Phase="Running", Reason="", readiness=true. Elapsed: 16.0449719s
May  3 12:08:08.980: INFO: Pod "pod-subpath-test-projected-jfcr": Phase="Running", Reason="", readiness=true. Elapsed: 18.0494716s
May  3 12:08:10.985: INFO: Pod "pod-subpath-test-projected-jfcr": Phase="Running", Reason="", readiness=true. Elapsed: 20.054144s
May  3 12:08:12.989: INFO: Pod "pod-subpath-test-projected-jfcr": Phase="Running", Reason="", readiness=true. Elapsed: 22.0580731s
May  3 12:08:14.993: INFO: Pod "pod-subpath-test-projected-jfcr": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.0623023s
STEP: Saw pod success
May  3 12:08:14.993: INFO: Pod "pod-subpath-test-projected-jfcr" satisfied condition "success or failure"
May  3 12:08:14.997: INFO: Trying to get logs from node docker-desktop pod pod-subpath-test-projected-jfcr container test-container-subpath-projected-jfcr: <nil>
STEP: delete the pod
May  3 12:08:15.031: INFO: Waiting for pod pod-subpath-test-projected-jfcr to disappear
May  3 12:08:15.035: INFO: Pod pod-subpath-test-projected-jfcr no longer exists
STEP: Deleting pod pod-subpath-test-projected-jfcr
May  3 12:08:15.035: INFO: Deleting pod "pod-subpath-test-projected-jfcr" in namespace "subpath-5591"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:08:15.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5591" for this suite.
May  3 12:08:21.053: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:08:21.144: INFO: namespace subpath-5591 deletion completed in 6.1043742s

• [SLOW TEST:30.248 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:08:21.145: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating pod
May  3 12:08:25.193: INFO: Pod pod-hostip-24d394d1-6d9c-11e9-a622-a62f37ba3446 has hostIP: 192.168.65.3
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:08:25.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3112" for this suite.
May  3 12:08:47.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:08:47.298: INFO: namespace pods-3112 deletion completed in 22.1004623s

• [SLOW TEST:26.153 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:08:47.298: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-2699
May  3 12:08:53.349: INFO: Started pod liveness-exec in namespace container-probe-2699
STEP: checking the pod's current state and verifying that restartCount is present
May  3 12:08:53.353: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:12:54.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2699" for this suite.
May  3 12:13:00.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:13:00.231: INFO: namespace container-probe-2699 deletion completed in 6.1292036s

• [SLOW TEST:252.934 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:13:00.232: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-cb2d5886-6d9c-11e9-a622-a62f37ba3446
STEP: Creating configMap with name cm-test-opt-upd-cb2d58bb-6d9c-11e9-a622-a62f37ba3446
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-cb2d5886-6d9c-11e9-a622-a62f37ba3446
STEP: Updating configmap cm-test-opt-upd-cb2d58bb-6d9c-11e9-a622-a62f37ba3446
STEP: Creating configMap with name cm-test-opt-create-cb2d58ce-6d9c-11e9-a622-a62f37ba3446
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:14:13.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2185" for this suite.
May  3 12:14:35.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:14:35.124: INFO: namespace configmap-2185 deletion completed in 22.1057772s

• [SLOW TEST:94.893 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:14:35.125: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-5458
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May  3 12:14:35.206: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May  3 12:14:55.310: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.1.0.21 8081 | grep -v '^\s*$'] Namespace:pod-network-test-5458 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May  3 12:14:55.310: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
May  3 12:14:56.465: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:14:56.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5458" for this suite.
May  3 12:15:18.479: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:15:18.563: INFO: namespace pod-network-test-5458 deletion completed in 22.0958366s

• [SLOW TEST:43.438 seconds]
[sig-network] Networking
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:15:18.564: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
May  3 12:15:22.669: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May  3 12:15:22.672: INFO: Pod pod-with-poststart-http-hook still exists
May  3 12:15:24.672: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May  3 12:15:24.674: INFO: Pod pod-with-poststart-http-hook still exists
May  3 12:15:26.672: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May  3 12:15:26.674: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:15:26.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9967" for this suite.
May  3 12:15:48.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:15:48.780: INFO: namespace container-lifecycle-hook-9967 deletion completed in 22.1034014s

• [SLOW TEST:30.216 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:15:48.780: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-2fa32f47-6d9d-11e9-a622-a62f37ba3446
STEP: Creating a pod to test consume secrets
May  3 12:15:48.810: INFO: Waiting up to 5m0s for pod "pod-secrets-2fa394ef-6d9d-11e9-a622-a62f37ba3446" in namespace "secrets-7461" to be "success or failure"
May  3 12:15:48.818: INFO: Pod "pod-secrets-2fa394ef-6d9d-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 8.1153ms
May  3 12:15:50.823: INFO: Pod "pod-secrets-2fa394ef-6d9d-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0133018s
May  3 12:15:52.837: INFO: Pod "pod-secrets-2fa394ef-6d9d-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0270681s
STEP: Saw pod success
May  3 12:15:52.837: INFO: Pod "pod-secrets-2fa394ef-6d9d-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 12:15:52.846: INFO: Trying to get logs from node docker-desktop pod pod-secrets-2fa394ef-6d9d-11e9-a622-a62f37ba3446 container secret-env-test: <nil>
STEP: delete the pod
May  3 12:15:52.869: INFO: Waiting for pod pod-secrets-2fa394ef-6d9d-11e9-a622-a62f37ba3446 to disappear
May  3 12:15:52.879: INFO: Pod pod-secrets-2fa394ef-6d9d-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:15:52.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7461" for this suite.
May  3 12:15:58.889: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:15:58.981: INFO: namespace secrets-7461 deletion completed in 6.1007587s

• [SLOW TEST:10.201 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:15:58.982: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0503 12:16:29.530261      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May  3 12:16:29.530: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:16:29.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6865" for this suite.
May  3 12:16:35.541: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:16:35.611: INFO: namespace gc-6865 deletion completed in 6.0780357s

• [SLOW TEST:36.629 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:16:35.612: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-6923
May  3 12:16:39.716: INFO: Started pod liveness-exec in namespace container-probe-6923
STEP: checking the pod's current state and verifying that restartCount is present
May  3 12:16:39.723: INFO: Initial restart count of pod liveness-exec is 0
May  3 12:17:27.861: INFO: Restart count of pod container-probe-6923/liveness-exec is now 1 (48.1379531s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:17:27.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6923" for this suite.
May  3 12:17:33.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:17:34.002: INFO: namespace container-probe-6923 deletion completed in 6.111747s

• [SLOW TEST:58.391 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:17:34.004: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
May  3 12:17:34.056: INFO: Number of nodes with available pods: 0
May  3 12:17:34.056: INFO: Node docker-desktop is running more than one daemon pod
May  3 12:17:35.089: INFO: Number of nodes with available pods: 0
May  3 12:17:35.089: INFO: Node docker-desktop is running more than one daemon pod
May  3 12:17:36.065: INFO: Number of nodes with available pods: 0
May  3 12:17:36.065: INFO: Node docker-desktop is running more than one daemon pod
May  3 12:17:37.064: INFO: Number of nodes with available pods: 1
May  3 12:17:37.064: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Stop a daemon pod, check that the daemon pod is revived.
May  3 12:17:37.095: INFO: Number of nodes with available pods: 0
May  3 12:17:37.095: INFO: Node docker-desktop is running more than one daemon pod
May  3 12:17:38.112: INFO: Number of nodes with available pods: 0
May  3 12:17:38.112: INFO: Node docker-desktop is running more than one daemon pod
May  3 12:17:39.100: INFO: Number of nodes with available pods: 0
May  3 12:17:39.100: INFO: Node docker-desktop is running more than one daemon pod
May  3 12:17:40.109: INFO: Number of nodes with available pods: 0
May  3 12:17:40.109: INFO: Node docker-desktop is running more than one daemon pod
May  3 12:17:41.110: INFO: Number of nodes with available pods: 0
May  3 12:17:41.110: INFO: Node docker-desktop is running more than one daemon pod
May  3 12:17:42.111: INFO: Number of nodes with available pods: 0
May  3 12:17:42.111: INFO: Node docker-desktop is running more than one daemon pod
May  3 12:17:43.104: INFO: Number of nodes with available pods: 0
May  3 12:17:43.105: INFO: Node docker-desktop is running more than one daemon pod
May  3 12:17:44.102: INFO: Number of nodes with available pods: 0
May  3 12:17:44.102: INFO: Node docker-desktop is running more than one daemon pod
May  3 12:17:45.110: INFO: Number of nodes with available pods: 0
May  3 12:17:45.111: INFO: Node docker-desktop is running more than one daemon pod
May  3 12:17:46.114: INFO: Number of nodes with available pods: 0
May  3 12:17:46.114: INFO: Node docker-desktop is running more than one daemon pod
May  3 12:17:47.099: INFO: Number of nodes with available pods: 0
May  3 12:17:47.099: INFO: Node docker-desktop is running more than one daemon pod
May  3 12:17:48.110: INFO: Number of nodes with available pods: 0
May  3 12:17:48.110: INFO: Node docker-desktop is running more than one daemon pod
May  3 12:17:49.108: INFO: Number of nodes with available pods: 1
May  3 12:17:49.108: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8607, will wait for the garbage collector to delete the pods
May  3 12:17:49.177: INFO: Deleting DaemonSet.extensions daemon-set took: 5.71ms
May  3 12:17:49.577: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.243ms
May  3 12:17:52.480: INFO: Number of nodes with available pods: 0
May  3 12:17:52.480: INFO: Number of running nodes: 0, number of available pods: 0
May  3 12:17:52.483: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8607/daemonsets","resourceVersion":"8518"},"items":null}

May  3 12:17:52.484: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8607/pods","resourceVersion":"8518"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:17:52.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8607" for this suite.
May  3 12:17:58.498: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:17:58.610: INFO: namespace daemonsets-8607 deletion completed in 6.1197738s

• [SLOW TEST:24.606 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:17:58.610: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May  3 12:17:58.645: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7d06475c-6d9d-11e9-a622-a62f37ba3446" in namespace "downward-api-5006" to be "success or failure"
May  3 12:17:58.663: INFO: Pod "downwardapi-volume-7d06475c-6d9d-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 18.4438ms
May  3 12:18:00.666: INFO: Pod "downwardapi-volume-7d06475c-6d9d-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020828s
STEP: Saw pod success
May  3 12:18:00.666: INFO: Pod "downwardapi-volume-7d06475c-6d9d-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 12:18:00.670: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-7d06475c-6d9d-11e9-a622-a62f37ba3446 container client-container: <nil>
STEP: delete the pod
May  3 12:18:00.766: INFO: Waiting for pod downwardapi-volume-7d06475c-6d9d-11e9-a622-a62f37ba3446 to disappear
May  3 12:18:00.768: INFO: Pod downwardapi-volume-7d06475c-6d9d-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:18:00.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5006" for this suite.
May  3 12:18:06.784: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:18:06.869: INFO: namespace downward-api-5006 deletion completed in 6.0994866s

• [SLOW TEST:8.259 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:18:06.870: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
May  3 12:18:06.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 create -f - --namespace=kubectl-546'
May  3 12:18:07.427: INFO: stderr: ""
May  3 12:18:07.427: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May  3 12:18:07.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-546'
May  3 12:18:07.538: INFO: stderr: ""
May  3 12:18:07.538: INFO: stdout: "update-demo-nautilus-mc95n update-demo-nautilus-xfw5f "
May  3 12:18:07.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pods update-demo-nautilus-mc95n -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-546'
May  3 12:18:07.602: INFO: stderr: ""
May  3 12:18:07.602: INFO: stdout: ""
May  3 12:18:07.602: INFO: update-demo-nautilus-mc95n is created but not running
May  3 12:18:12.602: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-546'
May  3 12:18:12.703: INFO: stderr: ""
May  3 12:18:12.703: INFO: stdout: "update-demo-nautilus-mc95n update-demo-nautilus-xfw5f "
May  3 12:18:12.703: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pods update-demo-nautilus-mc95n -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-546'
May  3 12:18:12.762: INFO: stderr: ""
May  3 12:18:12.762: INFO: stdout: "true"
May  3 12:18:12.762: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pods update-demo-nautilus-mc95n -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-546'
May  3 12:18:12.821: INFO: stderr: ""
May  3 12:18:12.821: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May  3 12:18:12.821: INFO: validating pod update-demo-nautilus-mc95n
May  3 12:18:12.823: INFO: got data: {
  "image": "nautilus.jpg"
}

May  3 12:18:12.823: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May  3 12:18:12.823: INFO: update-demo-nautilus-mc95n is verified up and running
May  3 12:18:12.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pods update-demo-nautilus-xfw5f -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-546'
May  3 12:18:12.883: INFO: stderr: ""
May  3 12:18:12.883: INFO: stdout: "true"
May  3 12:18:12.883: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pods update-demo-nautilus-xfw5f -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-546'
May  3 12:18:12.941: INFO: stderr: ""
May  3 12:18:12.941: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May  3 12:18:12.941: INFO: validating pod update-demo-nautilus-xfw5f
May  3 12:18:12.944: INFO: got data: {
  "image": "nautilus.jpg"
}

May  3 12:18:12.944: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May  3 12:18:12.944: INFO: update-demo-nautilus-xfw5f is verified up and running
STEP: scaling down the replication controller
May  3 12:18:12.945: INFO: scanned /root for discovery docs: <nil>
May  3 12:18:12.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-546'
May  3 12:18:14.025: INFO: stderr: ""
May  3 12:18:14.025: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May  3 12:18:14.025: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-546'
May  3 12:18:14.100: INFO: stderr: ""
May  3 12:18:14.101: INFO: stdout: "update-demo-nautilus-mc95n update-demo-nautilus-xfw5f "
STEP: Replicas for name=update-demo: expected=1 actual=2
May  3 12:18:19.101: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-546'
May  3 12:18:19.184: INFO: stderr: ""
May  3 12:18:19.184: INFO: stdout: "update-demo-nautilus-mc95n update-demo-nautilus-xfw5f "
STEP: Replicas for name=update-demo: expected=1 actual=2
May  3 12:18:24.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-546'
May  3 12:18:24.278: INFO: stderr: ""
May  3 12:18:24.278: INFO: stdout: "update-demo-nautilus-mc95n update-demo-nautilus-xfw5f "
STEP: Replicas for name=update-demo: expected=1 actual=2
May  3 12:18:29.279: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-546'
May  3 12:18:29.396: INFO: stderr: ""
May  3 12:18:29.396: INFO: stdout: "update-demo-nautilus-xfw5f "
May  3 12:18:29.396: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pods update-demo-nautilus-xfw5f -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-546'
May  3 12:18:29.508: INFO: stderr: ""
May  3 12:18:29.508: INFO: stdout: "true"
May  3 12:18:29.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pods update-demo-nautilus-xfw5f -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-546'
May  3 12:18:29.574: INFO: stderr: ""
May  3 12:18:29.574: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May  3 12:18:29.574: INFO: validating pod update-demo-nautilus-xfw5f
May  3 12:18:29.576: INFO: got data: {
  "image": "nautilus.jpg"
}

May  3 12:18:29.577: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May  3 12:18:29.577: INFO: update-demo-nautilus-xfw5f is verified up and running
STEP: scaling up the replication controller
May  3 12:18:29.578: INFO: scanned /root for discovery docs: <nil>
May  3 12:18:29.578: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-546'
May  3 12:18:30.694: INFO: stderr: ""
May  3 12:18:30.694: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May  3 12:18:30.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-546'
May  3 12:18:30.791: INFO: stderr: ""
May  3 12:18:30.791: INFO: stdout: "update-demo-nautilus-g78sp update-demo-nautilus-xfw5f "
May  3 12:18:30.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pods update-demo-nautilus-g78sp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-546'
May  3 12:18:30.883: INFO: stderr: ""
May  3 12:18:30.883: INFO: stdout: ""
May  3 12:18:30.883: INFO: update-demo-nautilus-g78sp is created but not running
May  3 12:18:35.883: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-546'
May  3 12:18:35.967: INFO: stderr: ""
May  3 12:18:35.967: INFO: stdout: "update-demo-nautilus-g78sp update-demo-nautilus-xfw5f "
May  3 12:18:35.967: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pods update-demo-nautilus-g78sp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-546'
May  3 12:18:36.032: INFO: stderr: ""
May  3 12:18:36.032: INFO: stdout: "true"
May  3 12:18:36.032: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pods update-demo-nautilus-g78sp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-546'
May  3 12:18:36.090: INFO: stderr: ""
May  3 12:18:36.090: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May  3 12:18:36.090: INFO: validating pod update-demo-nautilus-g78sp
May  3 12:18:36.093: INFO: got data: {
  "image": "nautilus.jpg"
}

May  3 12:18:36.093: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May  3 12:18:36.093: INFO: update-demo-nautilus-g78sp is verified up and running
May  3 12:18:36.093: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pods update-demo-nautilus-xfw5f -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-546'
May  3 12:18:36.152: INFO: stderr: ""
May  3 12:18:36.152: INFO: stdout: "true"
May  3 12:18:36.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pods update-demo-nautilus-xfw5f -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-546'
May  3 12:18:36.218: INFO: stderr: ""
May  3 12:18:36.218: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May  3 12:18:36.218: INFO: validating pod update-demo-nautilus-xfw5f
May  3 12:18:36.220: INFO: got data: {
  "image": "nautilus.jpg"
}

May  3 12:18:36.220: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May  3 12:18:36.220: INFO: update-demo-nautilus-xfw5f is verified up and running
STEP: using delete to clean up resources
May  3 12:18:36.220: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 delete --grace-period=0 --force -f - --namespace=kubectl-546'
May  3 12:18:36.296: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May  3 12:18:36.296: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
May  3 12:18:36.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-546'
May  3 12:18:36.373: INFO: stderr: "No resources found.\n"
May  3 12:18:36.373: INFO: stdout: ""
May  3 12:18:36.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pods -l name=update-demo --namespace=kubectl-546 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May  3 12:18:36.436: INFO: stderr: ""
May  3 12:18:36.436: INFO: stdout: "update-demo-nautilus-g78sp\nupdate-demo-nautilus-xfw5f\n"
May  3 12:18:36.960: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-546'
May  3 12:18:37.037: INFO: stderr: "No resources found.\n"
May  3 12:18:37.037: INFO: stdout: ""
May  3 12:18:37.037: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pods -l name=update-demo --namespace=kubectl-546 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May  3 12:18:37.149: INFO: stderr: ""
May  3 12:18:37.149: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:18:37.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-546" for this suite.
May  3 12:18:59.169: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:18:59.246: INFO: namespace kubectl-546 deletion completed in 22.0923264s

• [SLOW TEST:52.377 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:18:59.247: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:177
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:18:59.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7052" for this suite.
May  3 12:19:21.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:19:21.376: INFO: namespace pods-7052 deletion completed in 22.0858209s

• [SLOW TEST:22.129 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:19:21.377: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
May  3 12:19:21.409: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-9848,SelfLink:/api/v1/namespaces/watch-9848/configmaps/e2e-watch-test-configmap-a,UID:ae5c28d9-6d9d-11e9-9efa-00155da4710f,ResourceVersion:8781,Generation:0,CreationTimestamp:2019-05-03 12:19:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
May  3 12:19:21.409: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-9848,SelfLink:/api/v1/namespaces/watch-9848/configmaps/e2e-watch-test-configmap-a,UID:ae5c28d9-6d9d-11e9-9efa-00155da4710f,ResourceVersion:8781,Generation:0,CreationTimestamp:2019-05-03 12:19:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
May  3 12:19:31.415: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-9848,SelfLink:/api/v1/namespaces/watch-9848/configmaps/e2e-watch-test-configmap-a,UID:ae5c28d9-6d9d-11e9-9efa-00155da4710f,ResourceVersion:8794,Generation:0,CreationTimestamp:2019-05-03 12:19:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
May  3 12:19:31.415: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-9848,SelfLink:/api/v1/namespaces/watch-9848/configmaps/e2e-watch-test-configmap-a,UID:ae5c28d9-6d9d-11e9-9efa-00155da4710f,ResourceVersion:8794,Generation:0,CreationTimestamp:2019-05-03 12:19:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
May  3 12:19:41.422: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-9848,SelfLink:/api/v1/namespaces/watch-9848/configmaps/e2e-watch-test-configmap-a,UID:ae5c28d9-6d9d-11e9-9efa-00155da4710f,ResourceVersion:8807,Generation:0,CreationTimestamp:2019-05-03 12:19:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May  3 12:19:41.422: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-9848,SelfLink:/api/v1/namespaces/watch-9848/configmaps/e2e-watch-test-configmap-a,UID:ae5c28d9-6d9d-11e9-9efa-00155da4710f,ResourceVersion:8807,Generation:0,CreationTimestamp:2019-05-03 12:19:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
May  3 12:19:51.431: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-9848,SelfLink:/api/v1/namespaces/watch-9848/configmaps/e2e-watch-test-configmap-a,UID:ae5c28d9-6d9d-11e9-9efa-00155da4710f,ResourceVersion:8820,Generation:0,CreationTimestamp:2019-05-03 12:19:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May  3 12:19:51.431: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-9848,SelfLink:/api/v1/namespaces/watch-9848/configmaps/e2e-watch-test-configmap-a,UID:ae5c28d9-6d9d-11e9-9efa-00155da4710f,ResourceVersion:8820,Generation:0,CreationTimestamp:2019-05-03 12:19:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
May  3 12:20:01.449: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-9848,SelfLink:/api/v1/namespaces/watch-9848/configmaps/e2e-watch-test-configmap-b,UID:c6379a91-6d9d-11e9-9efa-00155da4710f,ResourceVersion:8833,Generation:0,CreationTimestamp:2019-05-03 12:20:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
May  3 12:20:01.449: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-9848,SelfLink:/api/v1/namespaces/watch-9848/configmaps/e2e-watch-test-configmap-b,UID:c6379a91-6d9d-11e9-9efa-00155da4710f,ResourceVersion:8833,Generation:0,CreationTimestamp:2019-05-03 12:20:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
May  3 12:20:11.459: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-9848,SelfLink:/api/v1/namespaces/watch-9848/configmaps/e2e-watch-test-configmap-b,UID:c6379a91-6d9d-11e9-9efa-00155da4710f,ResourceVersion:8847,Generation:0,CreationTimestamp:2019-05-03 12:20:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
May  3 12:20:11.459: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-9848,SelfLink:/api/v1/namespaces/watch-9848/configmaps/e2e-watch-test-configmap-b,UID:c6379a91-6d9d-11e9-9efa-00155da4710f,ResourceVersion:8847,Generation:0,CreationTimestamp:2019-05-03 12:20:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:20:21.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9848" for this suite.
May  3 12:20:27.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:20:27.578: INFO: namespace watch-9848 deletion completed in 6.1138031s

• [SLOW TEST:66.201 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:20:27.579: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on node default medium
May  3 12:20:27.609: INFO: Waiting up to 5m0s for pod "pod-d5d0bd9d-6d9d-11e9-a622-a62f37ba3446" in namespace "emptydir-4799" to be "success or failure"
May  3 12:20:27.620: INFO: Pod "pod-d5d0bd9d-6d9d-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 11.4105ms
May  3 12:20:29.623: INFO: Pod "pod-d5d0bd9d-6d9d-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0140507s
May  3 12:20:31.628: INFO: Pod "pod-d5d0bd9d-6d9d-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0192598s
STEP: Saw pod success
May  3 12:20:31.628: INFO: Pod "pod-d5d0bd9d-6d9d-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 12:20:31.630: INFO: Trying to get logs from node docker-desktop pod pod-d5d0bd9d-6d9d-11e9-a622-a62f37ba3446 container test-container: <nil>
STEP: delete the pod
May  3 12:20:31.655: INFO: Waiting for pod pod-d5d0bd9d-6d9d-11e9-a622-a62f37ba3446 to disappear
May  3 12:20:31.658: INFO: Pod pod-d5d0bd9d-6d9d-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:20:31.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4799" for this suite.
May  3 12:20:37.671: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:20:37.758: INFO: namespace emptydir-4799 deletion completed in 6.0962679s

• [SLOW TEST:10.180 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:20:37.760: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May  3 12:20:37.791: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dbe28701-6d9d-11e9-a622-a62f37ba3446" in namespace "projected-3447" to be "success or failure"
May  3 12:20:37.798: INFO: Pod "downwardapi-volume-dbe28701-6d9d-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 7.684ms
May  3 12:20:39.801: INFO: Pod "downwardapi-volume-dbe28701-6d9d-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0102658s
May  3 12:20:41.803: INFO: Pod "downwardapi-volume-dbe28701-6d9d-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0125511s
STEP: Saw pod success
May  3 12:20:41.803: INFO: Pod "downwardapi-volume-dbe28701-6d9d-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 12:20:41.805: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-dbe28701-6d9d-11e9-a622-a62f37ba3446 container client-container: <nil>
STEP: delete the pod
May  3 12:20:41.826: INFO: Waiting for pod downwardapi-volume-dbe28701-6d9d-11e9-a622-a62f37ba3446 to disappear
May  3 12:20:41.829: INFO: Pod downwardapi-volume-dbe28701-6d9d-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:20:41.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3447" for this suite.
May  3 12:20:47.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:20:47.925: INFO: namespace projected-3447 deletion completed in 6.0934876s

• [SLOW TEST:10.165 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:20:47.925: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
May  3 12:20:47.973: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-9694,SelfLink:/api/v1/namespaces/watch-9694/configmaps/e2e-watch-test-label-changed,UID:e1f36fbc-6d9d-11e9-9efa-00155da4710f,ResourceVersion:8950,Generation:0,CreationTimestamp:2019-05-03 12:20:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
May  3 12:20:47.974: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-9694,SelfLink:/api/v1/namespaces/watch-9694/configmaps/e2e-watch-test-label-changed,UID:e1f36fbc-6d9d-11e9-9efa-00155da4710f,ResourceVersion:8951,Generation:0,CreationTimestamp:2019-05-03 12:20:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
May  3 12:20:47.974: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-9694,SelfLink:/api/v1/namespaces/watch-9694/configmaps/e2e-watch-test-label-changed,UID:e1f36fbc-6d9d-11e9-9efa-00155da4710f,ResourceVersion:8952,Generation:0,CreationTimestamp:2019-05-03 12:20:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
May  3 12:20:58.003: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-9694,SelfLink:/api/v1/namespaces/watch-9694/configmaps/e2e-watch-test-label-changed,UID:e1f36fbc-6d9d-11e9-9efa-00155da4710f,ResourceVersion:8966,Generation:0,CreationTimestamp:2019-05-03 12:20:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May  3 12:20:58.003: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-9694,SelfLink:/api/v1/namespaces/watch-9694/configmaps/e2e-watch-test-label-changed,UID:e1f36fbc-6d9d-11e9-9efa-00155da4710f,ResourceVersion:8967,Generation:0,CreationTimestamp:2019-05-03 12:20:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
May  3 12:20:58.003: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-9694,SelfLink:/api/v1/namespaces/watch-9694/configmaps/e2e-watch-test-label-changed,UID:e1f36fbc-6d9d-11e9-9efa-00155da4710f,ResourceVersion:8968,Generation:0,CreationTimestamp:2019-05-03 12:20:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:20:58.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9694" for this suite.
May  3 12:21:04.014: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:21:04.090: INFO: namespace watch-9694 deletion completed in 6.0842986s

• [SLOW TEST:16.164 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:21:04.090: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May  3 12:21:04.118: INFO: Waiting up to 5m0s for pod "downwardapi-volume-eb93c093-6d9d-11e9-a622-a62f37ba3446" in namespace "downward-api-419" to be "success or failure"
May  3 12:21:04.125: INFO: Pod "downwardapi-volume-eb93c093-6d9d-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 7.7237ms
May  3 12:21:06.128: INFO: Pod "downwardapi-volume-eb93c093-6d9d-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0104898s
STEP: Saw pod success
May  3 12:21:06.128: INFO: Pod "downwardapi-volume-eb93c093-6d9d-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 12:21:06.130: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-eb93c093-6d9d-11e9-a622-a62f37ba3446 container client-container: <nil>
STEP: delete the pod
May  3 12:21:06.149: INFO: Waiting for pod downwardapi-volume-eb93c093-6d9d-11e9-a622-a62f37ba3446 to disappear
May  3 12:21:06.151: INFO: Pod downwardapi-volume-eb93c093-6d9d-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:21:06.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-419" for this suite.
May  3 12:21:12.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:21:12.262: INFO: namespace downward-api-419 deletion completed in 6.1085475s

• [SLOW TEST:8.172 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:21:12.263: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-6612
May  3 12:21:14.305: INFO: Started pod liveness-http in namespace container-probe-6612
STEP: checking the pod's current state and verifying that restartCount is present
May  3 12:21:14.307: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:25:15.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6612" for this suite.
May  3 12:25:21.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:25:21.127: INFO: namespace container-probe-6612 deletion completed in 6.1018987s

• [SLOW TEST:248.864 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:25:21.127: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-8906/configmap-test-84c871f7-6d9e-11e9-a622-a62f37ba3446
STEP: Creating a pod to test consume configMaps
May  3 12:25:21.157: INFO: Waiting up to 5m0s for pod "pod-configmaps-84c8dade-6d9e-11e9-a622-a62f37ba3446" in namespace "configmap-8906" to be "success or failure"
May  3 12:25:21.168: INFO: Pod "pod-configmaps-84c8dade-6d9e-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 11.2945ms
May  3 12:25:23.172: INFO: Pod "pod-configmaps-84c8dade-6d9e-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014899s
STEP: Saw pod success
May  3 12:25:23.172: INFO: Pod "pod-configmaps-84c8dade-6d9e-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 12:25:23.175: INFO: Trying to get logs from node docker-desktop pod pod-configmaps-84c8dade-6d9e-11e9-a622-a62f37ba3446 container env-test: <nil>
STEP: delete the pod
May  3 12:25:23.194: INFO: Waiting for pod pod-configmaps-84c8dade-6d9e-11e9-a622-a62f37ba3446 to disappear
May  3 12:25:23.196: INFO: Pod pod-configmaps-84c8dade-6d9e-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:25:23.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8906" for this suite.
May  3 12:25:29.207: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:25:29.310: INFO: namespace configmap-8906 deletion completed in 6.1115344s

• [SLOW TEST:8.183 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:25:29.311: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-8828/configmap-test-89b232db-6d9e-11e9-a622-a62f37ba3446
STEP: Creating a pod to test consume configMaps
May  3 12:25:29.409: INFO: Waiting up to 5m0s for pod "pod-configmaps-89b34b4c-6d9e-11e9-a622-a62f37ba3446" in namespace "configmap-8828" to be "success or failure"
May  3 12:25:29.439: INFO: Pod "pod-configmaps-89b34b4c-6d9e-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 29.8948ms
May  3 12:25:31.441: INFO: Pod "pod-configmaps-89b34b4c-6d9e-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0321953s
STEP: Saw pod success
May  3 12:25:31.441: INFO: Pod "pod-configmaps-89b34b4c-6d9e-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 12:25:31.443: INFO: Trying to get logs from node docker-desktop pod pod-configmaps-89b34b4c-6d9e-11e9-a622-a62f37ba3446 container env-test: <nil>
STEP: delete the pod
May  3 12:25:31.474: INFO: Waiting for pod pod-configmaps-89b34b4c-6d9e-11e9-a622-a62f37ba3446 to disappear
May  3 12:25:31.483: INFO: Pod pod-configmaps-89b34b4c-6d9e-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:25:31.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8828" for this suite.
May  3 12:25:37.501: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:25:37.600: INFO: namespace configmap-8828 deletion completed in 6.112957s

• [SLOW TEST:8.289 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:25:37.600: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-5766
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-5766
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5766
May  3 12:25:37.640: INFO: Found 0 stateful pods, waiting for 1
May  3 12:25:47.649: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
May  3 12:25:47.660: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-5766 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May  3 12:25:47.933: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May  3 12:25:47.933: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May  3 12:25:47.933: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May  3 12:25:47.935: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
May  3 12:25:57.938: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May  3 12:25:57.938: INFO: Waiting for statefulset status.replicas updated to 0
May  3 12:25:57.950: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999s
May  3 12:25:58.955: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.9971411s
May  3 12:25:59.963: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.9876167s
May  3 12:26:00.969: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.9843509s
May  3 12:26:01.974: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.977801s
May  3 12:26:02.980: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.9729684s
May  3 12:26:03.983: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.9674847s
May  3 12:26:04.988: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.9636463s
May  3 12:26:05.995: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.9584785s
May  3 12:26:06.999: INFO: Verifying statefulset ss doesn't scale past 1 for another 951.8858ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5766
May  3 12:26:08.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-5766 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May  3 12:26:08.208: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
May  3 12:26:08.208: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May  3 12:26:08.208: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May  3 12:26:08.210: INFO: Found 1 stateful pods, waiting for 3
May  3 12:26:18.214: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
May  3 12:26:18.214: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
May  3 12:26:18.214: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
May  3 12:26:18.221: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-5766 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May  3 12:26:18.380: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May  3 12:26:18.380: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May  3 12:26:18.380: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May  3 12:26:18.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-5766 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May  3 12:26:18.579: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May  3 12:26:18.579: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May  3 12:26:18.579: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May  3 12:26:18.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-5766 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May  3 12:26:18.769: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May  3 12:26:18.769: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May  3 12:26:18.769: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May  3 12:26:18.769: INFO: Waiting for statefulset status.replicas updated to 0
May  3 12:26:18.772: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
May  3 12:26:28.781: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May  3 12:26:28.781: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
May  3 12:26:28.781: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
May  3 12:26:28.802: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.9999983s
May  3 12:26:29.807: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.9901016s
May  3 12:26:30.813: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.9854113s
May  3 12:26:31.822: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.9787244s
May  3 12:26:32.847: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.9702095s
May  3 12:26:33.854: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.9446961s
May  3 12:26:34.859: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.9382058s
May  3 12:26:35.864: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.9333311s
May  3 12:26:36.867: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.9289213s
May  3 12:26:37.875: INFO: Verifying statefulset ss doesn't scale past 3 for another 925.5508ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5766
May  3 12:26:38.883: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-5766 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May  3 12:26:39.086: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
May  3 12:26:39.086: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May  3 12:26:39.086: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May  3 12:26:39.086: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-5766 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May  3 12:26:39.301: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
May  3 12:26:39.301: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May  3 12:26:39.301: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May  3 12:26:39.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-5766 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May  3 12:26:39.518: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
May  3 12:26:39.518: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May  3 12:26:39.518: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May  3 12:26:39.518: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May  3 12:26:49.535: INFO: Deleting all statefulset in ns statefulset-5766
May  3 12:26:49.537: INFO: Scaling statefulset ss to 0
May  3 12:26:49.548: INFO: Waiting for statefulset status.replicas updated to 0
May  3 12:26:49.551: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:26:49.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5766" for this suite.
May  3 12:26:55.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:26:55.687: INFO: namespace statefulset-5766 deletion completed in 6.1149843s

• [SLOW TEST:78.086 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:26:55.687: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
May  3 12:26:55.713: INFO: Waiting up to 5m0s for pod "pod-bd24d8de-6d9e-11e9-a622-a62f37ba3446" in namespace "emptydir-9501" to be "success or failure"
May  3 12:26:55.721: INFO: Pod "pod-bd24d8de-6d9e-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 8.2184ms
May  3 12:26:57.729: INFO: Pod "pod-bd24d8de-6d9e-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0160252s
May  3 12:26:59.734: INFO: Pod "pod-bd24d8de-6d9e-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0210532s
STEP: Saw pod success
May  3 12:26:59.734: INFO: Pod "pod-bd24d8de-6d9e-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 12:26:59.740: INFO: Trying to get logs from node docker-desktop pod pod-bd24d8de-6d9e-11e9-a622-a62f37ba3446 container test-container: <nil>
STEP: delete the pod
May  3 12:26:59.778: INFO: Waiting for pod pod-bd24d8de-6d9e-11e9-a622-a62f37ba3446 to disappear
May  3 12:26:59.781: INFO: Pod pod-bd24d8de-6d9e-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:26:59.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9501" for this suite.
May  3 12:27:05.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:27:05.885: INFO: namespace emptydir-9501 deletion completed in 6.1011176s

• [SLOW TEST:10.198 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:27:05.886: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
May  3 12:27:05.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 create -f - --namespace=kubectl-675'
May  3 12:27:06.078: INFO: stderr: ""
May  3 12:27:06.078: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May  3 12:27:06.078: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-675'
May  3 12:27:06.201: INFO: stderr: ""
May  3 12:27:06.201: INFO: stdout: "update-demo-nautilus-bhthq update-demo-nautilus-jn99z "
May  3 12:27:06.201: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pods update-demo-nautilus-bhthq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-675'
May  3 12:27:06.273: INFO: stderr: ""
May  3 12:27:06.273: INFO: stdout: ""
May  3 12:27:06.273: INFO: update-demo-nautilus-bhthq is created but not running
May  3 12:27:11.274: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-675'
May  3 12:27:11.352: INFO: stderr: ""
May  3 12:27:11.352: INFO: stdout: "update-demo-nautilus-bhthq update-demo-nautilus-jn99z "
May  3 12:27:11.352: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pods update-demo-nautilus-bhthq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-675'
May  3 12:27:11.412: INFO: stderr: ""
May  3 12:27:11.412: INFO: stdout: "true"
May  3 12:27:11.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pods update-demo-nautilus-bhthq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-675'
May  3 12:27:11.477: INFO: stderr: ""
May  3 12:27:11.477: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May  3 12:27:11.477: INFO: validating pod update-demo-nautilus-bhthq
May  3 12:27:11.480: INFO: got data: {
  "image": "nautilus.jpg"
}

May  3 12:27:11.480: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May  3 12:27:11.480: INFO: update-demo-nautilus-bhthq is verified up and running
May  3 12:27:11.480: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pods update-demo-nautilus-jn99z -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-675'
May  3 12:27:11.539: INFO: stderr: ""
May  3 12:27:11.539: INFO: stdout: "true"
May  3 12:27:11.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pods update-demo-nautilus-jn99z -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-675'
May  3 12:27:11.601: INFO: stderr: ""
May  3 12:27:11.601: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May  3 12:27:11.601: INFO: validating pod update-demo-nautilus-jn99z
May  3 12:27:11.603: INFO: got data: {
  "image": "nautilus.jpg"
}

May  3 12:27:11.603: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May  3 12:27:11.603: INFO: update-demo-nautilus-jn99z is verified up and running
STEP: using delete to clean up resources
May  3 12:27:11.604: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 delete --grace-period=0 --force -f - --namespace=kubectl-675'
May  3 12:27:11.676: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May  3 12:27:11.676: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
May  3 12:27:11.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-675'
May  3 12:27:11.835: INFO: stderr: "No resources found.\n"
May  3 12:27:11.835: INFO: stdout: ""
May  3 12:27:11.835: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pods -l name=update-demo --namespace=kubectl-675 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May  3 12:27:11.960: INFO: stderr: ""
May  3 12:27:11.960: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:27:11.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-675" for this suite.
May  3 12:27:17.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:27:18.072: INFO: namespace kubectl-675 deletion completed in 6.1079144s

• [SLOW TEST:12.187 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:27:18.072: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-ca7d0821-6d9e-11e9-a622-a62f37ba3446
STEP: Creating a pod to test consume secrets
May  3 12:27:18.105: INFO: Waiting up to 5m0s for pod "pod-secrets-ca7d6b65-6d9e-11e9-a622-a62f37ba3446" in namespace "secrets-896" to be "success or failure"
May  3 12:27:18.120: INFO: Pod "pod-secrets-ca7d6b65-6d9e-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 15.3115ms
May  3 12:27:20.125: INFO: Pod "pod-secrets-ca7d6b65-6d9e-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0202455s
May  3 12:27:22.133: INFO: Pod "pod-secrets-ca7d6b65-6d9e-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0278368s
STEP: Saw pod success
May  3 12:27:22.133: INFO: Pod "pod-secrets-ca7d6b65-6d9e-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 12:27:22.139: INFO: Trying to get logs from node docker-desktop pod pod-secrets-ca7d6b65-6d9e-11e9-a622-a62f37ba3446 container secret-volume-test: <nil>
STEP: delete the pod
May  3 12:27:22.172: INFO: Waiting for pod pod-secrets-ca7d6b65-6d9e-11e9-a622-a62f37ba3446 to disappear
May  3 12:27:22.178: INFO: Pod pod-secrets-ca7d6b65-6d9e-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:27:22.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-896" for this suite.
May  3 12:27:28.192: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:27:28.293: INFO: namespace secrets-896 deletion completed in 6.1124504s

• [SLOW TEST:10.221 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:27:28.293: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8444.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8444.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May  3 12:27:40.371: INFO: DNS probes using dns-8444/dns-test-d0946e55-6d9e-11e9-a622-a62f37ba3446 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:27:40.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8444" for this suite.
May  3 12:27:46.446: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:27:46.575: INFO: namespace dns-8444 deletion completed in 6.1812422s

• [SLOW TEST:18.282 seconds]
[sig-network] DNS
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:27:46.575: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service multi-endpoint-test in namespace services-4733
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4733 to expose endpoints map[]
May  3 12:27:46.665: INFO: successfully validated that service multi-endpoint-test in namespace services-4733 exposes endpoints map[] (4.176ms elapsed)
STEP: Creating pod pod1 in namespace services-4733
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4733 to expose endpoints map[pod1:[100]]
May  3 12:27:48.705: INFO: successfully validated that service multi-endpoint-test in namespace services-4733 exposes endpoints map[pod1:[100]] (2.0340128s elapsed)
STEP: Creating pod pod2 in namespace services-4733
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4733 to expose endpoints map[pod1:[100] pod2:[101]]
May  3 12:27:50.778: INFO: successfully validated that service multi-endpoint-test in namespace services-4733 exposes endpoints map[pod1:[100] pod2:[101]] (2.069273s elapsed)
STEP: Deleting pod pod1 in namespace services-4733
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4733 to expose endpoints map[pod2:[101]]
May  3 12:27:50.810: INFO: successfully validated that service multi-endpoint-test in namespace services-4733 exposes endpoints map[pod2:[101]] (25.4402ms elapsed)
STEP: Deleting pod pod2 in namespace services-4733
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4733 to expose endpoints map[]
May  3 12:27:50.822: INFO: successfully validated that service multi-endpoint-test in namespace services-4733 exposes endpoints map[] (4.5513ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:27:50.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4733" for this suite.
May  3 12:27:56.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:27:57.000: INFO: namespace services-4733 deletion completed in 6.1554692s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:10.425 seconds]
[sig-network] Services
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:27:57.000: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-e1b148cc-6d9e-11e9-a622-a62f37ba3446
STEP: Creating a pod to test consume secrets
May  3 12:27:57.035: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e1b1a746-6d9e-11e9-a622-a62f37ba3446" in namespace "projected-7456" to be "success or failure"
May  3 12:27:57.044: INFO: Pod "pod-projected-secrets-e1b1a746-6d9e-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 8.7775ms
May  3 12:27:59.047: INFO: Pod "pod-projected-secrets-e1b1a746-6d9e-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0116414s
STEP: Saw pod success
May  3 12:27:59.047: INFO: Pod "pod-projected-secrets-e1b1a746-6d9e-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 12:27:59.049: INFO: Trying to get logs from node docker-desktop pod pod-projected-secrets-e1b1a746-6d9e-11e9-a622-a62f37ba3446 container projected-secret-volume-test: <nil>
STEP: delete the pod
May  3 12:27:59.063: INFO: Waiting for pod pod-projected-secrets-e1b1a746-6d9e-11e9-a622-a62f37ba3446 to disappear
May  3 12:27:59.065: INFO: Pod pod-projected-secrets-e1b1a746-6d9e-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:27:59.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7456" for this suite.
May  3 12:28:05.078: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:28:05.160: INFO: namespace projected-7456 deletion completed in 6.0924019s

• [SLOW TEST:8.160 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:28:05.161: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
May  3 12:28:11.246: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May  3 12:28:11.251: INFO: Pod pod-with-prestop-http-hook still exists
May  3 12:28:13.252: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May  3 12:28:13.260: INFO: Pod pod-with-prestop-http-hook still exists
May  3 12:28:15.252: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May  3 12:28:15.260: INFO: Pod pod-with-prestop-http-hook still exists
May  3 12:28:17.252: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May  3 12:28:17.256: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:28:17.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3268" for this suite.
May  3 12:28:39.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:28:39.407: INFO: namespace container-lifecycle-hook-3268 deletion completed in 22.137605s

• [SLOW TEST:34.247 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:28:39.410: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test env composition
May  3 12:28:39.450: INFO: Waiting up to 5m0s for pod "var-expansion-faf9324b-6d9e-11e9-a622-a62f37ba3446" in namespace "var-expansion-3688" to be "success or failure"
May  3 12:28:39.455: INFO: Pod "var-expansion-faf9324b-6d9e-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 5.0691ms
May  3 12:28:41.460: INFO: Pod "var-expansion-faf9324b-6d9e-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0093332s
STEP: Saw pod success
May  3 12:28:41.460: INFO: Pod "var-expansion-faf9324b-6d9e-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 12:28:41.462: INFO: Trying to get logs from node docker-desktop pod var-expansion-faf9324b-6d9e-11e9-a622-a62f37ba3446 container dapi-container: <nil>
STEP: delete the pod
May  3 12:28:41.488: INFO: Waiting for pod var-expansion-faf9324b-6d9e-11e9-a622-a62f37ba3446 to disappear
May  3 12:28:41.505: INFO: Pod var-expansion-faf9324b-6d9e-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:28:41.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3688" for this suite.
May  3 12:28:47.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:28:47.592: INFO: namespace var-expansion-3688 deletion completed in 6.0829681s

• [SLOW TEST:8.182 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:28:47.592: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-ffd827a1-6d9e-11e9-a622-a62f37ba3446
STEP: Creating a pod to test consume configMaps
May  3 12:28:47.620: INFO: Waiting up to 5m0s for pod "pod-configmaps-ffd8bb95-6d9e-11e9-a622-a62f37ba3446" in namespace "configmap-9543" to be "success or failure"
May  3 12:28:47.627: INFO: Pod "pod-configmaps-ffd8bb95-6d9e-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 6.6305ms
May  3 12:28:49.632: INFO: Pod "pod-configmaps-ffd8bb95-6d9e-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0120664s
STEP: Saw pod success
May  3 12:28:49.632: INFO: Pod "pod-configmaps-ffd8bb95-6d9e-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 12:28:49.635: INFO: Trying to get logs from node docker-desktop pod pod-configmaps-ffd8bb95-6d9e-11e9-a622-a62f37ba3446 container configmap-volume-test: <nil>
STEP: delete the pod
May  3 12:28:49.671: INFO: Waiting for pod pod-configmaps-ffd8bb95-6d9e-11e9-a622-a62f37ba3446 to disappear
May  3 12:28:49.676: INFO: Pod pod-configmaps-ffd8bb95-6d9e-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:28:49.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9543" for this suite.
May  3 12:28:55.700: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:28:55.796: INFO: namespace configmap-9543 deletion completed in 6.1172877s

• [SLOW TEST:8.204 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:28:55.799: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-04bd0bf6-6d9f-11e9-a622-a62f37ba3446
STEP: Creating a pod to test consume secrets
May  3 12:28:55.831: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-04bd718b-6d9f-11e9-a622-a62f37ba3446" in namespace "projected-2959" to be "success or failure"
May  3 12:28:55.840: INFO: Pod "pod-projected-secrets-04bd718b-6d9f-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 8.0117ms
May  3 12:28:57.862: INFO: Pod "pod-projected-secrets-04bd718b-6d9f-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0308098s
STEP: Saw pod success
May  3 12:28:57.862: INFO: Pod "pod-projected-secrets-04bd718b-6d9f-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 12:28:57.865: INFO: Trying to get logs from node docker-desktop pod pod-projected-secrets-04bd718b-6d9f-11e9-a622-a62f37ba3446 container projected-secret-volume-test: <nil>
STEP: delete the pod
May  3 12:28:57.893: INFO: Waiting for pod pod-projected-secrets-04bd718b-6d9f-11e9-a622-a62f37ba3446 to disappear
May  3 12:28:57.895: INFO: Pod pod-projected-secrets-04bd718b-6d9f-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:28:57.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2959" for this suite.
May  3 12:29:03.907: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:29:03.986: INFO: namespace projected-2959 deletion completed in 6.0883292s

• [SLOW TEST:8.187 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:29:03.987: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
May  3 12:29:08.588: INFO: Successfully updated pod "annotationupdate099e81da-6d9f-11e9-a622-a62f37ba3446"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:29:10.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1390" for this suite.
May  3 12:29:32.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:29:32.726: INFO: namespace downward-api-1390 deletion completed in 22.0996984s

• [SLOW TEST:28.739 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:29:32.727: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May  3 12:29:32.753: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1abf5e7a-6d9f-11e9-a622-a62f37ba3446" in namespace "projected-3807" to be "success or failure"
May  3 12:29:32.757: INFO: Pod "downwardapi-volume-1abf5e7a-6d9f-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 4.5936ms
May  3 12:29:34.760: INFO: Pod "downwardapi-volume-1abf5e7a-6d9f-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0076431s
STEP: Saw pod success
May  3 12:29:34.760: INFO: Pod "downwardapi-volume-1abf5e7a-6d9f-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 12:29:34.764: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-1abf5e7a-6d9f-11e9-a622-a62f37ba3446 container client-container: <nil>
STEP: delete the pod
May  3 12:29:34.792: INFO: Waiting for pod downwardapi-volume-1abf5e7a-6d9f-11e9-a622-a62f37ba3446 to disappear
May  3 12:29:34.796: INFO: Pod downwardapi-volume-1abf5e7a-6d9f-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:29:34.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3807" for this suite.
May  3 12:29:40.808: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:29:40.886: INFO: namespace projected-3807 deletion completed in 6.0875179s

• [SLOW TEST:8.159 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:29:40.886: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:29:42.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-1318" for this suite.
May  3 12:29:48.969: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:29:49.082: INFO: namespace emptydir-wrapper-1318 deletion completed in 6.1248415s

• [SLOW TEST:8.196 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:29:49.082: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
May  3 12:29:53.661: INFO: Successfully updated pod "labelsupdate247ee9d4-6d9f-11e9-a622-a62f37ba3446"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:29:55.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5692" for this suite.
May  3 12:30:17.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:30:17.810: INFO: namespace projected-5692 deletion completed in 22.1050221s

• [SLOW TEST:28.728 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:30:17.810: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
May  3 12:30:17.850: INFO: Waiting up to 5m0s for pod "pod-35a082ec-6d9f-11e9-a622-a62f37ba3446" in namespace "emptydir-5812" to be "success or failure"
May  3 12:30:17.856: INFO: Pod "pod-35a082ec-6d9f-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 6.0965ms
May  3 12:30:19.874: INFO: Pod "pod-35a082ec-6d9f-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0240551s
May  3 12:30:21.880: INFO: Pod "pod-35a082ec-6d9f-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0296441s
STEP: Saw pod success
May  3 12:30:21.880: INFO: Pod "pod-35a082ec-6d9f-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 12:30:21.886: INFO: Trying to get logs from node docker-desktop pod pod-35a082ec-6d9f-11e9-a622-a62f37ba3446 container test-container: <nil>
STEP: delete the pod
May  3 12:30:21.920: INFO: Waiting for pod pod-35a082ec-6d9f-11e9-a622-a62f37ba3446 to disappear
May  3 12:30:21.948: INFO: Pod pod-35a082ec-6d9f-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:30:21.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5812" for this suite.
May  3 12:30:27.962: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:30:28.050: INFO: namespace emptydir-5812 deletion completed in 6.0983311s

• [SLOW TEST:10.240 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:30:28.051: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-27
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
May  3 12:30:28.097: INFO: Found 0 stateful pods, waiting for 3
May  3 12:30:38.121: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May  3 12:30:38.121: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May  3 12:30:38.121: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
May  3 12:30:38.142: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-27 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May  3 12:30:38.351: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May  3 12:30:38.351: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May  3 12:30:38.351: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
May  3 12:30:48.386: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
May  3 12:30:58.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-27 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May  3 12:30:58.619: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
May  3 12:30:58.619: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May  3 12:30:58.619: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May  3 12:31:28.657: INFO: Waiting for StatefulSet statefulset-27/ss2 to complete update
STEP: Rolling back to a previous revision
May  3 12:31:38.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-27 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May  3 12:31:38.865: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May  3 12:31:38.865: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May  3 12:31:38.865: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May  3 12:31:48.901: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
May  3 12:31:58.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-27 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May  3 12:31:59.135: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
May  3 12:31:59.135: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May  3 12:31:59.135: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May  3 12:32:09.160: INFO: Waiting for StatefulSet statefulset-27/ss2 to complete update
May  3 12:32:09.160: INFO: Waiting for Pod statefulset-27/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
May  3 12:32:09.160: INFO: Waiting for Pod statefulset-27/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
May  3 12:32:19.167: INFO: Waiting for StatefulSet statefulset-27/ss2 to complete update
May  3 12:32:19.167: INFO: Waiting for Pod statefulset-27/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May  3 12:32:29.177: INFO: Deleting all statefulset in ns statefulset-27
May  3 12:32:29.182: INFO: Scaling statefulset ss2 to 0
May  3 12:32:49.214: INFO: Waiting for statefulset status.replicas updated to 0
May  3 12:32:49.220: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:32:49.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-27" for this suite.
May  3 12:32:55.273: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:32:55.357: INFO: namespace statefulset-27 deletion completed in 6.103271s

• [SLOW TEST:147.306 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:32:55.357: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1619
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
May  3 12:32:55.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-7569'
May  3 12:32:55.693: INFO: stderr: ""
May  3 12:32:55.693: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
May  3 12:33:00.749: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pod e2e-test-nginx-pod --namespace=kubectl-7569 -o json'
May  3 12:33:00.845: INFO: stderr: ""
May  3 12:33:00.846: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-05-03T12:32:55Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-7569\",\n        \"resourceVersion\": \"10986\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-7569/pods/e2e-test-nginx-pod\",\n        \"uid\": \"93b3072d-6d9f-11e9-9efa-00155da4710f\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-pkvt5\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"docker-desktop\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-pkvt5\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-pkvt5\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-03T12:32:55Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-03T12:32:57Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-03T12:32:57Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-03T12:32:55Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://21cab6710261506028fa92df1247af2840510d782a6b25adf5f4077a7e373864\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-05-03T12:32:57Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.65.3\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.1.0.73\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-05-03T12:32:55Z\"\n    }\n}\n"
STEP: replace the image in the pod
May  3 12:33:00.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 replace -f - --namespace=kubectl-7569'
May  3 12:33:01.002: INFO: stderr: ""
May  3 12:33:01.002: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1624
May  3 12:33:01.008: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 delete pods e2e-test-nginx-pod --namespace=kubectl-7569'
May  3 12:33:06.233: INFO: stderr: ""
May  3 12:33:06.233: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:33:06.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7569" for this suite.
May  3 12:33:12.243: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:33:12.332: INFO: namespace kubectl-7569 deletion completed in 6.0966421s

• [SLOW TEST:16.974 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:33:12.332: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May  3 12:33:12.365: INFO: (0) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 5.6407ms)
May  3 12:33:12.373: INFO: (1) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 8.0178ms)
May  3 12:33:12.376: INFO: (2) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 3.3961ms)
May  3 12:33:12.379: INFO: (3) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 2.7879ms)
May  3 12:33:12.382: INFO: (4) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 2.6312ms)
May  3 12:33:12.384: INFO: (5) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 2.4344ms)
May  3 12:33:12.387: INFO: (6) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 2.5593ms)
May  3 12:33:12.390: INFO: (7) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 2.4688ms)
May  3 12:33:12.392: INFO: (8) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 2.4822ms)
May  3 12:33:12.395: INFO: (9) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 2.8305ms)
May  3 12:33:12.398: INFO: (10) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 2.7608ms)
May  3 12:33:12.413: INFO: (11) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 14.8769ms)
May  3 12:33:12.418: INFO: (12) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 5.4765ms)
May  3 12:33:12.422: INFO: (13) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 3.0988ms)
May  3 12:33:12.424: INFO: (14) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 2.8365ms)
May  3 12:33:12.429: INFO: (15) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 4.9159ms)
May  3 12:33:12.433: INFO: (16) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 3.0682ms)
May  3 12:33:12.435: INFO: (17) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 2.6434ms)
May  3 12:33:12.438: INFO: (18) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 2.8824ms)
May  3 12:33:12.441: INFO: (19) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 2.8923ms)
[AfterEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:33:12.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-9041" for this suite.
May  3 12:33:18.455: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:33:18.522: INFO: namespace proxy-9041 deletion completed in 6.079029s

• [SLOW TEST:6.191 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:33:18.523: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May  3 12:33:18.555: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a1561cc7-6d9f-11e9-a622-a62f37ba3446" in namespace "downward-api-69" to be "success or failure"
May  3 12:33:18.558: INFO: Pod "downwardapi-volume-a1561cc7-6d9f-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 2.7664ms
May  3 12:33:20.563: INFO: Pod "downwardapi-volume-a1561cc7-6d9f-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0079172s
May  3 12:33:22.569: INFO: Pod "downwardapi-volume-a1561cc7-6d9f-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0136851s
STEP: Saw pod success
May  3 12:33:22.569: INFO: Pod "downwardapi-volume-a1561cc7-6d9f-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 12:33:22.572: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-a1561cc7-6d9f-11e9-a622-a62f37ba3446 container client-container: <nil>
STEP: delete the pod
May  3 12:33:22.602: INFO: Waiting for pod downwardapi-volume-a1561cc7-6d9f-11e9-a622-a62f37ba3446 to disappear
May  3 12:33:22.609: INFO: Pod downwardapi-volume-a1561cc7-6d9f-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:33:22.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-69" for this suite.
May  3 12:33:28.630: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:33:28.742: INFO: namespace downward-api-69 deletion completed in 6.1298916s

• [SLOW TEST:10.219 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:33:28.742: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
May  3 12:33:28.763: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:33:33.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3819" for this suite.
May  3 12:33:39.635: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:33:39.705: INFO: namespace init-container-3819 deletion completed in 6.0823176s

• [SLOW TEST:10.963 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:33:39.706: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:34:05.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-7934" for this suite.
May  3 12:34:11.893: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:34:11.989: INFO: namespace namespaces-7934 deletion completed in 6.1098124s
STEP: Destroying namespace "nsdeletetest-6940" for this suite.
May  3 12:34:11.991: INFO: Namespace nsdeletetest-6940 was already deleted
STEP: Destroying namespace "nsdeletetest-4841" for this suite.
May  3 12:34:18.003: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:34:18.082: INFO: namespace nsdeletetest-4841 deletion completed in 6.0904139s

• [SLOW TEST:38.376 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:34:18.082: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May  3 12:34:18.107: INFO: Creating ReplicaSet my-hostname-basic-c4d59750-6d9f-11e9-a622-a62f37ba3446
May  3 12:34:18.116: INFO: Pod name my-hostname-basic-c4d59750-6d9f-11e9-a622-a62f37ba3446: Found 0 pods out of 1
May  3 12:34:23.127: INFO: Pod name my-hostname-basic-c4d59750-6d9f-11e9-a622-a62f37ba3446: Found 1 pods out of 1
May  3 12:34:23.127: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-c4d59750-6d9f-11e9-a622-a62f37ba3446" is running
May  3 12:34:23.131: INFO: Pod "my-hostname-basic-c4d59750-6d9f-11e9-a622-a62f37ba3446-lg8kk" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-03 12:34:18 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-03 12:34:22 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-03 12:34:22 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-03 12:34:18 +0000 UTC Reason: Message:}])
May  3 12:34:23.131: INFO: Trying to dial the pod
May  3 12:34:28.154: INFO: Controller my-hostname-basic-c4d59750-6d9f-11e9-a622-a62f37ba3446: Got expected result from replica 1 [my-hostname-basic-c4d59750-6d9f-11e9-a622-a62f37ba3446-lg8kk]: "my-hostname-basic-c4d59750-6d9f-11e9-a622-a62f37ba3446-lg8kk", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:34:28.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-3566" for this suite.
May  3 12:34:34.174: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:34:34.271: INFO: namespace replicaset-3566 deletion completed in 6.1137214s

• [SLOW TEST:16.190 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:34:34.272: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating replication controller svc-latency-rc in namespace svc-latency-6813
I0503 12:34:34.303486      15 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-6813, replica count: 1
I0503 12:34:35.354063      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0503 12:34:36.354298      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0503 12:34:37.356093      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0503 12:34:38.356518      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May  3 12:34:38.479: INFO: Created: latency-svc-gfzkf
May  3 12:34:38.484: INFO: Got endpoints: latency-svc-gfzkf [27.1927ms]
May  3 12:34:38.520: INFO: Created: latency-svc-7s6t7
May  3 12:34:38.520: INFO: Got endpoints: latency-svc-7s6t7 [35.201ms]
May  3 12:34:38.531: INFO: Created: latency-svc-lf5zb
May  3 12:34:38.543: INFO: Got endpoints: latency-svc-lf5zb [57.3412ms]
May  3 12:34:38.544: INFO: Created: latency-svc-sd95s
May  3 12:34:38.548: INFO: Got endpoints: latency-svc-sd95s [62.0209ms]
May  3 12:34:38.555: INFO: Created: latency-svc-m9fl9
May  3 12:34:38.585: INFO: Got endpoints: latency-svc-m9fl9 [98.6485ms]
May  3 12:34:38.586: INFO: Created: latency-svc-v7q2z
May  3 12:34:38.591: INFO: Got endpoints: latency-svc-v7q2z [105.2ms]
May  3 12:34:38.598: INFO: Created: latency-svc-5hfhs
May  3 12:34:38.602: INFO: Got endpoints: latency-svc-5hfhs [115.9297ms]
May  3 12:34:38.613: INFO: Created: latency-svc-r8drd
May  3 12:34:38.620: INFO: Got endpoints: latency-svc-r8drd [133.6649ms]
May  3 12:34:38.625: INFO: Created: latency-svc-rj8pz
May  3 12:34:38.629: INFO: Got endpoints: latency-svc-rj8pz [142.7607ms]
May  3 12:34:38.644: INFO: Created: latency-svc-pbcsd
May  3 12:34:38.645: INFO: Got endpoints: latency-svc-pbcsd [157.4242ms]
May  3 12:34:38.658: INFO: Created: latency-svc-7fgkl
May  3 12:34:38.663: INFO: Got endpoints: latency-svc-7fgkl [176.2151ms]
May  3 12:34:38.673: INFO: Created: latency-svc-ns7tn
May  3 12:34:38.682: INFO: Got endpoints: latency-svc-ns7tn [194.7697ms]
May  3 12:34:38.703: INFO: Created: latency-svc-ljrwq
May  3 12:34:38.703: INFO: Created: latency-svc-wwtq4
May  3 12:34:38.703: INFO: Got endpoints: latency-svc-wwtq4 [216.2427ms]
May  3 12:34:38.707: INFO: Got endpoints: latency-svc-ljrwq [219.4914ms]
May  3 12:34:38.719: INFO: Created: latency-svc-r6ln6
May  3 12:34:38.719: INFO: Got endpoints: latency-svc-r6ln6 [231.6595ms]
May  3 12:34:38.734: INFO: Created: latency-svc-9fkhn
May  3 12:34:38.741: INFO: Got endpoints: latency-svc-9fkhn [253.4079ms]
May  3 12:34:38.747: INFO: Created: latency-svc-wvj8t
May  3 12:34:38.747: INFO: Got endpoints: latency-svc-wvj8t [226.6206ms]
May  3 12:34:38.758: INFO: Created: latency-svc-752ss
May  3 12:34:38.763: INFO: Got endpoints: latency-svc-752ss [219.741ms]
May  3 12:34:38.781: INFO: Created: latency-svc-dt22b
May  3 12:34:38.792: INFO: Got endpoints: latency-svc-dt22b [243.594ms]
May  3 12:34:38.798: INFO: Created: latency-svc-hdjft
May  3 12:34:38.802: INFO: Got endpoints: latency-svc-hdjft [217.3855ms]
May  3 12:34:38.810: INFO: Created: latency-svc-pq9bw
May  3 12:34:38.822: INFO: Created: latency-svc-cpztw
May  3 12:34:38.822: INFO: Got endpoints: latency-svc-pq9bw [230.603ms]
May  3 12:34:38.825: INFO: Got endpoints: latency-svc-cpztw [223.1983ms]
May  3 12:34:38.832: INFO: Created: latency-svc-gl4qs
May  3 12:34:38.837: INFO: Got endpoints: latency-svc-gl4qs [217.3004ms]
May  3 12:34:38.857: INFO: Created: latency-svc-9xxzt
May  3 12:34:38.857: INFO: Got endpoints: latency-svc-9xxzt [227.0332ms]
May  3 12:34:38.865: INFO: Created: latency-svc-wvplp
May  3 12:34:38.870: INFO: Got endpoints: latency-svc-wvplp [225.1078ms]
May  3 12:34:38.879: INFO: Created: latency-svc-r9cjs
May  3 12:34:38.881: INFO: Got endpoints: latency-svc-r9cjs [217.7871ms]
May  3 12:34:38.893: INFO: Created: latency-svc-rjm5r
May  3 12:34:38.913: INFO: Got endpoints: latency-svc-rjm5r [231.1916ms]
May  3 12:34:38.921: INFO: Created: latency-svc-vk5g8
May  3 12:34:38.932: INFO: Got endpoints: latency-svc-vk5g8 [228.9456ms]
May  3 12:34:38.936: INFO: Created: latency-svc-bj8qt
May  3 12:34:38.936: INFO: Got endpoints: latency-svc-bj8qt [229.6173ms]
May  3 12:34:38.963: INFO: Created: latency-svc-w7vfp
May  3 12:34:38.968: INFO: Got endpoints: latency-svc-w7vfp [248.8512ms]
May  3 12:34:38.975: INFO: Created: latency-svc-s82hf
May  3 12:34:38.983: INFO: Got endpoints: latency-svc-s82hf [241.9527ms]
May  3 12:34:38.993: INFO: Created: latency-svc-5grqk
May  3 12:34:38.996: INFO: Got endpoints: latency-svc-5grqk [249.7427ms]
May  3 12:34:39.010: INFO: Created: latency-svc-nh7mj
May  3 12:34:39.024: INFO: Got endpoints: latency-svc-nh7mj [261.2055ms]
May  3 12:34:39.038: INFO: Created: latency-svc-ng5kf
May  3 12:34:39.039: INFO: Got endpoints: latency-svc-ng5kf [247.1775ms]
May  3 12:34:39.052: INFO: Created: latency-svc-4sttm
May  3 12:34:39.055: INFO: Got endpoints: latency-svc-4sttm [252.8521ms]
May  3 12:34:39.062: INFO: Created: latency-svc-9hr5b
May  3 12:34:39.074: INFO: Created: latency-svc-jsv8g
May  3 12:34:39.074: INFO: Got endpoints: latency-svc-9hr5b [251.8179ms]
May  3 12:34:39.077: INFO: Got endpoints: latency-svc-jsv8g [251.5219ms]
May  3 12:34:39.088: INFO: Created: latency-svc-7jvnb
May  3 12:34:39.092: INFO: Got endpoints: latency-svc-7jvnb [254.9322ms]
May  3 12:34:39.105: INFO: Created: latency-svc-mrqwx
May  3 12:34:39.119: INFO: Created: latency-svc-dtrjr
May  3 12:34:39.121: INFO: Got endpoints: latency-svc-mrqwx [264.2901ms]
May  3 12:34:39.127: INFO: Got endpoints: latency-svc-dtrjr [255.9067ms]
May  3 12:34:39.152: INFO: Created: latency-svc-nzn69
May  3 12:34:39.157: INFO: Got endpoints: latency-svc-nzn69 [275.7089ms]
May  3 12:34:39.171: INFO: Created: latency-svc-bxw4v
May  3 12:34:39.175: INFO: Got endpoints: latency-svc-bxw4v [261.6671ms]
May  3 12:34:39.183: INFO: Created: latency-svc-dbqm2
May  3 12:34:39.187: INFO: Got endpoints: latency-svc-dbqm2 [254.1135ms]
May  3 12:34:39.196: INFO: Created: latency-svc-69wtc
May  3 12:34:39.196: INFO: Got endpoints: latency-svc-69wtc [259.7747ms]
May  3 12:34:39.301: INFO: Created: latency-svc-j94x6
May  3 12:34:39.305: INFO: Got endpoints: latency-svc-j94x6 [336.6038ms]
May  3 12:34:39.313: INFO: Created: latency-svc-qmk9r
May  3 12:34:39.318: INFO: Got endpoints: latency-svc-qmk9r [335.2964ms]
May  3 12:34:39.323: INFO: Created: latency-svc-2rvrm
May  3 12:34:39.341: INFO: Got endpoints: latency-svc-2rvrm [344.8713ms]
May  3 12:34:39.360: INFO: Created: latency-svc-bc9w9
May  3 12:34:39.362: INFO: Created: latency-svc-jbxxc
May  3 12:34:39.372: INFO: Created: latency-svc-kkvst
May  3 12:34:39.387: INFO: Got endpoints: latency-svc-bc9w9 [363.3458ms]
May  3 12:34:39.388: INFO: Created: latency-svc-z8699
May  3 12:34:39.423: INFO: Created: latency-svc-dh7wz
May  3 12:34:39.430: INFO: Got endpoints: latency-svc-jbxxc [390.5996ms]
May  3 12:34:39.433: INFO: Created: latency-svc-8qnpp
May  3 12:34:39.455: INFO: Created: latency-svc-pvvs4
May  3 12:34:39.474: INFO: Created: latency-svc-trt2p
May  3 12:34:39.507: INFO: Got endpoints: latency-svc-kkvst [452.0856ms]
May  3 12:34:39.525: INFO: Created: latency-svc-gldfh
May  3 12:34:39.530: INFO: Created: latency-svc-c9pgz
May  3 12:34:39.536: INFO: Got endpoints: latency-svc-z8699 [462.0431ms]
May  3 12:34:39.558: INFO: Created: latency-svc-xtnbs
May  3 12:34:39.569: INFO: Created: latency-svc-5qv48
May  3 12:34:39.581: INFO: Created: latency-svc-hws22
May  3 12:34:39.588: INFO: Got endpoints: latency-svc-dh7wz [511.3116ms]
May  3 12:34:39.593: INFO: Created: latency-svc-b8lr7
May  3 12:34:39.607: INFO: Created: latency-svc-lc8sp
May  3 12:34:39.620: INFO: Created: latency-svc-6tqvp
May  3 12:34:39.631: INFO: Created: latency-svc-stssw
May  3 12:34:39.633: INFO: Got endpoints: latency-svc-8qnpp [541.0786ms]
May  3 12:34:39.646: INFO: Created: latency-svc-7wgbc
May  3 12:34:39.664: INFO: Created: latency-svc-22gsp
May  3 12:34:39.687: INFO: Got endpoints: latency-svc-pvvs4 [565.6142ms]
May  3 12:34:39.688: INFO: Created: latency-svc-4xlw2
May  3 12:34:39.708: INFO: Created: latency-svc-zrpcn
May  3 12:34:39.726: INFO: Created: latency-svc-c9xqv
May  3 12:34:39.728: INFO: Got endpoints: latency-svc-trt2p [600.7161ms]
May  3 12:34:39.742: INFO: Created: latency-svc-sdn5p
May  3 12:34:39.779: INFO: Got endpoints: latency-svc-gldfh [622.1642ms]
May  3 12:34:39.792: INFO: Created: latency-svc-kwmdz
May  3 12:34:39.828: INFO: Got endpoints: latency-svc-c9pgz [653.1301ms]
May  3 12:34:39.843: INFO: Created: latency-svc-n6rg9
May  3 12:34:39.883: INFO: Got endpoints: latency-svc-xtnbs [696.8103ms]
May  3 12:34:39.904: INFO: Created: latency-svc-rnpgx
May  3 12:34:39.927: INFO: Got endpoints: latency-svc-5qv48 [730.8242ms]
May  3 12:34:39.943: INFO: Created: latency-svc-2q8rk
May  3 12:34:39.978: INFO: Got endpoints: latency-svc-hws22 [673.449ms]
May  3 12:34:39.997: INFO: Created: latency-svc-kxxrv
May  3 12:34:40.029: INFO: Got endpoints: latency-svc-b8lr7 [710.9607ms]
May  3 12:34:40.050: INFO: Created: latency-svc-2qwg6
May  3 12:34:40.078: INFO: Got endpoints: latency-svc-lc8sp [490.2244ms]
May  3 12:34:40.107: INFO: Created: latency-svc-4r5dc
May  3 12:34:40.128: INFO: Got endpoints: latency-svc-6tqvp [786.3129ms]
May  3 12:34:40.142: INFO: Created: latency-svc-9kjr9
May  3 12:34:40.178: INFO: Got endpoints: latency-svc-stssw [790.6443ms]
May  3 12:34:40.202: INFO: Created: latency-svc-gnmtl
May  3 12:34:40.228: INFO: Got endpoints: latency-svc-7wgbc [797.8802ms]
May  3 12:34:40.243: INFO: Created: latency-svc-lq2f2
May  3 12:34:40.277: INFO: Got endpoints: latency-svc-22gsp [770.0988ms]
May  3 12:34:40.297: INFO: Created: latency-svc-bgl5p
May  3 12:34:40.330: INFO: Got endpoints: latency-svc-4xlw2 [794.2162ms]
May  3 12:34:40.343: INFO: Created: latency-svc-mfdgg
May  3 12:34:40.380: INFO: Got endpoints: latency-svc-zrpcn [746.1357ms]
May  3 12:34:40.398: INFO: Created: latency-svc-znt9c
May  3 12:34:40.428: INFO: Got endpoints: latency-svc-c9xqv [741.5103ms]
May  3 12:34:40.453: INFO: Created: latency-svc-nhg2m
May  3 12:34:40.479: INFO: Got endpoints: latency-svc-sdn5p [750.8718ms]
May  3 12:34:40.494: INFO: Created: latency-svc-m862c
May  3 12:34:40.533: INFO: Got endpoints: latency-svc-kwmdz [753.4807ms]
May  3 12:34:40.556: INFO: Created: latency-svc-dj5sl
May  3 12:34:40.584: INFO: Got endpoints: latency-svc-n6rg9 [755.9092ms]
May  3 12:34:40.596: INFO: Created: latency-svc-srsx7
May  3 12:34:40.629: INFO: Got endpoints: latency-svc-rnpgx [745.6213ms]
May  3 12:34:40.643: INFO: Created: latency-svc-qrhpb
May  3 12:34:40.678: INFO: Got endpoints: latency-svc-2q8rk [750.8905ms]
May  3 12:34:40.694: INFO: Created: latency-svc-gp25g
May  3 12:34:40.728: INFO: Got endpoints: latency-svc-kxxrv [749.9099ms]
May  3 12:34:40.741: INFO: Created: latency-svc-qkj79
May  3 12:34:40.781: INFO: Got endpoints: latency-svc-2qwg6 [751.892ms]
May  3 12:34:40.797: INFO: Created: latency-svc-ktklx
May  3 12:34:40.830: INFO: Got endpoints: latency-svc-4r5dc [751.5531ms]
May  3 12:34:40.844: INFO: Created: latency-svc-7h4fg
May  3 12:34:40.879: INFO: Got endpoints: latency-svc-9kjr9 [750.8368ms]
May  3 12:34:40.918: INFO: Created: latency-svc-shb72
May  3 12:34:40.938: INFO: Got endpoints: latency-svc-gnmtl [759.4143ms]
May  3 12:34:40.982: INFO: Created: latency-svc-xmwvw
May  3 12:34:40.989: INFO: Got endpoints: latency-svc-lq2f2 [760.9019ms]
May  3 12:34:41.015: INFO: Created: latency-svc-pbhzs
May  3 12:34:41.031: INFO: Got endpoints: latency-svc-bgl5p [753.2572ms]
May  3 12:34:41.044: INFO: Created: latency-svc-kgnx9
May  3 12:34:41.084: INFO: Got endpoints: latency-svc-mfdgg [753.405ms]
May  3 12:34:41.105: INFO: Created: latency-svc-z9kw8
May  3 12:34:41.128: INFO: Got endpoints: latency-svc-znt9c [748.4493ms]
May  3 12:34:41.146: INFO: Created: latency-svc-nlldk
May  3 12:34:41.182: INFO: Got endpoints: latency-svc-nhg2m [753.2447ms]
May  3 12:34:41.207: INFO: Created: latency-svc-w2sgb
May  3 12:34:41.230: INFO: Got endpoints: latency-svc-m862c [751.5275ms]
May  3 12:34:41.316: INFO: Created: latency-svc-k24hw
May  3 12:34:41.328: INFO: Got endpoints: latency-svc-dj5sl [795.1249ms]
May  3 12:34:41.330: INFO: Got endpoints: latency-svc-srsx7 [746.1461ms]
May  3 12:34:41.346: INFO: Created: latency-svc-qpswt
May  3 12:34:41.355: INFO: Created: latency-svc-grhfg
May  3 12:34:41.394: INFO: Got endpoints: latency-svc-qrhpb [765.1366ms]
May  3 12:34:41.407: INFO: Created: latency-svc-hb87k
May  3 12:34:41.437: INFO: Got endpoints: latency-svc-gp25g [758.3872ms]
May  3 12:34:41.450: INFO: Created: latency-svc-7xms6
May  3 12:34:41.480: INFO: Got endpoints: latency-svc-qkj79 [751.7714ms]
May  3 12:34:41.495: INFO: Created: latency-svc-nkt4q
May  3 12:34:41.531: INFO: Got endpoints: latency-svc-ktklx [750.0547ms]
May  3 12:34:41.550: INFO: Created: latency-svc-djndf
May  3 12:34:41.581: INFO: Got endpoints: latency-svc-7h4fg [750.7628ms]
May  3 12:34:41.597: INFO: Created: latency-svc-dq2p4
May  3 12:34:41.629: INFO: Got endpoints: latency-svc-shb72 [749.5356ms]
May  3 12:34:41.659: INFO: Created: latency-svc-h9q6r
May  3 12:34:41.687: INFO: Got endpoints: latency-svc-xmwvw [749.2122ms]
May  3 12:34:41.701: INFO: Created: latency-svc-qmblf
May  3 12:34:41.728: INFO: Got endpoints: latency-svc-pbhzs [739.0768ms]
May  3 12:34:41.746: INFO: Created: latency-svc-slhnk
May  3 12:34:41.779: INFO: Got endpoints: latency-svc-kgnx9 [747.8099ms]
May  3 12:34:41.797: INFO: Created: latency-svc-cs9mb
May  3 12:34:41.829: INFO: Got endpoints: latency-svc-z9kw8 [745.6474ms]
May  3 12:34:41.851: INFO: Created: latency-svc-kl4vp
May  3 12:34:41.880: INFO: Got endpoints: latency-svc-nlldk [751.8236ms]
May  3 12:34:41.896: INFO: Created: latency-svc-67c4p
May  3 12:34:41.932: INFO: Got endpoints: latency-svc-w2sgb [749.5739ms]
May  3 12:34:41.946: INFO: Created: latency-svc-tfrw4
May  3 12:34:41.981: INFO: Got endpoints: latency-svc-k24hw [750.4355ms]
May  3 12:34:41.996: INFO: Created: latency-svc-5zss8
May  3 12:34:42.031: INFO: Got endpoints: latency-svc-qpswt [703.5577ms]
May  3 12:34:42.051: INFO: Created: latency-svc-4zr9v
May  3 12:34:42.078: INFO: Got endpoints: latency-svc-grhfg [747.2502ms]
May  3 12:34:42.111: INFO: Created: latency-svc-txk7p
May  3 12:34:42.129: INFO: Got endpoints: latency-svc-hb87k [734.8471ms]
May  3 12:34:42.146: INFO: Created: latency-svc-47b4f
May  3 12:34:42.178: INFO: Got endpoints: latency-svc-7xms6 [741.4974ms]
May  3 12:34:42.212: INFO: Created: latency-svc-lq8xq
May  3 12:34:42.229: INFO: Got endpoints: latency-svc-nkt4q [748.6532ms]
May  3 12:34:42.250: INFO: Created: latency-svc-5b2h4
May  3 12:34:42.283: INFO: Got endpoints: latency-svc-djndf [751.7349ms]
May  3 12:34:42.299: INFO: Created: latency-svc-rxzrx
May  3 12:34:42.329: INFO: Got endpoints: latency-svc-dq2p4 [747.9352ms]
May  3 12:34:42.344: INFO: Created: latency-svc-lgx2h
May  3 12:34:42.379: INFO: Got endpoints: latency-svc-h9q6r [750.4338ms]
May  3 12:34:42.399: INFO: Created: latency-svc-62d77
May  3 12:34:42.429: INFO: Got endpoints: latency-svc-qmblf [742.4872ms]
May  3 12:34:42.443: INFO: Created: latency-svc-wm66n
May  3 12:34:42.478: INFO: Got endpoints: latency-svc-slhnk [750.3231ms]
May  3 12:34:42.492: INFO: Created: latency-svc-pjz78
May  3 12:34:42.534: INFO: Got endpoints: latency-svc-cs9mb [754.827ms]
May  3 12:34:42.550: INFO: Created: latency-svc-lzgqb
May  3 12:34:42.579: INFO: Got endpoints: latency-svc-kl4vp [749.6499ms]
May  3 12:34:42.598: INFO: Created: latency-svc-g9sn4
May  3 12:34:42.630: INFO: Got endpoints: latency-svc-67c4p [749.613ms]
May  3 12:34:42.653: INFO: Created: latency-svc-gqdtm
May  3 12:34:42.678: INFO: Got endpoints: latency-svc-tfrw4 [746.386ms]
May  3 12:34:42.695: INFO: Created: latency-svc-qbfg9
May  3 12:34:42.729: INFO: Got endpoints: latency-svc-5zss8 [747.9917ms]
May  3 12:34:42.746: INFO: Created: latency-svc-j2w9q
May  3 12:34:42.780: INFO: Got endpoints: latency-svc-4zr9v [748.0172ms]
May  3 12:34:42.797: INFO: Created: latency-svc-7nqv7
May  3 12:34:42.829: INFO: Got endpoints: latency-svc-txk7p [751.4356ms]
May  3 12:34:42.843: INFO: Created: latency-svc-7hnn5
May  3 12:34:42.880: INFO: Got endpoints: latency-svc-47b4f [750.2538ms]
May  3 12:34:42.894: INFO: Created: latency-svc-x5gsq
May  3 12:34:42.932: INFO: Got endpoints: latency-svc-lq8xq [753.7223ms]
May  3 12:34:42.949: INFO: Created: latency-svc-7ph4k
May  3 12:34:42.979: INFO: Got endpoints: latency-svc-5b2h4 [749.1488ms]
May  3 12:34:42.996: INFO: Created: latency-svc-dm2zj
May  3 12:34:43.030: INFO: Got endpoints: latency-svc-rxzrx [746.3779ms]
May  3 12:34:43.046: INFO: Created: latency-svc-f5msr
May  3 12:34:43.080: INFO: Got endpoints: latency-svc-lgx2h [750.7575ms]
May  3 12:34:43.094: INFO: Created: latency-svc-kv6fz
May  3 12:34:43.129: INFO: Got endpoints: latency-svc-62d77 [749.538ms]
May  3 12:34:43.142: INFO: Created: latency-svc-xh8wn
May  3 12:34:43.183: INFO: Got endpoints: latency-svc-wm66n [753.5006ms]
May  3 12:34:43.196: INFO: Created: latency-svc-nlv45
May  3 12:34:43.230: INFO: Got endpoints: latency-svc-pjz78 [751.1138ms]
May  3 12:34:43.256: INFO: Created: latency-svc-84pjb
May  3 12:34:43.283: INFO: Got endpoints: latency-svc-lzgqb [747.7619ms]
May  3 12:34:43.300: INFO: Created: latency-svc-rdx85
May  3 12:34:43.328: INFO: Got endpoints: latency-svc-g9sn4 [749.4733ms]
May  3 12:34:43.346: INFO: Created: latency-svc-db6bp
May  3 12:34:43.378: INFO: Got endpoints: latency-svc-gqdtm [748.1941ms]
May  3 12:34:43.406: INFO: Created: latency-svc-wgqlf
May  3 12:34:43.432: INFO: Got endpoints: latency-svc-qbfg9 [753.318ms]
May  3 12:34:43.446: INFO: Created: latency-svc-xd4xp
May  3 12:34:43.478: INFO: Got endpoints: latency-svc-j2w9q [749.5208ms]
May  3 12:34:43.492: INFO: Created: latency-svc-fwp8b
May  3 12:34:43.529: INFO: Got endpoints: latency-svc-7nqv7 [748.3743ms]
May  3 12:34:43.544: INFO: Created: latency-svc-q2vq8
May  3 12:34:43.578: INFO: Got endpoints: latency-svc-7hnn5 [748.4314ms]
May  3 12:34:43.595: INFO: Created: latency-svc-bjggv
May  3 12:34:43.629: INFO: Got endpoints: latency-svc-x5gsq [749.2502ms]
May  3 12:34:43.641: INFO: Created: latency-svc-sqs9b
May  3 12:34:43.680: INFO: Got endpoints: latency-svc-7ph4k [747.8424ms]
May  3 12:34:43.690: INFO: Created: latency-svc-t62d2
May  3 12:34:43.731: INFO: Got endpoints: latency-svc-dm2zj [750.8885ms]
May  3 12:34:43.744: INFO: Created: latency-svc-bh4n5
May  3 12:34:43.784: INFO: Got endpoints: latency-svc-f5msr [753.774ms]
May  3 12:34:43.799: INFO: Created: latency-svc-vtnw7
May  3 12:34:43.837: INFO: Got endpoints: latency-svc-kv6fz [756.8465ms]
May  3 12:34:43.853: INFO: Created: latency-svc-fd5md
May  3 12:34:43.878: INFO: Got endpoints: latency-svc-xh8wn [749.1031ms]
May  3 12:34:43.987: INFO: Got endpoints: latency-svc-84pjb [757.2378ms]
May  3 12:34:43.988: INFO: Got endpoints: latency-svc-nlv45 [805.1058ms]
May  3 12:34:43.989: INFO: Created: latency-svc-gljrp
May  3 12:34:44.016: INFO: Created: latency-svc-bx6ww
May  3 12:34:44.032: INFO: Got endpoints: latency-svc-rdx85 [749.2616ms]
May  3 12:34:44.032: INFO: Created: latency-svc-442vm
May  3 12:34:44.050: INFO: Created: latency-svc-85hhc
May  3 12:34:44.088: INFO: Got endpoints: latency-svc-db6bp [759.0265ms]
May  3 12:34:44.100: INFO: Created: latency-svc-rvk6d
May  3 12:34:44.130: INFO: Got endpoints: latency-svc-wgqlf [752.2378ms]
May  3 12:34:44.144: INFO: Created: latency-svc-qz474
May  3 12:34:44.179: INFO: Got endpoints: latency-svc-xd4xp [746.9105ms]
May  3 12:34:44.213: INFO: Created: latency-svc-wgtk9
May  3 12:34:44.227: INFO: Got endpoints: latency-svc-fwp8b [748.9941ms]
May  3 12:34:44.243: INFO: Created: latency-svc-jjvnq
May  3 12:34:44.280: INFO: Got endpoints: latency-svc-q2vq8 [751.7789ms]
May  3 12:34:44.302: INFO: Created: latency-svc-zl8tc
May  3 12:34:44.329: INFO: Got endpoints: latency-svc-bjggv [750.9162ms]
May  3 12:34:44.346: INFO: Created: latency-svc-49xsr
May  3 12:34:44.378: INFO: Got endpoints: latency-svc-sqs9b [749.5077ms]
May  3 12:34:44.403: INFO: Created: latency-svc-5wtw9
May  3 12:34:44.434: INFO: Got endpoints: latency-svc-t62d2 [754.1092ms]
May  3 12:34:44.452: INFO: Created: latency-svc-56l8r
May  3 12:34:44.478: INFO: Got endpoints: latency-svc-bh4n5 [747.0703ms]
May  3 12:34:44.493: INFO: Created: latency-svc-8sxr6
May  3 12:34:44.532: INFO: Got endpoints: latency-svc-vtnw7 [748.9258ms]
May  3 12:34:44.545: INFO: Created: latency-svc-n8gn6
May  3 12:34:44.578: INFO: Got endpoints: latency-svc-fd5md [741.5222ms]
May  3 12:34:44.592: INFO: Created: latency-svc-bfvc5
May  3 12:34:44.629: INFO: Got endpoints: latency-svc-gljrp [750.7583ms]
May  3 12:34:44.650: INFO: Created: latency-svc-5xw8m
May  3 12:34:44.679: INFO: Got endpoints: latency-svc-bx6ww [691.7629ms]
May  3 12:34:44.694: INFO: Created: latency-svc-nl2wn
May  3 12:34:44.729: INFO: Got endpoints: latency-svc-442vm [740.5386ms]
May  3 12:34:44.751: INFO: Created: latency-svc-xhbzz
May  3 12:34:44.779: INFO: Got endpoints: latency-svc-85hhc [746.1833ms]
May  3 12:34:44.793: INFO: Created: latency-svc-7r2z4
May  3 12:34:44.830: INFO: Got endpoints: latency-svc-rvk6d [742.3882ms]
May  3 12:34:44.851: INFO: Created: latency-svc-94pl5
May  3 12:34:44.879: INFO: Got endpoints: latency-svc-qz474 [748.2602ms]
May  3 12:34:44.898: INFO: Created: latency-svc-wnrxv
May  3 12:34:44.928: INFO: Got endpoints: latency-svc-wgtk9 [749.2629ms]
May  3 12:34:44.946: INFO: Created: latency-svc-6w25f
May  3 12:34:44.982: INFO: Got endpoints: latency-svc-jjvnq [754.2586ms]
May  3 12:34:44.998: INFO: Created: latency-svc-q8cjk
May  3 12:34:45.028: INFO: Got endpoints: latency-svc-zl8tc [747.2286ms]
May  3 12:34:45.056: INFO: Created: latency-svc-lt7lt
May  3 12:34:45.094: INFO: Got endpoints: latency-svc-49xsr [764.9477ms]
May  3 12:34:45.122: INFO: Created: latency-svc-w4rqw
May  3 12:34:45.127: INFO: Got endpoints: latency-svc-5wtw9 [748.6154ms]
May  3 12:34:45.141: INFO: Created: latency-svc-nx557
May  3 12:34:45.179: INFO: Got endpoints: latency-svc-56l8r [744.9619ms]
May  3 12:34:45.202: INFO: Created: latency-svc-mswlz
May  3 12:34:45.229: INFO: Got endpoints: latency-svc-8sxr6 [750.533ms]
May  3 12:34:45.244: INFO: Created: latency-svc-v5jnl
May  3 12:34:45.283: INFO: Got endpoints: latency-svc-n8gn6 [750.4105ms]
May  3 12:34:45.306: INFO: Created: latency-svc-zrkk9
May  3 12:34:45.328: INFO: Got endpoints: latency-svc-bfvc5 [749.0382ms]
May  3 12:34:45.346: INFO: Created: latency-svc-t6lxv
May  3 12:34:45.378: INFO: Got endpoints: latency-svc-5xw8m [748.5044ms]
May  3 12:34:45.394: INFO: Created: latency-svc-vt6kl
May  3 12:34:45.429: INFO: Got endpoints: latency-svc-nl2wn [750.2388ms]
May  3 12:34:45.450: INFO: Created: latency-svc-r5dxk
May  3 12:34:45.479: INFO: Got endpoints: latency-svc-xhbzz [749.9631ms]
May  3 12:34:45.496: INFO: Created: latency-svc-77s9d
May  3 12:34:45.528: INFO: Got endpoints: latency-svc-7r2z4 [748.9853ms]
May  3 12:34:45.543: INFO: Created: latency-svc-tsp78
May  3 12:34:45.578: INFO: Got endpoints: latency-svc-94pl5 [747.9318ms]
May  3 12:34:45.597: INFO: Created: latency-svc-zdhqh
May  3 12:34:45.629: INFO: Got endpoints: latency-svc-wnrxv [750.2051ms]
May  3 12:34:45.646: INFO: Created: latency-svc-xds7s
May  3 12:34:45.682: INFO: Got endpoints: latency-svc-6w25f [753.6066ms]
May  3 12:34:45.694: INFO: Created: latency-svc-2lmkz
May  3 12:34:45.728: INFO: Got endpoints: latency-svc-q8cjk [746.3986ms]
May  3 12:34:45.749: INFO: Created: latency-svc-rn95v
May  3 12:34:45.780: INFO: Got endpoints: latency-svc-lt7lt [752.3265ms]
May  3 12:34:45.796: INFO: Created: latency-svc-dldpp
May  3 12:34:45.834: INFO: Got endpoints: latency-svc-w4rqw [739.5799ms]
May  3 12:34:45.858: INFO: Created: latency-svc-7vlnv
May  3 12:34:45.879: INFO: Got endpoints: latency-svc-nx557 [751.3854ms]
May  3 12:34:45.898: INFO: Created: latency-svc-rrc28
May  3 12:34:45.930: INFO: Got endpoints: latency-svc-mswlz [750.2142ms]
May  3 12:34:45.948: INFO: Created: latency-svc-kbsrv
May  3 12:34:45.979: INFO: Got endpoints: latency-svc-v5jnl [750.3364ms]
May  3 12:34:45.992: INFO: Created: latency-svc-b9q75
May  3 12:34:46.030: INFO: Got endpoints: latency-svc-zrkk9 [746.4759ms]
May  3 12:34:46.043: INFO: Created: latency-svc-dp8pn
May  3 12:34:46.078: INFO: Got endpoints: latency-svc-t6lxv [750.7317ms]
May  3 12:34:46.098: INFO: Created: latency-svc-x6h8w
May  3 12:34:46.128: INFO: Got endpoints: latency-svc-vt6kl [750.6261ms]
May  3 12:34:46.157: INFO: Created: latency-svc-jkxws
May  3 12:34:46.180: INFO: Got endpoints: latency-svc-r5dxk [750.2553ms]
May  3 12:34:46.204: INFO: Created: latency-svc-htp5v
May  3 12:34:46.232: INFO: Got endpoints: latency-svc-77s9d [752.8278ms]
May  3 12:34:46.248: INFO: Created: latency-svc-kgtpg
May  3 12:34:46.278: INFO: Got endpoints: latency-svc-tsp78 [750.1226ms]
May  3 12:34:46.291: INFO: Created: latency-svc-4wh9w
May  3 12:34:46.329: INFO: Got endpoints: latency-svc-zdhqh [750.3848ms]
May  3 12:34:46.382: INFO: Got endpoints: latency-svc-xds7s [752.4922ms]
May  3 12:34:46.428: INFO: Got endpoints: latency-svc-2lmkz [746.6431ms]
May  3 12:34:46.483: INFO: Got endpoints: latency-svc-rn95v [754.5379ms]
May  3 12:34:46.529: INFO: Got endpoints: latency-svc-dldpp [748.8827ms]
May  3 12:34:46.579: INFO: Got endpoints: latency-svc-7vlnv [740.3678ms]
May  3 12:34:46.635: INFO: Got endpoints: latency-svc-rrc28 [756.0905ms]
May  3 12:34:46.679: INFO: Got endpoints: latency-svc-kbsrv [749.2596ms]
May  3 12:34:46.729: INFO: Got endpoints: latency-svc-b9q75 [749.9302ms]
May  3 12:34:46.782: INFO: Got endpoints: latency-svc-dp8pn [751.525ms]
May  3 12:34:46.828: INFO: Got endpoints: latency-svc-x6h8w [749.6408ms]
May  3 12:34:46.878: INFO: Got endpoints: latency-svc-jkxws [749.0919ms]
May  3 12:34:46.929: INFO: Got endpoints: latency-svc-htp5v [749.209ms]
May  3 12:34:46.979: INFO: Got endpoints: latency-svc-kgtpg [746.33ms]
May  3 12:34:47.028: INFO: Got endpoints: latency-svc-4wh9w [749.9739ms]
May  3 12:34:47.028: INFO: Latencies: [35.201ms 57.3412ms 62.0209ms 98.6485ms 105.2ms 115.9297ms 133.6649ms 142.7607ms 157.4242ms 176.2151ms 194.7697ms 216.2427ms 217.3004ms 217.3855ms 217.7871ms 219.4914ms 219.741ms 223.1983ms 225.1078ms 226.6206ms 227.0332ms 228.9456ms 229.6173ms 230.603ms 231.1916ms 231.6595ms 241.9527ms 243.594ms 247.1775ms 248.8512ms 249.7427ms 251.5219ms 251.8179ms 252.8521ms 253.4079ms 254.1135ms 254.9322ms 255.9067ms 259.7747ms 261.2055ms 261.6671ms 264.2901ms 275.7089ms 335.2964ms 336.6038ms 344.8713ms 363.3458ms 390.5996ms 452.0856ms 462.0431ms 490.2244ms 511.3116ms 541.0786ms 565.6142ms 600.7161ms 622.1642ms 653.1301ms 673.449ms 691.7629ms 696.8103ms 703.5577ms 710.9607ms 730.8242ms 734.8471ms 739.0768ms 739.5799ms 740.3678ms 740.5386ms 741.4974ms 741.5103ms 741.5222ms 742.3882ms 742.4872ms 744.9619ms 745.6213ms 745.6474ms 746.1357ms 746.1461ms 746.1833ms 746.33ms 746.3779ms 746.386ms 746.3986ms 746.4759ms 746.6431ms 746.9105ms 747.0703ms 747.2286ms 747.2502ms 747.7619ms 747.8099ms 747.8424ms 747.9318ms 747.9352ms 747.9917ms 748.0172ms 748.1941ms 748.2602ms 748.3743ms 748.4314ms 748.4493ms 748.5044ms 748.6154ms 748.6532ms 748.8827ms 748.9258ms 748.9853ms 748.9941ms 749.0382ms 749.0919ms 749.1031ms 749.1488ms 749.209ms 749.2122ms 749.2502ms 749.2596ms 749.2616ms 749.2629ms 749.4733ms 749.5077ms 749.5208ms 749.5356ms 749.538ms 749.5739ms 749.613ms 749.6408ms 749.6499ms 749.9099ms 749.9302ms 749.9631ms 749.9739ms 750.0547ms 750.1226ms 750.2051ms 750.2142ms 750.2388ms 750.2538ms 750.2553ms 750.3231ms 750.3364ms 750.3848ms 750.4105ms 750.4338ms 750.4355ms 750.533ms 750.6261ms 750.7317ms 750.7575ms 750.7583ms 750.7628ms 750.8368ms 750.8718ms 750.8885ms 750.8905ms 750.9162ms 751.1138ms 751.3854ms 751.4356ms 751.525ms 751.5275ms 751.5531ms 751.7349ms 751.7714ms 751.7789ms 751.8236ms 751.892ms 752.2378ms 752.3265ms 752.4922ms 752.8278ms 753.2447ms 753.2572ms 753.318ms 753.405ms 753.4807ms 753.5006ms 753.6066ms 753.7223ms 753.774ms 754.1092ms 754.2586ms 754.5379ms 754.827ms 755.9092ms 756.0905ms 756.8465ms 757.2378ms 758.3872ms 759.0265ms 759.4143ms 760.9019ms 764.9477ms 765.1366ms 770.0988ms 786.3129ms 790.6443ms 794.2162ms 795.1249ms 797.8802ms 805.1058ms]
May  3 12:34:47.028: INFO: 50 %ile: 748.4493ms
May  3 12:34:47.029: INFO: 90 %ile: 754.2586ms
May  3 12:34:47.029: INFO: 99 %ile: 797.8802ms
May  3 12:34:47.029: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:34:47.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-6813" for this suite.
May  3 12:34:59.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:34:59.137: INFO: namespace svc-latency-6813 deletion completed in 12.1041932s

• [SLOW TEST:24.866 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:34:59.138: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-2047
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-2047
STEP: Creating statefulset with conflicting port in namespace statefulset-2047
STEP: Waiting until pod test-pod will start running in namespace statefulset-2047
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-2047
May  3 12:35:03.198: INFO: Observed stateful pod in namespace: statefulset-2047, name: ss-0, uid: df5bb0fb-6d9f-11e9-9efa-00155da4710f, status phase: Failed. Waiting for statefulset controller to delete.
May  3 12:35:03.198: INFO: Observed stateful pod in namespace: statefulset-2047, name: ss-0, uid: df5bb0fb-6d9f-11e9-9efa-00155da4710f, status phase: Failed. Waiting for statefulset controller to delete.
May  3 12:35:03.210: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-2047
STEP: Removing pod with conflicting port in namespace statefulset-2047
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-2047 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May  3 12:35:07.250: INFO: Deleting all statefulset in ns statefulset-2047
May  3 12:35:07.252: INFO: Scaling statefulset ss to 0
May  3 12:35:17.267: INFO: Waiting for statefulset status.replicas updated to 0
May  3 12:35:17.271: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:35:17.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2047" for this suite.
May  3 12:35:23.323: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:35:23.421: INFO: namespace statefulset-2047 deletion completed in 6.1222704s

• [SLOW TEST:24.284 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:35:23.421: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May  3 12:35:23.454: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ebc7a45a-6d9f-11e9-a622-a62f37ba3446" in namespace "projected-7874" to be "success or failure"
May  3 12:35:23.461: INFO: Pod "downwardapi-volume-ebc7a45a-6d9f-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 7.054ms
May  3 12:35:25.468: INFO: Pod "downwardapi-volume-ebc7a45a-6d9f-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0143297s
May  3 12:35:27.472: INFO: Pod "downwardapi-volume-ebc7a45a-6d9f-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0178885s
STEP: Saw pod success
May  3 12:35:27.472: INFO: Pod "downwardapi-volume-ebc7a45a-6d9f-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 12:35:27.475: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-ebc7a45a-6d9f-11e9-a622-a62f37ba3446 container client-container: <nil>
STEP: delete the pod
May  3 12:35:27.497: INFO: Waiting for pod downwardapi-volume-ebc7a45a-6d9f-11e9-a622-a62f37ba3446 to disappear
May  3 12:35:27.500: INFO: Pod downwardapi-volume-ebc7a45a-6d9f-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:35:27.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7874" for this suite.
May  3 12:35:33.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:35:33.597: INFO: namespace projected-7874 deletion completed in 6.08141s

• [SLOW TEST:10.176 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:35:33.598: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
May  3 12:35:33.635: INFO: Pod name pod-release: Found 0 pods out of 1
May  3 12:35:38.644: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:35:39.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5851" for this suite.
May  3 12:35:45.740: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:35:45.825: INFO: namespace replication-controller-5851 deletion completed in 6.1484302s

• [SLOW TEST:12.227 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:35:45.825: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May  3 12:35:45.855: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f9220361-6d9f-11e9-a622-a62f37ba3446" in namespace "downward-api-4032" to be "success or failure"
May  3 12:35:45.864: INFO: Pod "downwardapi-volume-f9220361-6d9f-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 9.1655ms
May  3 12:35:47.869: INFO: Pod "downwardapi-volume-f9220361-6d9f-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0146047s
May  3 12:35:49.873: INFO: Pod "downwardapi-volume-f9220361-6d9f-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0185956s
STEP: Saw pod success
May  3 12:35:49.873: INFO: Pod "downwardapi-volume-f9220361-6d9f-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 12:35:49.878: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-f9220361-6d9f-11e9-a622-a62f37ba3446 container client-container: <nil>
STEP: delete the pod
May  3 12:35:49.909: INFO: Waiting for pod downwardapi-volume-f9220361-6d9f-11e9-a622-a62f37ba3446 to disappear
May  3 12:35:49.912: INFO: Pod downwardapi-volume-f9220361-6d9f-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:35:49.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4032" for this suite.
May  3 12:35:55.925: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:35:56.025: INFO: namespace downward-api-4032 deletion completed in 6.110928s

• [SLOW TEST:10.200 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:35:56.025: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May  3 12:35:56.051: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ff362542-6d9f-11e9-a622-a62f37ba3446" in namespace "downward-api-8824" to be "success or failure"
May  3 12:35:56.061: INFO: Pod "downwardapi-volume-ff362542-6d9f-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 9.5187ms
May  3 12:35:58.069: INFO: Pod "downwardapi-volume-ff362542-6d9f-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0179033s
May  3 12:36:00.075: INFO: Pod "downwardapi-volume-ff362542-6d9f-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023617s
STEP: Saw pod success
May  3 12:36:00.075: INFO: Pod "downwardapi-volume-ff362542-6d9f-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 12:36:00.081: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-ff362542-6d9f-11e9-a622-a62f37ba3446 container client-container: <nil>
STEP: delete the pod
May  3 12:36:00.108: INFO: Waiting for pod downwardapi-volume-ff362542-6d9f-11e9-a622-a62f37ba3446 to disappear
May  3 12:36:00.112: INFO: Pod downwardapi-volume-ff362542-6d9f-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:36:00.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8824" for this suite.
May  3 12:36:06.125: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:36:06.237: INFO: namespace downward-api-8824 deletion completed in 6.1230464s

• [SLOW TEST:10.212 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:36:06.238: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
May  3 12:36:14.308: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5884 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May  3 12:36:14.308: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
May  3 12:36:14.450: INFO: Exec stderr: ""
May  3 12:36:14.450: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5884 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May  3 12:36:14.450: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
May  3 12:36:14.628: INFO: Exec stderr: ""
May  3 12:36:14.628: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5884 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May  3 12:36:14.628: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
May  3 12:36:14.721: INFO: Exec stderr: ""
May  3 12:36:14.721: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5884 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May  3 12:36:14.721: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
May  3 12:36:14.872: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
May  3 12:36:14.872: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5884 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May  3 12:36:14.872: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
May  3 12:36:15.035: INFO: Exec stderr: ""
May  3 12:36:15.035: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5884 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May  3 12:36:15.035: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
May  3 12:36:15.160: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
May  3 12:36:15.160: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5884 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May  3 12:36:15.160: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
May  3 12:36:15.302: INFO: Exec stderr: ""
May  3 12:36:15.302: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5884 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May  3 12:36:15.302: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
May  3 12:36:15.468: INFO: Exec stderr: ""
May  3 12:36:15.468: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5884 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May  3 12:36:15.468: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
May  3 12:36:15.622: INFO: Exec stderr: ""
May  3 12:36:15.622: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5884 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May  3 12:36:15.622: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
May  3 12:36:15.792: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:36:15.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-5884" for this suite.
May  3 12:36:57.820: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:36:57.919: INFO: namespace e2e-kubelet-etc-hosts-5884 deletion completed in 42.125011s

• [SLOW TEST:51.682 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:36:57.920: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-241b075b-6da0-11e9-a622-a62f37ba3446
STEP: Creating secret with name s-test-opt-upd-241b1731-6da0-11e9-a622-a62f37ba3446
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-241b075b-6da0-11e9-a622-a62f37ba3446
STEP: Updating secret s-test-opt-upd-241b1731-6da0-11e9-a622-a62f37ba3446
STEP: Creating secret with name s-test-opt-create-241b1761-6da0-11e9-a622-a62f37ba3446
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:37:04.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3367" for this suite.
May  3 12:37:26.087: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:37:26.181: INFO: namespace projected-3367 deletion completed in 22.1156339s

• [SLOW TEST:28.262 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:37:26.182: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:37:31.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-408" for this suite.
May  3 12:37:53.278: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:37:53.375: INFO: namespace replication-controller-408 deletion completed in 22.1123318s

• [SLOW TEST:27.193 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:37:53.376: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:37:53.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7412" for this suite.
May  3 12:37:59.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:37:59.562: INFO: namespace kubelet-test-7412 deletion completed in 6.1354108s

• [SLOW TEST:6.186 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:37:59.563: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May  3 12:37:59.628: INFO: Waiting up to 5m0s for pod "downwardapi-volume-48dad8bf-6da0-11e9-a622-a62f37ba3446" in namespace "projected-4272" to be "success or failure"
May  3 12:37:59.663: INFO: Pod "downwardapi-volume-48dad8bf-6da0-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 35.2467ms
May  3 12:38:01.668: INFO: Pod "downwardapi-volume-48dad8bf-6da0-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0399546s
May  3 12:38:03.670: INFO: Pod "downwardapi-volume-48dad8bf-6da0-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042359s
STEP: Saw pod success
May  3 12:38:03.670: INFO: Pod "downwardapi-volume-48dad8bf-6da0-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 12:38:03.672: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-48dad8bf-6da0-11e9-a622-a62f37ba3446 container client-container: <nil>
STEP: delete the pod
May  3 12:38:03.690: INFO: Waiting for pod downwardapi-volume-48dad8bf-6da0-11e9-a622-a62f37ba3446 to disappear
May  3 12:38:03.695: INFO: Pod downwardapi-volume-48dad8bf-6da0-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:38:03.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4272" for this suite.
May  3 12:38:09.711: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:38:09.810: INFO: namespace projected-4272 deletion completed in 6.1104779s

• [SLOW TEST:10.247 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:38:09.810: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:69
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Registering the sample API server.
May  3 12:38:10.614: INFO: new replicaset for deployment "sample-apiserver-deployment" is yet to be created
May  3 12:38:12.681: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692483890, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692483890, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692483890, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692483890, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  3 12:38:14.684: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692483890, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692483890, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692483890, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692483890, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  3 12:38:16.688: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692483890, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692483890, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692483890, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692483890, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  3 12:38:18.688: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692483890, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692483890, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692483890, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692483890, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  3 12:38:21.433: INFO: Waited 740.3228ms for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:60
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:38:21.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-6868" for this suite.
May  3 12:38:28.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:38:28.229: INFO: namespace aggregator-6868 deletion completed in 6.2260196s

• [SLOW TEST:18.419 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:38:28.233: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating cluster-info
May  3 12:38:28.300: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 cluster-info'
May  3 12:38:28.551: INFO: stderr: ""
May  3 12:38:28.551: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:38:28.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8749" for this suite.
May  3 12:38:34.573: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:38:34.743: INFO: namespace kubectl-8749 deletion completed in 6.1874751s

• [SLOW TEST:6.510 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:38:34.751: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the initial replication controller
May  3 12:38:34.820: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 create -f - --namespace=kubectl-714'
May  3 12:38:35.098: INFO: stderr: ""
May  3 12:38:35.098: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May  3 12:38:35.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-714'
May  3 12:38:35.235: INFO: stderr: ""
May  3 12:38:35.235: INFO: stdout: "update-demo-nautilus-9bzsg update-demo-nautilus-thwbq "
May  3 12:38:35.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pods update-demo-nautilus-9bzsg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-714'
May  3 12:38:35.314: INFO: stderr: ""
May  3 12:38:35.314: INFO: stdout: ""
May  3 12:38:35.314: INFO: update-demo-nautilus-9bzsg is created but not running
May  3 12:38:40.314: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-714'
May  3 12:38:40.390: INFO: stderr: ""
May  3 12:38:40.390: INFO: stdout: "update-demo-nautilus-9bzsg update-demo-nautilus-thwbq "
May  3 12:38:40.390: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pods update-demo-nautilus-9bzsg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-714'
May  3 12:38:40.471: INFO: stderr: ""
May  3 12:38:40.471: INFO: stdout: "true"
May  3 12:38:40.472: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pods update-demo-nautilus-9bzsg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-714'
May  3 12:38:40.555: INFO: stderr: ""
May  3 12:38:40.555: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May  3 12:38:40.555: INFO: validating pod update-demo-nautilus-9bzsg
May  3 12:38:40.578: INFO: got data: {
  "image": "nautilus.jpg"
}

May  3 12:38:40.578: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May  3 12:38:40.578: INFO: update-demo-nautilus-9bzsg is verified up and running
May  3 12:38:40.578: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pods update-demo-nautilus-thwbq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-714'
May  3 12:38:40.668: INFO: stderr: ""
May  3 12:38:40.668: INFO: stdout: "true"
May  3 12:38:40.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pods update-demo-nautilus-thwbq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-714'
May  3 12:38:40.747: INFO: stderr: ""
May  3 12:38:40.747: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May  3 12:38:40.747: INFO: validating pod update-demo-nautilus-thwbq
May  3 12:38:40.758: INFO: got data: {
  "image": "nautilus.jpg"
}

May  3 12:38:40.758: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May  3 12:38:40.758: INFO: update-demo-nautilus-thwbq is verified up and running
STEP: rolling-update to new replication controller
May  3 12:38:40.774: INFO: scanned /root for discovery docs: <nil>
May  3 12:38:40.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-714'
May  3 12:39:00.260: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
May  3 12:39:00.260: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May  3 12:39:00.260: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-714'
May  3 12:39:00.354: INFO: stderr: ""
May  3 12:39:00.354: INFO: stdout: "update-demo-kitten-6qcnt update-demo-kitten-d7tkt "
May  3 12:39:00.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pods update-demo-kitten-6qcnt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-714'
May  3 12:39:00.426: INFO: stderr: ""
May  3 12:39:00.427: INFO: stdout: "true"
May  3 12:39:00.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pods update-demo-kitten-6qcnt -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-714'
May  3 12:39:00.511: INFO: stderr: ""
May  3 12:39:00.511: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
May  3 12:39:00.511: INFO: validating pod update-demo-kitten-6qcnt
May  3 12:39:00.525: INFO: got data: {
  "image": "kitten.jpg"
}

May  3 12:39:00.525: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
May  3 12:39:00.525: INFO: update-demo-kitten-6qcnt is verified up and running
May  3 12:39:00.525: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pods update-demo-kitten-d7tkt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-714'
May  3 12:39:00.603: INFO: stderr: ""
May  3 12:39:00.603: INFO: stdout: "true"
May  3 12:39:00.604: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pods update-demo-kitten-d7tkt -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-714'
May  3 12:39:00.677: INFO: stderr: ""
May  3 12:39:00.677: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
May  3 12:39:00.677: INFO: validating pod update-demo-kitten-d7tkt
May  3 12:39:00.698: INFO: got data: {
  "image": "kitten.jpg"
}

May  3 12:39:00.698: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
May  3 12:39:00.698: INFO: update-demo-kitten-d7tkt is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:39:00.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-714" for this suite.
May  3 12:39:22.728: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:39:22.838: INFO: namespace kubectl-714 deletion completed in 22.1281414s

• [SLOW TEST:48.088 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:39:22.846: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
May  3 12:39:29.013: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May  3 12:39:29.022: INFO: Pod pod-with-poststart-exec-hook still exists
May  3 12:39:31.022: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May  3 12:39:31.033: INFO: Pod pod-with-poststart-exec-hook still exists
May  3 12:39:33.022: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May  3 12:39:33.039: INFO: Pod pod-with-poststart-exec-hook still exists
May  3 12:39:35.022: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May  3 12:39:35.037: INFO: Pod pod-with-poststart-exec-hook still exists
May  3 12:39:37.022: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May  3 12:39:37.030: INFO: Pod pod-with-poststart-exec-hook still exists
May  3 12:39:39.022: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May  3 12:39:39.032: INFO: Pod pod-with-poststart-exec-hook still exists
May  3 12:39:41.022: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May  3 12:39:41.028: INFO: Pod pod-with-poststart-exec-hook still exists
May  3 12:39:43.022: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May  3 12:39:43.057: INFO: Pod pod-with-poststart-exec-hook still exists
May  3 12:39:45.022: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May  3 12:39:45.031: INFO: Pod pod-with-poststart-exec-hook still exists
May  3 12:39:47.022: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May  3 12:39:47.034: INFO: Pod pod-with-poststart-exec-hook still exists
May  3 12:39:49.023: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May  3 12:39:49.038: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:39:49.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4962" for this suite.
May  3 12:40:11.071: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:40:11.188: INFO: namespace container-lifecycle-hook-4962 deletion completed in 22.1368195s

• [SLOW TEST:48.348 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:40:11.189: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating api versions
May  3 12:40:11.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 api-versions'
May  3 12:40:11.339: INFO: stderr: ""
May  3 12:40:11.339: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncompose.docker.com/v1alpha3\ncompose.docker.com/v1beta1\ncompose.docker.com/v1beta2\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:40:11.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4422" for this suite.
May  3 12:40:17.372: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:40:17.474: INFO: namespace kubectl-4422 deletion completed in 6.1229954s

• [SLOW TEST:6.285 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:40:17.474: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0503 12:40:18.194834      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May  3 12:40:18.196: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:40:18.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4630" for this suite.
May  3 12:40:24.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:40:24.347: INFO: namespace gc-4630 deletion completed in 6.1332372s

• [SLOW TEST:6.873 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:40:24.351: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
May  3 12:40:24.427: INFO: Waiting up to 5m0s for pod "pod-9f2ae3fc-6da0-11e9-a622-a62f37ba3446" in namespace "emptydir-9273" to be "success or failure"
May  3 12:40:24.440: INFO: Pod "pod-9f2ae3fc-6da0-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 12.5113ms
May  3 12:40:26.446: INFO: Pod "pod-9f2ae3fc-6da0-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0183054s
May  3 12:40:28.452: INFO: Pod "pod-9f2ae3fc-6da0-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0251683s
STEP: Saw pod success
May  3 12:40:28.453: INFO: Pod "pod-9f2ae3fc-6da0-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 12:40:28.492: INFO: Trying to get logs from node docker-desktop pod pod-9f2ae3fc-6da0-11e9-a622-a62f37ba3446 container test-container: <nil>
STEP: delete the pod
May  3 12:40:28.528: INFO: Waiting for pod pod-9f2ae3fc-6da0-11e9-a622-a62f37ba3446 to disappear
May  3 12:40:28.537: INFO: Pod pod-9f2ae3fc-6da0-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:40:28.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9273" for this suite.
May  3 12:40:34.566: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:40:34.664: INFO: namespace emptydir-9273 deletion completed in 6.1180331s

• [SLOW TEST:10.313 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:40:34.673: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-1245
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May  3 12:40:34.769: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May  3 12:40:56.888: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.1.0.98:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1245 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May  3 12:40:56.888: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
May  3 12:40:57.039: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:40:57.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1245" for this suite.
May  3 12:41:19.059: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:41:19.168: INFO: namespace pod-network-test-1245 deletion completed in 22.1255402s

• [SLOW TEST:44.495 seconds]
[sig-network] Networking
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:41:19.169: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May  3 12:41:19.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 version'
May  3 12:41:19.346: INFO: stderr: ""
May  3 12:41:19.346: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.1\", GitCommit:\"b7394102d6ef778017f2ca4046abbaa23b88c290\", GitTreeState:\"clean\", BuildDate:\"2019-04-08T17:11:31Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.1\", GitCommit:\"b7394102d6ef778017f2ca4046abbaa23b88c290\", GitTreeState:\"clean\", BuildDate:\"2019-04-08T17:02:58Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:41:19.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-19" for this suite.
May  3 12:41:25.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:41:25.466: INFO: namespace kubectl-19 deletion completed in 6.1051787s

• [SLOW TEST:6.296 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:41:25.466: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:41:27.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6397" for this suite.
May  3 12:42:17.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:42:17.709: INFO: namespace kubelet-test-6397 deletion completed in 50.1123212s

• [SLOW TEST:52.243 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:42:17.711: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May  3 12:42:17.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 version --client'
May  3 12:42:17.837: INFO: stderr: ""
May  3 12:42:17.837: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.1\", GitCommit:\"b7394102d6ef778017f2ca4046abbaa23b88c290\", GitTreeState:\"clean\", BuildDate:\"2019-04-08T17:11:31Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
May  3 12:42:17.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 create -f - --namespace=kubectl-8631'
May  3 12:42:18.021: INFO: stderr: ""
May  3 12:42:18.021: INFO: stdout: "replicationcontroller/redis-master created\n"
May  3 12:42:18.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 create -f - --namespace=kubectl-8631'
May  3 12:42:18.233: INFO: stderr: ""
May  3 12:42:18.233: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
May  3 12:42:19.239: INFO: Selector matched 1 pods for map[app:redis]
May  3 12:42:19.240: INFO: Found 0 / 1
May  3 12:42:20.235: INFO: Selector matched 1 pods for map[app:redis]
May  3 12:42:20.235: INFO: Found 0 / 1
May  3 12:42:21.238: INFO: Selector matched 1 pods for map[app:redis]
May  3 12:42:21.238: INFO: Found 0 / 1
May  3 12:42:22.235: INFO: Selector matched 1 pods for map[app:redis]
May  3 12:42:22.235: INFO: Found 1 / 1
May  3 12:42:22.235: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May  3 12:42:22.242: INFO: Selector matched 1 pods for map[app:redis]
May  3 12:42:22.242: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May  3 12:42:22.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 describe pod redis-master-jhlgp --namespace=kubectl-8631'
May  3 12:42:22.342: INFO: stderr: ""
May  3 12:42:22.342: INFO: stdout: "Name:               redis-master-jhlgp\nNamespace:          kubectl-8631\nPriority:           0\nPriorityClassName:  <none>\nNode:               docker-desktop/192.168.65.3\nStart Time:         Fri, 03 May 2019 12:42:18 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.1.0.101\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://3a8eed577abe2199900edbc7b9fa08fe51e9346d9f933d67dfb3934d012caf78\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Fri, 03 May 2019 12:42:20 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-c5ctl (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-c5ctl:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-c5ctl\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                     Message\n  ----    ------     ----  ----                     -------\n  Normal  Scheduled  4s    default-scheduler        Successfully assigned kubectl-8631/redis-master-jhlgp to docker-desktop\n  Normal  Pulling    3s    kubelet, docker-desktop  Pulling image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\"\n  Normal  Pulled     2s    kubelet, docker-desktop  Successfully pulled image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\"\n  Normal  Created    2s    kubelet, docker-desktop  Created container redis-master\n  Normal  Started    2s    kubelet, docker-desktop  Started container redis-master\n"
May  3 12:42:22.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 describe rc redis-master --namespace=kubectl-8631'
May  3 12:42:22.443: INFO: stderr: ""
May  3 12:42:22.443: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-8631\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  4s    replication-controller  Created pod: redis-master-jhlgp\n"
May  3 12:42:22.443: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 describe service redis-master --namespace=kubectl-8631'
May  3 12:42:22.554: INFO: stderr: ""
May  3 12:42:22.554: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-8631\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.102.69.106\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.1.0.101:6379\nSession Affinity:  None\nEvents:            <none>\n"
May  3 12:42:22.562: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 describe node docker-desktop'
May  3 12:42:22.652: INFO: stderr: ""
May  3 12:42:22.652: INFO: stdout: "Name:               docker-desktop\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=docker-desktop\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/master=\nAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Fri, 03 May 2019 10:35:13 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Fri, 03 May 2019 12:42:17 +0000   Fri, 03 May 2019 10:35:09 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Fri, 03 May 2019 12:42:17 +0000   Fri, 03 May 2019 10:35:09 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Fri, 03 May 2019 12:42:17 +0000   Fri, 03 May 2019 10:35:09 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Fri, 03 May 2019 12:42:17 +0000   Fri, 03 May 2019 10:35:09 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  192.168.65.3\n  Hostname:    docker-desktop\nCapacity:\n cpu:                2\n ephemeral-storage:  65792556Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             2027860Ki\n pods:               110\nAllocatable:\n cpu:                2\n ephemeral-storage:  60634419510\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             1925460Ki\n pods:               110\nSystem Info:\n Machine ID:                 \n System UUID:                3416FEC3-E2F8-4971-A2EB-875CB3C2B763\n Boot ID:                    d6375831-d87d-444a-9ad4-a208c5efbcae\n Kernel Version:             4.9.125-linuxkit\n OS Image:                   Docker Desktop\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://19.3.0\n Kubelet Version:            v1.14.1\n Kube-Proxy Version:         v1.14.1\nNon-terminated Pods:         (13 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  docker                     compose-6b69ff6b9d-7blnv                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         125m\n  docker                     compose-api-6c5bf98cc7-6gs2q                               0 (0%)        0 (0%)      0 (0%)           0 (0%)         125m\n  heptio-sonobuoy            sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         35m\n  heptio-sonobuoy            sonobuoy-e2e-job-36cd23f1d2644d64                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         35m\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-605fe68f13894439-lg7rb    0 (0%)        0 (0%)      0 (0%)           0 (0%)         35m\n  kube-system                coredns-fb8b8dccf-nrmdq                                    100m (5%)     0 (0%)      70Mi (3%)        170Mi (9%)     126m\n  kube-system                coredns-fb8b8dccf-qsc86                                    100m (5%)     0 (0%)      70Mi (3%)        170Mi (9%)     126m\n  kube-system                etcd-docker-desktop                                        0 (0%)        0 (0%)      0 (0%)           0 (0%)         125m\n  kube-system                kube-apiserver-docker-desktop                              250m (12%)    0 (0%)      0 (0%)           0 (0%)         126m\n  kube-system                kube-controller-manager-docker-desktop                     200m (10%)    0 (0%)      0 (0%)           0 (0%)         125m\n  kube-system                kube-proxy-gskn5                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         126m\n  kube-system                kube-scheduler-docker-desktop                              100m (5%)     0 (0%)      0 (0%)           0 (0%)         126m\n  kubectl-8631               redis-master-jhlgp                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         4s\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                750m (37%)  0 (0%)\n  memory             140Mi (7%)  340Mi (18%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:              <none>\n"
May  3 12:42:22.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 describe namespace kubectl-8631'
May  3 12:42:22.741: INFO: stderr: ""
May  3 12:42:22.741: INFO: stdout: "Name:         kubectl-8631\nLabels:       e2e-framework=kubectl\n              e2e-run=ff92cc19-6d9b-11e9-a622-a62f37ba3446\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:42:22.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8631" for this suite.
May  3 12:42:44.767: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:42:44.879: INFO: namespace kubectl-8631 deletion completed in 22.1318486s

• [SLOW TEST:27.168 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:42:44.879: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-f2ee3987-6da0-11e9-a622-a62f37ba3446
STEP: Creating a pod to test consume configMaps
May  3 12:42:44.973: INFO: Waiting up to 5m0s for pod "pod-configmaps-f2f118bf-6da0-11e9-a622-a62f37ba3446" in namespace "configmap-3995" to be "success or failure"
May  3 12:42:45.005: INFO: Pod "pod-configmaps-f2f118bf-6da0-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 31.0979ms
May  3 12:42:47.008: INFO: Pod "pod-configmaps-f2f118bf-6da0-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0343925s
STEP: Saw pod success
May  3 12:42:47.008: INFO: Pod "pod-configmaps-f2f118bf-6da0-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 12:42:47.011: INFO: Trying to get logs from node docker-desktop pod pod-configmaps-f2f118bf-6da0-11e9-a622-a62f37ba3446 container configmap-volume-test: <nil>
STEP: delete the pod
May  3 12:42:47.060: INFO: Waiting for pod pod-configmaps-f2f118bf-6da0-11e9-a622-a62f37ba3446 to disappear
May  3 12:42:47.078: INFO: Pod pod-configmaps-f2f118bf-6da0-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:42:47.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3995" for this suite.
May  3 12:42:53.135: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:42:53.225: INFO: namespace configmap-3995 deletion completed in 6.1175776s

• [SLOW TEST:8.346 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:42:53.225: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-5299
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
May  3 12:42:53.337: INFO: Found 0 stateful pods, waiting for 3
May  3 12:43:03.357: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May  3 12:43:03.357: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May  3 12:43:03.357: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
May  3 12:43:03.409: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
May  3 12:43:13.485: INFO: Updating stateful set ss2
May  3 12:43:13.500: INFO: Waiting for Pod statefulset-5299/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
May  3 12:43:23.673: INFO: Found 2 stateful pods, waiting for 3
May  3 12:43:33.680: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May  3 12:43:33.680: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May  3 12:43:33.680: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
May  3 12:43:33.732: INFO: Updating stateful set ss2
May  3 12:43:33.771: INFO: Waiting for Pod statefulset-5299/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
May  3 12:43:43.809: INFO: Updating stateful set ss2
May  3 12:43:43.871: INFO: Waiting for StatefulSet statefulset-5299/ss2 to complete update
May  3 12:43:43.871: INFO: Waiting for Pod statefulset-5299/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
May  3 12:43:53.876: INFO: Waiting for StatefulSet statefulset-5299/ss2 to complete update
May  3 12:43:53.876: INFO: Waiting for Pod statefulset-5299/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May  3 12:44:03.879: INFO: Deleting all statefulset in ns statefulset-5299
May  3 12:44:03.891: INFO: Scaling statefulset ss2 to 0
May  3 12:44:13.920: INFO: Waiting for statefulset status.replicas updated to 0
May  3 12:44:13.927: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:44:13.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5299" for this suite.
May  3 12:44:19.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:44:20.103: INFO: namespace statefulset-5299 deletion completed in 6.1406152s

• [SLOW TEST:86.878 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:44:20.111: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4941.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-4941.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4941.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-4941.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4941.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-4941.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4941.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-4941.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4941.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-4941.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4941.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-4941.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4941.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 45.218.97.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.97.218.45_udp@PTR;check="$$(dig +tcp +noall +answer +search 45.218.97.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.97.218.45_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4941.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-4941.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4941.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-4941.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4941.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-4941.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4941.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-4941.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4941.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-4941.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4941.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-4941.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4941.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 45.218.97.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.97.218.45_udp@PTR;check="$$(dig +tcp +noall +answer +search 45.218.97.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.97.218.45_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May  3 12:44:24.258: INFO: Unable to read wheezy_udp@dns-test-service.dns-4941.svc.cluster.local from pod dns-4941/dns-test-2bb5aa3d-6da1-11e9-a622-a62f37ba3446: the server could not find the requested resource (get pods dns-test-2bb5aa3d-6da1-11e9-a622-a62f37ba3446)
May  3 12:44:24.269: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4941.svc.cluster.local from pod dns-4941/dns-test-2bb5aa3d-6da1-11e9-a622-a62f37ba3446: the server could not find the requested resource (get pods dns-test-2bb5aa3d-6da1-11e9-a622-a62f37ba3446)
May  3 12:44:24.274: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4941.svc.cluster.local from pod dns-4941/dns-test-2bb5aa3d-6da1-11e9-a622-a62f37ba3446: the server could not find the requested resource (get pods dns-test-2bb5aa3d-6da1-11e9-a622-a62f37ba3446)
May  3 12:44:24.280: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4941.svc.cluster.local from pod dns-4941/dns-test-2bb5aa3d-6da1-11e9-a622-a62f37ba3446: the server could not find the requested resource (get pods dns-test-2bb5aa3d-6da1-11e9-a622-a62f37ba3446)
May  3 12:44:24.320: INFO: Unable to read jessie_udp@dns-test-service.dns-4941.svc.cluster.local from pod dns-4941/dns-test-2bb5aa3d-6da1-11e9-a622-a62f37ba3446: the server could not find the requested resource (get pods dns-test-2bb5aa3d-6da1-11e9-a622-a62f37ba3446)
May  3 12:44:24.333: INFO: Unable to read jessie_tcp@dns-test-service.dns-4941.svc.cluster.local from pod dns-4941/dns-test-2bb5aa3d-6da1-11e9-a622-a62f37ba3446: the server could not find the requested resource (get pods dns-test-2bb5aa3d-6da1-11e9-a622-a62f37ba3446)
May  3 12:44:24.340: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4941.svc.cluster.local from pod dns-4941/dns-test-2bb5aa3d-6da1-11e9-a622-a62f37ba3446: the server could not find the requested resource (get pods dns-test-2bb5aa3d-6da1-11e9-a622-a62f37ba3446)
May  3 12:44:24.347: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4941.svc.cluster.local from pod dns-4941/dns-test-2bb5aa3d-6da1-11e9-a622-a62f37ba3446: the server could not find the requested resource (get pods dns-test-2bb5aa3d-6da1-11e9-a622-a62f37ba3446)
May  3 12:44:24.381: INFO: Lookups using dns-4941/dns-test-2bb5aa3d-6da1-11e9-a622-a62f37ba3446 failed for: [wheezy_udp@dns-test-service.dns-4941.svc.cluster.local wheezy_tcp@dns-test-service.dns-4941.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4941.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4941.svc.cluster.local jessie_udp@dns-test-service.dns-4941.svc.cluster.local jessie_tcp@dns-test-service.dns-4941.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4941.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4941.svc.cluster.local]

May  3 12:44:29.496: INFO: DNS probes using dns-4941/dns-test-2bb5aa3d-6da1-11e9-a622-a62f37ba3446 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:44:29.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4941" for this suite.
May  3 12:44:35.716: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:44:35.819: INFO: namespace dns-4941 deletion completed in 6.1221924s

• [SLOW TEST:15.709 seconds]
[sig-network] DNS
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:44:35.820: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-350d4d20-6da1-11e9-a622-a62f37ba3446
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-350d4d20-6da1-11e9-a622-a62f37ba3446
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:45:52.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9594" for this suite.
May  3 12:46:14.609: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:46:14.723: INFO: namespace configmap-9594 deletion completed in 22.1338991s

• [SLOW TEST:98.903 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:46:14.723: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
May  3 12:46:14.787: INFO: Waiting up to 5m0s for pod "downward-api-700075f2-6da1-11e9-a622-a62f37ba3446" in namespace "downward-api-7426" to be "success or failure"
May  3 12:46:14.809: INFO: Pod "downward-api-700075f2-6da1-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 22.1315ms
May  3 12:46:16.819: INFO: Pod "downward-api-700075f2-6da1-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0326805s
STEP: Saw pod success
May  3 12:46:16.820: INFO: Pod "downward-api-700075f2-6da1-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 12:46:16.825: INFO: Trying to get logs from node docker-desktop pod downward-api-700075f2-6da1-11e9-a622-a62f37ba3446 container dapi-container: <nil>
STEP: delete the pod
May  3 12:46:16.873: INFO: Waiting for pod downward-api-700075f2-6da1-11e9-a622-a62f37ba3446 to disappear
May  3 12:46:16.887: INFO: Pod downward-api-700075f2-6da1-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:46:16.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7426" for this suite.
May  3 12:46:22.909: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:46:23.011: INFO: namespace downward-api-7426 deletion completed in 6.1191152s

• [SLOW TEST:8.287 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:46:23.011: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-74f417cd-6da1-11e9-a622-a62f37ba3446
STEP: Creating a pod to test consume configMaps
May  3 12:46:23.119: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-74f5338e-6da1-11e9-a622-a62f37ba3446" in namespace "projected-2840" to be "success or failure"
May  3 12:46:23.133: INFO: Pod "pod-projected-configmaps-74f5338e-6da1-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 13.5461ms
May  3 12:46:25.135: INFO: Pod "pod-projected-configmaps-74f5338e-6da1-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0160783s
STEP: Saw pod success
May  3 12:46:25.135: INFO: Pod "pod-projected-configmaps-74f5338e-6da1-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 12:46:25.138: INFO: Trying to get logs from node docker-desktop pod pod-projected-configmaps-74f5338e-6da1-11e9-a622-a62f37ba3446 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May  3 12:46:25.172: INFO: Waiting for pod pod-projected-configmaps-74f5338e-6da1-11e9-a622-a62f37ba3446 to disappear
May  3 12:46:25.184: INFO: Pod pod-projected-configmaps-74f5338e-6da1-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:46:25.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2840" for this suite.
May  3 12:46:31.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:46:31.310: INFO: namespace projected-2840 deletion completed in 6.113391s

• [SLOW TEST:8.299 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:46:31.310: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-79e37524-6da1-11e9-a622-a62f37ba3446
STEP: Creating a pod to test consume configMaps
May  3 12:46:31.380: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-79e4c1ef-6da1-11e9-a622-a62f37ba3446" in namespace "projected-2370" to be "success or failure"
May  3 12:46:31.391: INFO: Pod "pod-projected-configmaps-79e4c1ef-6da1-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 11.7297ms
May  3 12:46:33.394: INFO: Pod "pod-projected-configmaps-79e4c1ef-6da1-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0143186s
STEP: Saw pod success
May  3 12:46:33.394: INFO: Pod "pod-projected-configmaps-79e4c1ef-6da1-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 12:46:33.397: INFO: Trying to get logs from node docker-desktop pod pod-projected-configmaps-79e4c1ef-6da1-11e9-a622-a62f37ba3446 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May  3 12:46:33.430: INFO: Waiting for pod pod-projected-configmaps-79e4c1ef-6da1-11e9-a622-a62f37ba3446 to disappear
May  3 12:46:33.440: INFO: Pod pod-projected-configmaps-79e4c1ef-6da1-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:46:33.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2370" for this suite.
May  3 12:46:39.478: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:46:39.586: INFO: namespace projected-2370 deletion completed in 6.1348124s

• [SLOW TEST:8.276 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:46:39.586: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-7ed3088b-6da1-11e9-a622-a62f37ba3446
STEP: Creating a pod to test consume secrets
May  3 12:46:39.665: INFO: Waiting up to 5m0s for pod "pod-secrets-7ed4a8e0-6da1-11e9-a622-a62f37ba3446" in namespace "secrets-4943" to be "success or failure"
May  3 12:46:39.688: INFO: Pod "pod-secrets-7ed4a8e0-6da1-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 22.9172ms
May  3 12:46:41.691: INFO: Pod "pod-secrets-7ed4a8e0-6da1-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0255817s
STEP: Saw pod success
May  3 12:46:41.691: INFO: Pod "pod-secrets-7ed4a8e0-6da1-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 12:46:41.694: INFO: Trying to get logs from node docker-desktop pod pod-secrets-7ed4a8e0-6da1-11e9-a622-a62f37ba3446 container secret-volume-test: <nil>
STEP: delete the pod
May  3 12:46:41.725: INFO: Waiting for pod pod-secrets-7ed4a8e0-6da1-11e9-a622-a62f37ba3446 to disappear
May  3 12:46:41.734: INFO: Pod pod-secrets-7ed4a8e0-6da1-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:46:41.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4943" for this suite.
May  3 12:46:47.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:46:47.862: INFO: namespace secrets-4943 deletion completed in 6.114144s

• [SLOW TEST:8.276 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:46:47.863: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating secret secrets-1475/secret-test-83c2b26c-6da1-11e9-a622-a62f37ba3446
STEP: Creating a pod to test consume secrets
May  3 12:46:47.947: INFO: Waiting up to 5m0s for pod "pod-configmaps-83c48f25-6da1-11e9-a622-a62f37ba3446" in namespace "secrets-1475" to be "success or failure"
May  3 12:46:47.958: INFO: Pod "pod-configmaps-83c48f25-6da1-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 10.6218ms
May  3 12:46:49.961: INFO: Pod "pod-configmaps-83c48f25-6da1-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0132991s
STEP: Saw pod success
May  3 12:46:49.961: INFO: Pod "pod-configmaps-83c48f25-6da1-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 12:46:49.965: INFO: Trying to get logs from node docker-desktop pod pod-configmaps-83c48f25-6da1-11e9-a622-a62f37ba3446 container env-test: <nil>
STEP: delete the pod
May  3 12:46:49.994: INFO: Waiting for pod pod-configmaps-83c48f25-6da1-11e9-a622-a62f37ba3446 to disappear
May  3 12:46:50.002: INFO: Pod pod-configmaps-83c48f25-6da1-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:46:50.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1475" for this suite.
May  3 12:46:56.031: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:46:56.112: INFO: namespace secrets-1475 deletion completed in 6.1043751s

• [SLOW TEST:8.250 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:46:56.119: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override command
May  3 12:46:56.206: INFO: Waiting up to 5m0s for pod "client-containers-88ae39d5-6da1-11e9-a622-a62f37ba3446" in namespace "containers-4720" to be "success or failure"
May  3 12:46:56.219: INFO: Pod "client-containers-88ae39d5-6da1-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 9.0339ms
May  3 12:46:58.225: INFO: Pod "client-containers-88ae39d5-6da1-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0152546s
May  3 12:47:00.227: INFO: Pod "client-containers-88ae39d5-6da1-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0175346s
STEP: Saw pod success
May  3 12:47:00.227: INFO: Pod "client-containers-88ae39d5-6da1-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 12:47:00.231: INFO: Trying to get logs from node docker-desktop pod client-containers-88ae39d5-6da1-11e9-a622-a62f37ba3446 container test-container: <nil>
STEP: delete the pod
May  3 12:47:00.314: INFO: Waiting for pod client-containers-88ae39d5-6da1-11e9-a622-a62f37ba3446 to disappear
May  3 12:47:00.317: INFO: Pod client-containers-88ae39d5-6da1-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:47:00.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-4720" for this suite.
May  3 12:47:06.376: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:47:06.460: INFO: namespace containers-4720 deletion completed in 6.1398172s

• [SLOW TEST:10.341 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:47:06.467: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-9838
May  3 12:47:10.567: INFO: Started pod liveness-http in namespace container-probe-9838
STEP: checking the pod's current state and verifying that restartCount is present
May  3 12:47:10.576: INFO: Initial restart count of pod liveness-http is 0
May  3 12:47:28.644: INFO: Restart count of pod container-probe-9838/liveness-http is now 1 (18.0685028s elapsed)
May  3 12:47:48.701: INFO: Restart count of pod container-probe-9838/liveness-http is now 2 (38.1253164s elapsed)
May  3 12:48:08.745: INFO: Restart count of pod container-probe-9838/liveness-http is now 3 (58.1692881s elapsed)
May  3 12:48:28.826: INFO: Restart count of pod container-probe-9838/liveness-http is now 4 (1m18.2505725s elapsed)
May  3 12:49:32.982: INFO: Restart count of pod container-probe-9838/liveness-http is now 5 (2m22.4062705s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:49:32.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9838" for this suite.
May  3 12:49:39.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:49:39.124: INFO: namespace container-probe-9838 deletion completed in 6.1053404s

• [SLOW TEST:152.659 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:49:39.130: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
May  3 12:49:39.178: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May  3 12:49:39.193: INFO: Waiting for terminating namespaces to be deleted...
May  3 12:49:39.200: INFO: 
Logging pods the kubelet thinks is on node docker-desktop before test
May  3 12:49:39.225: INFO: kube-apiserver-docker-desktop from kube-system started at <nil> (0 container statuses recorded)
May  3 12:49:39.226: INFO: kube-controller-manager-docker-desktop from kube-system started at <nil> (0 container statuses recorded)
May  3 12:49:39.226: INFO: coredns-fb8b8dccf-nrmdq from kube-system started at 2019-05-03 10:35:24 +0000 UTC (1 container statuses recorded)
May  3 12:49:39.226: INFO: 	Container coredns ready: true, restart count 0
May  3 12:49:39.233: INFO: coredns-fb8b8dccf-qsc86 from kube-system started at 2019-05-03 10:35:24 +0000 UTC (1 container statuses recorded)
May  3 12:49:39.234: INFO: 	Container coredns ready: true, restart count 0
May  3 12:49:39.234: INFO: compose-api-6c5bf98cc7-6gs2q from docker started at 2019-05-03 10:36:34 +0000 UTC (1 container statuses recorded)
May  3 12:49:39.234: INFO: 	Container compose ready: true, restart count 0
May  3 12:49:39.234: INFO: sonobuoy-e2e-job-36cd23f1d2644d64 from heptio-sonobuoy started at 2019-05-03 12:06:54 +0000 UTC (2 container statuses recorded)
May  3 12:49:39.234: INFO: 	Container e2e ready: true, restart count 0
May  3 12:49:39.234: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May  3 12:49:39.234: INFO: sonobuoy from heptio-sonobuoy started at 2019-05-03 12:06:48 +0000 UTC (1 container statuses recorded)
May  3 12:49:39.234: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May  3 12:49:39.234: INFO: etcd-docker-desktop from kube-system started at <nil> (0 container statuses recorded)
May  3 12:49:39.235: INFO: kube-scheduler-docker-desktop from kube-system started at <nil> (0 container statuses recorded)
May  3 12:49:39.235: INFO: kube-proxy-gskn5 from kube-system started at 2019-05-03 10:35:24 +0000 UTC (1 container statuses recorded)
May  3 12:49:39.235: INFO: 	Container kube-proxy ready: true, restart count 0
May  3 12:49:39.235: INFO: compose-6b69ff6b9d-7blnv from docker started at 2019-05-03 10:36:34 +0000 UTC (1 container statuses recorded)
May  3 12:49:39.235: INFO: 	Container compose ready: true, restart count 0
May  3 12:49:39.235: INFO: sonobuoy-systemd-logs-daemon-set-605fe68f13894439-lg7rb from heptio-sonobuoy started at 2019-05-03 12:06:54 +0000 UTC (2 container statuses recorded)
May  3 12:49:39.236: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May  3 12:49:39.236: INFO: 	Container systemd-logs ready: false, restart count 13
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-eb1aea00-6da1-11e9-a622-a62f37ba3446 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-eb1aea00-6da1-11e9-a622-a62f37ba3446 off the node docker-desktop
STEP: verifying the node doesn't have the label kubernetes.io/e2e-eb1aea00-6da1-11e9-a622-a62f37ba3446
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:49:45.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4833" for this suite.
May  3 12:49:53.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:49:53.598: INFO: namespace sched-pred-4833 deletion completed in 8.134943s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:14.468 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:49:53.598: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May  3 12:49:53.721: INFO: (0) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 11.8919ms)
May  3 12:49:53.733: INFO: (1) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 12.0996ms)
May  3 12:49:53.744: INFO: (2) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 11.1211ms)
May  3 12:49:53.755: INFO: (3) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 10.6114ms)
May  3 12:49:53.767: INFO: (4) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 12.4743ms)
May  3 12:49:53.775: INFO: (5) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 8.1693ms)
May  3 12:49:53.786: INFO: (6) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 10.7755ms)
May  3 12:49:53.795: INFO: (7) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 8.184ms)
May  3 12:49:53.811: INFO: (8) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 16.2398ms)
May  3 12:49:53.819: INFO: (9) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 8.4895ms)
May  3 12:49:53.851: INFO: (10) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 31.4964ms)
May  3 12:49:53.869: INFO: (11) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 17.9211ms)
May  3 12:49:53.877: INFO: (12) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 7.8355ms)
May  3 12:49:53.892: INFO: (13) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 15.0562ms)
May  3 12:49:53.901: INFO: (14) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 9.4244ms)
May  3 12:49:53.914: INFO: (15) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 12.2464ms)
May  3 12:49:53.922: INFO: (16) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 8.6559ms)
May  3 12:49:53.930: INFO: (17) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 7.2189ms)
May  3 12:49:53.936: INFO: (18) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 6.4623ms)
May  3 12:49:53.949: INFO: (19) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 12.0344ms)
[AfterEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:49:53.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-4924" for this suite.
May  3 12:49:59.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:50:00.081: INFO: namespace proxy-4924 deletion completed in 6.1223666s

• [SLOW TEST:6.482 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:50:00.081: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0503 12:50:06.313232      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May  3 12:50:06.313: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:50:06.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5781" for this suite.
May  3 12:50:12.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:50:12.540: INFO: namespace gc-5781 deletion completed in 6.222777s

• [SLOW TEST:12.459 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:50:12.546: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1354
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
May  3 12:50:12.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-3524'
May  3 12:50:13.133: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May  3 12:50:13.134: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
May  3 12:50:13.192: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-cp42t]
May  3 12:50:13.196: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-cp42t" in namespace "kubectl-3524" to be "running and ready"
May  3 12:50:13.212: INFO: Pod "e2e-test-nginx-rc-cp42t": Phase="Pending", Reason="", readiness=false. Elapsed: 15.0471ms
May  3 12:50:15.219: INFO: Pod "e2e-test-nginx-rc-cp42t": Phase="Running", Reason="", readiness=true. Elapsed: 2.0212207s
May  3 12:50:15.219: INFO: Pod "e2e-test-nginx-rc-cp42t" satisfied condition "running and ready"
May  3 12:50:15.219: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-cp42t]
May  3 12:50:15.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 logs rc/e2e-test-nginx-rc --namespace=kubectl-3524'
May  3 12:50:15.331: INFO: stderr: ""
May  3 12:50:15.331: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1359
May  3 12:50:15.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 delete rc e2e-test-nginx-rc --namespace=kubectl-3524'
May  3 12:50:15.422: INFO: stderr: ""
May  3 12:50:15.422: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:50:15.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3524" for this suite.
May  3 12:50:29.449: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:50:29.583: INFO: namespace kubectl-3524 deletion completed in 14.1511823s

• [SLOW TEST:17.037 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:50:29.583: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name projected-secret-test-07e90be5-6da2-11e9-a622-a62f37ba3446
STEP: Creating a pod to test consume secrets
May  3 12:50:29.664: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-07eb333b-6da2-11e9-a622-a62f37ba3446" in namespace "projected-5259" to be "success or failure"
May  3 12:50:29.689: INFO: Pod "pod-projected-secrets-07eb333b-6da2-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 24.4574ms
May  3 12:50:31.692: INFO: Pod "pod-projected-secrets-07eb333b-6da2-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0268606s
STEP: Saw pod success
May  3 12:50:31.692: INFO: Pod "pod-projected-secrets-07eb333b-6da2-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 12:50:31.699: INFO: Trying to get logs from node docker-desktop pod pod-projected-secrets-07eb333b-6da2-11e9-a622-a62f37ba3446 container secret-volume-test: <nil>
STEP: delete the pod
May  3 12:50:31.743: INFO: Waiting for pod pod-projected-secrets-07eb333b-6da2-11e9-a622-a62f37ba3446 to disappear
May  3 12:50:31.767: INFO: Pod pod-projected-secrets-07eb333b-6da2-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:50:31.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5259" for this suite.
May  3 12:50:37.816: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:50:37.931: INFO: namespace projected-5259 deletion completed in 6.1389746s

• [SLOW TEST:8.348 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:50:37.932: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-0ce27b3d-6da2-11e9-a622-a62f37ba3446
STEP: Creating a pod to test consume configMaps
May  3 12:50:38.006: INFO: Waiting up to 5m0s for pod "pod-configmaps-0ce4c5df-6da2-11e9-a622-a62f37ba3446" in namespace "configmap-8428" to be "success or failure"
May  3 12:50:38.018: INFO: Pod "pod-configmaps-0ce4c5df-6da2-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 12.1861ms
May  3 12:50:40.029: INFO: Pod "pod-configmaps-0ce4c5df-6da2-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0234397s
STEP: Saw pod success
May  3 12:50:40.029: INFO: Pod "pod-configmaps-0ce4c5df-6da2-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 12:50:40.032: INFO: Trying to get logs from node docker-desktop pod pod-configmaps-0ce4c5df-6da2-11e9-a622-a62f37ba3446 container configmap-volume-test: <nil>
STEP: delete the pod
May  3 12:50:40.070: INFO: Waiting for pod pod-configmaps-0ce4c5df-6da2-11e9-a622-a62f37ba3446 to disappear
May  3 12:50:40.076: INFO: Pod pod-configmaps-0ce4c5df-6da2-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:50:40.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8428" for this suite.
May  3 12:50:46.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:50:46.269: INFO: namespace configmap-8428 deletion completed in 6.1691127s

• [SLOW TEST:8.337 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:50:46.269: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May  3 12:50:46.335: INFO: Creating deployment "nginx-deployment"
May  3 12:50:46.355: INFO: Waiting for observed generation 1
May  3 12:50:48.507: INFO: Waiting for all required pods to come up
May  3 12:50:48.674: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
May  3 12:50:54.932: INFO: Waiting for deployment "nginx-deployment" to complete
May  3 12:50:54.976: INFO: Updating deployment "nginx-deployment" with a non-existent image
May  3 12:50:54.988: INFO: Updating deployment nginx-deployment
May  3 12:50:54.988: INFO: Waiting for observed generation 2
May  3 12:50:57.054: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
May  3 12:50:57.058: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
May  3 12:50:57.062: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
May  3 12:50:57.103: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
May  3 12:50:57.103: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
May  3 12:50:57.109: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
May  3 12:50:57.161: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
May  3 12:50:57.161: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
May  3 12:50:57.172: INFO: Updating deployment nginx-deployment
May  3 12:50:57.172: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
May  3 12:50:57.241: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
May  3 12:50:59.695: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May  3 12:51:01.113: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-2455,SelfLink:/apis/apps/v1/namespaces/deployment-2455/deployments/nginx-deployment,UID:11decacd-6da2-11e9-9efa-00155da4710f,ResourceVersion:15841,Generation:3,CreationTimestamp:2019-05-03 12:50:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-05-03 12:50:57 +0000 UTC 2019-05-03 12:50:57 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-05-03 12:50:57 +0000 UTC 2019-05-03 12:50:46 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-5f9595f595" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

May  3 12:51:01.139: INFO: New ReplicaSet "nginx-deployment-5f9595f595" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595,GenerateName:,Namespace:deployment-2455,SelfLink:/apis/apps/v1/namespaces/deployment-2455/replicasets/nginx-deployment-5f9595f595,UID:1706d340-6da2-11e9-9efa-00155da4710f,ResourceVersion:15838,Generation:3,CreationTimestamp:2019-05-03 12:50:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 11decacd-6da2-11e9-9efa-00155da4710f 0xc003a7ef27 0xc003a7ef28}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May  3 12:51:01.141: INFO: All old ReplicaSets of Deployment "nginx-deployment":
May  3 12:51:01.142: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8,GenerateName:,Namespace:deployment-2455,SelfLink:/apis/apps/v1/namespaces/deployment-2455/replicasets/nginx-deployment-6f478d8d8,UID:11e27652-6da2-11e9-9efa-00155da4710f,ResourceVersion:15836,Generation:3,CreationTimestamp:2019-05-03 12:50:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 11decacd-6da2-11e9-9efa-00155da4710f 0xc003a7f027 0xc003a7f028}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
May  3 12:51:01.332: INFO: Pod "nginx-deployment-5f9595f595-4j42b" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-4j42b,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-2455,SelfLink:/api/v1/namespaces/deployment-2455/pods/nginx-deployment-5f9595f595-4j42b,UID:1708e1e8-6da2-11e9-9efa-00155da4710f,ResourceVersion:15743,Generation:0,CreationTimestamp:2019-05-03 12:50:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 1706d340-6da2-11e9-9efa-00155da4710f 0xc0025ec1c7 0xc0025ec1c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qfcms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qfcms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qfcms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025ec240} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025ec260}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:55 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:,StartTime:2019-05-03 12:50:55 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May  3 12:51:01.332: INFO: Pod "nginx-deployment-5f9595f595-9vxhd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-9vxhd,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-2455,SelfLink:/api/v1/namespaces/deployment-2455/pods/nginx-deployment-5f9595f595-9vxhd,UID:186e22ef-6da2-11e9-9efa-00155da4710f,ResourceVersion:15893,Generation:0,CreationTimestamp:2019-05-03 12:50:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 1706d340-6da2-11e9-9efa-00155da4710f 0xc0025ec330 0xc0025ec331}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qfcms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qfcms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qfcms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025ec3b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025ec3d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:,StartTime:2019-05-03 12:50:57 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May  3 12:51:01.333: INFO: Pod "nginx-deployment-5f9595f595-9wk9n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-9wk9n,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-2455,SelfLink:/api/v1/namespaces/deployment-2455/pods/nginx-deployment-5f9595f595-9wk9n,UID:1874b713-6da2-11e9-9efa-00155da4710f,ResourceVersion:15822,Generation:0,CreationTimestamp:2019-05-03 12:50:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 1706d340-6da2-11e9-9efa-00155da4710f 0xc0025ec4a0 0xc0025ec4a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qfcms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qfcms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qfcms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025ec520} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025ec540}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May  3 12:51:01.333: INFO: Pod "nginx-deployment-5f9595f595-g99mk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-g99mk,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-2455,SelfLink:/api/v1/namespaces/deployment-2455/pods/nginx-deployment-5f9595f595-g99mk,UID:187c3b0e-6da2-11e9-9efa-00155da4710f,ResourceVersion:15832,Generation:0,CreationTimestamp:2019-05-03 12:50:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 1706d340-6da2-11e9-9efa-00155da4710f 0xc0025ec5c0 0xc0025ec5c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qfcms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qfcms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qfcms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025ec640} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025ec660}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May  3 12:51:01.333: INFO: Pod "nginx-deployment-5f9595f595-k9bzr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-k9bzr,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-2455,SelfLink:/api/v1/namespaces/deployment-2455/pods/nginx-deployment-5f9595f595-k9bzr,UID:1874cba3-6da2-11e9-9efa-00155da4710f,ResourceVersion:15828,Generation:0,CreationTimestamp:2019-05-03 12:50:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 1706d340-6da2-11e9-9efa-00155da4710f 0xc0025ec6e0 0xc0025ec6e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qfcms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qfcms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qfcms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025ec760} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025ec780}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May  3 12:51:01.333: INFO: Pod "nginx-deployment-5f9595f595-krwjt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-krwjt,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-2455,SelfLink:/api/v1/namespaces/deployment-2455/pods/nginx-deployment-5f9595f595-krwjt,UID:1707f227-6da2-11e9-9efa-00155da4710f,ResourceVersion:15736,Generation:0,CreationTimestamp:2019-05-03 12:50:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 1706d340-6da2-11e9-9efa-00155da4710f 0xc0025ec820 0xc0025ec821}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qfcms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qfcms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qfcms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025ec8a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025ec8c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:55 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:,StartTime:2019-05-03 12:50:55 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May  3 12:51:01.333: INFO: Pod "nginx-deployment-5f9595f595-mls42" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-mls42,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-2455,SelfLink:/api/v1/namespaces/deployment-2455/pods/nginx-deployment-5f9595f595-mls42,UID:1859edfb-6da2-11e9-9efa-00155da4710f,ResourceVersion:15848,Generation:0,CreationTimestamp:2019-05-03 12:50:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 1706d340-6da2-11e9-9efa-00155da4710f 0xc0025ec9a0 0xc0025ec9a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qfcms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qfcms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qfcms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025eca20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025eca40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:,StartTime:2019-05-03 12:50:57 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May  3 12:51:01.333: INFO: Pod "nginx-deployment-5f9595f595-rdmm6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-rdmm6,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-2455,SelfLink:/api/v1/namespaces/deployment-2455/pods/nginx-deployment-5f9595f595-rdmm6,UID:170a5263-6da2-11e9-9efa-00155da4710f,ResourceVersion:15757,Generation:0,CreationTimestamp:2019-05-03 12:50:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 1706d340-6da2-11e9-9efa-00155da4710f 0xc0025ecb20 0xc0025ecb21}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qfcms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qfcms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qfcms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025ecbd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025ecbf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:55 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:,StartTime:2019-05-03 12:50:55 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May  3 12:51:01.333: INFO: Pod "nginx-deployment-5f9595f595-sll65" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-sll65,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-2455,SelfLink:/api/v1/namespaces/deployment-2455/pods/nginx-deployment-5f9595f595-sll65,UID:171c841b-6da2-11e9-9efa-00155da4710f,ResourceVersion:15767,Generation:0,CreationTimestamp:2019-05-03 12:50:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 1706d340-6da2-11e9-9efa-00155da4710f 0xc0025eccc0 0xc0025eccc1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qfcms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qfcms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qfcms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025ecd40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025ecd60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:55 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:,StartTime:2019-05-03 12:50:55 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May  3 12:51:01.334: INFO: Pod "nginx-deployment-5f9595f595-vhcsz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-vhcsz,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-2455,SelfLink:/api/v1/namespaces/deployment-2455/pods/nginx-deployment-5f9595f595-vhcsz,UID:1719ee7c-6da2-11e9-9efa-00155da4710f,ResourceVersion:15766,Generation:0,CreationTimestamp:2019-05-03 12:50:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 1706d340-6da2-11e9-9efa-00155da4710f 0xc0025ece30 0xc0025ece31}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qfcms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qfcms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qfcms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025eceb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025eced0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:55 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:,StartTime:2019-05-03 12:50:55 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May  3 12:51:01.334: INFO: Pod "nginx-deployment-5f9595f595-x4hhg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-x4hhg,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-2455,SelfLink:/api/v1/namespaces/deployment-2455/pods/nginx-deployment-5f9595f595-x4hhg,UID:1874a6e5-6da2-11e9-9efa-00155da4710f,ResourceVersion:15829,Generation:0,CreationTimestamp:2019-05-03 12:50:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 1706d340-6da2-11e9-9efa-00155da4710f 0xc0025ecfa0 0xc0025ecfa1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qfcms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qfcms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qfcms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025ed020} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025ed040}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May  3 12:51:01.334: INFO: Pod "nginx-deployment-5f9595f595-z8469" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-z8469,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-2455,SelfLink:/api/v1/namespaces/deployment-2455/pods/nginx-deployment-5f9595f595-z8469,UID:186e0d9f-6da2-11e9-9efa-00155da4710f,ResourceVersion:15883,Generation:0,CreationTimestamp:2019-05-03 12:50:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 1706d340-6da2-11e9-9efa-00155da4710f 0xc0025ed0c0 0xc0025ed0c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qfcms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qfcms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qfcms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025ed140} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025ed160}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:,StartTime:2019-05-03 12:50:57 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May  3 12:51:01.338: INFO: Pod "nginx-deployment-5f9595f595-zjgd4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-zjgd4,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-2455,SelfLink:/api/v1/namespaces/deployment-2455/pods/nginx-deployment-5f9595f595-zjgd4,UID:18747500-6da2-11e9-9efa-00155da4710f,ResourceVersion:15827,Generation:0,CreationTimestamp:2019-05-03 12:50:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 1706d340-6da2-11e9-9efa-00155da4710f 0xc0025ed230 0xc0025ed231}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qfcms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qfcms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qfcms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025ed2b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025ed2d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May  3 12:51:01.418: INFO: Pod "nginx-deployment-6f478d8d8-2k8kd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-2k8kd,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2455,SelfLink:/api/v1/namespaces/deployment-2455/pods/nginx-deployment-6f478d8d8-2k8kd,UID:11e99a2f-6da2-11e9-9efa-00155da4710f,ResourceVersion:15678,Generation:0,CreationTimestamp:2019-05-03 12:50:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 11e27652-6da2-11e9-9efa-00155da4710f 0xc0025ed350 0xc0025ed351}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qfcms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qfcms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qfcms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025ed3c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025ed3e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:46 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:51 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:51 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:46 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.0.141,StartTime:2019-05-03 12:50:46 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-03 12:50:50 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://352b6e4161dbffc6ccfdeef0136110a7ef1171ab5bab5d6fc2b360351b90360f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May  3 12:51:01.428: INFO: Pod "nginx-deployment-6f478d8d8-4v7xn" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-4v7xn,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2455,SelfLink:/api/v1/namespaces/deployment-2455/pods/nginx-deployment-6f478d8d8-4v7xn,UID:11e43548-6da2-11e9-9efa-00155da4710f,ResourceVersion:15693,Generation:0,CreationTimestamp:2019-05-03 12:50:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 11e27652-6da2-11e9-9efa-00155da4710f 0xc0025ed4b0 0xc0025ed4b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qfcms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qfcms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qfcms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025ed520} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025ed540}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:46 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:51 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:51 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:46 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.0.138,StartTime:2019-05-03 12:50:46 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-03 12:50:50 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://f4e663f667ec11b5caf98949e55049f626df141cf5f5bf5d5aba189abadfb3ba}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May  3 12:51:01.441: INFO: Pod "nginx-deployment-6f478d8d8-7g5z9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-7g5z9,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2455,SelfLink:/api/v1/namespaces/deployment-2455/pods/nginx-deployment-6f478d8d8-7g5z9,UID:1856ed86-6da2-11e9-9efa-00155da4710f,ResourceVersion:15842,Generation:0,CreationTimestamp:2019-05-03 12:50:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 11e27652-6da2-11e9-9efa-00155da4710f 0xc0025ed610 0xc0025ed611}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qfcms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qfcms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qfcms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025ed680} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025ed6a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:,StartTime:2019-05-03 12:50:57 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May  3 12:51:01.441: INFO: Pod "nginx-deployment-6f478d8d8-cprk7" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-cprk7,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2455,SelfLink:/api/v1/namespaces/deployment-2455/pods/nginx-deployment-6f478d8d8-cprk7,UID:11e5b549-6da2-11e9-9efa-00155da4710f,ResourceVersion:15681,Generation:0,CreationTimestamp:2019-05-03 12:50:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 11e27652-6da2-11e9-9efa-00155da4710f 0xc0025ed767 0xc0025ed768}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qfcms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qfcms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qfcms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025ed7e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025ed800}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:46 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:51 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:51 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:46 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.0.137,StartTime:2019-05-03 12:50:46 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-03 12:50:50 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://39f36c7388e967d25c71992b39093a8e64e2af6df64b4ba9ce7083452129e688}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May  3 12:51:01.453: INFO: Pod "nginx-deployment-6f478d8d8-dqgvr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-dqgvr,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2455,SelfLink:/api/v1/namespaces/deployment-2455/pods/nginx-deployment-6f478d8d8-dqgvr,UID:11eeee95-6da2-11e9-9efa-00155da4710f,ResourceVersion:15688,Generation:0,CreationTimestamp:2019-05-03 12:50:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 11e27652-6da2-11e9-9efa-00155da4710f 0xc0025ed8d0 0xc0025ed8d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qfcms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qfcms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qfcms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025ed940} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025ed960}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:46 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:51 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:51 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:46 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.0.140,StartTime:2019-05-03 12:50:46 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-03 12:50:50 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://9eaf0cd89fbc0d3b5b95b400611a78c57ab19eec89017d68b31d947d4d62b364}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May  3 12:51:01.454: INFO: Pod "nginx-deployment-6f478d8d8-drtkb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-drtkb,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2455,SelfLink:/api/v1/namespaces/deployment-2455/pods/nginx-deployment-6f478d8d8-drtkb,UID:18546a5d-6da2-11e9-9efa-00155da4710f,ResourceVersion:15803,Generation:0,CreationTimestamp:2019-05-03 12:50:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 11e27652-6da2-11e9-9efa-00155da4710f 0xc0025eda30 0xc0025eda31}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qfcms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qfcms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qfcms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025edaa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025edac0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:,StartTime:2019-05-03 12:50:57 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May  3 12:51:01.455: INFO: Pod "nginx-deployment-6f478d8d8-fcjh7" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-fcjh7,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2455,SelfLink:/api/v1/namespaces/deployment-2455/pods/nginx-deployment-6f478d8d8-fcjh7,UID:11e96e01-6da2-11e9-9efa-00155da4710f,ResourceVersion:15674,Generation:0,CreationTimestamp:2019-05-03 12:50:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 11e27652-6da2-11e9-9efa-00155da4710f 0xc0025edb87 0xc0025edb88}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qfcms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qfcms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qfcms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025edc00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025edc20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:46 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:51 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:51 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:46 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.0.139,StartTime:2019-05-03 12:50:46 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-03 12:50:50 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://7f5aec6f2f0a0f75719a6b744866526f800c3aa84cc5f4259a7afa78573462f1}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May  3 12:51:01.499: INFO: Pod "nginx-deployment-6f478d8d8-g7bzf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-g7bzf,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2455,SelfLink:/api/v1/namespaces/deployment-2455/pods/nginx-deployment-6f478d8d8-g7bzf,UID:186f1a0f-6da2-11e9-9efa-00155da4710f,ResourceVersion:15824,Generation:0,CreationTimestamp:2019-05-03 12:50:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 11e27652-6da2-11e9-9efa-00155da4710f 0xc0025edcf0 0xc0025edcf1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qfcms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qfcms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qfcms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025edd60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025edd80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May  3 12:51:01.500: INFO: Pod "nginx-deployment-6f478d8d8-gfdlt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-gfdlt,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2455,SelfLink:/api/v1/namespaces/deployment-2455/pods/nginx-deployment-6f478d8d8-gfdlt,UID:186f29f4-6da2-11e9-9efa-00155da4710f,ResourceVersion:15825,Generation:0,CreationTimestamp:2019-05-03 12:50:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 11e27652-6da2-11e9-9efa-00155da4710f 0xc0025ede00 0xc0025ede01}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qfcms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qfcms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qfcms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025ede70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025ede90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May  3 12:51:01.538: INFO: Pod "nginx-deployment-6f478d8d8-gzclr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-gzclr,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2455,SelfLink:/api/v1/namespaces/deployment-2455/pods/nginx-deployment-6f478d8d8-gzclr,UID:1860f499-6da2-11e9-9efa-00155da4710f,ResourceVersion:15878,Generation:0,CreationTimestamp:2019-05-03 12:50:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 11e27652-6da2-11e9-9efa-00155da4710f 0xc0025edf10 0xc0025edf11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qfcms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qfcms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qfcms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025edf80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025edfa0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:,StartTime:2019-05-03 12:50:57 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May  3 12:51:01.539: INFO: Pod "nginx-deployment-6f478d8d8-ls4j7" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-ls4j7,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2455,SelfLink:/api/v1/namespaces/deployment-2455/pods/nginx-deployment-6f478d8d8-ls4j7,UID:11eed36d-6da2-11e9-9efa-00155da4710f,ResourceVersion:15671,Generation:0,CreationTimestamp:2019-05-03 12:50:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 11e27652-6da2-11e9-9efa-00155da4710f 0xc00241c067 0xc00241c068}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qfcms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qfcms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qfcms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00241c0e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00241c100}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:46 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:51 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:51 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:46 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.0.143,StartTime:2019-05-03 12:50:46 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-03 12:50:50 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://4ff79b68459b4cece992375b84c8eea02aa643d0c9595c7845ae95da793ce013}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May  3 12:51:01.539: INFO: Pod "nginx-deployment-6f478d8d8-psr9w" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-psr9w,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2455,SelfLink:/api/v1/namespaces/deployment-2455/pods/nginx-deployment-6f478d8d8-psr9w,UID:186f3fa4-6da2-11e9-9efa-00155da4710f,ResourceVersion:15890,Generation:0,CreationTimestamp:2019-05-03 12:50:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 11e27652-6da2-11e9-9efa-00155da4710f 0xc00241c1e0 0xc00241c1e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qfcms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qfcms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qfcms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00241c260} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00241c280}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:,StartTime:2019-05-03 12:50:57 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May  3 12:51:01.539: INFO: Pod "nginx-deployment-6f478d8d8-r8mdp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-r8mdp,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2455,SelfLink:/api/v1/namespaces/deployment-2455/pods/nginx-deployment-6f478d8d8-r8mdp,UID:18608650-6da2-11e9-9efa-00155da4710f,ResourceVersion:15864,Generation:0,CreationTimestamp:2019-05-03 12:50:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 11e27652-6da2-11e9-9efa-00155da4710f 0xc00241c347 0xc00241c348}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qfcms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qfcms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qfcms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00241c3c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00241c3e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:,StartTime:2019-05-03 12:50:57 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May  3 12:51:01.539: INFO: Pod "nginx-deployment-6f478d8d8-rb7m9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-rb7m9,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2455,SelfLink:/api/v1/namespaces/deployment-2455/pods/nginx-deployment-6f478d8d8-rb7m9,UID:186f0aa3-6da2-11e9-9efa-00155da4710f,ResourceVersion:15888,Generation:0,CreationTimestamp:2019-05-03 12:50:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 11e27652-6da2-11e9-9efa-00155da4710f 0xc00241c4a7 0xc00241c4a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qfcms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qfcms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qfcms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00241c520} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00241c540}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:,StartTime:2019-05-03 12:50:57 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May  3 12:51:01.539: INFO: Pod "nginx-deployment-6f478d8d8-rmpbr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-rmpbr,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2455,SelfLink:/api/v1/namespaces/deployment-2455/pods/nginx-deployment-6f478d8d8-rmpbr,UID:11e5abdf-6da2-11e9-9efa-00155da4710f,ResourceVersion:15700,Generation:0,CreationTimestamp:2019-05-03 12:50:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 11e27652-6da2-11e9-9efa-00155da4710f 0xc00241c607 0xc00241c608}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qfcms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qfcms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qfcms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00241c680} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00241c6a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:46 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:51 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:51 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:46 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.0.136,StartTime:2019-05-03 12:50:46 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-03 12:50:50 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://154e05f8665968d43057013e9f717430705f008547e520214f68d3344b2c4923}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May  3 12:51:01.539: INFO: Pod "nginx-deployment-6f478d8d8-s55dr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-s55dr,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2455,SelfLink:/api/v1/namespaces/deployment-2455/pods/nginx-deployment-6f478d8d8-s55dr,UID:18611581-6da2-11e9-9efa-00155da4710f,ResourceVersion:15880,Generation:0,CreationTimestamp:2019-05-03 12:50:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 11e27652-6da2-11e9-9efa-00155da4710f 0xc00241c770 0xc00241c771}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qfcms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qfcms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qfcms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00241c7e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00241c800}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:,StartTime:2019-05-03 12:50:57 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May  3 12:51:01.539: INFO: Pod "nginx-deployment-6f478d8d8-s99wm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-s99wm,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2455,SelfLink:/api/v1/namespaces/deployment-2455/pods/nginx-deployment-6f478d8d8-s99wm,UID:11e98537-6da2-11e9-9efa-00155da4710f,ResourceVersion:15684,Generation:0,CreationTimestamp:2019-05-03 12:50:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 11e27652-6da2-11e9-9efa-00155da4710f 0xc00241c8c7 0xc00241c8c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qfcms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qfcms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qfcms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00241c940} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00241c960}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:46 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:51 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:51 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:46 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.0.142,StartTime:2019-05-03 12:50:46 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-03 12:50:50 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://8fbb84e15a5bcf6b203b9f994c6a1eccb70587bebd89b3c10e24b7af30cebe57}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May  3 12:51:01.539: INFO: Pod "nginx-deployment-6f478d8d8-vhmm5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-vhmm5,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2455,SelfLink:/api/v1/namespaces/deployment-2455/pods/nginx-deployment-6f478d8d8-vhmm5,UID:186eda9c-6da2-11e9-9efa-00155da4710f,ResourceVersion:15896,Generation:0,CreationTimestamp:2019-05-03 12:50:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 11e27652-6da2-11e9-9efa-00155da4710f 0xc00241ca30 0xc00241ca31}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qfcms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qfcms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qfcms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00241caa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00241cac0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:,StartTime:2019-05-03 12:50:57 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May  3 12:51:01.548: INFO: Pod "nginx-deployment-6f478d8d8-vsfqz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-vsfqz,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2455,SelfLink:/api/v1/namespaces/deployment-2455/pods/nginx-deployment-6f478d8d8-vsfqz,UID:1856e5ec-6da2-11e9-9efa-00155da4710f,ResourceVersion:15823,Generation:0,CreationTimestamp:2019-05-03 12:50:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 11e27652-6da2-11e9-9efa-00155da4710f 0xc00241cb87 0xc00241cb88}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qfcms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qfcms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qfcms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00241cc00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00241cc20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:,StartTime:2019-05-03 12:50:57 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May  3 12:51:01.548: INFO: Pod "nginx-deployment-6f478d8d8-z5wrz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-z5wrz,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-2455,SelfLink:/api/v1/namespaces/deployment-2455/pods/nginx-deployment-6f478d8d8-z5wrz,UID:186109df-6da2-11e9-9efa-00155da4710f,ResourceVersion:15879,Generation:0,CreationTimestamp:2019-05-03 12:50:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 11e27652-6da2-11e9-9efa-00155da4710f 0xc00241cce7 0xc00241cce8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qfcms {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qfcms,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qfcms true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00241cd60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00241cd80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:50:57 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:,StartTime:2019-05-03 12:50:57 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:51:01.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2455" for this suite.
May  3 12:51:15.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:51:15.719: INFO: namespace deployment-2455 deletion completed in 14.1583063s

• [SLOW TEST:29.450 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:51:15.736: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May  3 12:51:15.872: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
May  3 12:51:15.910: INFO: Number of nodes with available pods: 0
May  3 12:51:15.910: INFO: Node docker-desktop is running more than one daemon pod
May  3 12:51:16.916: INFO: Number of nodes with available pods: 0
May  3 12:51:16.916: INFO: Node docker-desktop is running more than one daemon pod
May  3 12:51:17.920: INFO: Number of nodes with available pods: 0
May  3 12:51:17.920: INFO: Node docker-desktop is running more than one daemon pod
May  3 12:51:18.918: INFO: Number of nodes with available pods: 0
May  3 12:51:18.918: INFO: Node docker-desktop is running more than one daemon pod
May  3 12:51:19.921: INFO: Number of nodes with available pods: 0
May  3 12:51:19.921: INFO: Node docker-desktop is running more than one daemon pod
May  3 12:51:20.917: INFO: Number of nodes with available pods: 0
May  3 12:51:20.918: INFO: Node docker-desktop is running more than one daemon pod
May  3 12:51:21.923: INFO: Number of nodes with available pods: 0
May  3 12:51:21.923: INFO: Node docker-desktop is running more than one daemon pod
May  3 12:51:22.916: INFO: Number of nodes with available pods: 0
May  3 12:51:22.916: INFO: Node docker-desktop is running more than one daemon pod
May  3 12:51:23.919: INFO: Number of nodes with available pods: 0
May  3 12:51:23.920: INFO: Node docker-desktop is running more than one daemon pod
May  3 12:51:24.915: INFO: Number of nodes with available pods: 0
May  3 12:51:24.915: INFO: Node docker-desktop is running more than one daemon pod
May  3 12:51:25.925: INFO: Number of nodes with available pods: 0
May  3 12:51:25.925: INFO: Node docker-desktop is running more than one daemon pod
May  3 12:51:26.916: INFO: Number of nodes with available pods: 0
May  3 12:51:26.916: INFO: Node docker-desktop is running more than one daemon pod
May  3 12:51:27.921: INFO: Number of nodes with available pods: 0
May  3 12:51:27.921: INFO: Node docker-desktop is running more than one daemon pod
May  3 12:51:28.917: INFO: Number of nodes with available pods: 1
May  3 12:51:28.918: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
May  3 12:51:28.988: INFO: Wrong image for pod: daemon-set-88pv9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May  3 12:51:30.005: INFO: Wrong image for pod: daemon-set-88pv9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May  3 12:51:31.007: INFO: Wrong image for pod: daemon-set-88pv9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May  3 12:51:32.007: INFO: Wrong image for pod: daemon-set-88pv9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May  3 12:51:32.007: INFO: Pod daemon-set-88pv9 is not available
May  3 12:51:33.005: INFO: Pod daemon-set-7m4pj is not available
STEP: Check that daemon pods are still running on every node of the cluster.
May  3 12:51:33.023: INFO: Number of nodes with available pods: 0
May  3 12:51:33.023: INFO: Node docker-desktop is running more than one daemon pod
May  3 12:51:34.027: INFO: Number of nodes with available pods: 0
May  3 12:51:34.027: INFO: Node docker-desktop is running more than one daemon pod
May  3 12:51:35.038: INFO: Number of nodes with available pods: 1
May  3 12:51:35.038: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1667, will wait for the garbage collector to delete the pods
May  3 12:51:35.159: INFO: Deleting DaemonSet.extensions daemon-set took: 10.8362ms
May  3 12:51:35.559: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.6124ms
May  3 12:51:38.762: INFO: Number of nodes with available pods: 0
May  3 12:51:38.762: INFO: Number of running nodes: 0, number of available pods: 0
May  3 12:51:38.766: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1667/daemonsets","resourceVersion":"16203"},"items":null}

May  3 12:51:38.774: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1667/pods","resourceVersion":"16203"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:51:38.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1667" for this suite.
May  3 12:51:44.817: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:51:44.945: INFO: namespace daemonsets-1667 deletion completed in 6.1446835s

• [SLOW TEST:29.212 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:51:44.945: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-2670
May  3 12:51:47.060: INFO: Started pod liveness-http in namespace container-probe-2670
STEP: checking the pod's current state and verifying that restartCount is present
May  3 12:51:47.085: INFO: Initial restart count of pod liveness-http is 0
May  3 12:52:11.159: INFO: Restart count of pod container-probe-2670/liveness-http is now 1 (24.0735221s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:52:11.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2670" for this suite.
May  3 12:52:17.243: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:52:17.350: INFO: namespace container-probe-2670 deletion completed in 6.1401583s

• [SLOW TEST:32.405 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:52:17.367: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May  3 12:52:17.442: INFO: Waiting up to 5m0s for pod "downwardapi-volume-48287a9b-6da2-11e9-a622-a62f37ba3446" in namespace "projected-5784" to be "success or failure"
May  3 12:52:17.455: INFO: Pod "downwardapi-volume-48287a9b-6da2-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 12.1728ms
May  3 12:52:19.463: INFO: Pod "downwardapi-volume-48287a9b-6da2-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0198129s
May  3 12:52:21.475: INFO: Pod "downwardapi-volume-48287a9b-6da2-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0320505s
STEP: Saw pod success
May  3 12:52:21.475: INFO: Pod "downwardapi-volume-48287a9b-6da2-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 12:52:21.492: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-48287a9b-6da2-11e9-a622-a62f37ba3446 container client-container: <nil>
STEP: delete the pod
May  3 12:52:21.556: INFO: Waiting for pod downwardapi-volume-48287a9b-6da2-11e9-a622-a62f37ba3446 to disappear
May  3 12:52:21.560: INFO: Pod downwardapi-volume-48287a9b-6da2-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:52:21.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5784" for this suite.
May  3 12:52:27.596: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:52:27.708: INFO: namespace projected-5784 deletion completed in 6.1323479s

• [SLOW TEST:10.341 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:52:27.710: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
May  3 12:52:32.428: INFO: Successfully updated pod "pod-update-activedeadlineseconds-4e5ceecb-6da2-11e9-a622-a62f37ba3446"
May  3 12:52:32.429: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-4e5ceecb-6da2-11e9-a622-a62f37ba3446" in namespace "pods-8626" to be "terminated due to deadline exceeded"
May  3 12:52:32.474: INFO: Pod "pod-update-activedeadlineseconds-4e5ceecb-6da2-11e9-a622-a62f37ba3446": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 40.2643ms
May  3 12:52:32.474: INFO: Pod "pod-update-activedeadlineseconds-4e5ceecb-6da2-11e9-a622-a62f37ba3446" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:52:32.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8626" for this suite.
May  3 12:52:38.496: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:52:38.586: INFO: namespace pods-8626 deletion completed in 6.1034617s

• [SLOW TEST:10.876 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:52:38.586: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-54ce2389-6da2-11e9-a622-a62f37ba3446
STEP: Creating a pod to test consume secrets
May  3 12:52:38.675: INFO: Waiting up to 5m0s for pod "pod-secrets-54d0e603-6da2-11e9-a622-a62f37ba3446" in namespace "secrets-5048" to be "success or failure"
May  3 12:52:38.698: INFO: Pod "pod-secrets-54d0e603-6da2-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 22.6894ms
May  3 12:52:40.700: INFO: Pod "pod-secrets-54d0e603-6da2-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0251552s
STEP: Saw pod success
May  3 12:52:40.700: INFO: Pod "pod-secrets-54d0e603-6da2-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 12:52:40.703: INFO: Trying to get logs from node docker-desktop pod pod-secrets-54d0e603-6da2-11e9-a622-a62f37ba3446 container secret-volume-test: <nil>
STEP: delete the pod
May  3 12:52:40.742: INFO: Waiting for pod pod-secrets-54d0e603-6da2-11e9-a622-a62f37ba3446 to disappear
May  3 12:52:40.751: INFO: Pod pod-secrets-54d0e603-6da2-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:52:40.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5048" for this suite.
May  3 12:52:46.797: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:52:46.898: INFO: namespace secrets-5048 deletion completed in 6.1387943s

• [SLOW TEST:8.312 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:52:46.898: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May  3 12:52:46.976: INFO: Waiting up to 5m0s for pod "downwardapi-volume-59c281ca-6da2-11e9-a622-a62f37ba3446" in namespace "downward-api-7372" to be "success or failure"
May  3 12:52:46.990: INFO: Pod "downwardapi-volume-59c281ca-6da2-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 13.9535ms
May  3 12:52:48.992: INFO: Pod "downwardapi-volume-59c281ca-6da2-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0161807s
STEP: Saw pod success
May  3 12:52:48.992: INFO: Pod "downwardapi-volume-59c281ca-6da2-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 12:52:48.995: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-59c281ca-6da2-11e9-a622-a62f37ba3446 container client-container: <nil>
STEP: delete the pod
May  3 12:52:49.025: INFO: Waiting for pod downwardapi-volume-59c281ca-6da2-11e9-a622-a62f37ba3446 to disappear
May  3 12:52:49.038: INFO: Pod downwardapi-volume-59c281ca-6da2-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:52:49.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7372" for this suite.
May  3 12:52:55.065: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:52:55.156: INFO: namespace downward-api-7372 deletion completed in 6.1129234s

• [SLOW TEST:8.258 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:52:55.159: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
May  3 12:52:57.284: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-5eafdc7e-6da2-11e9-a622-a62f37ba3446,GenerateName:,Namespace:events-417,SelfLink:/api/v1/namespaces/events-417/pods/send-events-5eafdc7e-6da2-11e9-a622-a62f37ba3446,UID:5eb2ba9a-6da2-11e9-9efa-00155da4710f,ResourceVersion:16469,Generation:0,CreationTimestamp:2019-05-03 12:52:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 222391900,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-hngrr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hngrr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-hngrr true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025ed6e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025ed700}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:52:55 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:52:57 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:52:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 12:52:55 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.0.178,StartTime:2019-05-03 12:52:55 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-05-03 12:52:56 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://9413f9f01d26bbc5a4a79e3b339b4a69d37581f39be9edf9d04a7379fb17b32b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
May  3 12:52:59.291: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
May  3 12:53:01.296: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:53:01.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-417" for this suite.
May  3 12:53:39.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:53:39.518: INFO: namespace events-417 deletion completed in 38.1798108s

• [SLOW TEST:44.359 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:53:39.518: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: executing a command with run --rm and attach with stdin
May  3 12:53:39.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 --namespace=kubectl-363 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
May  3 12:53:42.212: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
May  3 12:53:42.212: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:53:44.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-363" for this suite.
May  3 12:53:50.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:53:50.334: INFO: namespace kubectl-363 deletion completed in 6.0962441s

• [SLOW TEST:10.816 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:53:50.340: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-763.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-763.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-763.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-763.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-763.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-763.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May  3 12:53:54.516: INFO: DNS probes using dns-763/dns-test-7f937e36-6da2-11e9-a622-a62f37ba3446 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:53:54.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-763" for this suite.
May  3 12:54:00.660: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:54:00.751: INFO: namespace dns-763 deletion completed in 6.1326554s

• [SLOW TEST:10.411 seconds]
[sig-network] DNS
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:54:00.752: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1190
STEP: creating an rc
May  3 12:54:00.819: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 create -f - --namespace=kubectl-5053'
May  3 12:54:01.012: INFO: stderr: ""
May  3 12:54:01.012: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Waiting for Redis master to start.
May  3 12:54:02.019: INFO: Selector matched 1 pods for map[app:redis]
May  3 12:54:02.019: INFO: Found 0 / 1
May  3 12:54:03.021: INFO: Selector matched 1 pods for map[app:redis]
May  3 12:54:03.021: INFO: Found 1 / 1
May  3 12:54:03.021: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May  3 12:54:03.044: INFO: Selector matched 1 pods for map[app:redis]
May  3 12:54:03.044: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
May  3 12:54:03.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 logs redis-master-zxs78 redis-master --namespace=kubectl-5053'
May  3 12:54:03.134: INFO: stderr: ""
May  3 12:54:03.134: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 03 May 12:54:02.501 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 03 May 12:54:02.502 # Server started, Redis version 3.2.12\n1:M 03 May 12:54:02.502 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 03 May 12:54:02.502 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
May  3 12:54:03.134: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 log redis-master-zxs78 redis-master --namespace=kubectl-5053 --tail=1'
May  3 12:54:03.218: INFO: stderr: ""
May  3 12:54:03.218: INFO: stdout: "1:M 03 May 12:54:02.502 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
May  3 12:54:03.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 log redis-master-zxs78 redis-master --namespace=kubectl-5053 --limit-bytes=1'
May  3 12:54:03.298: INFO: stderr: ""
May  3 12:54:03.298: INFO: stdout: " "
STEP: exposing timestamps
May  3 12:54:03.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 log redis-master-zxs78 redis-master --namespace=kubectl-5053 --tail=1 --timestamps'
May  3 12:54:03.385: INFO: stderr: ""
May  3 12:54:03.385: INFO: stdout: "2019-05-03T12:54:02.5026408Z 1:M 03 May 12:54:02.502 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
May  3 12:54:05.892: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 log redis-master-zxs78 redis-master --namespace=kubectl-5053 --since=1s'
May  3 12:54:05.987: INFO: stderr: ""
May  3 12:54:05.987: INFO: stdout: ""
May  3 12:54:05.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 log redis-master-zxs78 redis-master --namespace=kubectl-5053 --since=24h'
May  3 12:54:06.070: INFO: stderr: ""
May  3 12:54:06.071: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 03 May 12:54:02.501 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 03 May 12:54:02.502 # Server started, Redis version 3.2.12\n1:M 03 May 12:54:02.502 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 03 May 12:54:02.502 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1196
STEP: using delete to clean up resources
May  3 12:54:06.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 delete --grace-period=0 --force -f - --namespace=kubectl-5053'
May  3 12:54:06.164: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May  3 12:54:06.168: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
May  3 12:54:06.168: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get rc,svc -l name=nginx --no-headers --namespace=kubectl-5053'
May  3 12:54:06.281: INFO: stderr: "No resources found.\n"
May  3 12:54:06.281: INFO: stdout: ""
May  3 12:54:06.288: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pods -l name=nginx --namespace=kubectl-5053 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May  3 12:54:06.363: INFO: stderr: ""
May  3 12:54:06.363: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:54:06.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5053" for this suite.
May  3 12:54:28.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:54:28.502: INFO: namespace kubectl-5053 deletion completed in 22.1296301s

• [SLOW TEST:27.751 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:54:28.503: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
May  3 12:54:28.573: INFO: Waiting up to 5m0s for pod "pod-9650e9b4-6da2-11e9-a622-a62f37ba3446" in namespace "emptydir-7070" to be "success or failure"
May  3 12:54:28.594: INFO: Pod "pod-9650e9b4-6da2-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 20.9493ms
May  3 12:54:30.597: INFO: Pod "pod-9650e9b4-6da2-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023284s
STEP: Saw pod success
May  3 12:54:30.597: INFO: Pod "pod-9650e9b4-6da2-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 12:54:30.599: INFO: Trying to get logs from node docker-desktop pod pod-9650e9b4-6da2-11e9-a622-a62f37ba3446 container test-container: <nil>
STEP: delete the pod
May  3 12:54:30.661: INFO: Waiting for pod pod-9650e9b4-6da2-11e9-a622-a62f37ba3446 to disappear
May  3 12:54:30.665: INFO: Pod pod-9650e9b4-6da2-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:54:30.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7070" for this suite.
May  3 12:54:36.686: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:54:36.791: INFO: namespace emptydir-7070 deletion completed in 6.1229531s

• [SLOW TEST:8.288 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:54:36.792: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1414
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
May  3 12:54:36.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-9357'
May  3 12:54:36.945: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May  3 12:54:36.946: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: rolling-update to same image controller
May  3 12:54:36.997: INFO: scanned /root for discovery docs: <nil>
May  3 12:54:36.997: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-9357'
May  3 12:54:52.044: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
May  3 12:54:52.044: INFO: stdout: "Created e2e-test-nginx-rc-fb6d9e1b366406f1719a9379e4549d81\nScaling up e2e-test-nginx-rc-fb6d9e1b366406f1719a9379e4549d81 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-fb6d9e1b366406f1719a9379e4549d81 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-fb6d9e1b366406f1719a9379e4549d81 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
May  3 12:54:52.044: INFO: stdout: "Created e2e-test-nginx-rc-fb6d9e1b366406f1719a9379e4549d81\nScaling up e2e-test-nginx-rc-fb6d9e1b366406f1719a9379e4549d81 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-fb6d9e1b366406f1719a9379e4549d81 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-fb6d9e1b366406f1719a9379e4549d81 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
May  3 12:54:52.044: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-9357'
May  3 12:54:52.127: INFO: stderr: ""
May  3 12:54:52.127: INFO: stdout: "e2e-test-nginx-rc-fb6d9e1b366406f1719a9379e4549d81-n8pdq "
May  3 12:54:52.127: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pods e2e-test-nginx-rc-fb6d9e1b366406f1719a9379e4549d81-n8pdq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9357'
May  3 12:54:52.205: INFO: stderr: ""
May  3 12:54:52.205: INFO: stdout: "true"
May  3 12:54:52.205: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pods e2e-test-nginx-rc-fb6d9e1b366406f1719a9379e4549d81-n8pdq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9357'
May  3 12:54:52.273: INFO: stderr: ""
May  3 12:54:52.273: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
May  3 12:54:52.273: INFO: e2e-test-nginx-rc-fb6d9e1b366406f1719a9379e4549d81-n8pdq is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1420
May  3 12:54:52.273: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 delete rc e2e-test-nginx-rc --namespace=kubectl-9357'
May  3 12:54:52.358: INFO: stderr: ""
May  3 12:54:52.358: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:54:52.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9357" for this suite.
May  3 12:54:58.405: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:54:58.503: INFO: namespace kubectl-9357 deletion completed in 6.1298438s

• [SLOW TEST:21.712 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:54:58.507: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service endpoint-test2 in namespace services-8135
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8135 to expose endpoints map[]
May  3 12:54:58.611: INFO: Get endpoints failed (8.5722ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
May  3 12:54:59.615: INFO: successfully validated that service endpoint-test2 in namespace services-8135 exposes endpoints map[] (1.0130709s elapsed)
STEP: Creating pod pod1 in namespace services-8135
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8135 to expose endpoints map[pod1:[80]]
May  3 12:55:01.697: INFO: successfully validated that service endpoint-test2 in namespace services-8135 exposes endpoints map[pod1:[80]] (2.0501899s elapsed)
STEP: Creating pod pod2 in namespace services-8135
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8135 to expose endpoints map[pod1:[80] pod2:[80]]
May  3 12:55:03.755: INFO: successfully validated that service endpoint-test2 in namespace services-8135 exposes endpoints map[pod1:[80] pod2:[80]] (2.0458801s elapsed)
STEP: Deleting pod pod1 in namespace services-8135
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8135 to expose endpoints map[pod2:[80]]
May  3 12:55:04.800: INFO: successfully validated that service endpoint-test2 in namespace services-8135 exposes endpoints map[pod2:[80]] (1.036109s elapsed)
STEP: Deleting pod pod2 in namespace services-8135
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8135 to expose endpoints map[]
May  3 12:55:04.818: INFO: successfully validated that service endpoint-test2 in namespace services-8135 exposes endpoints map[] (7.4151ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:55:04.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8135" for this suite.
May  3 12:55:26.869: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:55:26.968: INFO: namespace services-8135 deletion completed in 22.1157153s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:28.461 seconds]
[sig-network] Services
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:55:26.970: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:55:27.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2864" for this suite.
May  3 12:55:33.059: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:55:33.160: INFO: namespace services-2864 deletion completed in 6.123132s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:6.190 seconds]
[sig-network] Services
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:55:33.163: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
May  3 12:55:33.247: INFO: Waiting up to 5m0s for pod "pod-bcdd8d1e-6da2-11e9-a622-a62f37ba3446" in namespace "emptydir-301" to be "success or failure"
May  3 12:55:33.280: INFO: Pod "pod-bcdd8d1e-6da2-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 33.0329ms
May  3 12:55:35.288: INFO: Pod "pod-bcdd8d1e-6da2-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0412577s
STEP: Saw pod success
May  3 12:55:35.288: INFO: Pod "pod-bcdd8d1e-6da2-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 12:55:35.302: INFO: Trying to get logs from node docker-desktop pod pod-bcdd8d1e-6da2-11e9-a622-a62f37ba3446 container test-container: <nil>
STEP: delete the pod
May  3 12:55:35.368: INFO: Waiting for pod pod-bcdd8d1e-6da2-11e9-a622-a62f37ba3446 to disappear
May  3 12:55:35.371: INFO: Pod pod-bcdd8d1e-6da2-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:55:35.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-301" for this suite.
May  3 12:55:41.412: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:55:41.509: INFO: namespace emptydir-301 deletion completed in 6.1153199s

• [SLOW TEST:8.349 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:55:41.511: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-c1de041d-6da2-11e9-a622-a62f37ba3446
STEP: Creating a pod to test consume configMaps
May  3 12:55:41.650: INFO: Waiting up to 5m0s for pod "pod-configmaps-c1e08580-6da2-11e9-a622-a62f37ba3446" in namespace "configmap-8353" to be "success or failure"
May  3 12:55:41.682: INFO: Pod "pod-configmaps-c1e08580-6da2-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 31.7409ms
May  3 12:55:43.689: INFO: Pod "pod-configmaps-c1e08580-6da2-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0388143s
STEP: Saw pod success
May  3 12:55:43.689: INFO: Pod "pod-configmaps-c1e08580-6da2-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 12:55:43.692: INFO: Trying to get logs from node docker-desktop pod pod-configmaps-c1e08580-6da2-11e9-a622-a62f37ba3446 container configmap-volume-test: <nil>
STEP: delete the pod
May  3 12:55:43.741: INFO: Waiting for pod pod-configmaps-c1e08580-6da2-11e9-a622-a62f37ba3446 to disappear
May  3 12:55:43.748: INFO: Pod pod-configmaps-c1e08580-6da2-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:55:43.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8353" for this suite.
May  3 12:55:49.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:55:49.873: INFO: namespace configmap-8353 deletion completed in 6.1144478s

• [SLOW TEST:8.362 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:55:49.873: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-5081
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May  3 12:55:49.927: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May  3 12:56:14.031: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.1.0.190:8080/dial?request=hostName&protocol=udp&host=10.1.0.189&port=8081&tries=1'] Namespace:pod-network-test-5081 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May  3 12:56:14.031: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
May  3 12:56:14.213: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:56:14.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5081" for this suite.
May  3 12:56:36.237: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:56:36.325: INFO: namespace pod-network-test-5081 deletion completed in 22.1090018s

• [SLOW TEST:46.452 seconds]
[sig-network] Networking
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:56:36.325: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating all guestbook components
May  3 12:56:36.389: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

May  3 12:56:36.390: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 create -f - --namespace=kubectl-3315'
May  3 12:56:36.576: INFO: stderr: ""
May  3 12:56:36.576: INFO: stdout: "service/redis-slave created\n"
May  3 12:56:36.576: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

May  3 12:56:36.576: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 create -f - --namespace=kubectl-3315'
May  3 12:56:36.775: INFO: stderr: ""
May  3 12:56:36.775: INFO: stdout: "service/redis-master created\n"
May  3 12:56:36.775: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

May  3 12:56:36.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 create -f - --namespace=kubectl-3315'
May  3 12:56:36.966: INFO: stderr: ""
May  3 12:56:36.966: INFO: stdout: "service/frontend created\n"
May  3 12:56:36.967: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

May  3 12:56:36.967: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 create -f - --namespace=kubectl-3315'
May  3 12:56:37.153: INFO: stderr: ""
May  3 12:56:37.157: INFO: stdout: "deployment.apps/frontend created\n"
May  3 12:56:37.160: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

May  3 12:56:37.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 create -f - --namespace=kubectl-3315'
May  3 12:56:37.419: INFO: stderr: ""
May  3 12:56:37.419: INFO: stdout: "deployment.apps/redis-master created\n"
May  3 12:56:37.423: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

May  3 12:56:37.423: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 create -f - --namespace=kubectl-3315'
May  3 12:56:37.637: INFO: stderr: ""
May  3 12:56:37.649: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
May  3 12:56:37.649: INFO: Waiting for all frontend pods to be Running.
May  3 12:56:57.719: INFO: Waiting for frontend to serve content.
May  3 12:56:58.822: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection refused [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection refu...', 111)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stream in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

May  3 12:57:03.868: INFO: Trying to add a new entry to the guestbook.
May  3 12:57:03.897: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
May  3 12:57:03.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 delete --grace-period=0 --force -f - --namespace=kubectl-3315'
May  3 12:57:04.207: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May  3 12:57:04.207: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
May  3 12:57:04.210: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 delete --grace-period=0 --force -f - --namespace=kubectl-3315'
May  3 12:57:04.344: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May  3 12:57:04.344: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
May  3 12:57:04.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 delete --grace-period=0 --force -f - --namespace=kubectl-3315'
May  3 12:57:04.452: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May  3 12:57:04.452: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
May  3 12:57:04.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 delete --grace-period=0 --force -f - --namespace=kubectl-3315'
May  3 12:57:04.549: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May  3 12:57:04.549: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
May  3 12:57:04.550: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 delete --grace-period=0 --force -f - --namespace=kubectl-3315'
May  3 12:57:04.638: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May  3 12:57:04.638: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
May  3 12:57:04.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 delete --grace-period=0 --force -f - --namespace=kubectl-3315'
May  3 12:57:04.714: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May  3 12:57:04.715: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:57:04.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3315" for this suite.
May  3 12:57:46.750: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:57:46.852: INFO: namespace kubectl-3315 deletion completed in 42.1247719s

• [SLOW TEST:70.527 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:57:46.855: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-rxb8
STEP: Creating a pod to test atomic-volume-subpath
May  3 12:57:46.989: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-rxb8" in namespace "subpath-9869" to be "success or failure"
May  3 12:57:46.998: INFO: Pod "pod-subpath-test-configmap-rxb8": Phase="Pending", Reason="", readiness=false. Elapsed: 9.0922ms
May  3 12:57:49.002: INFO: Pod "pod-subpath-test-configmap-rxb8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0134972s
May  3 12:57:51.007: INFO: Pod "pod-subpath-test-configmap-rxb8": Phase="Running", Reason="", readiness=true. Elapsed: 4.0184072s
May  3 12:57:53.019: INFO: Pod "pod-subpath-test-configmap-rxb8": Phase="Running", Reason="", readiness=true. Elapsed: 6.0308604s
May  3 12:57:55.029: INFO: Pod "pod-subpath-test-configmap-rxb8": Phase="Running", Reason="", readiness=true. Elapsed: 8.0402089s
May  3 12:57:57.033: INFO: Pod "pod-subpath-test-configmap-rxb8": Phase="Running", Reason="", readiness=true. Elapsed: 10.0445758s
May  3 12:57:59.041: INFO: Pod "pod-subpath-test-configmap-rxb8": Phase="Running", Reason="", readiness=true. Elapsed: 12.0523738s
May  3 12:58:01.049: INFO: Pod "pod-subpath-test-configmap-rxb8": Phase="Running", Reason="", readiness=true. Elapsed: 14.0603995s
May  3 12:58:03.056: INFO: Pod "pod-subpath-test-configmap-rxb8": Phase="Running", Reason="", readiness=true. Elapsed: 16.067355s
May  3 12:58:05.062: INFO: Pod "pod-subpath-test-configmap-rxb8": Phase="Running", Reason="", readiness=true. Elapsed: 18.0730827s
May  3 12:58:07.068: INFO: Pod "pod-subpath-test-configmap-rxb8": Phase="Running", Reason="", readiness=true. Elapsed: 20.0793811s
May  3 12:58:09.076: INFO: Pod "pod-subpath-test-configmap-rxb8": Phase="Running", Reason="", readiness=true. Elapsed: 22.0876129s
May  3 12:58:11.084: INFO: Pod "pod-subpath-test-configmap-rxb8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.0956973s
STEP: Saw pod success
May  3 12:58:11.084: INFO: Pod "pod-subpath-test-configmap-rxb8" satisfied condition "success or failure"
May  3 12:58:11.115: INFO: Trying to get logs from node docker-desktop pod pod-subpath-test-configmap-rxb8 container test-container-subpath-configmap-rxb8: <nil>
STEP: delete the pod
May  3 12:58:11.169: INFO: Waiting for pod pod-subpath-test-configmap-rxb8 to disappear
May  3 12:58:11.177: INFO: Pod pod-subpath-test-configmap-rxb8 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-rxb8
May  3 12:58:11.177: INFO: Deleting pod "pod-subpath-test-configmap-rxb8" in namespace "subpath-9869"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:58:11.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9869" for this suite.
May  3 12:58:17.229: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:58:17.317: INFO: namespace subpath-9869 deletion completed in 6.1094343s

• [SLOW TEST:30.463 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:58:17.346: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-1eb8a8f5-6da3-11e9-a622-a62f37ba3446
STEP: Creating a pod to test consume secrets
May  3 12:58:17.433: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1eba7f67-6da3-11e9-a622-a62f37ba3446" in namespace "projected-6145" to be "success or failure"
May  3 12:58:17.445: INFO: Pod "pod-projected-secrets-1eba7f67-6da3-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 12.3331ms
May  3 12:58:19.448: INFO: Pod "pod-projected-secrets-1eba7f67-6da3-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0150527s
May  3 12:58:21.458: INFO: Pod "pod-projected-secrets-1eba7f67-6da3-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0245041s
STEP: Saw pod success
May  3 12:58:21.458: INFO: Pod "pod-projected-secrets-1eba7f67-6da3-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 12:58:21.493: INFO: Trying to get logs from node docker-desktop pod pod-projected-secrets-1eba7f67-6da3-11e9-a622-a62f37ba3446 container projected-secret-volume-test: <nil>
STEP: delete the pod
May  3 12:58:21.537: INFO: Waiting for pod pod-projected-secrets-1eba7f67-6da3-11e9-a622-a62f37ba3446 to disappear
May  3 12:58:21.545: INFO: Pod pod-projected-secrets-1eba7f67-6da3-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:58:21.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6145" for this suite.
May  3 12:58:27.576: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:58:27.679: INFO: namespace projected-6145 deletion completed in 6.123934s

• [SLOW TEST:10.334 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:58:27.686: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-24e38728-6da3-11e9-a622-a62f37ba3446
STEP: Creating a pod to test consume secrets
May  3 12:58:27.769: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-24e4ce37-6da3-11e9-a622-a62f37ba3446" in namespace "projected-788" to be "success or failure"
May  3 12:58:27.791: INFO: Pod "pod-projected-secrets-24e4ce37-6da3-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 22.7975ms
May  3 12:58:29.800: INFO: Pod "pod-projected-secrets-24e4ce37-6da3-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0310888s
May  3 12:58:31.807: INFO: Pod "pod-projected-secrets-24e4ce37-6da3-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0385139s
STEP: Saw pod success
May  3 12:58:31.807: INFO: Pod "pod-projected-secrets-24e4ce37-6da3-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 12:58:31.839: INFO: Trying to get logs from node docker-desktop pod pod-projected-secrets-24e4ce37-6da3-11e9-a622-a62f37ba3446 container projected-secret-volume-test: <nil>
STEP: delete the pod
May  3 12:58:31.882: INFO: Waiting for pod pod-projected-secrets-24e4ce37-6da3-11e9-a622-a62f37ba3446 to disappear
May  3 12:58:31.900: INFO: Pod pod-projected-secrets-24e4ce37-6da3-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:58:31.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-788" for this suite.
May  3 12:58:37.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:58:38.034: INFO: namespace projected-788 deletion completed in 6.1255912s

• [SLOW TEST:10.348 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:58:38.043: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May  3 12:58:38.111: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:58:42.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1207" for this suite.
May  3 12:59:28.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:59:28.446: INFO: namespace pods-1207 deletion completed in 46.1268323s

• [SLOW TEST:50.404 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:59:28.449: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May  3 12:59:28.532: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4919678f-6da3-11e9-a622-a62f37ba3446" in namespace "projected-2425" to be "success or failure"
May  3 12:59:28.548: INFO: Pod "downwardapi-volume-4919678f-6da3-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 16.7777ms
May  3 12:59:30.566: INFO: Pod "downwardapi-volume-4919678f-6da3-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0340344s
STEP: Saw pod success
May  3 12:59:30.566: INFO: Pod "downwardapi-volume-4919678f-6da3-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 12:59:30.575: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-4919678f-6da3-11e9-a622-a62f37ba3446 container client-container: <nil>
STEP: delete the pod
May  3 12:59:30.616: INFO: Waiting for pod downwardapi-volume-4919678f-6da3-11e9-a622-a62f37ba3446 to disappear
May  3 12:59:30.630: INFO: Pod downwardapi-volume-4919678f-6da3-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:59:30.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2425" for this suite.
May  3 12:59:36.707: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 12:59:36.800: INFO: namespace projected-2425 deletion completed in 6.1542359s

• [SLOW TEST:8.351 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 12:59:36.802: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-871
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May  3 12:59:36.881: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May  3 12:59:55.006: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.1.0.203:8080/dial?request=hostName&protocol=http&host=10.1.0.202&port=8080&tries=1'] Namespace:pod-network-test-871 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May  3 12:59:55.006: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
May  3 12:59:55.181: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 12:59:55.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-871" for this suite.
May  3 13:00:17.225: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:00:17.317: INFO: namespace pod-network-test-871 deletion completed in 22.1217687s

• [SLOW TEST:40.515 seconds]
[sig-network] Networking
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:00:17.317: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May  3 13:00:17.384: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
May  3 13:00:17.417: INFO: Number of nodes with available pods: 0
May  3 13:00:17.417: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
May  3 13:00:17.447: INFO: Number of nodes with available pods: 0
May  3 13:00:17.447: INFO: Node docker-desktop is running more than one daemon pod
May  3 13:00:18.468: INFO: Number of nodes with available pods: 0
May  3 13:00:18.473: INFO: Node docker-desktop is running more than one daemon pod
May  3 13:00:19.455: INFO: Number of nodes with available pods: 1
May  3 13:00:19.456: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
May  3 13:00:19.484: INFO: Number of nodes with available pods: 1
May  3 13:00:19.484: INFO: Number of running nodes: 0, number of available pods: 1
May  3 13:00:20.486: INFO: Number of nodes with available pods: 0
May  3 13:00:20.486: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
May  3 13:00:20.503: INFO: Number of nodes with available pods: 0
May  3 13:00:20.503: INFO: Node docker-desktop is running more than one daemon pod
May  3 13:00:21.505: INFO: Number of nodes with available pods: 0
May  3 13:00:21.505: INFO: Node docker-desktop is running more than one daemon pod
May  3 13:00:22.505: INFO: Number of nodes with available pods: 0
May  3 13:00:22.505: INFO: Node docker-desktop is running more than one daemon pod
May  3 13:00:23.505: INFO: Number of nodes with available pods: 0
May  3 13:00:23.505: INFO: Node docker-desktop is running more than one daemon pod
May  3 13:00:24.508: INFO: Number of nodes with available pods: 0
May  3 13:00:24.508: INFO: Node docker-desktop is running more than one daemon pod
May  3 13:00:25.507: INFO: Number of nodes with available pods: 0
May  3 13:00:25.507: INFO: Node docker-desktop is running more than one daemon pod
May  3 13:00:26.508: INFO: Number of nodes with available pods: 0
May  3 13:00:26.508: INFO: Node docker-desktop is running more than one daemon pod
May  3 13:00:27.505: INFO: Number of nodes with available pods: 0
May  3 13:00:27.505: INFO: Node docker-desktop is running more than one daemon pod
May  3 13:00:28.510: INFO: Number of nodes with available pods: 0
May  3 13:00:28.510: INFO: Node docker-desktop is running more than one daemon pod
May  3 13:00:29.505: INFO: Number of nodes with available pods: 1
May  3 13:00:29.505: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7181, will wait for the garbage collector to delete the pods
May  3 13:00:29.584: INFO: Deleting DaemonSet.extensions daemon-set took: 7.3196ms
May  3 13:00:29.987: INFO: Terminating DaemonSet.extensions daemon-set pods took: 402.6936ms
May  3 13:00:32.990: INFO: Number of nodes with available pods: 0
May  3 13:00:32.990: INFO: Number of running nodes: 0, number of available pods: 0
May  3 13:00:32.999: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7181/daemonsets","resourceVersion":"17858"},"items":null}

May  3 13:00:33.009: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7181/pods","resourceVersion":"17858"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:00:33.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7181" for this suite.
May  3 13:00:39.051: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:00:39.155: INFO: namespace daemonsets-7181 deletion completed in 6.1234088s

• [SLOW TEST:21.838 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:00:39.155: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May  3 13:00:39.234: INFO: Waiting up to 5m0s for pod "downwardapi-volume-733f3d6a-6da3-11e9-a622-a62f37ba3446" in namespace "projected-7971" to be "success or failure"
May  3 13:00:39.259: INFO: Pod "downwardapi-volume-733f3d6a-6da3-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 24.9921ms
May  3 13:00:41.276: INFO: Pod "downwardapi-volume-733f3d6a-6da3-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0419907s
STEP: Saw pod success
May  3 13:00:41.276: INFO: Pod "downwardapi-volume-733f3d6a-6da3-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 13:00:41.278: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-733f3d6a-6da3-11e9-a622-a62f37ba3446 container client-container: <nil>
STEP: delete the pod
May  3 13:00:41.377: INFO: Waiting for pod downwardapi-volume-733f3d6a-6da3-11e9-a622-a62f37ba3446 to disappear
May  3 13:00:41.387: INFO: Pod downwardapi-volume-733f3d6a-6da3-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:00:41.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7971" for this suite.
May  3 13:00:47.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:00:47.513: INFO: namespace projected-7971 deletion completed in 6.1089166s

• [SLOW TEST:8.358 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:00:47.515: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-783e24fe-6da3-11e9-a622-a62f37ba3446
STEP: Creating secret with name s-test-opt-upd-783e2540-6da3-11e9-a622-a62f37ba3446
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-783e24fe-6da3-11e9-a622-a62f37ba3446
STEP: Updating secret s-test-opt-upd-783e2540-6da3-11e9-a622-a62f37ba3446
STEP: Creating secret with name s-test-opt-create-783e2558-6da3-11e9-a622-a62f37ba3446
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:02:08.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-64" for this suite.
May  3 13:02:30.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:02:30.358: INFO: namespace secrets-64 deletion completed in 22.1108823s

• [SLOW TEST:102.843 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:02:30.358: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:02:59.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5619" for this suite.
May  3 13:03:05.938: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:03:06.044: INFO: namespace container-runtime-5619 deletion completed in 6.1244716s

• [SLOW TEST:35.686 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  blackbox test
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:03:06.050: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
May  3 13:03:06.130: INFO: Waiting up to 5m0s for pod "pod-cacf265c-6da3-11e9-a622-a62f37ba3446" in namespace "emptydir-2049" to be "success or failure"
May  3 13:03:06.139: INFO: Pod "pod-cacf265c-6da3-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 9.1544ms
May  3 13:03:08.146: INFO: Pod "pod-cacf265c-6da3-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015625s
STEP: Saw pod success
May  3 13:03:08.148: INFO: Pod "pod-cacf265c-6da3-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 13:03:08.155: INFO: Trying to get logs from node docker-desktop pod pod-cacf265c-6da3-11e9-a622-a62f37ba3446 container test-container: <nil>
STEP: delete the pod
May  3 13:03:08.194: INFO: Waiting for pod pod-cacf265c-6da3-11e9-a622-a62f37ba3446 to disappear
May  3 13:03:08.204: INFO: Pod pod-cacf265c-6da3-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:03:08.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2049" for this suite.
May  3 13:03:14.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:03:14.367: INFO: namespace emptydir-2049 deletion completed in 6.1369822s

• [SLOW TEST:8.318 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:03:14.371: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-cfc3509c-6da3-11e9-a622-a62f37ba3446
STEP: Creating a pod to test consume secrets
May  3 13:03:14.454: INFO: Waiting up to 5m0s for pod "pod-secrets-cfc47df1-6da3-11e9-a622-a62f37ba3446" in namespace "secrets-2469" to be "success or failure"
May  3 13:03:14.485: INFO: Pod "pod-secrets-cfc47df1-6da3-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 24.7242ms
May  3 13:03:16.493: INFO: Pod "pod-secrets-cfc47df1-6da3-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0326223s
STEP: Saw pod success
May  3 13:03:16.493: INFO: Pod "pod-secrets-cfc47df1-6da3-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 13:03:16.505: INFO: Trying to get logs from node docker-desktop pod pod-secrets-cfc47df1-6da3-11e9-a622-a62f37ba3446 container secret-volume-test: <nil>
STEP: delete the pod
May  3 13:03:16.540: INFO: Waiting for pod pod-secrets-cfc47df1-6da3-11e9-a622-a62f37ba3446 to disappear
May  3 13:03:16.553: INFO: Pod pod-secrets-cfc47df1-6da3-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:03:16.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2469" for this suite.
May  3 13:03:22.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:03:22.725: INFO: namespace secrets-2469 deletion completed in 6.1454795s

• [SLOW TEST:8.354 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:03:22.725: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with configMap that has name projected-configmap-test-upd-d4c15826-6da3-11e9-a622-a62f37ba3446
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-d4c15826-6da3-11e9-a622-a62f37ba3446
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:03:26.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1494" for this suite.
May  3 13:03:48.935: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:03:49.058: INFO: namespace projected-1494 deletion completed in 22.1418227s

• [SLOW TEST:26.332 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:03:49.065: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:03:53.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2952" for this suite.
May  3 13:03:59.212: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:03:59.317: INFO: namespace kubelet-test-2952 deletion completed in 6.1349243s

• [SLOW TEST:10.253 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:03:59.319: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1318
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
May  3 13:03:59.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-8891'
May  3 13:03:59.792: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May  3 13:03:59.792: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1324
May  3 13:03:59.815: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 delete deployment e2e-test-nginx-deployment --namespace=kubectl-8891'
May  3 13:03:59.921: INFO: stderr: ""
May  3 13:03:59.921: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:03:59.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8891" for this suite.
May  3 13:04:05.943: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:04:06.061: INFO: namespace kubectl-8891 deletion completed in 6.1380871s

• [SLOW TEST:6.744 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:04:06.063: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:05:06.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8505" for this suite.
May  3 13:05:28.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:05:28.305: INFO: namespace container-probe-8505 deletion completed in 22.1370456s

• [SLOW TEST:82.242 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:05:28.318: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
May  3 13:05:28.624: INFO: Pod name wrapped-volume-race-1fb52c36-6da4-11e9-a622-a62f37ba3446: Found 3 pods out of 5
May  3 13:05:33.628: INFO: Pod name wrapped-volume-race-1fb52c36-6da4-11e9-a622-a62f37ba3446: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-1fb52c36-6da4-11e9-a622-a62f37ba3446 in namespace emptydir-wrapper-5363, will wait for the garbage collector to delete the pods
May  3 13:05:43.784: INFO: Deleting ReplicationController wrapped-volume-race-1fb52c36-6da4-11e9-a622-a62f37ba3446 took: 32.9985ms
May  3 13:05:44.185: INFO: Terminating ReplicationController wrapped-volume-race-1fb52c36-6da4-11e9-a622-a62f37ba3446 pods took: 400.2156ms
STEP: Creating RC which spawns configmap-volume pods
May  3 13:06:26.705: INFO: Pod name wrapped-volume-race-425b4d99-6da4-11e9-a622-a62f37ba3446: Found 0 pods out of 5
May  3 13:06:31.710: INFO: Pod name wrapped-volume-race-425b4d99-6da4-11e9-a622-a62f37ba3446: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-425b4d99-6da4-11e9-a622-a62f37ba3446 in namespace emptydir-wrapper-5363, will wait for the garbage collector to delete the pods
May  3 13:06:43.823: INFO: Deleting ReplicationController wrapped-volume-race-425b4d99-6da4-11e9-a622-a62f37ba3446 took: 5.7081ms
May  3 13:06:44.323: INFO: Terminating ReplicationController wrapped-volume-race-425b4d99-6da4-11e9-a622-a62f37ba3446 pods took: 500.3884ms
STEP: Creating RC which spawns configmap-volume pods
May  3 13:07:26.345: INFO: Pod name wrapped-volume-race-65e76a36-6da4-11e9-a622-a62f37ba3446: Found 0 pods out of 5
May  3 13:07:31.350: INFO: Pod name wrapped-volume-race-65e76a36-6da4-11e9-a622-a62f37ba3446: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-65e76a36-6da4-11e9-a622-a62f37ba3446 in namespace emptydir-wrapper-5363, will wait for the garbage collector to delete the pods
May  3 13:07:43.479: INFO: Deleting ReplicationController wrapped-volume-race-65e76a36-6da4-11e9-a622-a62f37ba3446 took: 7.4013ms
May  3 13:07:43.984: INFO: Terminating ReplicationController wrapped-volume-race-65e76a36-6da4-11e9-a622-a62f37ba3446 pods took: 504.5955ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:08:26.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-5363" for this suite.
May  3 13:08:32.953: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:08:33.063: INFO: namespace emptydir-wrapper-5363 deletion completed in 6.1254359s

• [SLOW TEST:184.746 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:08:33.073: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-xpffg in namespace proxy-8473
I0503 13:08:33.184998      15 runners.go:184] Created replication controller with name: proxy-service-xpffg, namespace: proxy-8473, replica count: 1
I0503 13:08:34.236629      15 runners.go:184] proxy-service-xpffg Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0503 13:08:35.239623      15 runners.go:184] proxy-service-xpffg Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0503 13:08:36.239909      15 runners.go:184] proxy-service-xpffg Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0503 13:08:37.240231      15 runners.go:184] proxy-service-xpffg Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0503 13:08:38.240396      15 runners.go:184] proxy-service-xpffg Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0503 13:08:39.240837      15 runners.go:184] proxy-service-xpffg Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0503 13:08:40.241226      15 runners.go:184] proxy-service-xpffg Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0503 13:08:41.241570      15 runners.go:184] proxy-service-xpffg Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0503 13:08:42.241853      15 runners.go:184] proxy-service-xpffg Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0503 13:08:43.243588      15 runners.go:184] proxy-service-xpffg Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May  3 13:08:43.260: INFO: setup took 10.1296864s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
May  3 13:08:43.284: INFO: (0) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:162/proxy/: bar (200; 8.2209ms)
May  3 13:08:43.291: INFO: (0) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:1080/proxy/rewriteme">test<... (200; 15.7807ms)
May  3 13:08:43.304: INFO: (0) /api/v1/namespaces/proxy-8473/services/http:proxy-service-xpffg:portname2/proxy/: bar (200; 27.079ms)
May  3 13:08:43.312: INFO: (0) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:160/proxy/: foo (200; 35.2334ms)
May  3 13:08:43.312: INFO: (0) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:162/proxy/: bar (200; 35.2816ms)
May  3 13:08:43.312: INFO: (0) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:1080/proxy/rewriteme">... (200; 35.2962ms)
May  3 13:08:43.312: INFO: (0) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:160/proxy/: foo (200; 35.4273ms)
May  3 13:08:43.333: INFO: (0) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx/proxy/rewriteme">test</a> (200; 56.1538ms)
May  3 13:08:43.343: INFO: (0) /api/v1/namespaces/proxy-8473/services/proxy-service-xpffg:portname1/proxy/: foo (200; 66.0754ms)
May  3 13:08:43.345: INFO: (0) /api/v1/namespaces/proxy-8473/services/proxy-service-xpffg:portname2/proxy/: bar (200; 68.1164ms)
May  3 13:08:43.345: INFO: (0) /api/v1/namespaces/proxy-8473/services/http:proxy-service-xpffg:portname1/proxy/: foo (200; 68.1758ms)
May  3 13:08:43.352: INFO: (0) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:460/proxy/: tls baz (200; 75.9811ms)
May  3 13:08:43.356: INFO: (0) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:462/proxy/: tls qux (200; 79.6504ms)
May  3 13:08:43.356: INFO: (0) /api/v1/namespaces/proxy-8473/services/https:proxy-service-xpffg:tlsportname1/proxy/: tls baz (200; 79.5603ms)
May  3 13:08:43.362: INFO: (0) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:443/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:443/proxy/tlsrewritem... (200; 85.1089ms)
May  3 13:08:43.362: INFO: (0) /api/v1/namespaces/proxy-8473/services/https:proxy-service-xpffg:tlsportname2/proxy/: tls qux (200; 85.3968ms)
May  3 13:08:43.383: INFO: (1) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:462/proxy/: tls qux (200; 21.3214ms)
May  3 13:08:43.399: INFO: (1) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:160/proxy/: foo (200; 34.6954ms)
May  3 13:08:43.399: INFO: (1) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:162/proxy/: bar (200; 34.6174ms)
May  3 13:08:43.399: INFO: (1) /api/v1/namespaces/proxy-8473/services/http:proxy-service-xpffg:portname1/proxy/: foo (200; 34.9577ms)
May  3 13:08:43.400: INFO: (1) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:460/proxy/: tls baz (200; 35.2898ms)
May  3 13:08:43.400: INFO: (1) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:443/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:443/proxy/tlsrewritem... (200; 35.1996ms)
May  3 13:08:43.400: INFO: (1) /api/v1/namespaces/proxy-8473/services/http:proxy-service-xpffg:portname2/proxy/: bar (200; 35.2958ms)
May  3 13:08:43.414: INFO: (1) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:160/proxy/: foo (200; 49.4693ms)
May  3 13:08:43.414: INFO: (1) /api/v1/namespaces/proxy-8473/services/https:proxy-service-xpffg:tlsportname2/proxy/: tls qux (200; 49.6155ms)
May  3 13:08:43.415: INFO: (1) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:1080/proxy/rewriteme">test<... (200; 50.6821ms)
May  3 13:08:43.415: INFO: (1) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx/proxy/rewriteme">test</a> (200; 50.7574ms)
May  3 13:08:43.416: INFO: (1) /api/v1/namespaces/proxy-8473/services/proxy-service-xpffg:portname1/proxy/: foo (200; 50.9519ms)
May  3 13:08:43.416: INFO: (1) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:1080/proxy/rewriteme">... (200; 50.8209ms)
May  3 13:08:43.416: INFO: (1) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:162/proxy/: bar (200; 51.1588ms)
May  3 13:08:43.416: INFO: (1) /api/v1/namespaces/proxy-8473/services/proxy-service-xpffg:portname2/proxy/: bar (200; 51.3378ms)
May  3 13:08:43.426: INFO: (1) /api/v1/namespaces/proxy-8473/services/https:proxy-service-xpffg:tlsportname1/proxy/: tls baz (200; 61.3615ms)
May  3 13:08:43.444: INFO: (2) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:162/proxy/: bar (200; 17.5891ms)
May  3 13:08:43.460: INFO: (2) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:162/proxy/: bar (200; 29.9095ms)
May  3 13:08:43.460: INFO: (2) /api/v1/namespaces/proxy-8473/services/http:proxy-service-xpffg:portname2/proxy/: bar (200; 29.875ms)
May  3 13:08:43.460: INFO: (2) /api/v1/namespaces/proxy-8473/services/http:proxy-service-xpffg:portname1/proxy/: foo (200; 30.3615ms)
May  3 13:08:43.460: INFO: (2) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:160/proxy/: foo (200; 29.7748ms)
May  3 13:08:43.461: INFO: (2) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:460/proxy/: tls baz (200; 30.0964ms)
May  3 13:08:43.461: INFO: (2) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx/proxy/rewriteme">test</a> (200; 30.3005ms)
May  3 13:08:43.470: INFO: (2) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:1080/proxy/rewriteme">test<... (200; 39.2847ms)
May  3 13:08:43.470: INFO: (2) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:443/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:443/proxy/tlsrewritem... (200; 40.1001ms)
May  3 13:08:43.477: INFO: (2) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:1080/proxy/rewriteme">... (200; 46.9972ms)
May  3 13:08:43.477: INFO: (2) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:462/proxy/: tls qux (200; 46.4785ms)
May  3 13:08:43.477: INFO: (2) /api/v1/namespaces/proxy-8473/services/proxy-service-xpffg:portname2/proxy/: bar (200; 47.0633ms)
May  3 13:08:43.477: INFO: (2) /api/v1/namespaces/proxy-8473/services/https:proxy-service-xpffg:tlsportname1/proxy/: tls baz (200; 46.7678ms)
May  3 13:08:43.477: INFO: (2) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:160/proxy/: foo (200; 46.4308ms)
May  3 13:08:43.483: INFO: (2) /api/v1/namespaces/proxy-8473/services/proxy-service-xpffg:portname1/proxy/: foo (200; 52.4742ms)
May  3 13:08:43.483: INFO: (2) /api/v1/namespaces/proxy-8473/services/https:proxy-service-xpffg:tlsportname2/proxy/: tls qux (200; 52.7862ms)
May  3 13:08:43.501: INFO: (3) /api/v1/namespaces/proxy-8473/services/https:proxy-service-xpffg:tlsportname1/proxy/: tls baz (200; 17.2002ms)
May  3 13:08:43.508: INFO: (3) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:462/proxy/: tls qux (200; 23.2245ms)
May  3 13:08:43.515: INFO: (3) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:162/proxy/: bar (200; 31.387ms)
May  3 13:08:43.529: INFO: (3) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:1080/proxy/rewriteme">... (200; 28.2454ms)
May  3 13:08:43.530: INFO: (3) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx/proxy/rewriteme">test</a> (200; 30.4963ms)
May  3 13:08:43.530: INFO: (3) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:443/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:443/proxy/tlsrewritem... (200; 29.3113ms)
May  3 13:08:43.532: INFO: (3) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:160/proxy/: foo (200; 31.3572ms)
May  3 13:08:43.533: INFO: (3) /api/v1/namespaces/proxy-8473/services/http:proxy-service-xpffg:portname2/proxy/: bar (200; 35.8826ms)
May  3 13:08:43.537: INFO: (3) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:160/proxy/: foo (200; 36.4358ms)
May  3 13:08:43.545: INFO: (3) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:1080/proxy/rewriteme">test<... (200; 44.3207ms)
May  3 13:08:43.546: INFO: (3) /api/v1/namespaces/proxy-8473/services/proxy-service-xpffg:portname1/proxy/: foo (200; 45.3822ms)
May  3 13:08:43.546: INFO: (3) /api/v1/namespaces/proxy-8473/services/https:proxy-service-xpffg:tlsportname2/proxy/: tls qux (200; 45.9437ms)
May  3 13:08:43.550: INFO: (3) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:162/proxy/: bar (200; 49.9701ms)
May  3 13:08:43.553: INFO: (3) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:460/proxy/: tls baz (200; 52.1671ms)
May  3 13:08:43.553: INFO: (3) /api/v1/namespaces/proxy-8473/services/http:proxy-service-xpffg:portname1/proxy/: foo (200; 52.2935ms)
May  3 13:08:43.562: INFO: (3) /api/v1/namespaces/proxy-8473/services/proxy-service-xpffg:portname2/proxy/: bar (200; 61.4542ms)
May  3 13:08:43.581: INFO: (4) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:160/proxy/: foo (200; 16.468ms)
May  3 13:08:43.581: INFO: (4) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:162/proxy/: bar (200; 18.7164ms)
May  3 13:08:43.581: INFO: (4) /api/v1/namespaces/proxy-8473/services/proxy-service-xpffg:portname2/proxy/: bar (200; 17.6857ms)
May  3 13:08:43.581: INFO: (4) /api/v1/namespaces/proxy-8473/services/http:proxy-service-xpffg:portname2/proxy/: bar (200; 17.1216ms)
May  3 13:08:43.594: INFO: (4) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx/proxy/rewriteme">test</a> (200; 30.4867ms)
May  3 13:08:43.594: INFO: (4) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:1080/proxy/rewriteme">test<... (200; 30.4445ms)
May  3 13:08:43.594: INFO: (4) /api/v1/namespaces/proxy-8473/services/proxy-service-xpffg:portname1/proxy/: foo (200; 30.055ms)
May  3 13:08:43.594: INFO: (4) /api/v1/namespaces/proxy-8473/services/https:proxy-service-xpffg:tlsportname1/proxy/: tls baz (200; 31.0559ms)
May  3 13:08:43.594: INFO: (4) /api/v1/namespaces/proxy-8473/services/http:proxy-service-xpffg:portname1/proxy/: foo (200; 32.0459ms)
May  3 13:08:43.594: INFO: (4) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:162/proxy/: bar (200; 30.4511ms)
May  3 13:08:43.594: INFO: (4) /api/v1/namespaces/proxy-8473/services/https:proxy-service-xpffg:tlsportname2/proxy/: tls qux (200; 30.2625ms)
May  3 13:08:43.594: INFO: (4) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:462/proxy/: tls qux (200; 30.4032ms)
May  3 13:08:43.594: INFO: (4) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:1080/proxy/rewriteme">... (200; 30.9274ms)
May  3 13:08:43.594: INFO: (4) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:443/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:443/proxy/tlsrewritem... (200; 31.1042ms)
May  3 13:08:43.595: INFO: (4) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:160/proxy/: foo (200; 30.5693ms)
May  3 13:08:43.595: INFO: (4) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:460/proxy/: tls baz (200; 30.5386ms)
May  3 13:08:43.621: INFO: (5) /api/v1/namespaces/proxy-8473/services/proxy-service-xpffg:portname1/proxy/: foo (200; 21.3329ms)
May  3 13:08:43.621: INFO: (5) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:460/proxy/: tls baz (200; 22.5579ms)
May  3 13:08:43.621: INFO: (5) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:162/proxy/: bar (200; 21.2718ms)
May  3 13:08:43.621: INFO: (5) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:443/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:443/proxy/tlsrewritem... (200; 21.28ms)
May  3 13:08:43.621: INFO: (5) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:160/proxy/: foo (200; 21.3835ms)
May  3 13:08:43.630: INFO: (5) /api/v1/namespaces/proxy-8473/services/https:proxy-service-xpffg:tlsportname1/proxy/: tls baz (200; 30.8076ms)
May  3 13:08:43.630: INFO: (5) /api/v1/namespaces/proxy-8473/services/proxy-service-xpffg:portname2/proxy/: bar (200; 30.9522ms)
May  3 13:08:43.631: INFO: (5) /api/v1/namespaces/proxy-8473/services/http:proxy-service-xpffg:portname1/proxy/: foo (200; 31.0254ms)
May  3 13:08:43.631: INFO: (5) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx/proxy/rewriteme">test</a> (200; 30.9017ms)
May  3 13:08:43.641: INFO: (5) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:1080/proxy/rewriteme">test<... (200; 40.9348ms)
May  3 13:08:43.641: INFO: (5) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:160/proxy/: foo (200; 41.2846ms)
May  3 13:08:43.641: INFO: (5) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:1080/proxy/rewriteme">... (200; 41.8251ms)
May  3 13:08:43.642: INFO: (5) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:162/proxy/: bar (200; 41.8054ms)
May  3 13:08:43.642: INFO: (5) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:462/proxy/: tls qux (200; 42.052ms)
May  3 13:08:43.642: INFO: (5) /api/v1/namespaces/proxy-8473/services/http:proxy-service-xpffg:portname2/proxy/: bar (200; 42.0919ms)
May  3 13:08:43.647: INFO: (5) /api/v1/namespaces/proxy-8473/services/https:proxy-service-xpffg:tlsportname2/proxy/: tls qux (200; 47.474ms)
May  3 13:08:43.661: INFO: (6) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:160/proxy/: foo (200; 12.0381ms)
May  3 13:08:43.669: INFO: (6) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:162/proxy/: bar (200; 16.4695ms)
May  3 13:08:43.676: INFO: (6) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:162/proxy/: bar (200; 25.2263ms)
May  3 13:08:43.679: INFO: (6) /api/v1/namespaces/proxy-8473/services/proxy-service-xpffg:portname2/proxy/: bar (200; 26.7555ms)
May  3 13:08:43.679: INFO: (6) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:160/proxy/: foo (200; 26.9305ms)
May  3 13:08:43.681: INFO: (6) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx/proxy/rewriteme">test</a> (200; 28.8333ms)
May  3 13:08:43.681: INFO: (6) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:1080/proxy/rewriteme">test<... (200; 28.879ms)
May  3 13:08:43.681: INFO: (6) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:460/proxy/: tls baz (200; 28.9415ms)
May  3 13:08:43.681: INFO: (6) /api/v1/namespaces/proxy-8473/services/proxy-service-xpffg:portname1/proxy/: foo (200; 29.2985ms)
May  3 13:08:43.681: INFO: (6) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:1080/proxy/rewriteme">... (200; 28.9768ms)
May  3 13:08:43.681: INFO: (6) /api/v1/namespaces/proxy-8473/services/https:proxy-service-xpffg:tlsportname2/proxy/: tls qux (200; 33.2934ms)
May  3 13:08:43.681: INFO: (6) /api/v1/namespaces/proxy-8473/services/http:proxy-service-xpffg:portname1/proxy/: foo (200; 28.8816ms)
May  3 13:08:43.681: INFO: (6) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:443/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:443/proxy/tlsrewritem... (200; 28.9343ms)
May  3 13:08:43.681: INFO: (6) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:462/proxy/: tls qux (200; 29.1167ms)
May  3 13:08:43.681: INFO: (6) /api/v1/namespaces/proxy-8473/services/https:proxy-service-xpffg:tlsportname1/proxy/: tls baz (200; 29.0112ms)
May  3 13:08:43.698: INFO: (6) /api/v1/namespaces/proxy-8473/services/http:proxy-service-xpffg:portname2/proxy/: bar (200; 45.9774ms)
May  3 13:08:43.723: INFO: (7) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:162/proxy/: bar (200; 11.9826ms)
May  3 13:08:43.724: INFO: (7) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:162/proxy/: bar (200; 25.1691ms)
May  3 13:08:43.724: INFO: (7) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:160/proxy/: foo (200; 25.0996ms)
May  3 13:08:43.724: INFO: (7) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:460/proxy/: tls baz (200; 25.3012ms)
May  3 13:08:43.724: INFO: (7) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:443/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:443/proxy/tlsrewritem... (200; 12.8776ms)
May  3 13:08:43.726: INFO: (7) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx/proxy/rewriteme">test</a> (200; 14.072ms)
May  3 13:08:43.726: INFO: (7) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:1080/proxy/rewriteme">... (200; 14.2629ms)
May  3 13:08:43.726: INFO: (7) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:1080/proxy/rewriteme">test<... (200; 14.1947ms)
May  3 13:08:43.726: INFO: (7) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:462/proxy/: tls qux (200; 14.3108ms)
May  3 13:08:43.735: INFO: (7) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:160/proxy/: foo (200; 20.3066ms)
May  3 13:08:43.736: INFO: (7) /api/v1/namespaces/proxy-8473/services/proxy-service-xpffg:portname2/proxy/: bar (200; 25.1177ms)
May  3 13:08:43.737: INFO: (7) /api/v1/namespaces/proxy-8473/services/http:proxy-service-xpffg:portname1/proxy/: foo (200; 25.2106ms)
May  3 13:08:43.737: INFO: (7) /api/v1/namespaces/proxy-8473/services/https:proxy-service-xpffg:tlsportname2/proxy/: tls qux (200; 38.0264ms)
May  3 13:08:43.737: INFO: (7) /api/v1/namespaces/proxy-8473/services/proxy-service-xpffg:portname1/proxy/: foo (200; 37.8924ms)
May  3 13:08:43.737: INFO: (7) /api/v1/namespaces/proxy-8473/services/https:proxy-service-xpffg:tlsportname1/proxy/: tls baz (200; 25.5558ms)
May  3 13:08:43.742: INFO: (7) /api/v1/namespaces/proxy-8473/services/http:proxy-service-xpffg:portname2/proxy/: bar (200; 30.8645ms)
May  3 13:08:43.769: INFO: (8) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:1080/proxy/rewriteme">... (200; 16.1675ms)
May  3 13:08:43.769: INFO: (8) /api/v1/namespaces/proxy-8473/services/https:proxy-service-xpffg:tlsportname1/proxy/: tls baz (200; 16.2028ms)
May  3 13:08:43.769: INFO: (8) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:160/proxy/: foo (200; 26.8539ms)
May  3 13:08:43.770: INFO: (8) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:460/proxy/: tls baz (200; 26.4934ms)
May  3 13:08:43.771: INFO: (8) /api/v1/namespaces/proxy-8473/services/proxy-service-xpffg:portname2/proxy/: bar (200; 17.9779ms)
May  3 13:08:43.773: INFO: (8) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:162/proxy/: bar (200; 23.6403ms)
May  3 13:08:43.773: INFO: (8) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:443/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:443/proxy/tlsrewritem... (200; 23.5646ms)
May  3 13:08:43.773: INFO: (8) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:160/proxy/: foo (200; 24.4071ms)
May  3 13:08:43.773: INFO: (8) /api/v1/namespaces/proxy-8473/services/http:proxy-service-xpffg:portname2/proxy/: bar (200; 20.2528ms)
May  3 13:08:43.774: INFO: (8) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx/proxy/rewriteme">test</a> (200; 21.2216ms)
May  3 13:08:43.774: INFO: (8) /api/v1/namespaces/proxy-8473/services/http:proxy-service-xpffg:portname1/proxy/: foo (200; 21.5278ms)
May  3 13:08:43.774: INFO: (8) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:162/proxy/: bar (200; 21.7021ms)
May  3 13:08:43.774: INFO: (8) /api/v1/namespaces/proxy-8473/services/https:proxy-service-xpffg:tlsportname2/proxy/: tls qux (200; 29.6895ms)
May  3 13:08:43.775: INFO: (8) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:462/proxy/: tls qux (200; 21.535ms)
May  3 13:08:43.775: INFO: (8) /api/v1/namespaces/proxy-8473/services/proxy-service-xpffg:portname1/proxy/: foo (200; 25.7289ms)
May  3 13:08:43.782: INFO: (8) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:1080/proxy/rewriteme">test<... (200; 28.6138ms)
May  3 13:08:43.795: INFO: (9) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:1080/proxy/rewriteme">test<... (200; 13.1362ms)
May  3 13:08:43.803: INFO: (9) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:162/proxy/: bar (200; 21.5004ms)
May  3 13:08:43.803: INFO: (9) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:162/proxy/: bar (200; 17.8733ms)
May  3 13:08:43.814: INFO: (9) /api/v1/namespaces/proxy-8473/services/http:proxy-service-xpffg:portname1/proxy/: foo (200; 32.6245ms)
May  3 13:08:43.816: INFO: (9) /api/v1/namespaces/proxy-8473/services/http:proxy-service-xpffg:portname2/proxy/: bar (200; 24.0233ms)
May  3 13:08:43.816: INFO: (9) /api/v1/namespaces/proxy-8473/services/https:proxy-service-xpffg:tlsportname1/proxy/: tls baz (200; 25.058ms)
May  3 13:08:43.816: INFO: (9) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:1080/proxy/rewriteme">... (200; 24.998ms)
May  3 13:08:43.816: INFO: (9) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:462/proxy/: tls qux (200; 30.5024ms)
May  3 13:08:43.816: INFO: (9) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:460/proxy/: tls baz (200; 24.5912ms)
May  3 13:08:43.817: INFO: (9) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:160/proxy/: foo (200; 24.5626ms)
May  3 13:08:43.817: INFO: (9) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:160/proxy/: foo (200; 24.6989ms)
May  3 13:08:43.817: INFO: (9) /api/v1/namespaces/proxy-8473/services/proxy-service-xpffg:portname2/proxy/: bar (200; 31.6302ms)
May  3 13:08:43.817: INFO: (9) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx/proxy/rewriteme">test</a> (200; 24.8164ms)
May  3 13:08:43.818: INFO: (9) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:443/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:443/proxy/tlsrewritem... (200; 25.6503ms)
May  3 13:08:43.819: INFO: (9) /api/v1/namespaces/proxy-8473/services/https:proxy-service-xpffg:tlsportname2/proxy/: tls qux (200; 32.1048ms)
May  3 13:08:43.820: INFO: (9) /api/v1/namespaces/proxy-8473/services/proxy-service-xpffg:portname1/proxy/: foo (200; 27.9345ms)
May  3 13:08:43.863: INFO: (10) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:462/proxy/: tls qux (200; 38.8371ms)
May  3 13:08:43.864: INFO: (10) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:162/proxy/: bar (200; 15.0577ms)
May  3 13:08:43.875: INFO: (10) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:443/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:443/proxy/tlsrewritem... (200; 50.1267ms)
May  3 13:08:43.876: INFO: (10) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:1080/proxy/rewriteme">... (200; 50.9286ms)
May  3 13:08:43.877: INFO: (10) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:162/proxy/: bar (200; 53.5537ms)
May  3 13:08:43.877: INFO: (10) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:1080/proxy/rewriteme">test<... (200; 33.586ms)
May  3 13:08:43.880: INFO: (10) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:460/proxy/: tls baz (200; 35.8814ms)
May  3 13:08:43.879: INFO: (10) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:160/proxy/: foo (200; 29.4827ms)
May  3 13:08:43.882: INFO: (10) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx/proxy/rewriteme">test</a> (200; 38.6668ms)
May  3 13:08:43.885: INFO: (10) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:160/proxy/: foo (200; 40.9187ms)
May  3 13:08:43.887: INFO: (10) /api/v1/namespaces/proxy-8473/services/http:proxy-service-xpffg:portname2/proxy/: bar (200; 60.8208ms)
May  3 13:08:43.899: INFO: (10) /api/v1/namespaces/proxy-8473/services/https:proxy-service-xpffg:tlsportname2/proxy/: tls qux (200; 55.8455ms)
May  3 13:08:43.899: INFO: (10) /api/v1/namespaces/proxy-8473/services/http:proxy-service-xpffg:portname1/proxy/: foo (200; 74.195ms)
May  3 13:08:43.899: INFO: (10) /api/v1/namespaces/proxy-8473/services/https:proxy-service-xpffg:tlsportname1/proxy/: tls baz (200; 50.1402ms)
May  3 13:08:43.899: INFO: (10) /api/v1/namespaces/proxy-8473/services/proxy-service-xpffg:portname2/proxy/: bar (200; 74.0846ms)
May  3 13:08:43.900: INFO: (10) /api/v1/namespaces/proxy-8473/services/proxy-service-xpffg:portname1/proxy/: foo (200; 56.3068ms)
May  3 13:08:43.920: INFO: (11) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:160/proxy/: foo (200; 16.3687ms)
May  3 13:08:43.920: INFO: (11) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:460/proxy/: tls baz (200; 16.328ms)
May  3 13:08:43.920: INFO: (11) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:1080/proxy/rewriteme">... (200; 6.7605ms)
May  3 13:08:43.920: INFO: (11) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:162/proxy/: bar (200; 16.2882ms)
May  3 13:08:43.920: INFO: (11) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:160/proxy/: foo (200; 16.5301ms)
May  3 13:08:43.934: INFO: (11) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx/proxy/rewriteme">test</a> (200; 21.2803ms)
May  3 13:08:43.935: INFO: (11) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:162/proxy/: bar (200; 21.591ms)
May  3 13:08:43.943: INFO: (11) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:1080/proxy/rewriteme">test<... (200; 30.3768ms)
May  3 13:08:43.945: INFO: (11) /api/v1/namespaces/proxy-8473/services/http:proxy-service-xpffg:portname1/proxy/: foo (200; 40.532ms)
May  3 13:08:43.951: INFO: (11) /api/v1/namespaces/proxy-8473/services/https:proxy-service-xpffg:tlsportname1/proxy/: tls baz (200; 37.9162ms)
May  3 13:08:43.951: INFO: (11) /api/v1/namespaces/proxy-8473/services/http:proxy-service-xpffg:portname2/proxy/: bar (200; 46.5841ms)
May  3 13:08:43.951: INFO: (11) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:443/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:443/proxy/tlsrewritem... (200; 37.8567ms)
May  3 13:08:43.951: INFO: (11) /api/v1/namespaces/proxy-8473/services/proxy-service-xpffg:portname1/proxy/: foo (200; 47.5384ms)
May  3 13:08:43.951: INFO: (11) /api/v1/namespaces/proxy-8473/services/proxy-service-xpffg:portname2/proxy/: bar (200; 48.0609ms)
May  3 13:08:43.953: INFO: (11) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:462/proxy/: tls qux (200; 49.9691ms)
May  3 13:08:43.953: INFO: (11) /api/v1/namespaces/proxy-8473/services/https:proxy-service-xpffg:tlsportname2/proxy/: tls qux (200; 49.7409ms)
May  3 13:08:43.969: INFO: (12) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:1080/proxy/rewriteme">... (200; 11.8197ms)
May  3 13:08:43.979: INFO: (12) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:460/proxy/: tls baz (200; 18.2423ms)
May  3 13:08:43.983: INFO: (12) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:462/proxy/: tls qux (200; 21.5113ms)
May  3 13:08:43.996: INFO: (12) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx/proxy/rewriteme">test</a> (200; 35.3326ms)
May  3 13:08:44.000: INFO: (12) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:160/proxy/: foo (200; 38.7436ms)
May  3 13:08:44.000: INFO: (12) /api/v1/namespaces/proxy-8473/services/https:proxy-service-xpffg:tlsportname1/proxy/: tls baz (200; 31.1686ms)
May  3 13:08:44.000: INFO: (12) /api/v1/namespaces/proxy-8473/services/proxy-service-xpffg:portname1/proxy/: foo (200; 38.7584ms)
May  3 13:08:44.001: INFO: (12) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:1080/proxy/rewriteme">test<... (200; 39.7346ms)
May  3 13:08:44.001: INFO: (12) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:162/proxy/: bar (200; 39.7655ms)
May  3 13:08:44.001: INFO: (12) /api/v1/namespaces/proxy-8473/services/proxy-service-xpffg:portname2/proxy/: bar (200; 39.5568ms)
May  3 13:08:44.001: INFO: (12) /api/v1/namespaces/proxy-8473/services/http:proxy-service-xpffg:portname1/proxy/: foo (200; 39.791ms)
May  3 13:08:44.002: INFO: (12) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:443/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:443/proxy/tlsrewritem... (200; 40.2549ms)
May  3 13:08:44.002: INFO: (12) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:160/proxy/: foo (200; 40.2244ms)
May  3 13:08:44.002: INFO: (12) /api/v1/namespaces/proxy-8473/services/http:proxy-service-xpffg:portname2/proxy/: bar (200; 40.5108ms)
May  3 13:08:44.002: INFO: (12) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:162/proxy/: bar (200; 40.9671ms)
May  3 13:08:44.002: INFO: (12) /api/v1/namespaces/proxy-8473/services/https:proxy-service-xpffg:tlsportname2/proxy/: tls qux (200; 41.241ms)
May  3 13:08:44.047: INFO: (13) /api/v1/namespaces/proxy-8473/services/https:proxy-service-xpffg:tlsportname1/proxy/: tls baz (200; 42.9875ms)
May  3 13:08:44.047: INFO: (13) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:462/proxy/: tls qux (200; 43.7408ms)
May  3 13:08:44.047: INFO: (13) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:162/proxy/: bar (200; 43.2868ms)
May  3 13:08:44.047: INFO: (13) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:160/proxy/: foo (200; 43.6967ms)
May  3 13:08:44.047: INFO: (13) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:1080/proxy/rewriteme">test<... (200; 42.3729ms)
May  3 13:08:44.047: INFO: (13) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:160/proxy/: foo (200; 43.3839ms)
May  3 13:08:44.047: INFO: (13) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx/proxy/rewriteme">test</a> (200; 42.782ms)
May  3 13:08:44.047: INFO: (13) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:1080/proxy/rewriteme">... (200; 41.8942ms)
May  3 13:08:44.047: INFO: (13) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:460/proxy/: tls baz (200; 43.5266ms)
May  3 13:08:44.047: INFO: (13) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:443/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:443/proxy/tlsrewritem... (200; 41.1275ms)
May  3 13:08:44.047: INFO: (13) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:162/proxy/: bar (200; 42.1895ms)
May  3 13:08:44.062: INFO: (13) /api/v1/namespaces/proxy-8473/services/proxy-service-xpffg:portname2/proxy/: bar (200; 59.7674ms)
May  3 13:08:44.063: INFO: (13) /api/v1/namespaces/proxy-8473/services/https:proxy-service-xpffg:tlsportname2/proxy/: tls qux (200; 59.5278ms)
May  3 13:08:44.069: INFO: (13) /api/v1/namespaces/proxy-8473/services/http:proxy-service-xpffg:portname1/proxy/: foo (200; 65.5006ms)
May  3 13:08:44.069: INFO: (13) /api/v1/namespaces/proxy-8473/services/proxy-service-xpffg:portname1/proxy/: foo (200; 65.7938ms)
May  3 13:08:44.069: INFO: (13) /api/v1/namespaces/proxy-8473/services/http:proxy-service-xpffg:portname2/proxy/: bar (200; 65.605ms)
May  3 13:08:44.086: INFO: (14) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:1080/proxy/rewriteme">... (200; 7.7853ms)
May  3 13:08:44.087: INFO: (14) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:162/proxy/: bar (200; 17.2894ms)
May  3 13:08:44.102: INFO: (14) /api/v1/namespaces/proxy-8473/services/https:proxy-service-xpffg:tlsportname1/proxy/: tls baz (200; 24.6139ms)
May  3 13:08:44.102: INFO: (14) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:162/proxy/: bar (200; 21.4888ms)
May  3 13:08:44.102: INFO: (14) /api/v1/namespaces/proxy-8473/services/http:proxy-service-xpffg:portname2/proxy/: bar (200; 21.881ms)
May  3 13:08:44.102: INFO: (14) /api/v1/namespaces/proxy-8473/services/http:proxy-service-xpffg:portname1/proxy/: foo (200; 22.1483ms)
May  3 13:08:44.102: INFO: (14) /api/v1/namespaces/proxy-8473/services/proxy-service-xpffg:portname1/proxy/: foo (200; 32.7426ms)
May  3 13:08:44.102: INFO: (14) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:443/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:443/proxy/tlsrewritem... (200; 22.6747ms)
May  3 13:08:44.102: INFO: (14) /api/v1/namespaces/proxy-8473/services/https:proxy-service-xpffg:tlsportname2/proxy/: tls qux (200; 21.486ms)
May  3 13:08:44.112: INFO: (14) /api/v1/namespaces/proxy-8473/services/proxy-service-xpffg:portname2/proxy/: bar (200; 41.83ms)
May  3 13:08:44.116: INFO: (14) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:462/proxy/: tls qux (200; 35.9239ms)
May  3 13:08:44.116: INFO: (14) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx/proxy/rewriteme">test</a> (200; 35.7876ms)
May  3 13:08:44.116: INFO: (14) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:160/proxy/: foo (200; 35.461ms)
May  3 13:08:44.116: INFO: (14) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:160/proxy/: foo (200; 35.5469ms)
May  3 13:08:44.118: INFO: (14) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:1080/proxy/rewriteme">test<... (200; 38.5439ms)
May  3 13:08:44.118: INFO: (14) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:460/proxy/: tls baz (200; 38.4801ms)
May  3 13:08:44.151: INFO: (15) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:162/proxy/: bar (200; 32.6099ms)
May  3 13:08:44.160: INFO: (15) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:1080/proxy/rewriteme">test<... (200; 39.9254ms)
May  3 13:08:44.161: INFO: (15) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:162/proxy/: bar (200; 40.878ms)
May  3 13:08:44.162: INFO: (15) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:460/proxy/: tls baz (200; 34.5482ms)
May  3 13:08:44.162: INFO: (15) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:443/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:443/proxy/tlsrewritem... (200; 42.747ms)
May  3 13:08:44.162: INFO: (15) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx/proxy/rewriteme">test</a> (200; 42.4674ms)
May  3 13:08:44.163: INFO: (15) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:160/proxy/: foo (200; 42.5333ms)
May  3 13:08:44.163: INFO: (15) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:462/proxy/: tls qux (200; 42.6498ms)
May  3 13:08:44.167: INFO: (15) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:160/proxy/: foo (200; 38.7003ms)
May  3 13:08:44.178: INFO: (15) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:1080/proxy/rewriteme">... (200; 58.471ms)
May  3 13:08:44.178: INFO: (15) /api/v1/namespaces/proxy-8473/services/http:proxy-service-xpffg:portname2/proxy/: bar (200; 58.9232ms)
May  3 13:08:44.182: INFO: (15) /api/v1/namespaces/proxy-8473/services/https:proxy-service-xpffg:tlsportname1/proxy/: tls baz (200; 62.0412ms)
May  3 13:08:44.184: INFO: (15) /api/v1/namespaces/proxy-8473/services/https:proxy-service-xpffg:tlsportname2/proxy/: tls qux (200; 58.3351ms)
May  3 13:08:44.184: INFO: (15) /api/v1/namespaces/proxy-8473/services/http:proxy-service-xpffg:portname1/proxy/: foo (200; 63.9811ms)
May  3 13:08:44.184: INFO: (15) /api/v1/namespaces/proxy-8473/services/proxy-service-xpffg:portname2/proxy/: bar (200; 63.9719ms)
May  3 13:08:44.184: INFO: (15) /api/v1/namespaces/proxy-8473/services/proxy-service-xpffg:portname1/proxy/: foo (200; 55.8855ms)
May  3 13:08:44.218: INFO: (16) /api/v1/namespaces/proxy-8473/services/http:proxy-service-xpffg:portname1/proxy/: foo (200; 34.2487ms)
May  3 13:08:44.225: INFO: (16) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:443/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:443/proxy/tlsrewritem... (200; 24.321ms)
May  3 13:08:44.225: INFO: (16) /api/v1/namespaces/proxy-8473/services/proxy-service-xpffg:portname2/proxy/: bar (200; 30.5847ms)
May  3 13:08:44.225: INFO: (16) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:1080/proxy/rewriteme">... (200; 24.4189ms)
May  3 13:08:44.225: INFO: (16) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:160/proxy/: foo (200; 30.6705ms)
May  3 13:08:44.229: INFO: (16) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:1080/proxy/rewriteme">test<... (200; 27.7904ms)
May  3 13:08:44.229: INFO: (16) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:162/proxy/: bar (200; 27.8419ms)
May  3 13:08:44.233: INFO: (16) /api/v1/namespaces/proxy-8473/services/https:proxy-service-xpffg:tlsportname2/proxy/: tls qux (200; 47.8027ms)
May  3 13:08:44.234: INFO: (16) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:462/proxy/: tls qux (200; 49.7224ms)
May  3 13:08:44.237: INFO: (16) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx/proxy/rewriteme">test</a> (200; 35.4473ms)
May  3 13:08:44.247: INFO: (16) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:162/proxy/: bar (200; 45.9285ms)
May  3 13:08:44.247: INFO: (16) /api/v1/namespaces/proxy-8473/services/http:proxy-service-xpffg:portname2/proxy/: bar (200; 46.336ms)
May  3 13:08:44.247: INFO: (16) /api/v1/namespaces/proxy-8473/services/proxy-service-xpffg:portname1/proxy/: foo (200; 46.0989ms)
May  3 13:08:44.252: INFO: (16) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:160/proxy/: foo (200; 51.1749ms)
May  3 13:08:44.253: INFO: (16) /api/v1/namespaces/proxy-8473/services/https:proxy-service-xpffg:tlsportname1/proxy/: tls baz (200; 52.3943ms)
May  3 13:08:44.259: INFO: (16) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:460/proxy/: tls baz (200; 58.5851ms)
May  3 13:08:44.282: INFO: (17) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:160/proxy/: foo (200; 21.1254ms)
May  3 13:08:44.282: INFO: (17) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:460/proxy/: tls baz (200; 21.2654ms)
May  3 13:08:44.282: INFO: (17) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:160/proxy/: foo (200; 21.3868ms)
May  3 13:08:44.287: INFO: (17) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:462/proxy/: tls qux (200; 24.9859ms)
May  3 13:08:44.292: INFO: (17) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:443/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:443/proxy/tlsrewritem... (200; 30.8035ms)
May  3 13:08:44.292: INFO: (17) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:1080/proxy/rewriteme">... (200; 30.9444ms)
May  3 13:08:44.292: INFO: (17) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:1080/proxy/rewriteme">test<... (200; 30.626ms)
May  3 13:08:44.292: INFO: (17) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx/proxy/rewriteme">test</a> (200; 30.7811ms)
May  3 13:08:44.299: INFO: (17) /api/v1/namespaces/proxy-8473/services/http:proxy-service-xpffg:portname2/proxy/: bar (200; 39.2384ms)
May  3 13:08:44.299: INFO: (17) /api/v1/namespaces/proxy-8473/services/http:proxy-service-xpffg:portname1/proxy/: foo (200; 37.4835ms)
May  3 13:08:44.299: INFO: (17) /api/v1/namespaces/proxy-8473/services/https:proxy-service-xpffg:tlsportname1/proxy/: tls baz (200; 37.6046ms)
May  3 13:08:44.299: INFO: (17) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:162/proxy/: bar (200; 37.1183ms)
May  3 13:08:44.299: INFO: (17) /api/v1/namespaces/proxy-8473/services/proxy-service-xpffg:portname2/proxy/: bar (200; 37.6548ms)
May  3 13:08:44.299: INFO: (17) /api/v1/namespaces/proxy-8473/services/proxy-service-xpffg:portname1/proxy/: foo (200; 37.7101ms)
May  3 13:08:44.299: INFO: (17) /api/v1/namespaces/proxy-8473/services/https:proxy-service-xpffg:tlsportname2/proxy/: tls qux (200; 37.8479ms)
May  3 13:08:44.299: INFO: (17) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:162/proxy/: bar (200; 37.7751ms)
May  3 13:08:44.320: INFO: (18) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:162/proxy/: bar (200; 21.2685ms)
May  3 13:08:44.320: INFO: (18) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:460/proxy/: tls baz (200; 21.0199ms)
May  3 13:08:44.321: INFO: (18) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:160/proxy/: foo (200; 21.7069ms)
May  3 13:08:44.326: INFO: (18) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:1080/proxy/rewriteme">... (200; 25.9121ms)
May  3 13:08:44.326: INFO: (18) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:162/proxy/: bar (200; 26.1272ms)
May  3 13:08:44.326: INFO: (18) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:443/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:443/proxy/tlsrewritem... (200; 26.5268ms)
May  3 13:08:44.326: INFO: (18) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:160/proxy/: foo (200; 26.2475ms)
May  3 13:08:44.326: INFO: (18) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx/proxy/rewriteme">test</a> (200; 20.5292ms)
May  3 13:08:44.326: INFO: (18) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:462/proxy/: tls qux (200; 20.6841ms)
May  3 13:08:44.326: INFO: (18) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:1080/proxy/rewriteme">test<... (200; 20.4512ms)
May  3 13:08:44.337: INFO: (18) /api/v1/namespaces/proxy-8473/services/proxy-service-xpffg:portname1/proxy/: foo (200; 37.3944ms)
May  3 13:08:44.338: INFO: (18) /api/v1/namespaces/proxy-8473/services/https:proxy-service-xpffg:tlsportname1/proxy/: tls baz (200; 38.1252ms)
May  3 13:08:44.339: INFO: (18) /api/v1/namespaces/proxy-8473/services/proxy-service-xpffg:portname2/proxy/: bar (200; 39.2586ms)
May  3 13:08:44.339: INFO: (18) /api/v1/namespaces/proxy-8473/services/https:proxy-service-xpffg:tlsportname2/proxy/: tls qux (200; 39.7324ms)
May  3 13:08:44.339: INFO: (18) /api/v1/namespaces/proxy-8473/services/http:proxy-service-xpffg:portname1/proxy/: foo (200; 39.5483ms)
May  3 13:08:44.345: INFO: (18) /api/v1/namespaces/proxy-8473/services/http:proxy-service-xpffg:portname2/proxy/: bar (200; 45.4251ms)
May  3 13:08:44.364: INFO: (19) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx/proxy/rewriteme">test</a> (200; 12.3113ms)
May  3 13:08:44.368: INFO: (19) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:462/proxy/: tls qux (200; 15.9372ms)
May  3 13:08:44.374: INFO: (19) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:160/proxy/: foo (200; 21.8596ms)
May  3 13:08:44.381: INFO: (19) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:460/proxy/: tls baz (200; 29.0852ms)
May  3 13:08:44.381: INFO: (19) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:162/proxy/: bar (200; 29.351ms)
May  3 13:08:44.381: INFO: (19) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:160/proxy/: foo (200; 29.4871ms)
May  3 13:08:44.381: INFO: (19) /api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/proxy-service-xpffg-jcqtx:1080/proxy/rewriteme">test<... (200; 35.2428ms)
May  3 13:08:44.381: INFO: (19) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:162/proxy/: bar (200; 35.9728ms)
May  3 13:08:44.381: INFO: (19) /api/v1/namespaces/proxy-8473/services/proxy-service-xpffg:portname2/proxy/: bar (200; 35.2004ms)
May  3 13:08:44.383: INFO: (19) /api/v1/namespaces/proxy-8473/services/http:proxy-service-xpffg:portname1/proxy/: foo (200; 37.3503ms)
May  3 13:08:44.383: INFO: (19) /api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/http:proxy-service-xpffg-jcqtx:1080/proxy/rewriteme">... (200; 37.2094ms)
May  3 13:08:44.383: INFO: (19) /api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:443/proxy/: <a href="/api/v1/namespaces/proxy-8473/pods/https:proxy-service-xpffg-jcqtx:443/proxy/tlsrewritem... (200; 32.2678ms)
May  3 13:08:44.384: INFO: (19) /api/v1/namespaces/proxy-8473/services/https:proxy-service-xpffg:tlsportname1/proxy/: tls baz (200; 37.3533ms)
May  3 13:08:44.387: INFO: (19) /api/v1/namespaces/proxy-8473/services/http:proxy-service-xpffg:portname2/proxy/: bar (200; 35.8404ms)
May  3 13:08:44.387: INFO: (19) /api/v1/namespaces/proxy-8473/services/proxy-service-xpffg:portname1/proxy/: foo (200; 35.447ms)
May  3 13:08:44.387: INFO: (19) /api/v1/namespaces/proxy-8473/services/https:proxy-service-xpffg:tlsportname2/proxy/: tls qux (200; 35.5103ms)
STEP: deleting ReplicationController proxy-service-xpffg in namespace proxy-8473, will wait for the garbage collector to delete the pods
May  3 13:08:44.456: INFO: Deleting ReplicationController proxy-service-xpffg took: 4.8027ms
May  3 13:08:44.862: INFO: Terminating ReplicationController proxy-service-xpffg pods took: 405.9424ms
[AfterEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:08:46.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8473" for this suite.
May  3 13:08:52.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:08:52.996: INFO: namespace proxy-8473 deletion completed in 6.1253438s

• [SLOW TEST:19.923 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:08:52.996: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
May  3 13:08:53.041: INFO: PodSpec: initContainers in spec.initContainers
May  3 13:09:40.716: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-999761ee-6da4-11e9-a622-a62f37ba3446", GenerateName:"", Namespace:"init-container-4447", SelfLink:"/api/v1/namespaces/init-container-4447/pods/pod-init-999761ee-6da4-11e9-a622-a62f37ba3446", UID:"9999196e-6da4-11e9-9efa-00155da4710f", ResourceVersion:"19776", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63692485733, loc:(*time.Location)(0x8a060e0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"41004000"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-fbwjc", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0024305c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-fbwjc", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-fbwjc", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-fbwjc", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00223e248), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"docker-desktop", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0023ae900), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00223e2d0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00223e2f0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc00223e2f8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00223e2fc)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692485733, loc:(*time.Location)(0x8a060e0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692485733, loc:(*time.Location)(0x8a060e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692485733, loc:(*time.Location)(0x8a060e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692485733, loc:(*time.Location)(0x8a060e0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.65.3", PodIP:"10.1.0.233", StartTime:(*v1.Time)(0xc0025de060), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0026b9ce0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0026b9d50)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://4bcd129a2041872e57c40c2bd0476df459bbee45d604eab9ad0ff90cf7e5a1e5"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0025de0a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0025de080), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:09:40.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4447" for this suite.
May  3 13:10:02.774: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:10:02.868: INFO: namespace init-container-4447 deletion completed in 22.1109787s

• [SLOW TEST:69.872 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:10:02.869: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May  3 13:10:02.930: INFO: Pod name cleanup-pod: Found 0 pods out of 1
May  3 13:10:07.934: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May  3 13:10:07.934: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May  3 13:10:10.037: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-2552,SelfLink:/apis/apps/v1/namespaces/deployment-2552/deployments/test-cleanup-deployment,UID:c63e1402-6da4-11e9-9efa-00155da4710f,ResourceVersion:19877,Generation:1,CreationTimestamp:2019-05-03 13:10:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-05-03 13:10:08 +0000 UTC 2019-05-03 13:10:08 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-05-03 13:10:09 +0000 UTC 2019-05-03 13:10:08 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-55cbfbc8f5" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

May  3 13:10:10.056: INFO: New ReplicaSet "test-cleanup-deployment-55cbfbc8f5" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55cbfbc8f5,GenerateName:,Namespace:deployment-2552,SelfLink:/apis/apps/v1/namespaces/deployment-2552/replicasets/test-cleanup-deployment-55cbfbc8f5,UID:c644b562-6da4-11e9-9efa-00155da4710f,ResourceVersion:19866,Generation:1,CreationTimestamp:2019-05-03 13:10:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment c63e1402-6da4-11e9-9efa-00155da4710f 0xc001812117 0xc001812118}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
May  3 13:10:10.068: INFO: Pod "test-cleanup-deployment-55cbfbc8f5-ssjc9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55cbfbc8f5-ssjc9,GenerateName:test-cleanup-deployment-55cbfbc8f5-,Namespace:deployment-2552,SelfLink:/api/v1/namespaces/deployment-2552/pods/test-cleanup-deployment-55cbfbc8f5-ssjc9,UID:c6453d27-6da4-11e9-9efa-00155da4710f,ResourceVersion:19865,Generation:0,CreationTimestamp:2019-05-03 13:10:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-55cbfbc8f5 c644b562-6da4-11e9-9efa-00155da4710f 0xc0018126b7 0xc0018126b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pmpfn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pmpfn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-pmpfn true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001812730} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001812750}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:10:08 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:10:09 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:10:09 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:10:08 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.0.235,StartTime:2019-05-03 13:10:08 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-05-03 13:10:09 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://92115cc200b22b02692a0254f59e37fb670552859bda3536c413e86339cb3fc6}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:10:10.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2552" for this suite.
May  3 13:10:16.109: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:10:16.272: INFO: namespace deployment-2552 deletion completed in 6.1859429s

• [SLOW TEST:13.403 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:10:16.276: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May  3 13:10:16.316: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
May  3 13:10:16.336: INFO: Pod name sample-pod: Found 0 pods out of 1
May  3 13:10:21.351: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May  3 13:10:21.351: INFO: Creating deployment "test-rolling-update-deployment"
May  3 13:10:21.373: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
May  3 13:10:21.386: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
May  3 13:10:23.411: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
May  3 13:10:23.425: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692485821, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692485821, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692485821, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692485821, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-67599b4d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  3 13:10:25.435: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May  3 13:10:25.490: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-2283,SelfLink:/apis/apps/v1/namespaces/deployment-2283/deployments/test-rolling-update-deployment,UID:ce3c0b68-6da4-11e9-9efa-00155da4710f,ResourceVersion:19964,Generation:1,CreationTimestamp:2019-05-03 13:10:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-05-03 13:10:21 +0000 UTC 2019-05-03 13:10:21 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-05-03 13:10:23 +0000 UTC 2019-05-03 13:10:21 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-67599b4d9" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

May  3 13:10:25.497: INFO: New ReplicaSet "test-rolling-update-deployment-67599b4d9" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-67599b4d9,GenerateName:,Namespace:deployment-2283,SelfLink:/apis/apps/v1/namespaces/deployment-2283/replicasets/test-rolling-update-deployment-67599b4d9,UID:ce3f8cf1-6da4-11e9-9efa-00155da4710f,ResourceVersion:19954,Generation:1,CreationTimestamp:2019-05-03 13:10:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment ce3c0b68-6da4-11e9-9efa-00155da4710f 0xc003d86350 0xc003d86351}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
May  3 13:10:25.497: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
May  3 13:10:25.497: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-2283,SelfLink:/apis/apps/v1/namespaces/deployment-2283/replicasets/test-rolling-update-controller,UID:cb3b7894-6da4-11e9-9efa-00155da4710f,ResourceVersion:19963,Generation:2,CreationTimestamp:2019-05-03 13:10:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment ce3c0b68-6da4-11e9-9efa-00155da4710f 0xc003d86277 0xc003d86278}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May  3 13:10:25.505: INFO: Pod "test-rolling-update-deployment-67599b4d9-pndpk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-67599b4d9-pndpk,GenerateName:test-rolling-update-deployment-67599b4d9-,Namespace:deployment-2283,SelfLink:/api/v1/namespaces/deployment-2283/pods/test-rolling-update-deployment-67599b4d9-pndpk,UID:ce402f38-6da4-11e9-9efa-00155da4710f,ResourceVersion:19953,Generation:0,CreationTimestamp:2019-05-03 13:10:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-67599b4d9 ce3f8cf1-6da4-11e9-9efa-00155da4710f 0xc003d86cf0 0xc003d86cf1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6cdzf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6cdzf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-6cdzf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003d86d60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003d86d80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:10:21 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:10:23 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:10:23 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:10:21 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.0.237,StartTime:2019-05-03 13:10:21 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-05-03 13:10:22 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://b96887894fbed76168257461b510afe5c35ae9465f9aa2ea5191fcdc772797a0}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:10:25.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2283" for this suite.
May  3 13:10:31.542: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:10:31.638: INFO: namespace deployment-2283 deletion completed in 6.1195905s

• [SLOW TEST:15.362 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:10:31.638: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
May  3 13:10:31.701: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:10:35.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9880" for this suite.
May  3 13:10:41.375: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:10:41.502: INFO: namespace init-container-9880 deletion completed in 6.1460424s

• [SLOW TEST:9.864 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:10:41.503: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
May  3 13:10:41.557: INFO: Waiting up to 5m0s for pod "pod-da4367af-6da4-11e9-a622-a62f37ba3446" in namespace "emptydir-3076" to be "success or failure"
May  3 13:10:41.577: INFO: Pod "pod-da4367af-6da4-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 20.5328ms
May  3 13:10:43.606: INFO: Pod "pod-da4367af-6da4-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0494203s
STEP: Saw pod success
May  3 13:10:43.621: INFO: Pod "pod-da4367af-6da4-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 13:10:43.627: INFO: Trying to get logs from node docker-desktop pod pod-da4367af-6da4-11e9-a622-a62f37ba3446 container test-container: <nil>
STEP: delete the pod
May  3 13:10:43.678: INFO: Waiting for pod pod-da4367af-6da4-11e9-a622-a62f37ba3446 to disappear
May  3 13:10:43.687: INFO: Pod pod-da4367af-6da4-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:10:43.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3076" for this suite.
May  3 13:10:49.740: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:10:49.843: INFO: namespace emptydir-3076 deletion completed in 6.1457612s

• [SLOW TEST:8.340 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:10:49.847: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May  3 13:10:49.909: INFO: Waiting up to 5m0s for pod "downwardapi-volume-df3dc803-6da4-11e9-a622-a62f37ba3446" in namespace "projected-9808" to be "success or failure"
May  3 13:10:49.917: INFO: Pod "downwardapi-volume-df3dc803-6da4-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 7.484ms
May  3 13:10:51.974: INFO: Pod "downwardapi-volume-df3dc803-6da4-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0650194s
STEP: Saw pod success
May  3 13:10:51.974: INFO: Pod "downwardapi-volume-df3dc803-6da4-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 13:10:51.977: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-df3dc803-6da4-11e9-a622-a62f37ba3446 container client-container: <nil>
STEP: delete the pod
May  3 13:10:52.010: INFO: Waiting for pod downwardapi-volume-df3dc803-6da4-11e9-a622-a62f37ba3446 to disappear
May  3 13:10:52.013: INFO: Pod downwardapi-volume-df3dc803-6da4-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:10:52.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9808" for this suite.
May  3 13:10:58.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:10:58.128: INFO: namespace projected-9808 deletion completed in 6.1089633s

• [SLOW TEST:8.281 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:10:58.130: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-e42da355-6da4-11e9-a622-a62f37ba3446
STEP: Creating a pod to test consume configMaps
May  3 13:10:58.237: INFO: Waiting up to 5m0s for pod "pod-configmaps-e4300a9c-6da4-11e9-a622-a62f37ba3446" in namespace "configmap-8948" to be "success or failure"
May  3 13:10:58.251: INFO: Pod "pod-configmaps-e4300a9c-6da4-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 11.1578ms
May  3 13:11:00.253: INFO: Pod "pod-configmaps-e4300a9c-6da4-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0137583s
STEP: Saw pod success
May  3 13:11:00.253: INFO: Pod "pod-configmaps-e4300a9c-6da4-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 13:11:00.256: INFO: Trying to get logs from node docker-desktop pod pod-configmaps-e4300a9c-6da4-11e9-a622-a62f37ba3446 container configmap-volume-test: <nil>
STEP: delete the pod
May  3 13:11:00.287: INFO: Waiting for pod pod-configmaps-e4300a9c-6da4-11e9-a622-a62f37ba3446 to disappear
May  3 13:11:00.292: INFO: Pod pod-configmaps-e4300a9c-6da4-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:11:00.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8948" for this suite.
May  3 13:11:06.312: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:11:06.406: INFO: namespace configmap-8948 deletion completed in 6.1089279s

• [SLOW TEST:8.276 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:11:06.406: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-e91bb2ab-6da4-11e9-a622-a62f37ba3446
STEP: Creating a pod to test consume configMaps
May  3 13:11:06.473: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e91d7cf6-6da4-11e9-a622-a62f37ba3446" in namespace "projected-6166" to be "success or failure"
May  3 13:11:06.487: INFO: Pod "pod-projected-configmaps-e91d7cf6-6da4-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 13.6306ms
May  3 13:11:08.494: INFO: Pod "pod-projected-configmaps-e91d7cf6-6da4-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0203609s
STEP: Saw pod success
May  3 13:11:08.494: INFO: Pod "pod-projected-configmaps-e91d7cf6-6da4-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 13:11:08.504: INFO: Trying to get logs from node docker-desktop pod pod-projected-configmaps-e91d7cf6-6da4-11e9-a622-a62f37ba3446 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May  3 13:11:08.556: INFO: Waiting for pod pod-projected-configmaps-e91d7cf6-6da4-11e9-a622-a62f37ba3446 to disappear
May  3 13:11:08.568: INFO: Pod pod-projected-configmaps-e91d7cf6-6da4-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:11:08.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6166" for this suite.
May  3 13:11:14.590: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:11:14.682: INFO: namespace projected-6166 deletion completed in 6.1091134s

• [SLOW TEST:8.276 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:11:14.682: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-ee0cd2ad-6da4-11e9-a622-a62f37ba3446
STEP: Creating a pod to test consume configMaps
May  3 13:11:14.755: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ee0db5a7-6da4-11e9-a622-a62f37ba3446" in namespace "projected-8903" to be "success or failure"
May  3 13:11:14.773: INFO: Pod "pod-projected-configmaps-ee0db5a7-6da4-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 17.9721ms
May  3 13:11:16.779: INFO: Pod "pod-projected-configmaps-ee0db5a7-6da4-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0241004s
STEP: Saw pod success
May  3 13:11:16.779: INFO: Pod "pod-projected-configmaps-ee0db5a7-6da4-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 13:11:16.784: INFO: Trying to get logs from node docker-desktop pod pod-projected-configmaps-ee0db5a7-6da4-11e9-a622-a62f37ba3446 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May  3 13:11:16.809: INFO: Waiting for pod pod-projected-configmaps-ee0db5a7-6da4-11e9-a622-a62f37ba3446 to disappear
May  3 13:11:16.815: INFO: Pod pod-projected-configmaps-ee0db5a7-6da4-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:11:16.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8903" for this suite.
May  3 13:11:22.865: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:11:22.957: INFO: namespace projected-8903 deletion completed in 6.128372s

• [SLOW TEST:8.275 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:11:22.957: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
May  3 13:11:23.012: INFO: namespace kubectl-8623
May  3 13:11:23.017: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 create -f - --namespace=kubectl-8623'
May  3 13:11:23.281: INFO: stderr: ""
May  3 13:11:23.281: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
May  3 13:11:24.285: INFO: Selector matched 1 pods for map[app:redis]
May  3 13:11:24.285: INFO: Found 0 / 1
May  3 13:11:25.287: INFO: Selector matched 1 pods for map[app:redis]
May  3 13:11:25.287: INFO: Found 1 / 1
May  3 13:11:25.287: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May  3 13:11:25.302: INFO: Selector matched 1 pods for map[app:redis]
May  3 13:11:25.302: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May  3 13:11:25.302: INFO: wait on redis-master startup in kubectl-8623 
May  3 13:11:25.302: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 logs redis-master-xkrht redis-master --namespace=kubectl-8623'
May  3 13:11:25.393: INFO: stderr: ""
May  3 13:11:25.394: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 03 May 13:11:24.863 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 03 May 13:11:24.865 # Server started, Redis version 3.2.12\n1:M 03 May 13:11:24.865 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 03 May 13:11:24.866 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
May  3 13:11:25.394: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-8623'
May  3 13:11:25.494: INFO: stderr: ""
May  3 13:11:25.494: INFO: stdout: "service/rm2 exposed\n"
May  3 13:11:25.503: INFO: Service rm2 in namespace kubectl-8623 found.
STEP: exposing service
May  3 13:11:27.515: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-8623'
May  3 13:11:27.629: INFO: stderr: ""
May  3 13:11:27.629: INFO: stdout: "service/rm3 exposed\n"
May  3 13:11:27.634: INFO: Service rm3 in namespace kubectl-8623 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:11:29.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8623" for this suite.
May  3 13:11:51.685: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:11:51.797: INFO: namespace kubectl-8623 deletion completed in 22.1352788s

• [SLOW TEST:28.840 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create services for rc  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:11:51.797: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
May  3 13:11:51.867: INFO: Waiting up to 5m0s for pod "pod-042a8e4b-6da5-11e9-a622-a62f37ba3446" in namespace "emptydir-2548" to be "success or failure"
May  3 13:11:51.892: INFO: Pod "pod-042a8e4b-6da5-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 24.5706ms
May  3 13:11:53.895: INFO: Pod "pod-042a8e4b-6da5-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0270442s
STEP: Saw pod success
May  3 13:11:53.895: INFO: Pod "pod-042a8e4b-6da5-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 13:11:53.898: INFO: Trying to get logs from node docker-desktop pod pod-042a8e4b-6da5-11e9-a622-a62f37ba3446 container test-container: <nil>
STEP: delete the pod
May  3 13:11:53.931: INFO: Waiting for pod pod-042a8e4b-6da5-11e9-a622-a62f37ba3446 to disappear
May  3 13:11:53.946: INFO: Pod pod-042a8e4b-6da5-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:11:53.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2548" for this suite.
May  3 13:12:00.024: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:12:00.122: INFO: namespace emptydir-2548 deletion completed in 6.1599657s

• [SLOW TEST:8.325 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:12:00.135: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-downwardapi-56ln
STEP: Creating a pod to test atomic-volume-subpath
May  3 13:12:00.244: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-56ln" in namespace "subpath-1437" to be "success or failure"
May  3 13:12:00.256: INFO: Pod "pod-subpath-test-downwardapi-56ln": Phase="Pending", Reason="", readiness=false. Elapsed: 12.5672ms
May  3 13:12:02.262: INFO: Pod "pod-subpath-test-downwardapi-56ln": Phase="Running", Reason="", readiness=true. Elapsed: 2.0177523s
May  3 13:12:04.264: INFO: Pod "pod-subpath-test-downwardapi-56ln": Phase="Running", Reason="", readiness=true. Elapsed: 4.019808s
May  3 13:12:06.269: INFO: Pod "pod-subpath-test-downwardapi-56ln": Phase="Running", Reason="", readiness=true. Elapsed: 6.0254015s
May  3 13:12:08.277: INFO: Pod "pod-subpath-test-downwardapi-56ln": Phase="Running", Reason="", readiness=true. Elapsed: 8.0327298s
May  3 13:12:10.279: INFO: Pod "pod-subpath-test-downwardapi-56ln": Phase="Running", Reason="", readiness=true. Elapsed: 10.035578s
May  3 13:12:12.283: INFO: Pod "pod-subpath-test-downwardapi-56ln": Phase="Running", Reason="", readiness=true. Elapsed: 12.0389189s
May  3 13:12:14.285: INFO: Pod "pod-subpath-test-downwardapi-56ln": Phase="Running", Reason="", readiness=true. Elapsed: 14.0414619s
May  3 13:12:16.288: INFO: Pod "pod-subpath-test-downwardapi-56ln": Phase="Running", Reason="", readiness=true. Elapsed: 16.0439459s
May  3 13:12:18.310: INFO: Pod "pod-subpath-test-downwardapi-56ln": Phase="Running", Reason="", readiness=true. Elapsed: 18.0664786s
May  3 13:12:20.313: INFO: Pod "pod-subpath-test-downwardapi-56ln": Phase="Running", Reason="", readiness=true. Elapsed: 20.0693895s
May  3 13:12:22.317: INFO: Pod "pod-subpath-test-downwardapi-56ln": Phase="Running", Reason="", readiness=true. Elapsed: 22.0727309s
May  3 13:12:24.320: INFO: Pod "pod-subpath-test-downwardapi-56ln": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.0759927s
STEP: Saw pod success
May  3 13:12:24.320: INFO: Pod "pod-subpath-test-downwardapi-56ln" satisfied condition "success or failure"
May  3 13:12:24.330: INFO: Trying to get logs from node docker-desktop pod pod-subpath-test-downwardapi-56ln container test-container-subpath-downwardapi-56ln: <nil>
STEP: delete the pod
May  3 13:12:24.377: INFO: Waiting for pod pod-subpath-test-downwardapi-56ln to disappear
May  3 13:12:24.382: INFO: Pod pod-subpath-test-downwardapi-56ln no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-56ln
May  3 13:12:24.382: INFO: Deleting pod "pod-subpath-test-downwardapi-56ln" in namespace "subpath-1437"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:12:24.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1437" for this suite.
May  3 13:12:30.419: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:12:30.610: INFO: namespace subpath-1437 deletion completed in 6.2118307s

• [SLOW TEST:30.476 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:12:30.618: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-1b569a79-6da5-11e9-a622-a62f37ba3446
STEP: Creating a pod to test consume configMaps
May  3 13:12:30.737: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1b577bad-6da5-11e9-a622-a62f37ba3446" in namespace "projected-3416" to be "success or failure"
May  3 13:12:30.754: INFO: Pod "pod-projected-configmaps-1b577bad-6da5-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 17.1393ms
May  3 13:12:32.779: INFO: Pod "pod-projected-configmaps-1b577bad-6da5-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0416898s
STEP: Saw pod success
May  3 13:12:32.779: INFO: Pod "pod-projected-configmaps-1b577bad-6da5-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 13:12:32.785: INFO: Trying to get logs from node docker-desktop pod pod-projected-configmaps-1b577bad-6da5-11e9-a622-a62f37ba3446 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May  3 13:12:32.822: INFO: Waiting for pod pod-projected-configmaps-1b577bad-6da5-11e9-a622-a62f37ba3446 to disappear
May  3 13:12:32.828: INFO: Pod pod-projected-configmaps-1b577bad-6da5-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:12:32.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3416" for this suite.
May  3 13:12:38.856: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:12:38.948: INFO: namespace projected-3416 deletion completed in 6.1101284s

• [SLOW TEST:8.330 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:12:38.948: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
May  3 13:12:39.002: INFO: Waiting up to 5m0s for pod "pod-20452949-6da5-11e9-a622-a62f37ba3446" in namespace "emptydir-8432" to be "success or failure"
May  3 13:12:39.016: INFO: Pod "pod-20452949-6da5-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 13.8393ms
May  3 13:12:41.019: INFO: Pod "pod-20452949-6da5-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0166115s
STEP: Saw pod success
May  3 13:12:41.019: INFO: Pod "pod-20452949-6da5-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 13:12:41.024: INFO: Trying to get logs from node docker-desktop pod pod-20452949-6da5-11e9-a622-a62f37ba3446 container test-container: <nil>
STEP: delete the pod
May  3 13:12:41.049: INFO: Waiting for pod pod-20452949-6da5-11e9-a622-a62f37ba3446 to disappear
May  3 13:12:41.063: INFO: Pod pod-20452949-6da5-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:12:41.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8432" for this suite.
May  3 13:12:47.108: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:12:47.225: INFO: namespace emptydir-8432 deletion completed in 6.1461406s

• [SLOW TEST:8.277 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:12:47.225: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
May  3 13:12:47.314: INFO: Waiting up to 5m0s for pod "pod-25335645-6da5-11e9-a622-a62f37ba3446" in namespace "emptydir-966" to be "success or failure"
May  3 13:12:47.328: INFO: Pod "pod-25335645-6da5-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 13.5673ms
May  3 13:12:49.352: INFO: Pod "pod-25335645-6da5-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0370403s
STEP: Saw pod success
May  3 13:12:49.352: INFO: Pod "pod-25335645-6da5-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 13:12:49.366: INFO: Trying to get logs from node docker-desktop pod pod-25335645-6da5-11e9-a622-a62f37ba3446 container test-container: <nil>
STEP: delete the pod
May  3 13:12:49.407: INFO: Waiting for pod pod-25335645-6da5-11e9-a622-a62f37ba3446 to disappear
May  3 13:12:49.421: INFO: Pod pod-25335645-6da5-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:12:49.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-966" for this suite.
May  3 13:12:55.442: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:12:55.535: INFO: namespace emptydir-966 deletion completed in 6.1092674s

• [SLOW TEST:8.310 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:12:55.535: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-secret-92kk
STEP: Creating a pod to test atomic-volume-subpath
May  3 13:12:55.608: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-92kk" in namespace "subpath-9955" to be "success or failure"
May  3 13:12:55.618: INFO: Pod "pod-subpath-test-secret-92kk": Phase="Pending", Reason="", readiness=false. Elapsed: 9.6064ms
May  3 13:12:57.621: INFO: Pod "pod-subpath-test-secret-92kk": Phase="Running", Reason="", readiness=true. Elapsed: 2.0126268s
May  3 13:12:59.624: INFO: Pod "pod-subpath-test-secret-92kk": Phase="Running", Reason="", readiness=true. Elapsed: 4.0152781s
May  3 13:13:01.627: INFO: Pod "pod-subpath-test-secret-92kk": Phase="Running", Reason="", readiness=true. Elapsed: 6.0185653s
May  3 13:13:03.630: INFO: Pod "pod-subpath-test-secret-92kk": Phase="Running", Reason="", readiness=true. Elapsed: 8.021848s
May  3 13:13:05.635: INFO: Pod "pod-subpath-test-secret-92kk": Phase="Running", Reason="", readiness=true. Elapsed: 10.0269599s
May  3 13:13:07.638: INFO: Pod "pod-subpath-test-secret-92kk": Phase="Running", Reason="", readiness=true. Elapsed: 12.0293192s
May  3 13:13:09.640: INFO: Pod "pod-subpath-test-secret-92kk": Phase="Running", Reason="", readiness=true. Elapsed: 14.0317635s
May  3 13:13:11.648: INFO: Pod "pod-subpath-test-secret-92kk": Phase="Running", Reason="", readiness=true. Elapsed: 16.0390802s
May  3 13:13:13.655: INFO: Pod "pod-subpath-test-secret-92kk": Phase="Running", Reason="", readiness=true. Elapsed: 18.0461449s
May  3 13:13:15.659: INFO: Pod "pod-subpath-test-secret-92kk": Phase="Running", Reason="", readiness=true. Elapsed: 20.050363s
May  3 13:13:17.665: INFO: Pod "pod-subpath-test-secret-92kk": Phase="Running", Reason="", readiness=true. Elapsed: 22.0561773s
May  3 13:13:19.672: INFO: Pod "pod-subpath-test-secret-92kk": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.0634718s
STEP: Saw pod success
May  3 13:13:19.672: INFO: Pod "pod-subpath-test-secret-92kk" satisfied condition "success or failure"
May  3 13:13:19.692: INFO: Trying to get logs from node docker-desktop pod pod-subpath-test-secret-92kk container test-container-subpath-secret-92kk: <nil>
STEP: delete the pod
May  3 13:13:19.739: INFO: Waiting for pod pod-subpath-test-secret-92kk to disappear
May  3 13:13:19.746: INFO: Pod pod-subpath-test-secret-92kk no longer exists
STEP: Deleting pod pod-subpath-test-secret-92kk
May  3 13:13:19.746: INFO: Deleting pod "pod-subpath-test-secret-92kk" in namespace "subpath-9955"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:13:19.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9955" for this suite.
May  3 13:13:25.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:13:25.877: INFO: namespace subpath-9955 deletion completed in 6.1189718s

• [SLOW TEST:30.342 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:13:25.877: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
May  3 13:13:25.932: INFO: Waiting up to 5m0s for pod "downward-api-3c3da307-6da5-11e9-a622-a62f37ba3446" in namespace "downward-api-6196" to be "success or failure"
May  3 13:13:25.956: INFO: Pod "downward-api-3c3da307-6da5-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 24.0909ms
May  3 13:13:27.963: INFO: Pod "downward-api-3c3da307-6da5-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0311394s
May  3 13:13:29.972: INFO: Pod "downward-api-3c3da307-6da5-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0405372s
STEP: Saw pod success
May  3 13:13:29.972: INFO: Pod "downward-api-3c3da307-6da5-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 13:13:29.987: INFO: Trying to get logs from node docker-desktop pod downward-api-3c3da307-6da5-11e9-a622-a62f37ba3446 container dapi-container: <nil>
STEP: delete the pod
May  3 13:13:30.035: INFO: Waiting for pod downward-api-3c3da307-6da5-11e9-a622-a62f37ba3446 to disappear
May  3 13:13:30.044: INFO: Pod downward-api-3c3da307-6da5-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:13:30.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6196" for this suite.
May  3 13:13:36.069: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:13:36.185: INFO: namespace downward-api-6196 deletion completed in 6.1329155s

• [SLOW TEST:10.307 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:13:36.185: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
May  3 13:13:38.848: INFO: Successfully updated pod "labelsupdate426afbb1-6da5-11e9-a622-a62f37ba3446"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:13:40.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9744" for this suite.
May  3 13:14:02.912: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:14:03.028: INFO: namespace downward-api-9744 deletion completed in 22.1379057s

• [SLOW TEST:26.843 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:14:03.029: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override arguments
May  3 13:14:03.097: INFO: Waiting up to 5m0s for pod "client-containers-5262fa91-6da5-11e9-a622-a62f37ba3446" in namespace "containers-1234" to be "success or failure"
May  3 13:14:03.106: INFO: Pod "client-containers-5262fa91-6da5-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 9.4147ms
May  3 13:14:05.108: INFO: Pod "client-containers-5262fa91-6da5-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0117179s
STEP: Saw pod success
May  3 13:14:05.108: INFO: Pod "client-containers-5262fa91-6da5-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 13:14:05.112: INFO: Trying to get logs from node docker-desktop pod client-containers-5262fa91-6da5-11e9-a622-a62f37ba3446 container test-container: <nil>
STEP: delete the pod
May  3 13:14:05.162: INFO: Waiting for pod client-containers-5262fa91-6da5-11e9-a622-a62f37ba3446 to disappear
May  3 13:14:05.173: INFO: Pod client-containers-5262fa91-6da5-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:14:05.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1234" for this suite.
May  3 13:14:11.212: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:14:11.317: INFO: namespace containers-1234 deletion completed in 6.1254799s

• [SLOW TEST:8.288 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:14:11.318: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:14:17.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-9287" for this suite.
May  3 13:14:23.609: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:14:23.690: INFO: namespace namespaces-9287 deletion completed in 6.1343541s
STEP: Destroying namespace "nsdeletetest-7920" for this suite.
May  3 13:14:23.700: INFO: Namespace nsdeletetest-7920 was already deleted
STEP: Destroying namespace "nsdeletetest-2941" for this suite.
May  3 13:14:29.718: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:14:29.820: INFO: namespace nsdeletetest-2941 deletion completed in 6.1191944s

• [SLOW TEST:18.502 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:14:29.823: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
May  3 13:14:29.865: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May  3 13:14:29.878: INFO: Waiting for terminating namespaces to be deleted...
May  3 13:14:29.882: INFO: 
Logging pods the kubelet thinks is on node docker-desktop before test
May  3 13:14:29.900: INFO: etcd-docker-desktop from kube-system started at <nil> (0 container statuses recorded)
May  3 13:14:29.900: INFO: kube-scheduler-docker-desktop from kube-system started at <nil> (0 container statuses recorded)
May  3 13:14:29.900: INFO: kube-proxy-gskn5 from kube-system started at 2019-05-03 10:35:24 +0000 UTC (1 container statuses recorded)
May  3 13:14:29.900: INFO: 	Container kube-proxy ready: true, restart count 0
May  3 13:14:29.900: INFO: sonobuoy from heptio-sonobuoy started at 2019-05-03 12:06:48 +0000 UTC (1 container statuses recorded)
May  3 13:14:29.900: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May  3 13:14:29.900: INFO: compose-6b69ff6b9d-7blnv from docker started at 2019-05-03 10:36:34 +0000 UTC (1 container statuses recorded)
May  3 13:14:29.900: INFO: 	Container compose ready: true, restart count 0
May  3 13:14:29.900: INFO: sonobuoy-systemd-logs-daemon-set-605fe68f13894439-lg7rb from heptio-sonobuoy started at 2019-05-03 12:06:54 +0000 UTC (2 container statuses recorded)
May  3 13:14:29.900: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May  3 13:14:29.900: INFO: 	Container systemd-logs ready: false, restart count 17
May  3 13:14:29.900: INFO: kube-apiserver-docker-desktop from kube-system started at <nil> (0 container statuses recorded)
May  3 13:14:29.900: INFO: kube-controller-manager-docker-desktop from kube-system started at <nil> (0 container statuses recorded)
May  3 13:14:29.900: INFO: coredns-fb8b8dccf-nrmdq from kube-system started at 2019-05-03 10:35:24 +0000 UTC (1 container statuses recorded)
May  3 13:14:29.900: INFO: 	Container coredns ready: true, restart count 0
May  3 13:14:29.900: INFO: coredns-fb8b8dccf-qsc86 from kube-system started at 2019-05-03 10:35:24 +0000 UTC (1 container statuses recorded)
May  3 13:14:29.900: INFO: 	Container coredns ready: true, restart count 0
May  3 13:14:29.900: INFO: compose-api-6c5bf98cc7-6gs2q from docker started at 2019-05-03 10:36:34 +0000 UTC (1 container statuses recorded)
May  3 13:14:29.900: INFO: 	Container compose ready: true, restart count 0
May  3 13:14:29.900: INFO: sonobuoy-e2e-job-36cd23f1d2644d64 from heptio-sonobuoy started at 2019-05-03 12:06:54 +0000 UTC (2 container statuses recorded)
May  3 13:14:29.900: INFO: 	Container e2e ready: true, restart count 0
May  3 13:14:29.900: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: verifying the node has the label node docker-desktop
May  3 13:14:29.945: INFO: Pod compose-6b69ff6b9d-7blnv requesting resource cpu=0m on Node docker-desktop
May  3 13:14:29.945: INFO: Pod compose-api-6c5bf98cc7-6gs2q requesting resource cpu=0m on Node docker-desktop
May  3 13:14:29.945: INFO: Pod sonobuoy requesting resource cpu=0m on Node docker-desktop
May  3 13:14:29.945: INFO: Pod sonobuoy-e2e-job-36cd23f1d2644d64 requesting resource cpu=0m on Node docker-desktop
May  3 13:14:29.945: INFO: Pod sonobuoy-systemd-logs-daemon-set-605fe68f13894439-lg7rb requesting resource cpu=0m on Node docker-desktop
May  3 13:14:29.945: INFO: Pod coredns-fb8b8dccf-nrmdq requesting resource cpu=100m on Node docker-desktop
May  3 13:14:29.946: INFO: Pod coredns-fb8b8dccf-qsc86 requesting resource cpu=100m on Node docker-desktop
May  3 13:14:29.946: INFO: Pod etcd-docker-desktop requesting resource cpu=0m on Node docker-desktop
May  3 13:14:29.946: INFO: Pod kube-apiserver-docker-desktop requesting resource cpu=250m on Node docker-desktop
May  3 13:14:29.946: INFO: Pod kube-controller-manager-docker-desktop requesting resource cpu=200m on Node docker-desktop
May  3 13:14:29.946: INFO: Pod kube-proxy-gskn5 requesting resource cpu=0m on Node docker-desktop
May  3 13:14:29.946: INFO: Pod kube-scheduler-docker-desktop requesting resource cpu=100m on Node docker-desktop
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-62670946-6da5-11e9-a622-a62f37ba3446.159b2e8ad309e240], Reason = [Scheduled], Message = [Successfully assigned sched-pred-5946/filler-pod-62670946-6da5-11e9-a622-a62f37ba3446 to docker-desktop]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-62670946-6da5-11e9-a622-a62f37ba3446.159b2e8b1a01b2cc], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-62670946-6da5-11e9-a622-a62f37ba3446.159b2e8b1fd99994], Reason = [Created], Message = [Created container filler-pod-62670946-6da5-11e9-a622-a62f37ba3446]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-62670946-6da5-11e9-a622-a62f37ba3446.159b2e8b33fd9c40], Reason = [Started], Message = [Started container filler-pod-62670946-6da5-11e9-a622-a62f37ba3446]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.159b2e8bc52a2e54], Reason = [FailedScheduling], Message = [0/1 nodes are available: 1 Insufficient cpu.]
STEP: removing the label node off the node docker-desktop
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:14:35.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5946" for this suite.
May  3 13:14:41.104: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:14:41.221: INFO: namespace sched-pred-5946 deletion completed in 6.1378578s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:11.398 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:14:41.221: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1583
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
May  3 13:14:41.264: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-2002'
May  3 13:14:41.588: INFO: stderr: ""
May  3 13:14:41.588: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1588
May  3 13:14:41.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 delete pods e2e-test-nginx-pod --namespace=kubectl-2002'
May  3 13:14:45.127: INFO: stderr: ""
May  3 13:14:45.127: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:14:45.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2002" for this suite.
May  3 13:14:51.151: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:14:51.277: INFO: namespace kubectl-2002 deletion completed in 6.1425177s

• [SLOW TEST:10.056 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:14:51.278: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-6f25b4ff-6da5-11e9-a622-a62f37ba3446
STEP: Creating a pod to test consume configMaps
May  3 13:14:51.349: INFO: Waiting up to 5m0s for pod "pod-configmaps-6f270825-6da5-11e9-a622-a62f37ba3446" in namespace "configmap-3924" to be "success or failure"
May  3 13:14:51.365: INFO: Pod "pod-configmaps-6f270825-6da5-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 15.8779ms
May  3 13:14:53.369: INFO: Pod "pod-configmaps-6f270825-6da5-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0198778s
STEP: Saw pod success
May  3 13:14:53.369: INFO: Pod "pod-configmaps-6f270825-6da5-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 13:14:53.372: INFO: Trying to get logs from node docker-desktop pod pod-configmaps-6f270825-6da5-11e9-a622-a62f37ba3446 container configmap-volume-test: <nil>
STEP: delete the pod
May  3 13:14:53.402: INFO: Waiting for pod pod-configmaps-6f270825-6da5-11e9-a622-a62f37ba3446 to disappear
May  3 13:14:53.406: INFO: Pod pod-configmaps-6f270825-6da5-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:14:53.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3924" for this suite.
May  3 13:14:59.433: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:14:59.553: INFO: namespace configmap-3924 deletion completed in 6.1442806s

• [SLOW TEST:8.275 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:14:59.555: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
May  3 13:15:03.681: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May  3 13:15:03.687: INFO: Pod pod-with-prestop-exec-hook still exists
May  3 13:15:05.687: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May  3 13:15:05.697: INFO: Pod pod-with-prestop-exec-hook still exists
May  3 13:15:07.687: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May  3 13:15:07.695: INFO: Pod pod-with-prestop-exec-hook still exists
May  3 13:15:09.687: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May  3 13:15:09.698: INFO: Pod pod-with-prestop-exec-hook still exists
May  3 13:15:11.687: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May  3 13:15:11.698: INFO: Pod pod-with-prestop-exec-hook still exists
May  3 13:15:13.687: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May  3 13:15:13.703: INFO: Pod pod-with-prestop-exec-hook still exists
May  3 13:15:15.687: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May  3 13:15:15.694: INFO: Pod pod-with-prestop-exec-hook still exists
May  3 13:15:17.687: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May  3 13:15:17.693: INFO: Pod pod-with-prestop-exec-hook still exists
May  3 13:15:19.687: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May  3 13:15:19.695: INFO: Pod pod-with-prestop-exec-hook still exists
May  3 13:15:21.687: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May  3 13:15:21.695: INFO: Pod pod-with-prestop-exec-hook still exists
May  3 13:15:23.687: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May  3 13:15:23.703: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:15:23.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2550" for this suite.
May  3 13:15:45.763: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:15:45.860: INFO: namespace container-lifecycle-hook-2550 deletion completed in 22.1199072s

• [SLOW TEST:46.305 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:15:45.860: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May  3 13:15:45.903: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:15:47.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1894" for this suite.
May  3 13:16:37.993: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:16:38.089: INFO: namespace pods-1894 deletion completed in 50.1147998s

• [SLOW TEST:52.229 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:16:38.089: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
May  3 13:16:38.165: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-8488,SelfLink:/api/v1/namespaces/watch-8488/configmaps/e2e-watch-test-watch-closed,UID:aed0b562-6da5-11e9-9efa-00155da4710f,ResourceVersion:21069,Generation:0,CreationTimestamp:2019-05-03 13:16:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
May  3 13:16:38.167: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-8488,SelfLink:/api/v1/namespaces/watch-8488/configmaps/e2e-watch-test-watch-closed,UID:aed0b562-6da5-11e9-9efa-00155da4710f,ResourceVersion:21070,Generation:0,CreationTimestamp:2019-05-03 13:16:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
May  3 13:16:38.212: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-8488,SelfLink:/api/v1/namespaces/watch-8488/configmaps/e2e-watch-test-watch-closed,UID:aed0b562-6da5-11e9-9efa-00155da4710f,ResourceVersion:21071,Generation:0,CreationTimestamp:2019-05-03 13:16:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May  3 13:16:38.212: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-8488,SelfLink:/api/v1/namespaces/watch-8488/configmaps/e2e-watch-test-watch-closed,UID:aed0b562-6da5-11e9-9efa-00155da4710f,ResourceVersion:21072,Generation:0,CreationTimestamp:2019-05-03 13:16:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:16:38.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8488" for this suite.
May  3 13:16:44.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:16:44.334: INFO: namespace watch-8488 deletion completed in 6.1129937s

• [SLOW TEST:6.245 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:16:44.334: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May  3 13:17:08.416: INFO: Container started at 2019-05-03 13:16:45 +0000 UTC, pod became ready at 2019-05-03 13:17:07 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:17:08.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7220" for this suite.
May  3 13:17:30.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:17:30.571: INFO: namespace container-probe-7220 deletion completed in 22.1276402s

• [SLOW TEST:46.237 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:17:30.571: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
May  3 13:17:30.625: INFO: Waiting up to 5m0s for pod "pod-ce170000-6da5-11e9-a622-a62f37ba3446" in namespace "emptydir-6876" to be "success or failure"
May  3 13:17:30.639: INFO: Pod "pod-ce170000-6da5-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 14.0314ms
May  3 13:17:32.642: INFO: Pod "pod-ce170000-6da5-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0164472s
STEP: Saw pod success
May  3 13:17:32.642: INFO: Pod "pod-ce170000-6da5-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 13:17:32.650: INFO: Trying to get logs from node docker-desktop pod pod-ce170000-6da5-11e9-a622-a62f37ba3446 container test-container: <nil>
STEP: delete the pod
May  3 13:17:32.685: INFO: Waiting for pod pod-ce170000-6da5-11e9-a622-a62f37ba3446 to disappear
May  3 13:17:32.691: INFO: Pod pod-ce170000-6da5-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:17:32.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6876" for this suite.
May  3 13:17:38.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:17:38.820: INFO: namespace emptydir-6876 deletion completed in 6.1189588s

• [SLOW TEST:8.249 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:17:38.827: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
May  3 13:17:38.930: INFO: Waiting up to 5m0s for pod "pod-d3092cf7-6da5-11e9-a622-a62f37ba3446" in namespace "emptydir-8499" to be "success or failure"
May  3 13:17:38.950: INFO: Pod "pod-d3092cf7-6da5-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 19.7461ms
May  3 13:17:40.953: INFO: Pod "pod-d3092cf7-6da5-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0226005s
STEP: Saw pod success
May  3 13:17:40.953: INFO: Pod "pod-d3092cf7-6da5-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 13:17:40.957: INFO: Trying to get logs from node docker-desktop pod pod-d3092cf7-6da5-11e9-a622-a62f37ba3446 container test-container: <nil>
STEP: delete the pod
May  3 13:17:40.982: INFO: Waiting for pod pod-d3092cf7-6da5-11e9-a622-a62f37ba3446 to disappear
May  3 13:17:40.994: INFO: Pod pod-d3092cf7-6da5-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:17:40.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8499" for this suite.
May  3 13:17:47.016: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:17:47.095: INFO: namespace emptydir-8499 deletion completed in 6.0938052s

• [SLOW TEST:8.268 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:17:47.102: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's args
May  3 13:17:47.174: INFO: Waiting up to 5m0s for pod "var-expansion-d7f23383-6da5-11e9-a622-a62f37ba3446" in namespace "var-expansion-209" to be "success or failure"
May  3 13:17:47.190: INFO: Pod "var-expansion-d7f23383-6da5-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 7.7363ms
May  3 13:17:49.192: INFO: Pod "var-expansion-d7f23383-6da5-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0101703s
STEP: Saw pod success
May  3 13:17:49.192: INFO: Pod "var-expansion-d7f23383-6da5-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 13:17:49.199: INFO: Trying to get logs from node docker-desktop pod var-expansion-d7f23383-6da5-11e9-a622-a62f37ba3446 container dapi-container: <nil>
STEP: delete the pod
May  3 13:17:49.228: INFO: Waiting for pod var-expansion-d7f23383-6da5-11e9-a622-a62f37ba3446 to disappear
May  3 13:17:49.238: INFO: Pod var-expansion-d7f23383-6da5-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:17:49.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-209" for this suite.
May  3 13:17:55.263: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:17:55.434: INFO: namespace var-expansion-209 deletion completed in 6.1897037s

• [SLOW TEST:8.339 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:17:55.446: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
May  3 13:17:55.535: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-4108,SelfLink:/api/v1/namespaces/watch-4108/configmaps/e2e-watch-test-resource-version,UID:dceaf613-6da5-11e9-9efa-00155da4710f,ResourceVersion:21275,Generation:0,CreationTimestamp:2019-05-03 13:17:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May  3 13:17:55.539: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-4108,SelfLink:/api/v1/namespaces/watch-4108/configmaps/e2e-watch-test-resource-version,UID:dceaf613-6da5-11e9-9efa-00155da4710f,ResourceVersion:21276,Generation:0,CreationTimestamp:2019-05-03 13:17:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:17:55.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4108" for this suite.
May  3 13:18:01.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:18:01.649: INFO: namespace watch-4108 deletion completed in 6.0972763s

• [SLOW TEST:6.204 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:18:01.663: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May  3 13:18:01.718: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e09e84d2-6da5-11e9-a622-a62f37ba3446" in namespace "downward-api-4016" to be "success or failure"
May  3 13:18:01.733: INFO: Pod "downwardapi-volume-e09e84d2-6da5-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 15.445ms
May  3 13:18:03.738: INFO: Pod "downwardapi-volume-e09e84d2-6da5-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0199816s
STEP: Saw pod success
May  3 13:18:03.738: INFO: Pod "downwardapi-volume-e09e84d2-6da5-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 13:18:03.743: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-e09e84d2-6da5-11e9-a622-a62f37ba3446 container client-container: <nil>
STEP: delete the pod
May  3 13:18:03.811: INFO: Waiting for pod downwardapi-volume-e09e84d2-6da5-11e9-a622-a62f37ba3446 to disappear
May  3 13:18:03.818: INFO: Pod downwardapi-volume-e09e84d2-6da5-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:18:03.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4016" for this suite.
May  3 13:18:09.843: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:18:09.971: INFO: namespace downward-api-4016 deletion completed in 6.1445611s

• [SLOW TEST:8.309 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:18:09.972: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Starting the proxy
May  3 13:18:10.018: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-343589126 proxy --unix-socket=/tmp/kubectl-proxy-unix016120881/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:18:10.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-501" for this suite.
May  3 13:18:16.112: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:18:16.226: INFO: namespace kubectl-501 deletion completed in 6.1305531s

• [SLOW TEST:6.255 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:18:16.226: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May  3 13:18:18.377: INFO: Waiting up to 5m0s for pod "client-envvars-ea8d8f12-6da5-11e9-a622-a62f37ba3446" in namespace "pods-2996" to be "success or failure"
May  3 13:18:18.392: INFO: Pod "client-envvars-ea8d8f12-6da5-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 14.792ms
May  3 13:18:20.395: INFO: Pod "client-envvars-ea8d8f12-6da5-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0173424s
STEP: Saw pod success
May  3 13:18:20.395: INFO: Pod "client-envvars-ea8d8f12-6da5-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 13:18:20.399: INFO: Trying to get logs from node docker-desktop pod client-envvars-ea8d8f12-6da5-11e9-a622-a62f37ba3446 container env3cont: <nil>
STEP: delete the pod
May  3 13:18:20.432: INFO: Waiting for pod client-envvars-ea8d8f12-6da5-11e9-a622-a62f37ba3446 to disappear
May  3 13:18:20.440: INFO: Pod client-envvars-ea8d8f12-6da5-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:18:20.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2996" for this suite.
May  3 13:19:10.480: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:19:10.583: INFO: namespace pods-2996 deletion completed in 50.1272181s

• [SLOW TEST:54.357 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:19:10.584: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-09b3f923-6da6-11e9-a622-a62f37ba3446
STEP: Creating a pod to test consume configMaps
May  3 13:19:10.647: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-09b56925-6da6-11e9-a622-a62f37ba3446" in namespace "projected-7838" to be "success or failure"
May  3 13:19:10.675: INFO: Pod "pod-projected-configmaps-09b56925-6da6-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 20.4262ms
May  3 13:19:12.679: INFO: Pod "pod-projected-configmaps-09b56925-6da6-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0249417s
STEP: Saw pod success
May  3 13:19:12.687: INFO: Pod "pod-projected-configmaps-09b56925-6da6-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 13:19:12.696: INFO: Trying to get logs from node docker-desktop pod pod-projected-configmaps-09b56925-6da6-11e9-a622-a62f37ba3446 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May  3 13:19:12.771: INFO: Waiting for pod pod-projected-configmaps-09b56925-6da6-11e9-a622-a62f37ba3446 to disappear
May  3 13:19:12.779: INFO: Pod pod-projected-configmaps-09b56925-6da6-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:19:12.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7838" for this suite.
May  3 13:19:18.816: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:19:18.916: INFO: namespace projected-7838 deletion completed in 6.1186991s

• [SLOW TEST:8.332 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:19:18.922: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May  3 13:19:18.983: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:19:20.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8882" for this suite.
May  3 13:19:26.122: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:19:26.232: INFO: namespace custom-resource-definition-8882 deletion completed in 6.1307525s

• [SLOW TEST:7.310 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:19:26.232: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1108
STEP: creating the pod
May  3 13:19:26.273: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 create -f - --namespace=kubectl-3432'
May  3 13:19:26.482: INFO: stderr: ""
May  3 13:19:26.482: INFO: stdout: "pod/pause created\n"
May  3 13:19:26.494: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
May  3 13:19:26.494: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-3432" to be "running and ready"
May  3 13:19:26.501: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 6.5934ms
May  3 13:19:28.506: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01225s
May  3 13:19:30.510: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.0161395s
May  3 13:19:30.510: INFO: Pod "pause" satisfied condition "running and ready"
May  3 13:19:30.510: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: adding the label testing-label with value testing-label-value to a pod
May  3 13:19:30.510: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 label pods pause testing-label=testing-label-value --namespace=kubectl-3432'
May  3 13:19:30.622: INFO: stderr: ""
May  3 13:19:30.622: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
May  3 13:19:30.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pod pause -L testing-label --namespace=kubectl-3432'
May  3 13:19:30.693: INFO: stderr: ""
May  3 13:19:30.693: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
May  3 13:19:30.693: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 label pods pause testing-label- --namespace=kubectl-3432'
May  3 13:19:30.763: INFO: stderr: ""
May  3 13:19:30.763: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
May  3 13:19:30.763: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pod pause -L testing-label --namespace=kubectl-3432'
May  3 13:19:30.838: INFO: stderr: ""
May  3 13:19:30.838: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1115
STEP: using delete to clean up resources
May  3 13:19:30.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 delete --grace-period=0 --force -f - --namespace=kubectl-3432'
May  3 13:19:30.925: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May  3 13:19:30.926: INFO: stdout: "pod \"pause\" force deleted\n"
May  3 13:19:30.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get rc,svc -l name=pause --no-headers --namespace=kubectl-3432'
May  3 13:19:31.030: INFO: stderr: "No resources found.\n"
May  3 13:19:31.030: INFO: stdout: ""
May  3 13:19:31.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 get pods -l name=pause --namespace=kubectl-3432 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May  3 13:19:31.193: INFO: stderr: ""
May  3 13:19:31.193: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:19:31.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3432" for this suite.
May  3 13:19:37.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:19:37.302: INFO: namespace kubectl-3432 deletion completed in 6.1048755s

• [SLOW TEST:11.070 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:19:37.302: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-19a27412-6da6-11e9-a622-a62f37ba3446
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:19:41.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7180" for this suite.
May  3 13:20:03.496: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:20:03.590: INFO: namespace configmap-7180 deletion completed in 22.1272202s

• [SLOW TEST:26.288 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:20:03.590: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0503 13:20:43.679028      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May  3 13:20:43.685: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:20:43.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8488" for this suite.
May  3 13:20:51.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:20:51.817: INFO: namespace gc-8488 deletion completed in 8.1207748s

• [SLOW TEST:48.227 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:20:51.819: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
May  3 13:20:51.895: INFO: Waiting up to 5m0s for pod "downward-api-460d630f-6da6-11e9-a622-a62f37ba3446" in namespace "downward-api-4512" to be "success or failure"
May  3 13:20:51.901: INFO: Pod "downward-api-460d630f-6da6-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 6.4962ms
May  3 13:20:53.914: INFO: Pod "downward-api-460d630f-6da6-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0190774s
May  3 13:20:55.921: INFO: Pod "downward-api-460d630f-6da6-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 4.0264189s
May  3 13:20:57.931: INFO: Pod "downward-api-460d630f-6da6-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.0360156s
STEP: Saw pod success
May  3 13:20:57.931: INFO: Pod "downward-api-460d630f-6da6-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 13:20:57.946: INFO: Trying to get logs from node docker-desktop pod downward-api-460d630f-6da6-11e9-a622-a62f37ba3446 container dapi-container: <nil>
STEP: delete the pod
May  3 13:20:57.985: INFO: Waiting for pod downward-api-460d630f-6da6-11e9-a622-a62f37ba3446 to disappear
May  3 13:20:57.993: INFO: Pod downward-api-460d630f-6da6-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:20:57.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4512" for this suite.
May  3 13:21:04.015: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:21:04.106: INFO: namespace downward-api-4512 deletion completed in 6.1042633s

• [SLOW TEST:12.287 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:21:04.106: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating server pod server in namespace prestop-3140
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-3140
STEP: Deleting pre-stop pod
May  3 13:21:17.301: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:21:17.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-3140" for this suite.
May  3 13:21:57.396: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:21:57.511: INFO: namespace prestop-3140 deletion completed in 40.1329831s

• [SLOW TEST:53.405 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:21:57.514: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1510
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
May  3 13:21:57.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-405'
May  3 13:21:57.646: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May  3 13:21:57.646: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1515
May  3 13:21:57.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 delete jobs e2e-test-nginx-job --namespace=kubectl-405'
May  3 13:21:57.778: INFO: stderr: ""
May  3 13:21:57.779: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:21:57.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-405" for this suite.
May  3 13:22:03.809: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:22:03.910: INFO: namespace kubectl-405 deletion completed in 6.1213013s

• [SLOW TEST:6.395 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:22:03.912: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1455
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
May  3 13:22:03.947: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=kubectl-668'
May  3 13:22:04.036: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May  3 13:22:04.036: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1460
May  3 13:22:06.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 delete deployment e2e-test-nginx-deployment --namespace=kubectl-668'
May  3 13:22:06.145: INFO: stderr: ""
May  3 13:22:06.145: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:22:06.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-668" for this suite.
May  3 13:22:28.169: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:22:28.281: INFO: namespace kubectl-668 deletion completed in 22.12619s

• [SLOW TEST:24.370 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:22:28.282: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May  3 13:22:28.384: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"7f8fc27b-6da6-11e9-9efa-00155da4710f", Controller:(*bool)(0xc003fcdb1a), BlockOwnerDeletion:(*bool)(0xc003fcdb1b)}}
May  3 13:22:28.403: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"7f8b410f-6da6-11e9-9efa-00155da4710f", Controller:(*bool)(0xc0018131fe), BlockOwnerDeletion:(*bool)(0xc0018131ff)}}
May  3 13:22:28.415: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"7f8bfd9c-6da6-11e9-9efa-00155da4710f", Controller:(*bool)(0xc003fcdd56), BlockOwnerDeletion:(*bool)(0xc003fcdd57)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:22:33.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1559" for this suite.
May  3 13:22:39.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:22:39.602: INFO: namespace gc-1559 deletion completed in 6.1119704s

• [SLOW TEST:11.320 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:22:39.605: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's command
May  3 13:22:39.678: INFO: Waiting up to 5m0s for pod "var-expansion-864c2110-6da6-11e9-a622-a62f37ba3446" in namespace "var-expansion-4446" to be "success or failure"
May  3 13:22:39.693: INFO: Pod "var-expansion-864c2110-6da6-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 15.4966ms
May  3 13:22:41.697: INFO: Pod "var-expansion-864c2110-6da6-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0195646s
May  3 13:22:43.702: INFO: Pod "var-expansion-864c2110-6da6-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0238114s
STEP: Saw pod success
May  3 13:22:43.702: INFO: Pod "var-expansion-864c2110-6da6-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 13:22:43.711: INFO: Trying to get logs from node docker-desktop pod var-expansion-864c2110-6da6-11e9-a622-a62f37ba3446 container dapi-container: <nil>
STEP: delete the pod
May  3 13:22:43.765: INFO: Waiting for pod var-expansion-864c2110-6da6-11e9-a622-a62f37ba3446 to disappear
May  3 13:22:43.770: INFO: Pod var-expansion-864c2110-6da6-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:22:43.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4446" for this suite.
May  3 13:22:49.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:22:49.892: INFO: namespace var-expansion-4446 deletion completed in 6.1144317s

• [SLOW TEST:10.287 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:22:49.892: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-1830
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating stateful set ss in namespace statefulset-1830
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-1830
May  3 13:22:49.988: INFO: Found 0 stateful pods, waiting for 1
May  3 13:22:59.995: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
May  3 13:23:00.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May  3 13:23:00.233: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May  3 13:23:00.233: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May  3 13:23:00.233: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May  3 13:23:00.240: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
May  3 13:23:10.244: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May  3 13:23:10.244: INFO: Waiting for statefulset status.replicas updated to 0
May  3 13:23:10.277: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
May  3 13:23:10.278: INFO: ss-0  docker-desktop  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:22:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:22:49 +0000 UTC  }]
May  3 13:23:10.278: INFO: ss-1                  Pending         []
May  3 13:23:10.278: INFO: 
May  3 13:23:10.278: INFO: StatefulSet ss has not reached scale 3, at 2
May  3 13:23:11.280: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.9904955s
May  3 13:23:12.285: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.9866644s
May  3 13:23:13.290: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.9830391s
May  3 13:23:14.292: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.9783224s
May  3 13:23:15.305: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.9739983s
May  3 13:23:16.310: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.962769s
May  3 13:23:17.318: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.9573563s
May  3 13:23:18.324: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.9492643s
May  3 13:23:19.328: INFO: Verifying statefulset ss doesn't scale past 3 for another 944.2344ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-1830
May  3 13:23:20.340: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May  3 13:23:20.555: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
May  3 13:23:20.555: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May  3 13:23:20.555: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May  3 13:23:20.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May  3 13:23:20.804: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
May  3 13:23:20.804: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May  3 13:23:20.804: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May  3 13:23:20.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May  3 13:23:20.997: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
May  3 13:23:20.997: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May  3 13:23:20.997: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May  3 13:23:21.010: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
May  3 13:23:31.017: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
May  3 13:23:31.018: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
May  3 13:23:31.018: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
May  3 13:23:31.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May  3 13:23:31.240: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May  3 13:23:31.240: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May  3 13:23:31.240: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May  3 13:23:31.240: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May  3 13:23:31.451: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May  3 13:23:31.451: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May  3 13:23:31.451: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May  3 13:23:31.451: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May  3 13:23:31.683: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May  3 13:23:31.683: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May  3 13:23:31.683: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May  3 13:23:31.683: INFO: Waiting for statefulset status.replicas updated to 0
May  3 13:23:31.689: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
May  3 13:23:41.713: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May  3 13:23:41.713: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
May  3 13:23:41.713: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
May  3 13:23:41.747: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
May  3 13:23:41.747: INFO: ss-0  docker-desktop  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:22:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:22:49 +0000 UTC  }]
May  3 13:23:41.747: INFO: ss-1  docker-desktop  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:10 +0000 UTC  }]
May  3 13:23:41.747: INFO: ss-2  docker-desktop  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:10 +0000 UTC  }]
May  3 13:23:41.747: INFO: 
May  3 13:23:41.747: INFO: StatefulSet ss has not reached scale 0, at 3
May  3 13:23:42.753: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
May  3 13:23:42.753: INFO: ss-0  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:22:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:22:49 +0000 UTC  }]
May  3 13:23:42.753: INFO: ss-1  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:10 +0000 UTC  }]
May  3 13:23:42.753: INFO: ss-2  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:10 +0000 UTC  }]
May  3 13:23:42.753: INFO: 
May  3 13:23:42.753: INFO: StatefulSet ss has not reached scale 0, at 3
May  3 13:23:43.759: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
May  3 13:23:43.759: INFO: ss-0  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:22:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:22:49 +0000 UTC  }]
May  3 13:23:43.759: INFO: ss-1  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:10 +0000 UTC  }]
May  3 13:23:43.759: INFO: ss-2  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:10 +0000 UTC  }]
May  3 13:23:43.760: INFO: 
May  3 13:23:43.760: INFO: StatefulSet ss has not reached scale 0, at 3
May  3 13:23:44.766: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
May  3 13:23:44.766: INFO: ss-0  docker-desktop  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:22:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:22:49 +0000 UTC  }]
May  3 13:23:44.766: INFO: ss-1  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:10 +0000 UTC  }]
May  3 13:23:44.766: INFO: ss-2  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:10 +0000 UTC  }]
May  3 13:23:44.766: INFO: 
May  3 13:23:44.766: INFO: StatefulSet ss has not reached scale 0, at 3
May  3 13:23:45.773: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
May  3 13:23:45.774: INFO: ss-0  docker-desktop  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:22:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:22:49 +0000 UTC  }]
May  3 13:23:45.774: INFO: ss-1  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:10 +0000 UTC  }]
May  3 13:23:45.775: INFO: ss-2  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:10 +0000 UTC  }]
May  3 13:23:45.776: INFO: 
May  3 13:23:45.776: INFO: StatefulSet ss has not reached scale 0, at 3
May  3 13:23:46.781: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
May  3 13:23:46.781: INFO: ss-0  docker-desktop  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:22:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:22:49 +0000 UTC  }]
May  3 13:23:46.781: INFO: ss-2  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:10 +0000 UTC  }]
May  3 13:23:46.781: INFO: 
May  3 13:23:46.781: INFO: StatefulSet ss has not reached scale 0, at 2
May  3 13:23:47.786: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
May  3 13:23:47.786: INFO: ss-0  docker-desktop  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:22:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:22:49 +0000 UTC  }]
May  3 13:23:47.786: INFO: ss-2  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:10 +0000 UTC  }]
May  3 13:23:47.786: INFO: 
May  3 13:23:47.787: INFO: StatefulSet ss has not reached scale 0, at 2
May  3 13:23:48.791: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
May  3 13:23:48.791: INFO: ss-0  docker-desktop  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:22:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:22:49 +0000 UTC  }]
May  3 13:23:48.791: INFO: ss-2  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:10 +0000 UTC  }]
May  3 13:23:48.801: INFO: 
May  3 13:23:48.801: INFO: StatefulSet ss has not reached scale 0, at 2
May  3 13:23:49.812: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
May  3 13:23:49.812: INFO: ss-0  docker-desktop  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:22:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:22:49 +0000 UTC  }]
May  3 13:23:49.813: INFO: ss-2  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:10 +0000 UTC  }]
May  3 13:23:49.814: INFO: 
May  3 13:23:49.814: INFO: StatefulSet ss has not reached scale 0, at 2
May  3 13:23:50.820: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
May  3 13:23:50.820: INFO: ss-0  docker-desktop  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:22:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:22:49 +0000 UTC  }]
May  3 13:23:50.823: INFO: ss-2  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:23:10 +0000 UTC  }]
May  3 13:23:50.827: INFO: 
May  3 13:23:50.827: INFO: StatefulSet ss has not reached scale 0, at 2
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-1830
May  3 13:23:51.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May  3 13:23:51.955: INFO: rc: 1
May  3 13:23:51.965: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc0020cf650 exit status 1 <nil> <nil> true [0xc0026f49b0 0xc0026f49c8 0xc0026f49e0] [0xc0026f49b0 0xc0026f49c8 0xc0026f49e0] [0xc0026f49c0 0xc0026f49d8] [0x9bf9f0 0x9bf9f0] 0xc0024ed1a0 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

May  3 13:24:01.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May  3 13:24:02.062: INFO: rc: 1
May  3 13:24:02.062: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0020cf9b0 exit status 1 <nil> <nil> true [0xc0026f49e8 0xc0026f4a00 0xc0026f4a18] [0xc0026f49e8 0xc0026f4a00 0xc0026f4a18] [0xc0026f49f8 0xc0026f4a10] [0x9bf9f0 0x9bf9f0] 0xc0024edaa0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May  3 13:24:12.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May  3 13:24:12.160: INFO: rc: 1
May  3 13:24:12.160: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0020cfd40 exit status 1 <nil> <nil> true [0xc0026f4a20 0xc0026f4a38 0xc0026f4a50] [0xc0026f4a20 0xc0026f4a38 0xc0026f4a50] [0xc0026f4a30 0xc0026f4a48] [0x9bf9f0 0x9bf9f0] 0xc003d160c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May  3 13:24:22.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May  3 13:24:22.256: INFO: rc: 1
May  3 13:24:22.257: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00398ffb0 exit status 1 <nil> <nil> true [0xc003e3a518 0xc003e3a530 0xc003e3a548] [0xc003e3a518 0xc003e3a530 0xc003e3a548] [0xc003e3a528 0xc003e3a540] [0x9bf9f0 0x9bf9f0] 0xc001b59b60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May  3 13:24:32.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May  3 13:24:32.328: INFO: rc: 1
May  3 13:24:32.329: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0016ea300 exit status 1 <nil> <nil> true [0xc0008bc010 0xc0008bc048 0xc0008bc0f8] [0xc0008bc010 0xc0008bc048 0xc0008bc0f8] [0xc0008bc030 0xc0008bc0c0] [0x9bf9f0 0x9bf9f0] 0xc0024ecc60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May  3 13:24:42.329: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May  3 13:24:42.411: INFO: rc: 1
May  3 13:24:42.411: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0016ea660 exit status 1 <nil> <nil> true [0xc0008bc130 0xc0008bc1c8 0xc0008bc230] [0xc0008bc130 0xc0008bc1c8 0xc0008bc230] [0xc0008bc198 0xc0008bc228] [0x9bf9f0 0x9bf9f0] 0xc0024ed7a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May  3 13:24:52.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May  3 13:24:52.548: INFO: rc: 1
May  3 13:24:52.548: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0026a0300 exit status 1 <nil> <nil> true [0xc0000c45b8 0xc00044d7f0 0xc00044d918] [0xc0000c45b8 0xc00044d7f0 0xc00044d918] [0xc00044d7a0 0xc00044d908] [0x9bf9f0 0x9bf9f0] 0xc002490600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May  3 13:25:02.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May  3 13:25:02.626: INFO: rc: 1
May  3 13:25:02.627: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0026a07e0 exit status 1 <nil> <nil> true [0xc00044d978 0xc00044dd90 0xc00044df48] [0xc00044d978 0xc00044dd90 0xc00044df48] [0xc00044db90 0xc00044de80] [0x9bf9f0 0x9bf9f0] 0xc002490c00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May  3 13:25:12.627: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May  3 13:25:12.715: INFO: rc: 1
May  3 13:25:12.715: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0026a0b10 exit status 1 <nil> <nil> true [0xc000010010 0xc0000108a8 0xc000010978] [0xc000010010 0xc0000108a8 0xc000010978] [0xc000010858 0xc000010928] [0x9bf9f0 0x9bf9f0] 0xc002491200 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May  3 13:25:22.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May  3 13:25:22.806: INFO: rc: 1
May  3 13:25:22.806: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0026a0ea0 exit status 1 <nil> <nil> true [0xc000010a38 0xc000010c88 0xc000010e20] [0xc000010a38 0xc000010c88 0xc000010e20] [0xc000010c10 0xc000010da0] [0x9bf9f0 0x9bf9f0] 0xc002491740 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May  3 13:25:32.806: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May  3 13:25:32.894: INFO: rc: 1
May  3 13:25:32.894: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0016eacf0 exit status 1 <nil> <nil> true [0xc0008bc250 0xc0008bc360 0xc0008bc420] [0xc0008bc250 0xc0008bc360 0xc0008bc420] [0xc0008bc2f0 0xc0008bc3e8] [0x9bf9f0 0x9bf9f0] 0xc0024ede00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May  3 13:25:42.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May  3 13:25:42.974: INFO: rc: 1
May  3 13:25:42.974: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0016eb050 exit status 1 <nil> <nil> true [0xc0008bc428 0xc0008bc5d0 0xc0008bc780] [0xc0008bc428 0xc0008bc5d0 0xc0008bc780] [0xc0008bc548 0xc0008bc6d8] [0x9bf9f0 0x9bf9f0] 0xc000c56360 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May  3 13:25:52.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May  3 13:25:53.060: INFO: rc: 1
May  3 13:25:53.060: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0016eb3b0 exit status 1 <nil> <nil> true [0xc0008bc848 0xc0008bc958 0xc0008bca48] [0xc0008bc848 0xc0008bc958 0xc0008bca48] [0xc0008bc900 0xc0008bc9f8] [0x9bf9f0 0x9bf9f0] 0xc000c56840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May  3 13:26:03.061: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May  3 13:26:03.165: INFO: rc: 1
May  3 13:26:03.165: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0016eb9b0 exit status 1 <nil> <nil> true [0xc0008bca70 0xc0008bcb50 0xc0008bcbc8] [0xc0008bca70 0xc0008bcb50 0xc0008bcbc8] [0xc0008bcae8 0xc0008bcba8] [0x9bf9f0 0x9bf9f0] 0xc000c56de0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May  3 13:26:13.165: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May  3 13:26:13.255: INFO: rc: 1
May  3 13:26:13.256: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0026a1380 exit status 1 <nil> <nil> true [0xc000010e30 0xc000010ee0 0xc000011010] [0xc000010e30 0xc000010ee0 0xc000011010] [0xc000010eb0 0xc000010f58] [0x9bf9f0 0x9bf9f0] 0xc002491c80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May  3 13:26:23.256: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May  3 13:26:23.333: INFO: rc: 1
May  3 13:26:23.333: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0016ebd10 exit status 1 <nil> <nil> true [0xc0008bcca8 0xc0008bcde0 0xc0008bce98] [0xc0008bcca8 0xc0008bcde0 0xc0008bce98] [0xc0008bcd60 0xc0008bce38] [0x9bf9f0 0x9bf9f0] 0xc000c574a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May  3 13:26:33.334: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May  3 13:26:33.415: INFO: rc: 1
May  3 13:26:33.415: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0016ea330 exit status 1 <nil> <nil> true [0xc00044d7a0 0xc00044d908 0xc00044da50] [0xc00044d7a0 0xc00044d908 0xc00044da50] [0xc00044d848 0xc00044d978] [0x9bf9f0 0x9bf9f0] 0xc0024ecc60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May  3 13:26:43.415: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May  3 13:26:43.521: INFO: rc: 1
May  3 13:26:43.521: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0016ea6c0 exit status 1 <nil> <nil> true [0xc00044db90 0xc00044de80 0xc0008bc000] [0xc00044db90 0xc00044de80 0xc0008bc000] [0xc00044de60 0xc0000c45b8] [0x9bf9f0 0x9bf9f0] 0xc0024ed7a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May  3 13:26:53.522: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May  3 13:26:53.640: INFO: rc: 1
May  3 13:26:53.640: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0016ead20 exit status 1 <nil> <nil> true [0xc0008bc010 0xc0008bc048 0xc0008bc0f8] [0xc0008bc010 0xc0008bc048 0xc0008bc0f8] [0xc0008bc030 0xc0008bc0c0] [0x9bf9f0 0x9bf9f0] 0xc0024ede00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May  3 13:27:03.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May  3 13:27:03.729: INFO: rc: 1
May  3 13:27:03.729: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0026a0390 exit status 1 <nil> <nil> true [0xc000010010 0xc0000108a8 0xc000010978] [0xc000010010 0xc0000108a8 0xc000010978] [0xc000010858 0xc000010928] [0x9bf9f0 0x9bf9f0] 0xc000c56420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May  3 13:27:13.729: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May  3 13:27:13.805: INFO: rc: 1
May  3 13:27:13.805: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0016eb080 exit status 1 <nil> <nil> true [0xc0008bc130 0xc0008bc1c8 0xc0008bc230] [0xc0008bc130 0xc0008bc1c8 0xc0008bc230] [0xc0008bc198 0xc0008bc228] [0x9bf9f0 0x9bf9f0] 0xc002490480 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May  3 13:27:23.806: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May  3 13:27:23.914: INFO: rc: 1
May  3 13:27:23.914: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0026a0870 exit status 1 <nil> <nil> true [0xc000010a38 0xc000010c88 0xc000010e20] [0xc000010a38 0xc000010c88 0xc000010e20] [0xc000010c10 0xc000010da0] [0x9bf9f0 0x9bf9f0] 0xc000c568a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May  3 13:27:33.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May  3 13:27:33.988: INFO: rc: 1
May  3 13:27:33.988: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0026a0c00 exit status 1 <nil> <nil> true [0xc000010e30 0xc000010ee0 0xc000011010] [0xc000010e30 0xc000010ee0 0xc000011010] [0xc000010eb0 0xc000010f58] [0x9bf9f0 0x9bf9f0] 0xc000c56ea0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May  3 13:27:43.989: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May  3 13:27:44.062: INFO: rc: 1
May  3 13:27:44.062: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0026a10e0 exit status 1 <nil> <nil> true [0xc000011050 0xc0000110d0 0xc0000111c8] [0xc000011050 0xc0000110d0 0xc0000111c8] [0xc000011080 0xc0000111a8] [0x9bf9f0 0x9bf9f0] 0xc000c57560 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May  3 13:27:54.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May  3 13:27:54.120: INFO: rc: 1
May  3 13:27:54.120: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0026a14a0 exit status 1 <nil> <nil> true [0xc0000111d8 0xc000011290 0xc0000112f8] [0xc0000111d8 0xc000011290 0xc0000112f8] [0xc000011260 0xc0000112e8] [0x9bf9f0 0x9bf9f0] 0xc000c57bc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May  3 13:28:04.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May  3 13:28:04.178: INFO: rc: 1
May  3 13:28:04.181: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0026a1800 exit status 1 <nil> <nil> true [0xc000011340 0xc000011400 0xc0000114f0] [0xc000011340 0xc000011400 0xc0000114f0] [0xc0000113e0 0xc000011490] [0x9bf9f0 0x9bf9f0] 0xc001638060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May  3 13:28:14.181: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May  3 13:28:14.251: INFO: rc: 1
May  3 13:28:14.251: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0026a1b60 exit status 1 <nil> <nil> true [0xc000011520 0xc000011688 0xc000011810] [0xc000011520 0xc000011688 0xc000011810] [0xc000011600 0xc000011788] [0x9bf9f0 0x9bf9f0] 0xc0016387e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May  3 13:28:24.251: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May  3 13:28:24.317: INFO: rc: 1
May  3 13:28:24.317: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0016eb530 exit status 1 <nil> <nil> true [0xc0008bc250 0xc0008bc360 0xc0008bc420] [0xc0008bc250 0xc0008bc360 0xc0008bc420] [0xc0008bc2f0 0xc0008bc3e8] [0x9bf9f0 0x9bf9f0] 0xc002490b40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May  3 13:28:34.318: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May  3 13:28:34.409: INFO: rc: 1
May  3 13:28:34.409: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0016ea300 exit status 1 <nil> <nil> true [0xc00044d630 0xc00044d848 0xc00044d978] [0xc00044d630 0xc00044d848 0xc00044d978] [0xc00044d7f0 0xc00044d918] [0x9bf9f0 0x9bf9f0] 0xc000c56420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May  3 13:28:44.409: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May  3 13:28:44.496: INFO: rc: 1
May  3 13:28:44.496: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0016ea690 exit status 1 <nil> <nil> true [0xc00044da50 0xc00044de60 0xc0008bc000] [0xc00044da50 0xc00044de60 0xc0008bc000] [0xc00044dd90 0xc00044df48] [0x9bf9f0 0x9bf9f0] 0xc000c568a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May  3 13:28:54.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 exec --namespace=statefulset-1830 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May  3 13:28:54.580: INFO: rc: 1
May  3 13:28:54.580: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: 
May  3 13:28:54.580: INFO: Scaling statefulset ss to 0
May  3 13:28:54.589: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May  3 13:28:54.592: INFO: Deleting all statefulset in ns statefulset-1830
May  3 13:28:54.597: INFO: Scaling statefulset ss to 0
May  3 13:28:54.607: INFO: Waiting for statefulset status.replicas updated to 0
May  3 13:28:54.612: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:28:54.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1830" for this suite.
May  3 13:29:00.680: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:29:00.765: INFO: namespace statefulset-1830 deletion completed in 6.1050822s

• [SLOW TEST:370.873 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:29:00.767: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May  3 13:29:00.831: INFO: Conformance test suite needs a cluster with at least 2 nodes.
May  3 13:29:00.831: INFO: Create a RollingUpdate DaemonSet
May  3 13:29:00.847: INFO: Check that daemon pods launch on every node of the cluster
May  3 13:29:00.877: INFO: Number of nodes with available pods: 0
May  3 13:29:00.887: INFO: Node docker-desktop is running more than one daemon pod
May  3 13:29:01.917: INFO: Number of nodes with available pods: 0
May  3 13:29:01.917: INFO: Node docker-desktop is running more than one daemon pod
May  3 13:29:02.901: INFO: Number of nodes with available pods: 0
May  3 13:29:02.901: INFO: Node docker-desktop is running more than one daemon pod
May  3 13:29:03.901: INFO: Number of nodes with available pods: 1
May  3 13:29:03.901: INFO: Number of running nodes: 1, number of available pods: 1
May  3 13:29:03.901: INFO: Update the DaemonSet to trigger a rollout
May  3 13:29:03.927: INFO: Updating DaemonSet daemon-set
May  3 13:29:16.953: INFO: Roll back the DaemonSet before rollout is complete
May  3 13:29:16.969: INFO: Updating DaemonSet daemon-set
May  3 13:29:16.969: INFO: Make sure DaemonSet rollback is complete
May  3 13:29:16.986: INFO: Wrong image for pod: daemon-set-dzjhh. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
May  3 13:29:16.986: INFO: Pod daemon-set-dzjhh is not available
May  3 13:29:18.006: INFO: Wrong image for pod: daemon-set-dzjhh. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
May  3 13:29:18.006: INFO: Pod daemon-set-dzjhh is not available
May  3 13:29:19.005: INFO: Wrong image for pod: daemon-set-dzjhh. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
May  3 13:29:19.005: INFO: Pod daemon-set-dzjhh is not available
May  3 13:29:20.012: INFO: Wrong image for pod: daemon-set-dzjhh. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
May  3 13:29:20.012: INFO: Pod daemon-set-dzjhh is not available
May  3 13:29:21.004: INFO: Wrong image for pod: daemon-set-dzjhh. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
May  3 13:29:21.004: INFO: Pod daemon-set-dzjhh is not available
May  3 13:29:22.005: INFO: Wrong image for pod: daemon-set-dzjhh. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
May  3 13:29:22.005: INFO: Pod daemon-set-dzjhh is not available
May  3 13:29:23.009: INFO: Wrong image for pod: daemon-set-dzjhh. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
May  3 13:29:23.009: INFO: Pod daemon-set-dzjhh is not available
May  3 13:29:24.010: INFO: Wrong image for pod: daemon-set-dzjhh. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
May  3 13:29:24.010: INFO: Pod daemon-set-dzjhh is not available
May  3 13:29:25.007: INFO: Wrong image for pod: daemon-set-dzjhh. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
May  3 13:29:25.008: INFO: Pod daemon-set-dzjhh is not available
May  3 13:29:26.004: INFO: Wrong image for pod: daemon-set-dzjhh. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
May  3 13:29:26.004: INFO: Pod daemon-set-dzjhh is not available
May  3 13:29:27.004: INFO: Pod daemon-set-dk5kx is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4102, will wait for the garbage collector to delete the pods
May  3 13:29:27.080: INFO: Deleting DaemonSet.extensions daemon-set took: 5.877ms
May  3 13:29:27.480: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.1995ms
May  3 13:31:06.286: INFO: Number of nodes with available pods: 0
May  3 13:31:06.286: INFO: Number of running nodes: 0, number of available pods: 0
May  3 13:31:06.299: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4102/daemonsets","resourceVersion":"23067"},"items":null}

May  3 13:31:06.314: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4102/pods","resourceVersion":"23067"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:31:06.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4102" for this suite.
May  3 13:31:12.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:31:12.438: INFO: namespace daemonsets-4102 deletion completed in 6.0942025s

• [SLOW TEST:131.671 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:31:12.438: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
STEP: reading a file in the container
May  3 13:31:17.123: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3615 pod-service-account-b853426c-6da7-11e9-a622-a62f37ba3446 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
May  3 13:31:17.354: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3615 pod-service-account-b853426c-6da7-11e9-a622-a62f37ba3446 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
May  3 13:31:17.603: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3615 pod-service-account-b853426c-6da7-11e9-a622-a62f37ba3446 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:31:17.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-3615" for this suite.
May  3 13:31:23.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:31:23.956: INFO: namespace svcaccounts-3615 deletion completed in 6.132447s

• [SLOW TEST:11.518 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:31:23.963: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-bed6c28d-6da7-11e9-a622-a62f37ba3446
STEP: Creating a pod to test consume secrets
May  3 13:31:24.038: INFO: Waiting up to 5m0s for pod "pod-secrets-bed8318e-6da7-11e9-a622-a62f37ba3446" in namespace "secrets-3095" to be "success or failure"
May  3 13:31:24.053: INFO: Pod "pod-secrets-bed8318e-6da7-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 15.7886ms
May  3 13:31:26.056: INFO: Pod "pod-secrets-bed8318e-6da7-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0185758s
STEP: Saw pod success
May  3 13:31:26.056: INFO: Pod "pod-secrets-bed8318e-6da7-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 13:31:26.062: INFO: Trying to get logs from node docker-desktop pod pod-secrets-bed8318e-6da7-11e9-a622-a62f37ba3446 container secret-volume-test: <nil>
STEP: delete the pod
May  3 13:31:26.139: INFO: Waiting for pod pod-secrets-bed8318e-6da7-11e9-a622-a62f37ba3446 to disappear
May  3 13:31:26.152: INFO: Pod pod-secrets-bed8318e-6da7-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:31:26.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3095" for this suite.
May  3 13:31:32.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:31:32.271: INFO: namespace secrets-3095 deletion completed in 6.1162667s

• [SLOW TEST:8.308 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:31:32.271: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
May  3 13:31:32.342: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
May  3 13:31:39.433: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:31:39.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8784" for this suite.
May  3 13:31:45.461: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:31:45.580: INFO: namespace pods-8784 deletion completed in 6.1361892s

• [SLOW TEST:13.310 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:31:45.586: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
May  3 13:31:45.636: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May  3 13:31:45.645: INFO: Waiting for terminating namespaces to be deleted...
May  3 13:31:45.653: INFO: 
Logging pods the kubelet thinks is on node docker-desktop before test
May  3 13:31:45.662: INFO: coredns-fb8b8dccf-nrmdq from kube-system started at 2019-05-03 10:35:24 +0000 UTC (1 container statuses recorded)
May  3 13:31:45.662: INFO: 	Container coredns ready: true, restart count 0
May  3 13:31:45.662: INFO: coredns-fb8b8dccf-qsc86 from kube-system started at 2019-05-03 10:35:24 +0000 UTC (1 container statuses recorded)
May  3 13:31:45.662: INFO: 	Container coredns ready: true, restart count 0
May  3 13:31:45.662: INFO: compose-api-6c5bf98cc7-6gs2q from docker started at 2019-05-03 10:36:34 +0000 UTC (1 container statuses recorded)
May  3 13:31:45.662: INFO: 	Container compose ready: true, restart count 0
May  3 13:31:45.662: INFO: sonobuoy-e2e-job-36cd23f1d2644d64 from heptio-sonobuoy started at 2019-05-03 12:06:54 +0000 UTC (2 container statuses recorded)
May  3 13:31:45.662: INFO: 	Container e2e ready: true, restart count 0
May  3 13:31:45.662: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May  3 13:31:45.662: INFO: kube-apiserver-docker-desktop from kube-system started at <nil> (0 container statuses recorded)
May  3 13:31:45.662: INFO: kube-controller-manager-docker-desktop from kube-system started at <nil> (0 container statuses recorded)
May  3 13:31:45.662: INFO: kube-proxy-gskn5 from kube-system started at 2019-05-03 10:35:24 +0000 UTC (1 container statuses recorded)
May  3 13:31:45.662: INFO: 	Container kube-proxy ready: true, restart count 0
May  3 13:31:45.662: INFO: etcd-docker-desktop from kube-system started at <nil> (0 container statuses recorded)
May  3 13:31:45.662: INFO: kube-scheduler-docker-desktop from kube-system started at <nil> (0 container statuses recorded)
May  3 13:31:45.662: INFO: sonobuoy from heptio-sonobuoy started at 2019-05-03 12:06:48 +0000 UTC (1 container statuses recorded)
May  3 13:31:45.662: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May  3 13:31:45.662: INFO: compose-6b69ff6b9d-7blnv from docker started at 2019-05-03 10:36:34 +0000 UTC (1 container statuses recorded)
May  3 13:31:45.662: INFO: 	Container compose ready: true, restart count 0
May  3 13:31:45.662: INFO: sonobuoy-systemd-logs-daemon-set-605fe68f13894439-lg7rb from heptio-sonobuoy started at 2019-05-03 12:06:54 +0000 UTC (2 container statuses recorded)
May  3 13:31:45.662: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May  3 13:31:45.662: INFO: 	Container systemd-logs ready: false, restart count 21
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.159b2f7bf8fff060], Reason = [FailedScheduling], Message = [0/1 nodes are available: 1 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:31:46.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3970" for this suite.
May  3 13:31:52.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:31:52.816: INFO: namespace sched-pred-3970 deletion completed in 6.111483s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.230 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:31:52.816: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-d0074fdc-6da7-11e9-a622-a62f37ba3446
STEP: Creating a pod to test consume secrets
May  3 13:31:52.916: INFO: Waiting up to 5m0s for pod "pod-secrets-d00e6bf1-6da7-11e9-a622-a62f37ba3446" in namespace "secrets-8299" to be "success or failure"
May  3 13:31:52.939: INFO: Pod "pod-secrets-d00e6bf1-6da7-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 23.6121ms
May  3 13:31:54.959: INFO: Pod "pod-secrets-d00e6bf1-6da7-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.043032s
STEP: Saw pod success
May  3 13:31:54.959: INFO: Pod "pod-secrets-d00e6bf1-6da7-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 13:31:54.966: INFO: Trying to get logs from node docker-desktop pod pod-secrets-d00e6bf1-6da7-11e9-a622-a62f37ba3446 container secret-volume-test: <nil>
STEP: delete the pod
May  3 13:31:55.018: INFO: Waiting for pod pod-secrets-d00e6bf1-6da7-11e9-a622-a62f37ba3446 to disappear
May  3 13:31:55.025: INFO: Pod pod-secrets-d00e6bf1-6da7-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:31:55.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8299" for this suite.
May  3 13:32:01.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:32:01.157: INFO: namespace secrets-8299 deletion completed in 6.1175347s
STEP: Destroying namespace "secret-namespace-4208" for this suite.
May  3 13:32:07.172: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:32:07.272: INFO: namespace secret-namespace-4208 deletion completed in 6.114994s

• [SLOW TEST:14.456 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:32:07.273: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
May  3 13:32:07.336: INFO: Waiting up to 5m0s for pod "downward-api-d8a61e5f-6da7-11e9-a622-a62f37ba3446" in namespace "downward-api-132" to be "success or failure"
May  3 13:32:07.351: INFO: Pod "downward-api-d8a61e5f-6da7-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 14.9832ms
May  3 13:32:09.364: INFO: Pod "downward-api-d8a61e5f-6da7-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0282806s
STEP: Saw pod success
May  3 13:32:09.365: INFO: Pod "downward-api-d8a61e5f-6da7-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 13:32:09.392: INFO: Trying to get logs from node docker-desktop pod downward-api-d8a61e5f-6da7-11e9-a622-a62f37ba3446 container dapi-container: <nil>
STEP: delete the pod
May  3 13:32:09.446: INFO: Waiting for pod downward-api-d8a61e5f-6da7-11e9-a622-a62f37ba3446 to disappear
May  3 13:32:09.453: INFO: Pod downward-api-d8a61e5f-6da7-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:32:09.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-132" for this suite.
May  3 13:32:15.501: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:32:15.601: INFO: namespace downward-api-132 deletion completed in 6.1225826s

• [SLOW TEST:8.328 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:32:15.601: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
May  3 13:32:15.638: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:32:21.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5870" for this suite.
May  3 13:32:43.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:32:43.834: INFO: namespace init-container-5870 deletion completed in 22.136766s

• [SLOW TEST:28.232 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:32:43.834: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-projected-all-test-volume-ee7081fe-6da7-11e9-a622-a62f37ba3446
STEP: Creating secret with name secret-projected-all-test-volume-ee7081e2-6da7-11e9-a622-a62f37ba3446
STEP: Creating a pod to test Check all projections for projected volume plugin
May  3 13:32:43.920: INFO: Waiting up to 5m0s for pod "projected-volume-ee7081aa-6da7-11e9-a622-a62f37ba3446" in namespace "projected-718" to be "success or failure"
May  3 13:32:43.945: INFO: Pod "projected-volume-ee7081aa-6da7-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 24.9631ms
May  3 13:32:45.951: INFO: Pod "projected-volume-ee7081aa-6da7-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0306774s
May  3 13:32:47.959: INFO: Pod "projected-volume-ee7081aa-6da7-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038309s
STEP: Saw pod success
May  3 13:32:47.959: INFO: Pod "projected-volume-ee7081aa-6da7-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 13:32:47.985: INFO: Trying to get logs from node docker-desktop pod projected-volume-ee7081aa-6da7-11e9-a622-a62f37ba3446 container projected-all-volume-test: <nil>
STEP: delete the pod
May  3 13:32:48.035: INFO: Waiting for pod projected-volume-ee7081aa-6da7-11e9-a622-a62f37ba3446 to disappear
May  3 13:32:48.040: INFO: Pod projected-volume-ee7081aa-6da7-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:32:48.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-718" for this suite.
May  3 13:32:54.063: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:32:54.282: INFO: namespace projected-718 deletion completed in 6.2323463s

• [SLOW TEST:10.448 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:32:54.282: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-f4ac3aac-6da7-11e9-a622-a62f37ba3446
STEP: Creating a pod to test consume secrets
May  3 13:32:54.360: INFO: Waiting up to 5m0s for pod "pod-secrets-f4ad7ac5-6da7-11e9-a622-a62f37ba3446" in namespace "secrets-9984" to be "success or failure"
May  3 13:32:54.368: INFO: Pod "pod-secrets-f4ad7ac5-6da7-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 8.007ms
May  3 13:32:56.376: INFO: Pod "pod-secrets-f4ad7ac5-6da7-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0167084s
May  3 13:32:58.381: INFO: Pod "pod-secrets-f4ad7ac5-6da7-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0209403s
STEP: Saw pod success
May  3 13:32:58.381: INFO: Pod "pod-secrets-f4ad7ac5-6da7-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 13:32:58.393: INFO: Trying to get logs from node docker-desktop pod pod-secrets-f4ad7ac5-6da7-11e9-a622-a62f37ba3446 container secret-volume-test: <nil>
STEP: delete the pod
May  3 13:32:58.444: INFO: Waiting for pod pod-secrets-f4ad7ac5-6da7-11e9-a622-a62f37ba3446 to disappear
May  3 13:32:58.454: INFO: Pod pod-secrets-f4ad7ac5-6da7-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:32:58.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9984" for this suite.
May  3 13:33:04.488: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:33:04.587: INFO: namespace secrets-9984 deletion completed in 6.1199449s

• [SLOW TEST:10.305 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:33:04.588: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test hostPath mode
May  3 13:33:04.695: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-3726" to be "success or failure"
May  3 13:33:04.705: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 9.8469ms
May  3 13:33:06.710: INFO: Pod "pod-host-path-test": Phase="Running", Reason="", readiness=false. Elapsed: 2.0149616s
May  3 13:33:08.712: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0175187s
STEP: Saw pod success
May  3 13:33:08.712: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
May  3 13:33:08.714: INFO: Trying to get logs from node docker-desktop pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
May  3 13:33:08.744: INFO: Waiting for pod pod-host-path-test to disappear
May  3 13:33:08.749: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:33:08.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-3726" for this suite.
May  3 13:33:14.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:33:14.874: INFO: namespace hostpath-3726 deletion completed in 6.1130344s

• [SLOW TEST:10.286 seconds]
[sig-storage] HostPath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:33:14.874: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
May  3 13:33:14.937: INFO: Waiting up to 5m0s for pod "downward-api-00f05845-6da8-11e9-a622-a62f37ba3446" in namespace "downward-api-2851" to be "success or failure"
May  3 13:33:14.947: INFO: Pod "downward-api-00f05845-6da8-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 9.9221ms
May  3 13:33:16.967: INFO: Pod "downward-api-00f05845-6da8-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0296057s
STEP: Saw pod success
May  3 13:33:16.967: INFO: Pod "downward-api-00f05845-6da8-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 13:33:16.969: INFO: Trying to get logs from node docker-desktop pod downward-api-00f05845-6da8-11e9-a622-a62f37ba3446 container dapi-container: <nil>
STEP: delete the pod
May  3 13:33:17.005: INFO: Waiting for pod downward-api-00f05845-6da8-11e9-a622-a62f37ba3446 to disappear
May  3 13:33:17.017: INFO: Pod downward-api-00f05845-6da8-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:33:17.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2851" for this suite.
May  3 13:33:23.063: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:33:23.168: INFO: namespace downward-api-2851 deletion completed in 6.14462s

• [SLOW TEST:8.294 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:33:23.170: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0503 13:33:33.288852      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May  3 13:33:33.289: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:33:33.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8058" for this suite.
May  3 13:33:39.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:33:39.622: INFO: namespace gc-8058 deletion completed in 6.1835101s

• [SLOW TEST:16.452 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:33:39.625: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-0fb083c0-6da8-11e9-a622-a62f37ba3446
STEP: Creating a pod to test consume configMaps
May  3 13:33:39.694: INFO: Waiting up to 5m0s for pod "pod-configmaps-0fb2b7dc-6da8-11e9-a622-a62f37ba3446" in namespace "configmap-8143" to be "success or failure"
May  3 13:33:39.703: INFO: Pod "pod-configmaps-0fb2b7dc-6da8-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 8.812ms
May  3 13:33:41.709: INFO: Pod "pod-configmaps-0fb2b7dc-6da8-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0147181s
May  3 13:33:43.715: INFO: Pod "pod-configmaps-0fb2b7dc-6da8-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0205112s
STEP: Saw pod success
May  3 13:33:43.715: INFO: Pod "pod-configmaps-0fb2b7dc-6da8-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 13:33:43.732: INFO: Trying to get logs from node docker-desktop pod pod-configmaps-0fb2b7dc-6da8-11e9-a622-a62f37ba3446 container configmap-volume-test: <nil>
STEP: delete the pod
May  3 13:33:43.780: INFO: Waiting for pod pod-configmaps-0fb2b7dc-6da8-11e9-a622-a62f37ba3446 to disappear
May  3 13:33:43.786: INFO: Pod pod-configmaps-0fb2b7dc-6da8-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:33:43.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8143" for this suite.
May  3 13:33:49.816: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:33:49.922: INFO: namespace configmap-8143 deletion completed in 6.1264544s

• [SLOW TEST:10.296 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:33:49.927: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override all
May  3 13:33:50.004: INFO: Waiting up to 5m0s for pod "client-containers-15d75e3d-6da8-11e9-a622-a62f37ba3446" in namespace "containers-4711" to be "success or failure"
May  3 13:33:50.024: INFO: Pod "client-containers-15d75e3d-6da8-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 19.1793ms
May  3 13:33:52.032: INFO: Pod "client-containers-15d75e3d-6da8-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0273986s
May  3 13:33:54.037: INFO: Pod "client-containers-15d75e3d-6da8-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032374s
STEP: Saw pod success
May  3 13:33:54.037: INFO: Pod "client-containers-15d75e3d-6da8-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 13:33:54.057: INFO: Trying to get logs from node docker-desktop pod client-containers-15d75e3d-6da8-11e9-a622-a62f37ba3446 container test-container: <nil>
STEP: delete the pod
May  3 13:33:54.096: INFO: Waiting for pod client-containers-15d75e3d-6da8-11e9-a622-a62f37ba3446 to disappear
May  3 13:33:54.104: INFO: Pod client-containers-15d75e3d-6da8-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:33:54.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-4711" for this suite.
May  3 13:34:00.129: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:34:00.245: INFO: namespace containers-4711 deletion completed in 6.1338184s

• [SLOW TEST:10.319 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:34:00.246: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0503 13:34:10.405959      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May  3 13:34:10.406: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:34:10.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9510" for this suite.
May  3 13:34:16.431: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:34:16.589: INFO: namespace gc-9510 deletion completed in 6.1712151s

• [SLOW TEST:16.343 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:34:16.590: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap that has name configmap-test-emptyKey-25be9e97-6da8-11e9-a622-a62f37ba3446
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:34:16.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-900" for this suite.
May  3 13:34:22.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:34:22.852: INFO: namespace configmap-900 deletion completed in 6.1653149s

• [SLOW TEST:6.262 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:34:22.853: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
May  3 13:34:22.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 create -f - --namespace=kubectl-2766'
May  3 13:34:23.349: INFO: stderr: ""
May  3 13:34:23.349: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
May  3 13:34:24.353: INFO: Selector matched 1 pods for map[app:redis]
May  3 13:34:24.354: INFO: Found 0 / 1
May  3 13:34:25.356: INFO: Selector matched 1 pods for map[app:redis]
May  3 13:34:25.356: INFO: Found 1 / 1
May  3 13:34:25.356: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
May  3 13:34:25.364: INFO: Selector matched 1 pods for map[app:redis]
May  3 13:34:25.364: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May  3 13:34:25.367: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-343589126 patch pod redis-master-77q4q --namespace=kubectl-2766 -p {"metadata":{"annotations":{"x":"y"}}}'
May  3 13:34:25.449: INFO: stderr: ""
May  3 13:34:25.449: INFO: stdout: "pod/redis-master-77q4q patched\n"
STEP: checking annotations
May  3 13:34:25.453: INFO: Selector matched 1 pods for map[app:redis]
May  3 13:34:25.453: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:34:25.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2766" for this suite.
May  3 13:34:47.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:34:47.607: INFO: namespace kubectl-2766 deletion completed in 22.1428016s

• [SLOW TEST:24.754 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:34:47.608: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting the proxy server
May  3 13:34:47.654: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-343589126 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:34:47.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5204" for this suite.
May  3 13:34:53.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:34:53.880: INFO: namespace kubectl-5204 deletion completed in 6.1205233s

• [SLOW TEST:6.272 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:34:53.884: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-3bf3b6f5-6da8-11e9-a622-a62f37ba3446
STEP: Creating a pod to test consume secrets
May  3 13:34:53.954: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3bf5a7e8-6da8-11e9-a622-a62f37ba3446" in namespace "projected-8127" to be "success or failure"
May  3 13:34:53.968: INFO: Pod "pod-projected-secrets-3bf5a7e8-6da8-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 13.5114ms
May  3 13:34:55.975: INFO: Pod "pod-projected-secrets-3bf5a7e8-6da8-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020595s
STEP: Saw pod success
May  3 13:34:55.975: INFO: Pod "pod-projected-secrets-3bf5a7e8-6da8-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 13:34:55.977: INFO: Trying to get logs from node docker-desktop pod pod-projected-secrets-3bf5a7e8-6da8-11e9-a622-a62f37ba3446 container projected-secret-volume-test: <nil>
STEP: delete the pod
May  3 13:34:56.060: INFO: Waiting for pod pod-projected-secrets-3bf5a7e8-6da8-11e9-a622-a62f37ba3446 to disappear
May  3 13:34:56.074: INFO: Pod pod-projected-secrets-3bf5a7e8-6da8-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:34:56.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8127" for this suite.
May  3 13:35:02.144: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:35:02.241: INFO: namespace projected-8127 deletion completed in 6.1242517s

• [SLOW TEST:8.357 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:35:02.243: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-40f10040-6da8-11e9-a622-a62f37ba3446
STEP: Creating configMap with name cm-test-opt-upd-40f10072-6da8-11e9-a622-a62f37ba3446
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-40f10040-6da8-11e9-a622-a62f37ba3446
STEP: Updating configmap cm-test-opt-upd-40f10072-6da8-11e9-a622-a62f37ba3446
STEP: Creating configMap with name cm-test-opt-create-40f10086-6da8-11e9-a622-a62f37ba3446
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:35:08.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1925" for this suite.
May  3 13:35:30.461: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:35:30.551: INFO: namespace projected-1925 deletion completed in 22.1179122s

• [SLOW TEST:28.308 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:35:30.563: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
May  3 13:35:30.675: INFO: Number of nodes with available pods: 0
May  3 13:35:30.675: INFO: Node docker-desktop is running more than one daemon pod
May  3 13:35:31.681: INFO: Number of nodes with available pods: 0
May  3 13:35:31.681: INFO: Node docker-desktop is running more than one daemon pod
May  3 13:35:32.700: INFO: Number of nodes with available pods: 0
May  3 13:35:32.700: INFO: Node docker-desktop is running more than one daemon pod
May  3 13:35:33.691: INFO: Number of nodes with available pods: 0
May  3 13:35:33.691: INFO: Node docker-desktop is running more than one daemon pod
May  3 13:35:34.687: INFO: Number of nodes with available pods: 1
May  3 13:35:34.688: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
May  3 13:35:34.724: INFO: Number of nodes with available pods: 1
May  3 13:35:34.724: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3672, will wait for the garbage collector to delete the pods
May  3 13:35:35.798: INFO: Deleting DaemonSet.extensions daemon-set took: 6.1425ms
May  3 13:35:36.204: INFO: Terminating DaemonSet.extensions daemon-set pods took: 405.6017ms
May  3 13:35:46.308: INFO: Number of nodes with available pods: 0
May  3 13:35:46.308: INFO: Number of running nodes: 0, number of available pods: 0
May  3 13:35:46.312: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3672/daemonsets","resourceVersion":"24229"},"items":null}

May  3 13:35:46.315: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3672/pods","resourceVersion":"24229"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:35:46.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3672" for this suite.
May  3 13:35:52.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:35:52.451: INFO: namespace daemonsets-3672 deletion completed in 6.1153905s

• [SLOW TEST:21.889 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:35:52.457: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May  3 13:35:52.504: INFO: Creating deployment "test-recreate-deployment"
May  3 13:35:52.517: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
May  3 13:35:52.555: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
May  3 13:35:54.584: INFO: Waiting deployment "test-recreate-deployment" to complete
May  3 13:35:54.602: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692487352, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692487352, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692487352, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692487352, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d57d5ff7c\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  3 13:35:56.607: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
May  3 13:35:56.625: INFO: Updating deployment test-recreate-deployment
May  3 13:35:56.625: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May  3 13:35:56.766: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-8079,SelfLink:/apis/apps/v1/namespaces/deployment-8079/deployments/test-recreate-deployment,UID:5edf1237-6da8-11e9-9efa-00155da4710f,ResourceVersion:24304,Generation:2,CreationTimestamp:2019-05-03 13:35:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-05-03 13:35:56 +0000 UTC 2019-05-03 13:35:56 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-05-03 13:35:56 +0000 UTC 2019-05-03 13:35:52 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-c9cbd8684" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

May  3 13:35:56.773: INFO: New ReplicaSet "test-recreate-deployment-c9cbd8684" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-c9cbd8684,GenerateName:,Namespace:deployment-8079,SelfLink:/apis/apps/v1/namespaces/deployment-8079/replicasets/test-recreate-deployment-c9cbd8684,UID:615e7e7f-6da8-11e9-9efa-00155da4710f,ResourceVersion:24301,Generation:1,CreationTimestamp:2019-05-03 13:35:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 5edf1237-6da8-11e9-9efa-00155da4710f 0xc0000c1700 0xc0000c1701}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May  3 13:35:56.773: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
May  3 13:35:56.773: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7d57d5ff7c,GenerateName:,Namespace:deployment-8079,SelfLink:/apis/apps/v1/namespaces/deployment-8079/replicasets/test-recreate-deployment-7d57d5ff7c,UID:5edfd3aa-6da8-11e9-9efa-00155da4710f,ResourceVersion:24293,Generation:2,CreationTimestamp:2019-05-03 13:35:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 5edf1237-6da8-11e9-9efa-00155da4710f 0xc0000c15e7 0xc0000c15e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May  3 13:35:56.792: INFO: Pod "test-recreate-deployment-c9cbd8684-hvvm9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-c9cbd8684-hvvm9,GenerateName:test-recreate-deployment-c9cbd8684-,Namespace:deployment-8079,SelfLink:/api/v1/namespaces/deployment-8079/pods/test-recreate-deployment-c9cbd8684-hvvm9,UID:615f328c-6da8-11e9-9efa-00155da4710f,ResourceVersion:24303,Generation:0,CreationTimestamp:2019-05-03 13:35:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-c9cbd8684 615e7e7f-6da8-11e9-9efa-00155da4710f 0xc000d43a90 0xc000d43a91}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-cnns6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cnns6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-cnns6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000d43b00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000d43b20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:35:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:35:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:35:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:35:56 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:,StartTime:2019-05-03 13:35:56 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:35:56.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8079" for this suite.
May  3 13:36:02.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:36:02.923: INFO: namespace deployment-8079 deletion completed in 6.1072423s

• [SLOW TEST:10.467 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:36:02.924: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-651a4aaf-6da8-11e9-a622-a62f37ba3446
STEP: Creating a pod to test consume configMaps
May  3 13:36:03.001: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-651b966a-6da8-11e9-a622-a62f37ba3446" in namespace "projected-7304" to be "success or failure"
May  3 13:36:03.013: INFO: Pod "pod-projected-configmaps-651b966a-6da8-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 11.8923ms
May  3 13:36:05.017: INFO: Pod "pod-projected-configmaps-651b966a-6da8-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0156255s
STEP: Saw pod success
May  3 13:36:05.017: INFO: Pod "pod-projected-configmaps-651b966a-6da8-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 13:36:05.021: INFO: Trying to get logs from node docker-desktop pod pod-projected-configmaps-651b966a-6da8-11e9-a622-a62f37ba3446 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May  3 13:36:05.058: INFO: Waiting for pod pod-projected-configmaps-651b966a-6da8-11e9-a622-a62f37ba3446 to disappear
May  3 13:36:05.066: INFO: Pod pod-projected-configmaps-651b966a-6da8-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:36:05.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7304" for this suite.
May  3 13:36:11.096: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:36:11.192: INFO: namespace projected-7304 deletion completed in 6.1164925s

• [SLOW TEST:8.269 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:36:11.193: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test use defaults
May  3 13:36:11.251: INFO: Waiting up to 5m0s for pod "client-containers-6a07e48f-6da8-11e9-a622-a62f37ba3446" in namespace "containers-5142" to be "success or failure"
May  3 13:36:11.264: INFO: Pod "client-containers-6a07e48f-6da8-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 13.0483ms
May  3 13:36:13.266: INFO: Pod "client-containers-6a07e48f-6da8-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0155289s
STEP: Saw pod success
May  3 13:36:13.267: INFO: Pod "client-containers-6a07e48f-6da8-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 13:36:13.270: INFO: Trying to get logs from node docker-desktop pod client-containers-6a07e48f-6da8-11e9-a622-a62f37ba3446 container test-container: <nil>
STEP: delete the pod
May  3 13:36:13.295: INFO: Waiting for pod client-containers-6a07e48f-6da8-11e9-a622-a62f37ba3446 to disappear
May  3 13:36:13.305: INFO: Pod client-containers-6a07e48f-6da8-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:36:13.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5142" for this suite.
May  3 13:36:19.331: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:36:19.457: INFO: namespace containers-5142 deletion completed in 6.13945s

• [SLOW TEST:8.264 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:36:19.457: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on tmpfs
May  3 13:36:19.559: INFO: Waiting up to 5m0s for pod "pod-6efc4180-6da8-11e9-a622-a62f37ba3446" in namespace "emptydir-5281" to be "success or failure"
May  3 13:36:19.571: INFO: Pod "pod-6efc4180-6da8-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 11.5358ms
May  3 13:36:21.578: INFO: Pod "pod-6efc4180-6da8-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0180366s
STEP: Saw pod success
May  3 13:36:21.578: INFO: Pod "pod-6efc4180-6da8-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 13:36:21.587: INFO: Trying to get logs from node docker-desktop pod pod-6efc4180-6da8-11e9-a622-a62f37ba3446 container test-container: <nil>
STEP: delete the pod
May  3 13:36:21.642: INFO: Waiting for pod pod-6efc4180-6da8-11e9-a622-a62f37ba3446 to disappear
May  3 13:36:21.657: INFO: Pod pod-6efc4180-6da8-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:36:21.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5281" for this suite.
May  3 13:36:27.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:36:27.789: INFO: namespace emptydir-5281 deletion completed in 6.1241969s

• [SLOW TEST:8.332 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:36:27.789: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:36:29.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7306" for this suite.
May  3 13:37:19.894: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:37:19.991: INFO: namespace kubelet-test-7306 deletion completed in 50.1124067s

• [SLOW TEST:52.202 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a read only busybox container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:37:19.996: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-nxnx
STEP: Creating a pod to test atomic-volume-subpath
May  3 13:37:20.065: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-nxnx" in namespace "subpath-6456" to be "success or failure"
May  3 13:37:20.089: INFO: Pod "pod-subpath-test-configmap-nxnx": Phase="Pending", Reason="", readiness=false. Elapsed: 24.3067ms
May  3 13:37:22.097: INFO: Pod "pod-subpath-test-configmap-nxnx": Phase="Running", Reason="", readiness=true. Elapsed: 2.031885s
May  3 13:37:24.102: INFO: Pod "pod-subpath-test-configmap-nxnx": Phase="Running", Reason="", readiness=true. Elapsed: 4.0367529s
May  3 13:37:26.104: INFO: Pod "pod-subpath-test-configmap-nxnx": Phase="Running", Reason="", readiness=true. Elapsed: 6.0394059s
May  3 13:37:28.109: INFO: Pod "pod-subpath-test-configmap-nxnx": Phase="Running", Reason="", readiness=true. Elapsed: 8.0441625s
May  3 13:37:30.118: INFO: Pod "pod-subpath-test-configmap-nxnx": Phase="Running", Reason="", readiness=true. Elapsed: 10.0528091s
May  3 13:37:32.123: INFO: Pod "pod-subpath-test-configmap-nxnx": Phase="Running", Reason="", readiness=true. Elapsed: 12.0581801s
May  3 13:37:34.127: INFO: Pod "pod-subpath-test-configmap-nxnx": Phase="Running", Reason="", readiness=true. Elapsed: 14.0626174s
May  3 13:37:36.138: INFO: Pod "pod-subpath-test-configmap-nxnx": Phase="Running", Reason="", readiness=true. Elapsed: 16.0731559s
May  3 13:37:38.146: INFO: Pod "pod-subpath-test-configmap-nxnx": Phase="Running", Reason="", readiness=true. Elapsed: 18.0811429s
May  3 13:37:40.154: INFO: Pod "pod-subpath-test-configmap-nxnx": Phase="Running", Reason="", readiness=true. Elapsed: 20.089409s
May  3 13:37:42.162: INFO: Pod "pod-subpath-test-configmap-nxnx": Phase="Running", Reason="", readiness=true. Elapsed: 22.0974708s
May  3 13:37:44.167: INFO: Pod "pod-subpath-test-configmap-nxnx": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.1022451s
STEP: Saw pod success
May  3 13:37:44.167: INFO: Pod "pod-subpath-test-configmap-nxnx" satisfied condition "success or failure"
May  3 13:37:44.177: INFO: Trying to get logs from node docker-desktop pod pod-subpath-test-configmap-nxnx container test-container-subpath-configmap-nxnx: <nil>
STEP: delete the pod
May  3 13:37:44.241: INFO: Waiting for pod pod-subpath-test-configmap-nxnx to disappear
May  3 13:37:44.249: INFO: Pod pod-subpath-test-configmap-nxnx no longer exists
STEP: Deleting pod pod-subpath-test-configmap-nxnx
May  3 13:37:44.249: INFO: Deleting pod "pod-subpath-test-configmap-nxnx" in namespace "subpath-6456"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:37:44.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6456" for this suite.
May  3 13:37:50.274: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:37:50.359: INFO: namespace subpath-6456 deletion completed in 6.0963474s

• [SLOW TEST:30.364 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:37:50.370: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating replication controller my-hostname-basic-a5263aa9-6da8-11e9-a622-a62f37ba3446
May  3 13:37:50.443: INFO: Pod name my-hostname-basic-a5263aa9-6da8-11e9-a622-a62f37ba3446: Found 1 pods out of 1
May  3 13:37:50.443: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-a5263aa9-6da8-11e9-a622-a62f37ba3446" are running
May  3 13:37:54.476: INFO: Pod "my-hostname-basic-a5263aa9-6da8-11e9-a622-a62f37ba3446-55bkv" is running (conditions: [])
May  3 13:37:54.476: INFO: Trying to dial the pod
May  3 13:37:59.496: INFO: Controller my-hostname-basic-a5263aa9-6da8-11e9-a622-a62f37ba3446: Got expected result from replica 1 [my-hostname-basic-a5263aa9-6da8-11e9-a622-a62f37ba3446-55bkv]: "my-hostname-basic-a5263aa9-6da8-11e9-a622-a62f37ba3446-55bkv", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:37:59.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4936" for this suite.
May  3 13:38:05.545: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:38:05.648: INFO: namespace replication-controller-4936 deletion completed in 6.137948s

• [SLOW TEST:15.279 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:38:05.658: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:38:09.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-917" for this suite.
May  3 13:38:59.778: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:38:59.899: INFO: namespace kubelet-test-917 deletion completed in 50.1409333s

• [SLOW TEST:54.243 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:38:59.900: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May  3 13:38:59.961: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ce96d0c9-6da8-11e9-a622-a62f37ba3446" in namespace "downward-api-6347" to be "success or failure"
May  3 13:38:59.967: INFO: Pod "downwardapi-volume-ce96d0c9-6da8-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 6.0232ms
May  3 13:39:01.972: INFO: Pod "downwardapi-volume-ce96d0c9-6da8-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0106008s
May  3 13:39:03.980: INFO: Pod "downwardapi-volume-ce96d0c9-6da8-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0184417s
STEP: Saw pod success
May  3 13:39:03.980: INFO: Pod "downwardapi-volume-ce96d0c9-6da8-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 13:39:03.999: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-ce96d0c9-6da8-11e9-a622-a62f37ba3446 container client-container: <nil>
STEP: delete the pod
May  3 13:39:04.040: INFO: Waiting for pod downwardapi-volume-ce96d0c9-6da8-11e9-a622-a62f37ba3446 to disappear
May  3 13:39:04.051: INFO: Pod downwardapi-volume-ce96d0c9-6da8-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:39:04.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6347" for this suite.
May  3 13:39:10.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:39:10.205: INFO: namespace downward-api-6347 deletion completed in 6.1371958s

• [SLOW TEST:10.305 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:39:10.205: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
May  3 13:39:12.853: INFO: Successfully updated pod "pod-update-d4c36d99-6da8-11e9-a622-a62f37ba3446"
STEP: verifying the updated pod is in kubernetes
May  3 13:39:12.870: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:39:12.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8394" for this suite.
May  3 13:39:34.919: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:39:35.023: INFO: namespace pods-8394 deletion completed in 22.1280836s

• [SLOW TEST:24.819 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:39:35.024: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
May  3 13:39:35.083: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e385d0cf-6da8-11e9-a622-a62f37ba3446" in namespace "projected-3673" to be "success or failure"
May  3 13:39:35.103: INFO: Pod "downwardapi-volume-e385d0cf-6da8-11e9-a622-a62f37ba3446": Phase="Pending", Reason="", readiness=false. Elapsed: 5.9688ms
May  3 13:39:37.110: INFO: Pod "downwardapi-volume-e385d0cf-6da8-11e9-a622-a62f37ba3446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0124341s
STEP: Saw pod success
May  3 13:39:37.110: INFO: Pod "downwardapi-volume-e385d0cf-6da8-11e9-a622-a62f37ba3446" satisfied condition "success or failure"
May  3 13:39:37.114: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-e385d0cf-6da8-11e9-a622-a62f37ba3446 container client-container: <nil>
STEP: delete the pod
May  3 13:39:37.138: INFO: Waiting for pod downwardapi-volume-e385d0cf-6da8-11e9-a622-a62f37ba3446 to disappear
May  3 13:39:37.143: INFO: Pod downwardapi-volume-e385d0cf-6da8-11e9-a622-a62f37ba3446 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:39:37.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3673" for this suite.
May  3 13:39:43.199: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:39:43.296: INFO: namespace projected-3673 deletion completed in 6.1377528s

• [SLOW TEST:8.272 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:39:43.296: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
May  3 13:39:45.916: INFO: Successfully updated pod "annotationupdatee8747f4d-6da8-11e9-a622-a62f37ba3446"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:39:47.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7466" for this suite.
May  3 13:40:09.970: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:40:10.056: INFO: namespace projected-7466 deletion completed in 22.0985719s

• [SLOW TEST:26.760 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:40:10.056: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
May  3 13:40:10.117: INFO: Pod name rollover-pod: Found 0 pods out of 1
May  3 13:40:15.126: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May  3 13:40:15.126: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
May  3 13:40:17.131: INFO: Creating deployment "test-rollover-deployment"
May  3 13:40:17.147: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
May  3 13:40:19.169: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
May  3 13:40:19.189: INFO: Ensure that both replica sets have 1 created replica
May  3 13:40:19.216: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
May  3 13:40:19.249: INFO: Updating deployment test-rollover-deployment
May  3 13:40:19.249: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
May  3 13:40:21.283: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
May  3 13:40:21.289: INFO: Make sure deployment "test-rollover-deployment" is complete
May  3 13:40:21.299: INFO: all replica sets need to contain the pod-template-hash label
May  3 13:40:21.299: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692487617, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692487617, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692487619, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692487617, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  3 13:40:23.307: INFO: all replica sets need to contain the pod-template-hash label
May  3 13:40:23.308: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692487617, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692487617, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692487621, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692487617, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  3 13:40:25.310: INFO: all replica sets need to contain the pod-template-hash label
May  3 13:40:25.310: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692487617, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692487617, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692487621, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692487617, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  3 13:40:27.315: INFO: all replica sets need to contain the pod-template-hash label
May  3 13:40:27.316: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692487617, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692487617, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692487621, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692487617, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  3 13:40:29.308: INFO: all replica sets need to contain the pod-template-hash label
May  3 13:40:29.311: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692487617, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692487617, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692487621, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692487617, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  3 13:40:31.312: INFO: all replica sets need to contain the pod-template-hash label
May  3 13:40:31.312: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692487617, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692487617, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692487621, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692487617, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  3 13:40:33.307: INFO: 
May  3 13:40:33.307: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May  3 13:40:33.329: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-3639,SelfLink:/apis/apps/v1/namespaces/deployment-3639/deployments/test-rollover-deployment,UID:fc997709-6da8-11e9-9efa-00155da4710f,ResourceVersion:25027,Generation:2,CreationTimestamp:2019-05-03 13:40:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-05-03 13:40:17 +0000 UTC 2019-05-03 13:40:17 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-05-03 13:40:31 +0000 UTC 2019-05-03 13:40:17 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-766b4d6c9d" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

May  3 13:40:33.345: INFO: New ReplicaSet "test-rollover-deployment-766b4d6c9d" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-766b4d6c9d,GenerateName:,Namespace:deployment-3639,SelfLink:/apis/apps/v1/namespaces/deployment-3639/replicasets/test-rollover-deployment-766b4d6c9d,UID:fdd9fe38-6da8-11e9-9efa-00155da4710f,ResourceVersion:25016,Generation:2,CreationTimestamp:2019-05-03 13:40:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment fc997709-6da8-11e9-9efa-00155da4710f 0xc003fcdd07 0xc003fcdd08}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
May  3 13:40:33.345: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
May  3 13:40:33.345: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-3639,SelfLink:/apis/apps/v1/namespaces/deployment-3639/replicasets/test-rollover-controller,UID:f867dfd5-6da8-11e9-9efa-00155da4710f,ResourceVersion:25026,Generation:2,CreationTimestamp:2019-05-03 13:40:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment fc997709-6da8-11e9-9efa-00155da4710f 0xc003fcdb57 0xc003fcdb58}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May  3 13:40:33.346: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6455657675,GenerateName:,Namespace:deployment-3639,SelfLink:/apis/apps/v1/namespaces/deployment-3639/replicasets/test-rollover-deployment-6455657675,UID:fc9e7361-6da8-11e9-9efa-00155da4710f,ResourceVersion:24992,Generation:2,CreationTimestamp:2019-05-03 13:40:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment fc997709-6da8-11e9-9efa-00155da4710f 0xc003fcdc27 0xc003fcdc28}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May  3 13:40:33.361: INFO: Pod "test-rollover-deployment-766b4d6c9d-fskff" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-766b4d6c9d-fskff,GenerateName:test-rollover-deployment-766b4d6c9d-,Namespace:deployment-3639,SelfLink:/api/v1/namespaces/deployment-3639/pods/test-rollover-deployment-766b4d6c9d-fskff,UID:fdf05745-6da8-11e9-9efa-00155da4710f,ResourceVersion:25000,Generation:0,CreationTimestamp:2019-05-03 13:40:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-766b4d6c9d fdd9fe38-6da8-11e9-9efa-00155da4710f 0xc001930fa7 0xc001930fa8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9mswg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9mswg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-9mswg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0019311a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001931210}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:40:19 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:40:21 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:40:21 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-03 13:40:19 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.1.84,StartTime:2019-05-03 13:40:19 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-05-03 13:40:21 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://90eab56a1814cc127c26aa01bbd60218979c8cdfe65284ad71d8b93e328c7ac3}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:40:33.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3639" for this suite.
May  3 13:40:39.398: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:40:39.538: INFO: namespace deployment-3639 deletion completed in 6.1639579s

• [SLOW TEST:29.482 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
May  3 13:40:39.539: INFO: >>> kubeConfig: /tmp/kubeconfig-343589126
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
May  3 13:40:42.633: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May  3 13:40:42.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-3456" for this suite.
May  3 13:41:04.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May  3 13:41:04.815: INFO: namespace replicaset-3456 deletion completed in 22.1425215s

• [SLOW TEST:25.276 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSMay  3 13:41:04.817: INFO: Running AfterSuite actions on all nodes
May  3 13:41:04.820: INFO: Running AfterSuite actions on node 1
May  3 13:41:04.820: INFO: Skipping dumping logs from cluster

Ran 204 of 3584 Specs in 5625.050 seconds
SUCCESS! -- 204 Passed | 0 Failed | 0 Pending | 3380 Skipped PASS

Ginkgo ran 1 suite in 1h33m46.272514s
Test Suite Passed
