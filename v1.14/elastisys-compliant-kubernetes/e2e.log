I0909 13:52:30.466954      19 test_context.go:405] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-310951909
I0909 13:52:30.467060      19 e2e.go:240] Starting e2e run "106be669-d309-11e9-b473-6e32a6bc259a" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1568037149 - Will randomize all specs
Will run 204 of 3586 specs

Sep  9 13:52:30.636: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
Sep  9 13:52:30.638: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Sep  9 13:52:30.651: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Sep  9 13:52:30.681: INFO: The status of Pod rke-ingress-controller-deploy-job-hmk7s is Succeeded, skipping waiting
Sep  9 13:52:30.681: INFO: The status of Pod rke-metrics-addon-deploy-job-9v7l5 is Succeeded, skipping waiting
Sep  9 13:52:30.681: INFO: 12 / 14 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Sep  9 13:52:30.681: INFO: expected 8 pod replicas in namespace 'kube-system', 8 are Running and Ready.
Sep  9 13:52:30.681: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Sep  9 13:52:30.688: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'canal' (0 seconds elapsed)
Sep  9 13:52:30.688: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'fluentd-fluentd-elasticsearch' (0 seconds elapsed)
Sep  9 13:52:30.688: INFO: e2e test version: v1.14.6
Sep  9 13:52:30.689: INFO: kube-apiserver version: v1.14.6
S
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 13:52:30.689: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename secrets
Sep  9 13:52:30.742: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Sep  9 13:52:30.756: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3895
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-113bfa17-d309-11e9-b473-6e32a6bc259a
STEP: Creating secret with name s-test-opt-upd-113bfa92-d309-11e9-b473-6e32a6bc259a
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-113bfa17-d309-11e9-b473-6e32a6bc259a
STEP: Updating secret s-test-opt-upd-113bfa92-d309-11e9-b473-6e32a6bc259a
STEP: Creating secret with name s-test-opt-create-113bfaba-d309-11e9-b473-6e32a6bc259a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 13:53:43.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3895" for this suite.
Sep  9 13:54:05.365: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 13:54:05.442: INFO: namespace secrets-3895 deletion completed in 22.09281844s

• [SLOW TEST:94.753 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 13:54:05.442: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-499
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating server pod server in namespace prestop-499
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-499
STEP: Deleting pre-stop pod
Sep  9 13:54:18.667: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 13:54:18.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-499" for this suite.
Sep  9 13:54:58.707: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 13:54:58.781: INFO: namespace prestop-499 deletion completed in 40.086454006s

• [SLOW TEST:53.339 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 13:54:58.781: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9256
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0909 13:55:38.983831      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  9 13:55:38.983: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 13:55:38.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9256" for this suite.
Sep  9 13:55:45.002: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 13:55:45.077: INFO: namespace gc-9256 deletion completed in 6.090951882s

• [SLOW TEST:46.296 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 13:55:45.077: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4023
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1420
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  9 13:55:45.245: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-4023'
Sep  9 13:55:45.483: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep  9 13:55:45.483: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Sep  9 13:55:47.491: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-j6sg8]
Sep  9 13:55:47.491: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-j6sg8" in namespace "kubectl-4023" to be "running and ready"
Sep  9 13:55:47.495: INFO: Pod "e2e-test-nginx-rc-j6sg8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.743434ms
Sep  9 13:55:49.499: INFO: Pod "e2e-test-nginx-rc-j6sg8": Phase="Running", Reason="", readiness=true. Elapsed: 2.007852735s
Sep  9 13:55:49.499: INFO: Pod "e2e-test-nginx-rc-j6sg8" satisfied condition "running and ready"
Sep  9 13:55:49.499: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-j6sg8]
Sep  9 13:55:49.499: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 logs rc/e2e-test-nginx-rc --namespace=kubectl-4023'
Sep  9 13:55:49.617: INFO: stderr: ""
Sep  9 13:55:49.617: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1425
Sep  9 13:55:49.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 delete rc e2e-test-nginx-rc --namespace=kubectl-4023'
Sep  9 13:55:49.723: INFO: stderr: ""
Sep  9 13:55:49.723: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 13:55:49.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4023" for this suite.
Sep  9 13:55:55.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 13:55:55.819: INFO: namespace kubectl-4023 deletion completed in 6.093592502s

• [SLOW TEST:10.741 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 13:55:55.819: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2584
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Sep  9 13:55:58.549: INFO: Successfully updated pod "labelsupdate8b7c9641-d309-11e9-b473-6e32a6bc259a"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 13:56:02.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2584" for this suite.
Sep  9 13:56:24.593: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 13:56:24.679: INFO: namespace downward-api-2584 deletion completed in 22.101332511s

• [SLOW TEST:28.861 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 13:56:24.680: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-3948
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Sep  9 13:56:32.889: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3948 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  9 13:56:32.889: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
Sep  9 13:56:32.988: INFO: Exec stderr: ""
Sep  9 13:56:32.989: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3948 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  9 13:56:32.989: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
Sep  9 13:56:33.081: INFO: Exec stderr: ""
Sep  9 13:56:33.081: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3948 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  9 13:56:33.081: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
Sep  9 13:56:33.166: INFO: Exec stderr: ""
Sep  9 13:56:33.166: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3948 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  9 13:56:33.166: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
Sep  9 13:56:33.251: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Sep  9 13:56:33.251: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3948 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  9 13:56:33.251: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
Sep  9 13:56:33.335: INFO: Exec stderr: ""
Sep  9 13:56:33.335: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3948 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  9 13:56:33.335: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
Sep  9 13:56:33.425: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Sep  9 13:56:33.425: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3948 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  9 13:56:33.425: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
Sep  9 13:56:33.520: INFO: Exec stderr: ""
Sep  9 13:56:33.520: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3948 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  9 13:56:33.520: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
Sep  9 13:56:33.602: INFO: Exec stderr: ""
Sep  9 13:56:33.602: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3948 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  9 13:56:33.602: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
Sep  9 13:56:33.689: INFO: Exec stderr: ""
Sep  9 13:56:33.690: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3948 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  9 13:56:33.690: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
Sep  9 13:56:33.766: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 13:56:33.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-3948" for this suite.
Sep  9 13:57:13.813: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 13:57:13.904: INFO: namespace e2e-kubelet-etc-hosts-3948 deletion completed in 40.135202868s

• [SLOW TEST:49.224 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 13:57:13.904: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-3843
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0909 13:57:15.124148      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  9 13:57:15.124: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 13:57:15.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3843" for this suite.
Sep  9 13:57:21.143: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 13:57:21.234: INFO: namespace gc-3843 deletion completed in 6.107937625s

• [SLOW TEST:7.330 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 13:57:21.235: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5829
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Sep  9 13:57:21.412: INFO: Waiting up to 5m0s for pod "downward-api-be65619a-d309-11e9-b473-6e32a6bc259a" in namespace "downward-api-5829" to be "success or failure"
Sep  9 13:57:21.415: INFO: Pod "downward-api-be65619a-d309-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.913123ms
Sep  9 13:57:23.419: INFO: Pod "downward-api-be65619a-d309-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007122593s
STEP: Saw pod success
Sep  9 13:57:23.419: INFO: Pod "downward-api-be65619a-d309-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 13:57:23.422: INFO: Trying to get logs from node 185.19.31.168 pod downward-api-be65619a-d309-11e9-b473-6e32a6bc259a container dapi-container: <nil>
STEP: delete the pod
Sep  9 13:57:23.446: INFO: Waiting for pod downward-api-be65619a-d309-11e9-b473-6e32a6bc259a to disappear
Sep  9 13:57:23.450: INFO: Pod downward-api-be65619a-d309-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 13:57:23.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5829" for this suite.
Sep  9 13:57:29.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 13:57:29.549: INFO: namespace downward-api-5829 deletion completed in 6.097013104s

• [SLOW TEST:8.314 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 13:57:29.549: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1521
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-c359abc6-d309-11e9-b473-6e32a6bc259a
STEP: Creating a pod to test consume configMaps
Sep  9 13:57:29.734: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c35b3500-d309-11e9-b473-6e32a6bc259a" in namespace "projected-1521" to be "success or failure"
Sep  9 13:57:29.738: INFO: Pod "pod-projected-configmaps-c35b3500-d309-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.663928ms
Sep  9 13:57:31.742: INFO: Pod "pod-projected-configmaps-c35b3500-d309-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007961963s
STEP: Saw pod success
Sep  9 13:57:31.742: INFO: Pod "pod-projected-configmaps-c35b3500-d309-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 13:57:31.745: INFO: Trying to get logs from node 185.19.31.168 pod pod-projected-configmaps-c35b3500-d309-11e9-b473-6e32a6bc259a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  9 13:57:31.782: INFO: Waiting for pod pod-projected-configmaps-c35b3500-d309-11e9-b473-6e32a6bc259a to disappear
Sep  9 13:57:31.785: INFO: Pod pod-projected-configmaps-c35b3500-d309-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 13:57:31.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1521" for this suite.
Sep  9 13:57:37.805: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 13:57:37.884: INFO: namespace projected-1521 deletion completed in 6.096481164s

• [SLOW TEST:8.335 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 13:57:37.885: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-2556
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service endpoint-test2 in namespace services-2556
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2556 to expose endpoints map[]
Sep  9 13:57:38.095: INFO: Get endpoints failed (2.52932ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Sep  9 13:57:39.098: INFO: successfully validated that service endpoint-test2 in namespace services-2556 exposes endpoints map[] (1.005680884s elapsed)
STEP: Creating pod pod1 in namespace services-2556
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2556 to expose endpoints map[pod1:[80]]
Sep  9 13:57:42.162: INFO: successfully validated that service endpoint-test2 in namespace services-2556 exposes endpoints map[pod1:[80]] (3.045941738s elapsed)
STEP: Creating pod pod2 in namespace services-2556
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2556 to expose endpoints map[pod1:[80] pod2:[80]]
Sep  9 13:57:45.289: INFO: successfully validated that service endpoint-test2 in namespace services-2556 exposes endpoints map[pod1:[80] pod2:[80]] (3.038441221s elapsed)
STEP: Deleting pod pod1 in namespace services-2556
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2556 to expose endpoints map[pod2:[80]]
Sep  9 13:57:46.322: INFO: successfully validated that service endpoint-test2 in namespace services-2556 exposes endpoints map[pod2:[80]] (1.014415592s elapsed)
STEP: Deleting pod pod2 in namespace services-2556
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2556 to expose endpoints map[]
Sep  9 13:57:47.342: INFO: successfully validated that service endpoint-test2 in namespace services-2556 exposes endpoints map[] (1.006088421s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 13:57:47.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2556" for this suite.
Sep  9 13:57:53.382: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 13:57:53.469: INFO: namespace services-2556 deletion completed in 6.102890039s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:15.585 seconds]
[sig-network] Services
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 13:57:53.469: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8198
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  9 13:57:53.636: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 13:57:55.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8198" for this suite.
Sep  9 13:58:41.709: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 13:58:41.793: INFO: namespace pods-8198 deletion completed in 46.109174388s

• [SLOW TEST:48.324 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 13:58:41.794: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-8957
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Sep  9 13:58:41.964: INFO: PodSpec: initContainers in spec.initContainers
Sep  9 13:59:25.760: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-ee6aaf5b-d309-11e9-b473-6e32a6bc259a", GenerateName:"", Namespace:"init-container-8957", SelfLink:"/api/v1/namespaces/init-container-8957/pods/pod-init-ee6aaf5b-d309-11e9-b473-6e32a6bc259a", UID:"ee6b5c44-d309-11e9-9321-0635e40003e4", ResourceVersion:"65765", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63703634321, loc:(*time.Location)(0x8825120)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"964634953"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"10.42.0.25/32", "kubernetes.io/psp":"default-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-wksr9", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0024819c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-wksr9", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-wksr9", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-wksr9", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0022ace18), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"185.19.31.168", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001a69d40), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/memory-pressure", Operator:"Exists", Value:"", Effect:"NoSchedule", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0022acef0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0022acf70)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0022acf78), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0022acf7c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703634321, loc:(*time.Location)(0x8825120)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703634321, loc:(*time.Location)(0x8825120)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703634321, loc:(*time.Location)(0x8825120)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703634321, loc:(*time.Location)(0x8825120)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"185.19.31.168", PodIP:"10.42.0.25", StartTime:(*v1.Time)(0xc002ec2fe0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000cac150)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000cac1c0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://e5317d6266ff221a8747b19bde1e7c52c8536f8829ddaf1117d5af7846d0ef19"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002ec3060), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002ec3020), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 13:59:25.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8957" for this suite.
Sep  9 13:59:47.781: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 13:59:47.873: INFO: namespace init-container-8957 deletion completed in 22.107052199s

• [SLOW TEST:66.080 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 13:59:47.874: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-2842
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Sep  9 13:59:54.111: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep  9 13:59:54.115: INFO: Pod pod-with-prestop-http-hook still exists
Sep  9 13:59:56.115: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep  9 13:59:56.120: INFO: Pod pod-with-prestop-http-hook still exists
Sep  9 13:59:58.115: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep  9 13:59:58.120: INFO: Pod pod-with-prestop-http-hook still exists
Sep  9 14:00:00.115: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep  9 14:00:00.119: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:00:00.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2842" for this suite.
Sep  9 14:00:22.147: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:00:22.232: INFO: namespace container-lifecycle-hook-2842 deletion completed in 22.101075525s

• [SLOW TEST:34.358 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:00:22.232: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-2964
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's command
Sep  9 14:00:22.415: INFO: Waiting up to 5m0s for pod "var-expansion-2a47fc2b-d30a-11e9-b473-6e32a6bc259a" in namespace "var-expansion-2964" to be "success or failure"
Sep  9 14:00:22.419: INFO: Pod "var-expansion-2a47fc2b-d30a-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.539997ms
Sep  9 14:00:24.423: INFO: Pod "var-expansion-2a47fc2b-d30a-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00825867s
STEP: Saw pod success
Sep  9 14:00:24.423: INFO: Pod "var-expansion-2a47fc2b-d30a-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 14:00:24.427: INFO: Trying to get logs from node 185.19.31.168 pod var-expansion-2a47fc2b-d30a-11e9-b473-6e32a6bc259a container dapi-container: <nil>
STEP: delete the pod
Sep  9 14:00:24.450: INFO: Waiting for pod var-expansion-2a47fc2b-d30a-11e9-b473-6e32a6bc259a to disappear
Sep  9 14:00:24.459: INFO: Pod var-expansion-2a47fc2b-d30a-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:00:24.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2964" for this suite.
Sep  9 14:00:30.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:00:30.565: INFO: namespace var-expansion-2964 deletion completed in 6.10342392s

• [SLOW TEST:8.332 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:00:30.565: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8044
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:266
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Sep  9 14:00:30.734: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 create -f - --namespace=kubectl-8044'
Sep  9 14:00:30.979: INFO: stderr: ""
Sep  9 14:00:30.979: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  9 14:00:30.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8044'
Sep  9 14:00:31.080: INFO: stderr: ""
Sep  9 14:00:31.080: INFO: stdout: "update-demo-nautilus-c75pj update-demo-nautilus-vh2zx "
Sep  9 14:00:31.080: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods update-demo-nautilus-c75pj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8044'
Sep  9 14:00:31.152: INFO: stderr: ""
Sep  9 14:00:31.152: INFO: stdout: ""
Sep  9 14:00:31.152: INFO: update-demo-nautilus-c75pj is created but not running
Sep  9 14:00:36.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8044'
Sep  9 14:00:36.239: INFO: stderr: ""
Sep  9 14:00:36.239: INFO: stdout: "update-demo-nautilus-c75pj update-demo-nautilus-vh2zx "
Sep  9 14:00:36.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods update-demo-nautilus-c75pj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8044'
Sep  9 14:00:36.315: INFO: stderr: ""
Sep  9 14:00:36.315: INFO: stdout: "true"
Sep  9 14:00:36.315: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods update-demo-nautilus-c75pj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8044'
Sep  9 14:00:36.402: INFO: stderr: ""
Sep  9 14:00:36.402: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  9 14:00:36.402: INFO: validating pod update-demo-nautilus-c75pj
Sep  9 14:00:36.407: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  9 14:00:36.407: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  9 14:00:36.407: INFO: update-demo-nautilus-c75pj is verified up and running
Sep  9 14:00:36.407: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods update-demo-nautilus-vh2zx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8044'
Sep  9 14:00:36.488: INFO: stderr: ""
Sep  9 14:00:36.488: INFO: stdout: "true"
Sep  9 14:00:36.488: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods update-demo-nautilus-vh2zx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8044'
Sep  9 14:00:36.567: INFO: stderr: ""
Sep  9 14:00:36.567: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  9 14:00:36.567: INFO: validating pod update-demo-nautilus-vh2zx
Sep  9 14:00:36.570: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  9 14:00:36.570: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  9 14:00:36.570: INFO: update-demo-nautilus-vh2zx is verified up and running
STEP: using delete to clean up resources
Sep  9 14:00:36.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 delete --grace-period=0 --force -f - --namespace=kubectl-8044'
Sep  9 14:00:36.678: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  9 14:00:36.678: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Sep  9 14:00:36.678: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8044'
Sep  9 14:00:36.767: INFO: stderr: "No resources found.\n"
Sep  9 14:00:36.767: INFO: stdout: ""
Sep  9 14:00:36.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods -l name=update-demo --namespace=kubectl-8044 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  9 14:00:36.841: INFO: stderr: ""
Sep  9 14:00:36.841: INFO: stdout: "update-demo-nautilus-c75pj\nupdate-demo-nautilus-vh2zx\n"
Sep  9 14:00:37.341: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8044'
Sep  9 14:00:37.448: INFO: stderr: "No resources found.\n"
Sep  9 14:00:37.448: INFO: stdout: ""
Sep  9 14:00:37.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods -l name=update-demo --namespace=kubectl-8044 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  9 14:00:37.522: INFO: stderr: ""
Sep  9 14:00:37.522: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:00:37.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8044" for this suite.
Sep  9 14:00:59.542: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:00:59.638: INFO: namespace kubectl-8044 deletion completed in 22.113478392s

• [SLOW TEST:29.073 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:00:59.638: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-933
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-4092a6ac-d30a-11e9-b473-6e32a6bc259a
STEP: Creating a pod to test consume configMaps
Sep  9 14:00:59.826: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-40942a7d-d30a-11e9-b473-6e32a6bc259a" in namespace "projected-933" to be "success or failure"
Sep  9 14:00:59.835: INFO: Pod "pod-projected-configmaps-40942a7d-d30a-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 9.180697ms
Sep  9 14:01:01.840: INFO: Pod "pod-projected-configmaps-40942a7d-d30a-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01422012s
STEP: Saw pod success
Sep  9 14:01:01.840: INFO: Pod "pod-projected-configmaps-40942a7d-d30a-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 14:01:01.844: INFO: Trying to get logs from node 185.19.31.168 pod pod-projected-configmaps-40942a7d-d30a-11e9-b473-6e32a6bc259a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  9 14:01:01.868: INFO: Waiting for pod pod-projected-configmaps-40942a7d-d30a-11e9-b473-6e32a6bc259a to disappear
Sep  9 14:01:01.876: INFO: Pod pod-projected-configmaps-40942a7d-d30a-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:01:01.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-933" for this suite.
Sep  9 14:01:07.900: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:01:07.986: INFO: namespace projected-933 deletion completed in 6.102582219s

• [SLOW TEST:8.348 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:01:07.986: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2550
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-458bfd35-d30a-11e9-b473-6e32a6bc259a
STEP: Creating a pod to test consume configMaps
Sep  9 14:01:08.168: INFO: Waiting up to 5m0s for pod "pod-configmaps-458dca00-d30a-11e9-b473-6e32a6bc259a" in namespace "configmap-2550" to be "success or failure"
Sep  9 14:01:08.173: INFO: Pod "pod-configmaps-458dca00-d30a-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.615922ms
Sep  9 14:01:10.177: INFO: Pod "pod-configmaps-458dca00-d30a-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0091223s
STEP: Saw pod success
Sep  9 14:01:10.177: INFO: Pod "pod-configmaps-458dca00-d30a-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 14:01:10.181: INFO: Trying to get logs from node 185.19.31.168 pod pod-configmaps-458dca00-d30a-11e9-b473-6e32a6bc259a container configmap-volume-test: <nil>
STEP: delete the pod
Sep  9 14:01:10.206: INFO: Waiting for pod pod-configmaps-458dca00-d30a-11e9-b473-6e32a6bc259a to disappear
Sep  9 14:01:10.221: INFO: Pod pod-configmaps-458dca00-d30a-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:01:10.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2550" for this suite.
Sep  9 14:01:16.243: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:01:16.331: INFO: namespace configmap-2550 deletion completed in 6.10715007s

• [SLOW TEST:8.345 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:01:16.331: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-939
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with configMap that has name projected-configmap-test-upd-4a86cfe0-d30a-11e9-b473-6e32a6bc259a
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-4a86cfe0-d30a-11e9-b473-6e32a6bc259a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:02:30.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-939" for this suite.
Sep  9 14:02:52.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:02:53.065: INFO: namespace projected-939 deletion completed in 22.100659125s

• [SLOW TEST:96.734 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:02:53.066: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2502
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating pod
Sep  9 14:02:55.260: INFO: Pod pod-hostip-842ea088-d30a-11e9-b473-6e32a6bc259a has hostIP: 185.19.31.168
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:02:55.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2502" for this suite.
Sep  9 14:03:17.282: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:03:17.376: INFO: namespace pods-2502 deletion completed in 22.113794578s

• [SLOW TEST:24.311 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:03:17.376: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-740
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-740
Sep  9 14:03:19.564: INFO: Started pod liveness-http in namespace container-probe-740
STEP: checking the pod's current state and verifying that restartCount is present
Sep  9 14:03:19.566: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:07:20.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-740" for this suite.
Sep  9 14:07:26.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:07:26.297: INFO: namespace container-probe-740 deletion completed in 6.097962306s

• [SLOW TEST:248.921 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:07:26.297: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5406
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on node default medium
Sep  9 14:07:26.486: INFO: Waiting up to 5m0s for pod "pod-270ba40f-d30b-11e9-b473-6e32a6bc259a" in namespace "emptydir-5406" to be "success or failure"
Sep  9 14:07:26.489: INFO: Pod "pod-270ba40f-d30b-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.177365ms
Sep  9 14:07:28.493: INFO: Pod "pod-270ba40f-d30b-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00706899s
STEP: Saw pod success
Sep  9 14:07:28.493: INFO: Pod "pod-270ba40f-d30b-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 14:07:28.497: INFO: Trying to get logs from node 185.19.31.168 pod pod-270ba40f-d30b-11e9-b473-6e32a6bc259a container test-container: <nil>
STEP: delete the pod
Sep  9 14:07:28.524: INFO: Waiting for pod pod-270ba40f-d30b-11e9-b473-6e32a6bc259a to disappear
Sep  9 14:07:28.533: INFO: Pod pod-270ba40f-d30b-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:07:28.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5406" for this suite.
Sep  9 14:07:34.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:07:34.631: INFO: namespace emptydir-5406 deletion completed in 6.095270717s

• [SLOW TEST:8.334 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:07:34.632: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-9648
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:07:34.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9648" for this suite.
Sep  9 14:07:40.810: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:07:40.900: INFO: namespace services-9648 deletion completed in 6.105068321s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:6.269 seconds]
[sig-network] Services
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:07:40.900: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-3866
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:07:43.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3866" for this suite.
Sep  9 14:08:23.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:08:23.206: INFO: namespace kubelet-test-3866 deletion completed in 40.096299986s

• [SLOW TEST:42.305 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command in a pod
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:08:23.206: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8187
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name projected-secret-test-48f7c16c-d30b-11e9-b473-6e32a6bc259a
STEP: Creating a pod to test consume secrets
Sep  9 14:08:23.405: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-48f97723-d30b-11e9-b473-6e32a6bc259a" in namespace "projected-8187" to be "success or failure"
Sep  9 14:08:23.409: INFO: Pod "pod-projected-secrets-48f97723-d30b-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.088548ms
Sep  9 14:08:25.413: INFO: Pod "pod-projected-secrets-48f97723-d30b-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007486104s
Sep  9 14:08:27.418: INFO: Pod "pod-projected-secrets-48f97723-d30b-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012068246s
STEP: Saw pod success
Sep  9 14:08:27.418: INFO: Pod "pod-projected-secrets-48f97723-d30b-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 14:08:27.421: INFO: Trying to get logs from node 185.19.31.168 pod pod-projected-secrets-48f97723-d30b-11e9-b473-6e32a6bc259a container secret-volume-test: <nil>
STEP: delete the pod
Sep  9 14:08:27.448: INFO: Waiting for pod pod-projected-secrets-48f97723-d30b-11e9-b473-6e32a6bc259a to disappear
Sep  9 14:08:27.457: INFO: Pod pod-projected-secrets-48f97723-d30b-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:08:27.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8187" for this suite.
Sep  9 14:08:33.478: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:08:33.563: INFO: namespace projected-8187 deletion completed in 6.099900625s

• [SLOW TEST:10.357 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:08:33.563: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-4153
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Sep  9 14:08:37.782: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-4f25e554-d30b-11e9-b473-6e32a6bc259a,GenerateName:,Namespace:events-4153,SelfLink:/api/v1/namespaces/events-4153/pods/send-events-4f25e554-d30b-11e9-b473-6e32a6bc259a,UID:4f26947c-d30b-11e9-9321-0635e40003e4,ResourceVersion:67573,Generation:0,CreationTimestamp:2019-09-09 14:08:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 749544908,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.38/32,kubernetes.io/psp: default-psp,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-p6v6l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-p6v6l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-p6v6l true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:185.19.31.168,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00195c570} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00195c590}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:08:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:08:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:08:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:08:33 +0000 UTC  }],Message:,Reason:,HostIP:185.19.31.168,PodIP:10.42.0.38,StartTime:2019-09-09 14:08:33 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-09-09 14:08:37 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://1d0b33ee947b069569e81cbb39818cef0757fc4d71c2f0812d0f6ec2e1afafd2}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Sep  9 14:08:39.787: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Sep  9 14:08:41.791: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:08:41.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-4153" for this suite.
Sep  9 14:09:21.819: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:09:21.908: INFO: namespace events-4153 deletion completed in 40.105141803s

• [SLOW TEST:48.345 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:09:21.908: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-6321
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Sep  9 14:09:30.211: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  9 14:09:30.240: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  9 14:09:32.240: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  9 14:09:32.244: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  9 14:09:34.240: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  9 14:09:34.244: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  9 14:09:36.240: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  9 14:09:36.244: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  9 14:09:38.240: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  9 14:09:38.244: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  9 14:09:40.240: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  9 14:09:40.247: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  9 14:09:42.240: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  9 14:09:42.244: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  9 14:09:44.240: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  9 14:09:44.245: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  9 14:09:46.240: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  9 14:09:46.246: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  9 14:09:48.240: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  9 14:09:48.244: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:09:48.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6321" for this suite.
Sep  9 14:10:10.282: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:10:10.366: INFO: namespace container-lifecycle-hook-6321 deletion completed in 22.11000263s

• [SLOW TEST:48.458 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:10:10.366: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-2354
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-2354
Sep  9 14:10:12.559: INFO: Started pod liveness-exec in namespace container-probe-2354
STEP: checking the pod's current state and verifying that restartCount is present
Sep  9 14:10:12.563: INFO: Initial restart count of pod liveness-exec is 0
Sep  9 14:10:58.674: INFO: Restart count of pod container-probe-2354/liveness-exec is now 1 (46.110539406s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:10:58.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2354" for this suite.
Sep  9 14:11:04.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:11:04.811: INFO: namespace container-probe-2354 deletion completed in 6.104325653s

• [SLOW TEST:54.445 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:11:04.812: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-9846
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Sep  9 14:11:13.094: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  9 14:11:13.099: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  9 14:11:15.099: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  9 14:11:15.104: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  9 14:11:17.099: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  9 14:11:17.105: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  9 14:11:19.099: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  9 14:11:19.104: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  9 14:11:21.099: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  9 14:11:21.103: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  9 14:11:23.099: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  9 14:11:23.103: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  9 14:11:25.099: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  9 14:11:25.103: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  9 14:11:27.099: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  9 14:11:27.105: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  9 14:11:29.100: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  9 14:11:29.103: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  9 14:11:31.099: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  9 14:11:31.103: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:11:31.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9846" for this suite.
Sep  9 14:11:53.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:11:53.208: INFO: namespace container-lifecycle-hook-9846 deletion completed in 22.101289002s

• [SLOW TEST:48.397 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:11:53.208: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4916
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Sep  9 14:11:55.943: INFO: Successfully updated pod "annotationupdatec6221039-d30b-11e9-b473-6e32a6bc259a"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:11:59.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4916" for this suite.
Sep  9 14:12:22.030: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:12:22.114: INFO: namespace downward-api-4916 deletion completed in 22.133855286s

• [SLOW TEST:28.906 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:12:22.114: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-1862
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's args
Sep  9 14:12:22.293: INFO: Waiting up to 5m0s for pod "var-expansion-d75caa31-d30b-11e9-b473-6e32a6bc259a" in namespace "var-expansion-1862" to be "success or failure"
Sep  9 14:12:22.297: INFO: Pod "var-expansion-d75caa31-d30b-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.88324ms
Sep  9 14:12:24.301: INFO: Pod "var-expansion-d75caa31-d30b-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007521152s
STEP: Saw pod success
Sep  9 14:12:24.301: INFO: Pod "var-expansion-d75caa31-d30b-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 14:12:24.304: INFO: Trying to get logs from node 185.19.31.168 pod var-expansion-d75caa31-d30b-11e9-b473-6e32a6bc259a container dapi-container: <nil>
STEP: delete the pod
Sep  9 14:12:24.327: INFO: Waiting for pod var-expansion-d75caa31-d30b-11e9-b473-6e32a6bc259a to disappear
Sep  9 14:12:24.329: INFO: Pod var-expansion-d75caa31-d30b-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:12:24.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1862" for this suite.
Sep  9 14:12:30.348: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:12:30.428: INFO: namespace var-expansion-1862 deletion completed in 6.096154898s

• [SLOW TEST:8.314 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:12:30.428: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-1948
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override arguments
Sep  9 14:12:30.605: INFO: Waiting up to 5m0s for pod "client-containers-dc51369d-d30b-11e9-b473-6e32a6bc259a" in namespace "containers-1948" to be "success or failure"
Sep  9 14:12:30.607: INFO: Pod "client-containers-dc51369d-d30b-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.068259ms
Sep  9 14:12:32.612: INFO: Pod "client-containers-dc51369d-d30b-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006982192s
Sep  9 14:12:34.615: INFO: Pod "client-containers-dc51369d-d30b-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010844024s
STEP: Saw pod success
Sep  9 14:12:34.615: INFO: Pod "client-containers-dc51369d-d30b-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 14:12:34.618: INFO: Trying to get logs from node 185.19.31.168 pod client-containers-dc51369d-d30b-11e9-b473-6e32a6bc259a container test-container: <nil>
STEP: delete the pod
Sep  9 14:12:34.643: INFO: Waiting for pod client-containers-dc51369d-d30b-11e9-b473-6e32a6bc259a to disappear
Sep  9 14:12:34.651: INFO: Pod client-containers-dc51369d-d30b-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:12:34.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1948" for this suite.
Sep  9 14:12:40.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:12:40.761: INFO: namespace containers-1948 deletion completed in 6.104935974s

• [SLOW TEST:10.333 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:12:40.761: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6578
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Sep  9 14:12:40.942: INFO: Waiting up to 5m0s for pod "pod-e27a1e41-d30b-11e9-b473-6e32a6bc259a" in namespace "emptydir-6578" to be "success or failure"
Sep  9 14:12:40.945: INFO: Pod "pod-e27a1e41-d30b-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.67463ms
Sep  9 14:12:42.951: INFO: Pod "pod-e27a1e41-d30b-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00853926s
STEP: Saw pod success
Sep  9 14:12:42.951: INFO: Pod "pod-e27a1e41-d30b-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 14:12:42.954: INFO: Trying to get logs from node 185.19.31.168 pod pod-e27a1e41-d30b-11e9-b473-6e32a6bc259a container test-container: <nil>
STEP: delete the pod
Sep  9 14:12:42.989: INFO: Waiting for pod pod-e27a1e41-d30b-11e9-b473-6e32a6bc259a to disappear
Sep  9 14:12:42.999: INFO: Pod pod-e27a1e41-d30b-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:12:42.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6578" for this suite.
Sep  9 14:12:49.016: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:12:49.097: INFO: namespace emptydir-6578 deletion completed in 6.094967278s

• [SLOW TEST:8.336 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:12:49.097: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-3657
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  9 14:12:49.280: INFO: (0) /api/v1/nodes/185.19.31.168:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 5.289959ms)
Sep  9 14:12:49.283: INFO: (1) /api/v1/nodes/185.19.31.168:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.423172ms)
Sep  9 14:12:49.287: INFO: (2) /api/v1/nodes/185.19.31.168:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.415618ms)
Sep  9 14:12:49.290: INFO: (3) /api/v1/nodes/185.19.31.168:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.217095ms)
Sep  9 14:12:49.293: INFO: (4) /api/v1/nodes/185.19.31.168:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.665923ms)
Sep  9 14:12:49.295: INFO: (5) /api/v1/nodes/185.19.31.168:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.750862ms)
Sep  9 14:12:49.300: INFO: (6) /api/v1/nodes/185.19.31.168:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 4.115161ms)
Sep  9 14:12:49.303: INFO: (7) /api/v1/nodes/185.19.31.168:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.924553ms)
Sep  9 14:12:49.305: INFO: (8) /api/v1/nodes/185.19.31.168:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.187915ms)
Sep  9 14:12:49.307: INFO: (9) /api/v1/nodes/185.19.31.168:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.211324ms)
Sep  9 14:12:49.309: INFO: (10) /api/v1/nodes/185.19.31.168:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.429743ms)
Sep  9 14:12:49.312: INFO: (11) /api/v1/nodes/185.19.31.168:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.450657ms)
Sep  9 14:12:49.314: INFO: (12) /api/v1/nodes/185.19.31.168:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.456075ms)
Sep  9 14:12:49.316: INFO: (13) /api/v1/nodes/185.19.31.168:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.104101ms)
Sep  9 14:12:49.319: INFO: (14) /api/v1/nodes/185.19.31.168:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.107291ms)
Sep  9 14:12:49.321: INFO: (15) /api/v1/nodes/185.19.31.168:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.024377ms)
Sep  9 14:12:49.323: INFO: (16) /api/v1/nodes/185.19.31.168:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.505431ms)
Sep  9 14:12:49.326: INFO: (17) /api/v1/nodes/185.19.31.168:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.308429ms)
Sep  9 14:12:49.328: INFO: (18) /api/v1/nodes/185.19.31.168:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.568292ms)
Sep  9 14:12:49.331: INFO: (19) /api/v1/nodes/185.19.31.168:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.606894ms)
[AfterEach] version v1
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:12:49.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3657" for this suite.
Sep  9 14:12:55.355: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:12:55.435: INFO: namespace proxy-3657 deletion completed in 6.101201909s

• [SLOW TEST:6.337 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:12:55.435: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-1308
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-downwardapi-tnpr
STEP: Creating a pod to test atomic-volume-subpath
Sep  9 14:12:55.636: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-tnpr" in namespace "subpath-1308" to be "success or failure"
Sep  9 14:12:55.638: INFO: Pod "pod-subpath-test-downwardapi-tnpr": Phase="Pending", Reason="", readiness=false. Elapsed: 1.880759ms
Sep  9 14:12:57.642: INFO: Pod "pod-subpath-test-downwardapi-tnpr": Phase="Running", Reason="", readiness=true. Elapsed: 2.005925807s
Sep  9 14:12:59.646: INFO: Pod "pod-subpath-test-downwardapi-tnpr": Phase="Running", Reason="", readiness=true. Elapsed: 4.010607186s
Sep  9 14:13:01.651: INFO: Pod "pod-subpath-test-downwardapi-tnpr": Phase="Running", Reason="", readiness=true. Elapsed: 6.015407111s
Sep  9 14:13:03.657: INFO: Pod "pod-subpath-test-downwardapi-tnpr": Phase="Running", Reason="", readiness=true. Elapsed: 8.021611112s
Sep  9 14:13:05.662: INFO: Pod "pod-subpath-test-downwardapi-tnpr": Phase="Running", Reason="", readiness=true. Elapsed: 10.026636002s
Sep  9 14:13:07.667: INFO: Pod "pod-subpath-test-downwardapi-tnpr": Phase="Running", Reason="", readiness=true. Elapsed: 12.031128337s
Sep  9 14:13:09.672: INFO: Pod "pod-subpath-test-downwardapi-tnpr": Phase="Running", Reason="", readiness=true. Elapsed: 14.036508215s
Sep  9 14:13:11.677: INFO: Pod "pod-subpath-test-downwardapi-tnpr": Phase="Running", Reason="", readiness=true. Elapsed: 16.041444046s
Sep  9 14:13:13.682: INFO: Pod "pod-subpath-test-downwardapi-tnpr": Phase="Running", Reason="", readiness=true. Elapsed: 18.046289637s
Sep  9 14:13:15.687: INFO: Pod "pod-subpath-test-downwardapi-tnpr": Phase="Running", Reason="", readiness=true. Elapsed: 20.050876634s
Sep  9 14:13:17.691: INFO: Pod "pod-subpath-test-downwardapi-tnpr": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.055545243s
STEP: Saw pod success
Sep  9 14:13:17.691: INFO: Pod "pod-subpath-test-downwardapi-tnpr" satisfied condition "success or failure"
Sep  9 14:13:17.695: INFO: Trying to get logs from node 185.19.31.168 pod pod-subpath-test-downwardapi-tnpr container test-container-subpath-downwardapi-tnpr: <nil>
STEP: delete the pod
Sep  9 14:13:17.723: INFO: Waiting for pod pod-subpath-test-downwardapi-tnpr to disappear
Sep  9 14:13:17.727: INFO: Pod pod-subpath-test-downwardapi-tnpr no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-tnpr
Sep  9 14:13:17.728: INFO: Deleting pod "pod-subpath-test-downwardapi-tnpr" in namespace "subpath-1308"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:13:17.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1308" for this suite.
Sep  9 14:13:23.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:13:23.840: INFO: namespace subpath-1308 deletion completed in 6.101619232s

• [SLOW TEST:28.405 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:13:23.840: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7183
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Starting the proxy
Sep  9 14:13:24.002: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-310951909 proxy --unix-socket=/tmp/kubectl-proxy-unix939926016/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:13:24.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7183" for this suite.
Sep  9 14:13:30.087: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:13:30.165: INFO: namespace kubectl-7183 deletion completed in 6.094924322s

• [SLOW TEST:6.325 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:13:30.165: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-3183
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:14:30.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3183" for this suite.
Sep  9 14:14:52.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:14:52.483: INFO: namespace container-probe-3183 deletion completed in 22.10466022s

• [SLOW TEST:82.318 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:14:52.483: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1192
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-1192
Sep  9 14:14:58.676: INFO: Started pod liveness-http in namespace container-probe-1192
STEP: checking the pod's current state and verifying that restartCount is present
Sep  9 14:14:58.679: INFO: Initial restart count of pod liveness-http is 0
Sep  9 14:15:16.728: INFO: Restart count of pod container-probe-1192/liveness-http is now 1 (18.049329407s elapsed)
Sep  9 14:15:36.775: INFO: Restart count of pod container-probe-1192/liveness-http is now 2 (38.096126875s elapsed)
Sep  9 14:15:56.826: INFO: Restart count of pod container-probe-1192/liveness-http is now 3 (58.147235595s elapsed)
Sep  9 14:16:16.870: INFO: Restart count of pod container-probe-1192/liveness-http is now 4 (1m18.191315039s elapsed)
Sep  9 14:16:36.913: INFO: Restart count of pod container-probe-1192/liveness-http is now 5 (1m38.233773154s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:16:36.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1192" for this suite.
Sep  9 14:16:42.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:16:43.058: INFO: namespace container-probe-1192 deletion completed in 6.108899611s

• [SLOW TEST:110.575 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:16:43.058: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1624
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  9 14:16:43.241: INFO: Waiting up to 5m0s for pod "downwardapi-volume-72e5e711-d30c-11e9-b473-6e32a6bc259a" in namespace "projected-1624" to be "success or failure"
Sep  9 14:16:43.245: INFO: Pod "downwardapi-volume-72e5e711-d30c-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.413506ms
Sep  9 14:16:45.250: INFO: Pod "downwardapi-volume-72e5e711-d30c-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008762216s
Sep  9 14:16:47.255: INFO: Pod "downwardapi-volume-72e5e711-d30c-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013833552s
STEP: Saw pod success
Sep  9 14:16:47.255: INFO: Pod "downwardapi-volume-72e5e711-d30c-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 14:16:47.258: INFO: Trying to get logs from node 185.19.31.168 pod downwardapi-volume-72e5e711-d30c-11e9-b473-6e32a6bc259a container client-container: <nil>
STEP: delete the pod
Sep  9 14:16:47.278: INFO: Waiting for pod downwardapi-volume-72e5e711-d30c-11e9-b473-6e32a6bc259a to disappear
Sep  9 14:16:47.285: INFO: Pod downwardapi-volume-72e5e711-d30c-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:16:47.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1624" for this suite.
Sep  9 14:16:53.302: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:16:53.395: INFO: namespace projected-1624 deletion completed in 6.107303574s

• [SLOW TEST:10.337 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:16:53.395: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-5923
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-zdsh
STEP: Creating a pod to test atomic-volume-subpath
Sep  9 14:16:53.603: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-zdsh" in namespace "subpath-5923" to be "success or failure"
Sep  9 14:16:53.606: INFO: Pod "pod-subpath-test-configmap-zdsh": Phase="Pending", Reason="", readiness=false. Elapsed: 3.395945ms
Sep  9 14:16:55.612: INFO: Pod "pod-subpath-test-configmap-zdsh": Phase="Running", Reason="", readiness=true. Elapsed: 2.009004591s
Sep  9 14:16:57.616: INFO: Pod "pod-subpath-test-configmap-zdsh": Phase="Running", Reason="", readiness=true. Elapsed: 4.013681535s
Sep  9 14:16:59.621: INFO: Pod "pod-subpath-test-configmap-zdsh": Phase="Running", Reason="", readiness=true. Elapsed: 6.018676311s
Sep  9 14:17:01.625: INFO: Pod "pod-subpath-test-configmap-zdsh": Phase="Running", Reason="", readiness=true. Elapsed: 8.022139401s
Sep  9 14:17:03.628: INFO: Pod "pod-subpath-test-configmap-zdsh": Phase="Running", Reason="", readiness=true. Elapsed: 10.025604274s
Sep  9 14:17:05.633: INFO: Pod "pod-subpath-test-configmap-zdsh": Phase="Running", Reason="", readiness=true. Elapsed: 12.03081605s
Sep  9 14:17:07.639: INFO: Pod "pod-subpath-test-configmap-zdsh": Phase="Running", Reason="", readiness=true. Elapsed: 14.03623451s
Sep  9 14:17:09.644: INFO: Pod "pod-subpath-test-configmap-zdsh": Phase="Running", Reason="", readiness=true. Elapsed: 16.041449001s
Sep  9 14:17:11.648: INFO: Pod "pod-subpath-test-configmap-zdsh": Phase="Running", Reason="", readiness=true. Elapsed: 18.045271513s
Sep  9 14:17:13.652: INFO: Pod "pod-subpath-test-configmap-zdsh": Phase="Running", Reason="", readiness=true. Elapsed: 20.0495979s
Sep  9 14:17:15.656: INFO: Pod "pod-subpath-test-configmap-zdsh": Phase="Running", Reason="", readiness=true. Elapsed: 22.053160223s
Sep  9 14:17:17.660: INFO: Pod "pod-subpath-test-configmap-zdsh": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.057283972s
STEP: Saw pod success
Sep  9 14:17:17.660: INFO: Pod "pod-subpath-test-configmap-zdsh" satisfied condition "success or failure"
Sep  9 14:17:17.663: INFO: Trying to get logs from node 185.19.31.168 pod pod-subpath-test-configmap-zdsh container test-container-subpath-configmap-zdsh: <nil>
STEP: delete the pod
Sep  9 14:17:17.686: INFO: Waiting for pod pod-subpath-test-configmap-zdsh to disappear
Sep  9 14:17:17.689: INFO: Pod pod-subpath-test-configmap-zdsh no longer exists
STEP: Deleting pod pod-subpath-test-configmap-zdsh
Sep  9 14:17:17.689: INFO: Deleting pod "pod-subpath-test-configmap-zdsh" in namespace "subpath-5923"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:17:17.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5923" for this suite.
Sep  9 14:17:23.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:17:23.805: INFO: namespace subpath-5923 deletion completed in 6.102383599s

• [SLOW TEST:30.410 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:17:23.805: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1733
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0909 14:17:30.006196      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  9 14:17:30.006: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:17:30.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1733" for this suite.
Sep  9 14:17:36.024: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:17:36.125: INFO: namespace gc-1733 deletion completed in 6.116333863s

• [SLOW TEST:12.320 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:17:36.125: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-2784
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  9 14:17:36.282: INFO: Creating deployment "nginx-deployment"
Sep  9 14:17:36.293: INFO: Waiting for observed generation 1
Sep  9 14:17:38.299: INFO: Waiting for all required pods to come up
Sep  9 14:17:38.305: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Sep  9 14:17:40.324: INFO: Waiting for deployment "nginx-deployment" to complete
Sep  9 14:17:40.330: INFO: Updating deployment "nginx-deployment" with a non-existent image
Sep  9 14:17:40.343: INFO: Updating deployment nginx-deployment
Sep  9 14:17:40.343: INFO: Waiting for observed generation 2
Sep  9 14:17:42.350: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Sep  9 14:17:42.352: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Sep  9 14:17:42.355: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Sep  9 14:17:42.362: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Sep  9 14:17:42.362: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Sep  9 14:17:42.364: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Sep  9 14:17:42.368: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Sep  9 14:17:42.368: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Sep  9 14:17:42.382: INFO: Updating deployment nginx-deployment
Sep  9 14:17:42.382: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Sep  9 14:17:42.387: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Sep  9 14:17:44.393: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Sep  9 14:17:44.396: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-2784,SelfLink:/apis/apps/v1/namespaces/deployment-2784/deployments/nginx-deployment,UID:9285f56e-d30c-11e9-9321-0635e40003e4,ResourceVersion:69931,Generation:3,CreationTimestamp:2019-09-09 14:17:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-09-09 14:17:42 +0000 UTC 2019-09-09 14:17:42 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-09-09 14:17:42 +0000 UTC 2019-09-09 14:17:36 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-b79c9d74d" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Sep  9 14:17:44.399: INFO: New ReplicaSet "nginx-deployment-b79c9d74d" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d,GenerateName:,Namespace:deployment-2784,SelfLink:/apis/apps/v1/namespaces/deployment-2784/replicasets/nginx-deployment-b79c9d74d,UID:94f1b2d0-d30c-11e9-9321-0635e40003e4,ResourceVersion:69929,Generation:3,CreationTimestamp:2019-09-09 14:17:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 9285f56e-d30c-11e9-9321-0635e40003e4 0xc00293cc57 0xc00293cc58}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  9 14:17:44.399: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Sep  9 14:17:44.399: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5,GenerateName:,Namespace:deployment-2784,SelfLink:/apis/apps/v1/namespaces/deployment-2784/replicasets/nginx-deployment-85db8c99c5,UID:9287ae6f-d30c-11e9-9321-0635e40003e4,ResourceVersion:69920,Generation:3,CreationTimestamp:2019-09-09 14:17:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 9285f56e-d30c-11e9-9321-0635e40003e4 0xc00293cb87 0xc00293cb88}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Sep  9 14:17:44.406: INFO: Pod "nginx-deployment-85db8c99c5-47pqq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-47pqq,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-2784,SelfLink:/api/v1/namespaces/deployment-2784/pods/nginx-deployment-85db8c99c5-47pqq,UID:964cec50-d30c-11e9-9321-0635e40003e4,ResourceVersion:70021,Generation:0,CreationTimestamp:2019-09-09 14:17:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.51/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 9287ae6f-d30c-11e9-9321-0635e40003e4 0xc002525d87 0xc002525d88}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vf8bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vf8bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vf8bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:185.19.31.68,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002525e00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002525e20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC  }],Message:,Reason:,HostIP:185.19.31.68,PodIP:,StartTime:2019-09-09 14:17:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  9 14:17:44.407: INFO: Pod "nginx-deployment-85db8c99c5-66qwq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-66qwq,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-2784,SelfLink:/api/v1/namespaces/deployment-2784/pods/nginx-deployment-85db8c99c5-66qwq,UID:928c029e-d30c-11e9-9321-0635e40003e4,ResourceVersion:69761,Generation:0,CreationTimestamp:2019-09-09 14:17:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.60/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 9287ae6f-d30c-11e9-9321-0635e40003e4 0xc002525ef7 0xc002525ef8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vf8bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vf8bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vf8bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:185.19.31.168,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002525f70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002525f90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:36 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:36 +0000 UTC  }],Message:,Reason:,HostIP:185.19.31.168,PodIP:10.42.0.60,StartTime:2019-09-09 14:17:36 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-09 14:17:37 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://8c8e00e55344f139ec98590b35cfc3a80159494ca99fdc0655f4edba6178d0c9}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  9 14:17:44.407: INFO: Pod "nginx-deployment-85db8c99c5-6pm5z" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-6pm5z,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-2784,SelfLink:/api/v1/namespaces/deployment-2784/pods/nginx-deployment-85db8c99c5-6pm5z,UID:928fc4e5-d30c-11e9-9321-0635e40003e4,ResourceVersion:69777,Generation:0,CreationTimestamp:2019-09-09 14:17:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.38/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 9287ae6f-d30c-11e9-9321-0635e40003e4 0xc002a78070 0xc002a78071}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vf8bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vf8bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vf8bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:185.19.31.68,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a780e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a78100}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:36 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:36 +0000 UTC  }],Message:,Reason:,HostIP:185.19.31.68,PodIP:10.42.1.38,StartTime:2019-09-09 14:17:36 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-09 14:17:37 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://27b89b4e16973f6f947ebb20569a1d0076ea5a24d47f1bb290384358dad0f00a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  9 14:17:44.407: INFO: Pod "nginx-deployment-85db8c99c5-7lm76" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-7lm76,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-2784,SelfLink:/api/v1/namespaces/deployment-2784/pods/nginx-deployment-85db8c99c5-7lm76,UID:92908ecf-d30c-11e9-9321-0635e40003e4,ResourceVersion:69765,Generation:0,CreationTimestamp:2019-09-09 14:17:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.62/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 9287ae6f-d30c-11e9-9321-0635e40003e4 0xc002a781e0 0xc002a781e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vf8bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vf8bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vf8bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:185.19.31.168,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a78250} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a78270}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:36 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:36 +0000 UTC  }],Message:,Reason:,HostIP:185.19.31.168,PodIP:10.42.0.62,StartTime:2019-09-09 14:17:36 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-09 14:17:37 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://231dbb7590e3a3c97d382c2412385c1d1e3f8287a81e518fc6d3fad1c77e05d0}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  9 14:17:44.407: INFO: Pod "nginx-deployment-85db8c99c5-94fxd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-94fxd,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-2784,SelfLink:/api/v1/namespaces/deployment-2784/pods/nginx-deployment-85db8c99c5-94fxd,UID:929029b1-d30c-11e9-9321-0635e40003e4,ResourceVersion:69782,Generation:0,CreationTimestamp:2019-09-09 14:17:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.61/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 9287ae6f-d30c-11e9-9321-0635e40003e4 0xc002a78350 0xc002a78351}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vf8bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vf8bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vf8bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:185.19.31.168,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a783c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a783e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:36 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:36 +0000 UTC  }],Message:,Reason:,HostIP:185.19.31.168,PodIP:10.42.0.61,StartTime:2019-09-09 14:17:36 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-09 14:17:37 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://0490dbc2a2e712a9e43e47eeba3b9dea309b28c5aae09ed7abeb894cc6bdeed3}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  9 14:17:44.407: INFO: Pod "nginx-deployment-85db8c99c5-9g8bb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-9g8bb,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-2784,SelfLink:/api/v1/namespaces/deployment-2784/pods/nginx-deployment-85db8c99c5-9g8bb,UID:964c8ecb-d30c-11e9-9321-0635e40003e4,ResourceVersion:70005,Generation:0,CreationTimestamp:2019-09-09 14:17:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.73/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 9287ae6f-d30c-11e9-9321-0635e40003e4 0xc002a784c0 0xc002a784c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vf8bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vf8bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vf8bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:185.19.31.168,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a78530} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a78550}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC  }],Message:,Reason:,HostIP:185.19.31.168,PodIP:,StartTime:2019-09-09 14:17:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  9 14:17:44.407: INFO: Pod "nginx-deployment-85db8c99c5-b986l" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-b986l,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-2784,SelfLink:/api/v1/namespaces/deployment-2784/pods/nginx-deployment-85db8c99c5-b986l,UID:964ce649-d30c-11e9-9321-0635e40003e4,ResourceVersion:70015,Generation:0,CreationTimestamp:2019-09-09 14:17:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.74/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 9287ae6f-d30c-11e9-9321-0635e40003e4 0xc002a78627 0xc002a78628}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vf8bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vf8bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vf8bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:185.19.31.168,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a786a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a786c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  9 14:17:44.407: INFO: Pod "nginx-deployment-85db8c99c5-ctvkm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-ctvkm,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-2784,SelfLink:/api/v1/namespaces/deployment-2784/pods/nginx-deployment-85db8c99c5-ctvkm,UID:962a9c5b-d30c-11e9-9321-0635e40003e4,ResourceVersion:69969,Generation:0,CreationTimestamp:2019-09-09 14:17:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.43/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 9287ae6f-d30c-11e9-9321-0635e40003e4 0xc002a78750 0xc002a78751}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vf8bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vf8bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vf8bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:185.19.31.68,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a787c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a787e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC  }],Message:,Reason:,HostIP:185.19.31.68,PodIP:,StartTime:2019-09-09 14:17:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  9 14:17:44.408: INFO: Pod "nginx-deployment-85db8c99c5-dlhpb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-dlhpb,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-2784,SelfLink:/api/v1/namespaces/deployment-2784/pods/nginx-deployment-85db8c99c5-dlhpb,UID:9643190b-d30c-11e9-9321-0635e40003e4,ResourceVersion:69984,Generation:0,CreationTimestamp:2019-09-09 14:17:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.70/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 9287ae6f-d30c-11e9-9321-0635e40003e4 0xc002a788b7 0xc002a788b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vf8bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vf8bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vf8bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:185.19.31.168,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a78930} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a78950}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC  }],Message:,Reason:,HostIP:185.19.31.168,PodIP:,StartTime:2019-09-09 14:17:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  9 14:17:44.408: INFO: Pod "nginx-deployment-85db8c99c5-dwflp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-dwflp,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-2784,SelfLink:/api/v1/namespaces/deployment-2784/pods/nginx-deployment-85db8c99c5-dwflp,UID:96437cc4-d30c-11e9-9321-0635e40003e4,ResourceVersion:69988,Generation:0,CreationTimestamp:2019-09-09 14:17:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.46/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 9287ae6f-d30c-11e9-9321-0635e40003e4 0xc002a78a27 0xc002a78a28}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vf8bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vf8bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vf8bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:185.19.31.68,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a78aa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a78ac0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC  }],Message:,Reason:,HostIP:185.19.31.68,PodIP:,StartTime:2019-09-09 14:17:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  9 14:17:44.408: INFO: Pod "nginx-deployment-85db8c99c5-h62tp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-h62tp,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-2784,SelfLink:/api/v1/namespaces/deployment-2784/pods/nginx-deployment-85db8c99c5-h62tp,UID:92911fcb-d30c-11e9-9321-0635e40003e4,ResourceVersion:69772,Generation:0,CreationTimestamp:2019-09-09 14:17:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.39/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 9287ae6f-d30c-11e9-9321-0635e40003e4 0xc002a78b97 0xc002a78b98}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vf8bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vf8bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vf8bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:185.19.31.68,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a78c10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a78c30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:36 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:36 +0000 UTC  }],Message:,Reason:,HostIP:185.19.31.68,PodIP:10.42.1.39,StartTime:2019-09-09 14:17:36 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-09 14:17:37 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://e42a97ba417309a2a1a4290538958afcae25af803585287b6976ca60602be0e4}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  9 14:17:44.408: INFO: Pod "nginx-deployment-85db8c99c5-j5z75" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-j5z75,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-2784,SelfLink:/api/v1/namespaces/deployment-2784/pods/nginx-deployment-85db8c99c5-j5z75,UID:92941981-d30c-11e9-9321-0635e40003e4,ResourceVersion:69758,Generation:0,CreationTimestamp:2019-09-09 14:17:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.64/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 9287ae6f-d30c-11e9-9321-0635e40003e4 0xc002a78d10 0xc002a78d11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vf8bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vf8bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vf8bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:185.19.31.168,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a78d80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a78da0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:36 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:36 +0000 UTC  }],Message:,Reason:,HostIP:185.19.31.168,PodIP:10.42.0.64,StartTime:2019-09-09 14:17:36 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-09 14:17:37 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://39d6cf29f7cd6f968d479a9b6d234332e350e63a0e142dc1c3b8041b9fa3776d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  9 14:17:44.408: INFO: Pod "nginx-deployment-85db8c99c5-n9dq2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-n9dq2,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-2784,SelfLink:/api/v1/namespaces/deployment-2784/pods/nginx-deployment-85db8c99c5-n9dq2,UID:9293d7e2-d30c-11e9-9321-0635e40003e4,ResourceVersion:69755,Generation:0,CreationTimestamp:2019-09-09 14:17:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.63/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 9287ae6f-d30c-11e9-9321-0635e40003e4 0xc002a78e80 0xc002a78e81}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vf8bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vf8bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vf8bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:185.19.31.168,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a78ef0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a78f10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:36 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:36 +0000 UTC  }],Message:,Reason:,HostIP:185.19.31.168,PodIP:10.42.0.63,StartTime:2019-09-09 14:17:36 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-09 14:17:37 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://e7160bdd5bbe764b3ca34f0005141204f5de953cd9d6507ea7195a71c1060871}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  9 14:17:44.408: INFO: Pod "nginx-deployment-85db8c99c5-nbr4v" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-nbr4v,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-2784,SelfLink:/api/v1/namespaces/deployment-2784/pods/nginx-deployment-85db8c99c5-nbr4v,UID:964348eb-d30c-11e9-9321-0635e40003e4,ResourceVersion:69973,Generation:0,CreationTimestamp:2019-09-09 14:17:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.69/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 9287ae6f-d30c-11e9-9321-0635e40003e4 0xc002a78ff0 0xc002a78ff1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vf8bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vf8bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vf8bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:185.19.31.168,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a79060} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a79080}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC  }],Message:,Reason:,HostIP:185.19.31.168,PodIP:,StartTime:2019-09-09 14:17:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  9 14:17:44.408: INFO: Pod "nginx-deployment-85db8c99c5-nzbrv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-nzbrv,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-2784,SelfLink:/api/v1/namespaces/deployment-2784/pods/nginx-deployment-85db8c99c5-nzbrv,UID:964ca3a5-d30c-11e9-9321-0635e40003e4,ResourceVersion:70011,Generation:0,CreationTimestamp:2019-09-09 14:17:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.49/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 9287ae6f-d30c-11e9-9321-0635e40003e4 0xc002a79157 0xc002a79158}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vf8bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vf8bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vf8bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:185.19.31.68,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a791d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a791f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC  }],Message:,Reason:,HostIP:185.19.31.68,PodIP:,StartTime:2019-09-09 14:17:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  9 14:17:44.408: INFO: Pod "nginx-deployment-85db8c99c5-qp7vw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-qp7vw,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-2784,SelfLink:/api/v1/namespaces/deployment-2784/pods/nginx-deployment-85db8c99c5-qp7vw,UID:964e3ff2-d30c-11e9-9321-0635e40003e4,ResourceVersion:70013,Generation:0,CreationTimestamp:2019-09-09 14:17:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.50/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 9287ae6f-d30c-11e9-9321-0635e40003e4 0xc002a792c7 0xc002a792c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vf8bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vf8bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vf8bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:185.19.31.68,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a79340} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a79360}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC  }],Message:,Reason:,HostIP:185.19.31.68,PodIP:,StartTime:2019-09-09 14:17:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  9 14:17:44.408: INFO: Pod "nginx-deployment-85db8c99c5-s8fnf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-s8fnf,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-2784,SelfLink:/api/v1/namespaces/deployment-2784/pods/nginx-deployment-85db8c99c5-s8fnf,UID:962c4dd2-d30c-11e9-9321-0635e40003e4,ResourceVersion:69968,Generation:0,CreationTimestamp:2019-09-09 14:17:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.68/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 9287ae6f-d30c-11e9-9321-0635e40003e4 0xc002a79437 0xc002a79438}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vf8bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vf8bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vf8bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:185.19.31.168,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a794b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a794d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC  }],Message:,Reason:,HostIP:185.19.31.168,PodIP:,StartTime:2019-09-09 14:17:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  9 14:17:44.409: INFO: Pod "nginx-deployment-85db8c99c5-ts4p7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-ts4p7,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-2784,SelfLink:/api/v1/namespaces/deployment-2784/pods/nginx-deployment-85db8c99c5-ts4p7,UID:962c1728-d30c-11e9-9321-0635e40003e4,ResourceVersion:69978,Generation:0,CreationTimestamp:2019-09-09 14:17:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.44/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 9287ae6f-d30c-11e9-9321-0635e40003e4 0xc002a795a7 0xc002a795a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vf8bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vf8bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vf8bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:185.19.31.68,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a79620} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a79640}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC  }],Message:,Reason:,HostIP:185.19.31.68,PodIP:,StartTime:2019-09-09 14:17:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  9 14:17:44.409: INFO: Pod "nginx-deployment-85db8c99c5-xf66z" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-xf66z,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-2784,SelfLink:/api/v1/namespaces/deployment-2784/pods/nginx-deployment-85db8c99c5-xf66z,UID:9643c5aa-d30c-11e9-9321-0635e40003e4,ResourceVersion:70019,Generation:0,CreationTimestamp:2019-09-09 14:17:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.76/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 9287ae6f-d30c-11e9-9321-0635e40003e4 0xc002a79717 0xc002a79718}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vf8bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vf8bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vf8bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:185.19.31.168,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a79790} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a797b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC  }],Message:,Reason:,HostIP:185.19.31.168,PodIP:,StartTime:2019-09-09 14:17:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  9 14:17:44.409: INFO: Pod "nginx-deployment-85db8c99c5-xl7n4" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-xl7n4,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-2784,SelfLink:/api/v1/namespaces/deployment-2784/pods/nginx-deployment-85db8c99c5-xl7n4,UID:928c3d62-d30c-11e9-9321-0635e40003e4,ResourceVersion:69769,Generation:0,CreationTimestamp:2019-09-09 14:17:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.37/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 9287ae6f-d30c-11e9-9321-0635e40003e4 0xc002a79887 0xc002a79888}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vf8bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vf8bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vf8bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:185.19.31.68,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a79910} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a79930}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:36 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:36 +0000 UTC  }],Message:,Reason:,HostIP:185.19.31.68,PodIP:10.42.1.37,StartTime:2019-09-09 14:17:36 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-09 14:17:37 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://c14b07ef37abba06c573678783e7d1d6764a13afddfa9e04b48fb8f85f3a5721}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  9 14:17:44.409: INFO: Pod "nginx-deployment-b79c9d74d-29tjn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-29tjn,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-2784,SelfLink:/api/v1/namespaces/deployment-2784/pods/nginx-deployment-b79c9d74d-29tjn,UID:95050598-d30c-11e9-9321-0635e40003e4,ResourceVersion:69850,Generation:0,CreationTimestamp:2019-09-09 14:17:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.67/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 94f1b2d0-d30c-11e9-9321-0635e40003e4 0xc002a79a10 0xc002a79a11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vf8bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vf8bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vf8bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:185.19.31.168,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a79a90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a79ab0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:40 +0000 UTC  }],Message:,Reason:,HostIP:185.19.31.168,PodIP:,StartTime:2019-09-09 14:17:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  9 14:17:44.409: INFO: Pod "nginx-deployment-b79c9d74d-6qx4v" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-6qx4v,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-2784,SelfLink:/api/v1/namespaces/deployment-2784/pods/nginx-deployment-b79c9d74d-6qx4v,UID:964d664a-d30c-11e9-9321-0635e40003e4,ResourceVersion:70010,Generation:0,CreationTimestamp:2019-09-09 14:17:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.48/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 94f1b2d0-d30c-11e9-9321-0635e40003e4 0xc002a79b90 0xc002a79b91}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vf8bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vf8bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vf8bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:185.19.31.68,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a79c10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a79c30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC  }],Message:,Reason:,HostIP:185.19.31.68,PodIP:,StartTime:2019-09-09 14:17:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  9 14:17:44.409: INFO: Pod "nginx-deployment-b79c9d74d-7bmgk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-7bmgk,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-2784,SelfLink:/api/v1/namespaces/deployment-2784/pods/nginx-deployment-b79c9d74d-7bmgk,UID:9655a8a2-d30c-11e9-9321-0635e40003e4,ResourceVersion:70020,Generation:0,CreationTimestamp:2019-09-09 14:17:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.52/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 94f1b2d0-d30c-11e9-9321-0635e40003e4 0xc002a79d10 0xc002a79d11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vf8bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vf8bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vf8bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:185.19.31.68,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a79d90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a79db0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  9 14:17:44.409: INFO: Pod "nginx-deployment-b79c9d74d-7ksx5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-7ksx5,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-2784,SelfLink:/api/v1/namespaces/deployment-2784/pods/nginx-deployment-b79c9d74d-7ksx5,UID:962da503-d30c-11e9-9321-0635e40003e4,ResourceVersion:69983,Generation:0,CreationTimestamp:2019-09-09 14:17:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.45/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 94f1b2d0-d30c-11e9-9321-0635e40003e4 0xc002a79e40 0xc002a79e41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vf8bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vf8bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vf8bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:185.19.31.68,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a79ec0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a79ee0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC  }],Message:,Reason:,HostIP:185.19.31.68,PodIP:,StartTime:2019-09-09 14:17:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  9 14:17:44.409: INFO: Pod "nginx-deployment-b79c9d74d-98km8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-98km8,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-2784,SelfLink:/api/v1/namespaces/deployment-2784/pods/nginx-deployment-b79c9d74d-98km8,UID:94f50e4d-d30c-11e9-9321-0635e40003e4,ResourceVersion:69841,Generation:0,CreationTimestamp:2019-09-09 14:17:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.41/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 94f1b2d0-d30c-11e9-9321-0635e40003e4 0xc002a79fc0 0xc002a79fc1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vf8bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vf8bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vf8bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:185.19.31.68,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f5e040} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f5e060}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:40 +0000 UTC  }],Message:,Reason:,HostIP:185.19.31.68,PodIP:,StartTime:2019-09-09 14:17:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  9 14:17:44.409: INFO: Pod "nginx-deployment-b79c9d74d-d55q2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-d55q2,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-2784,SelfLink:/api/v1/namespaces/deployment-2784/pods/nginx-deployment-b79c9d74d-d55q2,UID:94f544fc-d30c-11e9-9321-0635e40003e4,ResourceVersion:69848,Generation:0,CreationTimestamp:2019-09-09 14:17:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.66/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 94f1b2d0-d30c-11e9-9321-0635e40003e4 0xc002f5e140 0xc002f5e141}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vf8bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vf8bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vf8bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:185.19.31.168,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f5e1c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f5e1e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:40 +0000 UTC  }],Message:,Reason:,HostIP:185.19.31.168,PodIP:,StartTime:2019-09-09 14:17:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  9 14:17:44.409: INFO: Pod "nginx-deployment-b79c9d74d-kcss6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-kcss6,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-2784,SelfLink:/api/v1/namespaces/deployment-2784/pods/nginx-deployment-b79c9d74d-kcss6,UID:964d5eb9-d30c-11e9-9321-0635e40003e4,ResourceVersion:70016,Generation:0,CreationTimestamp:2019-09-09 14:17:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.75/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 94f1b2d0-d30c-11e9-9321-0635e40003e4 0xc002f5e2c0 0xc002f5e2c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vf8bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vf8bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vf8bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:185.19.31.168,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f5e340} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f5e360}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC  }],Message:,Reason:,HostIP:185.19.31.168,PodIP:,StartTime:2019-09-09 14:17:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  9 14:17:44.410: INFO: Pod "nginx-deployment-b79c9d74d-m2prc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-m2prc,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-2784,SelfLink:/api/v1/namespaces/deployment-2784/pods/nginx-deployment-b79c9d74d-m2prc,UID:964d243d-d30c-11e9-9321-0635e40003e4,ResourceVersion:70022,Generation:0,CreationTimestamp:2019-09-09 14:17:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.77/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 94f1b2d0-d30c-11e9-9321-0635e40003e4 0xc002f5e440 0xc002f5e441}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vf8bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vf8bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vf8bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:185.19.31.168,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f5e4c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f5e4e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC  }],Message:,Reason:,HostIP:185.19.31.168,PodIP:,StartTime:2019-09-09 14:17:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  9 14:17:44.410: INFO: Pod "nginx-deployment-b79c9d74d-mmf49" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-mmf49,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-2784,SelfLink:/api/v1/namespaces/deployment-2784/pods/nginx-deployment-b79c9d74d-mmf49,UID:9644805a-d30c-11e9-9321-0635e40003e4,ResourceVersion:69998,Generation:0,CreationTimestamp:2019-09-09 14:17:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.72/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 94f1b2d0-d30c-11e9-9321-0635e40003e4 0xc002f5e5c0 0xc002f5e5c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vf8bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vf8bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vf8bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:185.19.31.168,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f5e640} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f5e660}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC  }],Message:,Reason:,HostIP:185.19.31.168,PodIP:,StartTime:2019-09-09 14:17:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  9 14:17:44.410: INFO: Pod "nginx-deployment-b79c9d74d-nbzsm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-nbzsm,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-2784,SelfLink:/api/v1/namespaces/deployment-2784/pods/nginx-deployment-b79c9d74d-nbzsm,UID:94f34b7f-d30c-11e9-9321-0635e40003e4,ResourceVersion:69843,Generation:0,CreationTimestamp:2019-09-09 14:17:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.65/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 94f1b2d0-d30c-11e9-9321-0635e40003e4 0xc002f5e740 0xc002f5e741}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vf8bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vf8bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vf8bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:185.19.31.168,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f5e7c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f5e7e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:40 +0000 UTC  }],Message:,Reason:,HostIP:185.19.31.168,PodIP:,StartTime:2019-09-09 14:17:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  9 14:17:44.410: INFO: Pod "nginx-deployment-b79c9d74d-p6lhz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-p6lhz,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-2784,SelfLink:/api/v1/namespaces/deployment-2784/pods/nginx-deployment-b79c9d74d-p6lhz,UID:964de991-d30c-11e9-9321-0635e40003e4,ResourceVersion:69997,Generation:0,CreationTimestamp:2019-09-09 14:17:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.47/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 94f1b2d0-d30c-11e9-9321-0635e40003e4 0xc002f5e8c0 0xc002f5e8c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vf8bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vf8bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vf8bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:185.19.31.68,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f5e940} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f5e960}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC  }],Message:,Reason:,HostIP:185.19.31.68,PodIP:,StartTime:2019-09-09 14:17:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  9 14:17:44.410: INFO: Pod "nginx-deployment-b79c9d74d-rtwnk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-rtwnk,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-2784,SelfLink:/api/v1/namespaces/deployment-2784/pods/nginx-deployment-b79c9d74d-rtwnk,UID:950312ad-d30c-11e9-9321-0635e40003e4,ResourceVersion:69845,Generation:0,CreationTimestamp:2019-09-09 14:17:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.42/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 94f1b2d0-d30c-11e9-9321-0635e40003e4 0xc002f5ea50 0xc002f5ea51}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vf8bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vf8bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vf8bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:185.19.31.68,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f5ead0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f5eaf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:40 +0000 UTC  }],Message:,Reason:,HostIP:185.19.31.68,PodIP:,StartTime:2019-09-09 14:17:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  9 14:17:44.410: INFO: Pod "nginx-deployment-b79c9d74d-tf2r9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-tf2r9,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-2784,SelfLink:/api/v1/namespaces/deployment-2784/pods/nginx-deployment-b79c9d74d-tf2r9,UID:9644aba6-d30c-11e9-9321-0635e40003e4,ResourceVersion:69987,Generation:0,CreationTimestamp:2019-09-09 14:17:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.71/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d 94f1b2d0-d30c-11e9-9321-0635e40003e4 0xc002f5ebd0 0xc002f5ebd1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vf8bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vf8bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vf8bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:185.19.31.168,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f5ec50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f5ec70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:17:42 +0000 UTC  }],Message:,Reason:,HostIP:185.19.31.168,PodIP:,StartTime:2019-09-09 14:17:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:17:44.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2784" for this suite.
Sep  9 14:17:52.428: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:17:52.511: INFO: namespace deployment-2784 deletion completed in 8.097930442s

• [SLOW TEST:16.386 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:17:52.511: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-5096
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-5096
Sep  9 14:17:58.753: INFO: Started pod liveness-http in namespace container-probe-5096
STEP: checking the pod's current state and verifying that restartCount is present
Sep  9 14:17:58.757: INFO: Initial restart count of pod liveness-http is 0
Sep  9 14:18:16.801: INFO: Restart count of pod container-probe-5096/liveness-http is now 1 (18.044327448s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:18:16.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5096" for this suite.
Sep  9 14:18:22.847: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:18:22.933: INFO: namespace container-probe-5096 deletion completed in 6.107314935s

• [SLOW TEST:30.422 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:18:22.933: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-595
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Sep  9 14:18:27.231: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep  9 14:18:27.237: INFO: Pod pod-with-poststart-http-hook still exists
Sep  9 14:18:29.237: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep  9 14:18:29.242: INFO: Pod pod-with-poststart-http-hook still exists
Sep  9 14:18:31.237: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep  9 14:18:31.242: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:18:31.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-595" for this suite.
Sep  9 14:18:53.263: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:18:53.350: INFO: namespace container-lifecycle-hook-595 deletion completed in 22.105131925s

• [SLOW TEST:30.417 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:18:53.350: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7779
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1521
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  9 14:18:53.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=kubectl-7779'
Sep  9 14:18:53.775: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep  9 14:18:53.775: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1526
Sep  9 14:18:55.784: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 delete deployment e2e-test-nginx-deployment --namespace=kubectl-7779'
Sep  9 14:18:55.877: INFO: stderr: ""
Sep  9 14:18:55.877: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:18:55.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7779" for this suite.
Sep  9 14:19:17.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:19:17.978: INFO: namespace kubectl-7779 deletion completed in 22.098430425s

• [SLOW TEST:24.628 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:19:17.979: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2634
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  9 14:19:18.204: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"cf42a795-d30c-11e9-9321-0635e40003e4", Controller:(*bool)(0xc001144c16), BlockOwnerDeletion:(*bool)(0xc001144c17)}}
Sep  9 14:19:18.225: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"cf3e3ec9-d30c-11e9-9321-0635e40003e4", Controller:(*bool)(0xc0029708ba), BlockOwnerDeletion:(*bool)(0xc0029708bb)}}
Sep  9 14:19:18.237: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"cf4035dd-d30c-11e9-9321-0635e40003e4", Controller:(*bool)(0xc001144e3a), BlockOwnerDeletion:(*bool)(0xc001144e3b)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:19:23.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2634" for this suite.
Sep  9 14:19:29.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:19:29.351: INFO: namespace gc-2634 deletion completed in 6.094308748s

• [SLOW TEST:11.372 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:19:29.351: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-3906
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test env composition
Sep  9 14:19:29.563: INFO: Waiting up to 5m0s for pod "var-expansion-d6081432-d30c-11e9-b473-6e32a6bc259a" in namespace "var-expansion-3906" to be "success or failure"
Sep  9 14:19:29.580: INFO: Pod "var-expansion-d6081432-d30c-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 17.094051ms
Sep  9 14:19:31.585: INFO: Pod "var-expansion-d6081432-d30c-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02253216s
STEP: Saw pod success
Sep  9 14:19:31.585: INFO: Pod "var-expansion-d6081432-d30c-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 14:19:31.588: INFO: Trying to get logs from node 185.19.31.168 pod var-expansion-d6081432-d30c-11e9-b473-6e32a6bc259a container dapi-container: <nil>
STEP: delete the pod
Sep  9 14:19:31.611: INFO: Waiting for pod var-expansion-d6081432-d30c-11e9-b473-6e32a6bc259a to disappear
Sep  9 14:19:31.614: INFO: Pod var-expansion-d6081432-d30c-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:19:31.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3906" for this suite.
Sep  9 14:19:37.633: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:19:37.713: INFO: namespace var-expansion-3906 deletion completed in 6.097669251s

• [SLOW TEST:8.362 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:19:37.714: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9797
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  9 14:19:37.882: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:19:40.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9797" for this suite.
Sep  9 14:20:22.030: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:20:22.113: INFO: namespace pods-9797 deletion completed in 42.100950886s

• [SLOW TEST:44.399 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:20:22.113: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8583
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Sep  9 14:20:22.314: INFO: Waiting up to 5m0s for pod "downward-api-f578dcb7-d30c-11e9-b473-6e32a6bc259a" in namespace "downward-api-8583" to be "success or failure"
Sep  9 14:20:22.317: INFO: Pod "downward-api-f578dcb7-d30c-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.587223ms
Sep  9 14:20:24.321: INFO: Pod "downward-api-f578dcb7-d30c-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006852914s
STEP: Saw pod success
Sep  9 14:20:24.321: INFO: Pod "downward-api-f578dcb7-d30c-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 14:20:24.324: INFO: Trying to get logs from node 185.19.31.168 pod downward-api-f578dcb7-d30c-11e9-b473-6e32a6bc259a container dapi-container: <nil>
STEP: delete the pod
Sep  9 14:20:24.348: INFO: Waiting for pod downward-api-f578dcb7-d30c-11e9-b473-6e32a6bc259a to disappear
Sep  9 14:20:24.351: INFO: Pod downward-api-f578dcb7-d30c-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:20:24.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8583" for this suite.
Sep  9 14:20:30.368: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:20:30.463: INFO: namespace downward-api-8583 deletion completed in 6.109471782s

• [SLOW TEST:8.350 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:20:30.463: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-2570
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Sep  9 14:20:30.667: INFO: Number of nodes with available pods: 0
Sep  9 14:20:30.667: INFO: Node 185.19.31.168 is running more than one daemon pod
Sep  9 14:20:31.678: INFO: Number of nodes with available pods: 0
Sep  9 14:20:31.678: INFO: Node 185.19.31.168 is running more than one daemon pod
Sep  9 14:20:32.677: INFO: Number of nodes with available pods: 2
Sep  9 14:20:32.677: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Sep  9 14:20:32.693: INFO: Number of nodes with available pods: 2
Sep  9 14:20:32.693: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2570, will wait for the garbage collector to delete the pods
Sep  9 14:20:33.771: INFO: Deleting DaemonSet.extensions daemon-set took: 12.187002ms
Sep  9 14:20:34.372: INFO: Terminating DaemonSet.extensions daemon-set pods took: 600.811108ms
Sep  9 14:21:49.976: INFO: Number of nodes with available pods: 0
Sep  9 14:21:49.976: INFO: Number of running nodes: 0, number of available pods: 0
Sep  9 14:21:49.983: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2570/daemonsets","resourceVersion":"71225"},"items":null}

Sep  9 14:21:49.985: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2570/pods","resourceVersion":"71225"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:21:49.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2570" for this suite.
Sep  9 14:21:56.011: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:21:56.093: INFO: namespace daemonsets-2570 deletion completed in 6.098428534s

• [SLOW TEST:85.630 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:21:56.093: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-5914
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:21:58.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-5914" for this suite.
Sep  9 14:22:04.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:22:04.458: INFO: namespace emptydir-wrapper-5914 deletion completed in 6.097781415s

• [SLOW TEST:8.365 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:22:04.458: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-2476
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Sep  9 14:22:04.624: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep  9 14:22:04.631: INFO: Waiting for terminating namespaces to be deleted...
Sep  9 14:22:04.633: INFO: 
Logging pods the kubelet thinks is on node 185.19.31.168 before test
Sep  9 14:22:04.644: INFO: fluentd-fluentd-elasticsearch-vqcrl from kube-system started at 2019-09-09 07:04:01 +0000 UTC (1 container statuses recorded)
Sep  9 14:22:04.644: INFO: 	Container fluentd-fluentd-elasticsearch ready: true, restart count 0
Sep  9 14:22:04.644: INFO: prometheus-operator-prometheus-node-exporter-pnbwc from monitoring started at 2019-09-09 13:46:48 +0000 UTC (1 container statuses recorded)
Sep  9 14:22:04.644: INFO: 	Container node-exporter ready: true, restart count 0
Sep  9 14:22:04.644: INFO: nginx-ingress-controller-xh9n9 from ingress-nginx started at 2019-09-09 13:46:48 +0000 UTC (1 container statuses recorded)
Sep  9 14:22:04.644: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Sep  9 14:22:04.644: INFO: rke-ingress-controller-deploy-job-hmk7s from kube-system started at 2019-09-09 07:00:59 +0000 UTC (1 container statuses recorded)
Sep  9 14:22:04.644: INFO: 	Container rke-ingress-controller-pod ready: false, restart count 0
Sep  9 14:22:04.644: INFO: sonobuoy-e2e-job-2f41c9be7abd4ce8 from heptio-sonobuoy started at 2019-09-09 13:52:27 +0000 UTC (2 container statuses recorded)
Sep  9 14:22:04.644: INFO: 	Container e2e ready: true, restart count 0
Sep  9 14:22:04.644: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  9 14:22:04.644: INFO: sonobuoy from heptio-sonobuoy started at 2019-09-09 13:52:25 +0000 UTC (1 container statuses recorded)
Sep  9 14:22:04.644: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep  9 14:22:04.644: INFO: falco-z7xtd from falco started at 2019-09-09 13:46:48 +0000 UTC (1 container statuses recorded)
Sep  9 14:22:04.644: INFO: 	Container falco ready: false, restart count 11
Sep  9 14:22:04.644: INFO: canal-zdgch from kube-system started at 2019-09-09 07:00:43 +0000 UTC (2 container statuses recorded)
Sep  9 14:22:04.644: INFO: 	Container calico-node ready: true, restart count 0
Sep  9 14:22:04.644: INFO: 	Container kube-flannel ready: true, restart count 0
Sep  9 14:22:04.644: INFO: rke-metrics-addon-deploy-job-9v7l5 from kube-system started at 2019-09-09 07:00:54 +0000 UTC (1 container statuses recorded)
Sep  9 14:22:04.644: INFO: 	Container rke-metrics-addon-pod ready: false, restart count 0
Sep  9 14:22:04.644: INFO: 
Logging pods the kubelet thinks is on node 185.19.31.68 before test
Sep  9 14:22:04.657: INFO: coredns-autoscaler-5d5d49b8ff-ctbzj from kube-system started at 2019-09-09 07:00:58 +0000 UTC (1 container statuses recorded)
Sep  9 14:22:04.657: INFO: 	Container autoscaler ready: true, restart count 0
Sep  9 14:22:04.657: INFO: kubernetes-metrics-scraper-79c9985bc6-mrxx6 from kube-system started at 2019-09-09 07:02:37 +0000 UTC (1 container statuses recorded)
Sep  9 14:22:04.657: INFO: 	Container kubernetes-metrics-scraper ready: true, restart count 0
Sep  9 14:22:04.657: INFO: fluentd-fluentd-elasticsearch-45rjj from kube-system started at 2019-09-09 07:04:01 +0000 UTC (1 container statuses recorded)
Sep  9 14:22:04.657: INFO: 	Container fluentd-fluentd-elasticsearch ready: true, restart count 0
Sep  9 14:22:04.657: INFO: nfs-client-provisioner-667644d49c-ttnfb from kube-system started at 2019-09-09 07:02:59 +0000 UTC (1 container statuses recorded)
Sep  9 14:22:04.657: INFO: 	Container nfs-client-provisioner ready: true, restart count 0
Sep  9 14:22:04.657: INFO: default-http-backend-5954bd5d8c-xqkx4 from ingress-nginx started at 2019-09-09 07:03:45 +0000 UTC (1 container statuses recorded)
Sep  9 14:22:04.657: INFO: 	Container default-http-backend ready: true, restart count 0
Sep  9 14:22:04.657: INFO: prometheus-operator-kube-state-metrics-59fb8495c9-jst6p from monitoring started at 2019-09-09 07:03:48 +0000 UTC (1 container statuses recorded)
Sep  9 14:22:04.657: INFO: 	Container kube-state-metrics ready: true, restart count 0
Sep  9 14:22:04.657: INFO: metrics-server-7f6bd4c888-ftrm2 from kube-system started at 2019-09-09 07:00:55 +0000 UTC (1 container statuses recorded)
Sep  9 14:22:04.657: INFO: 	Container metrics-server ready: true, restart count 0
Sep  9 14:22:04.657: INFO: opa-b6fb8dbff-xjctw from opa started at 2019-09-09 07:03:23 +0000 UTC (2 container statuses recorded)
Sep  9 14:22:04.657: INFO: 	Container mgmt ready: true, restart count 0
Sep  9 14:22:04.657: INFO: 	Container opa ready: true, restart count 0
Sep  9 14:22:04.657: INFO: prometheus-operator-prometheus-node-exporter-gph6w from monitoring started at 2019-09-09 07:03:48 +0000 UTC (1 container statuses recorded)
Sep  9 14:22:04.657: INFO: 	Container node-exporter ready: true, restart count 0
Sep  9 14:22:04.657: INFO: prometheus-prometheus-operator-prometheus-0 from monitoring started at 2019-09-09 07:04:02 +0000 UTC (3 container statuses recorded)
Sep  9 14:22:04.657: INFO: 	Container prometheus ready: true, restart count 1
Sep  9 14:22:04.657: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Sep  9 14:22:04.657: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
Sep  9 14:22:04.657: INFO: tiller-deploy-74bcc7bf9c-ng6b9 from kube-system started at 2019-09-09 07:02:29 +0000 UTC (1 container statuses recorded)
Sep  9 14:22:04.657: INFO: 	Container tiller ready: true, restart count 0
Sep  9 14:22:04.657: INFO: cert-manager-webhook-6484955794-jtctj from cert-manager started at 2019-09-09 07:02:58 +0000 UTC (1 container statuses recorded)
Sep  9 14:22:04.657: INFO: 	Container webhook ready: true, restart count 0
Sep  9 14:22:04.657: INFO: cert-manager-5d669ffbd8-zr582 from cert-manager started at 2019-09-09 07:02:58 +0000 UTC (1 container statuses recorded)
Sep  9 14:22:04.657: INFO: 	Container cert-manager ready: true, restart count 0
Sep  9 14:22:04.657: INFO: oauth2-oauth2-proxy-5b747dfb54-sbtd9 from kube-system started at 2019-09-09 07:03:22 +0000 UTC (1 container statuses recorded)
Sep  9 14:22:04.657: INFO: 	Container oauth2-proxy ready: true, restart count 2
Sep  9 14:22:04.657: INFO: prometheus-operator-operator-59578796bd-4xxr7 from monitoring started at 2019-09-09 07:03:48 +0000 UTC (1 container statuses recorded)
Sep  9 14:22:04.657: INFO: 	Container prometheus-operator ready: true, restart count 0
Sep  9 14:22:04.657: INFO: canal-kf52z from kube-system started at 2019-09-09 07:00:43 +0000 UTC (2 container statuses recorded)
Sep  9 14:22:04.657: INFO: 	Container calico-node ready: true, restart count 0
Sep  9 14:22:04.657: INFO: 	Container kube-flannel ready: true, restart count 0
Sep  9 14:22:04.657: INFO: nginx-ingress-controller-lvk92 from ingress-nginx started at 2019-09-09 07:03:45 +0000 UTC (1 container statuses recorded)
Sep  9 14:22:04.657: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Sep  9 14:22:04.657: INFO: coredns-bdffbc666-2s9bq from kube-system started at 2019-09-09 07:00:58 +0000 UTC (1 container statuses recorded)
Sep  9 14:22:04.657: INFO: 	Container coredns ready: true, restart count 0
Sep  9 14:22:04.657: INFO: cert-manager-cainjector-79b7fc64f-cmtcj from cert-manager started at 2019-09-09 07:02:58 +0000 UTC (1 container statuses recorded)
Sep  9 14:22:04.657: INFO: 	Container cainjector ready: true, restart count 0
Sep  9 14:22:04.657: INFO: kubernetes-dashboard-77997c455f-n2pd8 from kube-system started at 2019-09-09 07:02:37 +0000 UTC (1 container statuses recorded)
Sep  9 14:22:04.657: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Sep  9 14:22:04.657: INFO: falco-sbb9j from falco started at 2019-09-09 07:03:23 +0000 UTC (1 container statuses recorded)
Sep  9 14:22:04.657: INFO: 	Container falco ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: verifying the node has the label node 185.19.31.168
STEP: verifying the node has the label node 185.19.31.68
Sep  9 14:22:04.746: INFO: Pod cert-manager-5d669ffbd8-zr582 requesting resource cpu=0m on Node 185.19.31.68
Sep  9 14:22:04.746: INFO: Pod cert-manager-cainjector-79b7fc64f-cmtcj requesting resource cpu=0m on Node 185.19.31.68
Sep  9 14:22:04.746: INFO: Pod cert-manager-webhook-6484955794-jtctj requesting resource cpu=0m on Node 185.19.31.68
Sep  9 14:22:04.746: INFO: Pod falco-sbb9j requesting resource cpu=100m on Node 185.19.31.68
Sep  9 14:22:04.746: INFO: Pod falco-z7xtd requesting resource cpu=100m on Node 185.19.31.168
Sep  9 14:22:04.746: INFO: Pod sonobuoy requesting resource cpu=0m on Node 185.19.31.168
Sep  9 14:22:04.746: INFO: Pod sonobuoy-e2e-job-2f41c9be7abd4ce8 requesting resource cpu=0m on Node 185.19.31.168
Sep  9 14:22:04.746: INFO: Pod default-http-backend-5954bd5d8c-xqkx4 requesting resource cpu=10m on Node 185.19.31.68
Sep  9 14:22:04.746: INFO: Pod nginx-ingress-controller-lvk92 requesting resource cpu=0m on Node 185.19.31.68
Sep  9 14:22:04.746: INFO: Pod nginx-ingress-controller-xh9n9 requesting resource cpu=0m on Node 185.19.31.168
Sep  9 14:22:04.746: INFO: Pod canal-kf52z requesting resource cpu=250m on Node 185.19.31.68
Sep  9 14:22:04.746: INFO: Pod canal-zdgch requesting resource cpu=250m on Node 185.19.31.168
Sep  9 14:22:04.746: INFO: Pod coredns-autoscaler-5d5d49b8ff-ctbzj requesting resource cpu=20m on Node 185.19.31.68
Sep  9 14:22:04.746: INFO: Pod coredns-bdffbc666-2s9bq requesting resource cpu=100m on Node 185.19.31.68
Sep  9 14:22:04.746: INFO: Pod fluentd-fluentd-elasticsearch-45rjj requesting resource cpu=0m on Node 185.19.31.68
Sep  9 14:22:04.746: INFO: Pod fluentd-fluentd-elasticsearch-vqcrl requesting resource cpu=0m on Node 185.19.31.168
Sep  9 14:22:04.746: INFO: Pod kubernetes-dashboard-77997c455f-n2pd8 requesting resource cpu=0m on Node 185.19.31.68
Sep  9 14:22:04.746: INFO: Pod kubernetes-metrics-scraper-79c9985bc6-mrxx6 requesting resource cpu=0m on Node 185.19.31.68
Sep  9 14:22:04.746: INFO: Pod metrics-server-7f6bd4c888-ftrm2 requesting resource cpu=0m on Node 185.19.31.68
Sep  9 14:22:04.746: INFO: Pod nfs-client-provisioner-667644d49c-ttnfb requesting resource cpu=0m on Node 185.19.31.68
Sep  9 14:22:04.746: INFO: Pod oauth2-oauth2-proxy-5b747dfb54-sbtd9 requesting resource cpu=0m on Node 185.19.31.68
Sep  9 14:22:04.746: INFO: Pod tiller-deploy-74bcc7bf9c-ng6b9 requesting resource cpu=0m on Node 185.19.31.68
Sep  9 14:22:04.746: INFO: Pod prometheus-operator-kube-state-metrics-59fb8495c9-jst6p requesting resource cpu=0m on Node 185.19.31.68
Sep  9 14:22:04.746: INFO: Pod prometheus-operator-operator-59578796bd-4xxr7 requesting resource cpu=0m on Node 185.19.31.68
Sep  9 14:22:04.746: INFO: Pod prometheus-operator-prometheus-node-exporter-gph6w requesting resource cpu=0m on Node 185.19.31.68
Sep  9 14:22:04.746: INFO: Pod prometheus-operator-prometheus-node-exporter-pnbwc requesting resource cpu=0m on Node 185.19.31.168
Sep  9 14:22:04.746: INFO: Pod prometheus-prometheus-operator-prometheus-0 requesting resource cpu=200m on Node 185.19.31.68
Sep  9 14:22:04.746: INFO: Pod opa-b6fb8dbff-xjctw requesting resource cpu=0m on Node 185.19.31.68
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-328a3a57-d30d-11e9-b473-6e32a6bc259a.15c2cb18209793fa], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2476/filler-pod-328a3a57-d30d-11e9-b473-6e32a6bc259a to 185.19.31.168]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-328a3a57-d30d-11e9-b473-6e32a6bc259a.15c2cb1853f1e8b0], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-328a3a57-d30d-11e9-b473-6e32a6bc259a.15c2cb1858fa2c18], Reason = [Created], Message = [Created container filler-pod-328a3a57-d30d-11e9-b473-6e32a6bc259a]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-328a3a57-d30d-11e9-b473-6e32a6bc259a.15c2cb18690eb000], Reason = [Started], Message = [Started container filler-pod-328a3a57-d30d-11e9-b473-6e32a6bc259a]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-328c9399-d30d-11e9-b473-6e32a6bc259a.15c2cb18221e1f56], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2476/filler-pod-328c9399-d30d-11e9-b473-6e32a6bc259a to 185.19.31.68]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-328c9399-d30d-11e9-b473-6e32a6bc259a.15c2cb18574933e5], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-328c9399-d30d-11e9-b473-6e32a6bc259a.15c2cb185b8eb9af], Reason = [Created], Message = [Created container filler-pod-328c9399-d30d-11e9-b473-6e32a6bc259a]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-328c9399-d30d-11e9-b473-6e32a6bc259a.15c2cb186be0a166], Reason = [Started], Message = [Started container filler-pod-328c9399-d30d-11e9-b473-6e32a6bc259a]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15c2cb191216b3f4], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu.]
STEP: removing the label node off the node 185.19.31.168
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 185.19.31.68
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:22:09.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2476" for this suite.
Sep  9 14:22:15.898: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:22:15.979: INFO: namespace sched-pred-2476 deletion completed in 6.095889058s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:11.521 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:22:15.979: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-4636
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  9 14:22:16.151: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Sep  9 14:22:16.165: INFO: Pod name sample-pod: Found 0 pods out of 1
Sep  9 14:22:21.170: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep  9 14:22:21.170: INFO: Creating deployment "test-rolling-update-deployment"
Sep  9 14:22:21.179: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Sep  9 14:22:21.185: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Sep  9 14:22:23.193: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Sep  9 14:22:23.197: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703635741, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703635741, loc:(*time.Location)(0x8825120)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703635741, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703635741, loc:(*time.Location)(0x8825120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-57b6b5bb54\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  9 14:22:25.201: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703635741, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703635741, loc:(*time.Location)(0x8825120)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703635741, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703635741, loc:(*time.Location)(0x8825120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-57b6b5bb54\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  9 14:22:27.201: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Sep  9 14:22:27.210: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-4636,SelfLink:/apis/apps/v1/namespaces/deployment-4636/deployments/test-rolling-update-deployment,UID:3c5479fb-d30d-11e9-9321-0635e40003e4,ResourceVersion:71477,Generation:1,CreationTimestamp:2019-09-09 14:22:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-09-09 14:22:21 +0000 UTC 2019-09-09 14:22:21 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-09-09 14:22:25 +0000 UTC 2019-09-09 14:22:21 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-57b6b5bb54" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Sep  9 14:22:27.213: INFO: New ReplicaSet "test-rolling-update-deployment-57b6b5bb54" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-57b6b5bb54,GenerateName:,Namespace:deployment-4636,SelfLink:/apis/apps/v1/namespaces/deployment-4636/replicasets/test-rolling-update-deployment-57b6b5bb54,UID:3c590426-d30d-11e9-9321-0635e40003e4,ResourceVersion:71467,Generation:1,CreationTimestamp:2019-09-09 14:22:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 3c5479fb-d30d-11e9-9321-0635e40003e4 0xc0025bdbd7 0xc0025bdbd8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Sep  9 14:22:27.213: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Sep  9 14:22:27.213: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-4636,SelfLink:/apis/apps/v1/namespaces/deployment-4636/replicasets/test-rolling-update-controller,UID:39568fc0-d30d-11e9-9321-0635e40003e4,ResourceVersion:71476,Generation:2,CreationTimestamp:2019-09-09 14:22:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 3c5479fb-d30d-11e9-9321-0635e40003e4 0xc0025bdb07 0xc0025bdb08}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  9 14:22:27.215: INFO: Pod "test-rolling-update-deployment-57b6b5bb54-6k5c9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-57b6b5bb54-6k5c9,GenerateName:test-rolling-update-deployment-57b6b5bb54-,Namespace:deployment-4636,SelfLink:/api/v1/namespaces/deployment-4636/pods/test-rolling-update-deployment-57b6b5bb54-6k5c9,UID:3c5a7310-d30d-11e9-9321-0635e40003e4,ResourceVersion:71466,Generation:0,CreationTimestamp:2019-09-09 14:22:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.90/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-57b6b5bb54 3c590426-d30d-11e9-9321-0635e40003e4 0xc0018aa4b7 0xc0018aa4b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-n8kzm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-n8kzm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-n8kzm true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:185.19.31.168,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018aa530} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018aa550}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:22:21 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:22:25 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:22:25 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:22:21 +0000 UTC  }],Message:,Reason:,HostIP:185.19.31.168,PodIP:10.42.0.90,StartTime:2019-09-09 14:22:21 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-09-09 14:22:24 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://d4181dd2fba5ef1e9294a00d05c2d8c50f414cb592eb64e749788cba1bec2752}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:22:27.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4636" for this suite.
Sep  9 14:22:33.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:22:33.343: INFO: namespace deployment-4636 deletion completed in 6.12554708s

• [SLOW TEST:17.364 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:22:33.343: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-6541
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-6541
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep  9 14:22:33.515: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep  9 14:22:53.626: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.42.1.55 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6541 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  9 14:22:53.626: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
Sep  9 14:22:54.724: INFO: Found all expected endpoints: [netserver-0]
Sep  9 14:22:54.729: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.42.0.91 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6541 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  9 14:22:54.729: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
Sep  9 14:22:55.826: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:22:55.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6541" for this suite.
Sep  9 14:23:43.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:23:43.947: INFO: namespace pod-network-test-6541 deletion completed in 48.117168496s

• [SLOW TEST:70.604 seconds]
[sig-network] Networking
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:23:43.948: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3583
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Sep  9 14:23:48.741: INFO: Successfully updated pod "annotationupdate6dce6a4c-d30d-11e9-b473-6e32a6bc259a"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:23:50.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3583" for this suite.
Sep  9 14:24:12.779: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:24:12.853: INFO: namespace projected-3583 deletion completed in 22.088725338s

• [SLOW TEST:28.905 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:24:12.853: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1320
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  9 14:24:13.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-1320'
Sep  9 14:24:13.146: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep  9 14:24:13.146: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Sep  9 14:24:13.150: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Sep  9 14:24:13.155: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Sep  9 14:24:13.165: INFO: scanned /root for discovery docs: <nil>
Sep  9 14:24:13.165: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-1320'
Sep  9 14:24:28.981: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Sep  9 14:24:28.981: INFO: stdout: "Created e2e-test-nginx-rc-3cfa2e9cd9103e6d914f8dabdd440433\nScaling up e2e-test-nginx-rc-3cfa2e9cd9103e6d914f8dabdd440433 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-3cfa2e9cd9103e6d914f8dabdd440433 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-3cfa2e9cd9103e6d914f8dabdd440433 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Sep  9 14:24:28.981: INFO: stdout: "Created e2e-test-nginx-rc-3cfa2e9cd9103e6d914f8dabdd440433\nScaling up e2e-test-nginx-rc-3cfa2e9cd9103e6d914f8dabdd440433 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-3cfa2e9cd9103e6d914f8dabdd440433 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-3cfa2e9cd9103e6d914f8dabdd440433 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Sep  9 14:24:28.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-1320'
Sep  9 14:24:29.067: INFO: stderr: ""
Sep  9 14:24:29.067: INFO: stdout: "e2e-test-nginx-rc-3cfa2e9cd9103e6d914f8dabdd440433-ztktq "
Sep  9 14:24:29.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods e2e-test-nginx-rc-3cfa2e9cd9103e6d914f8dabdd440433-ztktq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1320'
Sep  9 14:24:29.158: INFO: stderr: ""
Sep  9 14:24:29.158: INFO: stdout: "true"
Sep  9 14:24:29.158: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods e2e-test-nginx-rc-3cfa2e9cd9103e6d914f8dabdd440433-ztktq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1320'
Sep  9 14:24:29.245: INFO: stderr: ""
Sep  9 14:24:29.245: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Sep  9 14:24:29.245: INFO: e2e-test-nginx-rc-3cfa2e9cd9103e6d914f8dabdd440433-ztktq is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1486
Sep  9 14:24:29.245: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 delete rc e2e-test-nginx-rc --namespace=kubectl-1320'
Sep  9 14:24:29.346: INFO: stderr: ""
Sep  9 14:24:29.346: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:24:29.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1320" for this suite.
Sep  9 14:24:51.368: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:24:51.447: INFO: namespace kubectl-1320 deletion completed in 22.094326953s

• [SLOW TEST:38.595 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:24:51.448: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1554
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-96012f53-d30d-11e9-b473-6e32a6bc259a
STEP: Creating configMap with name cm-test-opt-upd-96012fb1-d30d-11e9-b473-6e32a6bc259a
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-96012f53-d30d-11e9-b473-6e32a6bc259a
STEP: Updating configmap cm-test-opt-upd-96012fb1-d30d-11e9-b473-6e32a6bc259a
STEP: Creating configMap with name cm-test-opt-create-96012fd7-d30d-11e9-b473-6e32a6bc259a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:24:57.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1554" for this suite.
Sep  9 14:25:19.779: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:25:19.871: INFO: namespace configmap-1554 deletion completed in 22.110609012s

• [SLOW TEST:28.423 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:25:19.871: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4285
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-a6f108ec-d30d-11e9-b473-6e32a6bc259a
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-a6f108ec-d30d-11e9-b473-6e32a6bc259a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:26:40.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4285" for this suite.
Sep  9 14:27:02.547: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:27:02.620: INFO: namespace configmap-4285 deletion completed in 22.09149638s

• [SLOW TEST:102.748 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:27:02.620: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-877
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting the proxy server
Sep  9 14:27:02.785: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-310951909 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:27:02.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-877" for this suite.
Sep  9 14:27:08.877: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:27:08.955: INFO: namespace kubectl-877 deletion completed in 6.093397681s

• [SLOW TEST:6.335 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:27:08.955: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9043
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  9 14:27:09.119: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 version'
Sep  9 14:27:09.198: INFO: stderr: ""
Sep  9 14:27:09.198: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.6\", GitCommit:\"96fac5cd13a5dc064f7d9f4f23030a6aeface6cc\", GitTreeState:\"clean\", BuildDate:\"2019-08-19T11:13:49Z\", GoVersion:\"go1.12.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.6\", GitCommit:\"96fac5cd13a5dc064f7d9f4f23030a6aeface6cc\", GitTreeState:\"clean\", BuildDate:\"2019-08-19T11:05:16Z\", GoVersion:\"go1.12.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:27:09.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9043" for this suite.
Sep  9 14:27:15.218: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:27:15.320: INFO: namespace kubectl-9043 deletion completed in 6.118298189s

• [SLOW TEST:6.365 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:27:15.320: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-8960
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test use defaults
Sep  9 14:27:15.556: INFO: Waiting up to 5m0s for pod "client-containers-ebc9dca7-d30d-11e9-b473-6e32a6bc259a" in namespace "containers-8960" to be "success or failure"
Sep  9 14:27:15.565: INFO: Pod "client-containers-ebc9dca7-d30d-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 9.122587ms
Sep  9 14:27:17.570: INFO: Pod "client-containers-ebc9dca7-d30d-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013989296s
Sep  9 14:27:19.575: INFO: Pod "client-containers-ebc9dca7-d30d-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01892193s
STEP: Saw pod success
Sep  9 14:27:19.575: INFO: Pod "client-containers-ebc9dca7-d30d-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 14:27:19.578: INFO: Trying to get logs from node 185.19.31.168 pod client-containers-ebc9dca7-d30d-11e9-b473-6e32a6bc259a container test-container: <nil>
STEP: delete the pod
Sep  9 14:27:19.604: INFO: Waiting for pod client-containers-ebc9dca7-d30d-11e9-b473-6e32a6bc259a to disappear
Sep  9 14:27:19.609: INFO: Pod client-containers-ebc9dca7-d30d-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:27:19.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8960" for this suite.
Sep  9 14:27:25.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:27:25.737: INFO: namespace containers-8960 deletion completed in 6.114826278s

• [SLOW TEST:10.416 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:27:25.737: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3184
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  9 14:27:25.922: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f1f61420-d30d-11e9-b473-6e32a6bc259a" in namespace "projected-3184" to be "success or failure"
Sep  9 14:27:25.927: INFO: Pod "downwardapi-volume-f1f61420-d30d-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.824309ms
Sep  9 14:27:27.931: INFO: Pod "downwardapi-volume-f1f61420-d30d-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008838701s
STEP: Saw pod success
Sep  9 14:27:27.931: INFO: Pod "downwardapi-volume-f1f61420-d30d-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 14:27:27.934: INFO: Trying to get logs from node 185.19.31.168 pod downwardapi-volume-f1f61420-d30d-11e9-b473-6e32a6bc259a container client-container: <nil>
STEP: delete the pod
Sep  9 14:27:27.953: INFO: Waiting for pod downwardapi-volume-f1f61420-d30d-11e9-b473-6e32a6bc259a to disappear
Sep  9 14:27:27.958: INFO: Pod downwardapi-volume-f1f61420-d30d-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:27:27.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3184" for this suite.
Sep  9 14:27:33.979: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:27:34.065: INFO: namespace projected-3184 deletion completed in 6.101940541s

• [SLOW TEST:8.328 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:27:34.065: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9642
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-6266
STEP: Creating secret with name secret-test-f6ee8b56-d30d-11e9-b473-6e32a6bc259a
STEP: Creating a pod to test consume secrets
Sep  9 14:27:34.425: INFO: Waiting up to 5m0s for pod "pod-secrets-f709128f-d30d-11e9-b473-6e32a6bc259a" in namespace "secrets-9642" to be "success or failure"
Sep  9 14:27:34.428: INFO: Pod "pod-secrets-f709128f-d30d-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.089494ms
Sep  9 14:27:36.431: INFO: Pod "pod-secrets-f709128f-d30d-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006090653s
STEP: Saw pod success
Sep  9 14:27:36.431: INFO: Pod "pod-secrets-f709128f-d30d-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 14:27:36.434: INFO: Trying to get logs from node 185.19.31.168 pod pod-secrets-f709128f-d30d-11e9-b473-6e32a6bc259a container secret-volume-test: <nil>
STEP: delete the pod
Sep  9 14:27:36.456: INFO: Waiting for pod pod-secrets-f709128f-d30d-11e9-b473-6e32a6bc259a to disappear
Sep  9 14:27:36.459: INFO: Pod pod-secrets-f709128f-d30d-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:27:36.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9642" for this suite.
Sep  9 14:27:42.479: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:27:42.568: INFO: namespace secrets-9642 deletion completed in 6.104234545s
STEP: Destroying namespace "secret-namespace-6266" for this suite.
Sep  9 14:27:48.590: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:27:48.682: INFO: namespace secret-namespace-6266 deletion completed in 6.113639325s

• [SLOW TEST:14.617 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:27:48.682: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6424
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Sep  9 14:27:48.864: INFO: Waiting up to 5m0s for pod "pod-ffa3f909-d30d-11e9-b473-6e32a6bc259a" in namespace "emptydir-6424" to be "success or failure"
Sep  9 14:27:48.870: INFO: Pod "pod-ffa3f909-d30d-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.712327ms
Sep  9 14:27:50.877: INFO: Pod "pod-ffa3f909-d30d-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012975485s
Sep  9 14:27:52.881: INFO: Pod "pod-ffa3f909-d30d-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017174578s
STEP: Saw pod success
Sep  9 14:27:52.881: INFO: Pod "pod-ffa3f909-d30d-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 14:27:52.884: INFO: Trying to get logs from node 185.19.31.168 pod pod-ffa3f909-d30d-11e9-b473-6e32a6bc259a container test-container: <nil>
STEP: delete the pod
Sep  9 14:27:52.908: INFO: Waiting for pod pod-ffa3f909-d30d-11e9-b473-6e32a6bc259a to disappear
Sep  9 14:27:52.915: INFO: Pod pod-ffa3f909-d30d-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:27:52.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6424" for this suite.
Sep  9 14:27:58.935: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:27:59.047: INFO: namespace emptydir-6424 deletion completed in 6.12874394s

• [SLOW TEST:10.365 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:27:59.048: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-572
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-572
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep  9 14:27:59.229: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep  9 14:28:17.334: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.0.103:8080/dial?request=hostName&protocol=http&host=10.42.1.56&port=8080&tries=1'] Namespace:pod-network-test-572 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  9 14:28:17.334: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
Sep  9 14:28:17.441: INFO: Waiting for endpoints: map[]
Sep  9 14:28:17.445: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.0.103:8080/dial?request=hostName&protocol=http&host=10.42.0.102&port=8080&tries=1'] Namespace:pod-network-test-572 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  9 14:28:17.445: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
Sep  9 14:28:17.536: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:28:17.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-572" for this suite.
Sep  9 14:28:55.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:28:55.647: INFO: namespace pod-network-test-572 deletion completed in 38.106165669s

• [SLOW TEST:56.599 seconds]
[sig-network] Networking
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:28:55.647: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-716
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-278f46b5-d30e-11e9-b473-6e32a6bc259a
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:28:57.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-716" for this suite.
Sep  9 14:29:19.898: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:29:19.986: INFO: namespace configmap-716 deletion completed in 22.10538632s

• [SLOW TEST:24.339 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:29:19.987: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6613
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap that has name configmap-test-emptyKey-3610379a-d30e-11e9-b473-6e32a6bc259a
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:29:20.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6613" for this suite.
Sep  9 14:29:26.176: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:29:26.306: INFO: namespace configmap-6613 deletion completed in 6.145855523s

• [SLOW TEST:6.319 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:29:26.306: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3862
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  9 14:29:26.470: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 create -f - --namespace=kubectl-3862'
Sep  9 14:29:26.803: INFO: stderr: ""
Sep  9 14:29:26.803: INFO: stdout: "replicationcontroller/redis-master created\n"
Sep  9 14:29:26.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 create -f - --namespace=kubectl-3862'
Sep  9 14:29:27.016: INFO: stderr: ""
Sep  9 14:29:27.017: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Sep  9 14:29:28.021: INFO: Selector matched 1 pods for map[app:redis]
Sep  9 14:29:28.021: INFO: Found 0 / 1
Sep  9 14:29:29.022: INFO: Selector matched 1 pods for map[app:redis]
Sep  9 14:29:29.022: INFO: Found 1 / 1
Sep  9 14:29:29.022: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep  9 14:29:29.025: INFO: Selector matched 1 pods for map[app:redis]
Sep  9 14:29:29.025: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep  9 14:29:29.026: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 describe pod redis-master-x2jz7 --namespace=kubectl-3862'
Sep  9 14:29:29.126: INFO: stderr: ""
Sep  9 14:29:29.126: INFO: stdout: "Name:               redis-master-x2jz7\nNamespace:          kubectl-3862\nPriority:           0\nPriorityClassName:  <none>\nNode:               185.19.31.168/185.19.31.168\nStart Time:         Mon, 09 Sep 2019 14:29:26 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        cni.projectcalico.org/podIP: 10.42.0.105/32\n                    kubernetes.io/psp: e2e-test-privileged-psp\nStatus:             Running\nIP:                 10.42.0.105\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://120d5892b800da8b8e6ba002772f2705b5a011bdeb9c11587fdd72a75987481e\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 09 Sep 2019 14:29:27 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-g8hnv (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-g8hnv:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-g8hnv\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                    Message\n  ----    ------     ----  ----                    -------\n  Normal  Scheduled  3s    default-scheduler       Successfully assigned kubectl-3862/redis-master-x2jz7 to 185.19.31.168\n  Normal  Pulled     2s    kubelet, 185.19.31.168  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, 185.19.31.168  Created container redis-master\n  Normal  Started    2s    kubelet, 185.19.31.168  Started container redis-master\n"
Sep  9 14:29:29.126: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 describe rc redis-master --namespace=kubectl-3862'
Sep  9 14:29:29.230: INFO: stderr: ""
Sep  9 14:29:29.230: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-3862\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-x2jz7\n"
Sep  9 14:29:29.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 describe service redis-master --namespace=kubectl-3862'
Sep  9 14:29:29.331: INFO: stderr: ""
Sep  9 14:29:29.331: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-3862\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.43.11.0\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.42.0.105:6379\nSession Affinity:  None\nEvents:            <none>\n"
Sep  9 14:29:29.334: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 describe node 185.19.31.168'
Sep  9 14:29:29.444: INFO: stderr: ""
Sep  9 14:29:29.444: INFO: stdout: "Name:               185.19.31.168\nRoles:              controlplane,etcd\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=185.19.31.168\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/controlplane=true\n                    node-role.kubernetes.io/etcd=true\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"82:d7:69:45:75:8e\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 185.19.31.168\n                    node.alpha.kubernetes.io/ttl: 0\n                    rke.cattle.io/external-ip: 185.19.31.168\n                    rke.cattle.io/internal-ip: 185.19.31.168\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 09 Sep 2019 07:00:30 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Mon, 09 Sep 2019 14:29:10 +0000   Mon, 09 Sep 2019 07:00:30 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Mon, 09 Sep 2019 14:29:10 +0000   Mon, 09 Sep 2019 07:00:30 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Mon, 09 Sep 2019 14:29:10 +0000   Mon, 09 Sep 2019 07:00:30 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Mon, 09 Sep 2019 14:29:10 +0000   Mon, 09 Sep 2019 07:00:50 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  185.19.31.168\n  Hostname:    185.19.31.168\nCapacity:\n cpu:                4\n ephemeral-storage:  49081960Ki\n hugepages-2Mi:      0\n memory:             8170720Ki\n pods:               110\nAllocatable:\n cpu:                4\n ephemeral-storage:  45233934262\n hugepages-2Mi:      0\n memory:             8068320Ki\n pods:               110\nSystem Info:\n Machine ID:                 311936e2303b034fe7ef70182235b8cb\n System UUID:                008D9438-DCDB-45AB-9A4D-6BEE80D33955\n Boot ID:                    4f9e19c5-aaef-42f9-bb0c-31a9351c743e\n Kernel Version:             4.14.85-rancher\n OS Image:                   RancherOS v1.5.1\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.1\n Kubelet Version:            v1.14.6\n Kube-Proxy Version:         v1.14.6\nPodCIDR:                     10.42.0.0/24\nNon-terminated Pods:         (8 in total)\n  Namespace                  Name                                                  CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                  ------------  ----------  ---------------  -------------  ---\n  falco                      falco-z7xtd                                           100m (2%)     200m (5%)   512Mi (6%)       1Gi (12%)      42m\n  heptio-sonobuoy            sonobuoy                                              0 (0%)        0 (0%)      0 (0%)           0 (0%)         37m\n  heptio-sonobuoy            sonobuoy-e2e-job-2f41c9be7abd4ce8                     0 (0%)        0 (0%)      0 (0%)           0 (0%)         37m\n  ingress-nginx              nginx-ingress-controller-xh9n9                        0 (0%)        0 (0%)      0 (0%)           0 (0%)         42m\n  kube-system                canal-zdgch                                           250m (6%)     0 (0%)      0 (0%)           0 (0%)         7h28m\n  kube-system                fluentd-fluentd-elasticsearch-vqcrl                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         7h25m\n  kubectl-3862               redis-master-x2jz7                                    0 (0%)        0 (0%)      0 (0%)           0 (0%)         3s\n  monitoring                 prometheus-operator-prometheus-node-exporter-pnbwc    0 (0%)        0 (0%)      0 (0%)           0 (0%)         42m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                350m (8%)   200m (5%)\n  memory             512Mi (6%)  1Gi (12%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:              <none>\n"
Sep  9 14:29:29.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 describe namespace kubectl-3862'
Sep  9 14:29:29.540: INFO: stderr: ""
Sep  9 14:29:29.540: INFO: stdout: "Name:         kubectl-3862\nLabels:       e2e-framework=kubectl\n              e2e-run=106be669-d309-11e9-b473-6e32a6bc259a\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:29:29.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3862" for this suite.
Sep  9 14:29:51.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:29:51.644: INFO: namespace kubectl-3862 deletion completed in 22.101484295s

• [SLOW TEST:25.339 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:29:51.645: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1638
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating all guestbook components
Sep  9 14:29:51.857: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Sep  9 14:29:51.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 create -f - --namespace=kubectl-1638'
Sep  9 14:29:52.052: INFO: stderr: ""
Sep  9 14:29:52.052: INFO: stdout: "service/redis-slave created\n"
Sep  9 14:29:52.052: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Sep  9 14:29:52.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 create -f - --namespace=kubectl-1638'
Sep  9 14:29:52.243: INFO: stderr: ""
Sep  9 14:29:52.243: INFO: stdout: "service/redis-master created\n"
Sep  9 14:29:52.243: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Sep  9 14:29:52.244: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 create -f - --namespace=kubectl-1638'
Sep  9 14:29:52.444: INFO: stderr: ""
Sep  9 14:29:52.444: INFO: stdout: "service/frontend created\n"
Sep  9 14:29:52.444: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Sep  9 14:29:52.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 create -f - --namespace=kubectl-1638'
Sep  9 14:29:52.616: INFO: stderr: ""
Sep  9 14:29:52.616: INFO: stdout: "deployment.apps/frontend created\n"
Sep  9 14:29:52.616: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Sep  9 14:29:52.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 create -f - --namespace=kubectl-1638'
Sep  9 14:29:52.836: INFO: stderr: ""
Sep  9 14:29:52.836: INFO: stdout: "deployment.apps/redis-master created\n"
Sep  9 14:29:52.837: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Sep  9 14:29:52.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 create -f - --namespace=kubectl-1638'
Sep  9 14:29:53.038: INFO: stderr: ""
Sep  9 14:29:53.038: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Sep  9 14:29:53.038: INFO: Waiting for all frontend pods to be Running.
Sep  9 14:30:13.090: INFO: Waiting for frontend to serve content.
Sep  9 14:30:18.108: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Sep  9 14:30:23.145: INFO: Trying to add a new entry to the guestbook.
Sep  9 14:30:23.161: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Sep  9 14:30:23.173: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 delete --grace-period=0 --force -f - --namespace=kubectl-1638'
Sep  9 14:30:23.282: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  9 14:30:23.282: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Sep  9 14:30:23.283: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 delete --grace-period=0 --force -f - --namespace=kubectl-1638'
Sep  9 14:30:23.381: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  9 14:30:23.381: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Sep  9 14:30:23.381: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 delete --grace-period=0 --force -f - --namespace=kubectl-1638'
Sep  9 14:30:23.483: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  9 14:30:23.483: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Sep  9 14:30:23.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 delete --grace-period=0 --force -f - --namespace=kubectl-1638'
Sep  9 14:30:23.571: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  9 14:30:23.571: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Sep  9 14:30:23.571: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 delete --grace-period=0 --force -f - --namespace=kubectl-1638'
Sep  9 14:30:23.660: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  9 14:30:23.660: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Sep  9 14:30:23.660: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 delete --grace-period=0 --force -f - --namespace=kubectl-1638'
Sep  9 14:30:23.761: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  9 14:30:23.761: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:30:23.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1638" for this suite.
Sep  9 14:31:05.778: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:31:05.860: INFO: namespace kubectl-1638 deletion completed in 42.096132244s

• [SLOW TEST:74.215 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:31:05.860: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-8878
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8878.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-8878.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8878.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8878.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-8878.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8878.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep  9 14:31:20.070: INFO: DNS probes using dns-8878/dns-test-7529ac86-d30e-11e9-b473-6e32a6bc259a succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:31:20.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8878" for this suite.
Sep  9 14:31:26.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:31:26.197: INFO: namespace dns-8878 deletion completed in 6.099093139s

• [SLOW TEST:20.337 seconds]
[sig-network] DNS
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:31:26.197: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5197
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-814a6587-d30e-11e9-b473-6e32a6bc259a
STEP: Creating a pod to test consume secrets
Sep  9 14:31:26.394: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-814c2ba7-d30e-11e9-b473-6e32a6bc259a" in namespace "projected-5197" to be "success or failure"
Sep  9 14:31:26.400: INFO: Pod "pod-projected-secrets-814c2ba7-d30e-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.058253ms
Sep  9 14:31:28.405: INFO: Pod "pod-projected-secrets-814c2ba7-d30e-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010744287s
STEP: Saw pod success
Sep  9 14:31:28.405: INFO: Pod "pod-projected-secrets-814c2ba7-d30e-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 14:31:28.409: INFO: Trying to get logs from node 185.19.31.168 pod pod-projected-secrets-814c2ba7-d30e-11e9-b473-6e32a6bc259a container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep  9 14:31:28.443: INFO: Waiting for pod pod-projected-secrets-814c2ba7-d30e-11e9-b473-6e32a6bc259a to disappear
Sep  9 14:31:28.446: INFO: Pod pod-projected-secrets-814c2ba7-d30e-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:31:28.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5197" for this suite.
Sep  9 14:31:34.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:31:34.556: INFO: namespace projected-5197 deletion completed in 6.106760747s

• [SLOW TEST:8.359 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:31:34.556: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5658
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Sep  9 14:31:34.731: INFO: Waiting up to 5m0s for pod "pod-86450d01-d30e-11e9-b473-6e32a6bc259a" in namespace "emptydir-5658" to be "success or failure"
Sep  9 14:31:34.733: INFO: Pod "pod-86450d01-d30e-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.373296ms
Sep  9 14:31:36.736: INFO: Pod "pod-86450d01-d30e-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005799017s
Sep  9 14:31:38.741: INFO: Pod "pod-86450d01-d30e-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010006441s
STEP: Saw pod success
Sep  9 14:31:38.741: INFO: Pod "pod-86450d01-d30e-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 14:31:38.744: INFO: Trying to get logs from node 185.19.31.168 pod pod-86450d01-d30e-11e9-b473-6e32a6bc259a container test-container: <nil>
STEP: delete the pod
Sep  9 14:31:38.771: INFO: Waiting for pod pod-86450d01-d30e-11e9-b473-6e32a6bc259a to disappear
Sep  9 14:31:38.773: INFO: Pod pod-86450d01-d30e-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:31:38.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5658" for this suite.
Sep  9 14:31:44.796: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:31:44.881: INFO: namespace emptydir-5658 deletion completed in 6.104428064s

• [SLOW TEST:10.325 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:31:44.881: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-1271
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Sep  9 14:31:45.045: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep  9 14:31:45.051: INFO: Waiting for terminating namespaces to be deleted...
Sep  9 14:31:45.053: INFO: 
Logging pods the kubelet thinks is on node 185.19.31.168 before test
Sep  9 14:31:45.059: INFO: falco-z7xtd from falco started at 2019-09-09 13:46:48 +0000 UTC (1 container statuses recorded)
Sep  9 14:31:45.059: INFO: 	Container falco ready: false, restart count 13
Sep  9 14:31:45.059: INFO: canal-zdgch from kube-system started at 2019-09-09 07:00:43 +0000 UTC (2 container statuses recorded)
Sep  9 14:31:45.059: INFO: 	Container calico-node ready: true, restart count 0
Sep  9 14:31:45.059: INFO: 	Container kube-flannel ready: true, restart count 0
Sep  9 14:31:45.059: INFO: rke-metrics-addon-deploy-job-9v7l5 from kube-system started at 2019-09-09 07:00:54 +0000 UTC (1 container statuses recorded)
Sep  9 14:31:45.059: INFO: 	Container rke-metrics-addon-pod ready: false, restart count 0
Sep  9 14:31:45.059: INFO: fluentd-fluentd-elasticsearch-vqcrl from kube-system started at 2019-09-09 07:04:01 +0000 UTC (1 container statuses recorded)
Sep  9 14:31:45.059: INFO: 	Container fluentd-fluentd-elasticsearch ready: true, restart count 0
Sep  9 14:31:45.059: INFO: prometheus-operator-prometheus-node-exporter-pnbwc from monitoring started at 2019-09-09 13:46:48 +0000 UTC (1 container statuses recorded)
Sep  9 14:31:45.059: INFO: 	Container node-exporter ready: true, restart count 0
Sep  9 14:31:45.059: INFO: nginx-ingress-controller-xh9n9 from ingress-nginx started at 2019-09-09 13:46:48 +0000 UTC (1 container statuses recorded)
Sep  9 14:31:45.059: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Sep  9 14:31:45.059: INFO: rke-ingress-controller-deploy-job-hmk7s from kube-system started at 2019-09-09 07:00:59 +0000 UTC (1 container statuses recorded)
Sep  9 14:31:45.059: INFO: 	Container rke-ingress-controller-pod ready: false, restart count 0
Sep  9 14:31:45.059: INFO: sonobuoy-e2e-job-2f41c9be7abd4ce8 from heptio-sonobuoy started at 2019-09-09 13:52:27 +0000 UTC (2 container statuses recorded)
Sep  9 14:31:45.059: INFO: 	Container e2e ready: true, restart count 0
Sep  9 14:31:45.059: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  9 14:31:45.059: INFO: sonobuoy from heptio-sonobuoy started at 2019-09-09 13:52:25 +0000 UTC (1 container statuses recorded)
Sep  9 14:31:45.059: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep  9 14:31:45.059: INFO: 
Logging pods the kubelet thinks is on node 185.19.31.68 before test
Sep  9 14:31:45.071: INFO: kubernetes-dashboard-77997c455f-n2pd8 from kube-system started at 2019-09-09 07:02:37 +0000 UTC (1 container statuses recorded)
Sep  9 14:31:45.071: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Sep  9 14:31:45.071: INFO: falco-sbb9j from falco started at 2019-09-09 07:03:23 +0000 UTC (1 container statuses recorded)
Sep  9 14:31:45.071: INFO: 	Container falco ready: true, restart count 0
Sep  9 14:31:45.071: INFO: coredns-autoscaler-5d5d49b8ff-ctbzj from kube-system started at 2019-09-09 07:00:58 +0000 UTC (1 container statuses recorded)
Sep  9 14:31:45.071: INFO: 	Container autoscaler ready: true, restart count 0
Sep  9 14:31:45.071: INFO: kubernetes-metrics-scraper-79c9985bc6-mrxx6 from kube-system started at 2019-09-09 07:02:37 +0000 UTC (1 container statuses recorded)
Sep  9 14:31:45.071: INFO: 	Container kubernetes-metrics-scraper ready: true, restart count 0
Sep  9 14:31:45.071: INFO: fluentd-fluentd-elasticsearch-45rjj from kube-system started at 2019-09-09 07:04:01 +0000 UTC (1 container statuses recorded)
Sep  9 14:31:45.071: INFO: 	Container fluentd-fluentd-elasticsearch ready: true, restart count 0
Sep  9 14:31:45.071: INFO: nfs-client-provisioner-667644d49c-ttnfb from kube-system started at 2019-09-09 07:02:59 +0000 UTC (1 container statuses recorded)
Sep  9 14:31:45.071: INFO: 	Container nfs-client-provisioner ready: true, restart count 0
Sep  9 14:31:45.071: INFO: default-http-backend-5954bd5d8c-xqkx4 from ingress-nginx started at 2019-09-09 07:03:45 +0000 UTC (1 container statuses recorded)
Sep  9 14:31:45.071: INFO: 	Container default-http-backend ready: true, restart count 0
Sep  9 14:31:45.071: INFO: prometheus-operator-kube-state-metrics-59fb8495c9-jst6p from monitoring started at 2019-09-09 07:03:48 +0000 UTC (1 container statuses recorded)
Sep  9 14:31:45.071: INFO: 	Container kube-state-metrics ready: true, restart count 0
Sep  9 14:31:45.071: INFO: metrics-server-7f6bd4c888-ftrm2 from kube-system started at 2019-09-09 07:00:55 +0000 UTC (1 container statuses recorded)
Sep  9 14:31:45.071: INFO: 	Container metrics-server ready: true, restart count 0
Sep  9 14:31:45.071: INFO: opa-b6fb8dbff-xjctw from opa started at 2019-09-09 07:03:23 +0000 UTC (2 container statuses recorded)
Sep  9 14:31:45.071: INFO: 	Container mgmt ready: true, restart count 0
Sep  9 14:31:45.071: INFO: 	Container opa ready: true, restart count 0
Sep  9 14:31:45.071: INFO: prometheus-operator-prometheus-node-exporter-gph6w from monitoring started at 2019-09-09 07:03:48 +0000 UTC (1 container statuses recorded)
Sep  9 14:31:45.071: INFO: 	Container node-exporter ready: true, restart count 0
Sep  9 14:31:45.071: INFO: prometheus-prometheus-operator-prometheus-0 from monitoring started at 2019-09-09 07:04:02 +0000 UTC (3 container statuses recorded)
Sep  9 14:31:45.071: INFO: 	Container prometheus ready: true, restart count 1
Sep  9 14:31:45.071: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Sep  9 14:31:45.071: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
Sep  9 14:31:45.071: INFO: tiller-deploy-74bcc7bf9c-ng6b9 from kube-system started at 2019-09-09 07:02:29 +0000 UTC (1 container statuses recorded)
Sep  9 14:31:45.071: INFO: 	Container tiller ready: true, restart count 0
Sep  9 14:31:45.071: INFO: cert-manager-webhook-6484955794-jtctj from cert-manager started at 2019-09-09 07:02:58 +0000 UTC (1 container statuses recorded)
Sep  9 14:31:45.071: INFO: 	Container webhook ready: true, restart count 0
Sep  9 14:31:45.071: INFO: cert-manager-5d669ffbd8-zr582 from cert-manager started at 2019-09-09 07:02:58 +0000 UTC (1 container statuses recorded)
Sep  9 14:31:45.071: INFO: 	Container cert-manager ready: true, restart count 0
Sep  9 14:31:45.071: INFO: oauth2-oauth2-proxy-5b747dfb54-sbtd9 from kube-system started at 2019-09-09 07:03:22 +0000 UTC (1 container statuses recorded)
Sep  9 14:31:45.071: INFO: 	Container oauth2-proxy ready: true, restart count 2
Sep  9 14:31:45.071: INFO: prometheus-operator-operator-59578796bd-4xxr7 from monitoring started at 2019-09-09 07:03:48 +0000 UTC (1 container statuses recorded)
Sep  9 14:31:45.071: INFO: 	Container prometheus-operator ready: true, restart count 0
Sep  9 14:31:45.071: INFO: canal-kf52z from kube-system started at 2019-09-09 07:00:43 +0000 UTC (2 container statuses recorded)
Sep  9 14:31:45.071: INFO: 	Container calico-node ready: true, restart count 0
Sep  9 14:31:45.071: INFO: 	Container kube-flannel ready: true, restart count 0
Sep  9 14:31:45.071: INFO: nginx-ingress-controller-lvk92 from ingress-nginx started at 2019-09-09 07:03:45 +0000 UTC (1 container statuses recorded)
Sep  9 14:31:45.071: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Sep  9 14:31:45.071: INFO: coredns-bdffbc666-2s9bq from kube-system started at 2019-09-09 07:00:58 +0000 UTC (1 container statuses recorded)
Sep  9 14:31:45.071: INFO: 	Container coredns ready: true, restart count 0
Sep  9 14:31:45.071: INFO: cert-manager-cainjector-79b7fc64f-cmtcj from cert-manager started at 2019-09-09 07:02:58 +0000 UTC (1 container statuses recorded)
Sep  9 14:31:45.071: INFO: 	Container cainjector ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-8da87a15-d30e-11e9-b473-6e32a6bc259a 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-8da87a15-d30e-11e9-b473-6e32a6bc259a off the node 185.19.31.168
STEP: verifying the node doesn't have the label kubernetes.io/e2e-8da87a15-d30e-11e9-b473-6e32a6bc259a
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:31:49.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1271" for this suite.
Sep  9 14:32:01.207: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:32:01.290: INFO: namespace sched-pred-1271 deletion completed in 12.097481172s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:16.409 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:32:01.290: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9306
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1685
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  9 14:32:01.466: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-9306'
Sep  9 14:32:01.581: INFO: stderr: ""
Sep  9 14:32:01.581: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Sep  9 14:32:06.632: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pod e2e-test-nginx-pod --namespace=kubectl-9306 -o json'
Sep  9 14:32:06.715: INFO: stderr: ""
Sep  9 14:32:06.715: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"10.42.0.115/32\",\n            \"kubernetes.io/psp\": \"default-psp\"\n        },\n        \"creationTimestamp\": \"2019-09-09T14:32:01Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-9306\",\n        \"resourceVersion\": \"73951\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-9306/pods/e2e-test-nginx-pod\",\n        \"uid\": \"96438342-d30e-11e9-9321-0635e40003e4\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-nq9wz\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"185.19.31.168\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-nq9wz\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-nq9wz\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-09T14:32:01Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-09T14:32:03Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-09T14:32:03Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-09T14:32:01Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://c5961ffe1fce97512a54498cdad53c00f7ccf05261e6c55b80a3a0a9ac302c62\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-09-09T14:32:02Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"185.19.31.168\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.42.0.115\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-09-09T14:32:01Z\"\n    }\n}\n"
STEP: replace the image in the pod
Sep  9 14:32:06.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 replace -f - --namespace=kubectl-9306'
Sep  9 14:32:06.916: INFO: stderr: ""
Sep  9 14:32:06.916: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1690
Sep  9 14:32:06.919: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 delete pods e2e-test-nginx-pod --namespace=kubectl-9306'
Sep  9 14:32:08.524: INFO: stderr: ""
Sep  9 14:32:08.524: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:32:08.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9306" for this suite.
Sep  9 14:32:14.546: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:32:14.630: INFO: namespace kubectl-9306 deletion completed in 6.103558793s

• [SLOW TEST:13.340 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:32:14.631: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-3793
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0909 14:32:24.930392      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  9 14:32:24.930: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:32:24.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3793" for this suite.
Sep  9 14:32:30.950: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:32:31.034: INFO: namespace gc-3793 deletion completed in 6.10069117s

• [SLOW TEST:16.404 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:32:31.035: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3494
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-3494/configmap-test-a7ee9947-d30e-11e9-b473-6e32a6bc259a
STEP: Creating a pod to test consume configMaps
Sep  9 14:32:31.222: INFO: Waiting up to 5m0s for pod "pod-configmaps-a7f139cb-d30e-11e9-b473-6e32a6bc259a" in namespace "configmap-3494" to be "success or failure"
Sep  9 14:32:31.224: INFO: Pod "pod-configmaps-a7f139cb-d30e-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.838786ms
Sep  9 14:32:33.230: INFO: Pod "pod-configmaps-a7f139cb-d30e-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008247254s
STEP: Saw pod success
Sep  9 14:32:33.230: INFO: Pod "pod-configmaps-a7f139cb-d30e-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 14:32:33.234: INFO: Trying to get logs from node 185.19.31.168 pod pod-configmaps-a7f139cb-d30e-11e9-b473-6e32a6bc259a container env-test: <nil>
STEP: delete the pod
Sep  9 14:32:33.270: INFO: Waiting for pod pod-configmaps-a7f139cb-d30e-11e9-b473-6e32a6bc259a to disappear
Sep  9 14:32:33.272: INFO: Pod pod-configmaps-a7f139cb-d30e-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:32:33.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3494" for this suite.
Sep  9 14:32:39.292: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:32:39.380: INFO: namespace configmap-3494 deletion completed in 6.105045336s

• [SLOW TEST:8.345 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:32:39.380: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-4960
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  9 14:32:39.567: INFO: Create a RollingUpdate DaemonSet
Sep  9 14:32:39.577: INFO: Check that daemon pods launch on every node of the cluster
Sep  9 14:32:39.583: INFO: Number of nodes with available pods: 0
Sep  9 14:32:39.583: INFO: Node 185.19.31.168 is running more than one daemon pod
Sep  9 14:32:40.589: INFO: Number of nodes with available pods: 0
Sep  9 14:32:40.589: INFO: Node 185.19.31.168 is running more than one daemon pod
Sep  9 14:32:41.591: INFO: Number of nodes with available pods: 2
Sep  9 14:32:41.591: INFO: Number of running nodes: 2, number of available pods: 2
Sep  9 14:32:41.591: INFO: Update the DaemonSet to trigger a rollout
Sep  9 14:32:41.731: INFO: Updating DaemonSet daemon-set
Sep  9 14:32:54.744: INFO: Roll back the DaemonSet before rollout is complete
Sep  9 14:32:54.763: INFO: Updating DaemonSet daemon-set
Sep  9 14:32:54.763: INFO: Make sure DaemonSet rollback is complete
Sep  9 14:32:54.767: INFO: Wrong image for pod: daemon-set-ktqgw. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Sep  9 14:32:54.767: INFO: Pod daemon-set-ktqgw is not available
Sep  9 14:32:55.777: INFO: Wrong image for pod: daemon-set-ktqgw. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Sep  9 14:32:55.778: INFO: Pod daemon-set-ktqgw is not available
Sep  9 14:32:57.776: INFO: Pod daemon-set-7h9g8 is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4960, will wait for the garbage collector to delete the pods
Sep  9 14:32:57.852: INFO: Deleting DaemonSet.extensions daemon-set took: 13.921293ms
Sep  9 14:32:58.453: INFO: Terminating DaemonSet.extensions daemon-set pods took: 600.335655ms
Sep  9 14:34:33.858: INFO: Number of nodes with available pods: 0
Sep  9 14:34:33.858: INFO: Number of running nodes: 0, number of available pods: 0
Sep  9 14:34:33.860: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4960/daemonsets","resourceVersion":"74698"},"items":null}

Sep  9 14:34:33.863: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4960/pods","resourceVersion":"74698"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:34:33.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4960" for this suite.
Sep  9 14:34:39.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:34:39.990: INFO: namespace daemonsets-4960 deletion completed in 6.115378052s

• [SLOW TEST:120.610 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:34:39.990: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5419
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-f4cbe7b9-d30e-11e9-b473-6e32a6bc259a
STEP: Creating a pod to test consume secrets
Sep  9 14:34:40.182: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f4cecef2-d30e-11e9-b473-6e32a6bc259a" in namespace "projected-5419" to be "success or failure"
Sep  9 14:34:40.186: INFO: Pod "pod-projected-secrets-f4cecef2-d30e-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.885382ms
Sep  9 14:34:42.191: INFO: Pod "pod-projected-secrets-f4cecef2-d30e-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008824419s
STEP: Saw pod success
Sep  9 14:34:42.191: INFO: Pod "pod-projected-secrets-f4cecef2-d30e-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 14:34:42.194: INFO: Trying to get logs from node 185.19.31.168 pod pod-projected-secrets-f4cecef2-d30e-11e9-b473-6e32a6bc259a container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep  9 14:34:42.337: INFO: Waiting for pod pod-projected-secrets-f4cecef2-d30e-11e9-b473-6e32a6bc259a to disappear
Sep  9 14:34:42.339: INFO: Pod pod-projected-secrets-f4cecef2-d30e-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:34:42.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5419" for this suite.
Sep  9 14:34:48.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:34:48.457: INFO: namespace projected-5419 deletion completed in 6.115960506s

• [SLOW TEST:8.467 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:34:48.458: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3614
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Sep  9 14:34:48.639: INFO: Waiting up to 5m0s for pod "pod-f9d8a3da-d30e-11e9-b473-6e32a6bc259a" in namespace "emptydir-3614" to be "success or failure"
Sep  9 14:34:48.643: INFO: Pod "pod-f9d8a3da-d30e-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.52675ms
Sep  9 14:34:50.647: INFO: Pod "pod-f9d8a3da-d30e-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007966301s
STEP: Saw pod success
Sep  9 14:34:50.647: INFO: Pod "pod-f9d8a3da-d30e-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 14:34:50.650: INFO: Trying to get logs from node 185.19.31.168 pod pod-f9d8a3da-d30e-11e9-b473-6e32a6bc259a container test-container: <nil>
STEP: delete the pod
Sep  9 14:34:50.683: INFO: Waiting for pod pod-f9d8a3da-d30e-11e9-b473-6e32a6bc259a to disappear
Sep  9 14:34:50.690: INFO: Pod pod-f9d8a3da-d30e-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:34:50.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3614" for this suite.
Sep  9 14:34:56.712: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:34:56.787: INFO: namespace emptydir-3614 deletion completed in 6.092068662s

• [SLOW TEST:8.330 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:34:56.788: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7591
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  9 14:34:56.966: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fecebfd7-d30e-11e9-b473-6e32a6bc259a" in namespace "downward-api-7591" to be "success or failure"
Sep  9 14:34:56.980: INFO: Pod "downwardapi-volume-fecebfd7-d30e-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 14.886372ms
Sep  9 14:34:58.985: INFO: Pod "downwardapi-volume-fecebfd7-d30e-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019094679s
STEP: Saw pod success
Sep  9 14:34:58.985: INFO: Pod "downwardapi-volume-fecebfd7-d30e-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 14:34:58.989: INFO: Trying to get logs from node 185.19.31.168 pod downwardapi-volume-fecebfd7-d30e-11e9-b473-6e32a6bc259a container client-container: <nil>
STEP: delete the pod
Sep  9 14:34:59.026: INFO: Waiting for pod downwardapi-volume-fecebfd7-d30e-11e9-b473-6e32a6bc259a to disappear
Sep  9 14:34:59.029: INFO: Pod downwardapi-volume-fecebfd7-d30e-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:34:59.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7591" for this suite.
Sep  9 14:35:05.048: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:35:05.136: INFO: namespace downward-api-7591 deletion completed in 6.104739693s

• [SLOW TEST:8.348 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:35:05.136: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-2266
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:35:05.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2266" for this suite.
Sep  9 14:35:11.349: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:35:11.439: INFO: namespace kubelet-test-2266 deletion completed in 6.102914468s

• [SLOW TEST:6.303 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:35:11.439: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-867
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-078bd853-d30f-11e9-b473-6e32a6bc259a
STEP: Creating a pod to test consume configMaps
Sep  9 14:35:11.631: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-078d63e7-d30f-11e9-b473-6e32a6bc259a" in namespace "projected-867" to be "success or failure"
Sep  9 14:35:11.637: INFO: Pod "pod-projected-configmaps-078d63e7-d30f-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.343235ms
Sep  9 14:35:13.642: INFO: Pod "pod-projected-configmaps-078d63e7-d30f-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010614406s
STEP: Saw pod success
Sep  9 14:35:13.642: INFO: Pod "pod-projected-configmaps-078d63e7-d30f-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 14:35:13.645: INFO: Trying to get logs from node 185.19.31.168 pod pod-projected-configmaps-078d63e7-d30f-11e9-b473-6e32a6bc259a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  9 14:35:13.671: INFO: Waiting for pod pod-projected-configmaps-078d63e7-d30f-11e9-b473-6e32a6bc259a to disappear
Sep  9 14:35:13.675: INFO: Pod pod-projected-configmaps-078d63e7-d30f-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:35:13.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-867" for this suite.
Sep  9 14:35:19.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:35:19.771: INFO: namespace projected-867 deletion completed in 6.092905203s

• [SLOW TEST:8.332 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:35:19.771: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-2367
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-2367
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Sep  9 14:35:19.992: INFO: Found 0 stateful pods, waiting for 3
Sep  9 14:35:29.997: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep  9 14:35:29.997: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep  9 14:35:29.997: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Sep  9 14:35:30.035: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Sep  9 14:35:40.083: INFO: Updating stateful set ss2
Sep  9 14:35:40.090: INFO: Waiting for Pod statefulset-2367/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Restoring Pods to the correct revision when they are deleted
Sep  9 14:35:50.154: INFO: Found 1 stateful pods, waiting for 3
Sep  9 14:36:00.160: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep  9 14:36:00.160: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep  9 14:36:00.160: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Sep  9 14:36:00.192: INFO: Updating stateful set ss2
Sep  9 14:36:00.234: INFO: Waiting for Pod statefulset-2367/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Sep  9 14:36:10.267: INFO: Updating stateful set ss2
Sep  9 14:36:10.274: INFO: Waiting for StatefulSet statefulset-2367/ss2 to complete update
Sep  9 14:36:10.274: INFO: Waiting for Pod statefulset-2367/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Sep  9 14:36:20.284: INFO: Deleting all statefulset in ns statefulset-2367
Sep  9 14:36:20.287: INFO: Scaling statefulset ss2 to 0
Sep  9 14:36:40.313: INFO: Waiting for statefulset status.replicas updated to 0
Sep  9 14:36:40.316: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:36:40.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2367" for this suite.
Sep  9 14:36:46.349: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:36:46.432: INFO: namespace statefulset-2367 deletion completed in 6.099125711s

• [SLOW TEST:86.661 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:36:46.433: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-796
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  9 14:36:46.615: INFO: Pod name rollover-pod: Found 0 pods out of 1
Sep  9 14:36:51.622: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep  9 14:36:51.622: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Sep  9 14:36:53.629: INFO: Creating deployment "test-rollover-deployment"
Sep  9 14:36:53.644: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Sep  9 14:36:55.652: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Sep  9 14:36:55.658: INFO: Ensure that both replica sets have 1 created replica
Sep  9 14:36:55.663: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Sep  9 14:36:55.676: INFO: Updating deployment test-rollover-deployment
Sep  9 14:36:55.676: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Sep  9 14:36:57.683: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Sep  9 14:36:57.690: INFO: Make sure deployment "test-rollover-deployment" is complete
Sep  9 14:36:57.696: INFO: all replica sets need to contain the pod-template-hash label
Sep  9 14:36:57.696: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703636613, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703636613, loc:(*time.Location)(0x8825120)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703636617, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703636613, loc:(*time.Location)(0x8825120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  9 14:36:59.704: INFO: all replica sets need to contain the pod-template-hash label
Sep  9 14:36:59.704: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703636613, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703636613, loc:(*time.Location)(0x8825120)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703636617, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703636613, loc:(*time.Location)(0x8825120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  9 14:37:01.704: INFO: all replica sets need to contain the pod-template-hash label
Sep  9 14:37:01.704: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703636613, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703636613, loc:(*time.Location)(0x8825120)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703636617, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703636613, loc:(*time.Location)(0x8825120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  9 14:37:03.704: INFO: all replica sets need to contain the pod-template-hash label
Sep  9 14:37:03.704: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703636613, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703636613, loc:(*time.Location)(0x8825120)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703636617, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703636613, loc:(*time.Location)(0x8825120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  9 14:37:05.706: INFO: all replica sets need to contain the pod-template-hash label
Sep  9 14:37:05.706: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703636613, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703636613, loc:(*time.Location)(0x8825120)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703636617, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703636613, loc:(*time.Location)(0x8825120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  9 14:37:07.703: INFO: 
Sep  9 14:37:07.703: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Sep  9 14:37:07.718: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-796,SelfLink:/apis/apps/v1/namespaces/deployment-796/deployments/test-rollover-deployment,UID:445b2aca-d30f-11e9-9321-0635e40003e4,ResourceVersion:75591,Generation:2,CreationTimestamp:2019-09-09 14:36:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-09-09 14:36:53 +0000 UTC 2019-09-09 14:36:53 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-09-09 14:37:07 +0000 UTC 2019-09-09 14:36:53 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-659c699649" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Sep  9 14:37:07.723: INFO: New ReplicaSet "test-rollover-deployment-659c699649" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-659c699649,GenerateName:,Namespace:deployment-796,SelfLink:/apis/apps/v1/namespaces/deployment-796/replicasets/test-rollover-deployment-659c699649,UID:45935d65-d30f-11e9-9321-0635e40003e4,ResourceVersion:75580,Generation:2,CreationTimestamp:2019-09-09 14:36:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 445b2aca-d30f-11e9-9321-0635e40003e4 0xc00293d5a7 0xc00293d5a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Sep  9 14:37:07.723: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Sep  9 14:37:07.723: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-796,SelfLink:/apis/apps/v1/namespaces/deployment-796/replicasets/test-rollover-controller,UID:402acf1a-d30f-11e9-9321-0635e40003e4,ResourceVersion:75589,Generation:2,CreationTimestamp:2019-09-09 14:36:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 445b2aca-d30f-11e9-9321-0635e40003e4 0xc00293d4d7 0xc00293d4d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  9 14:37:07.723: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-7b45b6464,GenerateName:,Namespace:deployment-796,SelfLink:/apis/apps/v1/namespaces/deployment-796/replicasets/test-rollover-deployment-7b45b6464,UID:445eda9d-d30f-11e9-9321-0635e40003e4,ResourceVersion:75530,Generation:2,CreationTimestamp:2019-09-09 14:36:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 7b45b6464,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 445b2aca-d30f-11e9-9321-0635e40003e4 0xc00293d670 0xc00293d671}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 7b45b6464,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 7b45b6464,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  9 14:37:07.726: INFO: Pod "test-rollover-deployment-659c699649-4rhhk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-659c699649-4rhhk,GenerateName:test-rollover-deployment-659c699649-,Namespace:deployment-796,SelfLink:/api/v1/namespaces/deployment-796/pods/test-rollover-deployment-659c699649-4rhhk,UID:4599a86d-d30f-11e9-9321-0635e40003e4,ResourceVersion:75552,Generation:0,CreationTimestamp:2019-09-09 14:36:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.135/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-659c699649 45935d65-d30f-11e9-9321-0635e40003e4 0xc0025242e7 0xc0025242e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6jzgw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6jzgw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-6jzgw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:185.19.31.168,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002524370} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025243a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:36:55 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:36:57 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:36:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:36:55 +0000 UTC  }],Message:,Reason:,HostIP:185.19.31.168,PodIP:10.42.0.135,StartTime:2019-09-09 14:36:55 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-09-09 14:36:56 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://cbf52081e8c3ae36191fbe806b3b96dc6879cf31bde80f5bdaf71506b3c32cba}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:37:07.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-796" for this suite.
Sep  9 14:37:13.746: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:37:13.828: INFO: namespace deployment-796 deletion completed in 6.099135717s

• [SLOW TEST:27.395 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:37:13.828: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-169
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1384
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  9 14:37:13.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-169'
Sep  9 14:37:14.094: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep  9 14:37:14.094: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1390
Sep  9 14:37:16.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 delete deployment e2e-test-nginx-deployment --namespace=kubectl-169'
Sep  9 14:37:16.206: INFO: stderr: ""
Sep  9 14:37:16.206: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:37:16.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-169" for this suite.
Sep  9 14:37:22.225: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:37:22.307: INFO: namespace kubectl-169 deletion completed in 6.097554498s

• [SLOW TEST:8.480 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:37:22.307: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-903
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Sep  9 14:37:22.492: INFO: Pod name pod-release: Found 0 pods out of 1
Sep  9 14:37:27.497: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:37:28.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-903" for this suite.
Sep  9 14:37:34.542: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:37:34.633: INFO: namespace replication-controller-903 deletion completed in 6.106508659s

• [SLOW TEST:12.326 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:37:34.635: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9828
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-5ce698fc-d30f-11e9-b473-6e32a6bc259a
STEP: Creating a pod to test consume configMaps
Sep  9 14:37:34.833: INFO: Waiting up to 5m0s for pod "pod-configmaps-5ce7f98c-d30f-11e9-b473-6e32a6bc259a" in namespace "configmap-9828" to be "success or failure"
Sep  9 14:37:34.841: INFO: Pod "pod-configmaps-5ce7f98c-d30f-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 7.216781ms
Sep  9 14:37:36.844: INFO: Pod "pod-configmaps-5ce7f98c-d30f-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010703634s
STEP: Saw pod success
Sep  9 14:37:36.844: INFO: Pod "pod-configmaps-5ce7f98c-d30f-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 14:37:36.847: INFO: Trying to get logs from node 185.19.31.168 pod pod-configmaps-5ce7f98c-d30f-11e9-b473-6e32a6bc259a container configmap-volume-test: <nil>
STEP: delete the pod
Sep  9 14:37:36.873: INFO: Waiting for pod pod-configmaps-5ce7f98c-d30f-11e9-b473-6e32a6bc259a to disappear
Sep  9 14:37:36.881: INFO: Pod pod-configmaps-5ce7f98c-d30f-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:37:36.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9828" for this suite.
Sep  9 14:37:42.900: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:37:42.985: INFO: namespace configmap-9828 deletion completed in 6.101894649s

• [SLOW TEST:8.350 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:37:42.985: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-753
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  9 14:37:43.168: INFO: Waiting up to 5m0s for pod "downwardapi-volume-61df9fb6-d30f-11e9-b473-6e32a6bc259a" in namespace "downward-api-753" to be "success or failure"
Sep  9 14:37:43.172: INFO: Pod "downwardapi-volume-61df9fb6-d30f-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.682742ms
Sep  9 14:37:45.176: INFO: Pod "downwardapi-volume-61df9fb6-d30f-11e9-b473-6e32a6bc259a": Phase="Running", Reason="", readiness=true. Elapsed: 2.008234149s
Sep  9 14:37:47.182: INFO: Pod "downwardapi-volume-61df9fb6-d30f-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013577859s
STEP: Saw pod success
Sep  9 14:37:47.182: INFO: Pod "downwardapi-volume-61df9fb6-d30f-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 14:37:47.186: INFO: Trying to get logs from node 185.19.31.168 pod downwardapi-volume-61df9fb6-d30f-11e9-b473-6e32a6bc259a container client-container: <nil>
STEP: delete the pod
Sep  9 14:37:47.261: INFO: Waiting for pod downwardapi-volume-61df9fb6-d30f-11e9-b473-6e32a6bc259a to disappear
Sep  9 14:37:47.263: INFO: Pod downwardapi-volume-61df9fb6-d30f-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:37:47.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-753" for this suite.
Sep  9 14:37:53.281: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:37:53.373: INFO: namespace downward-api-753 deletion completed in 6.107523006s

• [SLOW TEST:10.388 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:37:53.373: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2175
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Sep  9 14:37:56.087: INFO: Successfully updated pod "pod-update-activedeadlineseconds-6810b549-d30f-11e9-b473-6e32a6bc259a"
Sep  9 14:37:56.087: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-6810b549-d30f-11e9-b473-6e32a6bc259a" in namespace "pods-2175" to be "terminated due to deadline exceeded"
Sep  9 14:37:56.090: INFO: Pod "pod-update-activedeadlineseconds-6810b549-d30f-11e9-b473-6e32a6bc259a": Phase="Running", Reason="", readiness=true. Elapsed: 2.719147ms
Sep  9 14:37:58.095: INFO: Pod "pod-update-activedeadlineseconds-6810b549-d30f-11e9-b473-6e32a6bc259a": Phase="Running", Reason="", readiness=true. Elapsed: 2.007755927s
Sep  9 14:38:00.099: INFO: Pod "pod-update-activedeadlineseconds-6810b549-d30f-11e9-b473-6e32a6bc259a": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.011719381s
Sep  9 14:38:00.099: INFO: Pod "pod-update-activedeadlineseconds-6810b549-d30f-11e9-b473-6e32a6bc259a" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:38:00.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2175" for this suite.
Sep  9 14:38:06.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:38:06.208: INFO: namespace pods-2175 deletion completed in 6.104942782s

• [SLOW TEST:12.835 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:38:06.208: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7561
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  9 14:38:06.393: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6fb70994-d30f-11e9-b473-6e32a6bc259a" in namespace "projected-7561" to be "success or failure"
Sep  9 14:38:06.402: INFO: Pod "downwardapi-volume-6fb70994-d30f-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.728763ms
Sep  9 14:38:08.407: INFO: Pod "downwardapi-volume-6fb70994-d30f-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013427761s
STEP: Saw pod success
Sep  9 14:38:08.407: INFO: Pod "downwardapi-volume-6fb70994-d30f-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 14:38:08.411: INFO: Trying to get logs from node 185.19.31.168 pod downwardapi-volume-6fb70994-d30f-11e9-b473-6e32a6bc259a container client-container: <nil>
STEP: delete the pod
Sep  9 14:38:08.439: INFO: Waiting for pod downwardapi-volume-6fb70994-d30f-11e9-b473-6e32a6bc259a to disappear
Sep  9 14:38:08.442: INFO: Pod downwardapi-volume-6fb70994-d30f-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:38:08.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7561" for this suite.
Sep  9 14:38:14.458: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:38:14.546: INFO: namespace projected-7561 deletion completed in 6.100453818s

• [SLOW TEST:8.338 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:38:14.547: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-9476
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating replication controller svc-latency-rc in namespace svc-latency-9476
I0909 14:38:14.713716      19 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-9476, replica count: 1
I0909 14:38:15.764364      19 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0909 14:38:16.764756      19 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0909 14:38:17.765103      19 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep  9 14:38:17.883: INFO: Created: latency-svc-4cvb6
Sep  9 14:38:17.894: INFO: Got endpoints: latency-svc-4cvb6 [28.717818ms]
Sep  9 14:38:17.905: INFO: Created: latency-svc-5spnf
Sep  9 14:38:17.913: INFO: Created: latency-svc-g7jz5
Sep  9 14:38:17.916: INFO: Got endpoints: latency-svc-5spnf [22.233375ms]
Sep  9 14:38:17.929: INFO: Created: latency-svc-lpkhv
Sep  9 14:38:17.930: INFO: Created: latency-svc-qrf8h
Sep  9 14:38:17.932: INFO: Got endpoints: latency-svc-g7jz5 [37.455382ms]
Sep  9 14:38:17.933: INFO: Created: latency-svc-lgzgq
Sep  9 14:38:17.938: INFO: Created: latency-svc-qc5d4
Sep  9 14:38:17.942: INFO: Got endpoints: latency-svc-lpkhv [47.133468ms]
Sep  9 14:38:17.950: INFO: Got endpoints: latency-svc-qrf8h [55.692588ms]
Sep  9 14:38:17.950: INFO: Created: latency-svc-6mhsm
Sep  9 14:38:17.950: INFO: Created: latency-svc-qwsxd
Sep  9 14:38:17.963: INFO: Got endpoints: latency-svc-lgzgq [68.101169ms]
Sep  9 14:38:17.968: INFO: Got endpoints: latency-svc-qwsxd [73.212049ms]
Sep  9 14:38:17.970: INFO: Created: latency-svc-ggpcj
Sep  9 14:38:17.970: INFO: Created: latency-svc-cs6cw
Sep  9 14:38:17.970: INFO: Created: latency-svc-2frjf
Sep  9 14:38:17.974: INFO: Got endpoints: latency-svc-6mhsm [78.965939ms]
Sep  9 14:38:17.980: INFO: Created: latency-svc-2skrj
Sep  9 14:38:17.982: INFO: Got endpoints: latency-svc-qc5d4 [86.980525ms]
Sep  9 14:38:17.988: INFO: Got endpoints: latency-svc-ggpcj [93.82703ms]
Sep  9 14:38:17.991: INFO: Created: latency-svc-gds2d
Sep  9 14:38:17.991: INFO: Created: latency-svc-dmjd8
Sep  9 14:38:17.992: INFO: Created: latency-svc-vrtvs
Sep  9 14:38:17.993: INFO: Created: latency-svc-9jgpn
Sep  9 14:38:17.993: INFO: Created: latency-svc-2mr5h
Sep  9 14:38:17.993: INFO: Created: latency-svc-t8d22
Sep  9 14:38:17.993: INFO: Created: latency-svc-spktz
Sep  9 14:38:17.999: INFO: Got endpoints: latency-svc-dmjd8 [103.759723ms]
Sep  9 14:38:17.999: INFO: Got endpoints: latency-svc-2frjf [104.678812ms]
Sep  9 14:38:17.999: INFO: Got endpoints: latency-svc-cs6cw [104.339494ms]
Sep  9 14:38:17.999: INFO: Got endpoints: latency-svc-2skrj [105.011458ms]
Sep  9 14:38:18.003: INFO: Created: latency-svc-kwt9s
Sep  9 14:38:18.003: INFO: Created: latency-svc-tgw4q
Sep  9 14:38:18.012: INFO: Got endpoints: latency-svc-9jgpn [117.672207ms]
Sep  9 14:38:18.024: INFO: Created: latency-svc-hl9c9
Sep  9 14:38:18.028: INFO: Created: latency-svc-kxscp
Sep  9 14:38:18.028: INFO: Got endpoints: latency-svc-vrtvs [112.215318ms]
Sep  9 14:38:18.029: INFO: Got endpoints: latency-svc-gds2d [86.707916ms]
Sep  9 14:38:18.029: INFO: Got endpoints: latency-svc-spktz [97.165497ms]
Sep  9 14:38:18.029: INFO: Got endpoints: latency-svc-t8d22 [79.143706ms]
Sep  9 14:38:18.037: INFO: Created: latency-svc-t87s7
Sep  9 14:38:18.046: INFO: Created: latency-svc-tb8rj
Sep  9 14:38:18.046: INFO: Created: latency-svc-6nqkj
Sep  9 14:38:18.047: INFO: Got endpoints: latency-svc-tgw4q [83.838951ms]
Sep  9 14:38:18.047: INFO: Created: latency-svc-z5bs7
Sep  9 14:38:18.047: INFO: Got endpoints: latency-svc-kwt9s [79.301448ms]
Sep  9 14:38:18.062: INFO: Created: latency-svc-t2hb7
Sep  9 14:38:18.064: INFO: Created: latency-svc-rtdc8
Sep  9 14:38:18.066: INFO: Created: latency-svc-6bps5
Sep  9 14:38:18.068: INFO: Got endpoints: latency-svc-kxscp [94.484801ms]
Sep  9 14:38:18.069: INFO: Got endpoints: latency-svc-2mr5h [173.483305ms]
Sep  9 14:38:18.077: INFO: Created: latency-svc-prl4c
Sep  9 14:38:18.077: INFO: Got endpoints: latency-svc-hl9c9 [88.238199ms]
Sep  9 14:38:18.077: INFO: Got endpoints: latency-svc-t87s7 [77.589296ms]
Sep  9 14:38:18.079: INFO: Created: latency-svc-pp2bt
Sep  9 14:38:18.079: INFO: Created: latency-svc-qm47k
Sep  9 14:38:18.079: INFO: Got endpoints: latency-svc-z5bs7 [97.324877ms]
Sep  9 14:38:18.084: INFO: Created: latency-svc-v2j4q
Sep  9 14:38:18.084: INFO: Created: latency-svc-dlkw7
Sep  9 14:38:18.084: INFO: Created: latency-svc-6v7jq
Sep  9 14:38:18.087: INFO: Got endpoints: latency-svc-6nqkj [87.688621ms]
Sep  9 14:38:18.093: INFO: Got endpoints: latency-svc-tb8rj [93.608285ms]
Sep  9 14:38:18.108: INFO: Got endpoints: latency-svc-rtdc8 [78.163864ms]
Sep  9 14:38:18.112: INFO: Got endpoints: latency-svc-6bps5 [100.072352ms]
Sep  9 14:38:18.112: INFO: Got endpoints: latency-svc-prl4c [112.76375ms]
Sep  9 14:38:18.118: INFO: Created: latency-svc-fbt44
Sep  9 14:38:18.118: INFO: Created: latency-svc-74sbr
Sep  9 14:38:18.118: INFO: Created: latency-svc-gjj7m
Sep  9 14:38:18.118: INFO: Created: latency-svc-hfcsd
Sep  9 14:38:18.118: INFO: Created: latency-svc-5qs4r
Sep  9 14:38:18.118: INFO: Got endpoints: latency-svc-pp2bt [89.882778ms]
Sep  9 14:38:18.119: INFO: Got endpoints: latency-svc-t2hb7 [87.463018ms]
Sep  9 14:38:18.126: INFO: Created: latency-svc-z7d22
Sep  9 14:38:18.126: INFO: Created: latency-svc-7b6vx
Sep  9 14:38:18.129: INFO: Created: latency-svc-f5pk8
Sep  9 14:38:18.131: INFO: Got endpoints: latency-svc-qm47k [102.113717ms]
Sep  9 14:38:18.135: INFO: Created: latency-svc-qc8t2
Sep  9 14:38:18.138: INFO: Created: latency-svc-nmmr6
Sep  9 14:38:18.141: INFO: Got endpoints: latency-svc-v2j4q [93.957159ms]
Sep  9 14:38:18.141: INFO: Created: latency-svc-jpq7c
Sep  9 14:38:18.148: INFO: Created: latency-svc-ppkp9
Sep  9 14:38:18.152: INFO: Created: latency-svc-dnf4h
Sep  9 14:38:18.189: INFO: Got endpoints: latency-svc-6v7jq [142.273784ms]
Sep  9 14:38:18.201: INFO: Created: latency-svc-cr4xq
Sep  9 14:38:18.240: INFO: Got endpoints: latency-svc-dlkw7 [171.291829ms]
Sep  9 14:38:18.252: INFO: Created: latency-svc-rgtwr
Sep  9 14:38:18.291: INFO: Got endpoints: latency-svc-hfcsd [214.618191ms]
Sep  9 14:38:18.301: INFO: Created: latency-svc-wc9sx
Sep  9 14:38:18.337: INFO: Got endpoints: latency-svc-gjj7m [268.247338ms]
Sep  9 14:38:18.348: INFO: Created: latency-svc-rpgqj
Sep  9 14:38:18.389: INFO: Got endpoints: latency-svc-74sbr [312.069742ms]
Sep  9 14:38:18.399: INFO: Created: latency-svc-wjj7c
Sep  9 14:38:18.444: INFO: Got endpoints: latency-svc-5qs4r [356.883952ms]
Sep  9 14:38:18.454: INFO: Created: latency-svc-652lj
Sep  9 14:38:18.489: INFO: Got endpoints: latency-svc-fbt44 [410.375203ms]
Sep  9 14:38:18.504: INFO: Created: latency-svc-xcksx
Sep  9 14:38:18.537: INFO: Got endpoints: latency-svc-z7d22 [444.531737ms]
Sep  9 14:38:18.551: INFO: Created: latency-svc-fhl7z
Sep  9 14:38:18.589: INFO: Got endpoints: latency-svc-7b6vx [477.074898ms]
Sep  9 14:38:18.602: INFO: Created: latency-svc-f76w9
Sep  9 14:38:18.640: INFO: Got endpoints: latency-svc-f5pk8 [532.114912ms]
Sep  9 14:38:18.649: INFO: Created: latency-svc-jt29j
Sep  9 14:38:18.688: INFO: Got endpoints: latency-svc-qc8t2 [569.614337ms]
Sep  9 14:38:18.698: INFO: Created: latency-svc-xrs4v
Sep  9 14:38:18.740: INFO: Got endpoints: latency-svc-nmmr6 [621.380081ms]
Sep  9 14:38:18.753: INFO: Created: latency-svc-gdgpb
Sep  9 14:38:18.790: INFO: Got endpoints: latency-svc-jpq7c [678.251471ms]
Sep  9 14:38:18.802: INFO: Created: latency-svc-7w6ts
Sep  9 14:38:18.840: INFO: Got endpoints: latency-svc-ppkp9 [708.968192ms]
Sep  9 14:38:18.852: INFO: Created: latency-svc-bnsjq
Sep  9 14:38:18.888: INFO: Got endpoints: latency-svc-dnf4h [746.401788ms]
Sep  9 14:38:18.901: INFO: Created: latency-svc-9wjhj
Sep  9 14:38:18.944: INFO: Got endpoints: latency-svc-cr4xq [754.995301ms]
Sep  9 14:38:18.956: INFO: Created: latency-svc-55zfm
Sep  9 14:38:18.991: INFO: Got endpoints: latency-svc-rgtwr [750.817415ms]
Sep  9 14:38:19.008: INFO: Created: latency-svc-cwgz9
Sep  9 14:38:19.039: INFO: Got endpoints: latency-svc-wc9sx [747.271203ms]
Sep  9 14:38:19.058: INFO: Created: latency-svc-rt8rr
Sep  9 14:38:19.092: INFO: Got endpoints: latency-svc-rpgqj [755.345775ms]
Sep  9 14:38:19.103: INFO: Created: latency-svc-dg7sh
Sep  9 14:38:19.139: INFO: Got endpoints: latency-svc-wjj7c [749.797981ms]
Sep  9 14:38:19.148: INFO: Created: latency-svc-qlc5c
Sep  9 14:38:19.188: INFO: Got endpoints: latency-svc-652lj [743.973175ms]
Sep  9 14:38:19.201: INFO: Created: latency-svc-xcp88
Sep  9 14:38:19.236: INFO: Got endpoints: latency-svc-xcksx [746.086491ms]
Sep  9 14:38:19.245: INFO: Created: latency-svc-rzgwn
Sep  9 14:38:19.291: INFO: Got endpoints: latency-svc-fhl7z [753.318466ms]
Sep  9 14:38:19.302: INFO: Created: latency-svc-chf9f
Sep  9 14:38:19.338: INFO: Got endpoints: latency-svc-f76w9 [749.201159ms]
Sep  9 14:38:19.348: INFO: Created: latency-svc-wq2n9
Sep  9 14:38:19.389: INFO: Got endpoints: latency-svc-jt29j [749.724691ms]
Sep  9 14:38:19.400: INFO: Created: latency-svc-s54fw
Sep  9 14:38:19.439: INFO: Got endpoints: latency-svc-xrs4v [750.567315ms]
Sep  9 14:38:19.451: INFO: Created: latency-svc-xqph4
Sep  9 14:38:19.491: INFO: Got endpoints: latency-svc-gdgpb [751.435337ms]
Sep  9 14:38:19.505: INFO: Created: latency-svc-tzxtf
Sep  9 14:38:19.538: INFO: Got endpoints: latency-svc-7w6ts [747.205881ms]
Sep  9 14:38:19.549: INFO: Created: latency-svc-xhn6k
Sep  9 14:38:19.589: INFO: Got endpoints: latency-svc-bnsjq [748.696376ms]
Sep  9 14:38:19.602: INFO: Created: latency-svc-rfvlz
Sep  9 14:38:19.636: INFO: Got endpoints: latency-svc-9wjhj [748.13352ms]
Sep  9 14:38:19.648: INFO: Created: latency-svc-qrkmf
Sep  9 14:38:19.693: INFO: Got endpoints: latency-svc-55zfm [749.011289ms]
Sep  9 14:38:19.703: INFO: Created: latency-svc-ztzj4
Sep  9 14:38:19.738: INFO: Got endpoints: latency-svc-cwgz9 [746.834669ms]
Sep  9 14:38:19.749: INFO: Created: latency-svc-2fh9r
Sep  9 14:38:19.804: INFO: Got endpoints: latency-svc-rt8rr [765.745909ms]
Sep  9 14:38:19.818: INFO: Created: latency-svc-f4vql
Sep  9 14:38:19.836: INFO: Got endpoints: latency-svc-dg7sh [743.667539ms]
Sep  9 14:38:19.845: INFO: Created: latency-svc-g6t5c
Sep  9 14:38:19.887: INFO: Got endpoints: latency-svc-qlc5c [748.419457ms]
Sep  9 14:38:19.902: INFO: Created: latency-svc-trwrp
Sep  9 14:38:19.938: INFO: Got endpoints: latency-svc-xcp88 [750.287756ms]
Sep  9 14:38:19.971: INFO: Created: latency-svc-wzk8m
Sep  9 14:38:19.987: INFO: Got endpoints: latency-svc-rzgwn [751.808937ms]
Sep  9 14:38:20.001: INFO: Created: latency-svc-k9fwc
Sep  9 14:38:20.038: INFO: Got endpoints: latency-svc-chf9f [747.61823ms]
Sep  9 14:38:20.051: INFO: Created: latency-svc-jbsjs
Sep  9 14:38:20.086: INFO: Got endpoints: latency-svc-wq2n9 [747.943984ms]
Sep  9 14:38:20.104: INFO: Created: latency-svc-bcsk8
Sep  9 14:38:20.140: INFO: Got endpoints: latency-svc-s54fw [750.017805ms]
Sep  9 14:38:20.151: INFO: Created: latency-svc-4sbbp
Sep  9 14:38:20.188: INFO: Got endpoints: latency-svc-xqph4 [749.333303ms]
Sep  9 14:38:20.199: INFO: Created: latency-svc-j7kt2
Sep  9 14:38:20.236: INFO: Got endpoints: latency-svc-tzxtf [744.516644ms]
Sep  9 14:38:20.248: INFO: Created: latency-svc-sb58z
Sep  9 14:38:20.294: INFO: Got endpoints: latency-svc-xhn6k [755.825593ms]
Sep  9 14:38:20.303: INFO: Created: latency-svc-95dg4
Sep  9 14:38:20.338: INFO: Got endpoints: latency-svc-rfvlz [748.919397ms]
Sep  9 14:38:20.348: INFO: Created: latency-svc-rg2b2
Sep  9 14:38:20.390: INFO: Got endpoints: latency-svc-qrkmf [753.931918ms]
Sep  9 14:38:20.404: INFO: Created: latency-svc-jrf5j
Sep  9 14:38:20.438: INFO: Got endpoints: latency-svc-ztzj4 [744.805967ms]
Sep  9 14:38:20.449: INFO: Created: latency-svc-4lrnh
Sep  9 14:38:20.491: INFO: Got endpoints: latency-svc-2fh9r [753.223948ms]
Sep  9 14:38:20.502: INFO: Created: latency-svc-mb24v
Sep  9 14:38:20.538: INFO: Got endpoints: latency-svc-f4vql [733.301137ms]
Sep  9 14:38:20.549: INFO: Created: latency-svc-d4v7k
Sep  9 14:38:20.592: INFO: Got endpoints: latency-svc-g6t5c [755.748127ms]
Sep  9 14:38:20.602: INFO: Created: latency-svc-qctdd
Sep  9 14:38:20.637: INFO: Got endpoints: latency-svc-trwrp [749.333904ms]
Sep  9 14:38:20.648: INFO: Created: latency-svc-x429f
Sep  9 14:38:20.696: INFO: Got endpoints: latency-svc-wzk8m [758.048647ms]
Sep  9 14:38:20.707: INFO: Created: latency-svc-vgxng
Sep  9 14:38:20.736: INFO: Got endpoints: latency-svc-k9fwc [748.406341ms]
Sep  9 14:38:20.746: INFO: Created: latency-svc-7f9nw
Sep  9 14:38:20.791: INFO: Got endpoints: latency-svc-jbsjs [752.576965ms]
Sep  9 14:38:20.800: INFO: Created: latency-svc-pjdbq
Sep  9 14:38:20.835: INFO: Got endpoints: latency-svc-bcsk8 [748.749509ms]
Sep  9 14:38:20.845: INFO: Created: latency-svc-j7mxd
Sep  9 14:38:20.889: INFO: Got endpoints: latency-svc-4sbbp [748.867925ms]
Sep  9 14:38:20.902: INFO: Created: latency-svc-mkhb4
Sep  9 14:38:20.935: INFO: Got endpoints: latency-svc-j7kt2 [747.305399ms]
Sep  9 14:38:20.950: INFO: Created: latency-svc-lhnld
Sep  9 14:38:20.991: INFO: Got endpoints: latency-svc-sb58z [754.313394ms]
Sep  9 14:38:21.003: INFO: Created: latency-svc-pr77l
Sep  9 14:38:21.037: INFO: Got endpoints: latency-svc-95dg4 [742.759987ms]
Sep  9 14:38:21.051: INFO: Created: latency-svc-mg4tj
Sep  9 14:38:21.093: INFO: Got endpoints: latency-svc-rg2b2 [754.916974ms]
Sep  9 14:38:21.103: INFO: Created: latency-svc-rpskq
Sep  9 14:38:21.136: INFO: Got endpoints: latency-svc-jrf5j [746.009833ms]
Sep  9 14:38:21.155: INFO: Created: latency-svc-gvb4d
Sep  9 14:38:21.187: INFO: Got endpoints: latency-svc-4lrnh [748.956234ms]
Sep  9 14:38:21.198: INFO: Created: latency-svc-lx97g
Sep  9 14:38:21.238: INFO: Got endpoints: latency-svc-mb24v [747.445913ms]
Sep  9 14:38:21.252: INFO: Created: latency-svc-ss5rw
Sep  9 14:38:21.288: INFO: Got endpoints: latency-svc-d4v7k [750.363988ms]
Sep  9 14:38:21.297: INFO: Created: latency-svc-dscsc
Sep  9 14:38:21.336: INFO: Got endpoints: latency-svc-qctdd [744.620324ms]
Sep  9 14:38:21.355: INFO: Created: latency-svc-lx8xc
Sep  9 14:38:21.390: INFO: Got endpoints: latency-svc-x429f [753.825172ms]
Sep  9 14:38:21.402: INFO: Created: latency-svc-92bfb
Sep  9 14:38:21.437: INFO: Got endpoints: latency-svc-vgxng [740.87787ms]
Sep  9 14:38:21.451: INFO: Created: latency-svc-bb4zr
Sep  9 14:38:21.489: INFO: Got endpoints: latency-svc-7f9nw [753.189225ms]
Sep  9 14:38:21.501: INFO: Created: latency-svc-6n8fw
Sep  9 14:38:21.536: INFO: Got endpoints: latency-svc-pjdbq [745.228185ms]
Sep  9 14:38:21.547: INFO: Created: latency-svc-6hjkm
Sep  9 14:38:21.590: INFO: Got endpoints: latency-svc-j7mxd [754.590371ms]
Sep  9 14:38:21.603: INFO: Created: latency-svc-6p2d2
Sep  9 14:38:21.644: INFO: Got endpoints: latency-svc-mkhb4 [755.594965ms]
Sep  9 14:38:21.662: INFO: Created: latency-svc-ldb4j
Sep  9 14:38:21.690: INFO: Got endpoints: latency-svc-lhnld [754.252598ms]
Sep  9 14:38:21.701: INFO: Created: latency-svc-9mssz
Sep  9 14:38:21.740: INFO: Got endpoints: latency-svc-pr77l [749.096309ms]
Sep  9 14:38:21.750: INFO: Created: latency-svc-xp7hq
Sep  9 14:38:21.786: INFO: Got endpoints: latency-svc-mg4tj [749.849192ms]
Sep  9 14:38:21.797: INFO: Created: latency-svc-wwgvz
Sep  9 14:38:21.838: INFO: Got endpoints: latency-svc-rpskq [745.580801ms]
Sep  9 14:38:21.850: INFO: Created: latency-svc-jg47k
Sep  9 14:38:21.888: INFO: Got endpoints: latency-svc-gvb4d [751.896708ms]
Sep  9 14:38:21.900: INFO: Created: latency-svc-t2f57
Sep  9 14:38:21.941: INFO: Got endpoints: latency-svc-lx97g [753.883716ms]
Sep  9 14:38:21.953: INFO: Created: latency-svc-gflxj
Sep  9 14:38:21.991: INFO: Got endpoints: latency-svc-ss5rw [752.087056ms]
Sep  9 14:38:22.001: INFO: Created: latency-svc-src86
Sep  9 14:38:22.040: INFO: Got endpoints: latency-svc-dscsc [751.499772ms]
Sep  9 14:38:22.051: INFO: Created: latency-svc-sm7gt
Sep  9 14:38:22.086: INFO: Got endpoints: latency-svc-lx8xc [748.64141ms]
Sep  9 14:38:22.097: INFO: Created: latency-svc-l6qrx
Sep  9 14:38:22.149: INFO: Got endpoints: latency-svc-92bfb [758.729614ms]
Sep  9 14:38:22.159: INFO: Created: latency-svc-22pzq
Sep  9 14:38:22.187: INFO: Got endpoints: latency-svc-bb4zr [748.93559ms]
Sep  9 14:38:22.198: INFO: Created: latency-svc-465vl
Sep  9 14:38:22.235: INFO: Got endpoints: latency-svc-6n8fw [745.573038ms]
Sep  9 14:38:22.244: INFO: Created: latency-svc-2lsjs
Sep  9 14:38:22.291: INFO: Got endpoints: latency-svc-6hjkm [755.243533ms]
Sep  9 14:38:22.301: INFO: Created: latency-svc-96ds4
Sep  9 14:38:22.338: INFO: Got endpoints: latency-svc-6p2d2 [747.995264ms]
Sep  9 14:38:22.350: INFO: Created: latency-svc-t72wz
Sep  9 14:38:22.392: INFO: Got endpoints: latency-svc-ldb4j [747.831863ms]
Sep  9 14:38:22.407: INFO: Created: latency-svc-jxkd7
Sep  9 14:38:22.437: INFO: Got endpoints: latency-svc-9mssz [746.8706ms]
Sep  9 14:38:22.449: INFO: Created: latency-svc-brmpc
Sep  9 14:38:22.491: INFO: Got endpoints: latency-svc-xp7hq [751.13007ms]
Sep  9 14:38:22.508: INFO: Created: latency-svc-d9699
Sep  9 14:38:22.539: INFO: Got endpoints: latency-svc-wwgvz [752.107694ms]
Sep  9 14:38:22.549: INFO: Created: latency-svc-hwcsp
Sep  9 14:38:22.589: INFO: Got endpoints: latency-svc-jg47k [750.608778ms]
Sep  9 14:38:22.599: INFO: Created: latency-svc-f4z7s
Sep  9 14:38:22.642: INFO: Got endpoints: latency-svc-t2f57 [753.223858ms]
Sep  9 14:38:22.652: INFO: Created: latency-svc-jfcfb
Sep  9 14:38:22.688: INFO: Got endpoints: latency-svc-gflxj [746.808017ms]
Sep  9 14:38:22.699: INFO: Created: latency-svc-67ww5
Sep  9 14:38:22.744: INFO: Got endpoints: latency-svc-src86 [753.45598ms]
Sep  9 14:38:22.756: INFO: Created: latency-svc-j8lpl
Sep  9 14:38:22.787: INFO: Got endpoints: latency-svc-sm7gt [747.473462ms]
Sep  9 14:38:22.806: INFO: Created: latency-svc-5r7qg
Sep  9 14:38:22.838: INFO: Got endpoints: latency-svc-l6qrx [751.905143ms]
Sep  9 14:38:22.847: INFO: Created: latency-svc-68hdl
Sep  9 14:38:22.887: INFO: Got endpoints: latency-svc-22pzq [737.391506ms]
Sep  9 14:38:22.903: INFO: Created: latency-svc-cjjsg
Sep  9 14:38:22.936: INFO: Got endpoints: latency-svc-465vl [749.339826ms]
Sep  9 14:38:22.949: INFO: Created: latency-svc-5bvnp
Sep  9 14:38:22.988: INFO: Got endpoints: latency-svc-2lsjs [753.027889ms]
Sep  9 14:38:22.999: INFO: Created: latency-svc-w4csj
Sep  9 14:38:23.037: INFO: Got endpoints: latency-svc-96ds4 [745.107865ms]
Sep  9 14:38:23.049: INFO: Created: latency-svc-v9bqf
Sep  9 14:38:23.092: INFO: Got endpoints: latency-svc-t72wz [754.169557ms]
Sep  9 14:38:23.102: INFO: Created: latency-svc-llxvg
Sep  9 14:38:23.136: INFO: Got endpoints: latency-svc-jxkd7 [743.981707ms]
Sep  9 14:38:23.147: INFO: Created: latency-svc-d6l8j
Sep  9 14:38:23.192: INFO: Got endpoints: latency-svc-brmpc [755.517389ms]
Sep  9 14:38:23.204: INFO: Created: latency-svc-742kb
Sep  9 14:38:23.236: INFO: Got endpoints: latency-svc-d9699 [744.834837ms]
Sep  9 14:38:23.247: INFO: Created: latency-svc-l6f9t
Sep  9 14:38:23.287: INFO: Got endpoints: latency-svc-hwcsp [748.512093ms]
Sep  9 14:38:23.299: INFO: Created: latency-svc-tvc9b
Sep  9 14:38:23.337: INFO: Got endpoints: latency-svc-f4z7s [747.712397ms]
Sep  9 14:38:23.346: INFO: Created: latency-svc-bxsnr
Sep  9 14:38:23.390: INFO: Got endpoints: latency-svc-jfcfb [748.099956ms]
Sep  9 14:38:23.401: INFO: Created: latency-svc-vt5wd
Sep  9 14:38:23.439: INFO: Got endpoints: latency-svc-67ww5 [751.083418ms]
Sep  9 14:38:23.451: INFO: Created: latency-svc-f8c8b
Sep  9 14:38:23.495: INFO: Got endpoints: latency-svc-j8lpl [750.751522ms]
Sep  9 14:38:23.505: INFO: Created: latency-svc-jbk54
Sep  9 14:38:23.536: INFO: Got endpoints: latency-svc-5r7qg [748.233497ms]
Sep  9 14:38:23.547: INFO: Created: latency-svc-bvjks
Sep  9 14:38:23.598: INFO: Got endpoints: latency-svc-68hdl [759.670004ms]
Sep  9 14:38:23.609: INFO: Created: latency-svc-hms7d
Sep  9 14:38:23.639: INFO: Got endpoints: latency-svc-cjjsg [751.803985ms]
Sep  9 14:38:23.651: INFO: Created: latency-svc-bctdx
Sep  9 14:38:23.689: INFO: Got endpoints: latency-svc-5bvnp [752.32285ms]
Sep  9 14:38:23.700: INFO: Created: latency-svc-74cfp
Sep  9 14:38:23.737: INFO: Got endpoints: latency-svc-w4csj [748.7761ms]
Sep  9 14:38:23.748: INFO: Created: latency-svc-5vhkl
Sep  9 14:38:23.786: INFO: Got endpoints: latency-svc-v9bqf [749.34216ms]
Sep  9 14:38:23.798: INFO: Created: latency-svc-d4mbc
Sep  9 14:38:23.849: INFO: Got endpoints: latency-svc-llxvg [756.382196ms]
Sep  9 14:38:23.859: INFO: Created: latency-svc-sfvdv
Sep  9 14:38:23.886: INFO: Got endpoints: latency-svc-d6l8j [749.512766ms]
Sep  9 14:38:23.898: INFO: Created: latency-svc-lb9zr
Sep  9 14:38:23.937: INFO: Got endpoints: latency-svc-742kb [744.328462ms]
Sep  9 14:38:23.951: INFO: Created: latency-svc-q96vz
Sep  9 14:38:23.988: INFO: Got endpoints: latency-svc-l6f9t [752.136609ms]
Sep  9 14:38:24.000: INFO: Created: latency-svc-hgxmz
Sep  9 14:38:24.042: INFO: Got endpoints: latency-svc-tvc9b [754.324718ms]
Sep  9 14:38:24.054: INFO: Created: latency-svc-kmmws
Sep  9 14:38:24.088: INFO: Got endpoints: latency-svc-bxsnr [750.887967ms]
Sep  9 14:38:24.098: INFO: Created: latency-svc-lg62m
Sep  9 14:38:24.138: INFO: Got endpoints: latency-svc-vt5wd [748.512507ms]
Sep  9 14:38:24.155: INFO: Created: latency-svc-pgl2h
Sep  9 14:38:24.203: INFO: Got endpoints: latency-svc-f8c8b [764.386922ms]
Sep  9 14:38:24.217: INFO: Created: latency-svc-j7jrn
Sep  9 14:38:24.237: INFO: Got endpoints: latency-svc-jbk54 [742.114064ms]
Sep  9 14:38:24.247: INFO: Created: latency-svc-xvvsk
Sep  9 14:38:24.290: INFO: Got endpoints: latency-svc-bvjks [754.468753ms]
Sep  9 14:38:24.302: INFO: Created: latency-svc-b86sl
Sep  9 14:38:24.336: INFO: Got endpoints: latency-svc-hms7d [738.634078ms]
Sep  9 14:38:24.346: INFO: Created: latency-svc-m2t72
Sep  9 14:38:24.390: INFO: Got endpoints: latency-svc-bctdx [751.314388ms]
Sep  9 14:38:24.400: INFO: Created: latency-svc-r7xfb
Sep  9 14:38:24.436: INFO: Got endpoints: latency-svc-74cfp [747.712363ms]
Sep  9 14:38:24.448: INFO: Created: latency-svc-t6x47
Sep  9 14:38:24.490: INFO: Got endpoints: latency-svc-5vhkl [752.875144ms]
Sep  9 14:38:24.501: INFO: Created: latency-svc-zqcq2
Sep  9 14:38:24.540: INFO: Got endpoints: latency-svc-d4mbc [753.659788ms]
Sep  9 14:38:24.550: INFO: Created: latency-svc-55zth
Sep  9 14:38:24.593: INFO: Got endpoints: latency-svc-sfvdv [744.467082ms]
Sep  9 14:38:24.603: INFO: Created: latency-svc-58db6
Sep  9 14:38:24.637: INFO: Got endpoints: latency-svc-lb9zr [750.775687ms]
Sep  9 14:38:24.650: INFO: Created: latency-svc-cchzd
Sep  9 14:38:24.691: INFO: Got endpoints: latency-svc-q96vz [754.423558ms]
Sep  9 14:38:24.703: INFO: Created: latency-svc-thfqh
Sep  9 14:38:24.738: INFO: Got endpoints: latency-svc-hgxmz [749.657712ms]
Sep  9 14:38:24.753: INFO: Created: latency-svc-mx9t7
Sep  9 14:38:24.790: INFO: Got endpoints: latency-svc-kmmws [748.302681ms]
Sep  9 14:38:24.801: INFO: Created: latency-svc-xbdp2
Sep  9 14:38:24.840: INFO: Got endpoints: latency-svc-lg62m [751.814779ms]
Sep  9 14:38:24.850: INFO: Created: latency-svc-k8bm9
Sep  9 14:38:24.893: INFO: Got endpoints: latency-svc-pgl2h [754.95983ms]
Sep  9 14:38:24.904: INFO: Created: latency-svc-2hsmk
Sep  9 14:38:24.937: INFO: Got endpoints: latency-svc-j7jrn [733.98774ms]
Sep  9 14:38:24.948: INFO: Created: latency-svc-9sx99
Sep  9 14:38:24.988: INFO: Got endpoints: latency-svc-xvvsk [750.820866ms]
Sep  9 14:38:25.001: INFO: Created: latency-svc-b7mmh
Sep  9 14:38:25.038: INFO: Got endpoints: latency-svc-b86sl [747.379627ms]
Sep  9 14:38:25.052: INFO: Created: latency-svc-w6fgs
Sep  9 14:38:25.089: INFO: Got endpoints: latency-svc-m2t72 [752.296746ms]
Sep  9 14:38:25.101: INFO: Created: latency-svc-bfgtk
Sep  9 14:38:25.139: INFO: Got endpoints: latency-svc-r7xfb [749.107449ms]
Sep  9 14:38:25.151: INFO: Created: latency-svc-gp5pr
Sep  9 14:38:25.190: INFO: Got endpoints: latency-svc-t6x47 [753.366856ms]
Sep  9 14:38:25.202: INFO: Created: latency-svc-nbwkc
Sep  9 14:38:25.241: INFO: Got endpoints: latency-svc-zqcq2 [751.446126ms]
Sep  9 14:38:25.251: INFO: Created: latency-svc-kqjc5
Sep  9 14:38:25.286: INFO: Got endpoints: latency-svc-55zth [746.07691ms]
Sep  9 14:38:25.296: INFO: Created: latency-svc-dtpg2
Sep  9 14:38:25.337: INFO: Got endpoints: latency-svc-58db6 [743.338797ms]
Sep  9 14:38:25.345: INFO: Created: latency-svc-r9mgj
Sep  9 14:38:25.396: INFO: Got endpoints: latency-svc-cchzd [758.853434ms]
Sep  9 14:38:25.407: INFO: Created: latency-svc-xphcc
Sep  9 14:38:25.437: INFO: Got endpoints: latency-svc-thfqh [745.770567ms]
Sep  9 14:38:25.447: INFO: Created: latency-svc-2qplm
Sep  9 14:38:25.491: INFO: Got endpoints: latency-svc-mx9t7 [753.293146ms]
Sep  9 14:38:25.502: INFO: Created: latency-svc-cpk6h
Sep  9 14:38:25.538: INFO: Got endpoints: latency-svc-xbdp2 [747.895897ms]
Sep  9 14:38:25.548: INFO: Created: latency-svc-l6b7x
Sep  9 14:38:25.590: INFO: Got endpoints: latency-svc-k8bm9 [750.69474ms]
Sep  9 14:38:25.600: INFO: Created: latency-svc-jh58s
Sep  9 14:38:25.636: INFO: Got endpoints: latency-svc-2hsmk [743.028751ms]
Sep  9 14:38:25.649: INFO: Created: latency-svc-dbtmc
Sep  9 14:38:25.692: INFO: Got endpoints: latency-svc-9sx99 [755.243572ms]
Sep  9 14:38:25.702: INFO: Created: latency-svc-cjfln
Sep  9 14:38:25.740: INFO: Got endpoints: latency-svc-b7mmh [751.431559ms]
Sep  9 14:38:25.798: INFO: Got endpoints: latency-svc-w6fgs [760.165162ms]
Sep  9 14:38:25.838: INFO: Got endpoints: latency-svc-bfgtk [749.337125ms]
Sep  9 14:38:25.893: INFO: Got endpoints: latency-svc-gp5pr [753.23716ms]
Sep  9 14:38:25.936: INFO: Got endpoints: latency-svc-nbwkc [745.795147ms]
Sep  9 14:38:25.989: INFO: Got endpoints: latency-svc-kqjc5 [747.780055ms]
Sep  9 14:38:26.037: INFO: Got endpoints: latency-svc-dtpg2 [750.491075ms]
Sep  9 14:38:26.093: INFO: Got endpoints: latency-svc-r9mgj [756.274925ms]
Sep  9 14:38:26.137: INFO: Got endpoints: latency-svc-xphcc [741.71289ms]
Sep  9 14:38:26.197: INFO: Got endpoints: latency-svc-2qplm [759.995709ms]
Sep  9 14:38:26.240: INFO: Got endpoints: latency-svc-cpk6h [748.729652ms]
Sep  9 14:38:26.289: INFO: Got endpoints: latency-svc-l6b7x [750.689984ms]
Sep  9 14:38:26.341: INFO: Got endpoints: latency-svc-jh58s [750.322404ms]
Sep  9 14:38:26.395: INFO: Got endpoints: latency-svc-dbtmc [758.321739ms]
Sep  9 14:38:26.436: INFO: Got endpoints: latency-svc-cjfln [743.744093ms]
Sep  9 14:38:26.436: INFO: Latencies: [22.233375ms 37.455382ms 47.133468ms 55.692588ms 68.101169ms 73.212049ms 77.589296ms 78.163864ms 78.965939ms 79.143706ms 79.301448ms 83.838951ms 86.707916ms 86.980525ms 87.463018ms 87.688621ms 88.238199ms 89.882778ms 93.608285ms 93.82703ms 93.957159ms 94.484801ms 97.165497ms 97.324877ms 100.072352ms 102.113717ms 103.759723ms 104.339494ms 104.678812ms 105.011458ms 112.215318ms 112.76375ms 117.672207ms 142.273784ms 171.291829ms 173.483305ms 214.618191ms 268.247338ms 312.069742ms 356.883952ms 410.375203ms 444.531737ms 477.074898ms 532.114912ms 569.614337ms 621.380081ms 678.251471ms 708.968192ms 733.301137ms 733.98774ms 737.391506ms 738.634078ms 740.87787ms 741.71289ms 742.114064ms 742.759987ms 743.028751ms 743.338797ms 743.667539ms 743.744093ms 743.973175ms 743.981707ms 744.328462ms 744.467082ms 744.516644ms 744.620324ms 744.805967ms 744.834837ms 745.107865ms 745.228185ms 745.573038ms 745.580801ms 745.770567ms 745.795147ms 746.009833ms 746.07691ms 746.086491ms 746.401788ms 746.808017ms 746.834669ms 746.8706ms 747.205881ms 747.271203ms 747.305399ms 747.379627ms 747.445913ms 747.473462ms 747.61823ms 747.712363ms 747.712397ms 747.780055ms 747.831863ms 747.895897ms 747.943984ms 747.995264ms 748.099956ms 748.13352ms 748.233497ms 748.302681ms 748.406341ms 748.419457ms 748.512093ms 748.512507ms 748.64141ms 748.696376ms 748.729652ms 748.749509ms 748.7761ms 748.867925ms 748.919397ms 748.93559ms 748.956234ms 749.011289ms 749.096309ms 749.107449ms 749.201159ms 749.333303ms 749.333904ms 749.337125ms 749.339826ms 749.34216ms 749.512766ms 749.657712ms 749.724691ms 749.797981ms 749.849192ms 750.017805ms 750.287756ms 750.322404ms 750.363988ms 750.491075ms 750.567315ms 750.608778ms 750.689984ms 750.69474ms 750.751522ms 750.775687ms 750.817415ms 750.820866ms 750.887967ms 751.083418ms 751.13007ms 751.314388ms 751.431559ms 751.435337ms 751.446126ms 751.499772ms 751.803985ms 751.808937ms 751.814779ms 751.896708ms 751.905143ms 752.087056ms 752.107694ms 752.136609ms 752.296746ms 752.32285ms 752.576965ms 752.875144ms 753.027889ms 753.189225ms 753.223858ms 753.223948ms 753.23716ms 753.293146ms 753.318466ms 753.366856ms 753.45598ms 753.659788ms 753.825172ms 753.883716ms 753.931918ms 754.169557ms 754.252598ms 754.313394ms 754.324718ms 754.423558ms 754.468753ms 754.590371ms 754.916974ms 754.95983ms 754.995301ms 755.243533ms 755.243572ms 755.345775ms 755.517389ms 755.594965ms 755.748127ms 755.825593ms 756.274925ms 756.382196ms 758.048647ms 758.321739ms 758.729614ms 758.853434ms 759.670004ms 759.995709ms 760.165162ms 764.386922ms 765.745909ms]
Sep  9 14:38:26.437: INFO: 50 %ile: 748.419457ms
Sep  9 14:38:26.437: INFO: 90 %ile: 754.95983ms
Sep  9 14:38:26.437: INFO: 99 %ile: 764.386922ms
Sep  9 14:38:26.437: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:38:26.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-9476" for this suite.
Sep  9 14:38:36.454: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:38:36.542: INFO: namespace svc-latency-9476 deletion completed in 10.101514733s

• [SLOW TEST:21.995 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:38:36.542: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7096
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-81cce097-d30f-11e9-b473-6e32a6bc259a
STEP: Creating a pod to test consume configMaps
Sep  9 14:38:36.740: INFO: Waiting up to 5m0s for pod "pod-configmaps-81ce6e12-d30f-11e9-b473-6e32a6bc259a" in namespace "configmap-7096" to be "success or failure"
Sep  9 14:38:36.762: INFO: Pod "pod-configmaps-81ce6e12-d30f-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 21.980358ms
Sep  9 14:38:38.767: INFO: Pod "pod-configmaps-81ce6e12-d30f-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.026455254s
STEP: Saw pod success
Sep  9 14:38:38.767: INFO: Pod "pod-configmaps-81ce6e12-d30f-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 14:38:38.772: INFO: Trying to get logs from node 185.19.31.168 pod pod-configmaps-81ce6e12-d30f-11e9-b473-6e32a6bc259a container configmap-volume-test: <nil>
STEP: delete the pod
Sep  9 14:38:38.795: INFO: Waiting for pod pod-configmaps-81ce6e12-d30f-11e9-b473-6e32a6bc259a to disappear
Sep  9 14:38:38.798: INFO: Pod pod-configmaps-81ce6e12-d30f-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:38:38.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7096" for this suite.
Sep  9 14:38:44.826: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:38:44.907: INFO: namespace configmap-7096 deletion completed in 6.103272861s

• [SLOW TEST:8.366 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:38:44.908: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9428
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-projected-all-test-volume-86cadd67-d30f-11e9-b473-6e32a6bc259a
STEP: Creating secret with name secret-projected-all-test-volume-86cadd47-d30f-11e9-b473-6e32a6bc259a
STEP: Creating a pod to test Check all projections for projected volume plugin
Sep  9 14:38:45.134: INFO: Waiting up to 5m0s for pod "projected-volume-86cadd0a-d30f-11e9-b473-6e32a6bc259a" in namespace "projected-9428" to be "success or failure"
Sep  9 14:38:45.138: INFO: Pod "projected-volume-86cadd0a-d30f-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.760483ms
Sep  9 14:38:47.141: INFO: Pod "projected-volume-86cadd0a-d30f-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007732857s
STEP: Saw pod success
Sep  9 14:38:47.141: INFO: Pod "projected-volume-86cadd0a-d30f-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 14:38:47.145: INFO: Trying to get logs from node 185.19.31.168 pod projected-volume-86cadd0a-d30f-11e9-b473-6e32a6bc259a container projected-all-volume-test: <nil>
STEP: delete the pod
Sep  9 14:38:47.169: INFO: Waiting for pod projected-volume-86cadd0a-d30f-11e9-b473-6e32a6bc259a to disappear
Sep  9 14:38:47.177: INFO: Pod projected-volume-86cadd0a-d30f-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:38:47.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9428" for this suite.
Sep  9 14:38:53.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:38:53.285: INFO: namespace projected-9428 deletion completed in 6.105763026s

• [SLOW TEST:8.377 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:38:53.285: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8685
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Sep  9 14:38:56.064: INFO: Successfully updated pod "labelsupdate8bcd7de0-d30f-11e9-b473-6e32a6bc259a"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:38:58.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8685" for this suite.
Sep  9 14:39:20.103: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:39:20.183: INFO: namespace projected-8685 deletion completed in 22.09721628s

• [SLOW TEST:26.898 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:39:20.183: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1302
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-9bce2430-d30f-11e9-b473-6e32a6bc259a
STEP: Creating a pod to test consume secrets
Sep  9 14:39:20.375: INFO: Waiting up to 5m0s for pod "pod-secrets-9bcfaf8e-d30f-11e9-b473-6e32a6bc259a" in namespace "secrets-1302" to be "success or failure"
Sep  9 14:39:20.383: INFO: Pod "pod-secrets-9bcfaf8e-d30f-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.199666ms
Sep  9 14:39:22.396: INFO: Pod "pod-secrets-9bcfaf8e-d30f-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020979218s
STEP: Saw pod success
Sep  9 14:39:22.396: INFO: Pod "pod-secrets-9bcfaf8e-d30f-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 14:39:22.399: INFO: Trying to get logs from node 185.19.31.168 pod pod-secrets-9bcfaf8e-d30f-11e9-b473-6e32a6bc259a container secret-volume-test: <nil>
STEP: delete the pod
Sep  9 14:39:22.427: INFO: Waiting for pod pod-secrets-9bcfaf8e-d30f-11e9-b473-6e32a6bc259a to disappear
Sep  9 14:39:22.431: INFO: Pod pod-secrets-9bcfaf8e-d30f-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:39:22.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1302" for this suite.
Sep  9 14:39:28.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:39:28.531: INFO: namespace secrets-1302 deletion completed in 6.097502872s

• [SLOW TEST:8.347 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:39:28.531: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3861
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Sep  9 14:39:28.716: INFO: Waiting up to 5m0s for pod "downward-api-a0c92124-d30f-11e9-b473-6e32a6bc259a" in namespace "downward-api-3861" to be "success or failure"
Sep  9 14:39:28.718: INFO: Pod "downward-api-a0c92124-d30f-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.496049ms
Sep  9 14:39:30.722: INFO: Pod "downward-api-a0c92124-d30f-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0063629s
STEP: Saw pod success
Sep  9 14:39:30.722: INFO: Pod "downward-api-a0c92124-d30f-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 14:39:30.725: INFO: Trying to get logs from node 185.19.31.168 pod downward-api-a0c92124-d30f-11e9-b473-6e32a6bc259a container dapi-container: <nil>
STEP: delete the pod
Sep  9 14:39:30.747: INFO: Waiting for pod downward-api-a0c92124-d30f-11e9-b473-6e32a6bc259a to disappear
Sep  9 14:39:30.749: INFO: Pod downward-api-a0c92124-d30f-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:39:30.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3861" for this suite.
Sep  9 14:39:36.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:39:36.858: INFO: namespace downward-api-3861 deletion completed in 6.103882585s

• [SLOW TEST:8.327 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:39:36.858: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1712
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-a5c0356f-d30f-11e9-b473-6e32a6bc259a
STEP: Creating a pod to test consume secrets
Sep  9 14:39:37.054: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a5c1cb49-d30f-11e9-b473-6e32a6bc259a" in namespace "projected-1712" to be "success or failure"
Sep  9 14:39:37.060: INFO: Pod "pod-projected-secrets-a5c1cb49-d30f-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.550495ms
Sep  9 14:39:39.063: INFO: Pod "pod-projected-secrets-a5c1cb49-d30f-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008724299s
STEP: Saw pod success
Sep  9 14:39:39.063: INFO: Pod "pod-projected-secrets-a5c1cb49-d30f-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 14:39:39.065: INFO: Trying to get logs from node 185.19.31.168 pod pod-projected-secrets-a5c1cb49-d30f-11e9-b473-6e32a6bc259a container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep  9 14:39:39.087: INFO: Waiting for pod pod-projected-secrets-a5c1cb49-d30f-11e9-b473-6e32a6bc259a to disappear
Sep  9 14:39:39.096: INFO: Pod pod-projected-secrets-a5c1cb49-d30f-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:39:39.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1712" for this suite.
Sep  9 14:39:45.113: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:39:45.201: INFO: namespace projected-1712 deletion completed in 6.102204499s

• [SLOW TEST:8.343 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:39:45.202: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5420
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  9 14:39:45.426: INFO: Waiting up to 5m0s for pod "downwardapi-volume-aabe3a62-d30f-11e9-b473-6e32a6bc259a" in namespace "downward-api-5420" to be "success or failure"
Sep  9 14:39:45.431: INFO: Pod "downwardapi-volume-aabe3a62-d30f-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.170923ms
Sep  9 14:39:47.434: INFO: Pod "downwardapi-volume-aabe3a62-d30f-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00859055s
STEP: Saw pod success
Sep  9 14:39:47.434: INFO: Pod "downwardapi-volume-aabe3a62-d30f-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 14:39:47.438: INFO: Trying to get logs from node 185.19.31.168 pod downwardapi-volume-aabe3a62-d30f-11e9-b473-6e32a6bc259a container client-container: <nil>
STEP: delete the pod
Sep  9 14:39:47.461: INFO: Waiting for pod downwardapi-volume-aabe3a62-d30f-11e9-b473-6e32a6bc259a to disappear
Sep  9 14:39:47.472: INFO: Pod downwardapi-volume-aabe3a62-d30f-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:39:47.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5420" for this suite.
Sep  9 14:39:53.490: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:39:53.572: INFO: namespace downward-api-5420 deletion completed in 6.097791129s

• [SLOW TEST:8.371 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:39:53.572: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9490
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-afb62054-d30f-11e9-b473-6e32a6bc259a
STEP: Creating a pod to test consume configMaps
Sep  9 14:39:53.769: INFO: Waiting up to 5m0s for pod "pod-configmaps-afb79eb3-d30f-11e9-b473-6e32a6bc259a" in namespace "configmap-9490" to be "success or failure"
Sep  9 14:39:53.778: INFO: Pod "pod-configmaps-afb79eb3-d30f-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.511047ms
Sep  9 14:39:55.781: INFO: Pod "pod-configmaps-afb79eb3-d30f-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012200881s
STEP: Saw pod success
Sep  9 14:39:55.781: INFO: Pod "pod-configmaps-afb79eb3-d30f-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 14:39:55.784: INFO: Trying to get logs from node 185.19.31.168 pod pod-configmaps-afb79eb3-d30f-11e9-b473-6e32a6bc259a container configmap-volume-test: <nil>
STEP: delete the pod
Sep  9 14:39:55.805: INFO: Waiting for pod pod-configmaps-afb79eb3-d30f-11e9-b473-6e32a6bc259a to disappear
Sep  9 14:39:55.808: INFO: Pod pod-configmaps-afb79eb3-d30f-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:39:55.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9490" for this suite.
Sep  9 14:40:01.826: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:40:01.942: INFO: namespace configmap-9490 deletion completed in 6.130514219s

• [SLOW TEST:8.369 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:40:01.942: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-9019
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-tq78
STEP: Creating a pod to test atomic-volume-subpath
Sep  9 14:40:02.140: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-tq78" in namespace "subpath-9019" to be "success or failure"
Sep  9 14:40:02.147: INFO: Pod "pod-subpath-test-configmap-tq78": Phase="Pending", Reason="", readiness=false. Elapsed: 7.057155ms
Sep  9 14:40:04.150: INFO: Pod "pod-subpath-test-configmap-tq78": Phase="Running", Reason="", readiness=true. Elapsed: 2.010435669s
Sep  9 14:40:06.156: INFO: Pod "pod-subpath-test-configmap-tq78": Phase="Running", Reason="", readiness=true. Elapsed: 4.015763989s
Sep  9 14:40:08.160: INFO: Pod "pod-subpath-test-configmap-tq78": Phase="Running", Reason="", readiness=true. Elapsed: 6.020596251s
Sep  9 14:40:10.165: INFO: Pod "pod-subpath-test-configmap-tq78": Phase="Running", Reason="", readiness=true. Elapsed: 8.025368074s
Sep  9 14:40:12.170: INFO: Pod "pod-subpath-test-configmap-tq78": Phase="Running", Reason="", readiness=true. Elapsed: 10.030499981s
Sep  9 14:40:14.175: INFO: Pod "pod-subpath-test-configmap-tq78": Phase="Running", Reason="", readiness=true. Elapsed: 12.035102945s
Sep  9 14:40:16.180: INFO: Pod "pod-subpath-test-configmap-tq78": Phase="Running", Reason="", readiness=true. Elapsed: 14.040125237s
Sep  9 14:40:18.184: INFO: Pod "pod-subpath-test-configmap-tq78": Phase="Running", Reason="", readiness=true. Elapsed: 16.044371698s
Sep  9 14:40:20.189: INFO: Pod "pod-subpath-test-configmap-tq78": Phase="Running", Reason="", readiness=true. Elapsed: 18.049035842s
Sep  9 14:40:22.192: INFO: Pod "pod-subpath-test-configmap-tq78": Phase="Running", Reason="", readiness=true. Elapsed: 20.052529142s
Sep  9 14:40:24.196: INFO: Pod "pod-subpath-test-configmap-tq78": Phase="Running", Reason="", readiness=true. Elapsed: 22.056522439s
Sep  9 14:40:26.202: INFO: Pod "pod-subpath-test-configmap-tq78": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.061781995s
STEP: Saw pod success
Sep  9 14:40:26.202: INFO: Pod "pod-subpath-test-configmap-tq78" satisfied condition "success or failure"
Sep  9 14:40:26.205: INFO: Trying to get logs from node 185.19.31.168 pod pod-subpath-test-configmap-tq78 container test-container-subpath-configmap-tq78: <nil>
STEP: delete the pod
Sep  9 14:40:26.235: INFO: Waiting for pod pod-subpath-test-configmap-tq78 to disappear
Sep  9 14:40:26.241: INFO: Pod pod-subpath-test-configmap-tq78 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-tq78
Sep  9 14:40:26.241: INFO: Deleting pod "pod-subpath-test-configmap-tq78" in namespace "subpath-9019"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:40:26.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9019" for this suite.
Sep  9 14:40:32.270: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:40:32.450: INFO: namespace subpath-9019 deletion completed in 6.195738138s

• [SLOW TEST:30.508 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:40:32.450: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-9471
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-9471
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-9471
STEP: Creating statefulset with conflicting port in namespace statefulset-9471
STEP: Waiting until pod test-pod will start running in namespace statefulset-9471
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-9471
Sep  9 14:40:36.726: INFO: Observed stateful pod in namespace: statefulset-9471, name: ss-0, uid: c953cb83-d30f-11e9-9321-0635e40003e4, status phase: Pending. Waiting for statefulset controller to delete.
Sep  9 14:40:37.278: INFO: Observed stateful pod in namespace: statefulset-9471, name: ss-0, uid: c953cb83-d30f-11e9-9321-0635e40003e4, status phase: Failed. Waiting for statefulset controller to delete.
Sep  9 14:40:37.289: INFO: Observed stateful pod in namespace: statefulset-9471, name: ss-0, uid: c953cb83-d30f-11e9-9321-0635e40003e4, status phase: Failed. Waiting for statefulset controller to delete.
Sep  9 14:40:37.292: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-9471
STEP: Removing pod with conflicting port in namespace statefulset-9471
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-9471 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Sep  9 14:40:41.332: INFO: Deleting all statefulset in ns statefulset-9471
Sep  9 14:40:41.335: INFO: Scaling statefulset ss to 0
Sep  9 14:40:51.357: INFO: Waiting for statefulset status.replicas updated to 0
Sep  9 14:40:51.360: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:40:51.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9471" for this suite.
Sep  9 14:40:57.399: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:40:57.492: INFO: namespace statefulset-9471 deletion completed in 6.111649528s

• [SLOW TEST:25.042 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:40:57.493: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-4699
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Sep  9 14:41:00.712: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:41:01.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-4699" for this suite.
Sep  9 14:41:23.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:41:23.850: INFO: namespace replicaset-4699 deletion completed in 22.105387922s

• [SLOW TEST:26.357 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:41:23.850: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5374
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-e58551fa-d30f-11e9-b473-6e32a6bc259a
STEP: Creating a pod to test consume secrets
Sep  9 14:41:24.048: INFO: Waiting up to 5m0s for pod "pod-secrets-e586b121-d30f-11e9-b473-6e32a6bc259a" in namespace "secrets-5374" to be "success or failure"
Sep  9 14:41:24.055: INFO: Pod "pod-secrets-e586b121-d30f-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.818388ms
Sep  9 14:41:26.060: INFO: Pod "pod-secrets-e586b121-d30f-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011825021s
STEP: Saw pod success
Sep  9 14:41:26.060: INFO: Pod "pod-secrets-e586b121-d30f-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 14:41:26.063: INFO: Trying to get logs from node 185.19.31.168 pod pod-secrets-e586b121-d30f-11e9-b473-6e32a6bc259a container secret-volume-test: <nil>
STEP: delete the pod
Sep  9 14:41:26.086: INFO: Waiting for pod pod-secrets-e586b121-d30f-11e9-b473-6e32a6bc259a to disappear
Sep  9 14:41:26.096: INFO: Pod pod-secrets-e586b121-d30f-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:41:26.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5374" for this suite.
Sep  9 14:41:32.113: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:41:32.186: INFO: namespace secrets-5374 deletion completed in 6.087532401s

• [SLOW TEST:8.336 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:41:32.186: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-167
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Sep  9 14:41:32.345: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:41:35.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-167" for this suite.
Sep  9 14:41:41.395: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:41:41.483: INFO: namespace init-container-167 deletion completed in 6.106906186s

• [SLOW TEST:9.297 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:41:41.483: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3308
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Sep  9 14:41:41.699: INFO: Waiting up to 5m0s for pod "downward-api-f006ff39-d30f-11e9-b473-6e32a6bc259a" in namespace "downward-api-3308" to be "success or failure"
Sep  9 14:41:41.707: INFO: Pod "downward-api-f006ff39-d30f-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 7.578852ms
Sep  9 14:41:43.711: INFO: Pod "downward-api-f006ff39-d30f-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012263023s
STEP: Saw pod success
Sep  9 14:41:43.711: INFO: Pod "downward-api-f006ff39-d30f-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 14:41:43.715: INFO: Trying to get logs from node 185.19.31.168 pod downward-api-f006ff39-d30f-11e9-b473-6e32a6bc259a container dapi-container: <nil>
STEP: delete the pod
Sep  9 14:41:43.740: INFO: Waiting for pod downward-api-f006ff39-d30f-11e9-b473-6e32a6bc259a to disappear
Sep  9 14:41:43.748: INFO: Pod downward-api-f006ff39-d30f-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:41:43.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3308" for this suite.
Sep  9 14:41:49.769: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:41:49.854: INFO: namespace downward-api-3308 deletion completed in 6.099846669s

• [SLOW TEST:8.371 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:41:49.854: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4867
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  9 14:41:50.092: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f50d1b5e-d30f-11e9-b473-6e32a6bc259a" in namespace "downward-api-4867" to be "success or failure"
Sep  9 14:41:50.096: INFO: Pod "downwardapi-volume-f50d1b5e-d30f-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.074931ms
Sep  9 14:41:52.101: INFO: Pod "downwardapi-volume-f50d1b5e-d30f-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008813648s
STEP: Saw pod success
Sep  9 14:41:52.101: INFO: Pod "downwardapi-volume-f50d1b5e-d30f-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 14:41:52.105: INFO: Trying to get logs from node 185.19.31.168 pod downwardapi-volume-f50d1b5e-d30f-11e9-b473-6e32a6bc259a container client-container: <nil>
STEP: delete the pod
Sep  9 14:41:52.126: INFO: Waiting for pod downwardapi-volume-f50d1b5e-d30f-11e9-b473-6e32a6bc259a to disappear
Sep  9 14:41:52.128: INFO: Pod downwardapi-volume-f50d1b5e-d30f-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:41:52.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4867" for this suite.
Sep  9 14:41:58.148: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:41:58.233: INFO: namespace downward-api-4867 deletion completed in 6.102209492s

• [SLOW TEST:8.379 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:41:58.233: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8126
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-8126
Sep  9 14:42:00.435: INFO: Started pod liveness-exec in namespace container-probe-8126
STEP: checking the pod's current state and verifying that restartCount is present
Sep  9 14:42:00.439: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:46:01.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8126" for this suite.
Sep  9 14:46:07.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:46:07.201: INFO: namespace container-probe-8126 deletion completed in 6.099956114s

• [SLOW TEST:248.968 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:46:07.201: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8107
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Sep  9 14:46:07.384: INFO: Waiting up to 5m0s for pod "pod-8e683d96-d310-11e9-b473-6e32a6bc259a" in namespace "emptydir-8107" to be "success or failure"
Sep  9 14:46:07.396: INFO: Pod "pod-8e683d96-d310-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 11.458034ms
Sep  9 14:46:09.401: INFO: Pod "pod-8e683d96-d310-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016345755s
STEP: Saw pod success
Sep  9 14:46:09.401: INFO: Pod "pod-8e683d96-d310-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 14:46:09.405: INFO: Trying to get logs from node 185.19.31.168 pod pod-8e683d96-d310-11e9-b473-6e32a6bc259a container test-container: <nil>
STEP: delete the pod
Sep  9 14:46:09.428: INFO: Waiting for pod pod-8e683d96-d310-11e9-b473-6e32a6bc259a to disappear
Sep  9 14:46:09.431: INFO: Pod pod-8e683d96-d310-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:46:09.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8107" for this suite.
Sep  9 14:46:15.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:46:15.540: INFO: namespace emptydir-8107 deletion completed in 6.104873211s

• [SLOW TEST:8.339 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:46:15.540: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8586
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Sep  9 14:46:15.720: INFO: Waiting up to 5m0s for pod "pod-93607f39-d310-11e9-b473-6e32a6bc259a" in namespace "emptydir-8586" to be "success or failure"
Sep  9 14:46:15.728: INFO: Pod "pod-93607f39-d310-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.200732ms
Sep  9 14:46:17.732: INFO: Pod "pod-93607f39-d310-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012640388s
Sep  9 14:46:19.737: INFO: Pod "pod-93607f39-d310-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017578558s
STEP: Saw pod success
Sep  9 14:46:19.737: INFO: Pod "pod-93607f39-d310-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 14:46:19.741: INFO: Trying to get logs from node 185.19.31.168 pod pod-93607f39-d310-11e9-b473-6e32a6bc259a container test-container: <nil>
STEP: delete the pod
Sep  9 14:46:19.769: INFO: Waiting for pod pod-93607f39-d310-11e9-b473-6e32a6bc259a to disappear
Sep  9 14:46:19.782: INFO: Pod pod-93607f39-d310-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:46:19.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8586" for this suite.
Sep  9 14:46:25.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:46:25.883: INFO: namespace emptydir-8586 deletion completed in 6.098394646s

• [SLOW TEST:10.343 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:46:25.883: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-9225
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Sep  9 14:46:26.106: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep  9 14:46:26.113: INFO: Waiting for terminating namespaces to be deleted...
Sep  9 14:46:26.115: INFO: 
Logging pods the kubelet thinks is on node 185.19.31.168 before test
Sep  9 14:46:26.121: INFO: fluentd-fluentd-elasticsearch-vqcrl from kube-system started at 2019-09-09 07:04:01 +0000 UTC (1 container statuses recorded)
Sep  9 14:46:26.122: INFO: 	Container fluentd-fluentd-elasticsearch ready: true, restart count 0
Sep  9 14:46:26.122: INFO: prometheus-operator-prometheus-node-exporter-pnbwc from monitoring started at 2019-09-09 13:46:48 +0000 UTC (1 container statuses recorded)
Sep  9 14:46:26.122: INFO: 	Container node-exporter ready: true, restart count 0
Sep  9 14:46:26.122: INFO: rke-ingress-controller-deploy-job-hmk7s from kube-system started at 2019-09-09 07:00:59 +0000 UTC (1 container statuses recorded)
Sep  9 14:46:26.122: INFO: 	Container rke-ingress-controller-pod ready: false, restart count 0
Sep  9 14:46:26.122: INFO: sonobuoy-e2e-job-2f41c9be7abd4ce8 from heptio-sonobuoy started at 2019-09-09 13:52:27 +0000 UTC (2 container statuses recorded)
Sep  9 14:46:26.122: INFO: 	Container e2e ready: true, restart count 0
Sep  9 14:46:26.122: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  9 14:46:26.122: INFO: nginx-ingress-controller-xh9n9 from ingress-nginx started at 2019-09-09 13:46:48 +0000 UTC (1 container statuses recorded)
Sep  9 14:46:26.122: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Sep  9 14:46:26.122: INFO: sonobuoy from heptio-sonobuoy started at 2019-09-09 13:52:25 +0000 UTC (1 container statuses recorded)
Sep  9 14:46:26.122: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep  9 14:46:26.122: INFO: falco-z7xtd from falco started at 2019-09-09 13:46:48 +0000 UTC (1 container statuses recorded)
Sep  9 14:46:26.122: INFO: 	Container falco ready: false, restart count 16
Sep  9 14:46:26.122: INFO: rke-metrics-addon-deploy-job-9v7l5 from kube-system started at 2019-09-09 07:00:54 +0000 UTC (1 container statuses recorded)
Sep  9 14:46:26.122: INFO: 	Container rke-metrics-addon-pod ready: false, restart count 0
Sep  9 14:46:26.122: INFO: canal-zdgch from kube-system started at 2019-09-09 07:00:43 +0000 UTC (2 container statuses recorded)
Sep  9 14:46:26.122: INFO: 	Container calico-node ready: true, restart count 0
Sep  9 14:46:26.122: INFO: 	Container kube-flannel ready: true, restart count 0
Sep  9 14:46:26.122: INFO: 
Logging pods the kubelet thinks is on node 185.19.31.68 before test
Sep  9 14:46:26.133: INFO: prometheus-operator-operator-59578796bd-4xxr7 from monitoring started at 2019-09-09 07:03:48 +0000 UTC (1 container statuses recorded)
Sep  9 14:46:26.133: INFO: 	Container prometheus-operator ready: true, restart count 0
Sep  9 14:46:26.133: INFO: oauth2-oauth2-proxy-5b747dfb54-sbtd9 from kube-system started at 2019-09-09 07:03:22 +0000 UTC (1 container statuses recorded)
Sep  9 14:46:26.133: INFO: 	Container oauth2-proxy ready: true, restart count 2
Sep  9 14:46:26.133: INFO: nginx-ingress-controller-lvk92 from ingress-nginx started at 2019-09-09 07:03:45 +0000 UTC (1 container statuses recorded)
Sep  9 14:46:26.133: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Sep  9 14:46:26.133: INFO: canal-kf52z from kube-system started at 2019-09-09 07:00:43 +0000 UTC (2 container statuses recorded)
Sep  9 14:46:26.133: INFO: 	Container calico-node ready: true, restart count 0
Sep  9 14:46:26.133: INFO: 	Container kube-flannel ready: true, restart count 0
Sep  9 14:46:26.133: INFO: cert-manager-cainjector-79b7fc64f-cmtcj from cert-manager started at 2019-09-09 07:02:58 +0000 UTC (1 container statuses recorded)
Sep  9 14:46:26.133: INFO: 	Container cainjector ready: true, restart count 0
Sep  9 14:46:26.133: INFO: coredns-bdffbc666-2s9bq from kube-system started at 2019-09-09 07:00:58 +0000 UTC (1 container statuses recorded)
Sep  9 14:46:26.133: INFO: 	Container coredns ready: true, restart count 0
Sep  9 14:46:26.133: INFO: falco-sbb9j from falco started at 2019-09-09 07:03:23 +0000 UTC (1 container statuses recorded)
Sep  9 14:46:26.133: INFO: 	Container falco ready: true, restart count 0
Sep  9 14:46:26.133: INFO: kubernetes-dashboard-77997c455f-n2pd8 from kube-system started at 2019-09-09 07:02:37 +0000 UTC (1 container statuses recorded)
Sep  9 14:46:26.133: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Sep  9 14:46:26.133: INFO: kubernetes-metrics-scraper-79c9985bc6-mrxx6 from kube-system started at 2019-09-09 07:02:37 +0000 UTC (1 container statuses recorded)
Sep  9 14:46:26.133: INFO: 	Container kubernetes-metrics-scraper ready: true, restart count 0
Sep  9 14:46:26.133: INFO: fluentd-fluentd-elasticsearch-45rjj from kube-system started at 2019-09-09 07:04:01 +0000 UTC (1 container statuses recorded)
Sep  9 14:46:26.133: INFO: 	Container fluentd-fluentd-elasticsearch ready: true, restart count 0
Sep  9 14:46:26.133: INFO: coredns-autoscaler-5d5d49b8ff-ctbzj from kube-system started at 2019-09-09 07:00:58 +0000 UTC (1 container statuses recorded)
Sep  9 14:46:26.133: INFO: 	Container autoscaler ready: true, restart count 0
Sep  9 14:46:26.133: INFO: default-http-backend-5954bd5d8c-xqkx4 from ingress-nginx started at 2019-09-09 07:03:45 +0000 UTC (1 container statuses recorded)
Sep  9 14:46:26.133: INFO: 	Container default-http-backend ready: true, restart count 0
Sep  9 14:46:26.133: INFO: prometheus-operator-kube-state-metrics-59fb8495c9-jst6p from monitoring started at 2019-09-09 07:03:48 +0000 UTC (1 container statuses recorded)
Sep  9 14:46:26.133: INFO: 	Container kube-state-metrics ready: true, restart count 0
Sep  9 14:46:26.133: INFO: nfs-client-provisioner-667644d49c-ttnfb from kube-system started at 2019-09-09 07:02:59 +0000 UTC (1 container statuses recorded)
Sep  9 14:46:26.133: INFO: 	Container nfs-client-provisioner ready: true, restart count 0
Sep  9 14:46:26.133: INFO: opa-b6fb8dbff-xjctw from opa started at 2019-09-09 07:03:23 +0000 UTC (2 container statuses recorded)
Sep  9 14:46:26.133: INFO: 	Container mgmt ready: true, restart count 0
Sep  9 14:46:26.133: INFO: 	Container opa ready: true, restart count 0
Sep  9 14:46:26.133: INFO: prometheus-operator-prometheus-node-exporter-gph6w from monitoring started at 2019-09-09 07:03:48 +0000 UTC (1 container statuses recorded)
Sep  9 14:46:26.133: INFO: 	Container node-exporter ready: true, restart count 0
Sep  9 14:46:26.133: INFO: prometheus-prometheus-operator-prometheus-0 from monitoring started at 2019-09-09 07:04:02 +0000 UTC (3 container statuses recorded)
Sep  9 14:46:26.133: INFO: 	Container prometheus ready: true, restart count 1
Sep  9 14:46:26.133: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Sep  9 14:46:26.133: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
Sep  9 14:46:26.133: INFO: metrics-server-7f6bd4c888-ftrm2 from kube-system started at 2019-09-09 07:00:55 +0000 UTC (1 container statuses recorded)
Sep  9 14:46:26.133: INFO: 	Container metrics-server ready: true, restart count 0
Sep  9 14:46:26.133: INFO: cert-manager-webhook-6484955794-jtctj from cert-manager started at 2019-09-09 07:02:58 +0000 UTC (1 container statuses recorded)
Sep  9 14:46:26.133: INFO: 	Container webhook ready: true, restart count 0
Sep  9 14:46:26.133: INFO: cert-manager-5d669ffbd8-zr582 from cert-manager started at 2019-09-09 07:02:58 +0000 UTC (1 container statuses recorded)
Sep  9 14:46:26.133: INFO: 	Container cert-manager ready: true, restart count 0
Sep  9 14:46:26.133: INFO: tiller-deploy-74bcc7bf9c-ng6b9 from kube-system started at 2019-09-09 07:02:29 +0000 UTC (1 container statuses recorded)
Sep  9 14:46:26.133: INFO: 	Container tiller ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15c2cc6c6510b511], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:46:27.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9225" for this suite.
Sep  9 14:46:33.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:46:33.317: INFO: namespace sched-pred-9225 deletion completed in 6.096483771s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.434 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:46:33.317: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-7211
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override all
Sep  9 14:46:33.535: INFO: Waiting up to 5m0s for pod "client-containers-9dfee1f7-d310-11e9-b473-6e32a6bc259a" in namespace "containers-7211" to be "success or failure"
Sep  9 14:46:33.538: INFO: Pod "client-containers-9dfee1f7-d310-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.576639ms
Sep  9 14:46:35.542: INFO: Pod "client-containers-9dfee1f7-d310-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007474677s
STEP: Saw pod success
Sep  9 14:46:35.542: INFO: Pod "client-containers-9dfee1f7-d310-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 14:46:35.545: INFO: Trying to get logs from node 185.19.31.168 pod client-containers-9dfee1f7-d310-11e9-b473-6e32a6bc259a container test-container: <nil>
STEP: delete the pod
Sep  9 14:46:35.573: INFO: Waiting for pod client-containers-9dfee1f7-d310-11e9-b473-6e32a6bc259a to disappear
Sep  9 14:46:35.578: INFO: Pod client-containers-9dfee1f7-d310-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:46:35.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7211" for this suite.
Sep  9 14:46:41.605: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:46:41.690: INFO: namespace containers-7211 deletion completed in 6.105000328s

• [SLOW TEST:8.372 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:46:41.690: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2331
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:177
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:46:41.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2331" for this suite.
Sep  9 14:47:04.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:47:04.082: INFO: namespace pods-2331 deletion completed in 22.097507563s

• [SLOW TEST:22.393 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:47:04.082: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7427
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:266
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the initial replication controller
Sep  9 14:47:04.250: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 create -f - --namespace=kubectl-7427'
Sep  9 14:47:04.577: INFO: stderr: ""
Sep  9 14:47:04.577: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  9 14:47:04.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7427'
Sep  9 14:47:04.679: INFO: stderr: ""
Sep  9 14:47:04.679: INFO: stdout: "update-demo-nautilus-swpzx update-demo-nautilus-z858n "
Sep  9 14:47:04.679: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods update-demo-nautilus-swpzx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7427'
Sep  9 14:47:04.764: INFO: stderr: ""
Sep  9 14:47:04.764: INFO: stdout: ""
Sep  9 14:47:04.764: INFO: update-demo-nautilus-swpzx is created but not running
Sep  9 14:47:09.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7427'
Sep  9 14:47:09.859: INFO: stderr: ""
Sep  9 14:47:09.859: INFO: stdout: "update-demo-nautilus-swpzx update-demo-nautilus-z858n "
Sep  9 14:47:09.859: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods update-demo-nautilus-swpzx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7427'
Sep  9 14:47:09.942: INFO: stderr: ""
Sep  9 14:47:09.942: INFO: stdout: "true"
Sep  9 14:47:09.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods update-demo-nautilus-swpzx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7427'
Sep  9 14:47:10.022: INFO: stderr: ""
Sep  9 14:47:10.022: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  9 14:47:10.022: INFO: validating pod update-demo-nautilus-swpzx
Sep  9 14:47:10.026: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  9 14:47:10.026: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  9 14:47:10.026: INFO: update-demo-nautilus-swpzx is verified up and running
Sep  9 14:47:10.026: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods update-demo-nautilus-z858n -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7427'
Sep  9 14:47:10.111: INFO: stderr: ""
Sep  9 14:47:10.111: INFO: stdout: "true"
Sep  9 14:47:10.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods update-demo-nautilus-z858n -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7427'
Sep  9 14:47:10.196: INFO: stderr: ""
Sep  9 14:47:10.196: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  9 14:47:10.196: INFO: validating pod update-demo-nautilus-z858n
Sep  9 14:47:10.201: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  9 14:47:10.201: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  9 14:47:10.201: INFO: update-demo-nautilus-z858n is verified up and running
STEP: rolling-update to new replication controller
Sep  9 14:47:10.203: INFO: scanned /root for discovery docs: <nil>
Sep  9 14:47:10.203: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-7427'
Sep  9 14:47:33.635: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Sep  9 14:47:33.635: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  9 14:47:33.635: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7427'
Sep  9 14:47:33.722: INFO: stderr: ""
Sep  9 14:47:33.722: INFO: stdout: "update-demo-kitten-4vxbz update-demo-kitten-5z4ct "
Sep  9 14:47:33.722: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods update-demo-kitten-4vxbz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7427'
Sep  9 14:47:33.802: INFO: stderr: ""
Sep  9 14:47:33.802: INFO: stdout: "true"
Sep  9 14:47:33.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods update-demo-kitten-4vxbz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7427'
Sep  9 14:47:33.893: INFO: stderr: ""
Sep  9 14:47:33.893: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Sep  9 14:47:33.893: INFO: validating pod update-demo-kitten-4vxbz
Sep  9 14:47:33.896: INFO: got data: {
  "image": "kitten.jpg"
}

Sep  9 14:47:33.896: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Sep  9 14:47:33.896: INFO: update-demo-kitten-4vxbz is verified up and running
Sep  9 14:47:33.896: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods update-demo-kitten-5z4ct -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7427'
Sep  9 14:47:33.970: INFO: stderr: ""
Sep  9 14:47:33.970: INFO: stdout: "true"
Sep  9 14:47:33.970: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods update-demo-kitten-5z4ct -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7427'
Sep  9 14:47:34.050: INFO: stderr: ""
Sep  9 14:47:34.050: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Sep  9 14:47:34.050: INFO: validating pod update-demo-kitten-5z4ct
Sep  9 14:47:34.055: INFO: got data: {
  "image": "kitten.jpg"
}

Sep  9 14:47:34.055: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Sep  9 14:47:34.055: INFO: update-demo-kitten-5z4ct is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:47:34.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7427" for this suite.
Sep  9 14:47:56.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:47:56.151: INFO: namespace kubectl-7427 deletion completed in 22.09278735s

• [SLOW TEST:52.069 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:47:56.151: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-6083
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Sep  9 14:47:58.863: INFO: Successfully updated pod "pod-update-cf586128-d310-11e9-b473-6e32a6bc259a"
STEP: verifying the updated pod is in kubernetes
Sep  9 14:47:58.869: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:47:58.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6083" for this suite.
Sep  9 14:48:20.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:48:20.965: INFO: namespace pods-6083 deletion completed in 22.093050084s

• [SLOW TEST:24.814 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:48:20.966: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1171
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Sep  9 14:48:21.142: INFO: Waiting up to 5m0s for pod "pod-de235c30-d310-11e9-b473-6e32a6bc259a" in namespace "emptydir-1171" to be "success or failure"
Sep  9 14:48:21.145: INFO: Pod "pod-de235c30-d310-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.706708ms
Sep  9 14:48:23.149: INFO: Pod "pod-de235c30-d310-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006969357s
STEP: Saw pod success
Sep  9 14:48:23.149: INFO: Pod "pod-de235c30-d310-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 14:48:23.151: INFO: Trying to get logs from node 185.19.31.168 pod pod-de235c30-d310-11e9-b473-6e32a6bc259a container test-container: <nil>
STEP: delete the pod
Sep  9 14:48:23.170: INFO: Waiting for pod pod-de235c30-d310-11e9-b473-6e32a6bc259a to disappear
Sep  9 14:48:23.174: INFO: Pod pod-de235c30-d310-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:48:23.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1171" for this suite.
Sep  9 14:48:29.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:48:29.270: INFO: namespace emptydir-1171 deletion completed in 6.091798784s

• [SLOW TEST:8.304 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:48:29.271: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7334
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1256
STEP: creating an rc
Sep  9 14:48:29.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 create -f - --namespace=kubectl-7334'
Sep  9 14:48:29.638: INFO: stderr: ""
Sep  9 14:48:29.638: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Waiting for Redis master to start.
Sep  9 14:48:30.642: INFO: Selector matched 1 pods for map[app:redis]
Sep  9 14:48:30.642: INFO: Found 0 / 1
Sep  9 14:48:31.642: INFO: Selector matched 1 pods for map[app:redis]
Sep  9 14:48:31.643: INFO: Found 1 / 1
Sep  9 14:48:31.643: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep  9 14:48:31.646: INFO: Selector matched 1 pods for map[app:redis]
Sep  9 14:48:31.646: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Sep  9 14:48:31.646: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 logs redis-master-pwdvf redis-master --namespace=kubectl-7334'
Sep  9 14:48:31.733: INFO: stderr: ""
Sep  9 14:48:31.733: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 09 Sep 14:48:30.738 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 09 Sep 14:48:30.738 # Server started, Redis version 3.2.12\n1:M 09 Sep 14:48:30.738 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 09 Sep 14:48:30.738 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Sep  9 14:48:31.734: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 log redis-master-pwdvf redis-master --namespace=kubectl-7334 --tail=1'
Sep  9 14:48:31.819: INFO: stderr: ""
Sep  9 14:48:31.819: INFO: stdout: "1:M 09 Sep 14:48:30.738 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Sep  9 14:48:31.819: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 log redis-master-pwdvf redis-master --namespace=kubectl-7334 --limit-bytes=1'
Sep  9 14:48:31.921: INFO: stderr: ""
Sep  9 14:48:31.921: INFO: stdout: " "
STEP: exposing timestamps
Sep  9 14:48:31.921: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 log redis-master-pwdvf redis-master --namespace=kubectl-7334 --tail=1 --timestamps'
Sep  9 14:48:32.004: INFO: stderr: ""
Sep  9 14:48:32.004: INFO: stdout: "2019-09-09T14:48:30.738629658Z 1:M 09 Sep 14:48:30.738 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Sep  9 14:48:34.504: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 log redis-master-pwdvf redis-master --namespace=kubectl-7334 --since=1s'
Sep  9 14:48:34.600: INFO: stderr: ""
Sep  9 14:48:34.600: INFO: stdout: ""
Sep  9 14:48:34.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 log redis-master-pwdvf redis-master --namespace=kubectl-7334 --since=24h'
Sep  9 14:48:34.707: INFO: stderr: ""
Sep  9 14:48:34.707: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 09 Sep 14:48:30.738 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 09 Sep 14:48:30.738 # Server started, Redis version 3.2.12\n1:M 09 Sep 14:48:30.738 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 09 Sep 14:48:30.738 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
STEP: using delete to clean up resources
Sep  9 14:48:34.707: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 delete --grace-period=0 --force -f - --namespace=kubectl-7334'
Sep  9 14:48:34.800: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  9 14:48:34.800: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Sep  9 14:48:34.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get rc,svc -l name=nginx --no-headers --namespace=kubectl-7334'
Sep  9 14:48:34.878: INFO: stderr: "No resources found.\n"
Sep  9 14:48:34.878: INFO: stdout: ""
Sep  9 14:48:34.878: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods -l name=nginx --namespace=kubectl-7334 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  9 14:48:34.958: INFO: stderr: ""
Sep  9 14:48:34.958: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:48:34.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7334" for this suite.
Sep  9 14:48:40.979: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:48:41.066: INFO: namespace kubectl-7334 deletion completed in 6.10502425s

• [SLOW TEST:11.795 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:48:41.066: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-9405
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:48:43.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9405" for this suite.
Sep  9 14:49:23.278: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:49:23.373: INFO: namespace kubelet-test-9405 deletion completed in 40.109529928s

• [SLOW TEST:42.307 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:49:23.373: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-2908
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-2908
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Sep  9 14:49:23.563: INFO: Found 0 stateful pods, waiting for 3
Sep  9 14:49:33.569: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep  9 14:49:33.569: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep  9 14:49:33.569: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Sep  9 14:49:33.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 exec --namespace=statefulset-2908 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  9 14:49:33.789: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  9 14:49:33.789: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  9 14:49:33.789: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Sep  9 14:49:33.825: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Sep  9 14:49:43.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 exec --namespace=statefulset-2908 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  9 14:49:44.054: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep  9 14:49:44.054: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  9 14:49:44.054: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  9 14:50:04.077: INFO: Waiting for StatefulSet statefulset-2908/ss2 to complete update
Sep  9 14:50:04.077: INFO: Waiting for Pod statefulset-2908/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Rolling back to a previous revision
Sep  9 14:50:14.085: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 exec --namespace=statefulset-2908 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  9 14:50:14.313: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  9 14:50:14.313: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  9 14:50:14.313: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  9 14:50:24.352: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Sep  9 14:50:34.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 exec --namespace=statefulset-2908 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  9 14:50:34.551: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep  9 14:50:34.551: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  9 14:50:34.551: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  9 14:50:54.573: INFO: Waiting for StatefulSet statefulset-2908/ss2 to complete update
Sep  9 14:50:54.573: INFO: Waiting for Pod statefulset-2908/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Sep  9 14:51:04.582: INFO: Deleting all statefulset in ns statefulset-2908
Sep  9 14:51:04.586: INFO: Scaling statefulset ss2 to 0
Sep  9 14:51:24.608: INFO: Waiting for statefulset status.replicas updated to 0
Sep  9 14:51:24.611: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:51:24.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2908" for this suite.
Sep  9 14:51:30.646: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:51:30.725: INFO: namespace statefulset-2908 deletion completed in 6.094314881s

• [SLOW TEST:127.352 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:51:30.725: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2322
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-4f473157-d311-11e9-b473-6e32a6bc259a
STEP: Creating a pod to test consume configMaps
Sep  9 14:51:30.971: INFO: Waiting up to 5m0s for pod "pod-configmaps-4f488493-d311-11e9-b473-6e32a6bc259a" in namespace "configmap-2322" to be "success or failure"
Sep  9 14:51:30.974: INFO: Pod "pod-configmaps-4f488493-d311-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.111197ms
Sep  9 14:51:32.978: INFO: Pod "pod-configmaps-4f488493-d311-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006855823s
STEP: Saw pod success
Sep  9 14:51:32.978: INFO: Pod "pod-configmaps-4f488493-d311-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 14:51:32.982: INFO: Trying to get logs from node 185.19.31.168 pod pod-configmaps-4f488493-d311-11e9-b473-6e32a6bc259a container configmap-volume-test: <nil>
STEP: delete the pod
Sep  9 14:51:33.010: INFO: Waiting for pod pod-configmaps-4f488493-d311-11e9-b473-6e32a6bc259a to disappear
Sep  9 14:51:33.012: INFO: Pod pod-configmaps-4f488493-d311-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:51:33.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2322" for this suite.
Sep  9 14:51:39.029: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:51:39.112: INFO: namespace configmap-2322 deletion completed in 6.097056991s

• [SLOW TEST:8.387 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:51:39.113: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-4845
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:52:02.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4845" for this suite.
Sep  9 14:52:08.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:52:08.681: INFO: namespace container-runtime-4845 deletion completed in 6.10024146s

• [SLOW TEST:29.569 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  blackbox test
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:52:08.682: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-8860
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  9 14:52:08.850: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:52:09.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8860" for this suite.
Sep  9 14:52:15.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:52:15.564: INFO: namespace custom-resource-definition-8860 deletion completed in 6.132060953s

• [SLOW TEST:6.882 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:32
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:52:15.565: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-9210
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-9210
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep  9 14:52:15.727: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep  9 14:52:35.827: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.42.0.182:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9210 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  9 14:52:35.827: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
Sep  9 14:52:35.934: INFO: Found all expected endpoints: [netserver-0]
Sep  9 14:52:35.938: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.42.1.73:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9210 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  9 14:52:35.938: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
Sep  9 14:52:36.050: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:52:36.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9210" for this suite.
Sep  9 14:53:24.103: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:53:24.184: INFO: namespace pod-network-test-9210 deletion completed in 48.130300718s

• [SLOW TEST:68.619 seconds]
[sig-network] Networking
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:53:24.184: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-6370
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Sep  9 14:53:24.400: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-6370,SelfLink:/api/v1/namespaces/watch-6370/configmaps/e2e-watch-test-resource-version,UID:92df885f-d311-11e9-9321-0635e40003e4,ResourceVersion:81141,Generation:0,CreationTimestamp:2019-09-09 14:53:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  9 14:53:24.400: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-6370,SelfLink:/api/v1/namespaces/watch-6370/configmaps/e2e-watch-test-resource-version,UID:92df885f-d311-11e9-9321-0635e40003e4,ResourceVersion:81142,Generation:0,CreationTimestamp:2019-09-09 14:53:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:53:24.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6370" for this suite.
Sep  9 14:53:30.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:53:30.504: INFO: namespace watch-6370 deletion completed in 6.101785919s

• [SLOW TEST:6.320 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:53:30.504: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7810
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-96a34fe5-d311-11e9-b473-6e32a6bc259a
STEP: Creating a pod to test consume configMaps
Sep  9 14:53:30.697: INFO: Waiting up to 5m0s for pod "pod-configmaps-96a4e65e-d311-11e9-b473-6e32a6bc259a" in namespace "configmap-7810" to be "success or failure"
Sep  9 14:53:30.707: INFO: Pod "pod-configmaps-96a4e65e-d311-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 9.030232ms
Sep  9 14:53:32.711: INFO: Pod "pod-configmaps-96a4e65e-d311-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013291344s
STEP: Saw pod success
Sep  9 14:53:32.711: INFO: Pod "pod-configmaps-96a4e65e-d311-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 14:53:32.713: INFO: Trying to get logs from node 185.19.31.168 pod pod-configmaps-96a4e65e-d311-11e9-b473-6e32a6bc259a container configmap-volume-test: <nil>
STEP: delete the pod
Sep  9 14:53:32.739: INFO: Waiting for pod pod-configmaps-96a4e65e-d311-11e9-b473-6e32a6bc259a to disappear
Sep  9 14:53:32.743: INFO: Pod pod-configmaps-96a4e65e-d311-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:53:32.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7810" for this suite.
Sep  9 14:53:38.763: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:53:38.852: INFO: namespace configmap-7810 deletion completed in 6.106617642s

• [SLOW TEST:8.348 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:53:38.853: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-6469
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:53:41.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6469" for this suite.
Sep  9 14:54:21.071: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:54:21.154: INFO: namespace kubelet-test-6469 deletion completed in 40.096906205s

• [SLOW TEST:42.301 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a read only busybox container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:54:21.154: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-1915
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-1915
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating stateful set ss in namespace statefulset-1915
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-1915
Sep  9 14:54:21.347: INFO: Found 0 stateful pods, waiting for 1
Sep  9 14:54:31.352: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Sep  9 14:54:31.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 exec --namespace=statefulset-1915 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  9 14:54:31.543: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  9 14:54:31.543: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  9 14:54:31.543: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  9 14:54:31.546: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Sep  9 14:54:41.551: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep  9 14:54:41.551: INFO: Waiting for statefulset status.replicas updated to 0
Sep  9 14:54:41.573: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Sep  9 14:54:41.573: INFO: ss-0  185.19.31.168  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:54:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:54:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:54:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:54:21 +0000 UTC  }]
Sep  9 14:54:41.573: INFO: 
Sep  9 14:54:41.573: INFO: StatefulSet ss has not reached scale 3, at 1
Sep  9 14:54:42.577: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996978617s
Sep  9 14:54:43.583: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.993181045s
Sep  9 14:54:44.589: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.987049284s
Sep  9 14:54:45.595: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.980694468s
Sep  9 14:54:46.601: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.974695884s
Sep  9 14:54:47.606: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.96903838s
Sep  9 14:54:48.614: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.963509789s
Sep  9 14:54:49.620: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.955827354s
Sep  9 14:54:50.625: INFO: Verifying statefulset ss doesn't scale past 3 for another 950.199581ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-1915
Sep  9 14:54:51.632: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 exec --namespace=statefulset-1915 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  9 14:54:51.802: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep  9 14:54:51.802: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  9 14:54:51.802: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  9 14:54:51.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 exec --namespace=statefulset-1915 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  9 14:54:52.010: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Sep  9 14:54:52.011: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  9 14:54:52.011: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  9 14:54:52.011: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 exec --namespace=statefulset-1915 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  9 14:54:52.200: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Sep  9 14:54:52.200: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  9 14:54:52.200: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  9 14:54:52.203: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Sep  9 14:55:02.208: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Sep  9 14:55:02.208: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Sep  9 14:55:02.208: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Sep  9 14:55:02.212: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 exec --namespace=statefulset-1915 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  9 14:55:02.410: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  9 14:55:02.410: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  9 14:55:02.410: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  9 14:55:02.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 exec --namespace=statefulset-1915 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  9 14:55:02.625: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  9 14:55:02.625: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  9 14:55:02.625: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  9 14:55:02.625: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 exec --namespace=statefulset-1915 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  9 14:55:02.812: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  9 14:55:02.812: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  9 14:55:02.812: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  9 14:55:02.812: INFO: Waiting for statefulset status.replicas updated to 0
Sep  9 14:55:02.815: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Sep  9 14:55:12.824: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep  9 14:55:12.824: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Sep  9 14:55:12.824: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Sep  9 14:55:12.847: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Sep  9 14:55:12.847: INFO: ss-0  185.19.31.168  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:54:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:55:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:55:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:54:21 +0000 UTC  }]
Sep  9 14:55:12.847: INFO: ss-1  185.19.31.68   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:54:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:55:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:55:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:54:41 +0000 UTC  }]
Sep  9 14:55:12.847: INFO: ss-2  185.19.31.168  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:54:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:55:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:55:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:54:41 +0000 UTC  }]
Sep  9 14:55:12.847: INFO: 
Sep  9 14:55:12.847: INFO: StatefulSet ss has not reached scale 0, at 3
Sep  9 14:55:13.853: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Sep  9 14:55:13.853: INFO: ss-0  185.19.31.168  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:54:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:55:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:55:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:54:21 +0000 UTC  }]
Sep  9 14:55:13.853: INFO: ss-1  185.19.31.68   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:54:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:55:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:55:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:54:41 +0000 UTC  }]
Sep  9 14:55:13.853: INFO: ss-2  185.19.31.168  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:54:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:55:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:55:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:54:41 +0000 UTC  }]
Sep  9 14:55:13.853: INFO: 
Sep  9 14:55:13.853: INFO: StatefulSet ss has not reached scale 0, at 3
Sep  9 14:55:14.860: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Sep  9 14:55:14.860: INFO: ss-0  185.19.31.168  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:54:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:55:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:55:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:54:21 +0000 UTC  }]
Sep  9 14:55:14.860: INFO: ss-2  185.19.31.168  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:54:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:55:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:55:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:54:41 +0000 UTC  }]
Sep  9 14:55:14.860: INFO: 
Sep  9 14:55:14.860: INFO: StatefulSet ss has not reached scale 0, at 2
Sep  9 14:55:15.864: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Sep  9 14:55:15.865: INFO: ss-0  185.19.31.168  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:54:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:55:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:55:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:54:21 +0000 UTC  }]
Sep  9 14:55:15.865: INFO: ss-2  185.19.31.168  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:54:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:55:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:55:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:54:41 +0000 UTC  }]
Sep  9 14:55:15.865: INFO: 
Sep  9 14:55:15.865: INFO: StatefulSet ss has not reached scale 0, at 2
Sep  9 14:55:16.871: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Sep  9 14:55:16.871: INFO: ss-0  185.19.31.168  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:54:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:55:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:55:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:54:21 +0000 UTC  }]
Sep  9 14:55:16.871: INFO: ss-2  185.19.31.168  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:54:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:55:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:55:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:54:41 +0000 UTC  }]
Sep  9 14:55:16.871: INFO: 
Sep  9 14:55:16.871: INFO: StatefulSet ss has not reached scale 0, at 2
Sep  9 14:55:17.878: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Sep  9 14:55:17.878: INFO: ss-0  185.19.31.168  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:54:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:55:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:55:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:54:21 +0000 UTC  }]
Sep  9 14:55:17.878: INFO: ss-2  185.19.31.168  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:54:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:55:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:55:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:54:41 +0000 UTC  }]
Sep  9 14:55:17.878: INFO: 
Sep  9 14:55:17.878: INFO: StatefulSet ss has not reached scale 0, at 2
Sep  9 14:55:18.884: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Sep  9 14:55:18.884: INFO: ss-0  185.19.31.168  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:54:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:55:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:55:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:54:21 +0000 UTC  }]
Sep  9 14:55:18.884: INFO: ss-2  185.19.31.168  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:54:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:55:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:55:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:54:41 +0000 UTC  }]
Sep  9 14:55:18.884: INFO: 
Sep  9 14:55:18.884: INFO: StatefulSet ss has not reached scale 0, at 2
Sep  9 14:55:19.889: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Sep  9 14:55:19.889: INFO: ss-0  185.19.31.168  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:54:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:55:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:55:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:54:21 +0000 UTC  }]
Sep  9 14:55:19.889: INFO: ss-2  185.19.31.168  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:54:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:55:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:55:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 14:54:41 +0000 UTC  }]
Sep  9 14:55:19.889: INFO: 
Sep  9 14:55:19.889: INFO: StatefulSet ss has not reached scale 0, at 2
Sep  9 14:55:20.894: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.952716712s
Sep  9 14:55:21.898: INFO: Verifying statefulset ss doesn't scale past 0 for another 947.772496ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-1915
Sep  9 14:55:22.902: INFO: Scaling statefulset ss to 0
Sep  9 14:55:22.917: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Sep  9 14:55:22.919: INFO: Deleting all statefulset in ns statefulset-1915
Sep  9 14:55:22.922: INFO: Scaling statefulset ss to 0
Sep  9 14:55:22.936: INFO: Waiting for statefulset status.replicas updated to 0
Sep  9 14:55:22.939: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:55:22.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1915" for this suite.
Sep  9 14:55:28.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:55:29.064: INFO: namespace statefulset-1915 deletion completed in 6.1017279s

• [SLOW TEST:67.910 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:55:29.064: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6388
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  9 14:55:29.275: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dd52fa50-d311-11e9-b473-6e32a6bc259a" in namespace "downward-api-6388" to be "success or failure"
Sep  9 14:55:29.285: INFO: Pod "downwardapi-volume-dd52fa50-d311-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 9.167441ms
Sep  9 14:55:31.289: INFO: Pod "downwardapi-volume-dd52fa50-d311-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013369032s
Sep  9 14:55:33.294: INFO: Pod "downwardapi-volume-dd52fa50-d311-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018111749s
STEP: Saw pod success
Sep  9 14:55:33.294: INFO: Pod "downwardapi-volume-dd52fa50-d311-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 14:55:33.297: INFO: Trying to get logs from node 185.19.31.168 pod downwardapi-volume-dd52fa50-d311-11e9-b473-6e32a6bc259a container client-container: <nil>
STEP: delete the pod
Sep  9 14:55:33.320: INFO: Waiting for pod downwardapi-volume-dd52fa50-d311-11e9-b473-6e32a6bc259a to disappear
Sep  9 14:55:33.322: INFO: Pod downwardapi-volume-dd52fa50-d311-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:55:33.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6388" for this suite.
Sep  9 14:55:39.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:55:39.426: INFO: namespace downward-api-6388 deletion completed in 6.101526639s

• [SLOW TEST:10.362 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:55:39.426: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8464
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on tmpfs
Sep  9 14:55:39.606: INFO: Waiting up to 5m0s for pod "pod-e37b5d5f-d311-11e9-b473-6e32a6bc259a" in namespace "emptydir-8464" to be "success or failure"
Sep  9 14:55:39.608: INFO: Pod "pod-e37b5d5f-d311-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.327261ms
Sep  9 14:55:41.617: INFO: Pod "pod-e37b5d5f-d311-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011049567s
STEP: Saw pod success
Sep  9 14:55:41.617: INFO: Pod "pod-e37b5d5f-d311-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 14:55:41.620: INFO: Trying to get logs from node 185.19.31.168 pod pod-e37b5d5f-d311-11e9-b473-6e32a6bc259a container test-container: <nil>
STEP: delete the pod
Sep  9 14:55:41.753: INFO: Waiting for pod pod-e37b5d5f-d311-11e9-b473-6e32a6bc259a to disappear
Sep  9 14:55:41.771: INFO: Pod pod-e37b5d5f-d311-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:55:41.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8464" for this suite.
Sep  9 14:55:47.789: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:55:47.865: INFO: namespace emptydir-8464 deletion completed in 6.090508289s

• [SLOW TEST:8.438 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:55:47.865: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-7018
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test hostPath mode
Sep  9 14:55:48.048: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-7018" to be "success or failure"
Sep  9 14:55:48.054: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 5.491981ms
Sep  9 14:55:50.058: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010138913s
STEP: Saw pod success
Sep  9 14:55:50.059: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Sep  9 14:55:50.063: INFO: Trying to get logs from node 185.19.31.168 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Sep  9 14:55:50.091: INFO: Waiting for pod pod-host-path-test to disappear
Sep  9 14:55:50.101: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:55:50.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-7018" for this suite.
Sep  9 14:55:56.121: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:55:56.211: INFO: namespace hostpath-7018 deletion completed in 6.108218993s

• [SLOW TEST:8.346 seconds]
[sig-storage] HostPath
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:55:56.212: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3076
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Sep  9 14:55:56.393: INFO: Waiting up to 5m0s for pod "pod-ed7c1987-d311-11e9-b473-6e32a6bc259a" in namespace "emptydir-3076" to be "success or failure"
Sep  9 14:55:56.402: INFO: Pod "pod-ed7c1987-d311-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.527673ms
Sep  9 14:55:58.406: INFO: Pod "pod-ed7c1987-d311-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012762917s
STEP: Saw pod success
Sep  9 14:55:58.406: INFO: Pod "pod-ed7c1987-d311-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 14:55:58.409: INFO: Trying to get logs from node 185.19.31.168 pod pod-ed7c1987-d311-11e9-b473-6e32a6bc259a container test-container: <nil>
STEP: delete the pod
Sep  9 14:55:58.433: INFO: Waiting for pod pod-ed7c1987-d311-11e9-b473-6e32a6bc259a to disappear
Sep  9 14:55:58.454: INFO: Pod pod-ed7c1987-d311-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:55:58.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3076" for this suite.
Sep  9 14:56:04.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:56:04.559: INFO: namespace emptydir-3076 deletion completed in 6.102848802s

• [SLOW TEST:8.347 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:56:04.559: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1804
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  9 14:56:04.746: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f2772167-d311-11e9-b473-6e32a6bc259a" in namespace "projected-1804" to be "success or failure"
Sep  9 14:56:04.752: INFO: Pod "downwardapi-volume-f2772167-d311-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.904882ms
Sep  9 14:56:06.757: INFO: Pod "downwardapi-volume-f2772167-d311-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010158625s
STEP: Saw pod success
Sep  9 14:56:06.757: INFO: Pod "downwardapi-volume-f2772167-d311-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 14:56:06.760: INFO: Trying to get logs from node 185.19.31.168 pod downwardapi-volume-f2772167-d311-11e9-b473-6e32a6bc259a container client-container: <nil>
STEP: delete the pod
Sep  9 14:56:06.786: INFO: Waiting for pod downwardapi-volume-f2772167-d311-11e9-b473-6e32a6bc259a to disappear
Sep  9 14:56:06.798: INFO: Pod downwardapi-volume-f2772167-d311-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:56:06.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1804" for this suite.
Sep  9 14:56:12.825: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:56:12.915: INFO: namespace projected-1804 deletion completed in 6.112610248s

• [SLOW TEST:8.356 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:56:12.915: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-8915
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-8915
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep  9 14:56:13.083: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep  9 14:56:31.201: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.0.194:8080/dial?request=hostName&protocol=udp&host=10.42.1.75&port=8081&tries=1'] Namespace:pod-network-test-8915 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  9 14:56:31.201: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
Sep  9 14:56:31.303: INFO: Waiting for endpoints: map[]
Sep  9 14:56:31.306: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.0.194:8080/dial?request=hostName&protocol=udp&host=10.42.0.193&port=8081&tries=1'] Namespace:pod-network-test-8915 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  9 14:56:31.306: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
Sep  9 14:56:31.398: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:56:31.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8915" for this suite.
Sep  9 14:57:19.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:57:19.526: INFO: namespace pod-network-test-8915 deletion completed in 48.123712075s

• [SLOW TEST:66.611 seconds]
[sig-network] Networking
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:57:19.526: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-965
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Sep  9 14:57:19.699: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:57:29.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-965" for this suite.
Sep  9 14:57:35.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:57:36.053: INFO: namespace pods-965 deletion completed in 6.096340311s

• [SLOW TEST:16.528 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:57:36.054: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1765
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  9 14:57:36.234: INFO: Waiting up to 5m0s for pod "downwardapi-volume-28ff345c-d312-11e9-b473-6e32a6bc259a" in namespace "projected-1765" to be "success or failure"
Sep  9 14:57:36.241: INFO: Pod "downwardapi-volume-28ff345c-d312-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.813231ms
Sep  9 14:57:38.246: INFO: Pod "downwardapi-volume-28ff345c-d312-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011701345s
STEP: Saw pod success
Sep  9 14:57:38.246: INFO: Pod "downwardapi-volume-28ff345c-d312-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 14:57:38.250: INFO: Trying to get logs from node 185.19.31.168 pod downwardapi-volume-28ff345c-d312-11e9-b473-6e32a6bc259a container client-container: <nil>
STEP: delete the pod
Sep  9 14:57:38.274: INFO: Waiting for pod downwardapi-volume-28ff345c-d312-11e9-b473-6e32a6bc259a to disappear
Sep  9 14:57:38.277: INFO: Pod downwardapi-volume-28ff345c-d312-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:57:38.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1765" for this suite.
Sep  9 14:57:44.297: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:57:44.382: INFO: namespace projected-1765 deletion completed in 6.100595562s

• [SLOW TEST:8.329 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:57:44.383: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5777
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-2df7fa1e-d312-11e9-b473-6e32a6bc259a
STEP: Creating a pod to test consume secrets
Sep  9 14:57:44.584: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2df98b44-d312-11e9-b473-6e32a6bc259a" in namespace "projected-5777" to be "success or failure"
Sep  9 14:57:44.589: INFO: Pod "pod-projected-secrets-2df98b44-d312-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.700082ms
Sep  9 14:57:46.592: INFO: Pod "pod-projected-secrets-2df98b44-d312-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008133186s
STEP: Saw pod success
Sep  9 14:57:46.592: INFO: Pod "pod-projected-secrets-2df98b44-d312-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 14:57:46.595: INFO: Trying to get logs from node 185.19.31.168 pod pod-projected-secrets-2df98b44-d312-11e9-b473-6e32a6bc259a container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep  9 14:57:46.619: INFO: Waiting for pod pod-projected-secrets-2df98b44-d312-11e9-b473-6e32a6bc259a to disappear
Sep  9 14:57:46.625: INFO: Pod pod-projected-secrets-2df98b44-d312-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:57:46.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5777" for this suite.
Sep  9 14:57:52.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:57:52.730: INFO: namespace projected-5777 deletion completed in 6.10235632s

• [SLOW TEST:8.348 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:57:52.730: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-5017
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  9 14:57:52.903: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Sep  9 14:57:57.907: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep  9 14:57:57.907: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Sep  9 14:57:57.935: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-5017,SelfLink:/apis/apps/v1/namespaces/deployment-5017/deployments/test-cleanup-deployment,UID:35ee0a60-d312-11e9-9321-0635e40003e4,ResourceVersion:82405,Generation:1,CreationTimestamp:2019-09-09 14:57:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Sep  9 14:57:57.937: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:57:57.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5017" for this suite.
Sep  9 14:58:04.006: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:58:04.100: INFO: namespace deployment-5017 deletion completed in 6.157727471s

• [SLOW TEST:11.369 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:58:04.100: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-6856
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-6856
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-6856
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-6856
Sep  9 14:58:04.290: INFO: Found 0 stateful pods, waiting for 1
Sep  9 14:58:14.295: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Sep  9 14:58:14.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 exec --namespace=statefulset-6856 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  9 14:58:14.481: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  9 14:58:14.481: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  9 14:58:14.481: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  9 14:58:14.485: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Sep  9 14:58:24.491: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep  9 14:58:24.491: INFO: Waiting for statefulset status.replicas updated to 0
Sep  9 14:58:24.514: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999506s
Sep  9 14:58:25.518: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.996577737s
Sep  9 14:58:26.523: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.99195176s
Sep  9 14:58:27.528: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.986745786s
Sep  9 14:58:28.533: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.981588875s
Sep  9 14:58:29.538: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.977301312s
Sep  9 14:58:30.543: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.972062703s
Sep  9 14:58:31.548: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.967382192s
Sep  9 14:58:32.553: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.962319557s
Sep  9 14:58:33.558: INFO: Verifying statefulset ss doesn't scale past 1 for another 957.114523ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-6856
Sep  9 14:58:34.563: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 exec --namespace=statefulset-6856 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  9 14:58:34.744: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep  9 14:58:34.744: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  9 14:58:34.744: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  9 14:58:34.748: INFO: Found 1 stateful pods, waiting for 3
Sep  9 14:58:44.753: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Sep  9 14:58:44.753: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Sep  9 14:58:44.753: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Sep  9 14:58:44.760: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 exec --namespace=statefulset-6856 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  9 14:58:44.945: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  9 14:58:44.945: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  9 14:58:44.945: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  9 14:58:44.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 exec --namespace=statefulset-6856 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  9 14:58:45.220: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  9 14:58:45.220: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  9 14:58:45.220: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  9 14:58:45.220: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 exec --namespace=statefulset-6856 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  9 14:58:45.392: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  9 14:58:45.392: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  9 14:58:45.392: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  9 14:58:45.392: INFO: Waiting for statefulset status.replicas updated to 0
Sep  9 14:58:45.395: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Sep  9 14:58:55.403: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep  9 14:58:55.403: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Sep  9 14:58:55.403: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Sep  9 14:58:55.425: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999483s
Sep  9 14:58:56.431: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.99551586s
Sep  9 14:58:57.436: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.989785148s
Sep  9 14:58:58.443: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.984309225s
Sep  9 14:58:59.449: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.977717096s
Sep  9 14:59:00.454: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.971996136s
Sep  9 14:59:01.459: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.967209965s
Sep  9 14:59:02.465: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.961729523s
Sep  9 14:59:03.471: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.955909405s
Sep  9 14:59:04.477: INFO: Verifying statefulset ss doesn't scale past 3 for another 949.754534ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-6856
Sep  9 14:59:05.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 exec --namespace=statefulset-6856 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  9 14:59:05.681: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep  9 14:59:05.681: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  9 14:59:05.681: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  9 14:59:05.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 exec --namespace=statefulset-6856 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  9 14:59:05.882: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep  9 14:59:05.882: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  9 14:59:05.882: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  9 14:59:05.882: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 exec --namespace=statefulset-6856 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  9 14:59:06.057: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep  9 14:59:06.057: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  9 14:59:06.057: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  9 14:59:06.057: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Sep  9 14:59:26.082: INFO: Deleting all statefulset in ns statefulset-6856
Sep  9 14:59:26.085: INFO: Scaling statefulset ss to 0
Sep  9 14:59:26.099: INFO: Waiting for statefulset status.replicas updated to 0
Sep  9 14:59:26.101: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:59:26.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6856" for this suite.
Sep  9 14:59:32.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:59:32.221: INFO: namespace statefulset-6856 deletion completed in 6.103411193s

• [SLOW TEST:88.121 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:59:32.221: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-7810
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Sep  9 14:59:32.432: INFO: Number of nodes with available pods: 0
Sep  9 14:59:32.432: INFO: Node 185.19.31.168 is running more than one daemon pod
Sep  9 14:59:33.440: INFO: Number of nodes with available pods: 0
Sep  9 14:59:33.440: INFO: Node 185.19.31.168 is running more than one daemon pod
Sep  9 14:59:34.441: INFO: Number of nodes with available pods: 1
Sep  9 14:59:34.441: INFO: Node 185.19.31.168 is running more than one daemon pod
Sep  9 14:59:35.441: INFO: Number of nodes with available pods: 2
Sep  9 14:59:35.441: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Sep  9 14:59:35.464: INFO: Number of nodes with available pods: 1
Sep  9 14:59:35.464: INFO: Node 185.19.31.68 is running more than one daemon pod
Sep  9 14:59:36.474: INFO: Number of nodes with available pods: 1
Sep  9 14:59:36.474: INFO: Node 185.19.31.68 is running more than one daemon pod
Sep  9 14:59:37.473: INFO: Number of nodes with available pods: 1
Sep  9 14:59:37.473: INFO: Node 185.19.31.68 is running more than one daemon pod
Sep  9 14:59:38.469: INFO: Number of nodes with available pods: 1
Sep  9 14:59:38.470: INFO: Node 185.19.31.68 is running more than one daemon pod
Sep  9 14:59:39.475: INFO: Number of nodes with available pods: 1
Sep  9 14:59:39.475: INFO: Node 185.19.31.68 is running more than one daemon pod
Sep  9 14:59:40.479: INFO: Number of nodes with available pods: 2
Sep  9 14:59:40.479: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7810, will wait for the garbage collector to delete the pods
Sep  9 14:59:40.548: INFO: Deleting DaemonSet.extensions daemon-set took: 14.428494ms
Sep  9 14:59:40.649: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.317469ms
Sep  9 14:59:49.951: INFO: Number of nodes with available pods: 0
Sep  9 14:59:49.951: INFO: Number of running nodes: 0, number of available pods: 0
Sep  9 14:59:49.953: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7810/daemonsets","resourceVersion":"82975"},"items":null}

Sep  9 14:59:49.955: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7810/pods","resourceVersion":"82975"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 14:59:49.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7810" for this suite.
Sep  9 14:59:55.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 14:59:56.063: INFO: namespace daemonsets-7810 deletion completed in 6.097657744s

• [SLOW TEST:23.842 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 14:59:56.063: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-4597
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service multi-endpoint-test in namespace services-4597
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4597 to expose endpoints map[]
Sep  9 14:59:56.242: INFO: Get endpoints failed (2.422194ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Sep  9 14:59:57.246: INFO: successfully validated that service multi-endpoint-test in namespace services-4597 exposes endpoints map[] (1.007148401s elapsed)
STEP: Creating pod pod1 in namespace services-4597
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4597 to expose endpoints map[pod1:[100]]
Sep  9 14:59:59.288: INFO: successfully validated that service multi-endpoint-test in namespace services-4597 exposes endpoints map[pod1:[100]] (2.022829557s elapsed)
STEP: Creating pod pod2 in namespace services-4597
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4597 to expose endpoints map[pod1:[100] pod2:[101]]
Sep  9 15:00:01.333: INFO: successfully validated that service multi-endpoint-test in namespace services-4597 exposes endpoints map[pod1:[100] pod2:[101]] (2.032003923s elapsed)
STEP: Deleting pod pod1 in namespace services-4597
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4597 to expose endpoints map[pod2:[101]]
Sep  9 15:00:02.362: INFO: successfully validated that service multi-endpoint-test in namespace services-4597 exposes endpoints map[pod2:[101]] (1.015760702s elapsed)
STEP: Deleting pod pod2 in namespace services-4597
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4597 to expose endpoints map[]
Sep  9 15:00:03.381: INFO: successfully validated that service multi-endpoint-test in namespace services-4597 exposes endpoints map[] (1.006948938s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:00:03.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4597" for this suite.
Sep  9 15:00:25.424: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:00:25.509: INFO: namespace services-4597 deletion completed in 22.10273687s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:29.446 seconds]
[sig-network] Services
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:00:25.510: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-365
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  9 15:00:25.698: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Sep  9 15:00:25.708: INFO: Number of nodes with available pods: 0
Sep  9 15:00:25.709: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Sep  9 15:00:25.738: INFO: Number of nodes with available pods: 0
Sep  9 15:00:25.738: INFO: Node 185.19.31.168 is running more than one daemon pod
Sep  9 15:00:26.743: INFO: Number of nodes with available pods: 0
Sep  9 15:00:26.743: INFO: Node 185.19.31.168 is running more than one daemon pod
Sep  9 15:00:27.741: INFO: Number of nodes with available pods: 1
Sep  9 15:00:27.741: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Sep  9 15:00:27.770: INFO: Number of nodes with available pods: 1
Sep  9 15:00:27.770: INFO: Number of running nodes: 0, number of available pods: 1
Sep  9 15:00:28.774: INFO: Number of nodes with available pods: 0
Sep  9 15:00:28.774: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Sep  9 15:00:28.793: INFO: Number of nodes with available pods: 0
Sep  9 15:00:28.793: INFO: Node 185.19.31.168 is running more than one daemon pod
Sep  9 15:00:29.797: INFO: Number of nodes with available pods: 0
Sep  9 15:00:29.797: INFO: Node 185.19.31.168 is running more than one daemon pod
Sep  9 15:00:30.798: INFO: Number of nodes with available pods: 0
Sep  9 15:00:30.798: INFO: Node 185.19.31.168 is running more than one daemon pod
Sep  9 15:00:31.798: INFO: Number of nodes with available pods: 0
Sep  9 15:00:31.798: INFO: Node 185.19.31.168 is running more than one daemon pod
Sep  9 15:00:32.798: INFO: Number of nodes with available pods: 0
Sep  9 15:00:32.798: INFO: Node 185.19.31.168 is running more than one daemon pod
Sep  9 15:00:33.798: INFO: Number of nodes with available pods: 0
Sep  9 15:00:33.798: INFO: Node 185.19.31.168 is running more than one daemon pod
Sep  9 15:00:34.798: INFO: Number of nodes with available pods: 0
Sep  9 15:00:34.798: INFO: Node 185.19.31.168 is running more than one daemon pod
Sep  9 15:00:35.798: INFO: Number of nodes with available pods: 0
Sep  9 15:00:35.798: INFO: Node 185.19.31.168 is running more than one daemon pod
Sep  9 15:00:36.798: INFO: Number of nodes with available pods: 0
Sep  9 15:00:36.798: INFO: Node 185.19.31.168 is running more than one daemon pod
Sep  9 15:00:37.799: INFO: Number of nodes with available pods: 0
Sep  9 15:00:37.799: INFO: Node 185.19.31.168 is running more than one daemon pod
Sep  9 15:00:38.804: INFO: Number of nodes with available pods: 0
Sep  9 15:00:38.804: INFO: Node 185.19.31.168 is running more than one daemon pod
Sep  9 15:00:39.797: INFO: Number of nodes with available pods: 0
Sep  9 15:00:39.797: INFO: Node 185.19.31.168 is running more than one daemon pod
Sep  9 15:00:40.799: INFO: Number of nodes with available pods: 0
Sep  9 15:00:40.799: INFO: Node 185.19.31.168 is running more than one daemon pod
Sep  9 15:00:41.796: INFO: Number of nodes with available pods: 1
Sep  9 15:00:41.796: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-365, will wait for the garbage collector to delete the pods
Sep  9 15:00:41.867: INFO: Deleting DaemonSet.extensions daemon-set took: 14.825483ms
Sep  9 15:00:42.368: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.280138ms
Sep  9 15:00:49.977: INFO: Number of nodes with available pods: 0
Sep  9 15:00:49.977: INFO: Number of running nodes: 0, number of available pods: 0
Sep  9 15:00:49.980: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-365/daemonsets","resourceVersion":"83267"},"items":null}

Sep  9 15:00:49.982: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-365/pods","resourceVersion":"83267"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:00:50.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-365" for this suite.
Sep  9 15:00:56.032: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:00:56.116: INFO: namespace daemonsets-365 deletion completed in 6.100776822s

• [SLOW TEST:30.606 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:00:56.116: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-5410
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0909 15:01:26.823392      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  9 15:01:26.823: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:01:26.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5410" for this suite.
Sep  9 15:01:32.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:01:32.925: INFO: namespace gc-5410 deletion completed in 6.099370382s

• [SLOW TEST:36.809 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:01:32.925: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6089
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  9 15:01:33.102: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b62e9faa-d312-11e9-b473-6e32a6bc259a" in namespace "downward-api-6089" to be "success or failure"
Sep  9 15:01:33.104: INFO: Pod "downwardapi-volume-b62e9faa-d312-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.428709ms
Sep  9 15:01:35.108: INFO: Pod "downwardapi-volume-b62e9faa-d312-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006395945s
STEP: Saw pod success
Sep  9 15:01:35.108: INFO: Pod "downwardapi-volume-b62e9faa-d312-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 15:01:35.111: INFO: Trying to get logs from node 185.19.31.168 pod downwardapi-volume-b62e9faa-d312-11e9-b473-6e32a6bc259a container client-container: <nil>
STEP: delete the pod
Sep  9 15:01:35.133: INFO: Waiting for pod downwardapi-volume-b62e9faa-d312-11e9-b473-6e32a6bc259a to disappear
Sep  9 15:01:35.137: INFO: Pod downwardapi-volume-b62e9faa-d312-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:01:35.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6089" for this suite.
Sep  9 15:01:41.156: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:01:41.238: INFO: namespace downward-api-6089 deletion completed in 6.096690718s

• [SLOW TEST:8.313 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:01:41.238: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1759
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Sep  9 15:01:41.418: INFO: Waiting up to 5m0s for pod "pod-bb22a8ac-d312-11e9-b473-6e32a6bc259a" in namespace "emptydir-1759" to be "success or failure"
Sep  9 15:01:41.422: INFO: Pod "pod-bb22a8ac-d312-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.645085ms
Sep  9 15:01:43.436: INFO: Pod "pod-bb22a8ac-d312-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017385416s
STEP: Saw pod success
Sep  9 15:01:43.436: INFO: Pod "pod-bb22a8ac-d312-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 15:01:43.439: INFO: Trying to get logs from node 185.19.31.168 pod pod-bb22a8ac-d312-11e9-b473-6e32a6bc259a container test-container: <nil>
STEP: delete the pod
Sep  9 15:01:43.462: INFO: Waiting for pod pod-bb22a8ac-d312-11e9-b473-6e32a6bc259a to disappear
Sep  9 15:01:43.466: INFO: Pod pod-bb22a8ac-d312-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:01:43.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1759" for this suite.
Sep  9 15:01:49.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:01:49.570: INFO: namespace emptydir-1759 deletion completed in 6.099566366s

• [SLOW TEST:8.332 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:01:49.570: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8496
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Sep  9 15:01:49.750: INFO: Waiting up to 5m0s for pod "pod-c01a78d7-d312-11e9-b473-6e32a6bc259a" in namespace "emptydir-8496" to be "success or failure"
Sep  9 15:01:49.752: INFO: Pod "pod-c01a78d7-d312-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.317232ms
Sep  9 15:01:51.756: INFO: Pod "pod-c01a78d7-d312-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005818394s
STEP: Saw pod success
Sep  9 15:01:51.756: INFO: Pod "pod-c01a78d7-d312-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 15:01:51.759: INFO: Trying to get logs from node 185.19.31.168 pod pod-c01a78d7-d312-11e9-b473-6e32a6bc259a container test-container: <nil>
STEP: delete the pod
Sep  9 15:01:51.782: INFO: Waiting for pod pod-c01a78d7-d312-11e9-b473-6e32a6bc259a to disappear
Sep  9 15:01:51.789: INFO: Pod pod-c01a78d7-d312-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:01:51.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8496" for this suite.
Sep  9 15:01:57.823: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:01:57.903: INFO: namespace emptydir-8496 deletion completed in 6.109903492s

• [SLOW TEST:8.332 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:01:57.903: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3056
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-c519f454-d312-11e9-b473-6e32a6bc259a
STEP: Creating a pod to test consume configMaps
Sep  9 15:01:58.141: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c51b5473-d312-11e9-b473-6e32a6bc259a" in namespace "projected-3056" to be "success or failure"
Sep  9 15:01:58.145: INFO: Pod "pod-projected-configmaps-c51b5473-d312-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.486811ms
Sep  9 15:02:00.150: INFO: Pod "pod-projected-configmaps-c51b5473-d312-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008809123s
STEP: Saw pod success
Sep  9 15:02:00.150: INFO: Pod "pod-projected-configmaps-c51b5473-d312-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 15:02:00.153: INFO: Trying to get logs from node 185.19.31.168 pod pod-projected-configmaps-c51b5473-d312-11e9-b473-6e32a6bc259a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  9 15:02:00.177: INFO: Waiting for pod pod-projected-configmaps-c51b5473-d312-11e9-b473-6e32a6bc259a to disappear
Sep  9 15:02:00.181: INFO: Pod pod-projected-configmaps-c51b5473-d312-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:02:00.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3056" for this suite.
Sep  9 15:02:06.202: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:02:06.280: INFO: namespace projected-3056 deletion completed in 6.095849701s

• [SLOW TEST:8.377 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:02:06.280: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-2325
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Sep  9 15:02:06.469: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-2325,SelfLink:/api/v1/namespaces/watch-2325/configmaps/e2e-watch-test-watch-closed,UID:ca10821a-d312-11e9-9321-0635e40003e4,ResourceVersion:83661,Generation:0,CreationTimestamp:2019-09-09 15:02:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  9 15:02:06.469: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-2325,SelfLink:/api/v1/namespaces/watch-2325/configmaps/e2e-watch-test-watch-closed,UID:ca10821a-d312-11e9-9321-0635e40003e4,ResourceVersion:83662,Generation:0,CreationTimestamp:2019-09-09 15:02:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Sep  9 15:02:06.489: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-2325,SelfLink:/api/v1/namespaces/watch-2325/configmaps/e2e-watch-test-watch-closed,UID:ca10821a-d312-11e9-9321-0635e40003e4,ResourceVersion:83663,Generation:0,CreationTimestamp:2019-09-09 15:02:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  9 15:02:06.489: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-2325,SelfLink:/api/v1/namespaces/watch-2325/configmaps/e2e-watch-test-watch-closed,UID:ca10821a-d312-11e9-9321-0635e40003e4,ResourceVersion:83664,Generation:0,CreationTimestamp:2019-09-09 15:02:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:02:06.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2325" for this suite.
Sep  9 15:02:12.517: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:02:12.591: INFO: namespace watch-2325 deletion completed in 6.098833115s

• [SLOW TEST:6.311 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:02:12.592: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-7282
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Sep  9 15:02:12.775: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7282,SelfLink:/api/v1/namespaces/watch-7282/configmaps/e2e-watch-test-configmap-a,UID:cdd4e877-d312-11e9-9321-0635e40003e4,ResourceVersion:83692,Generation:0,CreationTimestamp:2019-09-09 15:02:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  9 15:02:12.775: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7282,SelfLink:/api/v1/namespaces/watch-7282/configmaps/e2e-watch-test-configmap-a,UID:cdd4e877-d312-11e9-9321-0635e40003e4,ResourceVersion:83692,Generation:0,CreationTimestamp:2019-09-09 15:02:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Sep  9 15:02:22.802: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7282,SelfLink:/api/v1/namespaces/watch-7282/configmaps/e2e-watch-test-configmap-a,UID:cdd4e877-d312-11e9-9321-0635e40003e4,ResourceVersion:83718,Generation:0,CreationTimestamp:2019-09-09 15:02:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Sep  9 15:02:22.802: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7282,SelfLink:/api/v1/namespaces/watch-7282/configmaps/e2e-watch-test-configmap-a,UID:cdd4e877-d312-11e9-9321-0635e40003e4,ResourceVersion:83718,Generation:0,CreationTimestamp:2019-09-09 15:02:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Sep  9 15:02:32.818: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7282,SelfLink:/api/v1/namespaces/watch-7282/configmaps/e2e-watch-test-configmap-a,UID:cdd4e877-d312-11e9-9321-0635e40003e4,ResourceVersion:83744,Generation:0,CreationTimestamp:2019-09-09 15:02:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  9 15:02:32.818: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7282,SelfLink:/api/v1/namespaces/watch-7282/configmaps/e2e-watch-test-configmap-a,UID:cdd4e877-d312-11e9-9321-0635e40003e4,ResourceVersion:83744,Generation:0,CreationTimestamp:2019-09-09 15:02:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Sep  9 15:02:42.830: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7282,SelfLink:/api/v1/namespaces/watch-7282/configmaps/e2e-watch-test-configmap-a,UID:cdd4e877-d312-11e9-9321-0635e40003e4,ResourceVersion:83771,Generation:0,CreationTimestamp:2019-09-09 15:02:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  9 15:02:42.830: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7282,SelfLink:/api/v1/namespaces/watch-7282/configmaps/e2e-watch-test-configmap-a,UID:cdd4e877-d312-11e9-9321-0635e40003e4,ResourceVersion:83771,Generation:0,CreationTimestamp:2019-09-09 15:02:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Sep  9 15:02:52.850: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-7282,SelfLink:/api/v1/namespaces/watch-7282/configmaps/e2e-watch-test-configmap-b,UID:e5b67437-d312-11e9-9321-0635e40003e4,ResourceVersion:83798,Generation:0,CreationTimestamp:2019-09-09 15:02:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  9 15:02:52.850: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-7282,SelfLink:/api/v1/namespaces/watch-7282/configmaps/e2e-watch-test-configmap-b,UID:e5b67437-d312-11e9-9321-0635e40003e4,ResourceVersion:83798,Generation:0,CreationTimestamp:2019-09-09 15:02:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Sep  9 15:03:02.864: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-7282,SelfLink:/api/v1/namespaces/watch-7282/configmaps/e2e-watch-test-configmap-b,UID:e5b67437-d312-11e9-9321-0635e40003e4,ResourceVersion:83824,Generation:0,CreationTimestamp:2019-09-09 15:02:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  9 15:03:02.865: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-7282,SelfLink:/api/v1/namespaces/watch-7282/configmaps/e2e-watch-test-configmap-b,UID:e5b67437-d312-11e9-9321-0635e40003e4,ResourceVersion:83824,Generation:0,CreationTimestamp:2019-09-09 15:02:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:03:12.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7282" for this suite.
Sep  9 15:03:18.910: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:03:18.997: INFO: namespace watch-7282 deletion completed in 6.127951021s

• [SLOW TEST:66.405 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:03:18.997: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-8318
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override command
Sep  9 15:03:19.167: INFO: Waiting up to 5m0s for pod "client-containers-f566a10a-d312-11e9-b473-6e32a6bc259a" in namespace "containers-8318" to be "success or failure"
Sep  9 15:03:19.173: INFO: Pod "client-containers-f566a10a-d312-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.92952ms
Sep  9 15:03:21.178: INFO: Pod "client-containers-f566a10a-d312-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010537748s
STEP: Saw pod success
Sep  9 15:03:21.178: INFO: Pod "client-containers-f566a10a-d312-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 15:03:21.182: INFO: Trying to get logs from node 185.19.31.168 pod client-containers-f566a10a-d312-11e9-b473-6e32a6bc259a container test-container: <nil>
STEP: delete the pod
Sep  9 15:03:21.219: INFO: Waiting for pod client-containers-f566a10a-d312-11e9-b473-6e32a6bc259a to disappear
Sep  9 15:03:21.222: INFO: Pod client-containers-f566a10a-d312-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:03:21.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8318" for this suite.
Sep  9 15:03:27.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:03:27.320: INFO: namespace containers-8318 deletion completed in 6.095259026s

• [SLOW TEST:8.323 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:03:27.320: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6978
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  9 15:03:27.504: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fa5e7ae9-d312-11e9-b473-6e32a6bc259a" in namespace "projected-6978" to be "success or failure"
Sep  9 15:03:27.511: INFO: Pod "downwardapi-volume-fa5e7ae9-d312-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 7.119974ms
Sep  9 15:03:29.514: INFO: Pod "downwardapi-volume-fa5e7ae9-d312-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010761593s
STEP: Saw pod success
Sep  9 15:03:29.515: INFO: Pod "downwardapi-volume-fa5e7ae9-d312-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 15:03:29.518: INFO: Trying to get logs from node 185.19.31.168 pod downwardapi-volume-fa5e7ae9-d312-11e9-b473-6e32a6bc259a container client-container: <nil>
STEP: delete the pod
Sep  9 15:03:29.548: INFO: Waiting for pod downwardapi-volume-fa5e7ae9-d312-11e9-b473-6e32a6bc259a to disappear
Sep  9 15:03:29.553: INFO: Pod downwardapi-volume-fa5e7ae9-d312-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:03:29.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6978" for this suite.
Sep  9 15:03:35.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:03:35.652: INFO: namespace projected-6978 deletion completed in 6.096868097s

• [SLOW TEST:8.332 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:03:35.653: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-240
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Sep  9 15:03:35.812: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:03:39.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-240" for this suite.
Sep  9 15:03:45.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:03:45.831: INFO: namespace init-container-240 deletion completed in 6.103927567s

• [SLOW TEST:10.178 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:03:45.831: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2141
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-0566461b-d313-11e9-b473-6e32a6bc259a
STEP: Creating a pod to test consume secrets
Sep  9 15:03:46.017: INFO: Waiting up to 5m0s for pod "pod-secrets-0567c1e5-d313-11e9-b473-6e32a6bc259a" in namespace "secrets-2141" to be "success or failure"
Sep  9 15:03:46.026: INFO: Pod "pod-secrets-0567c1e5-d313-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.635654ms
Sep  9 15:03:48.036: INFO: Pod "pod-secrets-0567c1e5-d313-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019085196s
STEP: Saw pod success
Sep  9 15:03:48.036: INFO: Pod "pod-secrets-0567c1e5-d313-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 15:03:48.040: INFO: Trying to get logs from node 185.19.31.168 pod pod-secrets-0567c1e5-d313-11e9-b473-6e32a6bc259a container secret-volume-test: <nil>
STEP: delete the pod
Sep  9 15:03:48.066: INFO: Waiting for pod pod-secrets-0567c1e5-d313-11e9-b473-6e32a6bc259a to disappear
Sep  9 15:03:48.073: INFO: Pod pod-secrets-0567c1e5-d313-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:03:48.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2141" for this suite.
Sep  9 15:03:54.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:03:54.180: INFO: namespace secrets-2141 deletion completed in 6.105057502s

• [SLOW TEST:8.349 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:03:54.181: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-5571
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Sep  9 15:03:54.790: INFO: Pod name wrapped-volume-race-0aa19ae3-d313-11e9-b473-6e32a6bc259a: Found 0 pods out of 5
Sep  9 15:03:59.797: INFO: Pod name wrapped-volume-race-0aa19ae3-d313-11e9-b473-6e32a6bc259a: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-0aa19ae3-d313-11e9-b473-6e32a6bc259a in namespace emptydir-wrapper-5571, will wait for the garbage collector to delete the pods
Sep  9 15:04:09.895: INFO: Deleting ReplicationController wrapped-volume-race-0aa19ae3-d313-11e9-b473-6e32a6bc259a took: 15.792548ms
Sep  9 15:04:10.495: INFO: Terminating ReplicationController wrapped-volume-race-0aa19ae3-d313-11e9-b473-6e32a6bc259a pods took: 600.203608ms
STEP: Creating RC which spawns configmap-volume pods
Sep  9 15:04:50.030: INFO: Pod name wrapped-volume-race-2b8c3fcc-d313-11e9-b473-6e32a6bc259a: Found 0 pods out of 5
Sep  9 15:04:55.040: INFO: Pod name wrapped-volume-race-2b8c3fcc-d313-11e9-b473-6e32a6bc259a: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-2b8c3fcc-d313-11e9-b473-6e32a6bc259a in namespace emptydir-wrapper-5571, will wait for the garbage collector to delete the pods
Sep  9 15:05:05.135: INFO: Deleting ReplicationController wrapped-volume-race-2b8c3fcc-d313-11e9-b473-6e32a6bc259a took: 12.284359ms
Sep  9 15:05:05.735: INFO: Terminating ReplicationController wrapped-volume-race-2b8c3fcc-d313-11e9-b473-6e32a6bc259a pods took: 600.269454ms
STEP: Creating RC which spawns configmap-volume pods
Sep  9 15:05:50.168: INFO: Pod name wrapped-volume-race-4f64e116-d313-11e9-b473-6e32a6bc259a: Found 0 pods out of 5
Sep  9 15:05:55.184: INFO: Pod name wrapped-volume-race-4f64e116-d313-11e9-b473-6e32a6bc259a: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-4f64e116-d313-11e9-b473-6e32a6bc259a in namespace emptydir-wrapper-5571, will wait for the garbage collector to delete the pods
Sep  9 15:06:07.292: INFO: Deleting ReplicationController wrapped-volume-race-4f64e116-d313-11e9-b473-6e32a6bc259a took: 15.356419ms
Sep  9 15:06:07.892: INFO: Terminating ReplicationController wrapped-volume-race-4f64e116-d313-11e9-b473-6e32a6bc259a pods took: 600.22449ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:06:44.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-5571" for this suite.
Sep  9 15:06:50.275: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:06:50.358: INFO: namespace emptydir-wrapper-5571 deletion completed in 6.096956049s

• [SLOW TEST:176.178 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:06:50.359: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-2065
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-v66gt in namespace proxy-2065
I0909 15:06:50.562796      19 runners.go:184] Created replication controller with name: proxy-service-v66gt, namespace: proxy-2065, replica count: 1
I0909 15:06:51.613439      19 runners.go:184] proxy-service-v66gt Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0909 15:06:52.613751      19 runners.go:184] proxy-service-v66gt Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0909 15:06:53.614004      19 runners.go:184] proxy-service-v66gt Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0909 15:06:54.614221      19 runners.go:184] proxy-service-v66gt Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0909 15:06:55.614682      19 runners.go:184] proxy-service-v66gt Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0909 15:06:56.615000      19 runners.go:184] proxy-service-v66gt Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0909 15:06:57.615238      19 runners.go:184] proxy-service-v66gt Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0909 15:06:58.615505      19 runners.go:184] proxy-service-v66gt Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0909 15:06:59.615784      19 runners.go:184] proxy-service-v66gt Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0909 15:07:00.616109      19 runners.go:184] proxy-service-v66gt Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0909 15:07:01.616353      19 runners.go:184] proxy-service-v66gt Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0909 15:07:02.616593      19 runners.go:184] proxy-service-v66gt Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0909 15:07:03.616842      19 runners.go:184] proxy-service-v66gt Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep  9 15:07:03.620: INFO: setup took 13.089734127s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Sep  9 15:07:03.626: INFO: (0) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:162/proxy/: bar (200; 5.91111ms)
Sep  9 15:07:03.636: INFO: (0) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:1080/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:1080/proxy/rewriteme">test<... (200; 14.670985ms)
Sep  9 15:07:03.636: INFO: (0) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:1080/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:1080/proxy/rewriteme">... (200; 14.875297ms)
Sep  9 15:07:03.636: INFO: (0) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:160/proxy/: foo (200; 14.757748ms)
Sep  9 15:07:03.638: INFO: (0) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:162/proxy/: bar (200; 16.795528ms)
Sep  9 15:07:03.640: INFO: (0) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72/proxy/rewriteme">test</a> (200; 18.610969ms)
Sep  9 15:07:03.640: INFO: (0) /api/v1/namespaces/proxy-2065/services/http:proxy-service-v66gt:portname1/proxy/: foo (200; 19.092048ms)
Sep  9 15:07:03.646: INFO: (0) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:462/proxy/: tls qux (200; 25.32826ms)
Sep  9 15:07:03.646: INFO: (0) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:160/proxy/: foo (200; 25.234801ms)
Sep  9 15:07:03.646: INFO: (0) /api/v1/namespaces/proxy-2065/services/proxy-service-v66gt:portname2/proxy/: bar (200; 25.036043ms)
Sep  9 15:07:03.646: INFO: (0) /api/v1/namespaces/proxy-2065/services/http:proxy-service-v66gt:portname2/proxy/: bar (200; 25.354128ms)
Sep  9 15:07:03.646: INFO: (0) /api/v1/namespaces/proxy-2065/services/proxy-service-v66gt:portname1/proxy/: foo (200; 25.266822ms)
Sep  9 15:07:03.646: INFO: (0) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:460/proxy/: tls baz (200; 25.613855ms)
Sep  9 15:07:03.646: INFO: (0) /api/v1/namespaces/proxy-2065/services/https:proxy-service-v66gt:tlsportname2/proxy/: tls qux (200; 25.305046ms)
Sep  9 15:07:03.648: INFO: (0) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:443/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:443/proxy/tlsrewritem... (200; 27.146111ms)
Sep  9 15:07:03.648: INFO: (0) /api/v1/namespaces/proxy-2065/services/https:proxy-service-v66gt:tlsportname1/proxy/: tls baz (200; 26.999741ms)
Sep  9 15:07:03.651: INFO: (1) /api/v1/namespaces/proxy-2065/services/https:proxy-service-v66gt:tlsportname2/proxy/: tls qux (200; 3.018196ms)
Sep  9 15:07:03.652: INFO: (1) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:443/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:443/proxy/tlsrewritem... (200; 3.272427ms)
Sep  9 15:07:03.652: INFO: (1) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:160/proxy/: foo (200; 3.545973ms)
Sep  9 15:07:03.658: INFO: (1) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:162/proxy/: bar (200; 7.824998ms)
Sep  9 15:07:03.658: INFO: (1) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72/proxy/rewriteme">test</a> (200; 7.839702ms)
Sep  9 15:07:03.658: INFO: (1) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:1080/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:1080/proxy/rewriteme">... (200; 8.012204ms)
Sep  9 15:07:03.658: INFO: (1) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:1080/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:1080/proxy/rewriteme">test<... (200; 7.808983ms)
Sep  9 15:07:03.658: INFO: (1) /api/v1/namespaces/proxy-2065/services/proxy-service-v66gt:portname2/proxy/: bar (200; 7.956322ms)
Sep  9 15:07:03.659: INFO: (1) /api/v1/namespaces/proxy-2065/services/https:proxy-service-v66gt:tlsportname1/proxy/: tls baz (200; 8.398988ms)
Sep  9 15:07:03.659: INFO: (1) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:162/proxy/: bar (200; 8.356369ms)
Sep  9 15:07:03.659: INFO: (1) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:460/proxy/: tls baz (200; 8.535616ms)
Sep  9 15:07:03.659: INFO: (1) /api/v1/namespaces/proxy-2065/services/proxy-service-v66gt:portname1/proxy/: foo (200; 8.372067ms)
Sep  9 15:07:03.659: INFO: (1) /api/v1/namespaces/proxy-2065/services/http:proxy-service-v66gt:portname1/proxy/: foo (200; 8.425399ms)
Sep  9 15:07:03.659: INFO: (1) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:160/proxy/: foo (200; 8.844838ms)
Sep  9 15:07:03.659: INFO: (1) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:462/proxy/: tls qux (200; 8.745332ms)
Sep  9 15:07:03.659: INFO: (1) /api/v1/namespaces/proxy-2065/services/http:proxy-service-v66gt:portname2/proxy/: bar (200; 9.022691ms)
Sep  9 15:07:03.670: INFO: (2) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:162/proxy/: bar (200; 10.617896ms)
Sep  9 15:07:03.670: INFO: (2) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:462/proxy/: tls qux (200; 11.220761ms)
Sep  9 15:07:03.671: INFO: (2) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:1080/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:1080/proxy/rewriteme">... (200; 10.733267ms)
Sep  9 15:07:03.671: INFO: (2) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:1080/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:1080/proxy/rewriteme">test<... (200; 10.655306ms)
Sep  9 15:07:03.674: INFO: (2) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:160/proxy/: foo (200; 13.728184ms)
Sep  9 15:07:03.674: INFO: (2) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:160/proxy/: foo (200; 13.987715ms)
Sep  9 15:07:03.674: INFO: (2) /api/v1/namespaces/proxy-2065/services/https:proxy-service-v66gt:tlsportname2/proxy/: tls qux (200; 13.940463ms)
Sep  9 15:07:03.674: INFO: (2) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72/proxy/rewriteme">test</a> (200; 14.155638ms)
Sep  9 15:07:03.674: INFO: (2) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:162/proxy/: bar (200; 13.957741ms)
Sep  9 15:07:03.674: INFO: (2) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:460/proxy/: tls baz (200; 13.966996ms)
Sep  9 15:07:03.674: INFO: (2) /api/v1/namespaces/proxy-2065/services/http:proxy-service-v66gt:portname2/proxy/: bar (200; 14.069506ms)
Sep  9 15:07:03.674: INFO: (2) /api/v1/namespaces/proxy-2065/services/http:proxy-service-v66gt:portname1/proxy/: foo (200; 14.119908ms)
Sep  9 15:07:03.674: INFO: (2) /api/v1/namespaces/proxy-2065/services/proxy-service-v66gt:portname2/proxy/: bar (200; 13.851036ms)
Sep  9 15:07:03.674: INFO: (2) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:443/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:443/proxy/tlsrewritem... (200; 13.881578ms)
Sep  9 15:07:03.674: INFO: (2) /api/v1/namespaces/proxy-2065/services/proxy-service-v66gt:portname1/proxy/: foo (200; 14.02236ms)
Sep  9 15:07:03.674: INFO: (2) /api/v1/namespaces/proxy-2065/services/https:proxy-service-v66gt:tlsportname1/proxy/: tls baz (200; 14.128559ms)
Sep  9 15:07:03.683: INFO: (3) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:160/proxy/: foo (200; 8.31387ms)
Sep  9 15:07:03.683: INFO: (3) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:443/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:443/proxy/tlsrewritem... (200; 8.621762ms)
Sep  9 15:07:03.683: INFO: (3) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:1080/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:1080/proxy/rewriteme">test<... (200; 8.805168ms)
Sep  9 15:07:03.683: INFO: (3) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:162/proxy/: bar (200; 8.631362ms)
Sep  9 15:07:03.684: INFO: (3) /api/v1/namespaces/proxy-2065/services/http:proxy-service-v66gt:portname1/proxy/: foo (200; 8.721572ms)
Sep  9 15:07:03.683: INFO: (3) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:160/proxy/: foo (200; 8.798203ms)
Sep  9 15:07:03.683: INFO: (3) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:1080/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:1080/proxy/rewriteme">... (200; 9.069325ms)
Sep  9 15:07:03.683: INFO: (3) /api/v1/namespaces/proxy-2065/services/http:proxy-service-v66gt:portname2/proxy/: bar (200; 8.311403ms)
Sep  9 15:07:03.683: INFO: (3) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72/proxy/rewriteme">test</a> (200; 8.666797ms)
Sep  9 15:07:03.684: INFO: (3) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:460/proxy/: tls baz (200; 8.547919ms)
Sep  9 15:07:03.684: INFO: (3) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:462/proxy/: tls qux (200; 8.520869ms)
Sep  9 15:07:03.684: INFO: (3) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:162/proxy/: bar (200; 8.637539ms)
Sep  9 15:07:03.684: INFO: (3) /api/v1/namespaces/proxy-2065/services/proxy-service-v66gt:portname1/proxy/: foo (200; 9.995983ms)
Sep  9 15:07:03.685: INFO: (3) /api/v1/namespaces/proxy-2065/services/proxy-service-v66gt:portname2/proxy/: bar (200; 10.122382ms)
Sep  9 15:07:03.685: INFO: (3) /api/v1/namespaces/proxy-2065/services/https:proxy-service-v66gt:tlsportname1/proxy/: tls baz (200; 10.107919ms)
Sep  9 15:07:03.685: INFO: (3) /api/v1/namespaces/proxy-2065/services/https:proxy-service-v66gt:tlsportname2/proxy/: tls qux (200; 10.284773ms)
Sep  9 15:07:03.688: INFO: (4) /api/v1/namespaces/proxy-2065/services/https:proxy-service-v66gt:tlsportname2/proxy/: tls qux (200; 2.576705ms)
Sep  9 15:07:03.695: INFO: (4) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:460/proxy/: tls baz (200; 7.741375ms)
Sep  9 15:07:03.695: INFO: (4) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:443/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:443/proxy/tlsrewritem... (200; 7.857574ms)
Sep  9 15:07:03.695: INFO: (4) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:160/proxy/: foo (200; 7.440934ms)
Sep  9 15:07:03.696: INFO: (4) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:1080/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:1080/proxy/rewriteme">... (200; 7.854745ms)
Sep  9 15:07:03.696: INFO: (4) /api/v1/namespaces/proxy-2065/services/proxy-service-v66gt:portname2/proxy/: bar (200; 7.982756ms)
Sep  9 15:07:03.696: INFO: (4) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:1080/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:1080/proxy/rewriteme">test<... (200; 7.4566ms)
Sep  9 15:07:03.696: INFO: (4) /api/v1/namespaces/proxy-2065/services/http:proxy-service-v66gt:portname1/proxy/: foo (200; 7.855695ms)
Sep  9 15:07:03.696: INFO: (4) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:162/proxy/: bar (200; 8.058248ms)
Sep  9 15:07:03.696: INFO: (4) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:162/proxy/: bar (200; 7.509584ms)
Sep  9 15:07:03.696: INFO: (4) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:160/proxy/: foo (200; 8.023193ms)
Sep  9 15:07:03.696: INFO: (4) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72/proxy/rewriteme">test</a> (200; 7.739562ms)
Sep  9 15:07:03.696: INFO: (4) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:462/proxy/: tls qux (200; 7.693591ms)
Sep  9 15:07:03.696: INFO: (4) /api/v1/namespaces/proxy-2065/services/https:proxy-service-v66gt:tlsportname1/proxy/: tls baz (200; 7.831771ms)
Sep  9 15:07:03.701: INFO: (4) /api/v1/namespaces/proxy-2065/services/http:proxy-service-v66gt:portname2/proxy/: bar (200; 12.856117ms)
Sep  9 15:07:03.701: INFO: (4) /api/v1/namespaces/proxy-2065/services/proxy-service-v66gt:portname1/proxy/: foo (200; 12.986942ms)
Sep  9 15:07:03.710: INFO: (5) /api/v1/namespaces/proxy-2065/services/http:proxy-service-v66gt:portname2/proxy/: bar (200; 8.36678ms)
Sep  9 15:07:03.710: INFO: (5) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:160/proxy/: foo (200; 8.239603ms)
Sep  9 15:07:03.710: INFO: (5) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:443/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:443/proxy/tlsrewritem... (200; 8.832385ms)
Sep  9 15:07:03.710: INFO: (5) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:160/proxy/: foo (200; 9.086128ms)
Sep  9 15:07:03.710: INFO: (5) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:1080/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:1080/proxy/rewriteme">... (200; 8.404053ms)
Sep  9 15:07:03.710: INFO: (5) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:460/proxy/: tls baz (200; 8.212186ms)
Sep  9 15:07:03.710: INFO: (5) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:162/proxy/: bar (200; 8.62121ms)
Sep  9 15:07:03.710: INFO: (5) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72/proxy/rewriteme">test</a> (200; 8.694035ms)
Sep  9 15:07:03.710: INFO: (5) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:162/proxy/: bar (200; 8.308235ms)
Sep  9 15:07:03.710: INFO: (5) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:462/proxy/: tls qux (200; 8.188766ms)
Sep  9 15:07:03.710: INFO: (5) /api/v1/namespaces/proxy-2065/services/http:proxy-service-v66gt:portname1/proxy/: foo (200; 8.595376ms)
Sep  9 15:07:03.710: INFO: (5) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:1080/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:1080/proxy/rewriteme">test<... (200; 8.081347ms)
Sep  9 15:07:03.710: INFO: (5) /api/v1/namespaces/proxy-2065/services/https:proxy-service-v66gt:tlsportname1/proxy/: tls baz (200; 8.805039ms)
Sep  9 15:07:03.710: INFO: (5) /api/v1/namespaces/proxy-2065/services/https:proxy-service-v66gt:tlsportname2/proxy/: tls qux (200; 9.037598ms)
Sep  9 15:07:03.712: INFO: (5) /api/v1/namespaces/proxy-2065/services/proxy-service-v66gt:portname1/proxy/: foo (200; 10.221375ms)
Sep  9 15:07:03.713: INFO: (5) /api/v1/namespaces/proxy-2065/services/proxy-service-v66gt:portname2/proxy/: bar (200; 11.274621ms)
Sep  9 15:07:03.717: INFO: (6) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:1080/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:1080/proxy/rewriteme">test<... (200; 3.82412ms)
Sep  9 15:07:03.718: INFO: (6) /api/v1/namespaces/proxy-2065/services/https:proxy-service-v66gt:tlsportname2/proxy/: tls qux (200; 4.949621ms)
Sep  9 15:07:03.718: INFO: (6) /api/v1/namespaces/proxy-2065/services/https:proxy-service-v66gt:tlsportname1/proxy/: tls baz (200; 5.645722ms)
Sep  9 15:07:03.724: INFO: (6) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:462/proxy/: tls qux (200; 10.834965ms)
Sep  9 15:07:03.724: INFO: (6) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72/proxy/rewriteme">test</a> (200; 10.541823ms)
Sep  9 15:07:03.724: INFO: (6) /api/v1/namespaces/proxy-2065/services/http:proxy-service-v66gt:portname1/proxy/: foo (200; 10.953596ms)
Sep  9 15:07:03.724: INFO: (6) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:162/proxy/: bar (200; 10.529191ms)
Sep  9 15:07:03.724: INFO: (6) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:443/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:443/proxy/tlsrewritem... (200; 10.651354ms)
Sep  9 15:07:03.724: INFO: (6) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:160/proxy/: foo (200; 10.89187ms)
Sep  9 15:07:03.724: INFO: (6) /api/v1/namespaces/proxy-2065/services/proxy-service-v66gt:portname2/proxy/: bar (200; 10.583912ms)
Sep  9 15:07:03.724: INFO: (6) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:1080/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:1080/proxy/rewriteme">... (200; 11.35094ms)
Sep  9 15:07:03.724: INFO: (6) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:162/proxy/: bar (200; 11.2551ms)
Sep  9 15:07:03.725: INFO: (6) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:160/proxy/: foo (200; 11.696445ms)
Sep  9 15:07:03.725: INFO: (6) /api/v1/namespaces/proxy-2065/services/http:proxy-service-v66gt:portname2/proxy/: bar (200; 12.266994ms)
Sep  9 15:07:03.726: INFO: (6) /api/v1/namespaces/proxy-2065/services/proxy-service-v66gt:portname1/proxy/: foo (200; 12.3867ms)
Sep  9 15:07:03.726: INFO: (6) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:460/proxy/: tls baz (200; 12.656279ms)
Sep  9 15:07:03.739: INFO: (7) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:443/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:443/proxy/tlsrewritem... (200; 13.476603ms)
Sep  9 15:07:03.739: INFO: (7) /api/v1/namespaces/proxy-2065/services/proxy-service-v66gt:portname2/proxy/: bar (200; 13.426017ms)
Sep  9 15:07:03.741: INFO: (7) /api/v1/namespaces/proxy-2065/services/http:proxy-service-v66gt:portname2/proxy/: bar (200; 14.474025ms)
Sep  9 15:07:03.741: INFO: (7) /api/v1/namespaces/proxy-2065/services/https:proxy-service-v66gt:tlsportname1/proxy/: tls baz (200; 14.753411ms)
Sep  9 15:07:03.741: INFO: (7) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:1080/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:1080/proxy/rewriteme">... (200; 14.498825ms)
Sep  9 15:07:03.741: INFO: (7) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:460/proxy/: tls baz (200; 14.372635ms)
Sep  9 15:07:03.741: INFO: (7) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72/proxy/rewriteme">test</a> (200; 14.755739ms)
Sep  9 15:07:03.741: INFO: (7) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:162/proxy/: bar (200; 14.719047ms)
Sep  9 15:07:03.741: INFO: (7) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:160/proxy/: foo (200; 15.187ms)
Sep  9 15:07:03.741: INFO: (7) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:462/proxy/: tls qux (200; 14.463196ms)
Sep  9 15:07:03.741: INFO: (7) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:1080/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:1080/proxy/rewriteme">test<... (200; 14.393592ms)
Sep  9 15:07:03.741: INFO: (7) /api/v1/namespaces/proxy-2065/services/https:proxy-service-v66gt:tlsportname2/proxy/: tls qux (200; 15.197905ms)
Sep  9 15:07:03.741: INFO: (7) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:162/proxy/: bar (200; 14.644042ms)
Sep  9 15:07:03.741: INFO: (7) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:160/proxy/: foo (200; 14.729067ms)
Sep  9 15:07:03.741: INFO: (7) /api/v1/namespaces/proxy-2065/services/proxy-service-v66gt:portname1/proxy/: foo (200; 14.529943ms)
Sep  9 15:07:03.741: INFO: (7) /api/v1/namespaces/proxy-2065/services/http:proxy-service-v66gt:portname1/proxy/: foo (200; 14.906145ms)
Sep  9 15:07:03.745: INFO: (8) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:160/proxy/: foo (200; 4.265676ms)
Sep  9 15:07:03.754: INFO: (8) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:462/proxy/: tls qux (200; 11.813037ms)
Sep  9 15:07:03.754: INFO: (8) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:443/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:443/proxy/tlsrewritem... (200; 12.239458ms)
Sep  9 15:07:03.754: INFO: (8) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:1080/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:1080/proxy/rewriteme">... (200; 12.079269ms)
Sep  9 15:07:03.754: INFO: (8) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:460/proxy/: tls baz (200; 12.113529ms)
Sep  9 15:07:03.754: INFO: (8) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:162/proxy/: bar (200; 12.072486ms)
Sep  9 15:07:03.754: INFO: (8) /api/v1/namespaces/proxy-2065/services/proxy-service-v66gt:portname2/proxy/: bar (200; 12.358083ms)
Sep  9 15:07:03.754: INFO: (8) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72/proxy/rewriteme">test</a> (200; 12.301338ms)
Sep  9 15:07:03.754: INFO: (8) /api/v1/namespaces/proxy-2065/services/https:proxy-service-v66gt:tlsportname2/proxy/: tls qux (200; 12.615735ms)
Sep  9 15:07:03.754: INFO: (8) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:160/proxy/: foo (200; 12.277108ms)
Sep  9 15:07:03.754: INFO: (8) /api/v1/namespaces/proxy-2065/services/https:proxy-service-v66gt:tlsportname1/proxy/: tls baz (200; 12.503409ms)
Sep  9 15:07:03.754: INFO: (8) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:162/proxy/: bar (200; 12.23351ms)
Sep  9 15:07:03.754: INFO: (8) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:1080/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:1080/proxy/rewriteme">test<... (200; 12.299708ms)
Sep  9 15:07:03.754: INFO: (8) /api/v1/namespaces/proxy-2065/services/proxy-service-v66gt:portname1/proxy/: foo (200; 12.341622ms)
Sep  9 15:07:03.754: INFO: (8) /api/v1/namespaces/proxy-2065/services/http:proxy-service-v66gt:portname1/proxy/: foo (200; 12.27859ms)
Sep  9 15:07:03.754: INFO: (8) /api/v1/namespaces/proxy-2065/services/http:proxy-service-v66gt:portname2/proxy/: bar (200; 12.291063ms)
Sep  9 15:07:03.762: INFO: (9) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:443/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:443/proxy/tlsrewritem... (200; 8.178983ms)
Sep  9 15:07:03.762: INFO: (9) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:162/proxy/: bar (200; 8.194588ms)
Sep  9 15:07:03.763: INFO: (9) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:1080/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:1080/proxy/rewriteme">test<... (200; 7.627137ms)
Sep  9 15:07:03.763: INFO: (9) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72/proxy/rewriteme">test</a> (200; 8.066762ms)
Sep  9 15:07:03.763: INFO: (9) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:162/proxy/: bar (200; 7.994694ms)
Sep  9 15:07:03.763: INFO: (9) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:160/proxy/: foo (200; 8.049932ms)
Sep  9 15:07:03.763: INFO: (9) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:462/proxy/: tls qux (200; 7.943123ms)
Sep  9 15:07:03.763: INFO: (9) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:1080/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:1080/proxy/rewriteme">... (200; 7.800951ms)
Sep  9 15:07:03.763: INFO: (9) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:160/proxy/: foo (200; 7.662756ms)
Sep  9 15:07:03.763: INFO: (9) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:460/proxy/: tls baz (200; 8.06149ms)
Sep  9 15:07:03.764: INFO: (9) /api/v1/namespaces/proxy-2065/services/https:proxy-service-v66gt:tlsportname1/proxy/: tls baz (200; 9.569978ms)
Sep  9 15:07:03.764: INFO: (9) /api/v1/namespaces/proxy-2065/services/proxy-service-v66gt:portname1/proxy/: foo (200; 9.155621ms)
Sep  9 15:07:03.764: INFO: (9) /api/v1/namespaces/proxy-2065/services/http:proxy-service-v66gt:portname1/proxy/: foo (200; 9.326046ms)
Sep  9 15:07:03.764: INFO: (9) /api/v1/namespaces/proxy-2065/services/proxy-service-v66gt:portname2/proxy/: bar (200; 9.668641ms)
Sep  9 15:07:03.764: INFO: (9) /api/v1/namespaces/proxy-2065/services/https:proxy-service-v66gt:tlsportname2/proxy/: tls qux (200; 9.042711ms)
Sep  9 15:07:03.764: INFO: (9) /api/v1/namespaces/proxy-2065/services/http:proxy-service-v66gt:portname2/proxy/: bar (200; 9.309841ms)
Sep  9 15:07:03.775: INFO: (10) /api/v1/namespaces/proxy-2065/services/https:proxy-service-v66gt:tlsportname2/proxy/: tls qux (200; 11.034001ms)
Sep  9 15:07:03.776: INFO: (10) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:1080/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:1080/proxy/rewriteme">test<... (200; 11.165442ms)
Sep  9 15:07:03.776: INFO: (10) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72/proxy/rewriteme">test</a> (200; 10.951364ms)
Sep  9 15:07:03.776: INFO: (10) /api/v1/namespaces/proxy-2065/services/https:proxy-service-v66gt:tlsportname1/proxy/: tls baz (200; 10.998844ms)
Sep  9 15:07:03.776: INFO: (10) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:160/proxy/: foo (200; 10.964778ms)
Sep  9 15:07:03.776: INFO: (10) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:462/proxy/: tls qux (200; 11.312126ms)
Sep  9 15:07:03.776: INFO: (10) /api/v1/namespaces/proxy-2065/services/proxy-service-v66gt:portname1/proxy/: foo (200; 11.450568ms)
Sep  9 15:07:03.776: INFO: (10) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:162/proxy/: bar (200; 11.402099ms)
Sep  9 15:07:03.776: INFO: (10) /api/v1/namespaces/proxy-2065/services/http:proxy-service-v66gt:portname2/proxy/: bar (200; 11.172366ms)
Sep  9 15:07:03.776: INFO: (10) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:460/proxy/: tls baz (200; 11.405416ms)
Sep  9 15:07:03.776: INFO: (10) /api/v1/namespaces/proxy-2065/services/http:proxy-service-v66gt:portname1/proxy/: foo (200; 11.169244ms)
Sep  9 15:07:03.776: INFO: (10) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:443/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:443/proxy/tlsrewritem... (200; 11.671516ms)
Sep  9 15:07:03.776: INFO: (10) /api/v1/namespaces/proxy-2065/services/proxy-service-v66gt:portname2/proxy/: bar (200; 11.392457ms)
Sep  9 15:07:03.776: INFO: (10) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:160/proxy/: foo (200; 11.426823ms)
Sep  9 15:07:03.776: INFO: (10) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:1080/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:1080/proxy/rewriteme">... (200; 11.303245ms)
Sep  9 15:07:03.776: INFO: (10) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:162/proxy/: bar (200; 11.432536ms)
Sep  9 15:07:03.786: INFO: (11) /api/v1/namespaces/proxy-2065/services/proxy-service-v66gt:portname1/proxy/: foo (200; 10.05198ms)
Sep  9 15:07:03.786: INFO: (11) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:462/proxy/: tls qux (200; 10.19906ms)
Sep  9 15:07:03.786: INFO: (11) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:160/proxy/: foo (200; 9.996421ms)
Sep  9 15:07:03.786: INFO: (11) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72/proxy/rewriteme">test</a> (200; 9.699542ms)
Sep  9 15:07:03.786: INFO: (11) /api/v1/namespaces/proxy-2065/services/https:proxy-service-v66gt:tlsportname2/proxy/: tls qux (200; 9.938561ms)
Sep  9 15:07:03.786: INFO: (11) /api/v1/namespaces/proxy-2065/services/proxy-service-v66gt:portname2/proxy/: bar (200; 9.754058ms)
Sep  9 15:07:03.786: INFO: (11) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:443/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:443/proxy/tlsrewritem... (200; 9.803574ms)
Sep  9 15:07:03.786: INFO: (11) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:160/proxy/: foo (200; 9.909888ms)
Sep  9 15:07:03.786: INFO: (11) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:162/proxy/: bar (200; 9.898845ms)
Sep  9 15:07:03.786: INFO: (11) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:1080/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:1080/proxy/rewriteme">test<... (200; 10.140504ms)
Sep  9 15:07:03.786: INFO: (11) /api/v1/namespaces/proxy-2065/services/https:proxy-service-v66gt:tlsportname1/proxy/: tls baz (200; 9.866571ms)
Sep  9 15:07:03.786: INFO: (11) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:460/proxy/: tls baz (200; 9.906904ms)
Sep  9 15:07:03.786: INFO: (11) /api/v1/namespaces/proxy-2065/services/http:proxy-service-v66gt:portname1/proxy/: foo (200; 10.079952ms)
Sep  9 15:07:03.786: INFO: (11) /api/v1/namespaces/proxy-2065/services/http:proxy-service-v66gt:portname2/proxy/: bar (200; 10.024612ms)
Sep  9 15:07:03.786: INFO: (11) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:162/proxy/: bar (200; 10.230655ms)
Sep  9 15:07:03.787: INFO: (11) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:1080/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:1080/proxy/rewriteme">... (200; 10.637152ms)
Sep  9 15:07:03.792: INFO: (12) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:460/proxy/: tls baz (200; 4.86071ms)
Sep  9 15:07:03.792: INFO: (12) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72/proxy/rewriteme">test</a> (200; 5.265137ms)
Sep  9 15:07:03.795: INFO: (12) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:462/proxy/: tls qux (200; 7.626009ms)
Sep  9 15:07:03.795: INFO: (12) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:1080/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:1080/proxy/rewriteme">test<... (200; 7.4163ms)
Sep  9 15:07:03.795: INFO: (12) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:160/proxy/: foo (200; 7.537145ms)
Sep  9 15:07:03.795: INFO: (12) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:443/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:443/proxy/tlsrewritem... (200; 8.170764ms)
Sep  9 15:07:03.795: INFO: (12) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:162/proxy/: bar (200; 7.992676ms)
Sep  9 15:07:03.795: INFO: (12) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:160/proxy/: foo (200; 7.857201ms)
Sep  9 15:07:03.795: INFO: (12) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:162/proxy/: bar (200; 7.909401ms)
Sep  9 15:07:03.795: INFO: (12) /api/v1/namespaces/proxy-2065/services/https:proxy-service-v66gt:tlsportname1/proxy/: tls baz (200; 8.084335ms)
Sep  9 15:07:03.795: INFO: (12) /api/v1/namespaces/proxy-2065/services/http:proxy-service-v66gt:portname1/proxy/: foo (200; 7.84541ms)
Sep  9 15:07:03.795: INFO: (12) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:1080/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:1080/proxy/rewriteme">... (200; 8.093404ms)
Sep  9 15:07:03.795: INFO: (12) /api/v1/namespaces/proxy-2065/services/https:proxy-service-v66gt:tlsportname2/proxy/: tls qux (200; 7.709419ms)
Sep  9 15:07:03.796: INFO: (12) /api/v1/namespaces/proxy-2065/services/proxy-service-v66gt:portname2/proxy/: bar (200; 8.925264ms)
Sep  9 15:07:03.796: INFO: (12) /api/v1/namespaces/proxy-2065/services/proxy-service-v66gt:portname1/proxy/: foo (200; 8.535955ms)
Sep  9 15:07:03.797: INFO: (12) /api/v1/namespaces/proxy-2065/services/http:proxy-service-v66gt:portname2/proxy/: bar (200; 9.028298ms)
Sep  9 15:07:03.804: INFO: (13) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:1080/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:1080/proxy/rewriteme">... (200; 6.74498ms)
Sep  9 15:07:03.804: INFO: (13) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:162/proxy/: bar (200; 7.032389ms)
Sep  9 15:07:03.804: INFO: (13) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72/proxy/rewriteme">test</a> (200; 6.25033ms)
Sep  9 15:07:03.806: INFO: (13) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:160/proxy/: foo (200; 8.950778ms)
Sep  9 15:07:03.806: INFO: (13) /api/v1/namespaces/proxy-2065/services/proxy-service-v66gt:portname2/proxy/: bar (200; 8.578166ms)
Sep  9 15:07:03.806: INFO: (13) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:160/proxy/: foo (200; 8.799873ms)
Sep  9 15:07:03.806: INFO: (13) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:462/proxy/: tls qux (200; 9.003249ms)
Sep  9 15:07:03.806: INFO: (13) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:162/proxy/: bar (200; 9.204396ms)
Sep  9 15:07:03.806: INFO: (13) /api/v1/namespaces/proxy-2065/services/https:proxy-service-v66gt:tlsportname2/proxy/: tls qux (200; 8.974498ms)
Sep  9 15:07:03.806: INFO: (13) /api/v1/namespaces/proxy-2065/services/http:proxy-service-v66gt:portname1/proxy/: foo (200; 9.516833ms)
Sep  9 15:07:03.807: INFO: (13) /api/v1/namespaces/proxy-2065/services/http:proxy-service-v66gt:portname2/proxy/: bar (200; 10.082428ms)
Sep  9 15:07:03.806: INFO: (13) /api/v1/namespaces/proxy-2065/services/proxy-service-v66gt:portname1/proxy/: foo (200; 8.811682ms)
Sep  9 15:07:03.808: INFO: (13) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:443/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:443/proxy/tlsrewritem... (200; 10.60886ms)
Sep  9 15:07:03.808: INFO: (13) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:1080/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:1080/proxy/rewriteme">test<... (200; 11.096572ms)
Sep  9 15:07:03.809: INFO: (13) /api/v1/namespaces/proxy-2065/services/https:proxy-service-v66gt:tlsportname1/proxy/: tls baz (200; 11.632658ms)
Sep  9 15:07:03.809: INFO: (13) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:460/proxy/: tls baz (200; 12.111006ms)
Sep  9 15:07:03.821: INFO: (14) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:160/proxy/: foo (200; 10.693184ms)
Sep  9 15:07:03.821: INFO: (14) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:443/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:443/proxy/tlsrewritem... (200; 11.552365ms)
Sep  9 15:07:03.821: INFO: (14) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:160/proxy/: foo (200; 11.920857ms)
Sep  9 15:07:03.821: INFO: (14) /api/v1/namespaces/proxy-2065/services/https:proxy-service-v66gt:tlsportname1/proxy/: tls baz (200; 11.388277ms)
Sep  9 15:07:03.821: INFO: (14) /api/v1/namespaces/proxy-2065/services/proxy-service-v66gt:portname2/proxy/: bar (200; 11.496941ms)
Sep  9 15:07:03.821: INFO: (14) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72/proxy/rewriteme">test</a> (200; 11.335451ms)
Sep  9 15:07:03.821: INFO: (14) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:462/proxy/: tls qux (200; 11.166052ms)
Sep  9 15:07:03.821: INFO: (14) /api/v1/namespaces/proxy-2065/services/https:proxy-service-v66gt:tlsportname2/proxy/: tls qux (200; 11.777441ms)
Sep  9 15:07:03.821: INFO: (14) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:162/proxy/: bar (200; 11.284661ms)
Sep  9 15:07:03.821: INFO: (14) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:162/proxy/: bar (200; 10.770799ms)
Sep  9 15:07:03.821: INFO: (14) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:460/proxy/: tls baz (200; 10.703388ms)
Sep  9 15:07:03.821: INFO: (14) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:1080/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:1080/proxy/rewriteme">test<... (200; 10.550635ms)
Sep  9 15:07:03.821: INFO: (14) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:1080/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:1080/proxy/rewriteme">... (200; 11.000212ms)
Sep  9 15:07:03.821: INFO: (14) /api/v1/namespaces/proxy-2065/services/http:proxy-service-v66gt:portname1/proxy/: foo (200; 11.186794ms)
Sep  9 15:07:03.821: INFO: (14) /api/v1/namespaces/proxy-2065/services/proxy-service-v66gt:portname1/proxy/: foo (200; 10.678633ms)
Sep  9 15:07:03.821: INFO: (14) /api/v1/namespaces/proxy-2065/services/http:proxy-service-v66gt:portname2/proxy/: bar (200; 11.130661ms)
Sep  9 15:07:03.825: INFO: (15) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:462/proxy/: tls qux (200; 3.446184ms)
Sep  9 15:07:03.826: INFO: (15) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:160/proxy/: foo (200; 3.973832ms)
Sep  9 15:07:03.826: INFO: (15) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:1080/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:1080/proxy/rewriteme">test<... (200; 3.880358ms)
Sep  9 15:07:03.827: INFO: (15) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:162/proxy/: bar (200; 5.28456ms)
Sep  9 15:07:03.827: INFO: (15) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:1080/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:1080/proxy/rewriteme">... (200; 5.107653ms)
Sep  9 15:07:03.829: INFO: (15) /api/v1/namespaces/proxy-2065/services/http:proxy-service-v66gt:portname1/proxy/: foo (200; 7.503845ms)
Sep  9 15:07:03.829: INFO: (15) /api/v1/namespaces/proxy-2065/services/proxy-service-v66gt:portname2/proxy/: bar (200; 5.842848ms)
Sep  9 15:07:03.832: INFO: (15) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:162/proxy/: bar (200; 10.355219ms)
Sep  9 15:07:03.832: INFO: (15) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:443/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:443/proxy/tlsrewritem... (200; 8.798683ms)
Sep  9 15:07:03.832: INFO: (15) /api/v1/namespaces/proxy-2065/services/proxy-service-v66gt:portname1/proxy/: foo (200; 10.252397ms)
Sep  9 15:07:03.832: INFO: (15) /api/v1/namespaces/proxy-2065/services/http:proxy-service-v66gt:portname2/proxy/: bar (200; 10.57927ms)
Sep  9 15:07:03.832: INFO: (15) /api/v1/namespaces/proxy-2065/services/https:proxy-service-v66gt:tlsportname2/proxy/: tls qux (200; 10.156718ms)
Sep  9 15:07:03.832: INFO: (15) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:460/proxy/: tls baz (200; 10.373383ms)
Sep  9 15:07:03.832: INFO: (15) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:160/proxy/: foo (200; 10.213839ms)
Sep  9 15:07:03.832: INFO: (15) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72/proxy/rewriteme">test</a> (200; 8.761627ms)
Sep  9 15:07:03.832: INFO: (15) /api/v1/namespaces/proxy-2065/services/https:proxy-service-v66gt:tlsportname1/proxy/: tls baz (200; 8.825153ms)
Sep  9 15:07:03.836: INFO: (16) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:1080/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:1080/proxy/rewriteme">... (200; 3.830797ms)
Sep  9 15:07:03.837: INFO: (16) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:160/proxy/: foo (200; 4.662909ms)
Sep  9 15:07:03.841: INFO: (16) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72/proxy/rewriteme">test</a> (200; 7.808846ms)
Sep  9 15:07:03.841: INFO: (16) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:162/proxy/: bar (200; 7.973112ms)
Sep  9 15:07:03.841: INFO: (16) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:460/proxy/: tls baz (200; 7.958591ms)
Sep  9 15:07:03.841: INFO: (16) /api/v1/namespaces/proxy-2065/services/https:proxy-service-v66gt:tlsportname1/proxy/: tls baz (200; 7.829657ms)
Sep  9 15:07:03.841: INFO: (16) /api/v1/namespaces/proxy-2065/services/proxy-service-v66gt:portname2/proxy/: bar (200; 7.911252ms)
Sep  9 15:07:03.841: INFO: (16) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:160/proxy/: foo (200; 7.999798ms)
Sep  9 15:07:03.841: INFO: (16) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:1080/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:1080/proxy/rewriteme">test<... (200; 8.015442ms)
Sep  9 15:07:03.841: INFO: (16) /api/v1/namespaces/proxy-2065/services/http:proxy-service-v66gt:portname2/proxy/: bar (200; 7.957414ms)
Sep  9 15:07:03.841: INFO: (16) /api/v1/namespaces/proxy-2065/services/https:proxy-service-v66gt:tlsportname2/proxy/: tls qux (200; 7.907799ms)
Sep  9 15:07:03.841: INFO: (16) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:443/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:443/proxy/tlsrewritem... (200; 7.946669ms)
Sep  9 15:07:03.841: INFO: (16) /api/v1/namespaces/proxy-2065/services/http:proxy-service-v66gt:portname1/proxy/: foo (200; 8.011505ms)
Sep  9 15:07:03.841: INFO: (16) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:162/proxy/: bar (200; 7.968473ms)
Sep  9 15:07:03.841: INFO: (16) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:462/proxy/: tls qux (200; 8.154713ms)
Sep  9 15:07:03.844: INFO: (16) /api/v1/namespaces/proxy-2065/services/proxy-service-v66gt:portname1/proxy/: foo (200; 7.391379ms)
Sep  9 15:07:03.850: INFO: (17) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72/proxy/rewriteme">test</a> (200; 5.948986ms)
Sep  9 15:07:03.850: INFO: (17) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:162/proxy/: bar (200; 6.775716ms)
Sep  9 15:07:03.850: INFO: (17) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:1080/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:1080/proxy/rewriteme">test<... (200; 6.588892ms)
Sep  9 15:07:03.850: INFO: (17) /api/v1/namespaces/proxy-2065/services/proxy-service-v66gt:portname1/proxy/: foo (200; 6.671651ms)
Sep  9 15:07:03.850: INFO: (17) /api/v1/namespaces/proxy-2065/services/https:proxy-service-v66gt:tlsportname1/proxy/: tls baz (200; 6.377858ms)
Sep  9 15:07:03.850: INFO: (17) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:162/proxy/: bar (200; 6.297259ms)
Sep  9 15:07:03.850: INFO: (17) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:443/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:443/proxy/tlsrewritem... (200; 6.492489ms)
Sep  9 15:07:03.851: INFO: (17) /api/v1/namespaces/proxy-2065/services/https:proxy-service-v66gt:tlsportname2/proxy/: tls qux (200; 6.552047ms)
Sep  9 15:07:03.852: INFO: (17) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:160/proxy/: foo (200; 7.782533ms)
Sep  9 15:07:03.852: INFO: (17) /api/v1/namespaces/proxy-2065/services/proxy-service-v66gt:portname2/proxy/: bar (200; 7.764025ms)
Sep  9 15:07:03.854: INFO: (17) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:460/proxy/: tls baz (200; 5.822625ms)
Sep  9 15:07:03.854: INFO: (17) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:160/proxy/: foo (200; 5.648931ms)
Sep  9 15:07:03.854: INFO: (17) /api/v1/namespaces/proxy-2065/services/http:proxy-service-v66gt:portname2/proxy/: bar (200; 5.757053ms)
Sep  9 15:07:03.854: INFO: (17) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:462/proxy/: tls qux (200; 5.909897ms)
Sep  9 15:07:03.855: INFO: (17) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:1080/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:1080/proxy/rewriteme">... (200; 6.291775ms)
Sep  9 15:07:03.854: INFO: (17) /api/v1/namespaces/proxy-2065/services/http:proxy-service-v66gt:portname1/proxy/: foo (200; 5.996212ms)
Sep  9 15:07:03.859: INFO: (18) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:1080/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:1080/proxy/rewriteme">... (200; 4.225596ms)
Sep  9 15:07:03.862: INFO: (18) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:162/proxy/: bar (200; 7.221356ms)
Sep  9 15:07:03.862: INFO: (18) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72/proxy/rewriteme">test</a> (200; 6.492376ms)
Sep  9 15:07:03.862: INFO: (18) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:160/proxy/: foo (200; 6.80728ms)
Sep  9 15:07:03.862: INFO: (18) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:160/proxy/: foo (200; 7.095641ms)
Sep  9 15:07:03.862: INFO: (18) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:162/proxy/: bar (200; 7.044919ms)
Sep  9 15:07:03.862: INFO: (18) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:462/proxy/: tls qux (200; 6.971353ms)
Sep  9 15:07:03.862: INFO: (18) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:460/proxy/: tls baz (200; 7.150984ms)
Sep  9 15:07:03.862: INFO: (18) /api/v1/namespaces/proxy-2065/services/http:proxy-service-v66gt:portname1/proxy/: foo (200; 7.42491ms)
Sep  9 15:07:03.862: INFO: (18) /api/v1/namespaces/proxy-2065/services/http:proxy-service-v66gt:portname2/proxy/: bar (200; 7.376187ms)
Sep  9 15:07:03.862: INFO: (18) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:1080/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:1080/proxy/rewriteme">test<... (200; 7.048568ms)
Sep  9 15:07:03.862: INFO: (18) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:443/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:443/proxy/tlsrewritem... (200; 6.930033ms)
Sep  9 15:07:03.865: INFO: (18) /api/v1/namespaces/proxy-2065/services/https:proxy-service-v66gt:tlsportname2/proxy/: tls qux (200; 9.504445ms)
Sep  9 15:07:03.865: INFO: (18) /api/v1/namespaces/proxy-2065/services/proxy-service-v66gt:portname1/proxy/: foo (200; 9.657868ms)
Sep  9 15:07:03.865: INFO: (18) /api/v1/namespaces/proxy-2065/services/https:proxy-service-v66gt:tlsportname1/proxy/: tls baz (200; 9.417494ms)
Sep  9 15:07:03.865: INFO: (18) /api/v1/namespaces/proxy-2065/services/proxy-service-v66gt:portname2/proxy/: bar (200; 9.542826ms)
Sep  9 15:07:03.871: INFO: (19) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72/proxy/rewriteme">test</a> (200; 5.534216ms)
Sep  9 15:07:03.873: INFO: (19) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:443/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:443/proxy/tlsrewritem... (200; 8.222988ms)
Sep  9 15:07:03.874: INFO: (19) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:460/proxy/: tls baz (200; 8.87372ms)
Sep  9 15:07:03.874: INFO: (19) /api/v1/namespaces/proxy-2065/services/http:proxy-service-v66gt:portname2/proxy/: bar (200; 8.443315ms)
Sep  9 15:07:03.874: INFO: (19) /api/v1/namespaces/proxy-2065/services/proxy-service-v66gt:portname2/proxy/: bar (200; 8.797809ms)
Sep  9 15:07:03.874: INFO: (19) /api/v1/namespaces/proxy-2065/pods/https:proxy-service-v66gt-66n72:462/proxy/: tls qux (200; 9.032846ms)
Sep  9 15:07:03.874: INFO: (19) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:162/proxy/: bar (200; 8.797714ms)
Sep  9 15:07:03.874: INFO: (19) /api/v1/namespaces/proxy-2065/services/http:proxy-service-v66gt:portname1/proxy/: foo (200; 8.756219ms)
Sep  9 15:07:03.874: INFO: (19) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:162/proxy/: bar (200; 8.9893ms)
Sep  9 15:07:03.874: INFO: (19) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:160/proxy/: foo (200; 9.02853ms)
Sep  9 15:07:03.874: INFO: (19) /api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:1080/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/proxy-service-v66gt-66n72:1080/proxy/rewriteme">test<... (200; 9.072542ms)
Sep  9 15:07:03.874: INFO: (19) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:1080/proxy/: <a href="/api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:1080/proxy/rewriteme">... (200; 8.913338ms)
Sep  9 15:07:03.876: INFO: (19) /api/v1/namespaces/proxy-2065/services/proxy-service-v66gt:portname1/proxy/: foo (200; 10.811561ms)
Sep  9 15:07:03.876: INFO: (19) /api/v1/namespaces/proxy-2065/services/https:proxy-service-v66gt:tlsportname1/proxy/: tls baz (200; 10.751495ms)
Sep  9 15:07:03.876: INFO: (19) /api/v1/namespaces/proxy-2065/services/https:proxy-service-v66gt:tlsportname2/proxy/: tls qux (200; 10.792982ms)
Sep  9 15:07:03.876: INFO: (19) /api/v1/namespaces/proxy-2065/pods/http:proxy-service-v66gt-66n72:160/proxy/: foo (200; 11.121368ms)
STEP: deleting ReplicationController proxy-service-v66gt in namespace proxy-2065, will wait for the garbage collector to delete the pods
Sep  9 15:07:03.943: INFO: Deleting ReplicationController proxy-service-v66gt took: 14.040325ms
Sep  9 15:07:04.444: INFO: Terminating ReplicationController proxy-service-v66gt pods took: 500.197544ms
[AfterEach] version v1
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:07:06.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2065" for this suite.
Sep  9 15:07:12.666: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:07:12.754: INFO: namespace proxy-2065 deletion completed in 6.10651452s

• [SLOW TEST:22.395 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:07:12.754: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-6806
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
STEP: reading a file in the container
Sep  9 15:07:15.466: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6806 pod-service-account-810bd234-d313-11e9-b473-6e32a6bc259a -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Sep  9 15:07:15.642: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6806 pod-service-account-810bd234-d313-11e9-b473-6e32a6bc259a -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Sep  9 15:07:15.807: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6806 pod-service-account-810bd234-d313-11e9-b473-6e32a6bc259a -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:07:15.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-6806" for this suite.
Sep  9 15:07:21.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:07:22.081: INFO: namespace svcaccounts-6806 deletion completed in 6.107236635s

• [SLOW TEST:9.327 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:07:22.081: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-5652
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  9 15:07:46.280: INFO: Container started at 2019-09-09 15:07:23 +0000 UTC, pod became ready at 2019-09-09 15:07:45 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:07:46.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5652" for this suite.
Sep  9 15:08:08.300: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:08:08.384: INFO: namespace container-probe-5652 deletion completed in 22.099520805s

• [SLOW TEST:46.302 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:08:08.384: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-646
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  9 15:08:08.551: INFO: (0) /api/v1/nodes/185.19.31.168/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 4.701677ms)
Sep  9 15:08:08.554: INFO: (1) /api/v1/nodes/185.19.31.168/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.120972ms)
Sep  9 15:08:08.557: INFO: (2) /api/v1/nodes/185.19.31.168/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.586968ms)
Sep  9 15:08:08.560: INFO: (3) /api/v1/nodes/185.19.31.168/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.616126ms)
Sep  9 15:08:08.563: INFO: (4) /api/v1/nodes/185.19.31.168/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.966628ms)
Sep  9 15:08:08.566: INFO: (5) /api/v1/nodes/185.19.31.168/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.7818ms)
Sep  9 15:08:08.569: INFO: (6) /api/v1/nodes/185.19.31.168/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.422266ms)
Sep  9 15:08:08.572: INFO: (7) /api/v1/nodes/185.19.31.168/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.880187ms)
Sep  9 15:08:08.574: INFO: (8) /api/v1/nodes/185.19.31.168/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.481546ms)
Sep  9 15:08:08.576: INFO: (9) /api/v1/nodes/185.19.31.168/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.112722ms)
Sep  9 15:08:08.579: INFO: (10) /api/v1/nodes/185.19.31.168/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.394742ms)
Sep  9 15:08:08.581: INFO: (11) /api/v1/nodes/185.19.31.168/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.189308ms)
Sep  9 15:08:08.583: INFO: (12) /api/v1/nodes/185.19.31.168/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.306594ms)
Sep  9 15:08:08.585: INFO: (13) /api/v1/nodes/185.19.31.168/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.149654ms)
Sep  9 15:08:08.587: INFO: (14) /api/v1/nodes/185.19.31.168/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 1.98986ms)
Sep  9 15:08:08.590: INFO: (15) /api/v1/nodes/185.19.31.168/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.324712ms)
Sep  9 15:08:08.592: INFO: (16) /api/v1/nodes/185.19.31.168/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.501702ms)
Sep  9 15:08:08.595: INFO: (17) /api/v1/nodes/185.19.31.168/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.298068ms)
Sep  9 15:08:08.597: INFO: (18) /api/v1/nodes/185.19.31.168/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.123455ms)
Sep  9 15:08:08.599: INFO: (19) /api/v1/nodes/185.19.31.168/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.060553ms)
[AfterEach] version v1
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:08:08.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-646" for this suite.
Sep  9 15:08:14.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:08:14.693: INFO: namespace proxy-646 deletion completed in 6.091858079s

• [SLOW TEST:6.309 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:08:14.693: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-333
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:266
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Sep  9 15:08:14.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 create -f - --namespace=kubectl-333'
Sep  9 15:08:15.367: INFO: stderr: ""
Sep  9 15:08:15.367: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  9 15:08:15.367: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-333'
Sep  9 15:08:15.480: INFO: stderr: ""
Sep  9 15:08:15.480: INFO: stdout: "update-demo-nautilus-8m8vj update-demo-nautilus-b6h6b "
Sep  9 15:08:15.480: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods update-demo-nautilus-8m8vj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-333'
Sep  9 15:08:15.563: INFO: stderr: ""
Sep  9 15:08:15.563: INFO: stdout: ""
Sep  9 15:08:15.563: INFO: update-demo-nautilus-8m8vj is created but not running
Sep  9 15:08:20.563: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-333'
Sep  9 15:08:20.665: INFO: stderr: ""
Sep  9 15:08:20.665: INFO: stdout: "update-demo-nautilus-8m8vj update-demo-nautilus-b6h6b "
Sep  9 15:08:20.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods update-demo-nautilus-8m8vj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-333'
Sep  9 15:08:20.754: INFO: stderr: ""
Sep  9 15:08:20.755: INFO: stdout: "true"
Sep  9 15:08:20.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods update-demo-nautilus-8m8vj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-333'
Sep  9 15:08:20.839: INFO: stderr: ""
Sep  9 15:08:20.839: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  9 15:08:20.839: INFO: validating pod update-demo-nautilus-8m8vj
Sep  9 15:08:20.844: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  9 15:08:20.844: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  9 15:08:20.844: INFO: update-demo-nautilus-8m8vj is verified up and running
Sep  9 15:08:20.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods update-demo-nautilus-b6h6b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-333'
Sep  9 15:08:20.925: INFO: stderr: ""
Sep  9 15:08:20.925: INFO: stdout: "true"
Sep  9 15:08:20.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods update-demo-nautilus-b6h6b -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-333'
Sep  9 15:08:21.008: INFO: stderr: ""
Sep  9 15:08:21.008: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  9 15:08:21.008: INFO: validating pod update-demo-nautilus-b6h6b
Sep  9 15:08:21.012: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  9 15:08:21.012: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  9 15:08:21.012: INFO: update-demo-nautilus-b6h6b is verified up and running
STEP: scaling down the replication controller
Sep  9 15:08:21.014: INFO: scanned /root for discovery docs: <nil>
Sep  9 15:08:21.014: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-333'
Sep  9 15:08:22.127: INFO: stderr: ""
Sep  9 15:08:22.127: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  9 15:08:22.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-333'
Sep  9 15:08:22.221: INFO: stderr: ""
Sep  9 15:08:22.221: INFO: stdout: "update-demo-nautilus-8m8vj update-demo-nautilus-b6h6b "
STEP: Replicas for name=update-demo: expected=1 actual=2
Sep  9 15:08:27.221: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-333'
Sep  9 15:08:27.314: INFO: stderr: ""
Sep  9 15:08:27.314: INFO: stdout: "update-demo-nautilus-8m8vj update-demo-nautilus-b6h6b "
STEP: Replicas for name=update-demo: expected=1 actual=2
Sep  9 15:08:32.315: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-333'
Sep  9 15:08:32.413: INFO: stderr: ""
Sep  9 15:08:32.413: INFO: stdout: "update-demo-nautilus-8m8vj update-demo-nautilus-b6h6b "
STEP: Replicas for name=update-demo: expected=1 actual=2
Sep  9 15:08:37.413: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-333'
Sep  9 15:08:37.516: INFO: stderr: ""
Sep  9 15:08:37.516: INFO: stdout: "update-demo-nautilus-b6h6b "
Sep  9 15:08:37.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods update-demo-nautilus-b6h6b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-333'
Sep  9 15:08:37.609: INFO: stderr: ""
Sep  9 15:08:37.609: INFO: stdout: "true"
Sep  9 15:08:37.609: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods update-demo-nautilus-b6h6b -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-333'
Sep  9 15:08:37.701: INFO: stderr: ""
Sep  9 15:08:37.701: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  9 15:08:37.701: INFO: validating pod update-demo-nautilus-b6h6b
Sep  9 15:08:37.705: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  9 15:08:37.705: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  9 15:08:37.705: INFO: update-demo-nautilus-b6h6b is verified up and running
STEP: scaling up the replication controller
Sep  9 15:08:37.707: INFO: scanned /root for discovery docs: <nil>
Sep  9 15:08:37.707: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-333'
Sep  9 15:08:38.833: INFO: stderr: ""
Sep  9 15:08:38.833: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  9 15:08:38.833: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-333'
Sep  9 15:08:38.931: INFO: stderr: ""
Sep  9 15:08:38.931: INFO: stdout: "update-demo-nautilus-b6h6b update-demo-nautilus-dk2l6 "
Sep  9 15:08:38.931: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods update-demo-nautilus-b6h6b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-333'
Sep  9 15:08:39.031: INFO: stderr: ""
Sep  9 15:08:39.031: INFO: stdout: "true"
Sep  9 15:08:39.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods update-demo-nautilus-b6h6b -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-333'
Sep  9 15:08:39.113: INFO: stderr: ""
Sep  9 15:08:39.113: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  9 15:08:39.113: INFO: validating pod update-demo-nautilus-b6h6b
Sep  9 15:08:39.116: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  9 15:08:39.116: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  9 15:08:39.117: INFO: update-demo-nautilus-b6h6b is verified up and running
Sep  9 15:08:39.117: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods update-demo-nautilus-dk2l6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-333'
Sep  9 15:08:39.200: INFO: stderr: ""
Sep  9 15:08:39.200: INFO: stdout: ""
Sep  9 15:08:39.200: INFO: update-demo-nautilus-dk2l6 is created but not running
Sep  9 15:08:44.200: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-333'
Sep  9 15:08:44.301: INFO: stderr: ""
Sep  9 15:08:44.301: INFO: stdout: "update-demo-nautilus-b6h6b update-demo-nautilus-dk2l6 "
Sep  9 15:08:44.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods update-demo-nautilus-b6h6b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-333'
Sep  9 15:08:44.388: INFO: stderr: ""
Sep  9 15:08:44.388: INFO: stdout: "true"
Sep  9 15:08:44.388: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods update-demo-nautilus-b6h6b -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-333'
Sep  9 15:08:44.485: INFO: stderr: ""
Sep  9 15:08:44.485: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  9 15:08:44.485: INFO: validating pod update-demo-nautilus-b6h6b
Sep  9 15:08:44.489: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  9 15:08:44.489: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  9 15:08:44.489: INFO: update-demo-nautilus-b6h6b is verified up and running
Sep  9 15:08:44.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods update-demo-nautilus-dk2l6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-333'
Sep  9 15:08:44.577: INFO: stderr: ""
Sep  9 15:08:44.577: INFO: stdout: "true"
Sep  9 15:08:44.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods update-demo-nautilus-dk2l6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-333'
Sep  9 15:08:44.664: INFO: stderr: ""
Sep  9 15:08:44.664: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  9 15:08:44.664: INFO: validating pod update-demo-nautilus-dk2l6
Sep  9 15:08:44.668: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  9 15:08:44.669: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  9 15:08:44.669: INFO: update-demo-nautilus-dk2l6 is verified up and running
STEP: using delete to clean up resources
Sep  9 15:08:44.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 delete --grace-period=0 --force -f - --namespace=kubectl-333'
Sep  9 15:08:44.762: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  9 15:08:44.762: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Sep  9 15:08:44.762: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-333'
Sep  9 15:08:44.856: INFO: stderr: "No resources found.\n"
Sep  9 15:08:44.856: INFO: stdout: ""
Sep  9 15:08:44.856: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods -l name=update-demo --namespace=kubectl-333 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  9 15:08:44.937: INFO: stderr: ""
Sep  9 15:08:44.937: INFO: stdout: "update-demo-nautilus-b6h6b\nupdate-demo-nautilus-dk2l6\n"
Sep  9 15:08:45.437: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-333'
Sep  9 15:08:45.534: INFO: stderr: "No resources found.\n"
Sep  9 15:08:45.534: INFO: stdout: ""
Sep  9 15:08:45.535: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods -l name=update-demo --namespace=kubectl-333 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  9 15:08:45.627: INFO: stderr: ""
Sep  9 15:08:45.627: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:08:45.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-333" for this suite.
Sep  9 15:09:07.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:09:07.741: INFO: namespace kubectl-333 deletion completed in 22.111338783s

• [SLOW TEST:53.048 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:09:07.741: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-8613
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  9 15:09:07.906: INFO: Creating deployment "test-recreate-deployment"
Sep  9 15:09:07.917: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Sep  9 15:09:07.925: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Sep  9 15:09:09.931: INFO: Waiting deployment "test-recreate-deployment" to complete
Sep  9 15:09:09.933: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Sep  9 15:09:09.955: INFO: Updating deployment test-recreate-deployment
Sep  9 15:09:09.955: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Sep  9 15:09:10.079: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-8613,SelfLink:/apis/apps/v1/namespaces/deployment-8613/deployments/test-recreate-deployment,UID:c5466074-d313-11e9-9321-0635e40003e4,ResourceVersion:86006,Generation:2,CreationTimestamp:2019-09-09 15:09:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-09-09 15:09:10 +0000 UTC 2019-09-09 15:09:10 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-09-09 15:09:10 +0000 UTC 2019-09-09 15:09:07 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-745fb9c84c" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Sep  9 15:09:10.082: INFO: New ReplicaSet "test-recreate-deployment-745fb9c84c" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-745fb9c84c,GenerateName:,Namespace:deployment-8613,SelfLink:/apis/apps/v1/namespaces/deployment-8613/replicasets/test-recreate-deployment-745fb9c84c,UID:c68874fb-d313-11e9-9321-0635e40003e4,ResourceVersion:86005,Generation:1,CreationTimestamp:2019-09-09 15:09:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment c5466074-d313-11e9-9321-0635e40003e4 0xc0025f2727 0xc0025f2728}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  9 15:09:10.082: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Sep  9 15:09:10.082: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-6566d46b4b,GenerateName:,Namespace:deployment-8613,SelfLink:/apis/apps/v1/namespaces/deployment-8613/replicasets/test-recreate-deployment-6566d46b4b,UID:c5484764-d313-11e9-9321-0635e40003e4,ResourceVersion:85994,Generation:2,CreationTimestamp:2019-09-09 15:09:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6566d46b4b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment c5466074-d313-11e9-9321-0635e40003e4 0xc0025f2417 0xc0025f2418}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6566d46b4b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6566d46b4b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  9 15:09:10.085: INFO: Pod "test-recreate-deployment-745fb9c84c-4lfh7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-745fb9c84c-4lfh7,GenerateName:test-recreate-deployment-745fb9c84c-,Namespace:deployment-8613,SelfLink:/api/v1/namespaces/deployment-8613/pods/test-recreate-deployment-745fb9c84c-4lfh7,UID:c68acc9b-d313-11e9-9321-0635e40003e4,ResourceVersion:86004,Generation:0,CreationTimestamp:2019-09-09 15:09:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-745fb9c84c c68874fb-d313-11e9-9321-0635e40003e4 0xc002488c17 0xc002488c18}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-mwbkj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mwbkj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mwbkj true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:185.19.31.168,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002488da0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002488dc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 15:09:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 15:09:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 15:09:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 15:09:10 +0000 UTC  }],Message:,Reason:,HostIP:185.19.31.168,PodIP:,StartTime:2019-09-09 15:09:10 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:09:10.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8613" for this suite.
Sep  9 15:09:16.105: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:09:16.192: INFO: namespace deployment-8613 deletion completed in 6.104767852s

• [SLOW TEST:8.451 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:09:16.192: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2896
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Sep  9 15:09:16.356: INFO: namespace kubectl-2896
Sep  9 15:09:16.357: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 create -f - --namespace=kubectl-2896'
Sep  9 15:09:16.575: INFO: stderr: ""
Sep  9 15:09:16.575: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Sep  9 15:09:17.578: INFO: Selector matched 1 pods for map[app:redis]
Sep  9 15:09:17.578: INFO: Found 0 / 1
Sep  9 15:09:18.579: INFO: Selector matched 1 pods for map[app:redis]
Sep  9 15:09:18.579: INFO: Found 0 / 1
Sep  9 15:09:19.580: INFO: Selector matched 1 pods for map[app:redis]
Sep  9 15:09:19.580: INFO: Found 1 / 1
Sep  9 15:09:19.580: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep  9 15:09:19.583: INFO: Selector matched 1 pods for map[app:redis]
Sep  9 15:09:19.583: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep  9 15:09:19.583: INFO: wait on redis-master startup in kubectl-2896 
Sep  9 15:09:19.583: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 logs redis-master-st5xz redis-master --namespace=kubectl-2896'
Sep  9 15:09:19.684: INFO: stderr: ""
Sep  9 15:09:19.684: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 09 Sep 15:09:17.771 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 09 Sep 15:09:17.771 # Server started, Redis version 3.2.12\n1:M 09 Sep 15:09:17.771 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 09 Sep 15:09:17.771 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Sep  9 15:09:19.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-2896'
Sep  9 15:09:19.794: INFO: stderr: ""
Sep  9 15:09:19.794: INFO: stdout: "service/rm2 exposed\n"
Sep  9 15:09:19.798: INFO: Service rm2 in namespace kubectl-2896 found.
STEP: exposing service
Sep  9 15:09:21.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-2896'
Sep  9 15:09:21.900: INFO: stderr: ""
Sep  9 15:09:21.900: INFO: stdout: "service/rm3 exposed\n"
Sep  9 15:09:21.903: INFO: Service rm3 in namespace kubectl-2896 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:09:23.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2896" for this suite.
Sep  9 15:09:45.931: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:09:46.006: INFO: namespace kubectl-2896 deletion completed in 22.094545896s

• [SLOW TEST:29.814 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create services for rc  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:09:46.007: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-4461
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Sep  9 15:09:46.205: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-4461,SelfLink:/api/v1/namespaces/watch-4461/configmaps/e2e-watch-test-label-changed,UID:dc14e83d-d313-11e9-9321-0635e40003e4,ResourceVersion:86177,Generation:0,CreationTimestamp:2019-09-09 15:09:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  9 15:09:46.205: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-4461,SelfLink:/api/v1/namespaces/watch-4461/configmaps/e2e-watch-test-label-changed,UID:dc14e83d-d313-11e9-9321-0635e40003e4,ResourceVersion:86178,Generation:0,CreationTimestamp:2019-09-09 15:09:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Sep  9 15:09:46.206: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-4461,SelfLink:/api/v1/namespaces/watch-4461/configmaps/e2e-watch-test-label-changed,UID:dc14e83d-d313-11e9-9321-0635e40003e4,ResourceVersion:86179,Generation:0,CreationTimestamp:2019-09-09 15:09:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Sep  9 15:09:56.260: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-4461,SelfLink:/api/v1/namespaces/watch-4461/configmaps/e2e-watch-test-label-changed,UID:dc14e83d-d313-11e9-9321-0635e40003e4,ResourceVersion:86208,Generation:0,CreationTimestamp:2019-09-09 15:09:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  9 15:09:56.260: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-4461,SelfLink:/api/v1/namespaces/watch-4461/configmaps/e2e-watch-test-label-changed,UID:dc14e83d-d313-11e9-9321-0635e40003e4,ResourceVersion:86209,Generation:0,CreationTimestamp:2019-09-09 15:09:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Sep  9 15:09:56.260: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-4461,SelfLink:/api/v1/namespaces/watch-4461/configmaps/e2e-watch-test-label-changed,UID:dc14e83d-d313-11e9-9321-0635e40003e4,ResourceVersion:86210,Generation:0,CreationTimestamp:2019-09-09 15:09:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:09:56.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4461" for this suite.
Sep  9 15:10:02.288: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:10:02.370: INFO: namespace watch-4461 deletion completed in 6.106018561s

• [SLOW TEST:16.363 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:10:02.370: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-5651
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0909 15:10:12.568714      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  9 15:10:12.568: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:10:12.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5651" for this suite.
Sep  9 15:10:18.587: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:10:18.676: INFO: namespace gc-5651 deletion completed in 6.10433746s

• [SLOW TEST:16.306 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:10:18.676: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-2668
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:10:21.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2668" for this suite.
Sep  9 15:10:43.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:10:43.987: INFO: namespace replication-controller-2668 deletion completed in 22.100764827s

• [SLOW TEST:25.311 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:10:43.987: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2420
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  9 15:10:44.172: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fea4ab2f-d313-11e9-b473-6e32a6bc259a" in namespace "downward-api-2420" to be "success or failure"
Sep  9 15:10:44.174: INFO: Pod "downwardapi-volume-fea4ab2f-d313-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.252439ms
Sep  9 15:10:46.178: INFO: Pod "downwardapi-volume-fea4ab2f-d313-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00631813s
STEP: Saw pod success
Sep  9 15:10:46.178: INFO: Pod "downwardapi-volume-fea4ab2f-d313-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 15:10:46.181: INFO: Trying to get logs from node 185.19.31.168 pod downwardapi-volume-fea4ab2f-d313-11e9-b473-6e32a6bc259a container client-container: <nil>
STEP: delete the pod
Sep  9 15:10:46.216: INFO: Waiting for pod downwardapi-volume-fea4ab2f-d313-11e9-b473-6e32a6bc259a to disappear
Sep  9 15:10:46.219: INFO: Pod downwardapi-volume-fea4ab2f-d313-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:10:46.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2420" for this suite.
Sep  9 15:10:52.238: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:10:52.321: INFO: namespace downward-api-2420 deletion completed in 6.099286599s

• [SLOW TEST:8.334 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:10:52.321: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8834
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Sep  9 15:10:52.504: INFO: Waiting up to 5m0s for pod "downward-api-039c4c66-d314-11e9-b473-6e32a6bc259a" in namespace "downward-api-8834" to be "success or failure"
Sep  9 15:10:52.510: INFO: Pod "downward-api-039c4c66-d314-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.27609ms
Sep  9 15:10:54.514: INFO: Pod "downward-api-039c4c66-d314-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009908064s
STEP: Saw pod success
Sep  9 15:10:54.514: INFO: Pod "downward-api-039c4c66-d314-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 15:10:54.518: INFO: Trying to get logs from node 185.19.31.168 pod downward-api-039c4c66-d314-11e9-b473-6e32a6bc259a container dapi-container: <nil>
STEP: delete the pod
Sep  9 15:10:54.539: INFO: Waiting for pod downward-api-039c4c66-d314-11e9-b473-6e32a6bc259a to disappear
Sep  9 15:10:54.541: INFO: Pod downward-api-039c4c66-d314-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:10:54.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8834" for this suite.
Sep  9 15:11:00.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:11:00.633: INFO: namespace downward-api-8834 deletion completed in 6.088758916s

• [SLOW TEST:8.312 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:11:00.633: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9981
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-088f55ba-d314-11e9-b473-6e32a6bc259a
STEP: Creating a pod to test consume configMaps
Sep  9 15:11:00.814: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0890b93a-d314-11e9-b473-6e32a6bc259a" in namespace "projected-9981" to be "success or failure"
Sep  9 15:11:00.823: INFO: Pod "pod-projected-configmaps-0890b93a-d314-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.705651ms
Sep  9 15:11:02.827: INFO: Pod "pod-projected-configmaps-0890b93a-d314-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012823773s
STEP: Saw pod success
Sep  9 15:11:02.827: INFO: Pod "pod-projected-configmaps-0890b93a-d314-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 15:11:02.831: INFO: Trying to get logs from node 185.19.31.168 pod pod-projected-configmaps-0890b93a-d314-11e9-b473-6e32a6bc259a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  9 15:11:02.859: INFO: Waiting for pod pod-projected-configmaps-0890b93a-d314-11e9-b473-6e32a6bc259a to disappear
Sep  9 15:11:02.867: INFO: Pod pod-projected-configmaps-0890b93a-d314-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:11:02.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9981" for this suite.
Sep  9 15:11:08.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:11:08.965: INFO: namespace projected-9981 deletion completed in 6.09577335s

• [SLOW TEST:8.333 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:11:08.966: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5299
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  9 15:11:09.140: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0d86e318-d314-11e9-b473-6e32a6bc259a" in namespace "projected-5299" to be "success or failure"
Sep  9 15:11:09.142: INFO: Pod "downwardapi-volume-0d86e318-d314-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.392446ms
Sep  9 15:11:11.146: INFO: Pod "downwardapi-volume-0d86e318-d314-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00563386s
STEP: Saw pod success
Sep  9 15:11:11.146: INFO: Pod "downwardapi-volume-0d86e318-d314-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 15:11:11.149: INFO: Trying to get logs from node 185.19.31.168 pod downwardapi-volume-0d86e318-d314-11e9-b473-6e32a6bc259a container client-container: <nil>
STEP: delete the pod
Sep  9 15:11:11.169: INFO: Waiting for pod downwardapi-volume-0d86e318-d314-11e9-b473-6e32a6bc259a to disappear
Sep  9 15:11:11.173: INFO: Pod downwardapi-volume-0d86e318-d314-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:11:11.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5299" for this suite.
Sep  9 15:11:17.191: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:11:17.276: INFO: namespace projected-5299 deletion completed in 6.100907894s

• [SLOW TEST:8.311 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:11:17.276: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3861
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-127abdae-d314-11e9-b473-6e32a6bc259a
STEP: Creating a pod to test consume secrets
Sep  9 15:11:17.461: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-127c88bd-d314-11e9-b473-6e32a6bc259a" in namespace "projected-3861" to be "success or failure"
Sep  9 15:11:17.466: INFO: Pod "pod-projected-secrets-127c88bd-d314-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.766246ms
Sep  9 15:11:19.470: INFO: Pod "pod-projected-secrets-127c88bd-d314-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008734873s
STEP: Saw pod success
Sep  9 15:11:19.470: INFO: Pod "pod-projected-secrets-127c88bd-d314-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 15:11:19.472: INFO: Trying to get logs from node 185.19.31.168 pod pod-projected-secrets-127c88bd-d314-11e9-b473-6e32a6bc259a container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep  9 15:11:19.498: INFO: Waiting for pod pod-projected-secrets-127c88bd-d314-11e9-b473-6e32a6bc259a to disappear
Sep  9 15:11:19.504: INFO: Pod pod-projected-secrets-127c88bd-d314-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:11:19.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3861" for this suite.
Sep  9 15:11:25.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:11:25.614: INFO: namespace projected-3861 deletion completed in 6.102390705s

• [SLOW TEST:8.338 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:11:25.614: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1228
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-17749df4-d314-11e9-b473-6e32a6bc259a
STEP: Creating configMap with name cm-test-opt-upd-17749e48-d314-11e9-b473-6e32a6bc259a
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-17749df4-d314-11e9-b473-6e32a6bc259a
STEP: Updating configmap cm-test-opt-upd-17749e48-d314-11e9-b473-6e32a6bc259a
STEP: Creating configMap with name cm-test-opt-create-17749e6f-d314-11e9-b473-6e32a6bc259a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:11:29.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1228" for this suite.
Sep  9 15:11:51.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:11:52.017: INFO: namespace projected-1228 deletion completed in 22.093209888s

• [SLOW TEST:26.403 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:11:52.018: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5536
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  9 15:11:52.190: INFO: Waiting up to 5m0s for pod "downwardapi-volume-272fac42-d314-11e9-b473-6e32a6bc259a" in namespace "downward-api-5536" to be "success or failure"
Sep  9 15:11:52.195: INFO: Pod "downwardapi-volume-272fac42-d314-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.271299ms
Sep  9 15:11:54.200: INFO: Pod "downwardapi-volume-272fac42-d314-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009113392s
STEP: Saw pod success
Sep  9 15:11:54.200: INFO: Pod "downwardapi-volume-272fac42-d314-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 15:11:54.203: INFO: Trying to get logs from node 185.19.31.168 pod downwardapi-volume-272fac42-d314-11e9-b473-6e32a6bc259a container client-container: <nil>
STEP: delete the pod
Sep  9 15:11:54.237: INFO: Waiting for pod downwardapi-volume-272fac42-d314-11e9-b473-6e32a6bc259a to disappear
Sep  9 15:11:54.240: INFO: Pod downwardapi-volume-272fac42-d314-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:11:54.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5536" for this suite.
Sep  9 15:12:00.260: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:12:00.339: INFO: namespace downward-api-5536 deletion completed in 6.096741941s

• [SLOW TEST:8.321 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:12:00.339: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8979
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: executing a command with run --rm and attach with stdin
Sep  9 15:12:00.498: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 --namespace=kubectl-8979 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Sep  9 15:12:02.575: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Sep  9 15:12:02.575: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:12:04.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8979" for this suite.
Sep  9 15:12:10.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:12:10.711: INFO: namespace kubectl-8979 deletion completed in 6.115764156s

• [SLOW TEST:10.372 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:12:10.711: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-361
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  9 15:12:10.871: INFO: Creating ReplicaSet my-hostname-basic-32548a91-d314-11e9-b473-6e32a6bc259a
Sep  9 15:12:10.887: INFO: Pod name my-hostname-basic-32548a91-d314-11e9-b473-6e32a6bc259a: Found 0 pods out of 1
Sep  9 15:12:15.892: INFO: Pod name my-hostname-basic-32548a91-d314-11e9-b473-6e32a6bc259a: Found 1 pods out of 1
Sep  9 15:12:15.892: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-32548a91-d314-11e9-b473-6e32a6bc259a" is running
Sep  9 15:12:15.896: INFO: Pod "my-hostname-basic-32548a91-d314-11e9-b473-6e32a6bc259a-mxq5q" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-09 15:12:10 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-09 15:12:12 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-09 15:12:12 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-09 15:12:10 +0000 UTC Reason: Message:}])
Sep  9 15:12:15.896: INFO: Trying to dial the pod
Sep  9 15:12:20.908: INFO: Controller my-hostname-basic-32548a91-d314-11e9-b473-6e32a6bc259a: Got expected result from replica 1 [my-hostname-basic-32548a91-d314-11e9-b473-6e32a6bc259a-mxq5q]: "my-hostname-basic-32548a91-d314-11e9-b473-6e32a6bc259a-mxq5q", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:12:20.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-361" for this suite.
Sep  9 15:12:26.929: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:12:27.027: INFO: namespace replicaset-361 deletion completed in 6.115589409s

• [SLOW TEST:16.316 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:12:27.027: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-7068
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  9 15:12:27.218: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Sep  9 15:12:27.236: INFO: Number of nodes with available pods: 0
Sep  9 15:12:27.236: INFO: Node 185.19.31.168 is running more than one daemon pod
Sep  9 15:12:28.248: INFO: Number of nodes with available pods: 0
Sep  9 15:12:28.248: INFO: Node 185.19.31.168 is running more than one daemon pod
Sep  9 15:12:29.246: INFO: Number of nodes with available pods: 2
Sep  9 15:12:29.246: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Sep  9 15:12:29.272: INFO: Wrong image for pod: daemon-set-4ncgm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 15:12:29.272: INFO: Wrong image for pod: daemon-set-rcmsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 15:12:30.279: INFO: Wrong image for pod: daemon-set-4ncgm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 15:12:30.279: INFO: Wrong image for pod: daemon-set-rcmsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 15:12:31.281: INFO: Wrong image for pod: daemon-set-4ncgm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 15:12:31.281: INFO: Wrong image for pod: daemon-set-rcmsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 15:12:32.279: INFO: Wrong image for pod: daemon-set-4ncgm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 15:12:32.279: INFO: Wrong image for pod: daemon-set-rcmsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 15:12:32.279: INFO: Pod daemon-set-rcmsh is not available
Sep  9 15:12:33.280: INFO: Wrong image for pod: daemon-set-4ncgm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 15:12:33.280: INFO: Wrong image for pod: daemon-set-rcmsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 15:12:33.280: INFO: Pod daemon-set-rcmsh is not available
Sep  9 15:12:34.279: INFO: Wrong image for pod: daemon-set-4ncgm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 15:12:34.279: INFO: Wrong image for pod: daemon-set-rcmsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 15:12:34.279: INFO: Pod daemon-set-rcmsh is not available
Sep  9 15:12:35.279: INFO: Wrong image for pod: daemon-set-4ncgm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 15:12:35.279: INFO: Wrong image for pod: daemon-set-rcmsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 15:12:35.279: INFO: Pod daemon-set-rcmsh is not available
Sep  9 15:12:36.279: INFO: Wrong image for pod: daemon-set-4ncgm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 15:12:36.279: INFO: Wrong image for pod: daemon-set-rcmsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 15:12:36.279: INFO: Pod daemon-set-rcmsh is not available
Sep  9 15:12:37.279: INFO: Wrong image for pod: daemon-set-4ncgm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 15:12:37.280: INFO: Wrong image for pod: daemon-set-rcmsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 15:12:37.280: INFO: Pod daemon-set-rcmsh is not available
Sep  9 15:12:38.279: INFO: Wrong image for pod: daemon-set-4ncgm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 15:12:38.279: INFO: Wrong image for pod: daemon-set-rcmsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 15:12:38.280: INFO: Pod daemon-set-rcmsh is not available
Sep  9 15:12:39.279: INFO: Wrong image for pod: daemon-set-4ncgm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 15:12:39.279: INFO: Wrong image for pod: daemon-set-rcmsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 15:12:39.279: INFO: Pod daemon-set-rcmsh is not available
Sep  9 15:12:40.279: INFO: Wrong image for pod: daemon-set-4ncgm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 15:12:40.279: INFO: Pod daemon-set-v4bft is not available
Sep  9 15:12:41.279: INFO: Wrong image for pod: daemon-set-4ncgm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 15:12:42.278: INFO: Wrong image for pod: daemon-set-4ncgm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 15:12:43.280: INFO: Wrong image for pod: daemon-set-4ncgm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 15:12:43.280: INFO: Pod daemon-set-4ncgm is not available
Sep  9 15:12:44.278: INFO: Wrong image for pod: daemon-set-4ncgm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 15:12:44.278: INFO: Pod daemon-set-4ncgm is not available
Sep  9 15:12:45.283: INFO: Wrong image for pod: daemon-set-4ncgm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 15:12:45.283: INFO: Pod daemon-set-4ncgm is not available
Sep  9 15:12:46.280: INFO: Wrong image for pod: daemon-set-4ncgm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 15:12:46.280: INFO: Pod daemon-set-4ncgm is not available
Sep  9 15:12:47.279: INFO: Wrong image for pod: daemon-set-4ncgm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 15:12:47.279: INFO: Pod daemon-set-4ncgm is not available
Sep  9 15:12:48.281: INFO: Wrong image for pod: daemon-set-4ncgm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 15:12:48.281: INFO: Pod daemon-set-4ncgm is not available
Sep  9 15:12:49.279: INFO: Wrong image for pod: daemon-set-4ncgm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 15:12:49.279: INFO: Pod daemon-set-4ncgm is not available
Sep  9 15:12:50.280: INFO: Wrong image for pod: daemon-set-4ncgm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 15:12:50.280: INFO: Pod daemon-set-4ncgm is not available
Sep  9 15:12:51.279: INFO: Wrong image for pod: daemon-set-4ncgm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 15:12:51.279: INFO: Pod daemon-set-4ncgm is not available
Sep  9 15:12:52.280: INFO: Wrong image for pod: daemon-set-4ncgm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 15:12:52.280: INFO: Pod daemon-set-4ncgm is not available
Sep  9 15:12:53.280: INFO: Wrong image for pod: daemon-set-4ncgm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 15:12:53.280: INFO: Pod daemon-set-4ncgm is not available
Sep  9 15:12:54.279: INFO: Pod daemon-set-2bp7b is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Sep  9 15:12:54.289: INFO: Number of nodes with available pods: 1
Sep  9 15:12:54.289: INFO: Node 185.19.31.68 is running more than one daemon pod
Sep  9 15:12:55.296: INFO: Number of nodes with available pods: 1
Sep  9 15:12:55.296: INFO: Node 185.19.31.68 is running more than one daemon pod
Sep  9 15:12:56.298: INFO: Number of nodes with available pods: 1
Sep  9 15:12:56.298: INFO: Node 185.19.31.68 is running more than one daemon pod
Sep  9 15:12:57.298: INFO: Number of nodes with available pods: 1
Sep  9 15:12:57.298: INFO: Node 185.19.31.68 is running more than one daemon pod
Sep  9 15:12:58.298: INFO: Number of nodes with available pods: 2
Sep  9 15:12:58.298: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7068, will wait for the garbage collector to delete the pods
Sep  9 15:12:58.381: INFO: Deleting DaemonSet.extensions daemon-set took: 12.936876ms
Sep  9 15:12:58.882: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.250554ms
Sep  9 15:13:03.886: INFO: Number of nodes with available pods: 0
Sep  9 15:13:03.886: INFO: Number of running nodes: 0, number of available pods: 0
Sep  9 15:13:03.889: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7068/daemonsets","resourceVersion":"87147"},"items":null}

Sep  9 15:13:03.893: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7068/pods","resourceVersion":"87147"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:13:03.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7068" for this suite.
Sep  9 15:13:09.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:13:10.002: INFO: namespace daemonsets-7068 deletion completed in 6.100466482s

• [SLOW TEST:42.976 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:13:10.003: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2680
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-55b0637e-d314-11e9-b473-6e32a6bc259a
STEP: Creating a pod to test consume secrets
Sep  9 15:13:10.222: INFO: Waiting up to 5m0s for pod "pod-secrets-55b2ccad-d314-11e9-b473-6e32a6bc259a" in namespace "secrets-2680" to be "success or failure"
Sep  9 15:13:10.227: INFO: Pod "pod-secrets-55b2ccad-d314-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.718049ms
Sep  9 15:13:12.233: INFO: Pod "pod-secrets-55b2ccad-d314-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010224727s
STEP: Saw pod success
Sep  9 15:13:12.233: INFO: Pod "pod-secrets-55b2ccad-d314-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 15:13:12.237: INFO: Trying to get logs from node 185.19.31.168 pod pod-secrets-55b2ccad-d314-11e9-b473-6e32a6bc259a container secret-volume-test: <nil>
STEP: delete the pod
Sep  9 15:13:12.261: INFO: Waiting for pod pod-secrets-55b2ccad-d314-11e9-b473-6e32a6bc259a to disappear
Sep  9 15:13:12.264: INFO: Pod pod-secrets-55b2ccad-d314-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:13:12.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2680" for this suite.
Sep  9 15:13:18.288: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:13:18.372: INFO: namespace secrets-2680 deletion completed in 6.100552494s

• [SLOW TEST:8.369 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:13:18.372: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3608
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  9 15:13:20.593: INFO: Waiting up to 5m0s for pod "client-envvars-5be0cc58-d314-11e9-b473-6e32a6bc259a" in namespace "pods-3608" to be "success or failure"
Sep  9 15:13:20.596: INFO: Pod "client-envvars-5be0cc58-d314-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.617372ms
Sep  9 15:13:22.603: INFO: Pod "client-envvars-5be0cc58-d314-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009611696s
STEP: Saw pod success
Sep  9 15:13:22.603: INFO: Pod "client-envvars-5be0cc58-d314-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 15:13:22.605: INFO: Trying to get logs from node 185.19.31.168 pod client-envvars-5be0cc58-d314-11e9-b473-6e32a6bc259a container env3cont: <nil>
STEP: delete the pod
Sep  9 15:13:22.688: INFO: Waiting for pod client-envvars-5be0cc58-d314-11e9-b473-6e32a6bc259a to disappear
Sep  9 15:13:22.698: INFO: Pod client-envvars-5be0cc58-d314-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:13:22.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3608" for this suite.
Sep  9 15:14:10.717: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:14:10.799: INFO: namespace pods-3608 deletion completed in 48.097376848s

• [SLOW TEST:52.427 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:14:10.799: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-6826
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6826.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6826.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6826.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6826.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6826.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6826.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6826.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-6826.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6826.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-6826.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6826.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 98.181.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.181.98_udp@PTR;check="$$(dig +tcp +noall +answer +search 98.181.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.181.98_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6826.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6826.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6826.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6826.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6826.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6826.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6826.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-6826.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6826.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-6826.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6826.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 98.181.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.181.98_udp@PTR;check="$$(dig +tcp +noall +answer +search 98.181.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.181.98_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep  9 15:14:13.024: INFO: Unable to read wheezy_udp@dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:13.027: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:13.029: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:13.032: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:13.047: INFO: Unable to read jessie_udp@dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:13.049: INFO: Unable to read jessie_tcp@dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:13.051: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:13.053: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:13.066: INFO: Lookups using dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a failed for: [wheezy_udp@dns-test-service.dns-6826.svc.cluster.local wheezy_tcp@dns-test-service.dns-6826.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local jessie_udp@dns-test-service.dns-6826.svc.cluster.local jessie_tcp@dns-test-service.dns-6826.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local]

Sep  9 15:14:18.074: INFO: Unable to read wheezy_udp@dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:18.078: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:18.083: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:18.087: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:18.106: INFO: Unable to read jessie_udp@dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:18.109: INFO: Unable to read jessie_tcp@dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:18.111: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:18.114: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:18.131: INFO: Lookups using dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a failed for: [wheezy_udp@dns-test-service.dns-6826.svc.cluster.local wheezy_tcp@dns-test-service.dns-6826.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local jessie_udp@dns-test-service.dns-6826.svc.cluster.local jessie_tcp@dns-test-service.dns-6826.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local]

Sep  9 15:14:23.071: INFO: Unable to read wheezy_udp@dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:23.075: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:23.077: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:23.080: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:23.094: INFO: Unable to read jessie_udp@dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:23.096: INFO: Unable to read jessie_tcp@dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:23.098: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:23.100: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:23.113: INFO: Lookups using dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a failed for: [wheezy_udp@dns-test-service.dns-6826.svc.cluster.local wheezy_tcp@dns-test-service.dns-6826.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local jessie_udp@dns-test-service.dns-6826.svc.cluster.local jessie_tcp@dns-test-service.dns-6826.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local]

Sep  9 15:14:28.074: INFO: Unable to read wheezy_udp@dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:28.078: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:28.080: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:28.082: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:28.095: INFO: Unable to read jessie_udp@dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:28.097: INFO: Unable to read jessie_tcp@dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:28.099: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:28.101: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:28.112: INFO: Lookups using dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a failed for: [wheezy_udp@dns-test-service.dns-6826.svc.cluster.local wheezy_tcp@dns-test-service.dns-6826.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local jessie_udp@dns-test-service.dns-6826.svc.cluster.local jessie_tcp@dns-test-service.dns-6826.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local]

Sep  9 15:14:33.072: INFO: Unable to read wheezy_udp@dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:33.075: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:33.077: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:33.079: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:33.094: INFO: Unable to read jessie_udp@dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:33.096: INFO: Unable to read jessie_tcp@dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:33.098: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:33.100: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:33.112: INFO: Lookups using dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a failed for: [wheezy_udp@dns-test-service.dns-6826.svc.cluster.local wheezy_tcp@dns-test-service.dns-6826.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local jessie_udp@dns-test-service.dns-6826.svc.cluster.local jessie_tcp@dns-test-service.dns-6826.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local]

Sep  9 15:14:38.071: INFO: Unable to read wheezy_udp@dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:38.074: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:38.077: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:38.080: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:38.095: INFO: Unable to read jessie_udp@dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:38.098: INFO: Unable to read jessie_tcp@dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:38.100: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:38.103: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:38.120: INFO: Lookups using dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a failed for: [wheezy_udp@dns-test-service.dns-6826.svc.cluster.local wheezy_tcp@dns-test-service.dns-6826.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local jessie_udp@dns-test-service.dns-6826.svc.cluster.local jessie_tcp@dns-test-service.dns-6826.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local]

Sep  9 15:14:43.102: INFO: Unable to read jessie_udp@dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:43.104: INFO: Unable to read jessie_tcp@dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:43.106: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:43.109: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local from pod dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a: the server could not find the requested resource (get pods dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a)
Sep  9 15:14:43.123: INFO: Lookups using dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a failed for: [jessie_udp@dns-test-service.dns-6826.svc.cluster.local jessie_tcp@dns-test-service.dns-6826.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-6826.svc.cluster.local]

Sep  9 15:14:48.118: INFO: DNS probes using dns-6826/dns-test-79ecb45f-d314-11e9-b473-6e32a6bc259a succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:14:48.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6826" for this suite.
Sep  9 15:14:54.238: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:14:54.328: INFO: namespace dns-6826 deletion completed in 6.107537411s

• [SLOW TEST:43.529 seconds]
[sig-network] DNS
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:14:54.328: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-585
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-secret-mwzr
STEP: Creating a pod to test atomic-volume-subpath
Sep  9 15:14:54.524: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-mwzr" in namespace "subpath-585" to be "success or failure"
Sep  9 15:14:54.531: INFO: Pod "pod-subpath-test-secret-mwzr": Phase="Pending", Reason="", readiness=false. Elapsed: 6.843344ms
Sep  9 15:14:56.537: INFO: Pod "pod-subpath-test-secret-mwzr": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012155544s
Sep  9 15:14:58.541: INFO: Pod "pod-subpath-test-secret-mwzr": Phase="Running", Reason="", readiness=true. Elapsed: 4.016713006s
Sep  9 15:15:00.546: INFO: Pod "pod-subpath-test-secret-mwzr": Phase="Running", Reason="", readiness=true. Elapsed: 6.021254003s
Sep  9 15:15:02.549: INFO: Pod "pod-subpath-test-secret-mwzr": Phase="Running", Reason="", readiness=true. Elapsed: 8.024334512s
Sep  9 15:15:04.554: INFO: Pod "pod-subpath-test-secret-mwzr": Phase="Running", Reason="", readiness=true. Elapsed: 10.029869206s
Sep  9 15:15:06.563: INFO: Pod "pod-subpath-test-secret-mwzr": Phase="Running", Reason="", readiness=true. Elapsed: 12.038595212s
Sep  9 15:15:08.567: INFO: Pod "pod-subpath-test-secret-mwzr": Phase="Running", Reason="", readiness=true. Elapsed: 14.042537424s
Sep  9 15:15:10.572: INFO: Pod "pod-subpath-test-secret-mwzr": Phase="Running", Reason="", readiness=true. Elapsed: 16.04710067s
Sep  9 15:15:12.578: INFO: Pod "pod-subpath-test-secret-mwzr": Phase="Running", Reason="", readiness=true. Elapsed: 18.05316505s
Sep  9 15:15:14.582: INFO: Pod "pod-subpath-test-secret-mwzr": Phase="Running", Reason="", readiness=true. Elapsed: 20.057642057s
Sep  9 15:15:16.587: INFO: Pod "pod-subpath-test-secret-mwzr": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.062449906s
STEP: Saw pod success
Sep  9 15:15:16.587: INFO: Pod "pod-subpath-test-secret-mwzr" satisfied condition "success or failure"
Sep  9 15:15:16.591: INFO: Trying to get logs from node 185.19.31.168 pod pod-subpath-test-secret-mwzr container test-container-subpath-secret-mwzr: <nil>
STEP: delete the pod
Sep  9 15:15:16.616: INFO: Waiting for pod pod-subpath-test-secret-mwzr to disappear
Sep  9 15:15:16.622: INFO: Pod pod-subpath-test-secret-mwzr no longer exists
STEP: Deleting pod pod-subpath-test-secret-mwzr
Sep  9 15:15:16.623: INFO: Deleting pod "pod-subpath-test-secret-mwzr" in namespace "subpath-585"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:15:16.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-585" for this suite.
Sep  9 15:15:22.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:15:22.770: INFO: namespace subpath-585 deletion completed in 6.129107928s

• [SLOW TEST:28.442 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:15:22.770: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1259
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Sep  9 15:15:22.942: INFO: Waiting up to 5m0s for pod "pod-a4ce5683-d314-11e9-b473-6e32a6bc259a" in namespace "emptydir-1259" to be "success or failure"
Sep  9 15:15:22.946: INFO: Pod "pod-a4ce5683-d314-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.763986ms
Sep  9 15:15:24.951: INFO: Pod "pod-a4ce5683-d314-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008207733s
Sep  9 15:15:26.955: INFO: Pod "pod-a4ce5683-d314-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01284976s
STEP: Saw pod success
Sep  9 15:15:26.955: INFO: Pod "pod-a4ce5683-d314-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 15:15:26.958: INFO: Trying to get logs from node 185.19.31.168 pod pod-a4ce5683-d314-11e9-b473-6e32a6bc259a container test-container: <nil>
STEP: delete the pod
Sep  9 15:15:26.980: INFO: Waiting for pod pod-a4ce5683-d314-11e9-b473-6e32a6bc259a to disappear
Sep  9 15:15:26.984: INFO: Pod pod-a4ce5683-d314-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:15:26.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1259" for this suite.
Sep  9 15:15:33.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:15:33.084: INFO: namespace emptydir-1259 deletion completed in 6.096576695s

• [SLOW TEST:10.315 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:15:33.085: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2885
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  9 15:15:33.258: INFO: Waiting up to 5m0s for pod "downwardapi-volume-aaf44174-d314-11e9-b473-6e32a6bc259a" in namespace "projected-2885" to be "success or failure"
Sep  9 15:15:33.261: INFO: Pod "downwardapi-volume-aaf44174-d314-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.343923ms
Sep  9 15:15:35.265: INFO: Pod "downwardapi-volume-aaf44174-d314-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006841213s
Sep  9 15:15:37.270: INFO: Pod "downwardapi-volume-aaf44174-d314-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011333558s
STEP: Saw pod success
Sep  9 15:15:37.270: INFO: Pod "downwardapi-volume-aaf44174-d314-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 15:15:37.273: INFO: Trying to get logs from node 185.19.31.168 pod downwardapi-volume-aaf44174-d314-11e9-b473-6e32a6bc259a container client-container: <nil>
STEP: delete the pod
Sep  9 15:15:37.300: INFO: Waiting for pod downwardapi-volume-aaf44174-d314-11e9-b473-6e32a6bc259a to disappear
Sep  9 15:15:37.302: INFO: Pod downwardapi-volume-aaf44174-d314-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:15:37.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2885" for this suite.
Sep  9 15:15:43.323: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:15:43.436: INFO: namespace projected-2885 deletion completed in 6.128226374s

• [SLOW TEST:10.351 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:15:43.436: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-8940
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-7329
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-8245
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:16:07.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8940" for this suite.
Sep  9 15:16:13.996: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:16:14.082: INFO: namespace namespaces-8940 deletion completed in 6.104400514s
STEP: Destroying namespace "nsdeletetest-7329" for this suite.
Sep  9 15:16:14.085: INFO: Namespace nsdeletetest-7329 was already deleted
STEP: Destroying namespace "nsdeletetest-8245" for this suite.
Sep  9 15:16:20.101: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:16:20.186: INFO: namespace nsdeletetest-8245 deletion completed in 6.101692095s

• [SLOW TEST:36.750 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:16:20.187: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-7135
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-7884
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-4489
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:16:26.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-7135" for this suite.
Sep  9 15:16:32.740: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:16:32.821: INFO: namespace namespaces-7135 deletion completed in 6.096578495s
STEP: Destroying namespace "nsdeletetest-7884" for this suite.
Sep  9 15:16:32.824: INFO: Namespace nsdeletetest-7884 was already deleted
STEP: Destroying namespace "nsdeletetest-4489" for this suite.
Sep  9 15:16:38.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:16:38.926: INFO: namespace nsdeletetest-4489 deletion completed in 6.101969296s

• [SLOW TEST:18.739 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:16:38.926: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-480
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating cluster-info
Sep  9 15:16:39.093: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 cluster-info'
Sep  9 15:16:39.176: INFO: stderr: ""
Sep  9 15:16:39.176: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.43.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.43.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:16:39.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-480" for this suite.
Sep  9 15:16:45.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:16:45.296: INFO: namespace kubectl-480 deletion completed in 6.116843131s

• [SLOW TEST:6.370 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:16:45.297: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6715
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  9 15:16:45.495: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d600fe56-d314-11e9-b473-6e32a6bc259a" in namespace "projected-6715" to be "success or failure"
Sep  9 15:16:45.498: INFO: Pod "downwardapi-volume-d600fe56-d314-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.568758ms
Sep  9 15:16:47.502: INFO: Pod "downwardapi-volume-d600fe56-d314-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006905943s
STEP: Saw pod success
Sep  9 15:16:47.502: INFO: Pod "downwardapi-volume-d600fe56-d314-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 15:16:47.505: INFO: Trying to get logs from node 185.19.31.168 pod downwardapi-volume-d600fe56-d314-11e9-b473-6e32a6bc259a container client-container: <nil>
STEP: delete the pod
Sep  9 15:16:47.540: INFO: Waiting for pod downwardapi-volume-d600fe56-d314-11e9-b473-6e32a6bc259a to disappear
Sep  9 15:16:47.542: INFO: Pod downwardapi-volume-d600fe56-d314-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:16:47.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6715" for this suite.
Sep  9 15:16:53.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:16:53.641: INFO: namespace projected-6715 deletion completed in 6.096723842s

• [SLOW TEST:8.345 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:16:53.641: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-5777
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-projected-4wk5
STEP: Creating a pod to test atomic-volume-subpath
Sep  9 15:16:53.843: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-4wk5" in namespace "subpath-5777" to be "success or failure"
Sep  9 15:16:53.847: INFO: Pod "pod-subpath-test-projected-4wk5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.55332ms
Sep  9 15:16:55.851: INFO: Pod "pod-subpath-test-projected-4wk5": Phase="Running", Reason="", readiness=true. Elapsed: 2.008853411s
Sep  9 15:16:57.857: INFO: Pod "pod-subpath-test-projected-4wk5": Phase="Running", Reason="", readiness=true. Elapsed: 4.014059819s
Sep  9 15:16:59.861: INFO: Pod "pod-subpath-test-projected-4wk5": Phase="Running", Reason="", readiness=true. Elapsed: 6.018794273s
Sep  9 15:17:01.866: INFO: Pod "pod-subpath-test-projected-4wk5": Phase="Running", Reason="", readiness=true. Elapsed: 8.023391923s
Sep  9 15:17:03.870: INFO: Pod "pod-subpath-test-projected-4wk5": Phase="Running", Reason="", readiness=true. Elapsed: 10.027089747s
Sep  9 15:17:05.874: INFO: Pod "pod-subpath-test-projected-4wk5": Phase="Running", Reason="", readiness=true. Elapsed: 12.031694278s
Sep  9 15:17:07.880: INFO: Pod "pod-subpath-test-projected-4wk5": Phase="Running", Reason="", readiness=true. Elapsed: 14.037195051s
Sep  9 15:17:09.885: INFO: Pod "pod-subpath-test-projected-4wk5": Phase="Running", Reason="", readiness=true. Elapsed: 16.042049708s
Sep  9 15:17:11.890: INFO: Pod "pod-subpath-test-projected-4wk5": Phase="Running", Reason="", readiness=true. Elapsed: 18.047264579s
Sep  9 15:17:13.895: INFO: Pod "pod-subpath-test-projected-4wk5": Phase="Running", Reason="", readiness=true. Elapsed: 20.052008732s
Sep  9 15:17:15.898: INFO: Pod "pod-subpath-test-projected-4wk5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.055437267s
STEP: Saw pod success
Sep  9 15:17:15.898: INFO: Pod "pod-subpath-test-projected-4wk5" satisfied condition "success or failure"
Sep  9 15:17:15.901: INFO: Trying to get logs from node 185.19.31.168 pod pod-subpath-test-projected-4wk5 container test-container-subpath-projected-4wk5: <nil>
STEP: delete the pod
Sep  9 15:17:15.937: INFO: Waiting for pod pod-subpath-test-projected-4wk5 to disappear
Sep  9 15:17:15.947: INFO: Pod pod-subpath-test-projected-4wk5 no longer exists
STEP: Deleting pod pod-subpath-test-projected-4wk5
Sep  9 15:17:15.947: INFO: Deleting pod "pod-subpath-test-projected-4wk5" in namespace "subpath-5777"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:17:15.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5777" for this suite.
Sep  9 15:17:21.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:17:22.056: INFO: namespace subpath-5777 deletion completed in 6.096722496s

• [SLOW TEST:28.415 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:17:22.056: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-635
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:69
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Registering the sample API server.
Sep  9 15:17:22.505: INFO: new replicaset for deployment "sample-apiserver-deployment" is yet to be created
Sep  9 15:17:24.561: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703639042, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703639042, loc:(*time.Location)(0x8825120)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703639042, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703639042, loc:(*time.Location)(0x8825120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  9 15:17:26.565: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703639042, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703639042, loc:(*time.Location)(0x8825120)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703639042, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703639042, loc:(*time.Location)(0x8825120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  9 15:17:28.566: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703639042, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703639042, loc:(*time.Location)(0x8825120)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703639042, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703639042, loc:(*time.Location)(0x8825120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  9 15:17:30.565: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703639042, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703639042, loc:(*time.Location)(0x8825120)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703639042, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703639042, loc:(*time.Location)(0x8825120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  9 15:17:32.565: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703639042, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703639042, loc:(*time.Location)(0x8825120)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703639042, loc:(*time.Location)(0x8825120)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703639042, loc:(*time.Location)(0x8825120)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  9 15:17:35.400: INFO: Waited 823.844504ms for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:60
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:17:36.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-635" for this suite.
Sep  9 15:17:42.203: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:17:42.291: INFO: namespace aggregator-635 deletion completed in 6.192644719s

• [SLOW TEST:20.235 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:17:42.291: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3345
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-f7f91358-d314-11e9-b473-6e32a6bc259a
STEP: Creating a pod to test consume secrets
Sep  9 15:17:42.611: INFO: Waiting up to 5m0s for pod "pod-secrets-f7fa5b94-d314-11e9-b473-6e32a6bc259a" in namespace "secrets-3345" to be "success or failure"
Sep  9 15:17:42.618: INFO: Pod "pod-secrets-f7fa5b94-d314-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.309187ms
Sep  9 15:17:44.623: INFO: Pod "pod-secrets-f7fa5b94-d314-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012175169s
Sep  9 15:17:46.630: INFO: Pod "pod-secrets-f7fa5b94-d314-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01829818s
STEP: Saw pod success
Sep  9 15:17:46.630: INFO: Pod "pod-secrets-f7fa5b94-d314-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 15:17:46.633: INFO: Trying to get logs from node 185.19.31.168 pod pod-secrets-f7fa5b94-d314-11e9-b473-6e32a6bc259a container secret-volume-test: <nil>
STEP: delete the pod
Sep  9 15:17:46.665: INFO: Waiting for pod pod-secrets-f7fa5b94-d314-11e9-b473-6e32a6bc259a to disappear
Sep  9 15:17:46.667: INFO: Pod pod-secrets-f7fa5b94-d314-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:17:46.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3345" for this suite.
Sep  9 15:17:52.686: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:17:52.769: INFO: namespace secrets-3345 deletion completed in 6.099878047s

• [SLOW TEST:10.478 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:17:52.769: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4411
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-fe372997-d314-11e9-b473-6e32a6bc259a
STEP: Creating a pod to test consume configMaps
Sep  9 15:17:52.960: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-fe38d742-d314-11e9-b473-6e32a6bc259a" in namespace "projected-4411" to be "success or failure"
Sep  9 15:17:52.968: INFO: Pod "pod-projected-configmaps-fe38d742-d314-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.006572ms
Sep  9 15:17:54.976: INFO: Pod "pod-projected-configmaps-fe38d742-d314-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016030271s
STEP: Saw pod success
Sep  9 15:17:54.976: INFO: Pod "pod-projected-configmaps-fe38d742-d314-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 15:17:54.979: INFO: Trying to get logs from node 185.19.31.168 pod pod-projected-configmaps-fe38d742-d314-11e9-b473-6e32a6bc259a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  9 15:17:55.017: INFO: Waiting for pod pod-projected-configmaps-fe38d742-d314-11e9-b473-6e32a6bc259a to disappear
Sep  9 15:17:55.023: INFO: Pod pod-projected-configmaps-fe38d742-d314-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:17:55.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4411" for this suite.
Sep  9 15:18:01.049: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:18:01.131: INFO: namespace projected-4411 deletion completed in 6.105118221s

• [SLOW TEST:8.362 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:18:01.131: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1643
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-03326f57-d315-11e9-b473-6e32a6bc259a
STEP: Creating a pod to test consume secrets
Sep  9 15:18:01.316: INFO: Waiting up to 5m0s for pod "pod-secrets-03343e9b-d315-11e9-b473-6e32a6bc259a" in namespace "secrets-1643" to be "success or failure"
Sep  9 15:18:01.322: INFO: Pod "pod-secrets-03343e9b-d315-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.656533ms
Sep  9 15:18:03.326: INFO: Pod "pod-secrets-03343e9b-d315-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00932702s
STEP: Saw pod success
Sep  9 15:18:03.326: INFO: Pod "pod-secrets-03343e9b-d315-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 15:18:03.332: INFO: Trying to get logs from node 185.19.31.168 pod pod-secrets-03343e9b-d315-11e9-b473-6e32a6bc259a container secret-env-test: <nil>
STEP: delete the pod
Sep  9 15:18:03.355: INFO: Waiting for pod pod-secrets-03343e9b-d315-11e9-b473-6e32a6bc259a to disappear
Sep  9 15:18:03.357: INFO: Pod pod-secrets-03343e9b-d315-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:18:03.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1643" for this suite.
Sep  9 15:18:09.382: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:18:09.463: INFO: namespace secrets-1643 deletion completed in 6.102493559s

• [SLOW TEST:8.332 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:18:09.464: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5078
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating secret secrets-5078/secret-test-082adbc7-d315-11e9-b473-6e32a6bc259a
STEP: Creating a pod to test consume secrets
Sep  9 15:18:09.651: INFO: Waiting up to 5m0s for pod "pod-configmaps-082c5de9-d315-11e9-b473-6e32a6bc259a" in namespace "secrets-5078" to be "success or failure"
Sep  9 15:18:09.668: INFO: Pod "pod-configmaps-082c5de9-d315-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 16.734629ms
Sep  9 15:18:11.673: INFO: Pod "pod-configmaps-082c5de9-d315-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021864328s
STEP: Saw pod success
Sep  9 15:18:11.673: INFO: Pod "pod-configmaps-082c5de9-d315-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 15:18:11.677: INFO: Trying to get logs from node 185.19.31.168 pod pod-configmaps-082c5de9-d315-11e9-b473-6e32a6bc259a container env-test: <nil>
STEP: delete the pod
Sep  9 15:18:11.711: INFO: Waiting for pod pod-configmaps-082c5de9-d315-11e9-b473-6e32a6bc259a to disappear
Sep  9 15:18:11.717: INFO: Pod pod-configmaps-082c5de9-d315-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:18:11.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5078" for this suite.
Sep  9 15:18:17.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:18:17.828: INFO: namespace secrets-5078 deletion completed in 6.108149336s

• [SLOW TEST:8.364 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:18:17.828: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-9852
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:18:22.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9852" for this suite.
Sep  9 15:18:28.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:18:28.113: INFO: namespace kubelet-test-9852 deletion completed in 6.092832038s

• [SLOW TEST:10.285 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:18:28.114: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2222
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-2222/configmap-test-134bf302-d315-11e9-b473-6e32a6bc259a
STEP: Creating a pod to test consume configMaps
Sep  9 15:18:28.328: INFO: Waiting up to 5m0s for pod "pod-configmaps-134d8c01-d315-11e9-b473-6e32a6bc259a" in namespace "configmap-2222" to be "success or failure"
Sep  9 15:18:28.331: INFO: Pod "pod-configmaps-134d8c01-d315-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.528649ms
Sep  9 15:18:30.335: INFO: Pod "pod-configmaps-134d8c01-d315-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0071691s
STEP: Saw pod success
Sep  9 15:18:30.335: INFO: Pod "pod-configmaps-134d8c01-d315-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 15:18:30.338: INFO: Trying to get logs from node 185.19.31.168 pod pod-configmaps-134d8c01-d315-11e9-b473-6e32a6bc259a container env-test: <nil>
STEP: delete the pod
Sep  9 15:18:30.364: INFO: Waiting for pod pod-configmaps-134d8c01-d315-11e9-b473-6e32a6bc259a to disappear
Sep  9 15:18:30.370: INFO: Pod pod-configmaps-134d8c01-d315-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:18:30.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2222" for this suite.
Sep  9 15:18:36.391: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:18:36.477: INFO: namespace configmap-2222 deletion completed in 6.102854776s

• [SLOW TEST:8.364 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:18:36.478: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1335
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Sep  9 15:18:36.633: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 create -f - --namespace=kubectl-1335'
Sep  9 15:18:37.070: INFO: stderr: ""
Sep  9 15:18:37.070: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Sep  9 15:18:38.073: INFO: Selector matched 1 pods for map[app:redis]
Sep  9 15:18:38.073: INFO: Found 0 / 1
Sep  9 15:18:39.075: INFO: Selector matched 1 pods for map[app:redis]
Sep  9 15:18:39.075: INFO: Found 0 / 1
Sep  9 15:18:40.075: INFO: Selector matched 1 pods for map[app:redis]
Sep  9 15:18:40.075: INFO: Found 1 / 1
Sep  9 15:18:40.075: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Sep  9 15:18:40.079: INFO: Selector matched 1 pods for map[app:redis]
Sep  9 15:18:40.079: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep  9 15:18:40.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 patch pod redis-master-ggzg2 --namespace=kubectl-1335 -p {"metadata":{"annotations":{"x":"y"}}}'
Sep  9 15:18:40.179: INFO: stderr: ""
Sep  9 15:18:40.179: INFO: stdout: "pod/redis-master-ggzg2 patched\n"
STEP: checking annotations
Sep  9 15:18:40.203: INFO: Selector matched 1 pods for map[app:redis]
Sep  9 15:18:40.204: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:18:40.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1335" for this suite.
Sep  9 15:19:02.224: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:19:02.316: INFO: namespace kubectl-1335 deletion completed in 22.108094173s

• [SLOW TEST:25.838 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:19:02.316: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-61
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1576
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  9 15:19:02.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-61'
Sep  9 15:19:02.589: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep  9 15:19:02.589: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1581
Sep  9 15:19:02.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 delete jobs e2e-test-nginx-job --namespace=kubectl-61'
Sep  9 15:19:02.699: INFO: stderr: ""
Sep  9 15:19:02.699: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:19:02.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-61" for this suite.
Sep  9 15:19:08.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:19:08.807: INFO: namespace kubectl-61 deletion completed in 6.104228783s

• [SLOW TEST:6.491 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:19:08.807: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-560
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-560.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-560.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep  9 15:19:11.014: INFO: DNS probes using dns-560/dns-test-2b8858ac-d315-11e9-b473-6e32a6bc259a succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:19:11.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-560" for this suite.
Sep  9 15:19:17.059: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:19:17.142: INFO: namespace dns-560 deletion completed in 6.107504102s

• [SLOW TEST:8.335 seconds]
[sig-network] DNS
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:19:17.142: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-8081
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
Sep  9 15:19:17.860: INFO: created pod pod-service-account-defaultsa
Sep  9 15:19:17.860: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Sep  9 15:19:17.885: INFO: created pod pod-service-account-mountsa
Sep  9 15:19:17.885: INFO: pod pod-service-account-mountsa service account token volume mount: true
Sep  9 15:19:17.901: INFO: created pod pod-service-account-nomountsa
Sep  9 15:19:17.901: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Sep  9 15:19:17.912: INFO: created pod pod-service-account-defaultsa-mountspec
Sep  9 15:19:17.912: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Sep  9 15:19:17.940: INFO: created pod pod-service-account-mountsa-mountspec
Sep  9 15:19:17.940: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Sep  9 15:19:17.958: INFO: created pod pod-service-account-nomountsa-mountspec
Sep  9 15:19:17.958: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Sep  9 15:19:17.976: INFO: created pod pod-service-account-defaultsa-nomountspec
Sep  9 15:19:17.976: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Sep  9 15:19:17.985: INFO: created pod pod-service-account-mountsa-nomountspec
Sep  9 15:19:17.985: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Sep  9 15:19:17.997: INFO: created pod pod-service-account-nomountsa-nomountspec
Sep  9 15:19:17.997: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:19:17.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-8081" for this suite.
Sep  9 15:19:40.017: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:19:40.105: INFO: namespace svcaccounts-8081 deletion completed in 22.103189156s

• [SLOW TEST:22.963 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:19:40.105: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3234
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-3e32e02b-d315-11e9-b473-6e32a6bc259a
STEP: Creating secret with name s-test-opt-upd-3e32e075-d315-11e9-b473-6e32a6bc259a
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-3e32e02b-d315-11e9-b473-6e32a6bc259a
STEP: Updating secret s-test-opt-upd-3e32e075-d315-11e9-b473-6e32a6bc259a
STEP: Creating secret with name s-test-opt-create-3e32e090-d315-11e9-b473-6e32a6bc259a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:19:44.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3234" for this suite.
Sep  9 15:20:08.671: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:20:08.745: INFO: namespace projected-3234 deletion completed in 24.094668241s

• [SLOW TEST:28.640 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:20:08.746: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4482
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1174
STEP: creating the pod
Sep  9 15:20:08.963: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 create -f - --namespace=kubectl-4482'
Sep  9 15:20:09.187: INFO: stderr: ""
Sep  9 15:20:09.187: INFO: stdout: "pod/pause created\n"
Sep  9 15:20:09.187: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Sep  9 15:20:09.187: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-4482" to be "running and ready"
Sep  9 15:20:09.189: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 1.994765ms
Sep  9 15:20:11.192: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.004950583s
Sep  9 15:20:11.192: INFO: Pod "pause" satisfied condition "running and ready"
Sep  9 15:20:11.192: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: adding the label testing-label with value testing-label-value to a pod
Sep  9 15:20:11.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 label pods pause testing-label=testing-label-value --namespace=kubectl-4482'
Sep  9 15:20:11.294: INFO: stderr: ""
Sep  9 15:20:11.294: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Sep  9 15:20:11.294: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pod pause -L testing-label --namespace=kubectl-4482'
Sep  9 15:20:11.383: INFO: stderr: ""
Sep  9 15:20:11.383: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Sep  9 15:20:11.383: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 label pods pause testing-label- --namespace=kubectl-4482'
Sep  9 15:20:11.480: INFO: stderr: ""
Sep  9 15:20:11.480: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Sep  9 15:20:11.480: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pod pause -L testing-label --namespace=kubectl-4482'
Sep  9 15:20:11.567: INFO: stderr: ""
Sep  9 15:20:11.567: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1181
STEP: using delete to clean up resources
Sep  9 15:20:11.567: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 delete --grace-period=0 --force -f - --namespace=kubectl-4482'
Sep  9 15:20:11.682: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  9 15:20:11.682: INFO: stdout: "pod \"pause\" force deleted\n"
Sep  9 15:20:11.682: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get rc,svc -l name=pause --no-headers --namespace=kubectl-4482'
Sep  9 15:20:11.766: INFO: stderr: "No resources found.\n"
Sep  9 15:20:11.766: INFO: stdout: ""
Sep  9 15:20:11.766: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 get pods -l name=pause --namespace=kubectl-4482 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  9 15:20:11.849: INFO: stderr: ""
Sep  9 15:20:11.849: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:20:11.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4482" for this suite.
Sep  9 15:20:17.867: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:20:17.960: INFO: namespace kubectl-4482 deletion completed in 6.108259155s

• [SLOW TEST:9.215 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:20:17.961: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-7763
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating replication controller my-hostname-basic-54c184de-d315-11e9-b473-6e32a6bc259a
Sep  9 15:20:18.140: INFO: Pod name my-hostname-basic-54c184de-d315-11e9-b473-6e32a6bc259a: Found 0 pods out of 1
Sep  9 15:20:23.144: INFO: Pod name my-hostname-basic-54c184de-d315-11e9-b473-6e32a6bc259a: Found 1 pods out of 1
Sep  9 15:20:23.144: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-54c184de-d315-11e9-b473-6e32a6bc259a" are running
Sep  9 15:20:23.147: INFO: Pod "my-hostname-basic-54c184de-d315-11e9-b473-6e32a6bc259a-q2t7q" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-09 15:20:18 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-09 15:20:20 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-09 15:20:20 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-09 15:20:18 +0000 UTC Reason: Message:}])
Sep  9 15:20:23.147: INFO: Trying to dial the pod
Sep  9 15:20:28.158: INFO: Controller my-hostname-basic-54c184de-d315-11e9-b473-6e32a6bc259a: Got expected result from replica 1 [my-hostname-basic-54c184de-d315-11e9-b473-6e32a6bc259a-q2t7q]: "my-hostname-basic-54c184de-d315-11e9-b473-6e32a6bc259a-q2t7q", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:20:28.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7763" for this suite.
Sep  9 15:20:34.179: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:20:34.278: INFO: namespace replication-controller-7763 deletion completed in 6.116894877s

• [SLOW TEST:16.318 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:20:34.279: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-265
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1649
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  9 15:20:34.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-265'
Sep  9 15:20:34.616: INFO: stderr: ""
Sep  9 15:20:34.616: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1654
Sep  9 15:20:34.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 delete pods e2e-test-nginx-pod --namespace=kubectl-265'
Sep  9 15:20:36.756: INFO: stderr: ""
Sep  9 15:20:36.756: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:20:36.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-265" for this suite.
Sep  9 15:20:42.773: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:20:42.862: INFO: namespace kubectl-265 deletion completed in 6.103217118s

• [SLOW TEST:8.583 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:20:42.862: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-3078
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Sep  9 15:20:43.023: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:20:47.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3078" for this suite.
Sep  9 15:21:09.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:21:09.215: INFO: namespace init-container-3078 deletion completed in 22.09943819s

• [SLOW TEST:26.353 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:21:09.216: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6256
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-734e0983-d315-11e9-b473-6e32a6bc259a
STEP: Creating a pod to test consume configMaps
Sep  9 15:21:09.397: INFO: Waiting up to 5m0s for pod "pod-configmaps-734f475a-d315-11e9-b473-6e32a6bc259a" in namespace "configmap-6256" to be "success or failure"
Sep  9 15:21:09.399: INFO: Pod "pod-configmaps-734f475a-d315-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036768ms
Sep  9 15:21:11.405: INFO: Pod "pod-configmaps-734f475a-d315-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00820083s
Sep  9 15:21:13.409: INFO: Pod "pod-configmaps-734f475a-d315-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012651511s
STEP: Saw pod success
Sep  9 15:21:13.410: INFO: Pod "pod-configmaps-734f475a-d315-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 15:21:13.413: INFO: Trying to get logs from node 185.19.31.168 pod pod-configmaps-734f475a-d315-11e9-b473-6e32a6bc259a container configmap-volume-test: <nil>
STEP: delete the pod
Sep  9 15:21:13.441: INFO: Waiting for pod pod-configmaps-734f475a-d315-11e9-b473-6e32a6bc259a to disappear
Sep  9 15:21:13.451: INFO: Pod pod-configmaps-734f475a-d315-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:21:13.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6256" for this suite.
Sep  9 15:21:19.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:21:19.566: INFO: namespace configmap-6256 deletion completed in 6.112034712s

• [SLOW TEST:10.351 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:21:19.567: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3242
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Sep  9 15:21:19.740: INFO: Waiting up to 5m0s for pod "pod-79791fde-d315-11e9-b473-6e32a6bc259a" in namespace "emptydir-3242" to be "success or failure"
Sep  9 15:21:19.753: INFO: Pod "pod-79791fde-d315-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 12.724291ms
Sep  9 15:21:21.756: INFO: Pod "pod-79791fde-d315-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015639958s
STEP: Saw pod success
Sep  9 15:21:21.756: INFO: Pod "pod-79791fde-d315-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 15:21:21.758: INFO: Trying to get logs from node 185.19.31.168 pod pod-79791fde-d315-11e9-b473-6e32a6bc259a container test-container: <nil>
STEP: delete the pod
Sep  9 15:21:21.784: INFO: Waiting for pod pod-79791fde-d315-11e9-b473-6e32a6bc259a to disappear
Sep  9 15:21:21.789: INFO: Pod pod-79791fde-d315-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:21:21.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3242" for this suite.
Sep  9 15:21:27.823: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:21:27.921: INFO: namespace emptydir-3242 deletion completed in 6.114686632s

• [SLOW TEST:8.354 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:21:27.921: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6027
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating api versions
Sep  9 15:21:28.081: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-310951909 api-versions'
Sep  9 15:21:28.167: INFO: stderr: ""
Sep  9 15:21:28.167: INFO: stdout: "admission.certmanager.k8s.io/v1beta1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncertmanager.k8s.io/v1alpha1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nmonitoring.coreos.com/v1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:21:28.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6027" for this suite.
Sep  9 15:21:34.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:21:34.280: INFO: namespace kubectl-6027 deletion completed in 6.109840667s

• [SLOW TEST:6.359 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:21:34.280: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2547
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  9 15:21:34.459: INFO: Waiting up to 5m0s for pod "downwardapi-volume-823ee4b1-d315-11e9-b473-6e32a6bc259a" in namespace "downward-api-2547" to be "success or failure"
Sep  9 15:21:34.465: INFO: Pod "downwardapi-volume-823ee4b1-d315-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.770386ms
Sep  9 15:21:36.470: INFO: Pod "downwardapi-volume-823ee4b1-d315-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010861444s
STEP: Saw pod success
Sep  9 15:21:36.470: INFO: Pod "downwardapi-volume-823ee4b1-d315-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 15:21:36.474: INFO: Trying to get logs from node 185.19.31.168 pod downwardapi-volume-823ee4b1-d315-11e9-b473-6e32a6bc259a container client-container: <nil>
STEP: delete the pod
Sep  9 15:21:36.521: INFO: Waiting for pod downwardapi-volume-823ee4b1-d315-11e9-b473-6e32a6bc259a to disappear
Sep  9 15:21:36.528: INFO: Pod downwardapi-volume-823ee4b1-d315-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:21:36.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2547" for this suite.
Sep  9 15:21:42.549: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:21:42.634: INFO: namespace downward-api-2547 deletion completed in 6.103982652s

• [SLOW TEST:8.354 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:21:42.634: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9234
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-873988e6-d315-11e9-b473-6e32a6bc259a
STEP: Creating a pod to test consume secrets
Sep  9 15:21:42.827: INFO: Waiting up to 5m0s for pod "pod-secrets-873b0840-d315-11e9-b473-6e32a6bc259a" in namespace "secrets-9234" to be "success or failure"
Sep  9 15:21:42.831: INFO: Pod "pod-secrets-873b0840-d315-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.508056ms
Sep  9 15:21:44.835: INFO: Pod "pod-secrets-873b0840-d315-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008455858s
Sep  9 15:21:46.840: INFO: Pod "pod-secrets-873b0840-d315-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013367391s
STEP: Saw pod success
Sep  9 15:21:46.840: INFO: Pod "pod-secrets-873b0840-d315-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 15:21:46.844: INFO: Trying to get logs from node 185.19.31.168 pod pod-secrets-873b0840-d315-11e9-b473-6e32a6bc259a container secret-volume-test: <nil>
STEP: delete the pod
Sep  9 15:21:46.895: INFO: Waiting for pod pod-secrets-873b0840-d315-11e9-b473-6e32a6bc259a to disappear
Sep  9 15:21:46.897: INFO: Pod pod-secrets-873b0840-d315-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:21:46.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9234" for this suite.
Sep  9 15:21:52.922: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:21:53.015: INFO: namespace secrets-9234 deletion completed in 6.109573601s

• [SLOW TEST:10.380 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  9 15:21:53.015: INFO: >>> kubeConfig: /tmp/kubeconfig-310951909
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5568
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-8d69762f-d315-11e9-b473-6e32a6bc259a
STEP: Creating a pod to test consume configMaps
Sep  9 15:21:53.199: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8d6af75c-d315-11e9-b473-6e32a6bc259a" in namespace "projected-5568" to be "success or failure"
Sep  9 15:21:53.203: INFO: Pod "pod-projected-configmaps-8d6af75c-d315-11e9-b473-6e32a6bc259a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.04505ms
Sep  9 15:21:55.208: INFO: Pod "pod-projected-configmaps-8d6af75c-d315-11e9-b473-6e32a6bc259a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009076903s
STEP: Saw pod success
Sep  9 15:21:55.208: INFO: Pod "pod-projected-configmaps-8d6af75c-d315-11e9-b473-6e32a6bc259a" satisfied condition "success or failure"
Sep  9 15:21:55.211: INFO: Trying to get logs from node 185.19.31.168 pod pod-projected-configmaps-8d6af75c-d315-11e9-b473-6e32a6bc259a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  9 15:21:55.235: INFO: Waiting for pod pod-projected-configmaps-8d6af75c-d315-11e9-b473-6e32a6bc259a to disappear
Sep  9 15:21:55.238: INFO: Pod pod-projected-configmaps-8d6af75c-d315-11e9-b473-6e32a6bc259a no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  9 15:21:55.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5568" for this suite.
Sep  9 15:22:01.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 15:22:01.351: INFO: namespace projected-5568 deletion completed in 6.10910779s

• [SLOW TEST:8.336 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.6-beta.0.47+96fac5cd13a5dc/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
Sep  9 15:22:01.351: INFO: Running AfterSuite actions on all nodes
Sep  9 15:22:01.351: INFO: Running AfterSuite actions on node 1
Sep  9 15:22:01.351: INFO: Skipping dumping logs from cluster

Ran 204 of 3586 Specs in 5370.715 seconds
SUCCESS! -- 204 Passed | 0 Failed | 0 Pending | 3382 Skipped PASS

Ginkgo ran 1 suite in 1h29m31.91148155s
Test Suite Passed
