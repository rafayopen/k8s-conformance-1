Conformance test: not doing test setup.
I0408 14:01:01.850916    5043 e2e.go:240] Starting e2e run "bd9269f1-5a06-11e9-b9a9-e6698ebc8bdf" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1554732060 - Will randomize all specs
Will run 204 of 3584 specs

Apr  8 14:01:02.096: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
Apr  8 14:01:02.098: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Apr  8 14:01:02.120: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Apr  8 14:01:02.165: INFO: 14 / 14 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Apr  8 14:01:02.166: INFO: expected 8 pod replicas in namespace 'kube-system', 8 are Running and Ready.
Apr  8 14:01:02.166: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Apr  8 14:01:02.176: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Apr  8 14:01:02.176: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Apr  8 14:01:02.176: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'node-exporter' (0 seconds elapsed)
Apr  8 14:01:02.176: INFO: e2e test version: v1.14.0
Apr  8 14:01:02.178: INFO: kube-apiserver version: v1.14.0
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:01:02.178: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubectl
Apr  8 14:01:02.222: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Apr  8 14:01:02.241: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9294
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: executing a command with run --rm and attach with stdin
Apr  8 14:01:02.355: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config --namespace=kubectl-9294 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Apr  8 14:01:07.312: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Apr  8 14:01:07.312: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:01:09.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9294" for this suite.
Apr  8 14:01:15.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:01:15.482: INFO: namespace kubectl-9294 deletion completed in 6.158468514s
â€¢SSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:01:15.482: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-8109
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  8 14:01:15.646: INFO: (0) /api/v1/nodes/shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 11.98849ms)
Apr  8 14:01:15.684: INFO: (1) /api/v1/nodes/shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 38.455708ms)
Apr  8 14:01:15.692: INFO: (2) /api/v1/nodes/shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 7.715514ms)
Apr  8 14:01:15.698: INFO: (3) /api/v1/nodes/shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.587194ms)
Apr  8 14:01:15.703: INFO: (4) /api/v1/nodes/shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.297668ms)
Apr  8 14:01:15.708: INFO: (5) /api/v1/nodes/shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.020146ms)
Apr  8 14:01:15.716: INFO: (6) /api/v1/nodes/shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 7.877125ms)
Apr  8 14:01:15.722: INFO: (7) /api/v1/nodes/shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.544535ms)
Apr  8 14:01:15.727: INFO: (8) /api/v1/nodes/shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.814147ms)
Apr  8 14:01:15.734: INFO: (9) /api/v1/nodes/shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 6.591517ms)
Apr  8 14:01:15.741: INFO: (10) /api/v1/nodes/shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 6.643288ms)
Apr  8 14:01:15.746: INFO: (11) /api/v1/nodes/shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.71053ms)
Apr  8 14:01:15.755: INFO: (12) /api/v1/nodes/shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 8.269064ms)
Apr  8 14:01:15.761: INFO: (13) /api/v1/nodes/shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 6.515577ms)
Apr  8 14:01:15.767: INFO: (14) /api/v1/nodes/shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.574957ms)
Apr  8 14:01:15.772: INFO: (15) /api/v1/nodes/shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.357823ms)
Apr  8 14:01:15.779: INFO: (16) /api/v1/nodes/shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 6.678475ms)
Apr  8 14:01:15.785: INFO: (17) /api/v1/nodes/shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 6.014294ms)
Apr  8 14:01:15.791: INFO: (18) /api/v1/nodes/shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.460042ms)
Apr  8 14:01:15.796: INFO: (19) /api/v1/nodes/shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.456628ms)
[AfterEach] version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:01:15.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8109" for this suite.
Apr  8 14:01:21.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:01:21.945: INFO: namespace proxy-8109 deletion completed in 6.145412957s
â€¢SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:01:21.946: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9390
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  8 14:01:22.100: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ca3ec034-5a06-11e9-b9a9-e6698ebc8bdf" in namespace "projected-9390" to be "success or failure"
Apr  8 14:01:22.109: INFO: Pod "downwardapi-volume-ca3ec034-5a06-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 8.454588ms
Apr  8 14:01:24.114: INFO: Pod "downwardapi-volume-ca3ec034-5a06-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013620944s
Apr  8 14:01:26.120: INFO: Pod "downwardapi-volume-ca3ec034-5a06-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019127863s
STEP: Saw pod success
Apr  8 14:01:26.120: INFO: Pod "downwardapi-volume-ca3ec034-5a06-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 14:01:26.124: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod downwardapi-volume-ca3ec034-5a06-11e9-b9a9-e6698ebc8bdf container client-container: <nil>
STEP: delete the pod
Apr  8 14:01:26.273: INFO: Waiting for pod downwardapi-volume-ca3ec034-5a06-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 14:01:26.277: INFO: Pod downwardapi-volume-ca3ec034-5a06-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:01:26.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9390" for this suite.
Apr  8 14:01:32.296: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:01:32.466: INFO: namespace projected-9390 deletion completed in 6.184130659s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:01:32.466: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3587
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-projected-all-test-volume-d08442f1-5a06-11e9-b9a9-e6698ebc8bdf
STEP: Creating secret with name secret-projected-all-test-volume-d08442df-5a06-11e9-b9a9-e6698ebc8bdf
STEP: Creating a pod to test Check all projections for projected volume plugin
Apr  8 14:01:32.638: INFO: Waiting up to 5m0s for pod "projected-volume-d08442b2-5a06-11e9-b9a9-e6698ebc8bdf" in namespace "projected-3587" to be "success or failure"
Apr  8 14:01:32.642: INFO: Pod "projected-volume-d08442b2-5a06-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 3.525322ms
Apr  8 14:01:34.647: INFO: Pod "projected-volume-d08442b2-5a06-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008797483s
STEP: Saw pod success
Apr  8 14:01:34.647: INFO: Pod "projected-volume-d08442b2-5a06-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 14:01:34.651: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod projected-volume-d08442b2-5a06-11e9-b9a9-e6698ebc8bdf container projected-all-volume-test: <nil>
STEP: delete the pod
Apr  8 14:01:34.672: INFO: Waiting for pod projected-volume-d08442b2-5a06-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 14:01:34.675: INFO: Pod projected-volume-d08442b2-5a06-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:01:34.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3587" for this suite.
Apr  8 14:01:40.691: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:01:40.808: INFO: namespace projected-3587 deletion completed in 6.129718601s
â€¢SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:01:40.808: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-4954
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:01:45.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-4954" for this suite.
Apr  8 14:01:51.025: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:01:51.144: INFO: namespace emptydir-wrapper-4954 deletion completed in 6.1316492s
â€¢SSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:01:51.144: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8003
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating pod
Apr  8 14:01:53.314: INFO: Pod pod-hostip-dba5f78f-5a06-11e9-b9a9-e6698ebc8bdf has hostIP: 10.250.0.16
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:01:53.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8003" for this suite.
Apr  8 14:02:15.329: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:02:15.455: INFO: namespace pods-8003 deletion completed in 22.13681093s
â€¢SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:02:15.455: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2136
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating cluster-info
Apr  8 14:02:15.599: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config cluster-info'
Apr  8 14:02:15.754: INFO: stderr: ""
Apr  8 14:02:15.754: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:02:15.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2136" for this suite.
Apr  8 14:02:21.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:02:21.915: INFO: namespace kubectl-2136 deletion completed in 6.156026223s
â€¢SSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:02:21.915: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-2110
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  8 14:02:22.070: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Apr  8 14:02:27.075: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr  8 14:02:27.075: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr  8 14:02:27.095: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-2110,SelfLink:/apis/apps/v1/namespaces/deployment-2110/deployments/test-cleanup-deployment,UID:f0fbdabb-5a06-11e9-8aed-4ea023eb3a48,ResourceVersion:2040,Generation:1,CreationTimestamp:2019-04-08 14:02:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Apr  8 14:02:27.104: INFO: New ReplicaSet "test-cleanup-deployment-55cbfbc8f5" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55cbfbc8f5,GenerateName:,Namespace:deployment-2110,SelfLink:/apis/apps/v1/namespaces/deployment-2110/replicasets/test-cleanup-deployment-55cbfbc8f5,UID:f0fd9fe0-5a06-11e9-8aed-4ea023eb3a48,ResourceVersion:2042,Generation:1,CreationTimestamp:2019-04-08 14:02:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment f0fbdabb-5a06-11e9-8aed-4ea023eb3a48 0xc0029638c7 0xc0029638c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr  8 14:02:27.104: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Apr  8 14:02:27.104: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:deployment-2110,SelfLink:/apis/apps/v1/namespaces/deployment-2110/replicasets/test-cleanup-controller,UID:edfdfca9-5a06-11e9-8aed-4ea023eb3a48,ResourceVersion:2041,Generation:1,CreationTimestamp:2019-04-08 14:02:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment f0fbdabb-5a06-11e9-8aed-4ea023eb3a48 0xc002963807 0xc002963808}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Apr  8 14:02:27.109: INFO: Pod "test-cleanup-controller-xxx84" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-xxx84,GenerateName:test-cleanup-controller-,Namespace:deployment-2110,SelfLink:/api/v1/namespaces/deployment-2110/pods/test-cleanup-controller-xxx84,UID:edff097b-5a06-11e9-8aed-4ea023eb3a48,ResourceVersion:2037,Generation:0,CreationTimestamp:2019-04-08 14:02:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.7/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller edfdfca9-5a06-11e9-8aed-4ea023eb3a48 0xc0027b624f 0xc0027b6270}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jl6dh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jl6dh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jl6dh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027b62d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027b62f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:02:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:02:26 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:02:26 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:02:22 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.16,PodIP:100.96.1.7,StartTime:2019-04-08 14:02:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-08 14:02:26 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://38c870c8f84fd388be4445c90885741b878be247b4b15a10d9871785c86b9bb7}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  8 14:02:27.110: INFO: Pod "test-cleanup-deployment-55cbfbc8f5-dm9cr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55cbfbc8f5-dm9cr,GenerateName:test-cleanup-deployment-55cbfbc8f5-,Namespace:deployment-2110,SelfLink:/api/v1/namespaces/deployment-2110/pods/test-cleanup-deployment-55cbfbc8f5-dm9cr,UID:f0fe0ce2-5a06-11e9-8aed-4ea023eb3a48,ResourceVersion:2045,Generation:0,CreationTimestamp:2019-04-08 14:02:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-55cbfbc8f5 f0fd9fe0-5a06-11e9-8aed-4ea023eb3a48 0xc0027b6407 0xc0027b6408}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-jl6dh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jl6dh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-jl6dh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027b6490} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027b64b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:02:27 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:02:27.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2110" for this suite.
Apr  8 14:02:33.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:02:33.258: INFO: namespace deployment-2110 deletion completed in 6.1444214s
â€¢SSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:02:33.258: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-480
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:02:35.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-480" for this suite.
Apr  8 14:03:21.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:03:21.696: INFO: namespace kubelet-test-480 deletion completed in 46.191441887s
â€¢SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:03:21.696: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7145
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  8 14:03:21.856: INFO: Waiting up to 5m0s for pod "downwardapi-volume-119fe529-5a07-11e9-b9a9-e6698ebc8bdf" in namespace "projected-7145" to be "success or failure"
Apr  8 14:03:21.862: INFO: Pod "downwardapi-volume-119fe529-5a07-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 5.513107ms
Apr  8 14:03:23.868: INFO: Pod "downwardapi-volume-119fe529-5a07-11e9-b9a9-e6698ebc8bdf": Phase="Running", Reason="", readiness=true. Elapsed: 2.011242473s
Apr  8 14:03:25.879: INFO: Pod "downwardapi-volume-119fe529-5a07-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02291801s
STEP: Saw pod success
Apr  8 14:03:25.880: INFO: Pod "downwardapi-volume-119fe529-5a07-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 14:03:25.885: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod downwardapi-volume-119fe529-5a07-11e9-b9a9-e6698ebc8bdf container client-container: <nil>
STEP: delete the pod
Apr  8 14:03:25.907: INFO: Waiting for pod downwardapi-volume-119fe529-5a07-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 14:03:25.911: INFO: Pod downwardapi-volume-119fe529-5a07-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:03:25.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7145" for this suite.
Apr  8 14:03:31.930: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:03:32.076: INFO: namespace projected-7145 deletion completed in 6.160484681s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:03:32.076: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-1565
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  8 14:03:32.242: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Apr  8 14:03:32.254: INFO: Number of nodes with available pods: 0
Apr  8 14:03:32.254: INFO: Node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw is running more than one daemon pod
Apr  8 14:03:33.264: INFO: Number of nodes with available pods: 0
Apr  8 14:03:33.264: INFO: Node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw is running more than one daemon pod
Apr  8 14:03:34.264: INFO: Number of nodes with available pods: 1
Apr  8 14:03:34.264: INFO: Node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw is running more than one daemon pod
Apr  8 14:03:35.263: INFO: Number of nodes with available pods: 1
Apr  8 14:03:35.263: INFO: Node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw is running more than one daemon pod
Apr  8 14:03:36.263: INFO: Number of nodes with available pods: 1
Apr  8 14:03:36.263: INFO: Node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw is running more than one daemon pod
Apr  8 14:03:37.293: INFO: Number of nodes with available pods: 1
Apr  8 14:03:37.293: INFO: Node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw is running more than one daemon pod
Apr  8 14:03:38.264: INFO: Number of nodes with available pods: 2
Apr  8 14:03:38.264: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Apr  8 14:03:38.296: INFO: Wrong image for pod: daemon-set-25h26. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  8 14:03:38.296: INFO: Wrong image for pod: daemon-set-kx5hd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  8 14:03:39.305: INFO: Wrong image for pod: daemon-set-25h26. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  8 14:03:39.305: INFO: Wrong image for pod: daemon-set-kx5hd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  8 14:03:40.304: INFO: Wrong image for pod: daemon-set-25h26. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  8 14:03:40.304: INFO: Wrong image for pod: daemon-set-kx5hd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  8 14:03:41.304: INFO: Wrong image for pod: daemon-set-25h26. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  8 14:03:41.304: INFO: Wrong image for pod: daemon-set-kx5hd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  8 14:03:41.304: INFO: Pod daemon-set-kx5hd is not available
Apr  8 14:03:42.305: INFO: Wrong image for pod: daemon-set-25h26. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  8 14:03:42.305: INFO: Wrong image for pod: daemon-set-kx5hd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  8 14:03:42.305: INFO: Pod daemon-set-kx5hd is not available
Apr  8 14:03:43.304: INFO: Wrong image for pod: daemon-set-25h26. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  8 14:03:43.304: INFO: Wrong image for pod: daemon-set-kx5hd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  8 14:03:43.304: INFO: Pod daemon-set-kx5hd is not available
Apr  8 14:03:44.306: INFO: Wrong image for pod: daemon-set-25h26. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  8 14:03:44.306: INFO: Pod daemon-set-k77kt is not available
Apr  8 14:03:45.305: INFO: Wrong image for pod: daemon-set-25h26. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  8 14:03:45.305: INFO: Pod daemon-set-k77kt is not available
Apr  8 14:03:46.305: INFO: Wrong image for pod: daemon-set-25h26. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  8 14:03:46.305: INFO: Pod daemon-set-k77kt is not available
Apr  8 14:03:47.305: INFO: Wrong image for pod: daemon-set-25h26. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  8 14:03:48.305: INFO: Wrong image for pod: daemon-set-25h26. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  8 14:03:48.305: INFO: Pod daemon-set-25h26 is not available
Apr  8 14:03:49.304: INFO: Wrong image for pod: daemon-set-25h26. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  8 14:03:49.304: INFO: Pod daemon-set-25h26 is not available
Apr  8 14:03:50.304: INFO: Wrong image for pod: daemon-set-25h26. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  8 14:03:50.304: INFO: Pod daemon-set-25h26 is not available
Apr  8 14:03:51.304: INFO: Wrong image for pod: daemon-set-25h26. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  8 14:03:51.304: INFO: Pod daemon-set-25h26 is not available
Apr  8 14:03:52.305: INFO: Wrong image for pod: daemon-set-25h26. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  8 14:03:52.305: INFO: Pod daemon-set-25h26 is not available
Apr  8 14:03:53.305: INFO: Wrong image for pod: daemon-set-25h26. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  8 14:03:53.305: INFO: Pod daemon-set-25h26 is not available
Apr  8 14:03:54.305: INFO: Pod daemon-set-f75bw is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Apr  8 14:03:54.317: INFO: Number of nodes with available pods: 1
Apr  8 14:03:54.317: INFO: Node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw is running more than one daemon pod
Apr  8 14:03:55.330: INFO: Number of nodes with available pods: 1
Apr  8 14:03:55.330: INFO: Node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw is running more than one daemon pod
Apr  8 14:03:56.327: INFO: Number of nodes with available pods: 2
Apr  8 14:03:56.327: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1565, will wait for the garbage collector to delete the pods
Apr  8 14:03:56.406: INFO: Deleting DaemonSet.extensions daemon-set took: 7.120682ms
Apr  8 14:03:56.506: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.358564ms
Apr  8 14:04:03.712: INFO: Number of nodes with available pods: 0
Apr  8 14:04:03.712: INFO: Number of running nodes: 0, number of available pods: 0
Apr  8 14:04:03.715: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1565/daemonsets","resourceVersion":"2380"},"items":null}

Apr  8 14:04:03.718: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1565/pods","resourceVersion":"2380"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:04:03.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1565" for this suite.
Apr  8 14:04:09.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:04:09.907: INFO: namespace daemonsets-1565 deletion completed in 6.171105175s
â€¢S
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:04:09.907: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2657
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr  8 14:04:10.060: INFO: Waiting up to 5m0s for pod "downward-api-2e5b781e-5a07-11e9-b9a9-e6698ebc8bdf" in namespace "downward-api-2657" to be "success or failure"
Apr  8 14:04:10.068: INFO: Pod "downward-api-2e5b781e-5a07-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 7.467381ms
Apr  8 14:04:12.073: INFO: Pod "downward-api-2e5b781e-5a07-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01253745s
STEP: Saw pod success
Apr  8 14:04:12.073: INFO: Pod "downward-api-2e5b781e-5a07-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 14:04:12.076: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod downward-api-2e5b781e-5a07-11e9-b9a9-e6698ebc8bdf container dapi-container: <nil>
STEP: delete the pod
Apr  8 14:04:12.099: INFO: Waiting for pod downward-api-2e5b781e-5a07-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 14:04:12.102: INFO: Pod downward-api-2e5b781e-5a07-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:04:12.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2657" for this suite.
Apr  8 14:04:18.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:04:18.245: INFO: namespace downward-api-2657 deletion completed in 6.138875369s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:04:18.246: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7584
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-3353ce38-5a07-11e9-b9a9-e6698ebc8bdf
STEP: Creating a pod to test consume secrets
Apr  8 14:04:18.404: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3354967f-5a07-11e9-b9a9-e6698ebc8bdf" in namespace "projected-7584" to be "success or failure"
Apr  8 14:04:18.409: INFO: Pod "pod-projected-secrets-3354967f-5a07-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 5.588315ms
Apr  8 14:04:20.415: INFO: Pod "pod-projected-secrets-3354967f-5a07-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011169019s
STEP: Saw pod success
Apr  8 14:04:20.415: INFO: Pod "pod-projected-secrets-3354967f-5a07-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 14:04:20.418: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-projected-secrets-3354967f-5a07-11e9-b9a9-e6698ebc8bdf container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr  8 14:04:20.440: INFO: Waiting for pod pod-projected-secrets-3354967f-5a07-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 14:04:20.443: INFO: Pod pod-projected-secrets-3354967f-5a07-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:04:20.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7584" for this suite.
Apr  8 14:04:26.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:04:26.607: INFO: namespace projected-7584 deletion completed in 6.159964454s
â€¢SSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:04:26.607: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-5433
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating server pod server in namespace prestop-5433
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-5433
STEP: Deleting pre-stop pod
Apr  8 14:04:37.888: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:04:37.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-5433" for this suite.
Apr  8 14:20:53.652: INFO: Error while waiting for namespace to be terminated: Get https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com/api/v1/namespaces/prestop-5433: read tcp 10.254.0.198:33358->172.18.120.97:443: read: no route to host
Apr  8 14:20:53.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:20:53.888: INFO: namespace prestop-5433 deletion completed in 16m15.988036381s

â€¢ [SLOW TEST:987.281 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:20:53.888: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2680
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  8 14:20:54.052: INFO: Waiting up to 5m0s for pod "downwardapi-volume-84c8a421-5a09-11e9-b9a9-e6698ebc8bdf" in namespace "downward-api-2680" to be "success or failure"
Apr  8 14:20:54.056: INFO: Pod "downwardapi-volume-84c8a421-5a09-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.250425ms
Apr  8 14:20:56.080: INFO: Pod "downwardapi-volume-84c8a421-5a09-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028012668s
STEP: Saw pod success
Apr  8 14:20:56.080: INFO: Pod "downwardapi-volume-84c8a421-5a09-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 14:20:56.101: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod downwardapi-volume-84c8a421-5a09-11e9-b9a9-e6698ebc8bdf container client-container: <nil>
STEP: delete the pod
Apr  8 14:20:56.159: INFO: Waiting for pod downwardapi-volume-84c8a421-5a09-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 14:20:56.181: INFO: Pod downwardapi-volume-84c8a421-5a09-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:20:56.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2680" for this suite.
Apr  8 14:21:02.269: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:21:02.778: INFO: namespace downward-api-2680 deletion completed in 6.573065452s
â€¢SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:21:02.778: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9627
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-8a156fa0-5a09-11e9-b9a9-e6698ebc8bdf
STEP: Creating secret with name s-test-opt-upd-8a156fdf-5a09-11e9-b9a9-e6698ebc8bdf
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-8a156fa0-5a09-11e9-b9a9-e6698ebc8bdf
STEP: Updating secret s-test-opt-upd-8a156fdf-5a09-11e9-b9a9-e6698ebc8bdf
STEP: Creating secret with name s-test-opt-create-8a156ff7-5a09-11e9-b9a9-e6698ebc8bdf
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:21:07.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9627" for this suite.
Apr  8 14:21:29.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:21:29.651: INFO: namespace projected-9627 deletion completed in 22.17725448s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:21:29.651: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5556
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1619
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr  8 14:21:29.802: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-5556'
Apr  8 14:21:30.900: INFO: stderr: ""
Apr  8 14:21:30.900: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Apr  8 14:21:35.951: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pod e2e-test-nginx-pod --namespace=kubectl-5556 -o json'
Apr  8 14:21:36.105: INFO: stderr: ""
Apr  8 14:21:36.105: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"100.96.1.19/32\",\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2019-04-08T14:21:30Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-5556\",\n        \"resourceVersion\": \"4763\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-5556/pods/e2e-test-nginx-pod\",\n        \"uid\": \"9abe175f-5a09-11e9-8aed-4ea023eb3a48\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-wsrtf\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-wsrtf\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-wsrtf\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-08T14:21:30Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-08T14:21:32Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-08T14:21:32Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-08T14:21:30Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://5c33ff4307922f460f5454d848683506f2f606bf3089d8c6538a49cfa3b8a88e\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-04-08T14:21:31Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.250.0.16\",\n        \"phase\": \"Running\",\n        \"podIP\": \"100.96.1.19\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-04-08T14:21:30Z\"\n    }\n}\n"
STEP: replace the image in the pod
Apr  8 14:21:36.105: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config replace -f - --namespace=kubectl-5556'
Apr  8 14:21:36.413: INFO: stderr: ""
Apr  8 14:21:36.413: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1624
Apr  8 14:21:36.416: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config delete pods e2e-test-nginx-pod --namespace=kubectl-5556'
Apr  8 14:21:44.647: INFO: stderr: ""
Apr  8 14:21:44.647: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:21:44.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5556" for this suite.
Apr  8 14:21:50.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:21:50.836: INFO: namespace kubectl-5556 deletion completed in 6.184326969s
â€¢SSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:21:50.837: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-6603
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:21:55.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6603" for this suite.
Apr  8 14:22:01.106: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:22:01.702: INFO: namespace kubelet-test-6603 deletion completed in 6.656825684s
â€¢SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:22:01.703: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7310
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-ad467d13-5a09-11e9-b9a9-e6698ebc8bdf
STEP: Creating a pod to test consume secrets
Apr  8 14:22:02.018: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ad493868-5a09-11e9-b9a9-e6698ebc8bdf" in namespace "projected-7310" to be "success or failure"
Apr  8 14:22:02.037: INFO: Pod "pod-projected-secrets-ad493868-5a09-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 19.480815ms
Apr  8 14:22:04.042: INFO: Pod "pod-projected-secrets-ad493868-5a09-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024522765s
STEP: Saw pod success
Apr  8 14:22:04.042: INFO: Pod "pod-projected-secrets-ad493868-5a09-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 14:22:04.046: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-projected-secrets-ad493868-5a09-11e9-b9a9-e6698ebc8bdf container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr  8 14:22:04.066: INFO: Waiting for pod pod-projected-secrets-ad493868-5a09-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 14:22:04.069: INFO: Pod pod-projected-secrets-ad493868-5a09-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:22:04.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7310" for this suite.
Apr  8 14:22:10.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:22:10.202: INFO: namespace projected-7310 deletion completed in 6.128977727s
â€¢SSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:22:10.202: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-4619
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  8 14:22:10.372: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Apr  8 14:22:10.383: INFO: Number of nodes with available pods: 0
Apr  8 14:22:10.383: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Apr  8 14:22:10.399: INFO: Number of nodes with available pods: 0
Apr  8 14:22:10.399: INFO: Node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw is running more than one daemon pod
Apr  8 14:22:11.406: INFO: Number of nodes with available pods: 0
Apr  8 14:22:11.406: INFO: Node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw is running more than one daemon pod
Apr  8 14:22:12.404: INFO: Number of nodes with available pods: 1
Apr  8 14:22:12.404: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Apr  8 14:22:12.421: INFO: Number of nodes with available pods: 1
Apr  8 14:22:12.421: INFO: Number of running nodes: 0, number of available pods: 1
Apr  8 14:22:13.442: INFO: Number of nodes with available pods: 0
Apr  8 14:22:13.442: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Apr  8 14:22:13.481: INFO: Number of nodes with available pods: 0
Apr  8 14:22:13.481: INFO: Node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw is running more than one daemon pod
Apr  8 14:22:14.496: INFO: Number of nodes with available pods: 0
Apr  8 14:22:14.496: INFO: Node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw is running more than one daemon pod
Apr  8 14:22:15.487: INFO: Number of nodes with available pods: 0
Apr  8 14:22:15.487: INFO: Node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw is running more than one daemon pod
Apr  8 14:22:16.492: INFO: Number of nodes with available pods: 0
Apr  8 14:22:16.492: INFO: Node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw is running more than one daemon pod
Apr  8 14:22:17.488: INFO: Number of nodes with available pods: 1
Apr  8 14:22:17.488: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4619, will wait for the garbage collector to delete the pods
Apr  8 14:22:17.555: INFO: Deleting DaemonSet.extensions daemon-set took: 7.109675ms
Apr  8 14:22:17.655: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.230643ms
Apr  8 14:22:23.759: INFO: Number of nodes with available pods: 0
Apr  8 14:22:23.759: INFO: Number of running nodes: 0, number of available pods: 0
Apr  8 14:22:23.762: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4619/daemonsets","resourceVersion":"4967"},"items":null}

Apr  8 14:22:23.765: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4619/pods","resourceVersion":"4967"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:22:23.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4619" for this suite.
Apr  8 14:22:29.799: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:22:29.922: INFO: namespace daemonsets-4619 deletion completed in 6.136575484s
â€¢SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:22:29.923: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-695
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0408 14:22:40.161663    5043 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr  8 14:22:40.161: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:22:40.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-695" for this suite.
Apr  8 14:22:46.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:22:46.294: INFO: namespace gc-695 deletion completed in 6.12877927s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:22:46.294: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6277
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Apr  8 14:22:46.439: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config create -f - --namespace=kubectl-6277'
Apr  8 14:22:46.751: INFO: stderr: ""
Apr  8 14:22:46.752: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr  8 14:22:46.752: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6277'
Apr  8 14:22:46.880: INFO: stderr: ""
Apr  8 14:22:46.880: INFO: stdout: "update-demo-nautilus-wdqt2 update-demo-nautilus-xkfmq "
Apr  8 14:22:46.880: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-wdqt2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6277'
Apr  8 14:22:47.000: INFO: stderr: ""
Apr  8 14:22:47.000: INFO: stdout: ""
Apr  8 14:22:47.000: INFO: update-demo-nautilus-wdqt2 is created but not running
Apr  8 14:22:52.001: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6277'
Apr  8 14:22:52.135: INFO: stderr: ""
Apr  8 14:22:52.135: INFO: stdout: "update-demo-nautilus-wdqt2 update-demo-nautilus-xkfmq "
Apr  8 14:22:52.135: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-wdqt2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6277'
Apr  8 14:22:52.250: INFO: stderr: ""
Apr  8 14:22:52.250: INFO: stdout: "true"
Apr  8 14:22:52.250: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-wdqt2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6277'
Apr  8 14:22:52.370: INFO: stderr: ""
Apr  8 14:22:52.371: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  8 14:22:52.371: INFO: validating pod update-demo-nautilus-wdqt2
Apr  8 14:22:52.460: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  8 14:22:52.460: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  8 14:22:52.460: INFO: update-demo-nautilus-wdqt2 is verified up and running
Apr  8 14:22:52.460: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-xkfmq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6277'
Apr  8 14:22:52.574: INFO: stderr: ""
Apr  8 14:22:52.574: INFO: stdout: "true"
Apr  8 14:22:52.574: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-xkfmq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6277'
Apr  8 14:22:52.693: INFO: stderr: ""
Apr  8 14:22:52.693: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  8 14:22:52.693: INFO: validating pod update-demo-nautilus-xkfmq
Apr  8 14:22:52.786: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  8 14:22:52.786: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  8 14:22:52.786: INFO: update-demo-nautilus-xkfmq is verified up and running
STEP: using delete to clean up resources
Apr  8 14:22:52.786: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-6277'
Apr  8 14:22:52.956: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  8 14:22:52.956: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr  8 14:22:52.956: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get rc,svc -l name=update-demo --no-headers --namespace=kubectl-6277'
Apr  8 14:22:53.099: INFO: stderr: "No resources found.\n"
Apr  8 14:22:53.099: INFO: stdout: ""
Apr  8 14:22:53.099: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods -l name=update-demo --namespace=kubectl-6277 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr  8 14:22:53.207: INFO: stderr: ""
Apr  8 14:22:53.207: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:22:53.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6277" for this suite.
Apr  8 14:23:15.227: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:23:15.350: INFO: namespace kubectl-6277 deletion completed in 22.137511756s
â€¢SSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:23:15.350: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-7153
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
Apr  8 14:23:16.027: INFO: created pod pod-service-account-defaultsa
Apr  8 14:23:16.027: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Apr  8 14:23:16.031: INFO: created pod pod-service-account-mountsa
Apr  8 14:23:16.031: INFO: pod pod-service-account-mountsa service account token volume mount: true
Apr  8 14:23:16.037: INFO: created pod pod-service-account-nomountsa
Apr  8 14:23:16.037: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Apr  8 14:23:16.041: INFO: created pod pod-service-account-defaultsa-mountspec
Apr  8 14:23:16.041: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Apr  8 14:23:16.045: INFO: created pod pod-service-account-mountsa-mountspec
Apr  8 14:23:16.045: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Apr  8 14:23:16.063: INFO: created pod pod-service-account-nomountsa-mountspec
Apr  8 14:23:16.063: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Apr  8 14:23:16.108: INFO: created pod pod-service-account-defaultsa-nomountspec
Apr  8 14:23:16.108: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Apr  8 14:23:16.130: INFO: created pod pod-service-account-mountsa-nomountspec
Apr  8 14:23:16.130: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Apr  8 14:23:16.136: INFO: created pod pod-service-account-nomountsa-nomountspec
Apr  8 14:23:16.136: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:23:16.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-7153" for this suite.
Apr  8 14:23:40.215: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:23:40.353: INFO: namespace svcaccounts-7153 deletion completed in 24.212785177s
â€¢SSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:23:40.353: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-4078
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Apr  8 14:23:40.498: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr  8 14:23:40.506: INFO: Waiting for terminating namespaces to be deleted...
Apr  8 14:23:40.510: INFO: 
Logging pods the kubelet thinks is on node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw before test
Apr  8 14:23:40.526: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-754f8f5dcb-scvf9 from kube-system started at 2019-04-08 13:54:14 +0000 UTC (1 container statuses recorded)
Apr  8 14:23:40.526: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Apr  8 14:23:40.526: INFO: metrics-server-bbc67f984-2cbzt from kube-system started at 2019-04-08 13:54:16 +0000 UTC (1 container statuses recorded)
Apr  8 14:23:40.526: INFO: 	Container metrics-server ready: true, restart count 0
Apr  8 14:23:40.526: INFO: coredns-7f7f7978c8-2cw6g from kube-system started at 2019-04-08 13:54:16 +0000 UTC (1 container statuses recorded)
Apr  8 14:23:40.526: INFO: 	Container coredns ready: true, restart count 0
Apr  8 14:23:40.526: INFO: node-exporter-52tc5 from kube-system started at 2019-04-08 13:53:56 +0000 UTC (1 container statuses recorded)
Apr  8 14:23:40.526: INFO: 	Container node-exporter ready: true, restart count 0
Apr  8 14:23:40.526: INFO: addons-nginx-ingress-controller-d4f8c9cc5-dz84h from kube-system started at 2019-04-08 13:54:14 +0000 UTC (1 container statuses recorded)
Apr  8 14:23:40.526: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Apr  8 14:23:40.526: INFO: vpn-shoot-846bd99d6c-frws7 from kube-system started at 2019-04-08 13:54:14 +0000 UTC (1 container statuses recorded)
Apr  8 14:23:40.526: INFO: 	Container vpn-shoot ready: true, restart count 0
Apr  8 14:23:40.526: INFO: coredns-7f7f7978c8-jpqwt from kube-system started at 2019-04-08 13:54:14 +0000 UTC (1 container statuses recorded)
Apr  8 14:23:40.526: INFO: 	Container coredns ready: true, restart count 0
Apr  8 14:23:40.526: INFO: blackbox-exporter-6dc58dcffc-kddgs from kube-system started at 2019-04-08 13:53:56 +0000 UTC (1 container statuses recorded)
Apr  8 14:23:40.526: INFO: 	Container blackbox-exporter ready: true, restart count 0
Apr  8 14:23:40.526: INFO: calico-node-rhz9g from kube-system started at 2019-04-08 13:53:56 +0000 UTC (1 container statuses recorded)
Apr  8 14:23:40.526: INFO: 	Container calico-node ready: true, restart count 0
Apr  8 14:23:40.526: INFO: kube-proxy-zwjh7 from kube-system started at 2019-04-08 13:53:56 +0000 UTC (1 container statuses recorded)
Apr  8 14:23:40.526: INFO: 	Container kube-proxy ready: true, restart count 0
Apr  8 14:23:40.526: INFO: addons-kubernetes-dashboard-665df4b66d-w6dfr from kube-system started at 2019-04-08 13:54:14 +0000 UTC (1 container statuses recorded)
Apr  8 14:23:40.526: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Apr  8 14:23:40.526: INFO: 
Logging pods the kubelet thinks is on node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw before test
Apr  8 14:23:40.576: INFO: calico-node-nk88t from kube-system started at 2019-04-08 13:53:55 +0000 UTC (1 container statuses recorded)
Apr  8 14:23:40.576: INFO: 	Container calico-node ready: true, restart count 0
Apr  8 14:23:40.576: INFO: node-exporter-j4f9g from kube-system started at 2019-04-08 13:53:55 +0000 UTC (1 container statuses recorded)
Apr  8 14:23:40.576: INFO: 	Container node-exporter ready: true, restart count 0
Apr  8 14:23:40.576: INFO: kube-proxy-txjx7 from kube-system started at 2019-04-08 13:53:55 +0000 UTC (1 container statuses recorded)
Apr  8 14:23:40.576: INFO: 	Container kube-proxy ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.159385cf07224cfc], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:23:41.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4078" for this suite.
Apr  8 14:23:47.623: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:23:47.759: INFO: namespace sched-pred-4078 deletion completed in 6.152445934s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:23:47.759: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-7225
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0408 14:24:27.946043    5043 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr  8 14:24:27.946: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:24:27.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7225" for this suite.
Apr  8 14:24:33.961: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:24:34.116: INFO: namespace gc-7225 deletion completed in 6.166942082s
â€¢SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:24:34.117: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7659
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-080ba1bb-5a0a-11e9-b9a9-e6698ebc8bdf
STEP: Creating a pod to test consume secrets
Apr  8 14:24:34.277: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-080c28ec-5a0a-11e9-b9a9-e6698ebc8bdf" in namespace "projected-7659" to be "success or failure"
Apr  8 14:24:34.282: INFO: Pod "pod-projected-secrets-080c28ec-5a0a-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.960485ms
Apr  8 14:24:36.286: INFO: Pod "pod-projected-secrets-080c28ec-5a0a-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009551997s
STEP: Saw pod success
Apr  8 14:24:36.286: INFO: Pod "pod-projected-secrets-080c28ec-5a0a-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 14:24:36.290: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-projected-secrets-080c28ec-5a0a-11e9-b9a9-e6698ebc8bdf container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr  8 14:24:36.308: INFO: Waiting for pod pod-projected-secrets-080c28ec-5a0a-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 14:24:36.310: INFO: Pod pod-projected-secrets-080c28ec-5a0a-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:24:36.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7659" for this suite.
Apr  8 14:24:42.326: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:24:42.445: INFO: namespace projected-7659 deletion completed in 6.130392325s
â€¢S
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:24:42.445: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-1144
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Apr  8 14:24:43.760: INFO: Pod name wrapped-volume-race-0daa641c-5a0a-11e9-b9a9-e6698ebc8bdf: Found 0 pods out of 5
Apr  8 14:24:48.785: INFO: Pod name wrapped-volume-race-0daa641c-5a0a-11e9-b9a9-e6698ebc8bdf: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-0daa641c-5a0a-11e9-b9a9-e6698ebc8bdf in namespace emptydir-wrapper-1144, will wait for the garbage collector to delete the pods
Apr  8 14:24:56.894: INFO: Deleting ReplicationController wrapped-volume-race-0daa641c-5a0a-11e9-b9a9-e6698ebc8bdf took: 8.000092ms
Apr  8 14:24:56.994: INFO: Terminating ReplicationController wrapped-volume-race-0daa641c-5a0a-11e9-b9a9-e6698ebc8bdf pods took: 100.306746ms
STEP: Creating RC which spawns configmap-volume pods
Apr  8 14:25:33.810: INFO: Pod name wrapped-volume-race-2b86f0c4-5a0a-11e9-b9a9-e6698ebc8bdf: Found 0 pods out of 5
Apr  8 14:25:38.826: INFO: Pod name wrapped-volume-race-2b86f0c4-5a0a-11e9-b9a9-e6698ebc8bdf: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-2b86f0c4-5a0a-11e9-b9a9-e6698ebc8bdf in namespace emptydir-wrapper-1144, will wait for the garbage collector to delete the pods
Apr  8 14:25:38.916: INFO: Deleting ReplicationController wrapped-volume-race-2b86f0c4-5a0a-11e9-b9a9-e6698ebc8bdf took: 7.941972ms
Apr  8 14:25:39.316: INFO: Terminating ReplicationController wrapped-volume-race-2b86f0c4-5a0a-11e9-b9a9-e6698ebc8bdf pods took: 400.309178ms
STEP: Creating RC which spawns configmap-volume pods
Apr  8 14:26:23.933: INFO: Pod name wrapped-volume-race-4966f306-5a0a-11e9-b9a9-e6698ebc8bdf: Found 0 pods out of 5
Apr  8 14:26:28.946: INFO: Pod name wrapped-volume-race-4966f306-5a0a-11e9-b9a9-e6698ebc8bdf: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-4966f306-5a0a-11e9-b9a9-e6698ebc8bdf in namespace emptydir-wrapper-1144, will wait for the garbage collector to delete the pods
Apr  8 14:26:29.056: INFO: Deleting ReplicationController wrapped-volume-race-4966f306-5a0a-11e9-b9a9-e6698ebc8bdf took: 7.675865ms
Apr  8 14:26:29.556: INFO: Terminating ReplicationController wrapped-volume-race-4966f306-5a0a-11e9-b9a9-e6698ebc8bdf pods took: 500.442271ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:27:14.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-1144" for this suite.
Apr  8 14:27:20.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:27:21.015: INFO: namespace emptydir-wrapper-1144 deletion completed in 6.187112044s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:27:21.016: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-9436
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Apr  8 14:27:21.163: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:27:24.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9436" for this suite.
Apr  8 14:27:31.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:27:31.604: INFO: namespace init-container-9436 deletion completed in 6.60118059s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:27:31.604: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3592
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-71e1895c-5a0a-11e9-b9a9-e6698ebc8bdf
STEP: Creating configMap with name cm-test-opt-upd-71e18997-5a0a-11e9-b9a9-e6698ebc8bdf
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-71e1895c-5a0a-11e9-b9a9-e6698ebc8bdf
STEP: Updating configmap cm-test-opt-upd-71e18997-5a0a-11e9-b9a9-e6698ebc8bdf
STEP: Creating configMap with name cm-test-opt-create-71e189ab-5a0a-11e9-b9a9-e6698ebc8bdf
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:28:57.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3592" for this suite.
Apr  8 14:29:19.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:29:19.730: INFO: namespace configmap-3592 deletion completed in 22.719863489s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:29:19.730: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-2291
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Apr  8 14:29:20.130: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-2291,SelfLink:/api/v1/namespaces/watch-2291/configmaps/e2e-watch-test-resource-version,UID:b2573fba-5a0a-11e9-8aed-4ea023eb3a48,ResourceVersion:6585,Generation:0,CreationTimestamp:2019-04-08 14:29:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr  8 14:29:20.130: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-2291,SelfLink:/api/v1/namespaces/watch-2291/configmaps/e2e-watch-test-resource-version,UID:b2573fba-5a0a-11e9-8aed-4ea023eb3a48,ResourceVersion:6586,Generation:0,CreationTimestamp:2019-04-08 14:29:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:29:20.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2291" for this suite.
Apr  8 14:29:26.224: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:29:26.878: INFO: namespace watch-2291 deletion completed in 6.724420704s
â€¢SSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:29:26.878: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-5830
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  8 14:29:27.053: INFO: Pod name rollover-pod: Found 0 pods out of 1
Apr  8 14:29:32.073: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr  8 14:29:32.073: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Apr  8 14:29:34.077: INFO: Creating deployment "test-rollover-deployment"
Apr  8 14:29:34.086: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Apr  8 14:29:36.097: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Apr  8 14:29:36.104: INFO: Ensure that both replica sets have 1 created replica
Apr  8 14:29:36.112: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Apr  8 14:29:36.120: INFO: Updating deployment test-rollover-deployment
Apr  8 14:29:36.120: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Apr  8 14:29:38.146: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Apr  8 14:29:38.187: INFO: Make sure deployment "test-rollover-deployment" is complete
Apr  8 14:29:38.234: INFO: all replica sets need to contain the pod-template-hash label
Apr  8 14:29:38.234: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690330574, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690330574, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690330577, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690330574, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  8 14:29:40.244: INFO: all replica sets need to contain the pod-template-hash label
Apr  8 14:29:40.245: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690330574, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690330574, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690330577, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690330574, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  8 14:29:42.244: INFO: all replica sets need to contain the pod-template-hash label
Apr  8 14:29:42.244: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690330574, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690330574, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690330577, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690330574, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  8 14:29:44.267: INFO: all replica sets need to contain the pod-template-hash label
Apr  8 14:29:44.267: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690330574, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690330574, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690330577, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690330574, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  8 14:29:46.243: INFO: all replica sets need to contain the pod-template-hash label
Apr  8 14:29:46.243: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690330574, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690330574, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690330577, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690330574, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  8 14:29:48.244: INFO: 
Apr  8 14:29:48.244: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr  8 14:29:48.254: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-5830,SelfLink:/apis/apps/v1/namespaces/deployment-5830/deployments/test-rollover-deployment,UID:bac042d8-5a0a-11e9-8aed-4ea023eb3a48,ResourceVersion:6707,Generation:2,CreationTimestamp:2019-04-08 14:29:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-04-08 14:29:34 +0000 UTC 2019-04-08 14:29:34 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-04-08 14:29:47 +0000 UTC 2019-04-08 14:29:34 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-766b4d6c9d" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Apr  8 14:29:48.258: INFO: New ReplicaSet "test-rollover-deployment-766b4d6c9d" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-766b4d6c9d,GenerateName:,Namespace:deployment-5830,SelfLink:/apis/apps/v1/namespaces/deployment-5830/replicasets/test-rollover-deployment-766b4d6c9d,UID:bbf7cf60-5a0a-11e9-8aed-4ea023eb3a48,ResourceVersion:6700,Generation:2,CreationTimestamp:2019-04-08 14:29:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment bac042d8-5a0a-11e9-8aed-4ea023eb3a48 0xc001620ae7 0xc001620ae8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Apr  8 14:29:48.258: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Apr  8 14:29:48.258: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-5830,SelfLink:/apis/apps/v1/namespaces/deployment-5830/replicasets/test-rollover-controller,UID:b68ec80a-5a0a-11e9-8aed-4ea023eb3a48,ResourceVersion:6706,Generation:2,CreationTimestamp:2019-04-08 14:29:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment bac042d8-5a0a-11e9-8aed-4ea023eb3a48 0xc00162093f 0xc001620950}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr  8 14:29:48.258: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6455657675,GenerateName:,Namespace:deployment-5830,SelfLink:/apis/apps/v1/namespaces/deployment-5830/replicasets/test-rollover-deployment-6455657675,UID:bac2203f-5a0a-11e9-8aed-4ea023eb3a48,ResourceVersion:6664,Generation:2,CreationTimestamp:2019-04-08 14:29:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment bac042d8-5a0a-11e9-8aed-4ea023eb3a48 0xc001620a17 0xc001620a18}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr  8 14:29:48.262: INFO: Pod "test-rollover-deployment-766b4d6c9d-b8tdk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-766b4d6c9d-b8tdk,GenerateName:test-rollover-deployment-766b4d6c9d-,Namespace:deployment-5830,SelfLink:/api/v1/namespaces/deployment-5830/pods/test-rollover-deployment-766b4d6c9d-b8tdk,UID:bbfafa5f-5a0a-11e9-8aed-4ea023eb3a48,ResourceVersion:6676,Generation:0,CreationTimestamp:2019-04-08 14:29:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.45/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-766b4d6c9d bbf7cf60-5a0a-11e9-8aed-4ea023eb3a48 0xc0027e95b7 0xc0027e95b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-rcvcm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rcvcm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-rcvcm true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027e9620} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027e9640}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:29:36 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:29:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:29:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:29:36 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.16,PodIP:100.96.1.45,StartTime:2019-04-08 14:29:36 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-04-08 14:29:36 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://7646ab40108af13260fb29e3976fe5308a432b2b89cecce1706b574c8a12d407}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:29:48.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5830" for this suite.
Apr  8 14:29:54.280: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:29:54.402: INFO: namespace deployment-5830 deletion completed in 6.134405006s
â€¢S
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:29:54.402: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-162
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-162
Apr  8 14:29:56.574: INFO: Started pod liveness-exec in namespace container-probe-162
STEP: checking the pod's current state and verifying that restartCount is present
Apr  8 14:29:56.589: INFO: Initial restart count of pod liveness-exec is 0
Apr  8 14:30:50.868: INFO: Restart count of pod container-probe-162/liveness-exec is now 1 (54.27873339s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:30:50.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-162" for this suite.
Apr  8 14:30:56.905: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:30:57.093: INFO: namespace container-probe-162 deletion completed in 6.206606622s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:30:57.093: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3678
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  8 14:30:57.245: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ec5076d8-5a0a-11e9-b9a9-e6698ebc8bdf" in namespace "projected-3678" to be "success or failure"
Apr  8 14:30:57.250: INFO: Pod "downwardapi-volume-ec5076d8-5a0a-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 5.738388ms
Apr  8 14:30:59.256: INFO: Pod "downwardapi-volume-ec5076d8-5a0a-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011228821s
STEP: Saw pod success
Apr  8 14:30:59.256: INFO: Pod "downwardapi-volume-ec5076d8-5a0a-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 14:30:59.262: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod downwardapi-volume-ec5076d8-5a0a-11e9-b9a9-e6698ebc8bdf container client-container: <nil>
STEP: delete the pod
Apr  8 14:30:59.297: INFO: Waiting for pod downwardapi-volume-ec5076d8-5a0a-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 14:30:59.300: INFO: Pod downwardapi-volume-ec5076d8-5a0a-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:30:59.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3678" for this suite.
Apr  8 14:31:05.321: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:31:05.528: INFO: namespace projected-3678 deletion completed in 6.224016382s
â€¢SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:31:05.529: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1569
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1455
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr  8 14:31:05.680: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=kubectl-1569'
Apr  8 14:31:06.054: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Apr  8 14:31:06.054: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1460
Apr  8 14:31:08.117: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config delete deployment e2e-test-nginx-deployment --namespace=kubectl-1569'
Apr  8 14:31:08.521: INFO: stderr: ""
Apr  8 14:31:08.521: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:31:08.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1569" for this suite.
Apr  8 14:31:30.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:31:31.707: INFO: namespace kubectl-1569 deletion completed in 23.144262104s
â€¢
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:31:31.707: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9072
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  8 14:31:31.980: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0101d6c1-5a0b-11e9-b9a9-e6698ebc8bdf" in namespace "downward-api-9072" to be "success or failure"
Apr  8 14:31:32.025: INFO: Pod "downwardapi-volume-0101d6c1-5a0b-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 45.311553ms
Apr  8 14:31:34.030: INFO: Pod "downwardapi-volume-0101d6c1-5a0b-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.050464216s
STEP: Saw pod success
Apr  8 14:31:34.030: INFO: Pod "downwardapi-volume-0101d6c1-5a0b-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 14:31:34.035: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod downwardapi-volume-0101d6c1-5a0b-11e9-b9a9-e6698ebc8bdf container client-container: <nil>
STEP: delete the pod
Apr  8 14:31:34.075: INFO: Waiting for pod downwardapi-volume-0101d6c1-5a0b-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 14:31:34.078: INFO: Pod downwardapi-volume-0101d6c1-5a0b-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:31:34.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9072" for this suite.
Apr  8 14:31:40.097: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:31:40.221: INFO: namespace downward-api-9072 deletion completed in 6.139062222s
â€¢SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:31:40.221: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-580
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1583
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr  8 14:31:40.372: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-580'
Apr  8 14:31:41.920: INFO: stderr: ""
Apr  8 14:31:41.920: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1588
Apr  8 14:31:41.925: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config delete pods e2e-test-nginx-pod --namespace=kubectl-580'
Apr  8 14:31:43.039: INFO: stderr: ""
Apr  8 14:31:43.039: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:31:43.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-580" for this suite.
Apr  8 14:31:49.108: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:31:50.160: INFO: namespace kubectl-580 deletion completed in 7.107025178s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:31:50.161: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2519
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Apr  8 14:31:50.419: INFO: Waiting up to 5m0s for pod "pod-0bffafe1-5a0b-11e9-b9a9-e6698ebc8bdf" in namespace "emptydir-2519" to be "success or failure"
Apr  8 14:31:50.439: INFO: Pod "pod-0bffafe1-5a0b-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 20.289136ms
Apr  8 14:31:52.444: INFO: Pod "pod-0bffafe1-5a0b-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025546054s
STEP: Saw pod success
Apr  8 14:31:52.444: INFO: Pod "pod-0bffafe1-5a0b-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 14:31:52.448: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-0bffafe1-5a0b-11e9-b9a9-e6698ebc8bdf container test-container: <nil>
STEP: delete the pod
Apr  8 14:31:52.470: INFO: Waiting for pod pod-0bffafe1-5a0b-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 14:31:52.473: INFO: Pod pod-0bffafe1-5a0b-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:31:52.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2519" for this suite.
Apr  8 14:31:58.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:31:58.651: INFO: namespace emptydir-2519 deletion completed in 6.174033418s
â€¢SSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:31:58.651: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-5318
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:31:58.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5318" for this suite.
Apr  8 14:32:04.820: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:32:05.028: INFO: namespace services-5318 deletion completed in 6.222198174s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:32:05.028: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1442
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap that has name configmap-test-emptyKey-14e1c263-5a0b-11e9-b9a9-e6698ebc8bdf
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:32:05.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1442" for this suite.
Apr  8 14:32:11.318: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:32:11.476: INFO: namespace configmap-1442 deletion completed in 6.16976965s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:32:11.476: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-5986
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-5986
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Apr  8 14:32:11.770: INFO: Found 0 stateful pods, waiting for 3
Apr  8 14:32:21.775: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr  8 14:32:21.775: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr  8 14:32:21.775: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Apr  8 14:32:21.805: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Apr  8 14:32:31.901: INFO: Updating stateful set ss2
Apr  8 14:32:31.939: INFO: Waiting for Pod statefulset-5986/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Apr  8 14:32:42.045: INFO: Found 1 stateful pods, waiting for 3
Apr  8 14:32:52.068: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr  8 14:32:52.068: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr  8 14:32:52.068: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Apr  8 14:32:52.096: INFO: Updating stateful set ss2
Apr  8 14:32:52.104: INFO: Waiting for Pod statefulset-5986/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr  8 14:33:02.204: INFO: Updating stateful set ss2
Apr  8 14:33:02.243: INFO: Waiting for StatefulSet statefulset-5986/ss2 to complete update
Apr  8 14:33:02.243: INFO: Waiting for Pod statefulset-5986/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr  8 14:33:12.252: INFO: Waiting for StatefulSet statefulset-5986/ss2 to complete update
Apr  8 14:33:12.252: INFO: Waiting for Pod statefulset-5986/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr  8 14:33:22.251: INFO: Deleting all statefulset in ns statefulset-5986
Apr  8 14:33:22.255: INFO: Scaling statefulset ss2 to 0
Apr  8 14:33:52.272: INFO: Waiting for statefulset status.replicas updated to 0
Apr  8 14:33:52.275: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:33:52.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5986" for this suite.
Apr  8 14:33:58.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:33:58.460: INFO: namespace statefulset-5986 deletion completed in 6.168600543s
â€¢SSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:33:58.460: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7557
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name projected-secret-test-586cc477-5a0b-11e9-b9a9-e6698ebc8bdf
STEP: Creating a pod to test consume secrets
Apr  8 14:33:58.633: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-586df081-5a0b-11e9-b9a9-e6698ebc8bdf" in namespace "projected-7557" to be "success or failure"
Apr  8 14:33:58.636: INFO: Pod "pod-projected-secrets-586df081-5a0b-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 3.315327ms
Apr  8 14:34:00.641: INFO: Pod "pod-projected-secrets-586df081-5a0b-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008159279s
STEP: Saw pod success
Apr  8 14:34:00.641: INFO: Pod "pod-projected-secrets-586df081-5a0b-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 14:34:00.645: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-projected-secrets-586df081-5a0b-11e9-b9a9-e6698ebc8bdf container secret-volume-test: <nil>
STEP: delete the pod
Apr  8 14:34:00.669: INFO: Waiting for pod pod-projected-secrets-586df081-5a0b-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 14:34:00.672: INFO: Pod pod-projected-secrets-586df081-5a0b-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:34:00.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7557" for this suite.
Apr  8 14:34:06.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:34:07.022: INFO: namespace projected-7557 deletion completed in 6.345969406s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:34:07.022: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5615
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  8 14:34:07.248: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config version'
Apr  8 14:34:07.557: INFO: stderr: ""
Apr  8 14:34:07.557: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.3\", GitCommit:\"435f92c719f279a3a67808c80521ea17d5715c66\", GitTreeState:\"clean\", BuildDate:\"2018-11-26T12:57:14Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.0\", GitCommit:\"641856db18352033a0d96dbc99153fa3b27298e5\", GitTreeState:\"clean\", BuildDate:\"2019-03-25T15:45:25Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:34:07.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5615" for this suite.
Apr  8 14:34:13.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:34:14.375: INFO: namespace kubectl-5615 deletion completed in 6.797120914s
â€¢SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:34:14.376: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-958
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-958
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr  8 14:34:14.720: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr  8 14:34:36.994: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.96.0.44 8081 | grep -v '^\s*$'] Namespace:pod-network-test-958 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  8 14:34:36.994: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
Apr  8 14:34:38.468: INFO: Found all expected endpoints: [netserver-0]
Apr  8 14:34:38.480: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.96.1.59 8081 | grep -v '^\s*$'] Namespace:pod-network-test-958 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  8 14:34:38.480: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
Apr  8 14:34:39.966: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:34:39.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-958" for this suite.
Apr  8 14:35:02.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:35:02.717: INFO: namespace pod-network-test-958 deletion completed in 22.746891066s
â€¢SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:35:02.717: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-744
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Apr  8 14:35:02.919: INFO: Number of nodes with available pods: 0
Apr  8 14:35:02.920: INFO: Node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw is running more than one daemon pod
Apr  8 14:35:03.930: INFO: Number of nodes with available pods: 0
Apr  8 14:35:03.930: INFO: Node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw is running more than one daemon pod
Apr  8 14:35:04.931: INFO: Number of nodes with available pods: 2
Apr  8 14:35:04.931: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Apr  8 14:35:04.952: INFO: Number of nodes with available pods: 1
Apr  8 14:35:04.952: INFO: Node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw is running more than one daemon pod
Apr  8 14:35:05.962: INFO: Number of nodes with available pods: 1
Apr  8 14:35:05.962: INFO: Node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw is running more than one daemon pod
Apr  8 14:35:07.209: INFO: Number of nodes with available pods: 2
Apr  8 14:35:07.209: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-744, will wait for the garbage collector to delete the pods
Apr  8 14:35:07.345: INFO: Deleting DaemonSet.extensions daemon-set took: 25.907374ms
Apr  8 14:35:07.745: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.24859ms
Apr  8 14:35:14.754: INFO: Number of nodes with available pods: 0
Apr  8 14:35:14.754: INFO: Number of running nodes: 0, number of available pods: 0
Apr  8 14:35:14.763: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-744/daemonsets","resourceVersion":"7847"},"items":null}

Apr  8 14:35:14.770: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-744/pods","resourceVersion":"7847"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:35:14.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-744" for this suite.
Apr  8 14:35:20.819: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:35:20.949: INFO: namespace daemonsets-744 deletion completed in 6.144239042s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:35:20.949: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-6888
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-6888
Apr  8 14:35:25.127: INFO: Started pod liveness-http in namespace container-probe-6888
STEP: checking the pod's current state and verifying that restartCount is present
Apr  8 14:35:25.149: INFO: Initial restart count of pod liveness-http is 0
Apr  8 14:35:47.261: INFO: Restart count of pod container-probe-6888/liveness-http is now 1 (22.11175407s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:35:47.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6888" for this suite.
Apr  8 14:35:53.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:35:53.406: INFO: namespace container-probe-6888 deletion completed in 6.132629721s
â€¢S
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:35:53.406: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2012
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the initial replication controller
Apr  8 14:35:53.554: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config create -f - --namespace=kubectl-2012'
Apr  8 14:35:53.782: INFO: stderr: ""
Apr  8 14:35:53.782: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr  8 14:35:53.782: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2012'
Apr  8 14:35:53.906: INFO: stderr: ""
Apr  8 14:35:53.906: INFO: stdout: "update-demo-nautilus-85b2j update-demo-nautilus-x4vlj "
Apr  8 14:35:53.906: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-85b2j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2012'
Apr  8 14:35:54.038: INFO: stderr: ""
Apr  8 14:35:54.038: INFO: stdout: ""
Apr  8 14:35:54.038: INFO: update-demo-nautilus-85b2j is created but not running
Apr  8 14:35:59.038: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2012'
Apr  8 14:35:59.147: INFO: stderr: ""
Apr  8 14:35:59.147: INFO: stdout: "update-demo-nautilus-85b2j update-demo-nautilus-x4vlj "
Apr  8 14:35:59.147: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-85b2j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2012'
Apr  8 14:35:59.247: INFO: stderr: ""
Apr  8 14:35:59.247: INFO: stdout: "true"
Apr  8 14:35:59.247: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-85b2j -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2012'
Apr  8 14:35:59.352: INFO: stderr: ""
Apr  8 14:35:59.352: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  8 14:35:59.352: INFO: validating pod update-demo-nautilus-85b2j
Apr  8 14:35:59.436: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  8 14:35:59.436: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  8 14:35:59.436: INFO: update-demo-nautilus-85b2j is verified up and running
Apr  8 14:35:59.436: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-x4vlj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2012'
Apr  8 14:35:59.552: INFO: stderr: ""
Apr  8 14:35:59.552: INFO: stdout: "true"
Apr  8 14:35:59.552: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-x4vlj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2012'
Apr  8 14:35:59.658: INFO: stderr: ""
Apr  8 14:35:59.658: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  8 14:35:59.658: INFO: validating pod update-demo-nautilus-x4vlj
Apr  8 14:35:59.744: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  8 14:35:59.744: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  8 14:35:59.744: INFO: update-demo-nautilus-x4vlj is verified up and running
STEP: rolling-update to new replication controller
Apr  8 14:35:59.749: INFO: scanned /root for discovery docs: <nil>
Apr  8 14:35:59.749: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-2012'
Apr  8 14:36:21.349: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Apr  8 14:36:21.349: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr  8 14:36:21.349: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2012'
Apr  8 14:36:21.467: INFO: stderr: ""
Apr  8 14:36:21.467: INFO: stdout: "update-demo-kitten-sr289 update-demo-kitten-z7nlv "
Apr  8 14:36:21.467: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-kitten-sr289 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2012'
Apr  8 14:36:21.614: INFO: stderr: ""
Apr  8 14:36:21.614: INFO: stdout: "true"
Apr  8 14:36:21.614: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-kitten-sr289 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2012'
Apr  8 14:36:21.730: INFO: stderr: ""
Apr  8 14:36:21.730: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Apr  8 14:36:21.730: INFO: validating pod update-demo-kitten-sr289
Apr  8 14:36:21.816: INFO: got data: {
  "image": "kitten.jpg"
}

Apr  8 14:36:21.816: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Apr  8 14:36:21.816: INFO: update-demo-kitten-sr289 is verified up and running
Apr  8 14:36:21.816: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-kitten-z7nlv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2012'
Apr  8 14:36:21.931: INFO: stderr: ""
Apr  8 14:36:21.931: INFO: stdout: "true"
Apr  8 14:36:21.931: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-kitten-z7nlv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2012'
Apr  8 14:36:22.049: INFO: stderr: ""
Apr  8 14:36:22.049: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Apr  8 14:36:22.049: INFO: validating pod update-demo-kitten-z7nlv
Apr  8 14:36:22.136: INFO: got data: {
  "image": "kitten.jpg"
}

Apr  8 14:36:22.136: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Apr  8 14:36:22.136: INFO: update-demo-kitten-z7nlv is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:36:22.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2012" for this suite.
Apr  8 14:36:44.170: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:36:44.535: INFO: namespace kubectl-2012 deletion completed in 22.39435224s
â€¢SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:36:44.535: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3151
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting the proxy server
Apr  8 14:36:44.766: INFO: Asynchronously running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:36:44.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3151" for this suite.
Apr  8 14:36:50.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:36:51.003: INFO: namespace kubectl-3151 deletion completed in 6.140737536s
â€¢SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:36:51.003: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1912
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1510
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr  8 14:36:51.157: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-1912'
Apr  8 14:36:51.292: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Apr  8 14:36:51.292: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1515
Apr  8 14:36:51.296: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config delete jobs e2e-test-nginx-job --namespace=kubectl-1912'
Apr  8 14:36:51.435: INFO: stderr: ""
Apr  8 14:36:51.435: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:36:51.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1912" for this suite.
Apr  8 14:36:57.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:36:57.573: INFO: namespace kubectl-1912 deletion completed in 6.133929357s
â€¢SSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:36:57.573: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-3278
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Apr  8 14:37:01.784: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr  8 14:37:01.790: INFO: Pod pod-with-poststart-http-hook still exists
Apr  8 14:37:03.790: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr  8 14:37:03.795: INFO: Pod pod-with-poststart-http-hook still exists
Apr  8 14:37:05.790: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr  8 14:37:05.796: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:37:05.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3278" for this suite.
Apr  8 14:37:27.814: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:37:27.932: INFO: namespace container-lifecycle-hook-3278 deletion completed in 22.130288346s
â€¢SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:37:27.932: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-162
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override command
Apr  8 14:37:28.086: INFO: Waiting up to 5m0s for pod "client-containers-d545e83e-5a0b-11e9-b9a9-e6698ebc8bdf" in namespace "containers-162" to be "success or failure"
Apr  8 14:37:28.092: INFO: Pod "client-containers-d545e83e-5a0b-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 6.341079ms
Apr  8 14:37:30.098: INFO: Pod "client-containers-d545e83e-5a0b-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011935932s
Apr  8 14:37:32.121: INFO: Pod "client-containers-d545e83e-5a0b-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034978619s
STEP: Saw pod success
Apr  8 14:37:32.121: INFO: Pod "client-containers-d545e83e-5a0b-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 14:37:32.143: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod client-containers-d545e83e-5a0b-11e9-b9a9-e6698ebc8bdf container test-container: <nil>
STEP: delete the pod
Apr  8 14:37:32.202: INFO: Waiting for pod client-containers-d545e83e-5a0b-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 14:37:32.222: INFO: Pod client-containers-d545e83e-5a0b-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:37:32.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-162" for this suite.
Apr  8 14:37:38.301: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:37:38.664: INFO: namespace containers-162 deletion completed in 6.422162583s
â€¢SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:37:38.664: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7004
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating secret secrets-7004/secret-test-dbaff50c-5a0b-11e9-b9a9-e6698ebc8bdf
STEP: Creating a pod to test consume secrets
Apr  8 14:37:38.858: INFO: Waiting up to 5m0s for pod "pod-configmaps-dbb1bd80-5a0b-11e9-b9a9-e6698ebc8bdf" in namespace "secrets-7004" to be "success or failure"
Apr  8 14:37:38.863: INFO: Pod "pod-configmaps-dbb1bd80-5a0b-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.90571ms
Apr  8 14:37:40.868: INFO: Pod "pod-configmaps-dbb1bd80-5a0b-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010200597s
STEP: Saw pod success
Apr  8 14:37:40.868: INFO: Pod "pod-configmaps-dbb1bd80-5a0b-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 14:37:40.872: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-configmaps-dbb1bd80-5a0b-11e9-b9a9-e6698ebc8bdf container env-test: <nil>
STEP: delete the pod
Apr  8 14:37:40.894: INFO: Waiting for pod pod-configmaps-dbb1bd80-5a0b-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 14:37:40.897: INFO: Pod pod-configmaps-dbb1bd80-5a0b-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:37:40.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7004" for this suite.
Apr  8 14:37:46.914: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:37:47.042: INFO: namespace secrets-7004 deletion completed in 6.141486611s
â€¢SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:37:47.042: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-2799
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-projected-l87n
STEP: Creating a pod to test atomic-volume-subpath
Apr  8 14:37:47.212: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-l87n" in namespace "subpath-2799" to be "success or failure"
Apr  8 14:37:47.217: INFO: Pod "pod-subpath-test-projected-l87n": Phase="Pending", Reason="", readiness=false. Elapsed: 4.814815ms
Apr  8 14:37:49.240: INFO: Pod "pod-subpath-test-projected-l87n": Phase="Running", Reason="", readiness=true. Elapsed: 2.027385188s
Apr  8 14:37:51.245: INFO: Pod "pod-subpath-test-projected-l87n": Phase="Running", Reason="", readiness=true. Elapsed: 4.032519011s
Apr  8 14:37:53.251: INFO: Pod "pod-subpath-test-projected-l87n": Phase="Running", Reason="", readiness=true. Elapsed: 6.038911227s
Apr  8 14:37:55.257: INFO: Pod "pod-subpath-test-projected-l87n": Phase="Running", Reason="", readiness=true. Elapsed: 8.044660259s
Apr  8 14:37:57.262: INFO: Pod "pod-subpath-test-projected-l87n": Phase="Running", Reason="", readiness=true. Elapsed: 10.049994657s
Apr  8 14:37:59.268: INFO: Pod "pod-subpath-test-projected-l87n": Phase="Running", Reason="", readiness=true. Elapsed: 12.055696964s
Apr  8 14:38:01.281: INFO: Pod "pod-subpath-test-projected-l87n": Phase="Running", Reason="", readiness=true. Elapsed: 14.068594294s
Apr  8 14:38:03.286: INFO: Pod "pod-subpath-test-projected-l87n": Phase="Running", Reason="", readiness=true. Elapsed: 16.073956375s
Apr  8 14:38:05.291: INFO: Pod "pod-subpath-test-projected-l87n": Phase="Running", Reason="", readiness=true. Elapsed: 18.078756071s
Apr  8 14:38:07.315: INFO: Pod "pod-subpath-test-projected-l87n": Phase="Running", Reason="", readiness=true. Elapsed: 20.102966706s
Apr  8 14:38:09.320: INFO: Pod "pod-subpath-test-projected-l87n": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.108149614s
STEP: Saw pod success
Apr  8 14:38:09.320: INFO: Pod "pod-subpath-test-projected-l87n" satisfied condition "success or failure"
Apr  8 14:38:09.324: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-subpath-test-projected-l87n container test-container-subpath-projected-l87n: <nil>
STEP: delete the pod
Apr  8 14:38:09.348: INFO: Waiting for pod pod-subpath-test-projected-l87n to disappear
Apr  8 14:38:09.352: INFO: Pod pod-subpath-test-projected-l87n no longer exists
STEP: Deleting pod pod-subpath-test-projected-l87n
Apr  8 14:38:09.352: INFO: Deleting pod "pod-subpath-test-projected-l87n" in namespace "subpath-2799"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:38:09.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2799" for this suite.
Apr  8 14:38:15.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:38:15.488: INFO: namespace subpath-2799 deletion completed in 6.128673562s
â€¢SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:38:15.488: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2810
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating all guestbook components
Apr  8 14:38:15.647: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Apr  8 14:38:15.647: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config create -f - --namespace=kubectl-2810'
Apr  8 14:38:15.894: INFO: stderr: ""
Apr  8 14:38:15.894: INFO: stdout: "service/redis-slave created\n"
Apr  8 14:38:15.894: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Apr  8 14:38:15.894: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config create -f - --namespace=kubectl-2810'
Apr  8 14:38:16.158: INFO: stderr: ""
Apr  8 14:38:16.158: INFO: stdout: "service/redis-master created\n"
Apr  8 14:38:16.159: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Apr  8 14:38:16.159: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config create -f - --namespace=kubectl-2810'
Apr  8 14:38:16.377: INFO: stderr: ""
Apr  8 14:38:16.377: INFO: stdout: "service/frontend created\n"
Apr  8 14:38:16.377: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Apr  8 14:38:16.377: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config create -f - --namespace=kubectl-2810'
Apr  8 14:38:16.597: INFO: stderr: ""
Apr  8 14:38:16.597: INFO: stdout: "deployment.apps/frontend created\n"
Apr  8 14:38:16.597: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Apr  8 14:38:16.597: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config create -f - --namespace=kubectl-2810'
Apr  8 14:38:16.827: INFO: stderr: ""
Apr  8 14:38:16.828: INFO: stdout: "deployment.apps/redis-master created\n"
Apr  8 14:38:16.828: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Apr  8 14:38:16.828: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config create -f - --namespace=kubectl-2810'
Apr  8 14:38:17.048: INFO: stderr: ""
Apr  8 14:38:17.048: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Apr  8 14:38:17.048: INFO: Waiting for all frontend pods to be Running.
Apr  8 14:38:37.101: INFO: Waiting for frontend to serve content.
Apr  8 14:38:42.245: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Apr  8 14:38:47.332: INFO: Trying to add a new entry to the guestbook.
Apr  8 14:38:47.452: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Apr  8 14:38:47.499: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-2810'
Apr  8 14:38:47.635: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  8 14:38:47.635: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Apr  8 14:38:47.635: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-2810'
Apr  8 14:38:47.772: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  8 14:38:47.772: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Apr  8 14:38:47.772: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-2810'
Apr  8 14:38:47.882: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  8 14:38:47.882: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Apr  8 14:38:47.882: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-2810'
Apr  8 14:38:48.000: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  8 14:38:48.000: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Apr  8 14:38:48.001: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-2810'
Apr  8 14:38:48.101: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  8 14:38:48.101: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Apr  8 14:38:48.102: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-2810'
Apr  8 14:38:48.202: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  8 14:38:48.202: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:38:48.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2810" for this suite.
Apr  8 14:39:26.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:39:26.683: INFO: namespace kubectl-2810 deletion completed in 38.476697637s
â€¢SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:39:26.684: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-846
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-846
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-846
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-846
Apr  8 14:39:26.857: INFO: Found 0 stateful pods, waiting for 1
Apr  8 14:39:36.883: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Apr  8 14:39:36.906: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  8 14:39:42.450: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  8 14:39:42.451: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  8 14:39:42.452: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr  8 14:39:42.458: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr  8 14:39:52.463: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr  8 14:39:52.463: INFO: Waiting for statefulset status.replicas updated to 0
Apr  8 14:39:52.477: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999783s
Apr  8 14:39:53.482: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.996102003s
Apr  8 14:39:54.486: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.991676439s
Apr  8 14:39:55.509: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.98716252s
Apr  8 14:39:56.522: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.964275542s
Apr  8 14:39:57.527: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.951150706s
Apr  8 14:39:58.533: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.946208027s
Apr  8 14:39:59.537: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.940886032s
Apr  8 14:40:00.546: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.93618021s
Apr  8 14:40:01.560: INFO: Verifying statefulset ss doesn't scale past 1 for another 927.507036ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-846
Apr  8 14:40:02.581: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  8 14:40:03.110: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr  8 14:40:03.110: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr  8 14:40:03.110: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr  8 14:40:03.115: INFO: Found 1 stateful pods, waiting for 3
Apr  8 14:40:13.121: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr  8 14:40:13.121: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr  8 14:40:13.121: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Apr  8 14:40:13.129: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  8 14:40:13.707: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  8 14:40:13.707: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  8 14:40:13.707: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr  8 14:40:13.707: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  8 14:40:14.415: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  8 14:40:14.415: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  8 14:40:14.415: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr  8 14:40:14.416: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  8 14:40:14.942: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  8 14:40:14.942: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  8 14:40:14.942: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr  8 14:40:14.942: INFO: Waiting for statefulset status.replicas updated to 0
Apr  8 14:40:14.946: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Apr  8 14:40:24.986: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr  8 14:40:24.986: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr  8 14:40:24.986: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr  8 14:40:25.038: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999662s
Apr  8 14:40:26.058: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.984107806s
Apr  8 14:40:27.063: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.964461972s
Apr  8 14:40:28.072: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.959550148s
Apr  8 14:40:29.082: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.950261154s
Apr  8 14:40:30.088: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.940846278s
Apr  8 14:40:31.107: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.934816816s
Apr  8 14:40:32.127: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.915701342s
Apr  8 14:40:33.133: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.895604994s
Apr  8 14:40:34.138: INFO: Verifying statefulset ss doesn't scale past 3 for another 889.783821ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-846
Apr  8 14:40:35.144: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  8 14:40:35.631: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr  8 14:40:35.631: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr  8 14:40:35.631: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr  8 14:40:35.631: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  8 14:40:36.140: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr  8 14:40:36.140: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr  8 14:40:36.140: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr  8 14:40:36.140: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  8 14:40:36.649: INFO: rc: 1
Apr  8 14:40:36.649: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl [kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: Internal error occurred: error executing command in container: container not running (988b956f047ce51ed8b1db5a40bba44e9bbfe0d51ce39ed735f1651816d4bb08)
 [] <nil> 0xc0024cf9e0 exit status 1 <nil> <nil> true [0xc001d9efb0 0xc001d9eff8 0xc001d9f080] [0xc001d9efb0 0xc001d9eff8 0xc001d9f080] [0xc001d9efd8 0xc001d9f040] [0x9bf9f0 0x9bf9f0] 0xc00234c300 <nil>}:
Command stdout:

stderr:
error: Internal error occurred: error executing command in container: container not running (988b956f047ce51ed8b1db5a40bba44e9bbfe0d51ce39ed735f1651816d4bb08)

error:
exit status 1

Apr  8 14:40:46.650: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  8 14:40:46.755: INFO: rc: 1
Apr  8 14:40:46.755: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl [kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002af8210 exit status 1 <nil> <nil> true [0xc000192010 0xc000192330 0xc000192410] [0xc000192010 0xc000192330 0xc000192410] [0xc000192308 0xc0001923f0] [0x9bf9f0 0x9bf9f0] 0xc00253ed80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr  8 14:40:56.755: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  8 14:40:56.852: INFO: rc: 1
Apr  8 14:40:56.853: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl [kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002af8480 exit status 1 <nil> <nil> true [0xc000192430 0xc0001927e0 0xc0001929a0] [0xc000192430 0xc0001927e0 0xc0001929a0] [0xc0001925a8 0xc000192908] [0x9bf9f0 0x9bf9f0] 0xc00253f800 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr  8 14:41:06.853: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  8 14:41:07.054: INFO: rc: 1
Apr  8 14:41:07.054: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl [kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0027ba210 exit status 1 <nil> <nil> true [0xc000010058 0xc000010950 0xc000010f28] [0xc000010058 0xc000010950 0xc000010f28] [0xc000010868 0xc000010e40] [0x9bf9f0 0x9bf9f0] 0xc0023605a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr  8 14:41:17.054: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  8 14:41:17.164: INFO: rc: 1
Apr  8 14:41:17.164: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl [kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0025e4330 exit status 1 <nil> <nil> true [0xc00019a2d0 0xc00019a558 0xc00019a8e8] [0xc00019a2d0 0xc00019a558 0xc00019a8e8] [0xc00019a480 0xc00019a760] [0x9bf9f0 0x9bf9f0] 0xc002272780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr  8 14:41:27.165: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  8 14:41:27.281: INFO: rc: 1
Apr  8 14:41:27.281: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl [kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002af86c0 exit status 1 <nil> <nil> true [0xc0001929c8 0xc000192a98 0xc000192ba0] [0xc0001929c8 0xc000192a98 0xc000192ba0] [0xc000192a40 0xc000192b68] [0x9bf9f0 0x9bf9f0] 0xc00253ff20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr  8 14:41:37.281: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  8 14:41:37.548: INFO: rc: 1
Apr  8 14:41:37.548: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl [kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0027ba7b0 exit status 1 <nil> <nil> true [0xc0000111d0 0xc0000114b8 0xc000011930] [0xc0000111d0 0xc0000114b8 0xc000011930] [0xc000011420 0xc000011758] [0x9bf9f0 0x9bf9f0] 0xc002360c00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr  8 14:41:47.548: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  8 14:41:47.644: INFO: rc: 1
Apr  8 14:41:47.644: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl [kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002182360 exit status 1 <nil> <nil> true [0xc001d9e050 0xc001d9e080 0xc001d9e0d0] [0xc001d9e050 0xc001d9e080 0xc001d9e0d0] [0xc001d9e068 0xc001d9e0c0] [0x9bf9f0 0x9bf9f0] 0xc002a50240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr  8 14:41:57.644: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  8 14:41:57.737: INFO: rc: 1
Apr  8 14:41:57.737: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl [kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0021825d0 exit status 1 <nil> <nil> true [0xc001d9e0e8 0xc001d9e128 0xc001d9e1a0] [0xc001d9e0e8 0xc001d9e128 0xc001d9e1a0] [0xc001d9e120 0xc001d9e180] [0x9bf9f0 0x9bf9f0] 0xc002a50540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr  8 14:42:07.738: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  8 14:42:07.865: INFO: rc: 1
Apr  8 14:42:07.865: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl [kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0025e4570 exit status 1 <nil> <nil> true [0xc00019aa48 0xc00019ad58 0xc00019ae58] [0xc00019aa48 0xc00019ad58 0xc00019ae58] [0xc00019abf0 0xc00019ade0] [0x9bf9f0 0x9bf9f0] 0xc0022732c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr  8 14:42:17.865: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  8 14:42:17.996: INFO: rc: 1
Apr  8 14:42:17.996: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl [kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0027ba9f0 exit status 1 <nil> <nil> true [0xc0000119b0 0xc000011a90 0xc000011b88] [0xc0000119b0 0xc000011a90 0xc000011b88] [0xc000011a70 0xc000011b50] [0x9bf9f0 0x9bf9f0] 0xc002361500 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr  8 14:42:27.996: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  8 14:42:28.098: INFO: rc: 1
Apr  8 14:42:28.098: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl [kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0025e4840 exit status 1 <nil> <nil> true [0xc00019aec0 0xc00019b020 0xc00019b1d0] [0xc00019aec0 0xc00019b020 0xc00019b1d0] [0xc00019afc8 0xc00019b188] [0x9bf9f0 0x9bf9f0] 0xc002273e00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr  8 14:42:38.099: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  8 14:42:38.272: INFO: rc: 1
Apr  8 14:42:38.272: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl [kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0027bac30 exit status 1 <nil> <nil> true [0xc000011bb0 0xc000011be0 0xc000011c80] [0xc000011bb0 0xc000011be0 0xc000011c80] [0xc000011bd0 0xc000011c70] [0x9bf9f0 0x9bf9f0] 0xc002361bc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr  8 14:42:48.272: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  8 14:42:48.432: INFO: rc: 1
Apr  8 14:42:48.432: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl [kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002af8240 exit status 1 <nil> <nil> true [0xc000192038 0xc0001923a0 0xc000192430] [0xc000192038 0xc0001923a0 0xc000192430] [0xc000192330 0xc000192410] [0x9bf9f0 0x9bf9f0] 0xc00253ed80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr  8 14:42:58.432: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  8 14:42:58.570: INFO: rc: 1
Apr  8 14:42:58.570: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl [kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002182330 exit status 1 <nil> <nil> true [0xc001d9e040 0xc001d9e068 0xc001d9e0c0] [0xc001d9e040 0xc001d9e068 0xc001d9e0c0] [0xc001d9e060 0xc001d9e0b0] [0x9bf9f0 0x9bf9f0] 0xc002590780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr  8 14:43:08.570: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  8 14:43:08.691: INFO: rc: 1
Apr  8 14:43:08.691: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl [kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002182600 exit status 1 <nil> <nil> true [0xc001d9e0d0 0xc001d9e120 0xc001d9e180] [0xc001d9e0d0 0xc001d9e120 0xc001d9e180] [0xc001d9e100 0xc001d9e150] [0x9bf9f0 0x9bf9f0] 0xc002590a80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr  8 14:43:18.692: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  8 14:43:23.831: INFO: rc: 1
Apr  8 14:43:23.831: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl [kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002af8510 exit status 1 <nil> <nil> true [0xc000192468 0xc000192810 0xc0001929c8] [0xc000192468 0xc000192810 0xc0001929c8] [0xc0001927e0 0xc0001929a0] [0x9bf9f0 0x9bf9f0] 0xc00253f800 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr  8 14:43:33.831: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  8 14:43:33.923: INFO: rc: 1
Apr  8 14:43:33.923: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl [kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0027ba240 exit status 1 <nil> <nil> true [0xc000010058 0xc000010950 0xc000010f28] [0xc000010058 0xc000010950 0xc000010f28] [0xc000010868 0xc000010e40] [0x9bf9f0 0x9bf9f0] 0xc002a50240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr  8 14:43:43.923: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  8 14:43:44.135: INFO: rc: 1
Apr  8 14:43:44.135: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl [kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002af87e0 exit status 1 <nil> <nil> true [0xc0001929d8 0xc000192b28 0xc000192c18] [0xc0001929d8 0xc000192b28 0xc000192c18] [0xc000192a98 0xc000192ba0] [0x9bf9f0 0x9bf9f0] 0xc00253ff20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr  8 14:43:54.136: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  8 14:43:54.262: INFO: rc: 1
Apr  8 14:43:54.262: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl [kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0027ba780 exit status 1 <nil> <nil> true [0xc0000111d0 0xc0000114b8 0xc000011930] [0xc0000111d0 0xc0000114b8 0xc000011930] [0xc000011420 0xc000011758] [0x9bf9f0 0x9bf9f0] 0xc002a50540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr  8 14:44:04.263: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  8 14:44:04.371: INFO: rc: 1
Apr  8 14:44:04.371: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl [kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002182870 exit status 1 <nil> <nil> true [0xc001d9e1a0 0xc001d9e1f0 0xc001d9e248] [0xc001d9e1a0 0xc001d9e1f0 0xc001d9e248] [0xc001d9e1d0 0xc001d9e240] [0x9bf9f0 0x9bf9f0] 0xc002590d80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr  8 14:44:14.371: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  8 14:44:14.549: INFO: rc: 1
Apr  8 14:44:14.550: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl [kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0025e4390 exit status 1 <nil> <nil> true [0xc00019a2d0 0xc00019a558 0xc00019a8e8] [0xc00019a2d0 0xc00019a558 0xc00019a8e8] [0xc00019a480 0xc00019a760] [0x9bf9f0 0x9bf9f0] 0xc002272780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr  8 14:44:24.550: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  8 14:44:24.697: INFO: rc: 1
Apr  8 14:44:24.697: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl [kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0025e4600 exit status 1 <nil> <nil> true [0xc00019aa48 0xc00019ad58 0xc00019ae58] [0xc00019aa48 0xc00019ad58 0xc00019ae58] [0xc00019abf0 0xc00019ade0] [0x9bf9f0 0x9bf9f0] 0xc0022732c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr  8 14:44:34.698: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  8 14:44:34.797: INFO: rc: 1
Apr  8 14:44:34.797: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl [kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002af8a20 exit status 1 <nil> <nil> true [0xc000192c20 0xc0001930d0 0xc000193168] [0xc000192c20 0xc0001930d0 0xc000193168] [0xc000192ce8 0xc000193128] [0x9bf9f0 0x9bf9f0] 0xc002360660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr  8 14:44:44.797: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  8 14:44:44.890: INFO: rc: 1
Apr  8 14:44:44.891: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl [kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0027baa50 exit status 1 <nil> <nil> true [0xc0000119b0 0xc000011a90 0xc000011b88] [0xc0000119b0 0xc000011a90 0xc000011b88] [0xc000011a70 0xc000011b50] [0x9bf9f0 0x9bf9f0] 0xc002a50840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr  8 14:44:54.891: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  8 14:44:55.050: INFO: rc: 1
Apr  8 14:44:55.050: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl [kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002182360 exit status 1 <nil> <nil> true [0xc001d9e050 0xc001d9e080 0xc001d9e0d0] [0xc001d9e050 0xc001d9e080 0xc001d9e0d0] [0xc001d9e068 0xc001d9e0c0] [0x9bf9f0 0x9bf9f0] 0xc00253ed80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr  8 14:45:05.050: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  8 14:45:05.151: INFO: rc: 1
Apr  8 14:45:05.151: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl [kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0027ba210 exit status 1 <nil> <nil> true [0xc000010058 0xc000010950 0xc000010f28] [0xc000010058 0xc000010950 0xc000010f28] [0xc000010868 0xc000010e40] [0x9bf9f0 0x9bf9f0] 0xc002a50240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr  8 14:45:15.151: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  8 14:45:15.249: INFO: rc: 1
Apr  8 14:45:15.249: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl [kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0025e4300 exit status 1 <nil> <nil> true [0xc00019a2d0 0xc00019a558 0xc00019a8e8] [0xc00019a2d0 0xc00019a558 0xc00019a8e8] [0xc00019a480 0xc00019a760] [0x9bf9f0 0x9bf9f0] 0xc002590780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr  8 14:45:25.250: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  8 14:45:25.379: INFO: rc: 1
Apr  8 14:45:25.379: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl [kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0025e4570 exit status 1 <nil> <nil> true [0xc00019aa48 0xc00019ad58 0xc00019ae58] [0xc00019aa48 0xc00019ad58 0xc00019ae58] [0xc00019abf0 0xc00019ade0] [0x9bf9f0 0x9bf9f0] 0xc002590a80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr  8 14:45:35.379: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  8 14:45:35.478: INFO: rc: 1
Apr  8 14:45:35.478: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl [kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0027ba810 exit status 1 <nil> <nil> true [0xc0000111d0 0xc0000114b8 0xc000011930] [0xc0000111d0 0xc0000114b8 0xc000011930] [0xc000011420 0xc000011758] [0x9bf9f0 0x9bf9f0] 0xc002a50540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Apr  8 14:45:45.479: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-846 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  8 14:45:55.627: INFO: rc: 1
Apr  8 14:45:55.627: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Apr  8 14:45:55.627: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr  8 14:45:55.753: INFO: Deleting all statefulset in ns statefulset-846
Apr  8 14:45:55.791: INFO: Scaling statefulset ss to 0
Apr  8 14:45:55.865: INFO: Waiting for statefulset status.replicas updated to 0
Apr  8 14:45:55.889: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:45:55.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-846" for this suite.
Apr  8 14:46:02.044: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:46:02.640: INFO: namespace statefulset-846 deletion completed in 6.663636232s

â€¢ [SLOW TEST:395.958 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:46:02.641: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-1302
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:69
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Registering the sample API server.
Apr  8 14:46:03.027: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Apr  8 14:46:05.074: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690331563, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690331563, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690331563, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690331563, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  8 14:46:07.093: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690331563, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690331563, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690331563, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690331563, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  8 14:46:09.080: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690331563, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690331563, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690331563, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690331563, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  8 14:46:11.204: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690331563, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690331563, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690331563, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690331563, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  8 14:46:14.349: INFO: Waited 1.243345184s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:60
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:46:15.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-1302" for this suite.
Apr  8 14:46:21.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:46:21.304: INFO: namespace aggregator-1302 deletion completed in 6.150613451s
â€¢SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:46:21.304: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-8320
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Apr  8 14:46:25.530: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  8 14:46:25.541: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  8 14:46:27.541: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  8 14:46:27.546: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  8 14:46:29.541: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  8 14:46:29.547: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  8 14:46:31.541: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  8 14:46:31.556: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  8 14:46:33.541: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  8 14:46:33.546: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  8 14:46:35.541: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  8 14:46:35.547: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  8 14:46:37.541: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  8 14:46:37.547: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  8 14:46:39.541: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  8 14:46:39.547: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  8 14:46:41.541: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  8 14:46:41.546: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  8 14:46:43.541: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  8 14:46:43.560: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  8 14:46:45.541: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  8 14:46:45.546: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  8 14:46:47.542: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  8 14:46:47.547: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  8 14:46:49.541: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  8 14:46:49.559: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  8 14:46:51.541: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  8 14:46:51.546: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  8 14:46:53.541: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  8 14:46:53.546: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  8 14:46:55.541: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  8 14:46:55.551: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:46:55.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8320" for this suite.
Apr  8 14:47:17.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:47:17.712: INFO: namespace container-lifecycle-hook-8320 deletion completed in 22.151651974s
â€¢SSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:47:17.712: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3972
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-34cfb998-5a0d-11e9-b9a9-e6698ebc8bdf
STEP: Creating a pod to test consume secrets
Apr  8 14:47:17.875: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-34d088ec-5a0d-11e9-b9a9-e6698ebc8bdf" in namespace "projected-3972" to be "success or failure"
Apr  8 14:47:17.880: INFO: Pod "pod-projected-secrets-34d088ec-5a0d-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 5.051745ms
Apr  8 14:47:19.904: INFO: Pod "pod-projected-secrets-34d088ec-5a0d-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028951184s
STEP: Saw pod success
Apr  8 14:47:19.904: INFO: Pod "pod-projected-secrets-34d088ec-5a0d-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 14:47:19.926: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-projected-secrets-34d088ec-5a0d-11e9-b9a9-e6698ebc8bdf container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr  8 14:47:19.979: INFO: Waiting for pod pod-projected-secrets-34d088ec-5a0d-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 14:47:19.998: INFO: Pod pod-projected-secrets-34d088ec-5a0d-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:47:19.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3972" for this suite.
Apr  8 14:47:26.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:47:26.487: INFO: namespace projected-3972 deletion completed in 6.470318939s
â€¢SS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:47:26.487: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3994
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr  8 14:47:26.678: INFO: Waiting up to 5m0s for pod "downward-api-3a0fe3d6-5a0d-11e9-b9a9-e6698ebc8bdf" in namespace "downward-api-3994" to be "success or failure"
Apr  8 14:47:26.682: INFO: Pod "downward-api-3a0fe3d6-5a0d-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 3.881681ms
Apr  8 14:47:28.687: INFO: Pod "downward-api-3a0fe3d6-5a0d-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008992941s
STEP: Saw pod success
Apr  8 14:47:28.687: INFO: Pod "downward-api-3a0fe3d6-5a0d-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 14:47:28.692: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod downward-api-3a0fe3d6-5a0d-11e9-b9a9-e6698ebc8bdf container dapi-container: <nil>
STEP: delete the pod
Apr  8 14:47:28.715: INFO: Waiting for pod downward-api-3a0fe3d6-5a0d-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 14:47:28.718: INFO: Pod downward-api-3a0fe3d6-5a0d-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:47:28.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3994" for this suite.
Apr  8 14:47:34.735: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:47:34.902: INFO: namespace downward-api-3994 deletion completed in 6.179548676s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:47:34.902: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3923
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Apr  8 14:47:35.065: INFO: Waiting up to 5m0s for pod "pod-3f0f97ec-5a0d-11e9-b9a9-e6698ebc8bdf" in namespace "emptydir-3923" to be "success or failure"
Apr  8 14:47:35.071: INFO: Pod "pod-3f0f97ec-5a0d-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 6.255803ms
Apr  8 14:47:37.100: INFO: Pod "pod-3f0f97ec-5a0d-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.035496948s
STEP: Saw pod success
Apr  8 14:47:37.100: INFO: Pod "pod-3f0f97ec-5a0d-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 14:47:37.122: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-3f0f97ec-5a0d-11e9-b9a9-e6698ebc8bdf container test-container: <nil>
STEP: delete the pod
Apr  8 14:47:37.179: INFO: Waiting for pod pod-3f0f97ec-5a0d-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 14:47:37.200: INFO: Pod pod-3f0f97ec-5a0d-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:47:37.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3923" for this suite.
Apr  8 14:47:43.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:47:44.303: INFO: namespace emptydir-3923 deletion completed in 7.077600175s
â€¢SSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:47:44.303: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-8735
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  8 14:47:44.492: INFO: Creating ReplicaSet my-hostname-basic-44af4505-5a0d-11e9-b9a9-e6698ebc8bdf
Apr  8 14:47:44.502: INFO: Pod name my-hostname-basic-44af4505-5a0d-11e9-b9a9-e6698ebc8bdf: Found 0 pods out of 1
Apr  8 14:47:49.514: INFO: Pod name my-hostname-basic-44af4505-5a0d-11e9-b9a9-e6698ebc8bdf: Found 1 pods out of 1
Apr  8 14:47:49.514: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-44af4505-5a0d-11e9-b9a9-e6698ebc8bdf" is running
Apr  8 14:47:49.521: INFO: Pod "my-hostname-basic-44af4505-5a0d-11e9-b9a9-e6698ebc8bdf-jc97j" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-08 14:47:44 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-08 14:47:47 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-08 14:47:47 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-08 14:47:44 +0000 UTC Reason: Message:}])
Apr  8 14:47:49.521: INFO: Trying to dial the pod
Apr  8 14:47:54.620: INFO: Controller my-hostname-basic-44af4505-5a0d-11e9-b9a9-e6698ebc8bdf: Got expected result from replica 1 [my-hostname-basic-44af4505-5a0d-11e9-b9a9-e6698ebc8bdf-jc97j]: "my-hostname-basic-44af4505-5a0d-11e9-b9a9-e6698ebc8bdf-jc97j", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:47:54.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-8735" for this suite.
Apr  8 14:48:00.658: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:48:00.936: INFO: namespace replicaset-8735 deletion completed in 6.311477864s
â€¢SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:48:00.936: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6135
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  8 14:48:01.090: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4e92d3a2-5a0d-11e9-b9a9-e6698ebc8bdf" in namespace "downward-api-6135" to be "success or failure"
Apr  8 14:48:01.096: INFO: Pod "downwardapi-volume-4e92d3a2-5a0d-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 5.882631ms
Apr  8 14:48:03.102: INFO: Pod "downwardapi-volume-4e92d3a2-5a0d-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011387189s
STEP: Saw pod success
Apr  8 14:48:03.102: INFO: Pod "downwardapi-volume-4e92d3a2-5a0d-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 14:48:03.106: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod downwardapi-volume-4e92d3a2-5a0d-11e9-b9a9-e6698ebc8bdf container client-container: <nil>
STEP: delete the pod
Apr  8 14:48:03.130: INFO: Waiting for pod downwardapi-volume-4e92d3a2-5a0d-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 14:48:03.134: INFO: Pod downwardapi-volume-4e92d3a2-5a0d-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:48:03.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6135" for this suite.
Apr  8 14:48:09.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:48:09.320: INFO: namespace downward-api-6135 deletion completed in 6.18183124s
â€¢SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:48:09.320: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-3672
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3672.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-3672.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3672.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-3672.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3672.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-3672.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3672.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-3672.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3672.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-3672.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3672.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-3672.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3672.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 121.195.70.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.70.195.121_udp@PTR;check="$$(dig +tcp +noall +answer +search 121.195.70.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.70.195.121_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3672.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-3672.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3672.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-3672.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3672.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-3672.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3672.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-3672.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3672.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-3672.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3672.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-3672.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3672.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 121.195.70.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.70.195.121_udp@PTR;check="$$(dig +tcp +noall +answer +search 121.195.70.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.70.195.121_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr  8 14:48:25.693: INFO: Unable to read wheezy_udp@dns-test-service.dns-3672.svc.cluster.local from pod dns-3672/dns-test-5394a1fb-5a0d-11e9-b9a9-e6698ebc8bdf: the server could not find the requested resource (get pods dns-test-5394a1fb-5a0d-11e9-b9a9-e6698ebc8bdf)
Apr  8 14:48:25.786: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3672.svc.cluster.local from pod dns-3672/dns-test-5394a1fb-5a0d-11e9-b9a9-e6698ebc8bdf: the server could not find the requested resource (get pods dns-test-5394a1fb-5a0d-11e9-b9a9-e6698ebc8bdf)
Apr  8 14:48:27.259: INFO: Lookups using dns-3672/dns-test-5394a1fb-5a0d-11e9-b9a9-e6698ebc8bdf failed for: [wheezy_udp@dns-test-service.dns-3672.svc.cluster.local wheezy_tcp@dns-test-service.dns-3672.svc.cluster.local]

Apr  8 14:48:33.975: INFO: DNS probes using dns-3672/dns-test-5394a1fb-5a0d-11e9-b9a9-e6698ebc8bdf succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:48:34.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3672" for this suite.
Apr  8 14:48:40.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:48:40.195: INFO: namespace dns-3672 deletion completed in 6.176995904s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:48:40.196: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-4703
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-downwardapi-j7gl
STEP: Creating a pod to test atomic-volume-subpath
Apr  8 14:48:40.385: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-j7gl" in namespace "subpath-4703" to be "success or failure"
Apr  8 14:48:40.388: INFO: Pod "pod-subpath-test-downwardapi-j7gl": Phase="Pending", Reason="", readiness=false. Elapsed: 3.487014ms
Apr  8 14:48:42.407: INFO: Pod "pod-subpath-test-downwardapi-j7gl": Phase="Running", Reason="", readiness=true. Elapsed: 2.0225457s
Apr  8 14:48:44.421: INFO: Pod "pod-subpath-test-downwardapi-j7gl": Phase="Running", Reason="", readiness=true. Elapsed: 4.036430138s
Apr  8 14:48:46.426: INFO: Pod "pod-subpath-test-downwardapi-j7gl": Phase="Running", Reason="", readiness=true. Elapsed: 6.041258741s
Apr  8 14:48:48.444: INFO: Pod "pod-subpath-test-downwardapi-j7gl": Phase="Running", Reason="", readiness=true. Elapsed: 8.058700437s
Apr  8 14:48:50.471: INFO: Pod "pod-subpath-test-downwardapi-j7gl": Phase="Running", Reason="", readiness=true. Elapsed: 10.086331879s
Apr  8 14:48:52.476: INFO: Pod "pod-subpath-test-downwardapi-j7gl": Phase="Running", Reason="", readiness=true. Elapsed: 12.091117928s
Apr  8 14:48:54.481: INFO: Pod "pod-subpath-test-downwardapi-j7gl": Phase="Running", Reason="", readiness=true. Elapsed: 14.096187402s
Apr  8 14:48:56.493: INFO: Pod "pod-subpath-test-downwardapi-j7gl": Phase="Running", Reason="", readiness=true. Elapsed: 16.107737383s
Apr  8 14:48:58.498: INFO: Pod "pod-subpath-test-downwardapi-j7gl": Phase="Running", Reason="", readiness=true. Elapsed: 18.112666081s
Apr  8 14:49:00.502: INFO: Pod "pod-subpath-test-downwardapi-j7gl": Phase="Running", Reason="", readiness=true. Elapsed: 20.117403906s
Apr  8 14:49:02.507: INFO: Pod "pod-subpath-test-downwardapi-j7gl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.122451633s
STEP: Saw pod success
Apr  8 14:49:02.507: INFO: Pod "pod-subpath-test-downwardapi-j7gl" satisfied condition "success or failure"
Apr  8 14:49:02.513: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-subpath-test-downwardapi-j7gl container test-container-subpath-downwardapi-j7gl: <nil>
STEP: delete the pod
Apr  8 14:49:02.538: INFO: Waiting for pod pod-subpath-test-downwardapi-j7gl to disappear
Apr  8 14:49:02.542: INFO: Pod pod-subpath-test-downwardapi-j7gl no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-j7gl
Apr  8 14:49:02.542: INFO: Deleting pod "pod-subpath-test-downwardapi-j7gl" in namespace "subpath-4703"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:49:02.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4703" for this suite.
Apr  8 14:49:08.572: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:49:08.800: INFO: namespace subpath-4703 deletion completed in 6.247207789s
â€¢SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:49:08.800: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-4347
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-4347
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating stateful set ss in namespace statefulset-4347
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-4347
Apr  8 14:49:09.007: INFO: Found 0 stateful pods, waiting for 1
Apr  8 14:49:19.022: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Apr  8 14:49:19.036: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-4347 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  8 14:49:19.892: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  8 14:49:19.892: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  8 14:49:19.892: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr  8 14:49:19.911: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr  8 14:49:29.916: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr  8 14:49:29.916: INFO: Waiting for statefulset status.replicas updated to 0
Apr  8 14:49:29.958: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999398s
Apr  8 14:49:30.973: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995977188s
Apr  8 14:49:31.995: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.981753492s
Apr  8 14:49:33.001: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.959317818s
Apr  8 14:49:34.007: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.953807043s
Apr  8 14:49:35.012: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.946974236s
Apr  8 14:49:36.018: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.942167025s
Apr  8 14:49:37.028: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.936069209s
Apr  8 14:49:38.042: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.926584392s
Apr  8 14:49:39.048: INFO: Verifying statefulset ss doesn't scale past 3 for another 912.199887ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-4347
Apr  8 14:49:40.054: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-4347 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  8 14:49:40.849: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr  8 14:49:40.849: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr  8 14:49:40.849: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr  8 14:49:40.849: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-4347 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  8 14:49:41.665: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr  8 14:49:41.665: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr  8 14:49:41.665: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr  8 14:49:41.665: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-4347 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  8 14:49:42.405: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr  8 14:49:42.405: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr  8 14:49:42.405: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr  8 14:49:42.410: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr  8 14:49:42.410: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr  8 14:49:42.410: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Apr  8 14:49:42.414: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-4347 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  8 14:49:43.113: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  8 14:49:43.113: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  8 14:49:43.113: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr  8 14:49:43.113: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-4347 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  8 14:49:43.901: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  8 14:49:43.901: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  8 14:49:43.901: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr  8 14:49:43.901: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-4347 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  8 14:49:44.646: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  8 14:49:44.646: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  8 14:49:44.646: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr  8 14:49:44.646: INFO: Waiting for statefulset status.replicas updated to 0
Apr  8 14:49:44.655: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Apr  8 14:49:54.693: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr  8 14:49:54.693: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr  8 14:49:54.693: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr  8 14:49:54.740: INFO: POD   NODE                                                    PHASE    GRACE  CONDITIONS
Apr  8 14:49:54.740: INFO: ss-0  shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:09 +0000 UTC  }]
Apr  8 14:49:54.740: INFO: ss-1  shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:29 +0000 UTC  }]
Apr  8 14:49:54.740: INFO: ss-2  shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:29 +0000 UTC  }]
Apr  8 14:49:54.740: INFO: 
Apr  8 14:49:54.740: INFO: StatefulSet ss has not reached scale 0, at 3
Apr  8 14:49:55.752: INFO: POD   NODE                                                    PHASE    GRACE  CONDITIONS
Apr  8 14:49:55.752: INFO: ss-0  shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:09 +0000 UTC  }]
Apr  8 14:49:55.752: INFO: ss-1  shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:29 +0000 UTC  }]
Apr  8 14:49:55.752: INFO: ss-2  shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:29 +0000 UTC  }]
Apr  8 14:49:55.752: INFO: 
Apr  8 14:49:55.752: INFO: StatefulSet ss has not reached scale 0, at 3
Apr  8 14:49:56.759: INFO: POD   NODE                                                    PHASE    GRACE  CONDITIONS
Apr  8 14:49:56.759: INFO: ss-0  shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:09 +0000 UTC  }]
Apr  8 14:49:56.759: INFO: ss-1  shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:29 +0000 UTC  }]
Apr  8 14:49:56.759: INFO: ss-2  shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:29 +0000 UTC  }]
Apr  8 14:49:56.759: INFO: 
Apr  8 14:49:56.759: INFO: StatefulSet ss has not reached scale 0, at 3
Apr  8 14:49:57.765: INFO: POD   NODE                                                    PHASE    GRACE  CONDITIONS
Apr  8 14:49:57.765: INFO: ss-0  shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:09 +0000 UTC  }]
Apr  8 14:49:57.765: INFO: ss-1  shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:29 +0000 UTC  }]
Apr  8 14:49:57.765: INFO: ss-2  shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:29 +0000 UTC  }]
Apr  8 14:49:57.765: INFO: 
Apr  8 14:49:57.765: INFO: StatefulSet ss has not reached scale 0, at 3
Apr  8 14:49:58.771: INFO: POD   NODE                                                    PHASE    GRACE  CONDITIONS
Apr  8 14:49:58.771: INFO: ss-0  shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:09 +0000 UTC  }]
Apr  8 14:49:58.771: INFO: ss-1  shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:29 +0000 UTC  }]
Apr  8 14:49:58.771: INFO: ss-2  shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:29 +0000 UTC  }]
Apr  8 14:49:58.771: INFO: 
Apr  8 14:49:58.771: INFO: StatefulSet ss has not reached scale 0, at 3
Apr  8 14:49:59.776: INFO: POD   NODE                                                    PHASE    GRACE  CONDITIONS
Apr  8 14:49:59.776: INFO: ss-0  shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:09 +0000 UTC  }]
Apr  8 14:49:59.776: INFO: ss-1  shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:29 +0000 UTC  }]
Apr  8 14:49:59.776: INFO: ss-2  shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:29 +0000 UTC  }]
Apr  8 14:49:59.776: INFO: 
Apr  8 14:49:59.776: INFO: StatefulSet ss has not reached scale 0, at 3
Apr  8 14:50:00.782: INFO: POD   NODE                                                    PHASE    GRACE  CONDITIONS
Apr  8 14:50:00.782: INFO: ss-0  shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:09 +0000 UTC  }]
Apr  8 14:50:00.782: INFO: ss-1  shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:29 +0000 UTC  }]
Apr  8 14:50:00.782: INFO: ss-2  shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:29 +0000 UTC  }]
Apr  8 14:50:00.782: INFO: 
Apr  8 14:50:00.782: INFO: StatefulSet ss has not reached scale 0, at 3
Apr  8 14:50:01.796: INFO: POD   NODE                                                    PHASE    GRACE  CONDITIONS
Apr  8 14:50:01.796: INFO: ss-0  shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:09 +0000 UTC  }]
Apr  8 14:50:01.796: INFO: ss-1  shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:29 +0000 UTC  }]
Apr  8 14:50:01.796: INFO: ss-2  shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:29 +0000 UTC  }]
Apr  8 14:50:01.796: INFO: 
Apr  8 14:50:01.796: INFO: StatefulSet ss has not reached scale 0, at 3
Apr  8 14:50:02.803: INFO: POD   NODE                                                    PHASE    GRACE  CONDITIONS
Apr  8 14:50:02.803: INFO: ss-0  shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:09 +0000 UTC  }]
Apr  8 14:50:02.803: INFO: ss-1  shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:29 +0000 UTC  }]
Apr  8 14:50:02.803: INFO: ss-2  shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:29 +0000 UTC  }]
Apr  8 14:50:02.803: INFO: 
Apr  8 14:50:02.803: INFO: StatefulSet ss has not reached scale 0, at 3
Apr  8 14:50:03.808: INFO: POD   NODE                                                    PHASE    GRACE  CONDITIONS
Apr  8 14:50:03.808: INFO: ss-0  shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:09 +0000 UTC  }]
Apr  8 14:50:03.808: INFO: ss-2  shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 14:49:29 +0000 UTC  }]
Apr  8 14:50:03.808: INFO: 
Apr  8 14:50:03.808: INFO: StatefulSet ss has not reached scale 0, at 2
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-4347
Apr  8 14:50:04.813: INFO: Scaling statefulset ss to 0
Apr  8 14:50:04.824: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr  8 14:50:04.828: INFO: Deleting all statefulset in ns statefulset-4347
Apr  8 14:50:04.832: INFO: Scaling statefulset ss to 0
Apr  8 14:50:04.845: INFO: Waiting for statefulset status.replicas updated to 0
Apr  8 14:50:04.849: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:50:04.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4347" for this suite.
Apr  8 14:50:10.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:50:11.005: INFO: namespace statefulset-4347 deletion completed in 6.139047171s
â€¢SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:50:11.005: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5888
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  8 14:50:11.165: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9c1aa8cb-5a0d-11e9-b9a9-e6698ebc8bdf" in namespace "downward-api-5888" to be "success or failure"
Apr  8 14:50:11.185: INFO: Pod "downwardapi-volume-9c1aa8cb-5a0d-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 19.769045ms
Apr  8 14:50:13.208: INFO: Pod "downwardapi-volume-9c1aa8cb-5a0d-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.042684757s
STEP: Saw pod success
Apr  8 14:50:13.208: INFO: Pod "downwardapi-volume-9c1aa8cb-5a0d-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 14:50:13.230: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod downwardapi-volume-9c1aa8cb-5a0d-11e9-b9a9-e6698ebc8bdf container client-container: <nil>
STEP: delete the pod
Apr  8 14:50:13.285: INFO: Waiting for pod downwardapi-volume-9c1aa8cb-5a0d-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 14:50:13.304: INFO: Pod downwardapi-volume-9c1aa8cb-5a0d-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:50:13.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5888" for this suite.
Apr  8 14:50:19.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:50:19.578: INFO: namespace downward-api-5888 deletion completed in 6.238531659s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:50:19.578: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5637
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-a13dbfb2-5a0d-11e9-b9a9-e6698ebc8bdf
STEP: Creating a pod to test consume secrets
Apr  8 14:50:19.825: INFO: Waiting up to 5m0s for pod "pod-secrets-a1418f7f-5a0d-11e9-b9a9-e6698ebc8bdf" in namespace "secrets-5637" to be "success or failure"
Apr  8 14:50:19.845: INFO: Pod "pod-secrets-a1418f7f-5a0d-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 20.574923ms
Apr  8 14:50:21.850: INFO: Pod "pod-secrets-a1418f7f-5a0d-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025479027s
STEP: Saw pod success
Apr  8 14:50:21.850: INFO: Pod "pod-secrets-a1418f7f-5a0d-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 14:50:21.854: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-secrets-a1418f7f-5a0d-11e9-b9a9-e6698ebc8bdf container secret-volume-test: <nil>
STEP: delete the pod
Apr  8 14:50:21.877: INFO: Waiting for pod pod-secrets-a1418f7f-5a0d-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 14:50:21.880: INFO: Pod pod-secrets-a1418f7f-5a0d-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:50:21.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5637" for this suite.
Apr  8 14:50:27.898: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:50:28.076: INFO: namespace secrets-5637 deletion completed in 6.190902154s
â€¢SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:50:28.077: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6792
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Apr  8 14:50:28.242: INFO: Waiting up to 5m0s for pod "pod-a6484642-5a0d-11e9-b9a9-e6698ebc8bdf" in namespace "emptydir-6792" to be "success or failure"
Apr  8 14:50:28.245: INFO: Pod "pod-a6484642-5a0d-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 3.540657ms
Apr  8 14:50:30.251: INFO: Pod "pod-a6484642-5a0d-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009503117s
Apr  8 14:50:32.276: INFO: Pod "pod-a6484642-5a0d-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034390311s
STEP: Saw pod success
Apr  8 14:50:32.276: INFO: Pod "pod-a6484642-5a0d-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 14:50:32.300: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-a6484642-5a0d-11e9-b9a9-e6698ebc8bdf container test-container: <nil>
STEP: delete the pod
Apr  8 14:50:32.355: INFO: Waiting for pod pod-a6484642-5a0d-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 14:50:32.373: INFO: Pod pod-a6484642-5a0d-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:50:32.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6792" for this suite.
Apr  8 14:50:38.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:50:38.978: INFO: namespace emptydir-6792 deletion completed in 6.570786429s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:50:38.979: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7094
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on node default medium
Apr  8 14:50:39.136: INFO: Waiting up to 5m0s for pod "pod-acc6c8c5-5a0d-11e9-b9a9-e6698ebc8bdf" in namespace "emptydir-7094" to be "success or failure"
Apr  8 14:50:39.141: INFO: Pod "pod-acc6c8c5-5a0d-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.556451ms
Apr  8 14:50:41.146: INFO: Pod "pod-acc6c8c5-5a0d-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01026818s
STEP: Saw pod success
Apr  8 14:50:41.146: INFO: Pod "pod-acc6c8c5-5a0d-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 14:50:41.152: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-acc6c8c5-5a0d-11e9-b9a9-e6698ebc8bdf container test-container: <nil>
STEP: delete the pod
Apr  8 14:50:41.170: INFO: Waiting for pod pod-acc6c8c5-5a0d-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 14:50:41.174: INFO: Pod pod-acc6c8c5-5a0d-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:50:41.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7094" for this suite.
Apr  8 14:50:47.191: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:50:47.311: INFO: namespace emptydir-7094 deletion completed in 6.13362981s
â€¢SSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:50:47.312: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-5121
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:51:47.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5121" for this suite.
Apr  8 14:52:09.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:52:09.626: INFO: namespace container-probe-5121 deletion completed in 22.143269854s
â€¢SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:52:09.626: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6005
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-e2cf3c57-5a0d-11e9-b9a9-e6698ebc8bdf
STEP: Creating a pod to test consume secrets
Apr  8 14:52:09.796: INFO: Waiting up to 5m0s for pod "pod-secrets-e2d00a86-5a0d-11e9-b9a9-e6698ebc8bdf" in namespace "secrets-6005" to be "success or failure"
Apr  8 14:52:09.800: INFO: Pod "pod-secrets-e2d00a86-5a0d-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 3.885936ms
Apr  8 14:52:11.806: INFO: Pod "pod-secrets-e2d00a86-5a0d-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00964866s
STEP: Saw pod success
Apr  8 14:52:11.806: INFO: Pod "pod-secrets-e2d00a86-5a0d-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 14:52:11.811: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-secrets-e2d00a86-5a0d-11e9-b9a9-e6698ebc8bdf container secret-volume-test: <nil>
STEP: delete the pod
Apr  8 14:52:11.835: INFO: Waiting for pod pod-secrets-e2d00a86-5a0d-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 14:52:11.838: INFO: Pod pod-secrets-e2d00a86-5a0d-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:52:11.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6005" for this suite.
Apr  8 14:52:17.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:52:18.017: INFO: namespace secrets-6005 deletion completed in 6.173905948s
â€¢
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:52:18.018: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5394
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-e7cfad2e-5a0d-11e9-b9a9-e6698ebc8bdf
STEP: Creating a pod to test consume configMaps
Apr  8 14:52:18.184: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e7d05ad3-5a0d-11e9-b9a9-e6698ebc8bdf" in namespace "projected-5394" to be "success or failure"
Apr  8 14:52:18.188: INFO: Pod "pod-projected-configmaps-e7d05ad3-5a0d-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 3.545204ms
Apr  8 14:52:20.206: INFO: Pod "pod-projected-configmaps-e7d05ad3-5a0d-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021495081s
STEP: Saw pod success
Apr  8 14:52:20.206: INFO: Pod "pod-projected-configmaps-e7d05ad3-5a0d-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 14:52:20.228: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-projected-configmaps-e7d05ad3-5a0d-11e9-b9a9-e6698ebc8bdf container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr  8 14:52:20.280: INFO: Waiting for pod pod-projected-configmaps-e7d05ad3-5a0d-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 14:52:20.299: INFO: Pod pod-projected-configmaps-e7d05ad3-5a0d-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:52:20.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5394" for this suite.
Apr  8 14:52:26.399: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:52:26.790: INFO: namespace projected-5394 deletion completed in 6.456294435s
â€¢S
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:52:26.790: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7755
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-ed0b84ed-5a0d-11e9-b9a9-e6698ebc8bdf
STEP: Creating secret with name s-test-opt-upd-ed0b8547-5a0d-11e9-b9a9-e6698ebc8bdf
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-ed0b84ed-5a0d-11e9-b9a9-e6698ebc8bdf
STEP: Updating secret s-test-opt-upd-ed0b8547-5a0d-11e9-b9a9-e6698ebc8bdf
STEP: Creating secret with name s-test-opt-create-ed0b8566-5a0d-11e9-b9a9-e6698ebc8bdf
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:52:33.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7755" for this suite.
Apr  8 14:52:49.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:52:50.256: INFO: namespace secrets-7755 deletion completed in 16.797274192s
â€¢SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:52:50.256: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-8768
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-8768
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Apr  8 14:52:50.518: INFO: Found 1 stateful pods, waiting for 3
Apr  8 14:53:00.524: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr  8 14:53:00.524: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr  8 14:53:00.524: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Apr  8 14:53:00.535: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-8768 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  8 14:53:01.127: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  8 14:53:01.127: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  8 14:53:01.127: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Apr  8 14:53:11.178: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Apr  8 14:53:21.304: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-8768 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  8 14:53:21.873: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr  8 14:53:21.873: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr  8 14:53:21.873: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr  8 14:53:31.958: INFO: Waiting for StatefulSet statefulset-8768/ss2 to complete update
Apr  8 14:53:31.958: INFO: Waiting for Pod statefulset-8768/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr  8 14:53:31.958: INFO: Waiting for Pod statefulset-8768/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr  8 14:53:31.958: INFO: Waiting for Pod statefulset-8768/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr  8 14:53:41.968: INFO: Waiting for StatefulSet statefulset-8768/ss2 to complete update
Apr  8 14:53:41.968: INFO: Waiting for Pod statefulset-8768/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Apr  8 14:53:51.967: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-8768 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  8 14:53:52.528: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  8 14:53:52.528: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  8 14:53:52.528: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr  8 14:54:02.567: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Apr  8 14:54:12.597: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-8768 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  8 14:54:13.140: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr  8 14:54:13.141: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr  8 14:54:13.141: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr  8 14:54:33.169: INFO: Deleting all statefulset in ns statefulset-8768
Apr  8 14:54:33.173: INFO: Scaling statefulset ss2 to 0
Apr  8 14:55:03.200: INFO: Waiting for statefulset status.replicas updated to 0
Apr  8 14:55:03.204: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:55:03.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8768" for this suite.
Apr  8 14:55:09.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:55:09.398: INFO: namespace statefulset-8768 deletion completed in 6.175833653s
â€¢SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:55:09.398: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4800
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1354
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr  8 14:55:09.544: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-4800'
Apr  8 14:55:10.434: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Apr  8 14:55:10.434: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Apr  8 14:55:10.441: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-xvjs4]
Apr  8 14:55:10.441: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-xvjs4" in namespace "kubectl-4800" to be "running and ready"
Apr  8 14:55:10.444: INFO: Pod "e2e-test-nginx-rc-xvjs4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.08322ms
Apr  8 14:55:12.449: INFO: Pod "e2e-test-nginx-rc-xvjs4": Phase="Running", Reason="", readiness=true. Elapsed: 2.00792463s
Apr  8 14:55:12.449: INFO: Pod "e2e-test-nginx-rc-xvjs4" satisfied condition "running and ready"
Apr  8 14:55:12.449: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-xvjs4]
Apr  8 14:55:12.449: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config logs rc/e2e-test-nginx-rc --namespace=kubectl-4800'
Apr  8 14:55:12.604: INFO: stderr: ""
Apr  8 14:55:12.604: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1359
Apr  8 14:55:12.604: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config delete rc e2e-test-nginx-rc --namespace=kubectl-4800'
Apr  8 14:55:12.723: INFO: stderr: ""
Apr  8 14:55:12.723: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:55:12.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4800" for this suite.
Apr  8 14:55:34.746: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:55:34.869: INFO: namespace kubectl-4800 deletion completed in 22.138583624s
â€¢SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:55:34.869: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3044
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Apr  8 14:55:35.013: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config create -f - --namespace=kubectl-3044'
Apr  8 14:55:35.302: INFO: stderr: ""
Apr  8 14:55:35.302: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Apr  8 14:55:36.307: INFO: Selector matched 1 pods for map[app:redis]
Apr  8 14:55:36.307: INFO: Found 0 / 1
Apr  8 14:55:37.312: INFO: Selector matched 1 pods for map[app:redis]
Apr  8 14:55:37.312: INFO: Found 0 / 1
Apr  8 14:55:38.311: INFO: Selector matched 1 pods for map[app:redis]
Apr  8 14:55:38.311: INFO: Found 1 / 1
Apr  8 14:55:38.311: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Apr  8 14:55:38.318: INFO: Selector matched 1 pods for map[app:redis]
Apr  8 14:55:38.318: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr  8 14:55:38.318: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config patch pod redis-master-mp944 --namespace=kubectl-3044 -p {"metadata":{"annotations":{"x":"y"}}}'
Apr  8 14:55:38.476: INFO: stderr: ""
Apr  8 14:55:38.476: INFO: stdout: "pod/redis-master-mp944 patched\n"
STEP: checking annotations
Apr  8 14:55:38.480: INFO: Selector matched 1 pods for map[app:redis]
Apr  8 14:55:38.480: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:55:38.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3044" for this suite.
Apr  8 14:56:00.497: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:56:00.670: INFO: namespace kubectl-3044 deletion completed in 22.184859989s
â€¢SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:56:00.670: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8455
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-6c8599cc-5a0e-11e9-b9a9-e6698ebc8bdf
STEP: Creating a pod to test consume secrets
Apr  8 14:56:00.835: INFO: Waiting up to 5m0s for pod "pod-secrets-6c863060-5a0e-11e9-b9a9-e6698ebc8bdf" in namespace "secrets-8455" to be "success or failure"
Apr  8 14:56:00.839: INFO: Pod "pod-secrets-6c863060-5a0e-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.849448ms
Apr  8 14:56:02.843: INFO: Pod "pod-secrets-6c863060-5a0e-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008548666s
STEP: Saw pod success
Apr  8 14:56:02.843: INFO: Pod "pod-secrets-6c863060-5a0e-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 14:56:02.846: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-secrets-6c863060-5a0e-11e9-b9a9-e6698ebc8bdf container secret-volume-test: <nil>
STEP: delete the pod
Apr  8 14:56:02.875: INFO: Waiting for pod pod-secrets-6c863060-5a0e-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 14:56:02.878: INFO: Pod pod-secrets-6c863060-5a0e-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:56:02.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8455" for this suite.
Apr  8 14:56:08.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:56:09.103: INFO: namespace secrets-8455 deletion completed in 6.219732171s
â€¢SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:56:09.103: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5653
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-718b1115-5a0e-11e9-b9a9-e6698ebc8bdf
STEP: Creating a pod to test consume configMaps
Apr  8 14:56:09.259: INFO: Waiting up to 5m0s for pod "pod-configmaps-718bab2a-5a0e-11e9-b9a9-e6698ebc8bdf" in namespace "configmap-5653" to be "success or failure"
Apr  8 14:56:09.264: INFO: Pod "pod-configmaps-718bab2a-5a0e-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 5.553858ms
Apr  8 14:56:11.269: INFO: Pod "pod-configmaps-718bab2a-5a0e-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010402374s
STEP: Saw pod success
Apr  8 14:56:11.269: INFO: Pod "pod-configmaps-718bab2a-5a0e-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 14:56:11.273: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-configmaps-718bab2a-5a0e-11e9-b9a9-e6698ebc8bdf container configmap-volume-test: <nil>
STEP: delete the pod
Apr  8 14:56:11.294: INFO: Waiting for pod pod-configmaps-718bab2a-5a0e-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 14:56:11.297: INFO: Pod pod-configmaps-718bab2a-5a0e-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:56:11.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5653" for this suite.
Apr  8 14:56:17.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:56:17.451: INFO: namespace configmap-5653 deletion completed in 6.148982692s
â€¢SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:56:17.451: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7046
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Apr  8 14:56:17.669: INFO: namespace kubectl-7046
Apr  8 14:56:17.669: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config create -f - --namespace=kubectl-7046'
Apr  8 14:56:17.887: INFO: stderr: ""
Apr  8 14:56:17.887: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Apr  8 14:56:18.892: INFO: Selector matched 1 pods for map[app:redis]
Apr  8 14:56:18.892: INFO: Found 0 / 1
Apr  8 14:56:19.906: INFO: Selector matched 1 pods for map[app:redis]
Apr  8 14:56:19.906: INFO: Found 1 / 1
Apr  8 14:56:19.906: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr  8 14:56:19.925: INFO: Selector matched 1 pods for map[app:redis]
Apr  8 14:56:19.925: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr  8 14:56:19.925: INFO: wait on redis-master startup in kubectl-7046 
Apr  8 14:56:19.925: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config logs redis-master-9jq2j redis-master --namespace=kubectl-7046'
Apr  8 14:56:20.169: INFO: stderr: ""
Apr  8 14:56:20.169: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 08 Apr 14:56:18.595 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 08 Apr 14:56:18.595 # Server started, Redis version 3.2.12\n1:M 08 Apr 14:56:18.595 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 08 Apr 14:56:18.595 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Apr  8 14:56:20.169: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-7046'
Apr  8 14:56:20.405: INFO: stderr: ""
Apr  8 14:56:20.405: INFO: stdout: "service/rm2 exposed\n"
Apr  8 14:56:20.419: INFO: Service rm2 in namespace kubectl-7046 found.
STEP: exposing service
Apr  8 14:56:22.428: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-7046'
Apr  8 14:56:22.558: INFO: stderr: ""
Apr  8 14:56:22.558: INFO: stdout: "service/rm3 exposed\n"
Apr  8 14:56:22.562: INFO: Service rm3 in namespace kubectl-7046 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:56:24.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7046" for this suite.
Apr  8 14:56:46.625: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:56:46.746: INFO: namespace kubectl-7046 deletion completed in 22.153792804s
â€¢SSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:56:46.746: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-1603
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-1603.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-1603.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1603.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-1603.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-1603.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1603.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr  8 14:56:51.561: INFO: DNS probes using dns-1603/dns-test-87fb34d9-5a0e-11e9-b9a9-e6698ebc8bdf succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:56:51.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1603" for this suite.
Apr  8 14:56:57.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:56:57.754: INFO: namespace dns-1603 deletion completed in 6.17866284s
â€¢SS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:56:57.754: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7671
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-7671/configmap-test-8e8ad3c5-5a0e-11e9-b9a9-e6698ebc8bdf
STEP: Creating a pod to test consume configMaps
Apr  8 14:56:57.913: INFO: Waiting up to 5m0s for pod "pod-configmaps-8e8b96a8-5a0e-11e9-b9a9-e6698ebc8bdf" in namespace "configmap-7671" to be "success or failure"
Apr  8 14:56:57.918: INFO: Pod "pod-configmaps-8e8b96a8-5a0e-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 5.191169ms
Apr  8 14:56:59.922: INFO: Pod "pod-configmaps-8e8b96a8-5a0e-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009811628s
STEP: Saw pod success
Apr  8 14:56:59.923: INFO: Pod "pod-configmaps-8e8b96a8-5a0e-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 14:56:59.926: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-configmaps-8e8b96a8-5a0e-11e9-b9a9-e6698ebc8bdf container env-test: <nil>
STEP: delete the pod
Apr  8 14:56:59.956: INFO: Waiting for pod pod-configmaps-8e8b96a8-5a0e-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 14:56:59.986: INFO: Pod pod-configmaps-8e8b96a8-5a0e-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:56:59.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7671" for this suite.
Apr  8 14:57:06.052: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:57:06.201: INFO: namespace configmap-7671 deletion completed in 6.208596504s
â€¢SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:57:06.201: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7629
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-9396969b-5a0e-11e9-b9a9-e6698ebc8bdf
STEP: Creating configMap with name cm-test-opt-upd-939696dd-5a0e-11e9-b9a9-e6698ebc8bdf
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-9396969b-5a0e-11e9-b9a9-e6698ebc8bdf
STEP: Updating configmap cm-test-opt-upd-939696dd-5a0e-11e9-b9a9-e6698ebc8bdf
STEP: Creating configMap with name cm-test-opt-create-939696f4-5a0e-11e9-b9a9-e6698ebc8bdf
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:57:12.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7629" for this suite.
Apr  8 14:57:34.903: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:57:35.033: INFO: namespace projected-7629 deletion completed in 22.142806516s
â€¢
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:57:35.033: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9455
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  8 14:57:35.177: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:57:37.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9455" for this suite.
Apr  8 14:58:21.613: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:58:21.736: INFO: namespace pods-9455 deletion completed in 44.167819744s
â€¢SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:58:21.736: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9665
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  8 14:58:21.893: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c0999dd2-5a0e-11e9-b9a9-e6698ebc8bdf" in namespace "projected-9665" to be "success or failure"
Apr  8 14:58:21.897: INFO: Pod "downwardapi-volume-c0999dd2-5a0e-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 3.656194ms
Apr  8 14:58:23.902: INFO: Pod "downwardapi-volume-c0999dd2-5a0e-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008821079s
STEP: Saw pod success
Apr  8 14:58:23.902: INFO: Pod "downwardapi-volume-c0999dd2-5a0e-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 14:58:23.905: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod downwardapi-volume-c0999dd2-5a0e-11e9-b9a9-e6698ebc8bdf container client-container: <nil>
STEP: delete the pod
Apr  8 14:58:23.968: INFO: Waiting for pod downwardapi-volume-c0999dd2-5a0e-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 14:58:23.972: INFO: Pod downwardapi-volume-c0999dd2-5a0e-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:58:23.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9665" for this suite.
Apr  8 14:58:29.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:58:30.118: INFO: namespace projected-9665 deletion completed in 6.142317116s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:58:30.118: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3031
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Apr  8 14:58:30.363: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config create -f - --namespace=kubectl-3031'
Apr  8 14:58:30.636: INFO: stderr: ""
Apr  8 14:58:30.636: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr  8 14:58:30.636: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3031'
Apr  8 14:58:30.763: INFO: stderr: ""
Apr  8 14:58:30.763: INFO: stdout: "update-demo-nautilus-25dww update-demo-nautilus-qd494 "
Apr  8 14:58:30.763: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-25dww -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3031'
Apr  8 14:58:30.861: INFO: stderr: ""
Apr  8 14:58:30.861: INFO: stdout: ""
Apr  8 14:58:30.861: INFO: update-demo-nautilus-25dww is created but not running
Apr  8 14:58:35.861: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3031'
Apr  8 14:58:35.970: INFO: stderr: ""
Apr  8 14:58:35.970: INFO: stdout: "update-demo-nautilus-25dww update-demo-nautilus-qd494 "
Apr  8 14:58:35.970: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-25dww -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3031'
Apr  8 14:58:36.075: INFO: stderr: ""
Apr  8 14:58:36.075: INFO: stdout: "true"
Apr  8 14:58:36.075: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-25dww -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3031'
Apr  8 14:58:36.174: INFO: stderr: ""
Apr  8 14:58:36.174: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  8 14:58:36.174: INFO: validating pod update-demo-nautilus-25dww
Apr  8 14:58:36.265: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  8 14:58:36.265: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  8 14:58:36.265: INFO: update-demo-nautilus-25dww is verified up and running
Apr  8 14:58:36.265: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-qd494 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3031'
Apr  8 14:58:36.381: INFO: stderr: ""
Apr  8 14:58:36.381: INFO: stdout: "true"
Apr  8 14:58:36.381: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-qd494 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3031'
Apr  8 14:58:36.479: INFO: stderr: ""
Apr  8 14:58:36.479: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  8 14:58:36.479: INFO: validating pod update-demo-nautilus-qd494
Apr  8 14:58:36.569: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  8 14:58:36.569: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  8 14:58:36.569: INFO: update-demo-nautilus-qd494 is verified up and running
STEP: scaling down the replication controller
Apr  8 14:58:36.575: INFO: scanned /root for discovery docs: <nil>
Apr  8 14:58:36.575: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-3031'
Apr  8 14:58:36.753: INFO: stderr: ""
Apr  8 14:58:36.753: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr  8 14:58:36.753: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3031'
Apr  8 14:58:36.937: INFO: stderr: ""
Apr  8 14:58:36.937: INFO: stdout: "update-demo-nautilus-25dww update-demo-nautilus-qd494 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Apr  8 14:58:41.937: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3031'
Apr  8 14:58:42.046: INFO: stderr: ""
Apr  8 14:58:42.046: INFO: stdout: "update-demo-nautilus-25dww update-demo-nautilus-qd494 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Apr  8 14:58:47.046: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3031'
Apr  8 14:58:47.178: INFO: stderr: ""
Apr  8 14:58:47.178: INFO: stdout: "update-demo-nautilus-25dww "
Apr  8 14:58:47.178: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-25dww -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3031'
Apr  8 14:58:47.289: INFO: stderr: ""
Apr  8 14:58:47.289: INFO: stdout: "true"
Apr  8 14:58:47.289: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-25dww -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3031'
Apr  8 14:58:47.404: INFO: stderr: ""
Apr  8 14:58:47.404: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  8 14:58:47.404: INFO: validating pod update-demo-nautilus-25dww
Apr  8 14:58:47.412: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  8 14:58:47.412: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  8 14:58:47.412: INFO: update-demo-nautilus-25dww is verified up and running
STEP: scaling up the replication controller
Apr  8 14:58:47.417: INFO: scanned /root for discovery docs: <nil>
Apr  8 14:58:47.417: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-3031'
Apr  8 14:58:48.571: INFO: stderr: ""
Apr  8 14:58:48.571: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr  8 14:58:48.571: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3031'
Apr  8 14:58:48.717: INFO: stderr: ""
Apr  8 14:58:48.717: INFO: stdout: "update-demo-nautilus-25dww update-demo-nautilus-p4rlh "
Apr  8 14:58:48.717: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-25dww -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3031'
Apr  8 14:58:48.840: INFO: stderr: ""
Apr  8 14:58:48.840: INFO: stdout: "true"
Apr  8 14:58:48.840: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-25dww -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3031'
Apr  8 14:58:49.001: INFO: stderr: ""
Apr  8 14:58:49.001: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  8 14:58:49.001: INFO: validating pod update-demo-nautilus-25dww
Apr  8 14:58:49.022: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  8 14:58:49.022: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  8 14:58:49.022: INFO: update-demo-nautilus-25dww is verified up and running
Apr  8 14:58:49.022: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-p4rlh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3031'
Apr  8 14:58:49.159: INFO: stderr: ""
Apr  8 14:58:49.159: INFO: stdout: ""
Apr  8 14:58:49.159: INFO: update-demo-nautilus-p4rlh is created but not running
Apr  8 14:58:54.160: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3031'
Apr  8 14:58:54.268: INFO: stderr: ""
Apr  8 14:58:54.268: INFO: stdout: "update-demo-nautilus-25dww update-demo-nautilus-p4rlh "
Apr  8 14:58:54.268: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-25dww -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3031'
Apr  8 14:58:54.400: INFO: stderr: ""
Apr  8 14:58:54.400: INFO: stdout: "true"
Apr  8 14:58:54.400: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-25dww -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3031'
Apr  8 14:58:54.513: INFO: stderr: ""
Apr  8 14:58:54.513: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  8 14:58:54.514: INFO: validating pod update-demo-nautilus-25dww
Apr  8 14:58:54.521: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  8 14:58:54.521: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  8 14:58:54.521: INFO: update-demo-nautilus-25dww is verified up and running
Apr  8 14:58:54.521: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-p4rlh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3031'
Apr  8 14:58:54.639: INFO: stderr: ""
Apr  8 14:58:54.639: INFO: stdout: "true"
Apr  8 14:58:54.639: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-p4rlh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3031'
Apr  8 14:58:54.774: INFO: stderr: ""
Apr  8 14:58:54.774: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  8 14:58:54.774: INFO: validating pod update-demo-nautilus-p4rlh
Apr  8 14:58:54.879: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  8 14:58:54.880: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  8 14:58:54.880: INFO: update-demo-nautilus-p4rlh is verified up and running
STEP: using delete to clean up resources
Apr  8 14:58:54.880: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-3031'
Apr  8 14:58:55.035: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  8 14:58:55.036: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr  8 14:58:55.036: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get rc,svc -l name=update-demo --no-headers --namespace=kubectl-3031'
Apr  8 14:58:55.161: INFO: stderr: "No resources found.\n"
Apr  8 14:58:55.161: INFO: stdout: ""
Apr  8 14:58:55.161: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods -l name=update-demo --namespace=kubectl-3031 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr  8 14:58:55.287: INFO: stderr: ""
Apr  8 14:58:55.287: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:58:55.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3031" for this suite.
Apr  8 14:59:17.307: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:59:17.437: INFO: namespace kubectl-3031 deletion completed in 22.143872458s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:59:17.437: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-2231
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-2231
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr  8 14:59:17.587: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr  8 14:59:33.669: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.96.0.58:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2231 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  8 14:59:33.669: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
Apr  8 14:59:34.082: INFO: Found all expected endpoints: [netserver-0]
Apr  8 14:59:34.086: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.96.1.113:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2231 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  8 14:59:34.086: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
Apr  8 14:59:34.593: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:59:34.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2231" for this suite.
Apr  8 14:59:56.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 14:59:56.761: INFO: namespace pod-network-test-2231 deletion completed in 22.162583938s
â€¢SSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 14:59:56.761: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-7236
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's command
Apr  8 14:59:56.917: INFO: Waiting up to 5m0s for pod "var-expansion-f93d30a7-5a0e-11e9-b9a9-e6698ebc8bdf" in namespace "var-expansion-7236" to be "success or failure"
Apr  8 14:59:56.921: INFO: Pod "var-expansion-f93d30a7-5a0e-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.52079ms
Apr  8 14:59:58.927: INFO: Pod "var-expansion-f93d30a7-5a0e-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010454643s
STEP: Saw pod success
Apr  8 14:59:58.927: INFO: Pod "var-expansion-f93d30a7-5a0e-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 14:59:58.934: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod var-expansion-f93d30a7-5a0e-11e9-b9a9-e6698ebc8bdf container dapi-container: <nil>
STEP: delete the pod
Apr  8 14:59:58.955: INFO: Waiting for pod var-expansion-f93d30a7-5a0e-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 14:59:58.958: INFO: Pod var-expansion-f93d30a7-5a0e-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 14:59:58.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7236" for this suite.
Apr  8 15:00:04.983: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:00:05.120: INFO: namespace var-expansion-7236 deletion completed in 6.156441652s
â€¢S
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:00:05.120: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7284
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  8 15:00:05.284: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fe3a0231-5a0e-11e9-b9a9-e6698ebc8bdf" in namespace "downward-api-7284" to be "success or failure"
Apr  8 15:00:05.290: INFO: Pod "downwardapi-volume-fe3a0231-5a0e-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 6.563095ms
Apr  8 15:00:07.296: INFO: Pod "downwardapi-volume-fe3a0231-5a0e-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011780606s
STEP: Saw pod success
Apr  8 15:00:07.296: INFO: Pod "downwardapi-volume-fe3a0231-5a0e-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:00:07.300: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod downwardapi-volume-fe3a0231-5a0e-11e9-b9a9-e6698ebc8bdf container client-container: <nil>
STEP: delete the pod
Apr  8 15:00:07.321: INFO: Waiting for pod downwardapi-volume-fe3a0231-5a0e-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:00:07.326: INFO: Pod downwardapi-volume-fe3a0231-5a0e-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:00:07.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7284" for this suite.
Apr  8 15:00:13.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:00:14.137: INFO: namespace downward-api-7284 deletion completed in 6.805700813s
â€¢SSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:00:14.137: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-5838
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5838.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5838.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr  8 15:00:17.089: INFO: DNS probes using dns-5838/dns-test-03a582c3-5a0f-11e9-b9a9-e6698ebc8bdf succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:00:17.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5838" for this suite.
Apr  8 15:00:23.121: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:00:23.240: INFO: namespace dns-5838 deletion completed in 6.132444201s
â€¢SSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:00:23.240: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8743
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  8 15:00:23.386: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:00:25.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8743" for this suite.
Apr  8 15:01:05.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:01:05.574: INFO: namespace pods-8743 deletion completed in 40.136449388s
â€¢SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:01:05.574: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-2609
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Apr  8 15:01:05.747: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-2609,SelfLink:/api/v1/namespaces/watch-2609/configmaps/e2e-watch-test-watch-closed,UID:22448005-5a0f-11e9-8aed-4ea023eb3a48,ResourceVersion:12736,Generation:0,CreationTimestamp:2019-04-08 15:01:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr  8 15:01:05.747: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-2609,SelfLink:/api/v1/namespaces/watch-2609/configmaps/e2e-watch-test-watch-closed,UID:22448005-5a0f-11e9-8aed-4ea023eb3a48,ResourceVersion:12737,Generation:0,CreationTimestamp:2019-04-08 15:01:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Apr  8 15:01:05.762: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-2609,SelfLink:/api/v1/namespaces/watch-2609/configmaps/e2e-watch-test-watch-closed,UID:22448005-5a0f-11e9-8aed-4ea023eb3a48,ResourceVersion:12738,Generation:0,CreationTimestamp:2019-04-08 15:01:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr  8 15:01:05.762: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-2609,SelfLink:/api/v1/namespaces/watch-2609/configmaps/e2e-watch-test-watch-closed,UID:22448005-5a0f-11e9-8aed-4ea023eb3a48,ResourceVersion:12739,Generation:0,CreationTimestamp:2019-04-08 15:01:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:01:05.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2609" for this suite.
Apr  8 15:01:11.780: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:01:11.906: INFO: namespace watch-2609 deletion completed in 6.139302037s
â€¢SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:01:11.906: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-5129
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Apr  8 15:01:12.069: INFO: Pod name pod-release: Found 0 pods out of 1
Apr  8 15:01:17.074: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:01:18.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5129" for this suite.
Apr  8 15:01:24.108: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:01:24.232: INFO: namespace replication-controller-5129 deletion completed in 6.136073378s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:01:24.233: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-4067
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Apr  8 15:01:24.379: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:01:28.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4067" for this suite.
Apr  8 15:01:50.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:01:50.294: INFO: namespace init-container-4067 deletion completed in 22.235126018s
â€¢SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:01:50.294: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5980
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-3cea8d50-5a0f-11e9-b9a9-e6698ebc8bdf
STEP: Creating a pod to test consume secrets
Apr  8 15:01:50.467: INFO: Waiting up to 5m0s for pod "pod-secrets-3ceb4af2-5a0f-11e9-b9a9-e6698ebc8bdf" in namespace "secrets-5980" to be "success or failure"
Apr  8 15:01:50.472: INFO: Pod "pod-secrets-3ceb4af2-5a0f-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 5.421316ms
Apr  8 15:01:52.477: INFO: Pod "pod-secrets-3ceb4af2-5a0f-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010485137s
STEP: Saw pod success
Apr  8 15:01:52.477: INFO: Pod "pod-secrets-3ceb4af2-5a0f-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:01:52.481: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-secrets-3ceb4af2-5a0f-11e9-b9a9-e6698ebc8bdf container secret-volume-test: <nil>
STEP: delete the pod
Apr  8 15:01:52.502: INFO: Waiting for pod pod-secrets-3ceb4af2-5a0f-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:01:52.506: INFO: Pod pod-secrets-3ceb4af2-5a0f-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:01:52.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5980" for this suite.
Apr  8 15:01:58.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:01:58.647: INFO: namespace secrets-5980 deletion completed in 6.137279797s
â€¢SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:01:58.647: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6152
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on tmpfs
Apr  8 15:01:58.801: INFO: Waiting up to 5m0s for pod "pod-41e37596-5a0f-11e9-b9a9-e6698ebc8bdf" in namespace "emptydir-6152" to be "success or failure"
Apr  8 15:01:58.805: INFO: Pod "pod-41e37596-5a0f-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.118516ms
Apr  8 15:02:00.816: INFO: Pod "pod-41e37596-5a0f-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014371776s
STEP: Saw pod success
Apr  8 15:02:00.816: INFO: Pod "pod-41e37596-5a0f-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:02:00.828: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-41e37596-5a0f-11e9-b9a9-e6698ebc8bdf container test-container: <nil>
STEP: delete the pod
Apr  8 15:02:00.873: INFO: Waiting for pod pod-41e37596-5a0f-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:02:00.894: INFO: Pod pod-41e37596-5a0f-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:02:00.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6152" for this suite.
Apr  8 15:02:06.985: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:02:07.502: INFO: namespace emptydir-6152 deletion completed in 6.560342298s
â€¢SSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:02:07.502: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2053
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Apr  8 15:02:10.299: INFO: Successfully updated pod "labelsupdate4736cdd9-5a0f-11e9-b9a9-e6698ebc8bdf"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:02:14.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2053" for this suite.
Apr  8 15:02:36.413: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:02:36.534: INFO: namespace downward-api-2053 deletion completed in 22.149559231s
â€¢SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:02:36.534: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2112
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-5878a51b-5a0f-11e9-b9a9-e6698ebc8bdf
STEP: Creating a pod to test consume configMaps
Apr  8 15:02:36.694: INFO: Waiting up to 5m0s for pod "pod-configmaps-58795aae-5a0f-11e9-b9a9-e6698ebc8bdf" in namespace "configmap-2112" to be "success or failure"
Apr  8 15:02:36.700: INFO: Pod "pod-configmaps-58795aae-5a0f-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 5.419798ms
Apr  8 15:02:38.705: INFO: Pod "pod-configmaps-58795aae-5a0f-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010552096s
STEP: Saw pod success
Apr  8 15:02:38.705: INFO: Pod "pod-configmaps-58795aae-5a0f-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:02:38.709: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-configmaps-58795aae-5a0f-11e9-b9a9-e6698ebc8bdf container configmap-volume-test: <nil>
STEP: delete the pod
Apr  8 15:02:38.733: INFO: Waiting for pod pod-configmaps-58795aae-5a0f-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:02:38.736: INFO: Pod pod-configmaps-58795aae-5a0f-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:02:38.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2112" for this suite.
Apr  8 15:02:44.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:02:44.882: INFO: namespace configmap-2112 deletion completed in 6.14037984s
â€¢SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:02:44.883: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9436
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  8 15:02:45.037: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5d726208-5a0f-11e9-b9a9-e6698ebc8bdf" in namespace "projected-9436" to be "success or failure"
Apr  8 15:02:45.041: INFO: Pod "downwardapi-volume-5d726208-5a0f-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 3.798832ms
Apr  8 15:02:47.046: INFO: Pod "downwardapi-volume-5d726208-5a0f-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008939947s
STEP: Saw pod success
Apr  8 15:02:47.046: INFO: Pod "downwardapi-volume-5d726208-5a0f-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:02:47.050: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod downwardapi-volume-5d726208-5a0f-11e9-b9a9-e6698ebc8bdf container client-container: <nil>
STEP: delete the pod
Apr  8 15:02:47.071: INFO: Waiting for pod downwardapi-volume-5d726208-5a0f-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:02:47.074: INFO: Pod downwardapi-volume-5d726208-5a0f-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:02:47.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9436" for this suite.
Apr  8 15:02:53.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:02:53.216: INFO: namespace projected-9436 deletion completed in 6.136849166s
â€¢SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:02:53.216: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-636
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Apr  8 15:02:53.367: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Apr  8 15:03:00.428: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:03:00.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-636" for this suite.
Apr  8 15:03:06.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:03:06.573: INFO: namespace pods-636 deletion completed in 6.138579892s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:03:06.574: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-7033
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
STEP: reading a file in the container
Apr  8 15:03:09.277: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl exec --namespace=svcaccounts-7033 pod-service-account-6ab1bbc0-5a0f-11e9-b9a9-e6698ebc8bdf -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Apr  8 15:03:09.797: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl exec --namespace=svcaccounts-7033 pod-service-account-6ab1bbc0-5a0f-11e9-b9a9-e6698ebc8bdf -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Apr  8 15:03:10.214: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl exec --namespace=svcaccounts-7033 pod-service-account-6ab1bbc0-5a0f-11e9-b9a9-e6698ebc8bdf -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:03:10.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-7033" for this suite.
Apr  8 15:03:16.794: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:03:16.923: INFO: namespace svcaccounts-7033 deletion completed in 6.14151097s
â€¢SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:03:16.923: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7066
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Apr  8 15:03:17.080: INFO: Waiting up to 5m0s for pod "pod-708bcabe-5a0f-11e9-b9a9-e6698ebc8bdf" in namespace "emptydir-7066" to be "success or failure"
Apr  8 15:03:17.084: INFO: Pod "pod-708bcabe-5a0f-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 3.885558ms
Apr  8 15:03:19.094: INFO: Pod "pod-708bcabe-5a0f-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014246655s
STEP: Saw pod success
Apr  8 15:03:19.094: INFO: Pod "pod-708bcabe-5a0f-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:03:19.101: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-708bcabe-5a0f-11e9-b9a9-e6698ebc8bdf container test-container: <nil>
STEP: delete the pod
Apr  8 15:03:19.126: INFO: Waiting for pod pod-708bcabe-5a0f-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:03:19.131: INFO: Pod pod-708bcabe-5a0f-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:03:19.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7066" for this suite.
Apr  8 15:03:25.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:03:25.311: INFO: namespace emptydir-7066 deletion completed in 6.173867914s
â€¢SSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:03:25.311: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2892
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr  8 15:03:25.466: INFO: Waiting up to 5m0s for pod "downward-api-758b77e3-5a0f-11e9-b9a9-e6698ebc8bdf" in namespace "downward-api-2892" to be "success or failure"
Apr  8 15:03:25.470: INFO: Pod "downward-api-758b77e3-5a0f-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.219685ms
Apr  8 15:03:27.475: INFO: Pod "downward-api-758b77e3-5a0f-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009357745s
STEP: Saw pod success
Apr  8 15:03:27.475: INFO: Pod "downward-api-758b77e3-5a0f-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:03:27.479: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod downward-api-758b77e3-5a0f-11e9-b9a9-e6698ebc8bdf container dapi-container: <nil>
STEP: delete the pod
Apr  8 15:03:27.499: INFO: Waiting for pod downward-api-758b77e3-5a0f-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:03:27.502: INFO: Pod downward-api-758b77e3-5a0f-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:03:27.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2892" for this suite.
Apr  8 15:03:33.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:03:33.643: INFO: namespace downward-api-2892 deletion completed in 6.136691606s
â€¢SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:03:33.643: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6710
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  8 15:03:33.796: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7a826b15-5a0f-11e9-b9a9-e6698ebc8bdf" in namespace "downward-api-6710" to be "success or failure"
Apr  8 15:03:33.800: INFO: Pod "downwardapi-volume-7a826b15-5a0f-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.571702ms
Apr  8 15:03:35.805: INFO: Pod "downwardapi-volume-7a826b15-5a0f-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009641316s
STEP: Saw pod success
Apr  8 15:03:35.806: INFO: Pod "downwardapi-volume-7a826b15-5a0f-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:03:35.809: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod downwardapi-volume-7a826b15-5a0f-11e9-b9a9-e6698ebc8bdf container client-container: <nil>
STEP: delete the pod
Apr  8 15:03:35.836: INFO: Waiting for pod downwardapi-volume-7a826b15-5a0f-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:03:35.843: INFO: Pod downwardapi-volume-7a826b15-5a0f-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:03:35.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6710" for this suite.
Apr  8 15:03:41.860: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:03:41.986: INFO: namespace downward-api-6710 deletion completed in 6.138564748s
â€¢SSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:03:41.986: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-8951
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  8 15:03:42.146: INFO: Creating deployment "nginx-deployment"
Apr  8 15:03:42.150: INFO: Waiting for observed generation 1
Apr  8 15:03:44.166: INFO: Waiting for all required pods to come up
Apr  8 15:03:44.178: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Apr  8 15:03:46.194: INFO: Waiting for deployment "nginx-deployment" to complete
Apr  8 15:03:46.200: INFO: Updating deployment "nginx-deployment" with a non-existent image
Apr  8 15:03:46.208: INFO: Updating deployment nginx-deployment
Apr  8 15:03:46.208: INFO: Waiting for observed generation 2
Apr  8 15:03:48.217: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Apr  8 15:03:48.221: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Apr  8 15:03:48.224: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Apr  8 15:03:48.234: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Apr  8 15:03:48.234: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Apr  8 15:03:48.237: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Apr  8 15:03:48.254: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Apr  8 15:03:48.254: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Apr  8 15:03:48.262: INFO: Updating deployment nginx-deployment
Apr  8 15:03:48.263: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Apr  8 15:03:48.307: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Apr  8 15:03:50.332: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr  8 15:03:50.363: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-8951,SelfLink:/apis/apps/v1/namespaces/deployment-8951/deployments/nginx-deployment,UID:7f7f2cf1-5a0f-11e9-8aed-4ea023eb3a48,ResourceVersion:13532,Generation:3,CreationTimestamp:2019-04-08 15:03:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-04-08 15:03:48 +0000 UTC 2019-04-08 15:03:48 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-04-08 15:03:48 +0000 UTC 2019-04-08 15:03:42 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-5f9595f595" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Apr  8 15:03:50.379: INFO: New ReplicaSet "nginx-deployment-5f9595f595" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595,GenerateName:,Namespace:deployment-8951,SelfLink:/apis/apps/v1/namespaces/deployment-8951/replicasets/nginx-deployment-5f9595f595,UID:81eb22d7-5a0f-11e9-8aed-4ea023eb3a48,ResourceVersion:13529,Generation:3,CreationTimestamp:2019-04-08 15:03:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 7f7f2cf1-5a0f-11e9-8aed-4ea023eb3a48 0xc0027602c7 0xc0027602c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr  8 15:03:50.379: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Apr  8 15:03:50.379: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8,GenerateName:,Namespace:deployment-8951,SelfLink:/apis/apps/v1/namespaces/deployment-8951/replicasets/nginx-deployment-6f478d8d8,UID:7f7fd46d-5a0f-11e9-8aed-4ea023eb3a48,ResourceVersion:13527,Generation:3,CreationTimestamp:2019-04-08 15:03:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 7f7f2cf1-5a0f-11e9-8aed-4ea023eb3a48 0xc0027603a7 0xc0027603a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Apr  8 15:03:50.428: INFO: Pod "nginx-deployment-5f9595f595-2fqbp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-2fqbp,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8951,SelfLink:/api/v1/namespaces/deployment-8951/pods/nginx-deployment-5f9595f595-2fqbp,UID:832ed151-5a0f-11e9-8aed-4ea023eb3a48,ResourceVersion:13504,Generation:0,CreationTimestamp:2019-04-08 15:03:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 81eb22d7-5a0f-11e9-8aed-4ea023eb3a48 0xc002a3ed57 0xc002a3ed58}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-66v97 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-66v97,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-66v97 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a3edd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a3edf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.16,PodIP:,StartTime:2019-04-08 15:03:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  8 15:03:50.428: INFO: Pod "nginx-deployment-5f9595f595-8hvwg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-8hvwg,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8951,SelfLink:/api/v1/namespaces/deployment-8951/pods/nginx-deployment-5f9595f595-8hvwg,UID:834c85d2-5a0f-11e9-8aed-4ea023eb3a48,ResourceVersion:13537,Generation:0,CreationTimestamp:2019-04-08 15:03:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 81eb22d7-5a0f-11e9-8aed-4ea023eb3a48 0xc002a3eec0 0xc002a3eec1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-66v97 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-66v97,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-66v97 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a3ef30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a3ef50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.16,PodIP:,StartTime:2019-04-08 15:03:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  8 15:03:50.429: INFO: Pod "nginx-deployment-5f9595f595-bm5fq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-bm5fq,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8951,SelfLink:/api/v1/namespaces/deployment-8951/pods/nginx-deployment-5f9595f595-bm5fq,UID:81ef2c92-5a0f-11e9-8aed-4ea023eb3a48,ResourceVersion:13467,Generation:0,CreationTimestamp:2019-04-08 15:03:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.63/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 81eb22d7-5a0f-11e9-8aed-4ea023eb3a48 0xc002a3f030 0xc002a3f031}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-66v97 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-66v97,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-66v97 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a3f0a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a3f0c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:46 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.13,PodIP:,StartTime:2019-04-08 15:03:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  8 15:03:50.429: INFO: Pod "nginx-deployment-5f9595f595-c6d8z" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-c6d8z,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8951,SelfLink:/api/v1/namespaces/deployment-8951/pods/nginx-deployment-5f9595f595-c6d8z,UID:835a3cc9-5a0f-11e9-8aed-4ea023eb3a48,ResourceVersion:13544,Generation:0,CreationTimestamp:2019-04-08 15:03:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 81eb22d7-5a0f-11e9-8aed-4ea023eb3a48 0xc002a3f190 0xc002a3f191}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-66v97 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-66v97,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-66v97 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a3f200} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a3f220}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.16,PodIP:,StartTime:2019-04-08 15:03:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  8 15:03:50.429: INFO: Pod "nginx-deployment-5f9595f595-fdqfh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-fdqfh,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8951,SelfLink:/api/v1/namespaces/deployment-8951/pods/nginx-deployment-5f9595f595-fdqfh,UID:81eb909f-5a0f-11e9-8aed-4ea023eb3a48,ResourceVersion:13470,Generation:0,CreationTimestamp:2019-04-08 15:03:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.140/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 81eb22d7-5a0f-11e9-8aed-4ea023eb3a48 0xc002a3f300 0xc002a3f301}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-66v97 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-66v97,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-66v97 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a3f370} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a3f390}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:46 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.16,PodIP:,StartTime:2019-04-08 15:03:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  8 15:03:50.429: INFO: Pod "nginx-deployment-5f9595f595-fv6qm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-fv6qm,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8951,SelfLink:/api/v1/namespaces/deployment-8951/pods/nginx-deployment-5f9595f595-fv6qm,UID:83493dfe-5a0f-11e9-8aed-4ea023eb3a48,ResourceVersion:13534,Generation:0,CreationTimestamp:2019-04-08 15:03:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 81eb22d7-5a0f-11e9-8aed-4ea023eb3a48 0xc002a3f460 0xc002a3f461}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-66v97 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-66v97,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-66v97 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a3f4d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a3f4f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.16,PodIP:,StartTime:2019-04-08 15:03:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  8 15:03:50.429: INFO: Pod "nginx-deployment-5f9595f595-hgv9r" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-hgv9r,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8951,SelfLink:/api/v1/namespaces/deployment-8951/pods/nginx-deployment-5f9595f595-hgv9r,UID:81f027ad-5a0f-11e9-8aed-4ea023eb3a48,ResourceVersion:13469,Generation:0,CreationTimestamp:2019-04-08 15:03:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.139/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 81eb22d7-5a0f-11e9-8aed-4ea023eb3a48 0xc002a3f5d0 0xc002a3f5d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-66v97 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-66v97,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-66v97 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a3f640} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a3f660}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:46 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.16,PodIP:,StartTime:2019-04-08 15:03:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  8 15:03:50.429: INFO: Pod "nginx-deployment-5f9595f595-j66q8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-j66q8,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8951,SelfLink:/api/v1/namespaces/deployment-8951/pods/nginx-deployment-5f9595f595-j66q8,UID:834beba3-5a0f-11e9-8aed-4ea023eb3a48,ResourceVersion:13541,Generation:0,CreationTimestamp:2019-04-08 15:03:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 81eb22d7-5a0f-11e9-8aed-4ea023eb3a48 0xc002a3f730 0xc002a3f731}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-66v97 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-66v97,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-66v97 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a3f7a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a3f7c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.13,PodIP:,StartTime:2019-04-08 15:03:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  8 15:03:50.429: INFO: Pod "nginx-deployment-5f9595f595-jf86v" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-jf86v,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8951,SelfLink:/api/v1/namespaces/deployment-8951/pods/nginx-deployment-5f9595f595-jf86v,UID:835bbe31-5a0f-11e9-8aed-4ea023eb3a48,ResourceVersion:13546,Generation:0,CreationTimestamp:2019-04-08 15:03:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 81eb22d7-5a0f-11e9-8aed-4ea023eb3a48 0xc002a3f890 0xc002a3f891}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-66v97 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-66v97,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-66v97 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a3f900} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a3f920}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.16,PodIP:,StartTime:2019-04-08 15:03:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  8 15:03:50.430: INFO: Pod "nginx-deployment-5f9595f595-mzqrn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-mzqrn,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8951,SelfLink:/api/v1/namespaces/deployment-8951/pods/nginx-deployment-5f9595f595-mzqrn,UID:832e83b2-5a0f-11e9-8aed-4ea023eb3a48,ResourceVersion:13530,Generation:0,CreationTimestamp:2019-04-08 15:03:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 81eb22d7-5a0f-11e9-8aed-4ea023eb3a48 0xc002a3f9f0 0xc002a3f9f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-66v97 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-66v97,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-66v97 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a3fa60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a3fa80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.13,PodIP:,StartTime:2019-04-08 15:03:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  8 15:03:50.430: INFO: Pod "nginx-deployment-5f9595f595-skhqf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-skhqf,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8951,SelfLink:/api/v1/namespaces/deployment-8951/pods/nginx-deployment-5f9595f595-skhqf,UID:81ec2e7a-5a0f-11e9-8aed-4ea023eb3a48,ResourceVersion:13468,Generation:0,CreationTimestamp:2019-04-08 15:03:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.64/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 81eb22d7-5a0f-11e9-8aed-4ea023eb3a48 0xc002a3fb60 0xc002a3fb61}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-66v97 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-66v97,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-66v97 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a3fbd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a3fbf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:46 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.13,PodIP:,StartTime:2019-04-08 15:03:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  8 15:03:50.430: INFO: Pod "nginx-deployment-5f9595f595-t54mc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-t54mc,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8951,SelfLink:/api/v1/namespaces/deployment-8951/pods/nginx-deployment-5f9595f595-t54mc,UID:832c2e59-5a0f-11e9-8aed-4ea023eb3a48,ResourceVersion:13501,Generation:0,CreationTimestamp:2019-04-08 15:03:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 81eb22d7-5a0f-11e9-8aed-4ea023eb3a48 0xc002a3fcc0 0xc002a3fcc1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-66v97 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-66v97,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-66v97 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a3fd30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a3fd50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.13,PodIP:,StartTime:2019-04-08 15:03:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  8 15:03:50.430: INFO: Pod "nginx-deployment-5f9595f595-xtscq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-xtscq,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8951,SelfLink:/api/v1/namespaces/deployment-8951/pods/nginx-deployment-5f9595f595-xtscq,UID:81ec3384-5a0f-11e9-8aed-4ea023eb3a48,ResourceVersion:13545,Generation:0,CreationTimestamp:2019-04-08 15:03:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.138/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 81eb22d7-5a0f-11e9-8aed-4ea023eb3a48 0xc002a3fe40 0xc002a3fe41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-66v97 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-66v97,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-66v97 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a3feb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a3fed0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:46 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.16,PodIP:100.96.1.138,StartTime:2019-04-08 15:03:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  8 15:03:50.430: INFO: Pod "nginx-deployment-6f478d8d8-5mdth" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-5mdth,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8951,SelfLink:/api/v1/namespaces/deployment-8951/pods/nginx-deployment-6f478d8d8-5mdth,UID:834d6f0f-5a0f-11e9-8aed-4ea023eb3a48,ResourceVersion:13543,Generation:0,CreationTimestamp:2019-04-08 15:03:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 7f7fd46d-5a0f-11e9-8aed-4ea023eb3a48 0xc00098c0a0 0xc00098c0a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-66v97 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-66v97,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-66v97 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00098c190} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00098c1c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.16,PodIP:,StartTime:2019-04-08 15:03:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  8 15:03:50.430: INFO: Pod "nginx-deployment-6f478d8d8-6cljd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-6cljd,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8951,SelfLink:/api/v1/namespaces/deployment-8951/pods/nginx-deployment-6f478d8d8-6cljd,UID:7f82a4f8-5a0f-11e9-8aed-4ea023eb3a48,ResourceVersion:13416,Generation:0,CreationTimestamp:2019-04-08 15:03:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.133/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 7f7fd46d-5a0f-11e9-8aed-4ea023eb3a48 0xc00098c320 0xc00098c321}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-66v97 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-66v97,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-66v97 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00098c3c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00098c3e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:42 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:45 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:45 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:42 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.16,PodIP:100.96.1.133,StartTime:2019-04-08 15:03:42 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-08 15:03:44 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://9a309fccc9718dba247a5355fb158cf6647b8f9a40a6aed95fb9a198e6ece150}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  8 15:03:50.430: INFO: Pod "nginx-deployment-6f478d8d8-6swsh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-6swsh,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8951,SelfLink:/api/v1/namespaces/deployment-8951/pods/nginx-deployment-6f478d8d8-6swsh,UID:832c00f8-5a0f-11e9-8aed-4ea023eb3a48,ResourceVersion:13499,Generation:0,CreationTimestamp:2019-04-08 15:03:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 7f7fd46d-5a0f-11e9-8aed-4ea023eb3a48 0xc00098c4b0 0xc00098c4b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-66v97 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-66v97,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-66v97 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00098c5a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00098c5c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.16,PodIP:,StartTime:2019-04-08 15:03:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  8 15:03:50.430: INFO: Pod "nginx-deployment-6f478d8d8-74jv7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-74jv7,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8951,SelfLink:/api/v1/namespaces/deployment-8951/pods/nginx-deployment-6f478d8d8-74jv7,UID:833a7871-5a0f-11e9-8aed-4ea023eb3a48,ResourceVersion:13510,Generation:0,CreationTimestamp:2019-04-08 15:03:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 7f7fd46d-5a0f-11e9-8aed-4ea023eb3a48 0xc00098c730 0xc00098c731}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-66v97 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-66v97,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-66v97 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00098c7b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00098c7d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.16,PodIP:,StartTime:2019-04-08 15:03:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  8 15:03:50.431: INFO: Pod "nginx-deployment-6f478d8d8-7n8h2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-7n8h2,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8951,SelfLink:/api/v1/namespaces/deployment-8951/pods/nginx-deployment-6f478d8d8-7n8h2,UID:8358447f-5a0f-11e9-8aed-4ea023eb3a48,ResourceVersion:13539,Generation:0,CreationTimestamp:2019-04-08 15:03:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 7f7fd46d-5a0f-11e9-8aed-4ea023eb3a48 0xc00098c8f0 0xc00098c8f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-66v97 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-66v97,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-66v97 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00098c950} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00098c9c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.13,PodIP:,StartTime:2019-04-08 15:03:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  8 15:03:50.431: INFO: Pod "nginx-deployment-6f478d8d8-7zx4s" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-7zx4s,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8951,SelfLink:/api/v1/namespaces/deployment-8951/pods/nginx-deployment-6f478d8d8-7zx4s,UID:833ac8e0-5a0f-11e9-8aed-4ea023eb3a48,ResourceVersion:13548,Generation:0,CreationTimestamp:2019-04-08 15:03:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.65/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 7f7fd46d-5a0f-11e9-8aed-4ea023eb3a48 0xc00098cbc0 0xc00098cbc1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-66v97 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-66v97,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-66v97 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00098cc20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00098cc40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.13,PodIP:,StartTime:2019-04-08 15:03:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  8 15:03:50.431: INFO: Pod "nginx-deployment-6f478d8d8-8497n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-8497n,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8951,SelfLink:/api/v1/namespaces/deployment-8951/pods/nginx-deployment-6f478d8d8-8497n,UID:834aef4f-5a0f-11e9-8aed-4ea023eb3a48,ResourceVersion:13538,Generation:0,CreationTimestamp:2019-04-08 15:03:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 7f7fd46d-5a0f-11e9-8aed-4ea023eb3a48 0xc00098cd30 0xc00098cd31}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-66v97 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-66v97,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-66v97 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00098cda0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00098cdc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.13,PodIP:,StartTime:2019-04-08 15:03:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  8 15:03:50.431: INFO: Pod "nginx-deployment-6f478d8d8-9mlt9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-9mlt9,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8951,SelfLink:/api/v1/namespaces/deployment-8951/pods/nginx-deployment-6f478d8d8-9mlt9,UID:832bb0d5-5a0f-11e9-8aed-4ea023eb3a48,ResourceVersion:13492,Generation:0,CreationTimestamp:2019-04-08 15:03:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 7f7fd46d-5a0f-11e9-8aed-4ea023eb3a48 0xc00098d010 0xc00098d011}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-66v97 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-66v97,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-66v97 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00098d070} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00098d130}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.16,PodIP:,StartTime:2019-04-08 15:03:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  8 15:03:50.431: INFO: Pod "nginx-deployment-6f478d8d8-dhk75" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-dhk75,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8951,SelfLink:/api/v1/namespaces/deployment-8951/pods/nginx-deployment-6f478d8d8-dhk75,UID:7f82be8e-5a0f-11e9-8aed-4ea023eb3a48,ResourceVersion:13404,Generation:0,CreationTimestamp:2019-04-08 15:03:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.59/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 7f7fd46d-5a0f-11e9-8aed-4ea023eb3a48 0xc00098d290 0xc00098d291}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-66v97 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-66v97,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-66v97 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00098d320} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00098d370}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:42 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:45 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:45 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:42 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.13,PodIP:100.96.0.59,StartTime:2019-04-08 15:03:42 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-08 15:03:44 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://901e54c30ee68203e07806b20639a77b0a4d97d2d4eb42752ae0f8995f076b52}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  8 15:03:50.431: INFO: Pod "nginx-deployment-6f478d8d8-dt44r" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-dt44r,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8951,SelfLink:/api/v1/namespaces/deployment-8951/pods/nginx-deployment-6f478d8d8-dt44r,UID:7f84afc1-5a0f-11e9-8aed-4ea023eb3a48,ResourceVersion:13407,Generation:0,CreationTimestamp:2019-04-08 15:03:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.60/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 7f7fd46d-5a0f-11e9-8aed-4ea023eb3a48 0xc00098d560 0xc00098d561}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-66v97 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-66v97,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-66v97 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00098d5e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00098d620}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:42 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:45 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:45 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:42 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.13,PodIP:100.96.0.60,StartTime:2019-04-08 15:03:42 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-08 15:03:44 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://566f5ba8cc8bcfcd481e8b8f12e7e73f4127e8317eb9c7a1133a02fadccf752f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  8 15:03:50.431: INFO: Pod "nginx-deployment-6f478d8d8-f52mq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-f52mq,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8951,SelfLink:/api/v1/namespaces/deployment-8951/pods/nginx-deployment-6f478d8d8-f52mq,UID:834cf2f6-5a0f-11e9-8aed-4ea023eb3a48,ResourceVersion:13542,Generation:0,CreationTimestamp:2019-04-08 15:03:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 7f7fd46d-5a0f-11e9-8aed-4ea023eb3a48 0xc00098d700 0xc00098d701}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-66v97 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-66v97,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-66v97 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00098d770} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00098d790}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.13,PodIP:,StartTime:2019-04-08 15:03:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  8 15:03:50.432: INFO: Pod "nginx-deployment-6f478d8d8-fspp6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-fspp6,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8951,SelfLink:/api/v1/namespaces/deployment-8951/pods/nginx-deployment-6f478d8d8-fspp6,UID:7f82d7f2-5a0f-11e9-8aed-4ea023eb3a48,ResourceVersion:13419,Generation:0,CreationTimestamp:2019-04-08 15:03:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.135/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 7f7fd46d-5a0f-11e9-8aed-4ea023eb3a48 0xc00098d860 0xc00098d861}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-66v97 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-66v97,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-66v97 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00098d9b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00098d9d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:42 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:45 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:45 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:42 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.16,PodIP:100.96.1.135,StartTime:2019-04-08 15:03:42 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-08 15:03:44 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://747b5c9f2205a4fedea4f8b2872f7926669dbc4b26ff23fdec4b607220c194b4}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  8 15:03:50.432: INFO: Pod "nginx-deployment-6f478d8d8-h427d" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-h427d,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8951,SelfLink:/api/v1/namespaces/deployment-8951/pods/nginx-deployment-6f478d8d8-h427d,UID:832aa031-5a0f-11e9-8aed-4ea023eb3a48,ResourceVersion:13552,Generation:0,CreationTimestamp:2019-04-08 15:03:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.67/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 7f7fd46d-5a0f-11e9-8aed-4ea023eb3a48 0xc00098dab0 0xc00098dab1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-66v97 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-66v97,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-66v97 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00098db20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00098db40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.13,PodIP:,StartTime:2019-04-08 15:03:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  8 15:03:50.432: INFO: Pod "nginx-deployment-6f478d8d8-j2pbz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-j2pbz,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8951,SelfLink:/api/v1/namespaces/deployment-8951/pods/nginx-deployment-6f478d8d8-j2pbz,UID:835aa67b-5a0f-11e9-8aed-4ea023eb3a48,ResourceVersion:13540,Generation:0,CreationTimestamp:2019-04-08 15:03:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 7f7fd46d-5a0f-11e9-8aed-4ea023eb3a48 0xc00098dc30 0xc00098dc31}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-66v97 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-66v97,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-66v97 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00098dca0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00098dcc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.13,PodIP:,StartTime:2019-04-08 15:03:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  8 15:03:50.432: INFO: Pod "nginx-deployment-6f478d8d8-j84fb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-j84fb,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8951,SelfLink:/api/v1/namespaces/deployment-8951/pods/nginx-deployment-6f478d8d8-j84fb,UID:8339c578-5a0f-11e9-8aed-4ea023eb3a48,ResourceVersion:13549,Generation:0,CreationTimestamp:2019-04-08 15:03:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.66/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 7f7fd46d-5a0f-11e9-8aed-4ea023eb3a48 0xc00098dda0 0xc00098dda1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-66v97 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-66v97,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-66v97 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00098de00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00098de20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.13,PodIP:,StartTime:2019-04-08 15:03:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  8 15:03:50.432: INFO: Pod "nginx-deployment-6f478d8d8-nt987" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-nt987,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8951,SelfLink:/api/v1/namespaces/deployment-8951/pods/nginx-deployment-6f478d8d8-nt987,UID:7f842c92-5a0f-11e9-8aed-4ea023eb3a48,ResourceVersion:13410,Generation:0,CreationTimestamp:2019-04-08 15:03:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.136/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 7f7fd46d-5a0f-11e9-8aed-4ea023eb3a48 0xc00098def0 0xc00098def1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-66v97 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-66v97,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-66v97 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00098df50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00098df70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:42 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:45 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:45 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:42 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.16,PodIP:100.96.1.136,StartTime:2019-04-08 15:03:42 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-08 15:03:44 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://ede2fa5c113a7dc0ab3e1c5ca5208096d2cdcc8a926b30688355255f98961022}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  8 15:03:50.432: INFO: Pod "nginx-deployment-6f478d8d8-p9758" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-p9758,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8951,SelfLink:/api/v1/namespaces/deployment-8951/pods/nginx-deployment-6f478d8d8-p9758,UID:7f80fd41-5a0f-11e9-8aed-4ea023eb3a48,ResourceVersion:13413,Generation:0,CreationTimestamp:2019-04-08 15:03:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.134/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 7f7fd46d-5a0f-11e9-8aed-4ea023eb3a48 0xc000e2c050 0xc000e2c051}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-66v97 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-66v97,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-66v97 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e2c0b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e2c0d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:42 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:45 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:45 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:42 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.16,PodIP:100.96.1.134,StartTime:2019-04-08 15:03:42 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-08 15:03:44 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://a1420e53f780debee025175a53b034391f87e6b2a2576919a6dfd7895aedd7e5}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  8 15:03:50.432: INFO: Pod "nginx-deployment-6f478d8d8-s5dbs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-s5dbs,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8951,SelfLink:/api/v1/namespaces/deployment-8951/pods/nginx-deployment-6f478d8d8-s5dbs,UID:833af29f-5a0f-11e9-8aed-4ea023eb3a48,ResourceVersion:13526,Generation:0,CreationTimestamp:2019-04-08 15:03:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 7f7fd46d-5a0f-11e9-8aed-4ea023eb3a48 0xc000e2c1b0 0xc000e2c1b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-66v97 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-66v97,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-66v97 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e2c210} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e2c230}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:48 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.16,PodIP:,StartTime:2019-04-08 15:03:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  8 15:03:50.432: INFO: Pod "nginx-deployment-6f478d8d8-vvk7r" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-vvk7r,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8951,SelfLink:/api/v1/namespaces/deployment-8951/pods/nginx-deployment-6f478d8d8-vvk7r,UID:7f84d279-5a0f-11e9-8aed-4ea023eb3a48,ResourceVersion:13422,Generation:0,CreationTimestamp:2019-04-08 15:03:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.137/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 7f7fd46d-5a0f-11e9-8aed-4ea023eb3a48 0xc000e2c310 0xc000e2c311}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-66v97 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-66v97,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-66v97 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e2c370} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e2c390}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:42 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:45 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:45 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:42 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.16,PodIP:100.96.1.137,StartTime:2019-04-08 15:03:42 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-08 15:03:45 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://7ddedbecfa98bc0ff86f0310c6297d5214df43f4f231b94ce47b7d2b97f51928}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  8 15:03:50.433: INFO: Pod "nginx-deployment-6f478d8d8-x7gds" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-x7gds,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8951,SelfLink:/api/v1/namespaces/deployment-8951/pods/nginx-deployment-6f478d8d8-x7gds,UID:7f817dcd-5a0f-11e9-8aed-4ea023eb3a48,ResourceVersion:13401,Generation:0,CreationTimestamp:2019-04-08 15:03:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.62/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 7f7fd46d-5a0f-11e9-8aed-4ea023eb3a48 0xc000e2c490 0xc000e2c491}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-66v97 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-66v97,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-66v97 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e2c500} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e2c520}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:42 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:45 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:45 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:03:42 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.13,PodIP:100.96.0.62,StartTime:2019-04-08 15:03:42 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-08 15:03:44 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://611bc367fabde9813f23707ade07796a3915c915935f19a1e2b68a79677ce0a8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:03:50.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8951" for this suite.
Apr  8 15:03:56.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:03:56.628: INFO: namespace deployment-8951 deletion completed in 6.182045792s
â€¢SSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:03:56.628: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5815
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr  8 15:03:56.785: INFO: Waiting up to 5m0s for pod "downward-api-88361e34-5a0f-11e9-b9a9-e6698ebc8bdf" in namespace "downward-api-5815" to be "success or failure"
Apr  8 15:03:56.790: INFO: Pod "downward-api-88361e34-5a0f-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 5.077524ms
Apr  8 15:03:58.795: INFO: Pod "downward-api-88361e34-5a0f-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010127307s
Apr  8 15:04:00.801: INFO: Pod "downward-api-88361e34-5a0f-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015667949s
STEP: Saw pod success
Apr  8 15:04:00.801: INFO: Pod "downward-api-88361e34-5a0f-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:04:00.805: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod downward-api-88361e34-5a0f-11e9-b9a9-e6698ebc8bdf container dapi-container: <nil>
STEP: delete the pod
Apr  8 15:04:00.834: INFO: Waiting for pod downward-api-88361e34-5a0f-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:04:00.838: INFO: Pod downward-api-88361e34-5a0f-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:04:00.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5815" for this suite.
Apr  8 15:04:06.860: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:04:07.001: INFO: namespace downward-api-5815 deletion completed in 6.156901768s
â€¢SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:04:07.001: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8995
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Apr  8 15:04:09.681: INFO: Successfully updated pod "pod-update-activedeadlineseconds-8e64858f-5a0f-11e9-b9a9-e6698ebc8bdf"
Apr  8 15:04:09.681: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-8e64858f-5a0f-11e9-b9a9-e6698ebc8bdf" in namespace "pods-8995" to be "terminated due to deadline exceeded"
Apr  8 15:04:09.686: INFO: Pod "pod-update-activedeadlineseconds-8e64858f-5a0f-11e9-b9a9-e6698ebc8bdf": Phase="Running", Reason="", readiness=true. Elapsed: 4.786982ms
Apr  8 15:04:11.691: INFO: Pod "pod-update-activedeadlineseconds-8e64858f-5a0f-11e9-b9a9-e6698ebc8bdf": Phase="Running", Reason="", readiness=true. Elapsed: 2.009886989s
Apr  8 15:04:13.714: INFO: Pod "pod-update-activedeadlineseconds-8e64858f-5a0f-11e9-b9a9-e6698ebc8bdf": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.033332269s
Apr  8 15:04:13.714: INFO: Pod "pod-update-activedeadlineseconds-8e64858f-5a0f-11e9-b9a9-e6698ebc8bdf" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:04:13.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8995" for this suite.
Apr  8 15:04:19.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:04:19.967: INFO: namespace pods-8995 deletion completed in 6.214701095s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:04:19.968: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2419
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Apr  8 15:04:22.687: INFO: Successfully updated pod "annotationupdate96224fde-5a0f-11e9-b9a9-e6698ebc8bdf"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:04:24.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2419" for this suite.
Apr  8 15:04:46.746: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:04:46.869: INFO: namespace projected-2419 deletion completed in 22.136477144s
â€¢SS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:04:46.869: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-3325
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-6118
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-5349
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:04:53.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-3325" for this suite.
Apr  8 15:04:59.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:04:59.473: INFO: namespace namespaces-3325 deletion completed in 6.128735355s
STEP: Destroying namespace "nsdeletetest-6118" for this suite.
Apr  8 15:04:59.477: INFO: Namespace nsdeletetest-6118 was already deleted
STEP: Destroying namespace "nsdeletetest-5349" for this suite.
Apr  8 15:05:05.492: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:05:05.634: INFO: namespace nsdeletetest-5349 deletion completed in 6.156898621s
â€¢SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:05:05.634: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-5297
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0408 15:05:35.827450    5043 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr  8 15:05:35.827: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:05:35.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5297" for this suite.
Apr  8 15:05:41.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:05:41.978: INFO: namespace gc-5297 deletion completed in 6.14633867s
â€¢SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:05:41.978: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2932
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-c701932d-5a0f-11e9-b9a9-e6698ebc8bdf
STEP: Creating a pod to test consume configMaps
Apr  8 15:05:42.140: INFO: Waiting up to 5m0s for pod "pod-configmaps-c7023a47-5a0f-11e9-b9a9-e6698ebc8bdf" in namespace "configmap-2932" to be "success or failure"
Apr  8 15:05:42.147: INFO: Pod "pod-configmaps-c7023a47-5a0f-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 7.133817ms
Apr  8 15:05:44.154: INFO: Pod "pod-configmaps-c7023a47-5a0f-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013487632s
STEP: Saw pod success
Apr  8 15:05:44.154: INFO: Pod "pod-configmaps-c7023a47-5a0f-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:05:44.158: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-configmaps-c7023a47-5a0f-11e9-b9a9-e6698ebc8bdf container configmap-volume-test: <nil>
STEP: delete the pod
Apr  8 15:05:44.187: INFO: Waiting for pod pod-configmaps-c7023a47-5a0f-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:05:44.194: INFO: Pod pod-configmaps-c7023a47-5a0f-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:05:44.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2932" for this suite.
Apr  8 15:05:50.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:05:50.368: INFO: namespace configmap-2932 deletion completed in 6.158770962s
â€¢SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:05:50.368: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6888
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Apr  8 15:05:53.060: INFO: Successfully updated pod "labelsupdatecc01459b-5a0f-11e9-b9a9-e6698ebc8bdf"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:05:57.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6888" for this suite.
Apr  8 15:06:19.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:06:19.239: INFO: namespace projected-6888 deletion completed in 22.137703821s
â€¢SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:06:19.239: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8138
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-dd36ed0e-5a0f-11e9-b9a9-e6698ebc8bdf
STEP: Creating a pod to test consume configMaps
Apr  8 15:06:19.400: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-dd37c86e-5a0f-11e9-b9a9-e6698ebc8bdf" in namespace "projected-8138" to be "success or failure"
Apr  8 15:06:19.405: INFO: Pod "pod-projected-configmaps-dd37c86e-5a0f-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 5.149528ms
Apr  8 15:06:21.412: INFO: Pod "pod-projected-configmaps-dd37c86e-5a0f-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011505833s
STEP: Saw pod success
Apr  8 15:06:21.412: INFO: Pod "pod-projected-configmaps-dd37c86e-5a0f-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:06:21.416: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-projected-configmaps-dd37c86e-5a0f-11e9-b9a9-e6698ebc8bdf container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr  8 15:06:21.459: INFO: Waiting for pod pod-projected-configmaps-dd37c86e-5a0f-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:06:21.462: INFO: Pod pod-projected-configmaps-dd37c86e-5a0f-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:06:21.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8138" for this suite.
Apr  8 15:06:27.496: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:06:27.609: INFO: namespace projected-8138 deletion completed in 6.12900103s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:06:27.610: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6939
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-e2335ac0-5a0f-11e9-b9a9-e6698ebc8bdf
STEP: Creating a pod to test consume configMaps
Apr  8 15:06:27.764: INFO: Waiting up to 5m0s for pod "pod-configmaps-e233f777-5a0f-11e9-b9a9-e6698ebc8bdf" in namespace "configmap-6939" to be "success or failure"
Apr  8 15:06:27.769: INFO: Pod "pod-configmaps-e233f777-5a0f-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.574568ms
Apr  8 15:06:29.774: INFO: Pod "pod-configmaps-e233f777-5a0f-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010062452s
STEP: Saw pod success
Apr  8 15:06:29.774: INFO: Pod "pod-configmaps-e233f777-5a0f-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:06:29.777: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-configmaps-e233f777-5a0f-11e9-b9a9-e6698ebc8bdf container configmap-volume-test: <nil>
STEP: delete the pod
Apr  8 15:06:29.796: INFO: Waiting for pod pod-configmaps-e233f777-5a0f-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:06:29.799: INFO: Pod pod-configmaps-e233f777-5a0f-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:06:29.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6939" for this suite.
Apr  8 15:06:35.815: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:06:35.938: INFO: namespace configmap-6939 deletion completed in 6.13413716s
â€¢SSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:06:35.938: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-5559
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:06:39.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5559" for this suite.
Apr  8 15:07:01.136: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:07:01.311: INFO: namespace replication-controller-5559 deletion completed in 22.187667793s
â€¢
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:07:01.311: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-2701
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service multi-endpoint-test in namespace services-2701
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2701 to expose endpoints map[]
Apr  8 15:07:01.481: INFO: successfully validated that service multi-endpoint-test in namespace services-2701 exposes endpoints map[] (5.489433ms elapsed)
STEP: Creating pod pod1 in namespace services-2701
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2701 to expose endpoints map[pod1:[100]]
Apr  8 15:07:03.517: INFO: successfully validated that service multi-endpoint-test in namespace services-2701 exposes endpoints map[pod1:[100]] (2.028076457s elapsed)
STEP: Creating pod pod2 in namespace services-2701
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2701 to expose endpoints map[pod1:[100] pod2:[101]]
Apr  8 15:07:06.568: INFO: successfully validated that service multi-endpoint-test in namespace services-2701 exposes endpoints map[pod1:[100] pod2:[101]] (3.045789675s elapsed)
STEP: Deleting pod pod1 in namespace services-2701
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2701 to expose endpoints map[pod2:[101]]
Apr  8 15:07:06.582: INFO: successfully validated that service multi-endpoint-test in namespace services-2701 exposes endpoints map[pod2:[101]] (8.300373ms elapsed)
STEP: Deleting pod pod2 in namespace services-2701
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2701 to expose endpoints map[]
Apr  8 15:07:06.591: INFO: successfully validated that service multi-endpoint-test in namespace services-2701 exposes endpoints map[] (3.456249ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:07:06.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2701" for this suite.
Apr  8 15:07:28.626: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:07:28.744: INFO: namespace services-2701 deletion completed in 22.132330188s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:07:28.745: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7397
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Apr  8 15:07:28.898: INFO: Waiting up to 5m0s for pod "pod-06a4158f-5a10-11e9-b9a9-e6698ebc8bdf" in namespace "emptydir-7397" to be "success or failure"
Apr  8 15:07:28.901: INFO: Pod "pod-06a4158f-5a10-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 3.079944ms
Apr  8 15:07:30.906: INFO: Pod "pod-06a4158f-5a10-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008165828s
STEP: Saw pod success
Apr  8 15:07:30.906: INFO: Pod "pod-06a4158f-5a10-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:07:30.909: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-06a4158f-5a10-11e9-b9a9-e6698ebc8bdf container test-container: <nil>
STEP: delete the pod
Apr  8 15:07:30.932: INFO: Waiting for pod pod-06a4158f-5a10-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:07:30.935: INFO: Pod pod-06a4158f-5a10-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:07:30.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7397" for this suite.
Apr  8 15:07:36.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:07:37.502: INFO: namespace emptydir-7397 deletion completed in 6.562904324s
â€¢SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:07:37.502: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6310
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-0bde16dd-5a10-11e9-b9a9-e6698ebc8bdf
STEP: Creating a pod to test consume secrets
Apr  8 15:07:37.671: INFO: Waiting up to 5m0s for pod "pod-secrets-0bded291-5a10-11e9-b9a9-e6698ebc8bdf" in namespace "secrets-6310" to be "success or failure"
Apr  8 15:07:37.677: INFO: Pod "pod-secrets-0bded291-5a10-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 5.947404ms
Apr  8 15:07:39.682: INFO: Pod "pod-secrets-0bded291-5a10-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011020777s
STEP: Saw pod success
Apr  8 15:07:39.682: INFO: Pod "pod-secrets-0bded291-5a10-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:07:39.686: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-secrets-0bded291-5a10-11e9-b9a9-e6698ebc8bdf container secret-volume-test: <nil>
STEP: delete the pod
Apr  8 15:07:39.707: INFO: Waiting for pod pod-secrets-0bded291-5a10-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:07:39.711: INFO: Pod pod-secrets-0bded291-5a10-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:07:39.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6310" for this suite.
Apr  8 15:07:45.730: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:07:45.857: INFO: namespace secrets-6310 deletion completed in 6.139601862s
â€¢SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:07:45.857: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9674
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-10d7fb33-5a10-11e9-b9a9-e6698ebc8bdf
STEP: Creating a pod to test consume configMaps
Apr  8 15:07:46.019: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-10d89ac3-5a10-11e9-b9a9-e6698ebc8bdf" in namespace "projected-9674" to be "success or failure"
Apr  8 15:07:46.024: INFO: Pod "pod-projected-configmaps-10d89ac3-5a10-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.969133ms
Apr  8 15:07:48.030: INFO: Pod "pod-projected-configmaps-10d89ac3-5a10-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010491649s
STEP: Saw pod success
Apr  8 15:07:48.030: INFO: Pod "pod-projected-configmaps-10d89ac3-5a10-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:07:48.034: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-projected-configmaps-10d89ac3-5a10-11e9-b9a9-e6698ebc8bdf container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr  8 15:07:48.055: INFO: Waiting for pod pod-projected-configmaps-10d89ac3-5a10-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:07:48.058: INFO: Pod pod-projected-configmaps-10d89ac3-5a10-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:07:48.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9674" for this suite.
Apr  8 15:07:54.077: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:07:54.208: INFO: namespace projected-9674 deletion completed in 6.144483642s
â€¢S
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:07:54.208: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-2929
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's args
Apr  8 15:07:54.364: INFO: Waiting up to 5m0s for pod "var-expansion-15d18db3-5a10-11e9-b9a9-e6698ebc8bdf" in namespace "var-expansion-2929" to be "success or failure"
Apr  8 15:07:54.368: INFO: Pod "var-expansion-15d18db3-5a10-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 3.872084ms
Apr  8 15:07:56.373: INFO: Pod "var-expansion-15d18db3-5a10-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008847843s
STEP: Saw pod success
Apr  8 15:07:56.373: INFO: Pod "var-expansion-15d18db3-5a10-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:07:56.377: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod var-expansion-15d18db3-5a10-11e9-b9a9-e6698ebc8bdf container dapi-container: <nil>
STEP: delete the pod
Apr  8 15:07:56.398: INFO: Waiting for pod var-expansion-15d18db3-5a10-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:07:56.402: INFO: Pod var-expansion-15d18db3-5a10-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:07:56.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2929" for this suite.
Apr  8 15:08:02.424: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:08:02.575: INFO: namespace var-expansion-2929 deletion completed in 6.168185445s
â€¢SSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:08:02.575: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7252
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-1ad2314a-5a10-11e9-b9a9-e6698ebc8bdf
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-1ad2314a-5a10-11e9-b9a9-e6698ebc8bdf
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:08:06.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7252" for this suite.
Apr  8 15:08:28.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:08:29.090: INFO: namespace configmap-7252 deletion completed in 22.147785013s
â€¢SSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:08:29.090: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-9266
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Apr  8 15:08:29.233: INFO: PodSpec: initContainers in spec.initContainers
Apr  8 15:09:13.246: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-2a9bc412-5a10-11e9-b9a9-e6698ebc8bdf", GenerateName:"", Namespace:"init-container-9266", SelfLink:"/api/v1/namespaces/init-container-9266/pods/pod-init-2a9bc412-5a10-11e9-b9a9-e6698ebc8bdf", UID:"2a9dd112-5a10-11e9-8aed-4ea023eb3a48", ResourceVersion:"14793", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63690332909, loc:(*time.Location)(0x89f10e0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"233875001"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"100.96.1.166/32", "kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-trv5c", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002f40000), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-trv5c", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-trv5c", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-trv5c", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0006860d8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002856120), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc000686150)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc000686180)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc000686188), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00068618c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690332909, loc:(*time.Location)(0x89f10e0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690332909, loc:(*time.Location)(0x89f10e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690332909, loc:(*time.Location)(0x89f10e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690332909, loc:(*time.Location)(0x89f10e0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.250.0.16", PodIP:"100.96.1.166", StartTime:(*v1.Time)(0xc002fb6320), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002554070)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0025540e0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://17cd925ea80da737f45e0bf569f17da07602dc7eb712b56418d57a0c55d74324"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002fb6420), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002fb6340), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:09:13.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9266" for this suite.
Apr  8 15:09:35.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:09:35.457: INFO: namespace init-container-9266 deletion completed in 22.203248651s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:09:35.457: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-6822
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  8 15:09:35.608: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Apr  8 15:09:35.619: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr  8 15:09:40.627: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr  8 15:09:40.627: INFO: Creating deployment "test-rolling-update-deployment"
Apr  8 15:09:40.634: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Apr  8 15:09:40.642: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Apr  8 15:09:42.651: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Apr  8 15:09:42.656: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr  8 15:09:42.667: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-6822,SelfLink:/apis/apps/v1/namespaces/deployment-6822/deployments/test-rolling-update-deployment,UID:552b71b8-5a10-11e9-8aed-4ea023eb3a48,ResourceVersion:14900,Generation:1,CreationTimestamp:2019-04-08 15:09:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-04-08 15:09:40 +0000 UTC 2019-04-08 15:09:40 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-04-08 15:09:41 +0000 UTC 2019-04-08 15:09:40 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-67599b4d9" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Apr  8 15:09:42.671: INFO: New ReplicaSet "test-rolling-update-deployment-67599b4d9" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-67599b4d9,GenerateName:,Namespace:deployment-6822,SelfLink:/apis/apps/v1/namespaces/deployment-6822/replicasets/test-rolling-update-deployment-67599b4d9,UID:552d2949-5a10-11e9-8aed-4ea023eb3a48,ResourceVersion:14893,Generation:1,CreationTimestamp:2019-04-08 15:09:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 552b71b8-5a10-11e9-8aed-4ea023eb3a48 0xc002deda70 0xc002deda71}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Apr  8 15:09:42.671: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Apr  8 15:09:42.671: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-6822,SelfLink:/apis/apps/v1/namespaces/deployment-6822/replicasets/test-rolling-update-controller,UID:522d7003-5a10-11e9-8aed-4ea023eb3a48,ResourceVersion:14899,Generation:2,CreationTimestamp:2019-04-08 15:09:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 552b71b8-5a10-11e9-8aed-4ea023eb3a48 0xc002ded9a7 0xc002ded9a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr  8 15:09:42.676: INFO: Pod "test-rolling-update-deployment-67599b4d9-kxmp4" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-67599b4d9-kxmp4,GenerateName:test-rolling-update-deployment-67599b4d9-,Namespace:deployment-6822,SelfLink:/api/v1/namespaces/deployment-6822/pods/test-rolling-update-deployment-67599b4d9-kxmp4,UID:552da128-5a10-11e9-8aed-4ea023eb3a48,ResourceVersion:14892,Generation:0,CreationTimestamp:2019-04-08 15:09:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.168/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-67599b4d9 552d2949-5a10-11e9-8aed-4ea023eb3a48 0xc00098c500 0xc00098c501}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-gcllh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gcllh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-gcllh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00098c5d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00098c5f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:09:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:09:41 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:09:41 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:09:40 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.16,PodIP:100.96.1.168,StartTime:2019-04-08 15:09:40 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-04-08 15:09:41 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://fdbd12d85624705b7f5ab75630ace74afc08c7d827fb5409b06b188d3f3c077d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:09:42.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6822" for this suite.
Apr  8 15:09:48.697: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:09:48.847: INFO: namespace deployment-6822 deletion completed in 6.16362484s
â€¢SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:09:48.847: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-8802
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Apr  8 15:09:49.013: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:09:51.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8802" for this suite.
Apr  8 15:09:57.774: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:09:57.896: INFO: namespace init-container-8802 deletion completed in 6.13394151s
â€¢SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:09:57.896: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8921
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with configMap that has name projected-configmap-test-upd-5f8b1a9f-5a10-11e9-b9a9-e6698ebc8bdf
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-5f8b1a9f-5a10-11e9-b9a9-e6698ebc8bdf
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:10:04.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8921" for this suite.
Apr  8 15:10:26.218: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:10:26.357: INFO: namespace projected-8921 deletion completed in 22.152531377s
â€¢SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:10:26.357: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-2624
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:10:28.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2624" for this suite.
Apr  8 15:11:06.604: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:11:06.809: INFO: namespace kubelet-test-2624 deletion completed in 38.267321469s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:11:06.809: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-680
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0408 15:11:07.641724    5043 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr  8 15:11:07.641: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:11:07.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-680" for this suite.
Apr  8 15:11:13.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:11:13.798: INFO: namespace gc-680 deletion completed in 6.152514271s
â€¢SSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:11:13.798: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1170
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Apr  8 15:11:16.480: INFO: Successfully updated pod "pod-update-8cc93d05-5a10-11e9-b9a9-e6698ebc8bdf"
STEP: verifying the updated pod is in kubernetes
Apr  8 15:11:16.488: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:11:16.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1170" for this suite.
Apr  8 15:11:38.504: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:11:38.638: INFO: namespace pods-1170 deletion completed in 22.145590751s
â€¢SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:11:38.638: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7169
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-9b9751ca-5a10-11e9-b9a9-e6698ebc8bdf
STEP: Creating a pod to test consume configMaps
Apr  8 15:11:38.798: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9b97f5ae-5a10-11e9-b9a9-e6698ebc8bdf" in namespace "projected-7169" to be "success or failure"
Apr  8 15:11:38.803: INFO: Pod "pod-projected-configmaps-9b97f5ae-5a10-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.951424ms
Apr  8 15:11:40.808: INFO: Pod "pod-projected-configmaps-9b97f5ae-5a10-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010598413s
STEP: Saw pod success
Apr  8 15:11:40.808: INFO: Pod "pod-projected-configmaps-9b97f5ae-5a10-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:11:40.812: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-projected-configmaps-9b97f5ae-5a10-11e9-b9a9-e6698ebc8bdf container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr  8 15:11:40.835: INFO: Waiting for pod pod-projected-configmaps-9b97f5ae-5a10-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:11:40.838: INFO: Pod pod-projected-configmaps-9b97f5ae-5a10-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:11:40.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7169" for this suite.
Apr  8 15:11:46.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:11:46.980: INFO: namespace projected-7169 deletion completed in 6.137592685s
â€¢SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:11:46.980: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-318
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Apr  8 15:11:47.136: INFO: Waiting up to 5m0s for pod "pod-a09034dc-5a10-11e9-b9a9-e6698ebc8bdf" in namespace "emptydir-318" to be "success or failure"
Apr  8 15:11:47.139: INFO: Pod "pod-a09034dc-5a10-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 3.104942ms
Apr  8 15:11:49.167: INFO: Pod "pod-a09034dc-5a10-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.031026351s
STEP: Saw pod success
Apr  8 15:11:49.167: INFO: Pod "pod-a09034dc-5a10-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:11:49.185: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-a09034dc-5a10-11e9-b9a9-e6698ebc8bdf container test-container: <nil>
STEP: delete the pod
Apr  8 15:11:49.228: INFO: Waiting for pod pod-a09034dc-5a10-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:11:49.243: INFO: Pod pod-a09034dc-5a10-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:11:49.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-318" for this suite.
Apr  8 15:11:55.302: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:11:55.505: INFO: namespace emptydir-318 deletion completed in 6.237522884s
â€¢
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:11:55.505: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-6217
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating replication controller svc-latency-rc in namespace svc-latency-6217
I0408 15:11:55.663795    5043 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-6217, replica count: 1
I0408 15:11:56.714295    5043 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0408 15:11:57.714531    5043 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr  8 15:11:57.826: INFO: Created: latency-svc-fc2hp
Apr  8 15:11:57.830: INFO: Got endpoints: latency-svc-fc2hp [15.667008ms]
Apr  8 15:11:57.842: INFO: Created: latency-svc-5fj82
Apr  8 15:11:57.844: INFO: Got endpoints: latency-svc-5fj82 [14.203983ms]
Apr  8 15:11:57.847: INFO: Created: latency-svc-zt484
Apr  8 15:11:57.851: INFO: Got endpoints: latency-svc-zt484 [21.150355ms]
Apr  8 15:11:57.856: INFO: Created: latency-svc-9mf7r
Apr  8 15:11:57.859: INFO: Got endpoints: latency-svc-9mf7r [28.357864ms]
Apr  8 15:11:57.866: INFO: Created: latency-svc-g27q2
Apr  8 15:11:57.871: INFO: Got endpoints: latency-svc-g27q2 [40.473296ms]
Apr  8 15:11:57.874: INFO: Created: latency-svc-7v7fp
Apr  8 15:11:57.877: INFO: Got endpoints: latency-svc-7v7fp [47.128096ms]
Apr  8 15:11:57.884: INFO: Created: latency-svc-4d8nq
Apr  8 15:11:57.890: INFO: Got endpoints: latency-svc-4d8nq [59.362362ms]
Apr  8 15:11:57.890: INFO: Created: latency-svc-2q2kf
Apr  8 15:11:57.893: INFO: Got endpoints: latency-svc-2q2kf [62.852389ms]
Apr  8 15:11:57.896: INFO: Created: latency-svc-52zgk
Apr  8 15:11:57.900: INFO: Got endpoints: latency-svc-52zgk [69.870424ms]
Apr  8 15:11:57.904: INFO: Created: latency-svc-62nj4
Apr  8 15:11:57.907: INFO: Got endpoints: latency-svc-62nj4 [76.826912ms]
Apr  8 15:11:57.921: INFO: Created: latency-svc-v2lhn
Apr  8 15:11:57.927: INFO: Got endpoints: latency-svc-v2lhn [96.849493ms]
Apr  8 15:11:57.931: INFO: Created: latency-svc-gps84
Apr  8 15:11:57.936: INFO: Got endpoints: latency-svc-gps84 [105.206368ms]
Apr  8 15:11:57.942: INFO: Created: latency-svc-mcn2n
Apr  8 15:11:57.946: INFO: Got endpoints: latency-svc-mcn2n [115.978586ms]
Apr  8 15:11:57.951: INFO: Created: latency-svc-nfqp5
Apr  8 15:11:57.954: INFO: Got endpoints: latency-svc-nfqp5 [123.423951ms]
Apr  8 15:11:57.958: INFO: Created: latency-svc-kscpr
Apr  8 15:11:57.964: INFO: Got endpoints: latency-svc-kscpr [133.681922ms]
Apr  8 15:11:57.965: INFO: Created: latency-svc-ktb26
Apr  8 15:11:57.968: INFO: Got endpoints: latency-svc-ktb26 [137.269786ms]
Apr  8 15:11:57.972: INFO: Created: latency-svc-mn7ws
Apr  8 15:11:57.980: INFO: Got endpoints: latency-svc-mn7ws [136.127186ms]
Apr  8 15:11:58.003: INFO: Created: latency-svc-ldjd8
Apr  8 15:11:58.007: INFO: Got endpoints: latency-svc-ldjd8 [156.005106ms]
Apr  8 15:11:58.019: INFO: Created: latency-svc-p2xrw
Apr  8 15:11:58.028: INFO: Got endpoints: latency-svc-p2xrw [169.100896ms]
Apr  8 15:11:58.028: INFO: Created: latency-svc-qf9zg
Apr  8 15:11:58.034: INFO: Got endpoints: latency-svc-qf9zg [162.835661ms]
Apr  8 15:11:58.103: INFO: Created: latency-svc-swtkd
Apr  8 15:11:58.113: INFO: Got endpoints: latency-svc-swtkd [235.09598ms]
Apr  8 15:11:58.114: INFO: Created: latency-svc-zbk8d
Apr  8 15:11:58.117: INFO: Got endpoints: latency-svc-zbk8d [227.262183ms]
Apr  8 15:11:58.123: INFO: Created: latency-svc-jbzlq
Apr  8 15:11:58.127: INFO: Got endpoints: latency-svc-jbzlq [233.749386ms]
Apr  8 15:11:58.200: INFO: Created: latency-svc-2wpng
Apr  8 15:11:58.210: INFO: Created: latency-svc-w29cs
Apr  8 15:11:58.210: INFO: Got endpoints: latency-svc-2wpng [309.836865ms]
Apr  8 15:11:58.213: INFO: Got endpoints: latency-svc-w29cs [305.565966ms]
Apr  8 15:11:58.216: INFO: Created: latency-svc-n5xhb
Apr  8 15:11:58.223: INFO: Got endpoints: latency-svc-n5xhb [296.013515ms]
Apr  8 15:11:58.227: INFO: Created: latency-svc-8zw6h
Apr  8 15:11:58.231: INFO: Got endpoints: latency-svc-8zw6h [295.324789ms]
Apr  8 15:11:58.242: INFO: Created: latency-svc-nqgs7
Apr  8 15:11:58.250: INFO: Created: latency-svc-kfgkf
Apr  8 15:11:58.252: INFO: Got endpoints: latency-svc-nqgs7 [306.011077ms]
Apr  8 15:11:58.306: INFO: Created: latency-svc-kccdq
Apr  8 15:11:58.306: INFO: Got endpoints: latency-svc-kfgkf [352.209596ms]
Apr  8 15:11:58.309: INFO: Got endpoints: latency-svc-kccdq [344.8665ms]
Apr  8 15:11:58.309: INFO: Created: latency-svc-bdq2v
Apr  8 15:11:58.316: INFO: Got endpoints: latency-svc-bdq2v [347.984893ms]
Apr  8 15:11:58.316: INFO: Created: latency-svc-4v2mx
Apr  8 15:11:58.320: INFO: Got endpoints: latency-svc-4v2mx [339.238402ms]
Apr  8 15:11:58.324: INFO: Created: latency-svc-ff2zw
Apr  8 15:11:58.332: INFO: Got endpoints: latency-svc-ff2zw [324.638751ms]
Apr  8 15:11:58.338: INFO: Created: latency-svc-7zh9s
Apr  8 15:11:58.340: INFO: Got endpoints: latency-svc-7zh9s [312.506627ms]
Apr  8 15:11:58.345: INFO: Created: latency-svc-6c7rj
Apr  8 15:11:58.352: INFO: Got endpoints: latency-svc-6c7rj [317.924112ms]
Apr  8 15:11:58.352: INFO: Created: latency-svc-gjs28
Apr  8 15:11:58.354: INFO: Got endpoints: latency-svc-gjs28 [241.678893ms]
Apr  8 15:11:58.358: INFO: Created: latency-svc-9fpz8
Apr  8 15:11:58.363: INFO: Got endpoints: latency-svc-9fpz8 [245.835849ms]
Apr  8 15:11:58.366: INFO: Created: latency-svc-cbzt7
Apr  8 15:11:58.369: INFO: Got endpoints: latency-svc-cbzt7 [242.473877ms]
Apr  8 15:11:58.372: INFO: Created: latency-svc-s9w7r
Apr  8 15:11:58.378: INFO: Got endpoints: latency-svc-s9w7r [167.992065ms]
Apr  8 15:11:58.380: INFO: Created: latency-svc-lttfk
Apr  8 15:11:58.384: INFO: Got endpoints: latency-svc-lttfk [171.570013ms]
Apr  8 15:11:58.387: INFO: Created: latency-svc-mp8k7
Apr  8 15:11:58.390: INFO: Got endpoints: latency-svc-mp8k7 [167.131816ms]
Apr  8 15:11:58.393: INFO: Created: latency-svc-qgkwc
Apr  8 15:11:58.402: INFO: Created: latency-svc-zcdmp
Apr  8 15:11:58.408: INFO: Created: latency-svc-bbsxj
Apr  8 15:11:58.416: INFO: Created: latency-svc-dkwpb
Apr  8 15:11:58.422: INFO: Created: latency-svc-xpmln
Apr  8 15:11:58.429: INFO: Created: latency-svc-fbl8w
Apr  8 15:11:58.434: INFO: Got endpoints: latency-svc-qgkwc [202.973229ms]
Apr  8 15:11:58.435: INFO: Created: latency-svc-wbz5v
Apr  8 15:11:58.441: INFO: Created: latency-svc-47h8r
Apr  8 15:11:58.448: INFO: Created: latency-svc-hxw4s
Apr  8 15:11:58.454: INFO: Created: latency-svc-wf44j
Apr  8 15:11:58.473: INFO: Created: latency-svc-qcpgk
Apr  8 15:11:58.475: INFO: Created: latency-svc-kk4gl
Apr  8 15:11:58.482: INFO: Got endpoints: latency-svc-zcdmp [229.125253ms]
Apr  8 15:11:58.482: INFO: Created: latency-svc-6tzpg
Apr  8 15:11:58.488: INFO: Created: latency-svc-rp4bf
Apr  8 15:11:58.494: INFO: Created: latency-svc-w5qfk
Apr  8 15:11:58.503: INFO: Created: latency-svc-ql2mm
Apr  8 15:11:58.510: INFO: Created: latency-svc-54q7b
Apr  8 15:11:58.530: INFO: Got endpoints: latency-svc-bbsxj [223.94311ms]
Apr  8 15:11:58.541: INFO: Created: latency-svc-ffgdj
Apr  8 15:11:58.580: INFO: Got endpoints: latency-svc-dkwpb [270.939585ms]
Apr  8 15:11:58.592: INFO: Created: latency-svc-zpnrm
Apr  8 15:11:58.632: INFO: Got endpoints: latency-svc-xpmln [315.780068ms]
Apr  8 15:11:58.644: INFO: Created: latency-svc-t5h2c
Apr  8 15:11:58.681: INFO: Got endpoints: latency-svc-fbl8w [361.638832ms]
Apr  8 15:11:58.702: INFO: Created: latency-svc-8mbn7
Apr  8 15:11:58.730: INFO: Got endpoints: latency-svc-wbz5v [398.307337ms]
Apr  8 15:11:58.741: INFO: Created: latency-svc-b7dpg
Apr  8 15:11:58.781: INFO: Got endpoints: latency-svc-47h8r [440.489677ms]
Apr  8 15:11:58.792: INFO: Created: latency-svc-w5p7h
Apr  8 15:11:58.830: INFO: Got endpoints: latency-svc-hxw4s [478.833774ms]
Apr  8 15:11:58.844: INFO: Created: latency-svc-cfwnz
Apr  8 15:11:58.881: INFO: Got endpoints: latency-svc-wf44j [526.347905ms]
Apr  8 15:11:58.895: INFO: Created: latency-svc-p2ndw
Apr  8 15:11:58.930: INFO: Got endpoints: latency-svc-qcpgk [567.583241ms]
Apr  8 15:11:58.941: INFO: Created: latency-svc-4rcrl
Apr  8 15:11:58.980: INFO: Got endpoints: latency-svc-kk4gl [610.477427ms]
Apr  8 15:11:58.992: INFO: Created: latency-svc-85x4j
Apr  8 15:11:59.030: INFO: Got endpoints: latency-svc-6tzpg [652.172934ms]
Apr  8 15:11:59.042: INFO: Created: latency-svc-6f9gp
Apr  8 15:11:59.080: INFO: Got endpoints: latency-svc-rp4bf [695.893967ms]
Apr  8 15:11:59.095: INFO: Created: latency-svc-6kcq2
Apr  8 15:11:59.130: INFO: Got endpoints: latency-svc-w5qfk [739.608195ms]
Apr  8 15:11:59.142: INFO: Created: latency-svc-scthv
Apr  8 15:11:59.181: INFO: Got endpoints: latency-svc-ql2mm [746.832586ms]
Apr  8 15:11:59.192: INFO: Created: latency-svc-mf557
Apr  8 15:11:59.231: INFO: Got endpoints: latency-svc-54q7b [749.479208ms]
Apr  8 15:11:59.243: INFO: Created: latency-svc-mc25k
Apr  8 15:11:59.285: INFO: Got endpoints: latency-svc-ffgdj [755.27054ms]
Apr  8 15:11:59.297: INFO: Created: latency-svc-4dwf5
Apr  8 15:11:59.330: INFO: Got endpoints: latency-svc-zpnrm [750.063388ms]
Apr  8 15:11:59.345: INFO: Created: latency-svc-hh8zr
Apr  8 15:11:59.380: INFO: Got endpoints: latency-svc-t5h2c [748.656838ms]
Apr  8 15:11:59.391: INFO: Created: latency-svc-bqbrw
Apr  8 15:11:59.431: INFO: Got endpoints: latency-svc-8mbn7 [749.829147ms]
Apr  8 15:11:59.445: INFO: Created: latency-svc-8p75p
Apr  8 15:11:59.481: INFO: Got endpoints: latency-svc-b7dpg [750.512106ms]
Apr  8 15:11:59.494: INFO: Created: latency-svc-rt2xd
Apr  8 15:11:59.531: INFO: Got endpoints: latency-svc-w5p7h [749.796071ms]
Apr  8 15:11:59.553: INFO: Created: latency-svc-fh6nb
Apr  8 15:11:59.580: INFO: Got endpoints: latency-svc-cfwnz [749.880336ms]
Apr  8 15:11:59.591: INFO: Created: latency-svc-ldsqt
Apr  8 15:11:59.630: INFO: Got endpoints: latency-svc-p2ndw [749.691293ms]
Apr  8 15:11:59.641: INFO: Created: latency-svc-9x8mr
Apr  8 15:11:59.683: INFO: Got endpoints: latency-svc-4rcrl [751.992608ms]
Apr  8 15:11:59.695: INFO: Created: latency-svc-brspb
Apr  8 15:11:59.730: INFO: Got endpoints: latency-svc-85x4j [749.592815ms]
Apr  8 15:11:59.741: INFO: Created: latency-svc-ksc2s
Apr  8 15:11:59.781: INFO: Got endpoints: latency-svc-6f9gp [750.394085ms]
Apr  8 15:11:59.791: INFO: Created: latency-svc-6749h
Apr  8 15:11:59.830: INFO: Got endpoints: latency-svc-6kcq2 [749.869812ms]
Apr  8 15:11:59.844: INFO: Created: latency-svc-wgtnj
Apr  8 15:11:59.881: INFO: Got endpoints: latency-svc-scthv [750.336324ms]
Apr  8 15:11:59.895: INFO: Created: latency-svc-lmppq
Apr  8 15:11:59.930: INFO: Got endpoints: latency-svc-mf557 [749.322376ms]
Apr  8 15:11:59.943: INFO: Created: latency-svc-6rrn2
Apr  8 15:11:59.981: INFO: Got endpoints: latency-svc-mc25k [749.805261ms]
Apr  8 15:11:59.995: INFO: Created: latency-svc-nksdq
Apr  8 15:12:00.039: INFO: Got endpoints: latency-svc-4dwf5 [753.828033ms]
Apr  8 15:12:00.051: INFO: Created: latency-svc-wzwsr
Apr  8 15:12:00.081: INFO: Got endpoints: latency-svc-hh8zr [751.222163ms]
Apr  8 15:12:00.097: INFO: Created: latency-svc-nttc5
Apr  8 15:12:00.132: INFO: Got endpoints: latency-svc-bqbrw [752.033416ms]
Apr  8 15:12:00.151: INFO: Created: latency-svc-mmjxs
Apr  8 15:12:00.182: INFO: Got endpoints: latency-svc-8p75p [749.955415ms]
Apr  8 15:12:00.195: INFO: Created: latency-svc-cprkn
Apr  8 15:12:00.237: INFO: Got endpoints: latency-svc-rt2xd [755.608663ms]
Apr  8 15:12:00.254: INFO: Created: latency-svc-zr5sl
Apr  8 15:12:00.280: INFO: Got endpoints: latency-svc-fh6nb [749.545425ms]
Apr  8 15:12:00.293: INFO: Created: latency-svc-vnc69
Apr  8 15:12:00.333: INFO: Got endpoints: latency-svc-ldsqt [752.536423ms]
Apr  8 15:12:00.354: INFO: Created: latency-svc-fpzkk
Apr  8 15:12:00.382: INFO: Got endpoints: latency-svc-9x8mr [751.718483ms]
Apr  8 15:12:00.395: INFO: Created: latency-svc-9pwpn
Apr  8 15:12:00.431: INFO: Got endpoints: latency-svc-brspb [748.395885ms]
Apr  8 15:12:00.449: INFO: Created: latency-svc-mccb9
Apr  8 15:12:00.482: INFO: Got endpoints: latency-svc-ksc2s [752.657142ms]
Apr  8 15:12:00.497: INFO: Created: latency-svc-cjjxm
Apr  8 15:12:00.532: INFO: Got endpoints: latency-svc-6749h [750.960281ms]
Apr  8 15:12:00.544: INFO: Created: latency-svc-z8bmb
Apr  8 15:12:00.584: INFO: Got endpoints: latency-svc-wgtnj [753.674726ms]
Apr  8 15:12:00.608: INFO: Created: latency-svc-ssbjw
Apr  8 15:12:00.634: INFO: Got endpoints: latency-svc-lmppq [753.651066ms]
Apr  8 15:12:00.651: INFO: Created: latency-svc-9vpz4
Apr  8 15:12:00.683: INFO: Got endpoints: latency-svc-6rrn2 [752.406435ms]
Apr  8 15:12:00.696: INFO: Created: latency-svc-m742z
Apr  8 15:12:00.730: INFO: Got endpoints: latency-svc-nksdq [748.983589ms]
Apr  8 15:12:00.747: INFO: Created: latency-svc-hq2kw
Apr  8 15:12:00.781: INFO: Got endpoints: latency-svc-wzwsr [742.062143ms]
Apr  8 15:12:00.794: INFO: Created: latency-svc-8r7fr
Apr  8 15:12:00.831: INFO: Got endpoints: latency-svc-nttc5 [749.257136ms]
Apr  8 15:12:00.847: INFO: Created: latency-svc-hws7m
Apr  8 15:12:00.881: INFO: Got endpoints: latency-svc-mmjxs [748.141782ms]
Apr  8 15:12:00.894: INFO: Created: latency-svc-zvcz9
Apr  8 15:12:00.931: INFO: Got endpoints: latency-svc-cprkn [749.284958ms]
Apr  8 15:12:00.942: INFO: Created: latency-svc-dhzfn
Apr  8 15:12:00.989: INFO: Got endpoints: latency-svc-zr5sl [752.407068ms]
Apr  8 15:12:01.001: INFO: Created: latency-svc-5s7ln
Apr  8 15:12:01.030: INFO: Got endpoints: latency-svc-vnc69 [749.756161ms]
Apr  8 15:12:01.041: INFO: Created: latency-svc-n8nrx
Apr  8 15:12:01.081: INFO: Got endpoints: latency-svc-fpzkk [748.041716ms]
Apr  8 15:12:01.096: INFO: Created: latency-svc-rt8ts
Apr  8 15:12:01.134: INFO: Got endpoints: latency-svc-9pwpn [751.989836ms]
Apr  8 15:12:01.147: INFO: Created: latency-svc-mswlt
Apr  8 15:12:01.180: INFO: Got endpoints: latency-svc-mccb9 [749.184417ms]
Apr  8 15:12:01.192: INFO: Created: latency-svc-mxxj2
Apr  8 15:12:01.231: INFO: Got endpoints: latency-svc-cjjxm [748.560695ms]
Apr  8 15:12:01.245: INFO: Created: latency-svc-m4jv4
Apr  8 15:12:01.281: INFO: Got endpoints: latency-svc-z8bmb [748.825185ms]
Apr  8 15:12:01.307: INFO: Created: latency-svc-5fnnc
Apr  8 15:12:01.331: INFO: Got endpoints: latency-svc-ssbjw [747.432924ms]
Apr  8 15:12:01.345: INFO: Created: latency-svc-8nnp2
Apr  8 15:12:01.381: INFO: Got endpoints: latency-svc-9vpz4 [746.853486ms]
Apr  8 15:12:01.393: INFO: Created: latency-svc-qhbgw
Apr  8 15:12:01.431: INFO: Got endpoints: latency-svc-m742z [748.121446ms]
Apr  8 15:12:01.445: INFO: Created: latency-svc-2ntxm
Apr  8 15:12:01.491: INFO: Got endpoints: latency-svc-hq2kw [761.173757ms]
Apr  8 15:12:01.518: INFO: Created: latency-svc-l8rwc
Apr  8 15:12:01.549: INFO: Got endpoints: latency-svc-8r7fr [767.157245ms]
Apr  8 15:12:01.587: INFO: Created: latency-svc-qdtzx
Apr  8 15:12:01.602: INFO: Got endpoints: latency-svc-hws7m [771.026378ms]
Apr  8 15:12:01.639: INFO: Created: latency-svc-bcl7p
Apr  8 15:12:01.640: INFO: Got endpoints: latency-svc-zvcz9 [759.278194ms]
Apr  8 15:12:01.666: INFO: Created: latency-svc-4v5qp
Apr  8 15:12:01.699: INFO: Got endpoints: latency-svc-dhzfn [768.103774ms]
Apr  8 15:12:01.727: INFO: Created: latency-svc-f9hbq
Apr  8 15:12:01.746: INFO: Got endpoints: latency-svc-5s7ln [756.562543ms]
Apr  8 15:12:01.774: INFO: Created: latency-svc-frk6w
Apr  8 15:12:01.798: INFO: Got endpoints: latency-svc-n8nrx [767.644881ms]
Apr  8 15:12:01.824: INFO: Created: latency-svc-4g5w5
Apr  8 15:12:01.841: INFO: Got endpoints: latency-svc-rt8ts [759.741197ms]
Apr  8 15:12:01.865: INFO: Created: latency-svc-cnprl
Apr  8 15:12:01.888: INFO: Got endpoints: latency-svc-mswlt [753.869007ms]
Apr  8 15:12:01.908: INFO: Created: latency-svc-7xvsp
Apr  8 15:12:01.937: INFO: Got endpoints: latency-svc-mxxj2 [756.513044ms]
Apr  8 15:12:01.963: INFO: Created: latency-svc-6xk26
Apr  8 15:12:01.986: INFO: Got endpoints: latency-svc-m4jv4 [755.312337ms]
Apr  8 15:12:02.019: INFO: Created: latency-svc-m7kfx
Apr  8 15:12:02.034: INFO: Got endpoints: latency-svc-5fnnc [753.339933ms]
Apr  8 15:12:02.054: INFO: Created: latency-svc-r8q2f
Apr  8 15:12:02.088: INFO: Got endpoints: latency-svc-8nnp2 [756.646437ms]
Apr  8 15:12:02.107: INFO: Created: latency-svc-gmtsv
Apr  8 15:12:02.133: INFO: Got endpoints: latency-svc-qhbgw [751.965766ms]
Apr  8 15:12:02.148: INFO: Created: latency-svc-6tkrh
Apr  8 15:12:02.183: INFO: Got endpoints: latency-svc-2ntxm [752.153369ms]
Apr  8 15:12:02.201: INFO: Created: latency-svc-l2jqh
Apr  8 15:12:02.236: INFO: Got endpoints: latency-svc-l8rwc [744.825905ms]
Apr  8 15:12:02.253: INFO: Created: latency-svc-tl5dv
Apr  8 15:12:02.287: INFO: Got endpoints: latency-svc-qdtzx [737.964202ms]
Apr  8 15:12:02.309: INFO: Created: latency-svc-dljv2
Apr  8 15:12:02.336: INFO: Got endpoints: latency-svc-bcl7p [734.442384ms]
Apr  8 15:12:02.366: INFO: Created: latency-svc-cvkbh
Apr  8 15:12:02.387: INFO: Got endpoints: latency-svc-4v5qp [747.234584ms]
Apr  8 15:12:02.409: INFO: Created: latency-svc-jdzdm
Apr  8 15:12:02.435: INFO: Got endpoints: latency-svc-f9hbq [736.073449ms]
Apr  8 15:12:02.452: INFO: Created: latency-svc-7q7n2
Apr  8 15:12:02.483: INFO: Got endpoints: latency-svc-frk6w [737.25869ms]
Apr  8 15:12:02.496: INFO: Created: latency-svc-p9tsz
Apr  8 15:12:02.530: INFO: Got endpoints: latency-svc-4g5w5 [732.187057ms]
Apr  8 15:12:02.541: INFO: Created: latency-svc-h5pcm
Apr  8 15:12:02.581: INFO: Got endpoints: latency-svc-cnprl [739.839164ms]
Apr  8 15:12:02.592: INFO: Created: latency-svc-vvwk2
Apr  8 15:12:02.632: INFO: Got endpoints: latency-svc-7xvsp [744.006818ms]
Apr  8 15:12:02.643: INFO: Created: latency-svc-wtcsw
Apr  8 15:12:02.684: INFO: Got endpoints: latency-svc-6xk26 [746.727643ms]
Apr  8 15:12:02.696: INFO: Created: latency-svc-nphj2
Apr  8 15:12:02.731: INFO: Got endpoints: latency-svc-m7kfx [744.202805ms]
Apr  8 15:12:02.741: INFO: Created: latency-svc-jsbjr
Apr  8 15:12:02.781: INFO: Got endpoints: latency-svc-r8q2f [746.564299ms]
Apr  8 15:12:02.797: INFO: Created: latency-svc-h52fr
Apr  8 15:12:02.831: INFO: Got endpoints: latency-svc-gmtsv [742.888335ms]
Apr  8 15:12:02.846: INFO: Created: latency-svc-47d24
Apr  8 15:12:02.880: INFO: Got endpoints: latency-svc-6tkrh [747.005999ms]
Apr  8 15:12:02.901: INFO: Created: latency-svc-d6qvk
Apr  8 15:12:02.930: INFO: Got endpoints: latency-svc-l2jqh [746.57101ms]
Apr  8 15:12:02.942: INFO: Created: latency-svc-vgxmn
Apr  8 15:12:02.981: INFO: Got endpoints: latency-svc-tl5dv [744.990927ms]
Apr  8 15:12:02.992: INFO: Created: latency-svc-lr9rt
Apr  8 15:12:03.030: INFO: Got endpoints: latency-svc-dljv2 [743.800916ms]
Apr  8 15:12:03.044: INFO: Created: latency-svc-lxvdp
Apr  8 15:12:03.080: INFO: Got endpoints: latency-svc-cvkbh [744.110962ms]
Apr  8 15:12:03.097: INFO: Created: latency-svc-b7bsx
Apr  8 15:12:03.131: INFO: Got endpoints: latency-svc-jdzdm [744.132428ms]
Apr  8 15:12:03.144: INFO: Created: latency-svc-mj254
Apr  8 15:12:03.181: INFO: Got endpoints: latency-svc-7q7n2 [745.53138ms]
Apr  8 15:12:03.221: INFO: Created: latency-svc-lh9dm
Apr  8 15:12:03.231: INFO: Got endpoints: latency-svc-p9tsz [747.601856ms]
Apr  8 15:12:03.303: INFO: Created: latency-svc-cn555
Apr  8 15:12:03.303: INFO: Got endpoints: latency-svc-h5pcm [772.959028ms]
Apr  8 15:12:03.314: INFO: Created: latency-svc-9p9nh
Apr  8 15:12:03.403: INFO: Got endpoints: latency-svc-vvwk2 [822.63272ms]
Apr  8 15:12:03.404: INFO: Got endpoints: latency-svc-wtcsw [771.659022ms]
Apr  8 15:12:03.416: INFO: Created: latency-svc-hdbwc
Apr  8 15:12:03.425: INFO: Created: latency-svc-vsc6v
Apr  8 15:12:03.430: INFO: Got endpoints: latency-svc-nphj2 [746.382752ms]
Apr  8 15:12:03.443: INFO: Created: latency-svc-z2xfg
Apr  8 15:12:03.481: INFO: Got endpoints: latency-svc-jsbjr [749.852514ms]
Apr  8 15:12:03.493: INFO: Created: latency-svc-ld5mx
Apr  8 15:12:03.542: INFO: Got endpoints: latency-svc-h52fr [760.875527ms]
Apr  8 15:12:03.553: INFO: Created: latency-svc-b85cm
Apr  8 15:12:03.580: INFO: Got endpoints: latency-svc-47d24 [748.8937ms]
Apr  8 15:12:03.593: INFO: Created: latency-svc-bskcp
Apr  8 15:12:03.630: INFO: Got endpoints: latency-svc-d6qvk [750.053128ms]
Apr  8 15:12:03.644: INFO: Created: latency-svc-mskrz
Apr  8 15:12:03.680: INFO: Got endpoints: latency-svc-vgxmn [750.095647ms]
Apr  8 15:12:03.692: INFO: Created: latency-svc-pvxbv
Apr  8 15:12:03.732: INFO: Got endpoints: latency-svc-lr9rt [750.763379ms]
Apr  8 15:12:03.743: INFO: Created: latency-svc-h6g8p
Apr  8 15:12:03.781: INFO: Got endpoints: latency-svc-lxvdp [750.620778ms]
Apr  8 15:12:03.795: INFO: Created: latency-svc-kzqng
Apr  8 15:12:03.832: INFO: Got endpoints: latency-svc-b7bsx [751.910022ms]
Apr  8 15:12:03.847: INFO: Created: latency-svc-bfqfx
Apr  8 15:12:03.881: INFO: Got endpoints: latency-svc-mj254 [749.349224ms]
Apr  8 15:12:03.901: INFO: Created: latency-svc-xtjj8
Apr  8 15:12:03.931: INFO: Got endpoints: latency-svc-lh9dm [749.980967ms]
Apr  8 15:12:03.944: INFO: Created: latency-svc-gsd2r
Apr  8 15:12:03.981: INFO: Got endpoints: latency-svc-cn555 [750.15731ms]
Apr  8 15:12:03.994: INFO: Created: latency-svc-4wqjx
Apr  8 15:12:04.030: INFO: Got endpoints: latency-svc-9p9nh [727.112491ms]
Apr  8 15:12:04.042: INFO: Created: latency-svc-sc8t5
Apr  8 15:12:04.081: INFO: Got endpoints: latency-svc-hdbwc [677.028681ms]
Apr  8 15:12:04.093: INFO: Created: latency-svc-tqj7g
Apr  8 15:12:04.131: INFO: Got endpoints: latency-svc-vsc6v [726.478118ms]
Apr  8 15:12:04.142: INFO: Created: latency-svc-6jhmz
Apr  8 15:12:04.187: INFO: Got endpoints: latency-svc-z2xfg [756.599531ms]
Apr  8 15:12:04.200: INFO: Created: latency-svc-4q4sh
Apr  8 15:12:04.231: INFO: Got endpoints: latency-svc-ld5mx [750.189876ms]
Apr  8 15:12:04.242: INFO: Created: latency-svc-vp7h2
Apr  8 15:12:04.280: INFO: Got endpoints: latency-svc-b85cm [738.849814ms]
Apr  8 15:12:04.293: INFO: Created: latency-svc-vl4nk
Apr  8 15:12:04.330: INFO: Got endpoints: latency-svc-bskcp [750.184578ms]
Apr  8 15:12:04.342: INFO: Created: latency-svc-d654j
Apr  8 15:12:04.381: INFO: Got endpoints: latency-svc-mskrz [750.097459ms]
Apr  8 15:12:04.395: INFO: Created: latency-svc-ptswb
Apr  8 15:12:04.431: INFO: Got endpoints: latency-svc-pvxbv [751.150972ms]
Apr  8 15:12:04.443: INFO: Created: latency-svc-z496r
Apr  8 15:12:04.481: INFO: Got endpoints: latency-svc-h6g8p [748.692575ms]
Apr  8 15:12:04.492: INFO: Created: latency-svc-sqxw9
Apr  8 15:12:04.530: INFO: Got endpoints: latency-svc-kzqng [748.743373ms]
Apr  8 15:12:04.541: INFO: Created: latency-svc-jxjmz
Apr  8 15:12:04.584: INFO: Got endpoints: latency-svc-bfqfx [751.420195ms]
Apr  8 15:12:04.597: INFO: Created: latency-svc-tt6k9
Apr  8 15:12:04.631: INFO: Got endpoints: latency-svc-xtjj8 [749.734479ms]
Apr  8 15:12:04.642: INFO: Created: latency-svc-4wt5g
Apr  8 15:12:04.682: INFO: Got endpoints: latency-svc-gsd2r [750.879406ms]
Apr  8 15:12:04.695: INFO: Created: latency-svc-z75p6
Apr  8 15:12:04.730: INFO: Got endpoints: latency-svc-4wqjx [749.192344ms]
Apr  8 15:12:04.743: INFO: Created: latency-svc-kjr2d
Apr  8 15:12:04.780: INFO: Got endpoints: latency-svc-sc8t5 [749.867274ms]
Apr  8 15:12:04.793: INFO: Created: latency-svc-ph7mr
Apr  8 15:12:04.831: INFO: Got endpoints: latency-svc-tqj7g [749.964836ms]
Apr  8 15:12:04.844: INFO: Created: latency-svc-p655l
Apr  8 15:12:04.882: INFO: Got endpoints: latency-svc-6jhmz [751.673826ms]
Apr  8 15:12:04.898: INFO: Created: latency-svc-7b2kj
Apr  8 15:12:04.940: INFO: Got endpoints: latency-svc-4q4sh [753.205879ms]
Apr  8 15:12:04.958: INFO: Created: latency-svc-2jf6t
Apr  8 15:12:04.984: INFO: Got endpoints: latency-svc-vp7h2 [753.509573ms]
Apr  8 15:12:05.001: INFO: Created: latency-svc-84c64
Apr  8 15:12:05.032: INFO: Got endpoints: latency-svc-vl4nk [751.322295ms]
Apr  8 15:12:05.047: INFO: Created: latency-svc-t5ptk
Apr  8 15:12:05.082: INFO: Got endpoints: latency-svc-d654j [751.312607ms]
Apr  8 15:12:05.094: INFO: Created: latency-svc-fhprn
Apr  8 15:12:05.130: INFO: Got endpoints: latency-svc-ptswb [749.796213ms]
Apr  8 15:12:05.160: INFO: Created: latency-svc-bx7qs
Apr  8 15:12:05.181: INFO: Got endpoints: latency-svc-z496r [749.436087ms]
Apr  8 15:12:05.192: INFO: Created: latency-svc-mtf64
Apr  8 15:12:05.231: INFO: Got endpoints: latency-svc-sqxw9 [749.85105ms]
Apr  8 15:12:05.314: INFO: Created: latency-svc-tptj8
Apr  8 15:12:05.314: INFO: Got endpoints: latency-svc-jxjmz [783.786296ms]
Apr  8 15:12:05.326: INFO: Created: latency-svc-zvvpp
Apr  8 15:12:05.347: INFO: Got endpoints: latency-svc-tt6k9 [763.270661ms]
Apr  8 15:12:05.370: INFO: Created: latency-svc-m4z64
Apr  8 15:12:05.400: INFO: Got endpoints: latency-svc-4wt5g [769.728346ms]
Apr  8 15:12:05.482: INFO: Created: latency-svc-fkddd
Apr  8 15:12:05.482: INFO: Got endpoints: latency-svc-z75p6 [800.561404ms]
Apr  8 15:12:05.482: INFO: Got endpoints: latency-svc-kjr2d [752.159793ms]
Apr  8 15:12:05.510: INFO: Created: latency-svc-dvncd
Apr  8 15:12:05.522: INFO: Created: latency-svc-crm8j
Apr  8 15:12:05.530: INFO: Got endpoints: latency-svc-ph7mr [749.815616ms]
Apr  8 15:12:05.542: INFO: Created: latency-svc-9zr84
Apr  8 15:12:05.581: INFO: Got endpoints: latency-svc-p655l [749.902146ms]
Apr  8 15:12:05.595: INFO: Created: latency-svc-dqdks
Apr  8 15:12:05.766: INFO: Got endpoints: latency-svc-84c64 [781.659172ms]
Apr  8 15:12:05.766: INFO: Got endpoints: latency-svc-7b2kj [883.888369ms]
Apr  8 15:12:05.767: INFO: Got endpoints: latency-svc-2jf6t [827.195412ms]
Apr  8 15:12:05.809: INFO: Got endpoints: latency-svc-t5ptk [776.914813ms]
Apr  8 15:12:05.809: INFO: Created: latency-svc-mnh94
Apr  8 15:12:05.830: INFO: Got endpoints: latency-svc-fhprn [748.347761ms]
Apr  8 15:12:05.881: INFO: Got endpoints: latency-svc-bx7qs [750.119336ms]
Apr  8 15:12:05.931: INFO: Got endpoints: latency-svc-mtf64 [750.122818ms]
Apr  8 15:12:05.981: INFO: Got endpoints: latency-svc-tptj8 [750.169466ms]
Apr  8 15:12:06.031: INFO: Got endpoints: latency-svc-zvvpp [717.249889ms]
Apr  8 15:12:06.081: INFO: Got endpoints: latency-svc-m4z64 [733.150041ms]
Apr  8 15:12:06.132: INFO: Got endpoints: latency-svc-fkddd [731.04508ms]
Apr  8 15:12:06.181: INFO: Got endpoints: latency-svc-dvncd [698.2942ms]
Apr  8 15:12:06.231: INFO: Got endpoints: latency-svc-crm8j [748.349829ms]
Apr  8 15:12:06.281: INFO: Got endpoints: latency-svc-9zr84 [750.408377ms]
Apr  8 15:12:06.331: INFO: Got endpoints: latency-svc-dqdks [749.893906ms]
Apr  8 15:12:06.420: INFO: Got endpoints: latency-svc-mnh94 [653.653511ms]
Apr  8 15:12:06.420: INFO: Latencies: [14.203983ms 21.150355ms 28.357864ms 40.473296ms 47.128096ms 59.362362ms 62.852389ms 69.870424ms 76.826912ms 96.849493ms 105.206368ms 115.978586ms 123.423951ms 133.681922ms 136.127186ms 137.269786ms 156.005106ms 162.835661ms 167.131816ms 167.992065ms 169.100896ms 171.570013ms 202.973229ms 223.94311ms 227.262183ms 229.125253ms 233.749386ms 235.09598ms 241.678893ms 242.473877ms 245.835849ms 270.939585ms 295.324789ms 296.013515ms 305.565966ms 306.011077ms 309.836865ms 312.506627ms 315.780068ms 317.924112ms 324.638751ms 339.238402ms 344.8665ms 347.984893ms 352.209596ms 361.638832ms 398.307337ms 440.489677ms 478.833774ms 526.347905ms 567.583241ms 610.477427ms 652.172934ms 653.653511ms 677.028681ms 695.893967ms 698.2942ms 717.249889ms 726.478118ms 727.112491ms 731.04508ms 732.187057ms 733.150041ms 734.442384ms 736.073449ms 737.25869ms 737.964202ms 738.849814ms 739.608195ms 739.839164ms 742.062143ms 742.888335ms 743.800916ms 744.006818ms 744.110962ms 744.132428ms 744.202805ms 744.825905ms 744.990927ms 745.53138ms 746.382752ms 746.564299ms 746.57101ms 746.727643ms 746.832586ms 746.853486ms 747.005999ms 747.234584ms 747.432924ms 747.601856ms 748.041716ms 748.121446ms 748.141782ms 748.347761ms 748.349829ms 748.395885ms 748.560695ms 748.656838ms 748.692575ms 748.743373ms 748.825185ms 748.8937ms 748.983589ms 749.184417ms 749.192344ms 749.257136ms 749.284958ms 749.322376ms 749.349224ms 749.436087ms 749.479208ms 749.545425ms 749.592815ms 749.691293ms 749.734479ms 749.756161ms 749.796071ms 749.796213ms 749.805261ms 749.815616ms 749.829147ms 749.85105ms 749.852514ms 749.867274ms 749.869812ms 749.880336ms 749.893906ms 749.902146ms 749.955415ms 749.964836ms 749.980967ms 750.053128ms 750.063388ms 750.095647ms 750.097459ms 750.119336ms 750.122818ms 750.15731ms 750.169466ms 750.184578ms 750.189876ms 750.336324ms 750.394085ms 750.408377ms 750.512106ms 750.620778ms 750.763379ms 750.879406ms 750.960281ms 751.150972ms 751.222163ms 751.312607ms 751.322295ms 751.420195ms 751.673826ms 751.718483ms 751.910022ms 751.965766ms 751.989836ms 751.992608ms 752.033416ms 752.153369ms 752.159793ms 752.406435ms 752.407068ms 752.536423ms 752.657142ms 753.205879ms 753.339933ms 753.509573ms 753.651066ms 753.674726ms 753.828033ms 753.869007ms 755.27054ms 755.312337ms 755.608663ms 756.513044ms 756.562543ms 756.599531ms 756.646437ms 759.278194ms 759.741197ms 760.875527ms 761.173757ms 763.270661ms 767.157245ms 767.644881ms 768.103774ms 769.728346ms 771.026378ms 771.659022ms 772.959028ms 776.914813ms 781.659172ms 783.786296ms 800.561404ms 822.63272ms 827.195412ms 883.888369ms]
Apr  8 15:12:06.420: INFO: 50 %ile: 748.825185ms
Apr  8 15:12:06.420: INFO: 90 %ile: 756.646437ms
Apr  8 15:12:06.420: INFO: 99 %ile: 827.195412ms
Apr  8 15:12:06.420: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:12:06.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-6217" for this suite.
Apr  8 15:12:16.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:12:16.623: INFO: namespace svc-latency-6217 deletion completed in 10.198464566s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:12:16.624: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3824
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-b23bfd4a-5a10-11e9-b9a9-e6698ebc8bdf
STEP: Creating a pod to test consume secrets
Apr  8 15:12:16.788: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b23cab5a-5a10-11e9-b9a9-e6698ebc8bdf" in namespace "projected-3824" to be "success or failure"
Apr  8 15:12:16.793: INFO: Pod "pod-projected-secrets-b23cab5a-5a10-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.966321ms
Apr  8 15:12:18.814: INFO: Pod "pod-projected-secrets-b23cab5a-5a10-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.026050968s
STEP: Saw pod success
Apr  8 15:12:18.814: INFO: Pod "pod-projected-secrets-b23cab5a-5a10-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:12:18.834: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-projected-secrets-b23cab5a-5a10-11e9-b9a9-e6698ebc8bdf container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr  8 15:12:19.019: INFO: Waiting for pod pod-projected-secrets-b23cab5a-5a10-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:12:19.039: INFO: Pod pod-projected-secrets-b23cab5a-5a10-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:12:19.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3824" for this suite.
Apr  8 15:12:25.137: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:12:25.261: INFO: namespace projected-3824 deletion completed in 6.184203s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:12:25.262: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-2277
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Apr  8 15:12:25.425: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2277,SelfLink:/api/v1/namespaces/watch-2277/configmaps/e2e-watch-test-label-changed,UID:b762c082-5a10-11e9-8aed-4ea023eb3a48,ResourceVersion:16751,Generation:0,CreationTimestamp:2019-04-08 15:12:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr  8 15:12:25.425: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2277,SelfLink:/api/v1/namespaces/watch-2277/configmaps/e2e-watch-test-label-changed,UID:b762c082-5a10-11e9-8aed-4ea023eb3a48,ResourceVersion:16752,Generation:0,CreationTimestamp:2019-04-08 15:12:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Apr  8 15:12:25.425: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2277,SelfLink:/api/v1/namespaces/watch-2277/configmaps/e2e-watch-test-label-changed,UID:b762c082-5a10-11e9-8aed-4ea023eb3a48,ResourceVersion:16753,Generation:0,CreationTimestamp:2019-04-08 15:12:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Apr  8 15:12:35.459: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2277,SelfLink:/api/v1/namespaces/watch-2277/configmaps/e2e-watch-test-label-changed,UID:b762c082-5a10-11e9-8aed-4ea023eb3a48,ResourceVersion:16776,Generation:0,CreationTimestamp:2019-04-08 15:12:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr  8 15:12:35.459: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2277,SelfLink:/api/v1/namespaces/watch-2277/configmaps/e2e-watch-test-label-changed,UID:b762c082-5a10-11e9-8aed-4ea023eb3a48,ResourceVersion:16777,Generation:0,CreationTimestamp:2019-04-08 15:12:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Apr  8 15:12:35.459: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2277,SelfLink:/api/v1/namespaces/watch-2277/configmaps/e2e-watch-test-label-changed,UID:b762c082-5a10-11e9-8aed-4ea023eb3a48,ResourceVersion:16778,Generation:0,CreationTimestamp:2019-04-08 15:12:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:12:35.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2277" for this suite.
Apr  8 15:12:41.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:12:41.604: INFO: namespace watch-2277 deletion completed in 6.138668858s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:12:41.605: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7534
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  8 15:12:41.758: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c11eecd1-5a10-11e9-b9a9-e6698ebc8bdf" in namespace "projected-7534" to be "success or failure"
Apr  8 15:12:41.763: INFO: Pod "downwardapi-volume-c11eecd1-5a10-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.515877ms
Apr  8 15:12:43.769: INFO: Pod "downwardapi-volume-c11eecd1-5a10-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010614732s
STEP: Saw pod success
Apr  8 15:12:43.769: INFO: Pod "downwardapi-volume-c11eecd1-5a10-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:12:43.773: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod downwardapi-volume-c11eecd1-5a10-11e9-b9a9-e6698ebc8bdf container client-container: <nil>
STEP: delete the pod
Apr  8 15:12:43.806: INFO: Waiting for pod downwardapi-volume-c11eecd1-5a10-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:12:43.811: INFO: Pod downwardapi-volume-c11eecd1-5a10-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:12:43.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7534" for this suite.
Apr  8 15:12:49.831: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:12:49.986: INFO: namespace projected-7534 deletion completed in 6.169826732s
â€¢
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:12:49.986: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-8419
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Apr  8 15:12:53.186: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:12:53.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-8419" for this suite.
Apr  8 15:13:15.226: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:13:15.345: INFO: namespace replicaset-8419 deletion completed in 22.135038885s
â€¢SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:13:15.346: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1226
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-d53e1045-5a10-11e9-b9a9-e6698ebc8bdf
STEP: Creating a pod to test consume configMaps
Apr  8 15:13:15.522: INFO: Waiting up to 5m0s for pod "pod-configmaps-d53eb4a2-5a10-11e9-b9a9-e6698ebc8bdf" in namespace "configmap-1226" to be "success or failure"
Apr  8 15:13:15.528: INFO: Pod "pod-configmaps-d53eb4a2-5a10-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 5.899349ms
Apr  8 15:13:17.534: INFO: Pod "pod-configmaps-d53eb4a2-5a10-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011341243s
STEP: Saw pod success
Apr  8 15:13:17.534: INFO: Pod "pod-configmaps-d53eb4a2-5a10-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:13:17.537: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-configmaps-d53eb4a2-5a10-11e9-b9a9-e6698ebc8bdf container configmap-volume-test: <nil>
STEP: delete the pod
Apr  8 15:13:17.557: INFO: Waiting for pod pod-configmaps-d53eb4a2-5a10-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:13:17.560: INFO: Pod pod-configmaps-d53eb4a2-5a10-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:13:17.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1226" for this suite.
Apr  8 15:13:23.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:13:23.864: INFO: namespace configmap-1226 deletion completed in 6.299030081s
â€¢SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:13:23.864: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5682
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Apr  8 15:13:24.019: INFO: Waiting up to 5m0s for pod "pod-da4f5395-5a10-11e9-b9a9-e6698ebc8bdf" in namespace "emptydir-5682" to be "success or failure"
Apr  8 15:13:24.023: INFO: Pod "pod-da4f5395-5a10-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.033077ms
Apr  8 15:13:26.038: INFO: Pod "pod-da4f5395-5a10-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019418195s
STEP: Saw pod success
Apr  8 15:13:26.038: INFO: Pod "pod-da4f5395-5a10-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:13:26.054: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-da4f5395-5a10-11e9-b9a9-e6698ebc8bdf container test-container: <nil>
STEP: delete the pod
Apr  8 15:13:26.097: INFO: Waiting for pod pod-da4f5395-5a10-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:13:26.109: INFO: Pod pod-da4f5395-5a10-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:13:26.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5682" for this suite.
Apr  8 15:13:32.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:13:32.285: INFO: namespace emptydir-5682 deletion completed in 6.155781003s
â€¢SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:13:32.285: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-5053
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override arguments
Apr  8 15:13:32.448: INFO: Waiting up to 5m0s for pod "client-containers-df55ae60-5a10-11e9-b9a9-e6698ebc8bdf" in namespace "containers-5053" to be "success or failure"
Apr  8 15:13:32.454: INFO: Pod "client-containers-df55ae60-5a10-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 5.268022ms
Apr  8 15:13:34.459: INFO: Pod "client-containers-df55ae60-5a10-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010609256s
STEP: Saw pod success
Apr  8 15:13:34.459: INFO: Pod "client-containers-df55ae60-5a10-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:13:34.463: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod client-containers-df55ae60-5a10-11e9-b9a9-e6698ebc8bdf container test-container: <nil>
STEP: delete the pod
Apr  8 15:13:34.485: INFO: Waiting for pod client-containers-df55ae60-5a10-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:13:34.488: INFO: Pod client-containers-df55ae60-5a10-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:13:34.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5053" for this suite.
Apr  8 15:13:40.508: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:13:40.653: INFO: namespace containers-5053 deletion completed in 6.160310779s
â€¢SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:13:40.653: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1892
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-1251
STEP: Creating secret with name secret-test-e453b246-5a10-11e9-b9a9-e6698ebc8bdf
STEP: Creating a pod to test consume secrets
Apr  8 15:13:40.983: INFO: Waiting up to 5m0s for pod "pod-secrets-e46a6fd8-5a10-11e9-b9a9-e6698ebc8bdf" in namespace "secrets-1892" to be "success or failure"
Apr  8 15:13:40.989: INFO: Pod "pod-secrets-e46a6fd8-5a10-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 5.503441ms
Apr  8 15:13:42.998: INFO: Pod "pod-secrets-e46a6fd8-5a10-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014399321s
Apr  8 15:13:45.003: INFO: Pod "pod-secrets-e46a6fd8-5a10-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019648923s
Apr  8 15:13:47.009: INFO: Pod "pod-secrets-e46a6fd8-5a10-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 6.025145901s
Apr  8 15:13:49.020: INFO: Pod "pod-secrets-e46a6fd8-5a10-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.036284002s
STEP: Saw pod success
Apr  8 15:13:49.020: INFO: Pod "pod-secrets-e46a6fd8-5a10-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:13:49.030: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-secrets-e46a6fd8-5a10-11e9-b9a9-e6698ebc8bdf container secret-volume-test: <nil>
STEP: delete the pod
Apr  8 15:13:49.057: INFO: Waiting for pod pod-secrets-e46a6fd8-5a10-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:13:49.062: INFO: Pod pod-secrets-e46a6fd8-5a10-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:13:49.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1892" for this suite.
Apr  8 15:13:55.083: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:13:55.368: INFO: namespace secrets-1892 deletion completed in 6.301897479s
STEP: Destroying namespace "secret-namespace-1251" for this suite.
Apr  8 15:14:01.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:14:01.573: INFO: namespace secret-namespace-1251 deletion completed in 6.204803596s
â€¢SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:14:01.573: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9130
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1414
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr  8 15:14:01.766: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-9130'
Apr  8 15:14:02.658: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Apr  8 15:14:02.658: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Apr  8 15:14:02.684: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Apr  8 15:14:02.697: INFO: scanned /root for discovery docs: <nil>
Apr  8 15:14:02.697: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-9130'
Apr  8 15:14:18.507: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Apr  8 15:14:18.507: INFO: stdout: "Created e2e-test-nginx-rc-baba31c2266c9f2f766ba6b301f189da\nScaling up e2e-test-nginx-rc-baba31c2266c9f2f766ba6b301f189da from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-baba31c2266c9f2f766ba6b301f189da up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-baba31c2266c9f2f766ba6b301f189da to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Apr  8 15:14:18.507: INFO: stdout: "Created e2e-test-nginx-rc-baba31c2266c9f2f766ba6b301f189da\nScaling up e2e-test-nginx-rc-baba31c2266c9f2f766ba6b301f189da from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-baba31c2266c9f2f766ba6b301f189da up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-baba31c2266c9f2f766ba6b301f189da to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Apr  8 15:14:18.507: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-9130'
Apr  8 15:14:21.621: INFO: stderr: ""
Apr  8 15:14:21.621: INFO: stdout: "e2e-test-nginx-rc-baba31c2266c9f2f766ba6b301f189da-bn5nr "
Apr  8 15:14:21.621: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods e2e-test-nginx-rc-baba31c2266c9f2f766ba6b301f189da-bn5nr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9130'
Apr  8 15:14:21.724: INFO: stderr: ""
Apr  8 15:14:21.724: INFO: stdout: "true"
Apr  8 15:14:21.724: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods e2e-test-nginx-rc-baba31c2266c9f2f766ba6b301f189da-bn5nr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9130'
Apr  8 15:14:21.854: INFO: stderr: ""
Apr  8 15:14:21.854: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Apr  8 15:14:21.854: INFO: e2e-test-nginx-rc-baba31c2266c9f2f766ba6b301f189da-bn5nr is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1420
Apr  8 15:14:21.854: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config delete rc e2e-test-nginx-rc --namespace=kubectl-9130'
Apr  8 15:14:21.990: INFO: stderr: ""
Apr  8 15:14:21.990: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:14:21.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9130" for this suite.
Apr  8 15:14:44.020: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:14:44.178: INFO: namespace kubectl-9130 deletion completed in 22.172180913s
â€¢SSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:14:44.178: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-2911
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Apr  8 15:14:48.467: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  8 15:14:48.481: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  8 15:14:50.482: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  8 15:14:50.487: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  8 15:14:52.482: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  8 15:14:52.487: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  8 15:14:54.482: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  8 15:14:54.487: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  8 15:14:56.482: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  8 15:14:56.488: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  8 15:14:58.482: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  8 15:14:58.486: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  8 15:15:00.482: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  8 15:15:00.486: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  8 15:15:02.482: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  8 15:15:02.487: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  8 15:15:04.482: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  8 15:15:04.486: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  8 15:15:06.482: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  8 15:15:06.487: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  8 15:15:08.482: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  8 15:15:08.487: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  8 15:15:10.482: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  8 15:15:10.487: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  8 15:15:12.482: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  8 15:15:12.488: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  8 15:15:14.482: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  8 15:15:14.486: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  8 15:15:16.482: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  8 15:15:16.486: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:15:16.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2911" for this suite.
Apr  8 15:15:38.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:15:38.629: INFO: namespace container-lifecycle-hook-2911 deletion completed in 22.123893208s
â€¢SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:15:38.630: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5823
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  8 15:15:38.784: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2aa2b179-5a11-11e9-b9a9-e6698ebc8bdf" in namespace "downward-api-5823" to be "success or failure"
Apr  8 15:15:38.787: INFO: Pod "downwardapi-volume-2aa2b179-5a11-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 3.539657ms
Apr  8 15:15:40.792: INFO: Pod "downwardapi-volume-2aa2b179-5a11-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008366713s
STEP: Saw pod success
Apr  8 15:15:40.792: INFO: Pod "downwardapi-volume-2aa2b179-5a11-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:15:40.796: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod downwardapi-volume-2aa2b179-5a11-11e9-b9a9-e6698ebc8bdf container client-container: <nil>
STEP: delete the pod
Apr  8 15:15:40.818: INFO: Waiting for pod downwardapi-volume-2aa2b179-5a11-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:15:40.821: INFO: Pod downwardapi-volume-2aa2b179-5a11-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:15:40.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5823" for this suite.
Apr  8 15:15:46.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:15:46.959: INFO: namespace downward-api-5823 deletion completed in 6.133399076s
â€¢SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:15:46.959: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-9091
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  8 15:15:47.124: INFO: Create a RollingUpdate DaemonSet
Apr  8 15:15:47.129: INFO: Check that daemon pods launch on every node of the cluster
Apr  8 15:15:47.137: INFO: Number of nodes with available pods: 0
Apr  8 15:15:47.137: INFO: Node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw is running more than one daemon pod
Apr  8 15:15:48.149: INFO: Number of nodes with available pods: 0
Apr  8 15:15:48.149: INFO: Node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw is running more than one daemon pod
Apr  8 15:15:49.181: INFO: Number of nodes with available pods: 1
Apr  8 15:15:49.181: INFO: Node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw is running more than one daemon pod
Apr  8 15:15:50.146: INFO: Number of nodes with available pods: 2
Apr  8 15:15:50.146: INFO: Number of running nodes: 2, number of available pods: 2
Apr  8 15:15:50.146: INFO: Update the DaemonSet to trigger a rollout
Apr  8 15:15:50.154: INFO: Updating DaemonSet daemon-set
Apr  8 15:16:04.168: INFO: Roll back the DaemonSet before rollout is complete
Apr  8 15:16:04.178: INFO: Updating DaemonSet daemon-set
Apr  8 15:16:04.178: INFO: Make sure DaemonSet rollback is complete
Apr  8 15:16:04.189: INFO: Wrong image for pod: daemon-set-g9lbw. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr  8 15:16:04.189: INFO: Pod daemon-set-g9lbw is not available
Apr  8 15:16:05.276: INFO: Wrong image for pod: daemon-set-g9lbw. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr  8 15:16:05.276: INFO: Pod daemon-set-g9lbw is not available
Apr  8 15:16:06.277: INFO: Wrong image for pod: daemon-set-g9lbw. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr  8 15:16:06.277: INFO: Pod daemon-set-g9lbw is not available
Apr  8 15:16:07.280: INFO: Pod daemon-set-npp8r is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9091, will wait for the garbage collector to delete the pods
Apr  8 15:16:07.360: INFO: Deleting DaemonSet.extensions daemon-set took: 6.125025ms
Apr  8 15:16:07.760: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.255589ms
Apr  8 15:17:43.766: INFO: Number of nodes with available pods: 0
Apr  8 15:17:43.766: INFO: Number of running nodes: 0, number of available pods: 0
Apr  8 15:17:43.770: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9091/daemonsets","resourceVersion":"17769"},"items":null}

Apr  8 15:17:43.773: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9091/pods","resourceVersion":"17769"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:17:43.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9091" for this suite.
Apr  8 15:17:49.803: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:17:49.974: INFO: namespace daemonsets-9091 deletion completed in 6.183520544s
â€¢SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:17:49.974: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-725
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-2476
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-1837
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:18:14.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-725" for this suite.
Apr  8 15:18:20.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:18:20.610: INFO: namespace namespaces-725 deletion completed in 6.137420087s
STEP: Destroying namespace "nsdeletetest-2476" for this suite.
Apr  8 15:18:20.613: INFO: Namespace nsdeletetest-2476 was already deleted
STEP: Destroying namespace "nsdeletetest-1837" for this suite.
Apr  8 15:18:26.626: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:18:26.743: INFO: namespace nsdeletetest-1837 deletion completed in 6.12958302s
â€¢SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:18:26.743: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-8210
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:18:26.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8210" for this suite.
Apr  8 15:18:48.923: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:18:49.081: INFO: namespace kubelet-test-8210 deletion completed in 22.170640864s
â€¢SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:18:49.081: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-5781
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0408 15:18:55.260061    5043 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr  8 15:18:55.260: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:18:55.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5781" for this suite.
Apr  8 15:19:01.276: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:19:01.408: INFO: namespace gc-5781 deletion completed in 6.144565556s
â€¢SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:19:01.408: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8981
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  8 15:19:01.566: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a380f582-5a11-11e9-b9a9-e6698ebc8bdf" in namespace "projected-8981" to be "success or failure"
Apr  8 15:19:01.572: INFO: Pod "downwardapi-volume-a380f582-5a11-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 5.732605ms
Apr  8 15:19:03.578: INFO: Pod "downwardapi-volume-a380f582-5a11-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012042334s
STEP: Saw pod success
Apr  8 15:19:03.578: INFO: Pod "downwardapi-volume-a380f582-5a11-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:19:03.582: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod downwardapi-volume-a380f582-5a11-11e9-b9a9-e6698ebc8bdf container client-container: <nil>
STEP: delete the pod
Apr  8 15:19:03.606: INFO: Waiting for pod downwardapi-volume-a380f582-5a11-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:19:03.615: INFO: Pod downwardapi-volume-a380f582-5a11-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:19:03.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8981" for this suite.
Apr  8 15:19:09.631: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:19:09.762: INFO: namespace projected-8981 deletion completed in 6.142194207s
â€¢SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:19:09.762: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-4495
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  8 15:19:09.936: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"a87f1226-5a11-11e9-8aed-4ea023eb3a48", Controller:(*bool)(0xc0006a046a), BlockOwnerDeletion:(*bool)(0xc0006a046b)}}
Apr  8 15:19:09.940: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"a87da24e-5a11-11e9-8aed-4ea023eb3a48", Controller:(*bool)(0xc0030a9646), BlockOwnerDeletion:(*bool)(0xc0030a9647)}}
Apr  8 15:19:09.945: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"a87e7026-5a11-11e9-8aed-4ea023eb3a48", Controller:(*bool)(0xc0030a9976), BlockOwnerDeletion:(*bool)(0xc0030a9977)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:19:14.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4495" for this suite.
Apr  8 15:19:20.979: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:19:21.110: INFO: namespace gc-4495 deletion completed in 6.146519838s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:19:21.111: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-2213
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Apr  8 15:19:25.310: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr  8 15:19:25.314: INFO: Pod pod-with-prestop-http-hook still exists
Apr  8 15:19:27.314: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr  8 15:19:27.320: INFO: Pod pod-with-prestop-http-hook still exists
Apr  8 15:19:29.314: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr  8 15:19:29.319: INFO: Pod pod-with-prestop-http-hook still exists
Apr  8 15:19:31.314: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr  8 15:19:31.319: INFO: Pod pod-with-prestop-http-hook still exists
Apr  8 15:19:33.314: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr  8 15:19:33.319: INFO: Pod pod-with-prestop-http-hook still exists
Apr  8 15:19:35.314: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr  8 15:19:35.319: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:19:35.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2213" for this suite.
Apr  8 15:19:57.357: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:19:57.474: INFO: namespace container-lifecycle-hook-2213 deletion completed in 22.130770691s
â€¢SSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:19:57.474: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-6571
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-6571
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr  8 15:19:57.620: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr  8 15:20:19.704: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.201:8080/dial?request=hostName&protocol=http&host=100.96.0.84&port=8080&tries=1'] Namespace:pod-network-test-6571 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  8 15:20:19.704: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
Apr  8 15:20:20.158: INFO: Waiting for endpoints: map[]
Apr  8 15:20:20.163: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.201:8080/dial?request=hostName&protocol=http&host=100.96.1.200&port=8080&tries=1'] Namespace:pod-network-test-6571 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  8 15:20:20.163: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
Apr  8 15:20:20.587: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:20:20.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6571" for this suite.
Apr  8 15:20:42.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:20:42.767: INFO: namespace pod-network-test-6571 deletion completed in 22.172666506s
â€¢SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:20:42.767: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-8356
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  8 15:20:42.931: INFO: (0) /api/v1/nodes/shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 10.158043ms)
Apr  8 15:20:42.969: INFO: (1) /api/v1/nodes/shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 38.10979ms)
Apr  8 15:20:42.975: INFO: (2) /api/v1/nodes/shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.874609ms)
Apr  8 15:20:42.980: INFO: (3) /api/v1/nodes/shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.926499ms)
Apr  8 15:20:42.985: INFO: (4) /api/v1/nodes/shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.067259ms)
Apr  8 15:20:42.991: INFO: (5) /api/v1/nodes/shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.944855ms)
Apr  8 15:20:42.996: INFO: (6) /api/v1/nodes/shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.589348ms)
Apr  8 15:20:43.001: INFO: (7) /api/v1/nodes/shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.114315ms)
Apr  8 15:20:43.007: INFO: (8) /api/v1/nodes/shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.754738ms)
Apr  8 15:20:43.013: INFO: (9) /api/v1/nodes/shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.500122ms)
Apr  8 15:20:43.018: INFO: (10) /api/v1/nodes/shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.204774ms)
Apr  8 15:20:43.023: INFO: (11) /api/v1/nodes/shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.306321ms)
Apr  8 15:20:43.028: INFO: (12) /api/v1/nodes/shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.101404ms)
Apr  8 15:20:43.034: INFO: (13) /api/v1/nodes/shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.107114ms)
Apr  8 15:20:43.039: INFO: (14) /api/v1/nodes/shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.471109ms)
Apr  8 15:20:43.044: INFO: (15) /api/v1/nodes/shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.867552ms)
Apr  8 15:20:43.050: INFO: (16) /api/v1/nodes/shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.617388ms)
Apr  8 15:20:43.056: INFO: (17) /api/v1/nodes/shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 6.153303ms)
Apr  8 15:20:43.063: INFO: (18) /api/v1/nodes/shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 7.13736ms)
Apr  8 15:20:43.072: INFO: (19) /api/v1/nodes/shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 8.655991ms)
[AfterEach] version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:20:43.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8356" for this suite.
Apr  8 15:20:49.098: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:20:49.233: INFO: namespace proxy-8356 deletion completed in 6.153177272s
â€¢SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:20:49.233: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4962
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1108
STEP: creating the pod
Apr  8 15:20:49.385: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config create -f - --namespace=kubectl-4962'
Apr  8 15:20:49.648: INFO: stderr: ""
Apr  8 15:20:49.648: INFO: stdout: "pod/pause created\n"
Apr  8 15:20:49.648: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Apr  8 15:20:49.648: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-4962" to be "running and ready"
Apr  8 15:20:49.653: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 4.629088ms
Apr  8 15:20:51.657: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.008962824s
Apr  8 15:20:51.657: INFO: Pod "pause" satisfied condition "running and ready"
Apr  8 15:20:51.657: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: adding the label testing-label with value testing-label-value to a pod
Apr  8 15:20:51.657: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config label pods pause testing-label=testing-label-value --namespace=kubectl-4962'
Apr  8 15:20:51.765: INFO: stderr: ""
Apr  8 15:20:51.765: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Apr  8 15:20:51.765: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pod pause -L testing-label --namespace=kubectl-4962'
Apr  8 15:20:51.860: INFO: stderr: ""
Apr  8 15:20:51.860: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Apr  8 15:20:51.860: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config label pods pause testing-label- --namespace=kubectl-4962'
Apr  8 15:20:51.965: INFO: stderr: ""
Apr  8 15:20:51.965: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Apr  8 15:20:51.965: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pod pause -L testing-label --namespace=kubectl-4962'
Apr  8 15:20:52.077: INFO: stderr: ""
Apr  8 15:20:52.077: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1115
STEP: using delete to clean up resources
Apr  8 15:20:52.077: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-4962'
Apr  8 15:20:52.184: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  8 15:20:52.184: INFO: stdout: "pod \"pause\" force deleted\n"
Apr  8 15:20:52.184: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get rc,svc -l name=pause --no-headers --namespace=kubectl-4962'
Apr  8 15:20:52.297: INFO: stderr: "No resources found.\n"
Apr  8 15:20:52.297: INFO: stdout: ""
Apr  8 15:20:52.297: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods -l name=pause --namespace=kubectl-4962 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr  8 15:20:52.393: INFO: stderr: ""
Apr  8 15:20:52.394: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:20:52.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4962" for this suite.
Apr  8 15:20:58.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:20:58.584: INFO: namespace kubectl-4962 deletion completed in 6.185984626s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:20:58.585: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-5450
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:21:00.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5450" for this suite.
Apr  8 15:21:46.788: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:21:46.909: INFO: namespace kubelet-test-5450 deletion completed in 46.137437056s
â€¢S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:21:46.909: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2510
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Apr  8 15:21:47.061: INFO: Waiting up to 5m0s for pod "pod-0625979e-5a12-11e9-b9a9-e6698ebc8bdf" in namespace "emptydir-2510" to be "success or failure"
Apr  8 15:21:47.064: INFO: Pod "pod-0625979e-5a12-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 3.092132ms
Apr  8 15:21:49.068: INFO: Pod "pod-0625979e-5a12-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007746922s
STEP: Saw pod success
Apr  8 15:21:49.069: INFO: Pod "pod-0625979e-5a12-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:21:49.072: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-0625979e-5a12-11e9-b9a9-e6698ebc8bdf container test-container: <nil>
STEP: delete the pod
Apr  8 15:21:49.092: INFO: Waiting for pod pod-0625979e-5a12-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:21:49.095: INFO: Pod pod-0625979e-5a12-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:21:49.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2510" for this suite.
Apr  8 15:21:55.112: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:21:55.320: INFO: namespace emptydir-2510 deletion completed in 6.220848545s
â€¢SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:21:55.320: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-457
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-0b29cc1f-5a12-11e9-b9a9-e6698ebc8bdf
STEP: Creating a pod to test consume secrets
Apr  8 15:21:55.484: INFO: Waiting up to 5m0s for pod "pod-secrets-0b2a7c0f-5a12-11e9-b9a9-e6698ebc8bdf" in namespace "secrets-457" to be "success or failure"
Apr  8 15:21:55.489: INFO: Pod "pod-secrets-0b2a7c0f-5a12-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.901841ms
Apr  8 15:21:57.494: INFO: Pod "pod-secrets-0b2a7c0f-5a12-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01004316s
STEP: Saw pod success
Apr  8 15:21:57.494: INFO: Pod "pod-secrets-0b2a7c0f-5a12-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:21:57.499: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-secrets-0b2a7c0f-5a12-11e9-b9a9-e6698ebc8bdf container secret-volume-test: <nil>
STEP: delete the pod
Apr  8 15:21:57.518: INFO: Waiting for pod pod-secrets-0b2a7c0f-5a12-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:21:57.521: INFO: Pod pod-secrets-0b2a7c0f-5a12-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:21:57.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-457" for this suite.
Apr  8 15:22:03.540: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:22:03.675: INFO: namespace secrets-457 deletion completed in 6.148871289s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:22:03.675: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1836
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Apr  8 15:22:03.831: INFO: Waiting up to 5m0s for pod "pod-102492e5-5a12-11e9-b9a9-e6698ebc8bdf" in namespace "emptydir-1836" to be "success or failure"
Apr  8 15:22:03.835: INFO: Pod "pod-102492e5-5a12-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 3.218373ms
Apr  8 15:22:05.839: INFO: Pod "pod-102492e5-5a12-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007528186s
STEP: Saw pod success
Apr  8 15:22:05.839: INFO: Pod "pod-102492e5-5a12-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:22:05.843: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-102492e5-5a12-11e9-b9a9-e6698ebc8bdf container test-container: <nil>
STEP: delete the pod
Apr  8 15:22:05.864: INFO: Waiting for pod pod-102492e5-5a12-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:22:05.868: INFO: Pod pod-102492e5-5a12-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:22:05.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1836" for this suite.
Apr  8 15:22:11.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:22:12.017: INFO: namespace emptydir-1836 deletion completed in 6.144268924s
â€¢
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:22:12.017: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-9063
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override all
Apr  8 15:22:12.177: INFO: Waiting up to 5m0s for pod "client-containers-151ddb5d-5a12-11e9-b9a9-e6698ebc8bdf" in namespace "containers-9063" to be "success or failure"
Apr  8 15:22:12.183: INFO: Pod "client-containers-151ddb5d-5a12-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 5.854366ms
Apr  8 15:22:14.189: INFO: Pod "client-containers-151ddb5d-5a12-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011744353s
STEP: Saw pod success
Apr  8 15:22:14.189: INFO: Pod "client-containers-151ddb5d-5a12-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:22:14.193: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod client-containers-151ddb5d-5a12-11e9-b9a9-e6698ebc8bdf container test-container: <nil>
STEP: delete the pod
Apr  8 15:22:14.215: INFO: Waiting for pod client-containers-151ddb5d-5a12-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:22:14.219: INFO: Pod client-containers-151ddb5d-5a12-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:22:14.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9063" for this suite.
Apr  8 15:22:20.237: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:22:20.373: INFO: namespace containers-9063 deletion completed in 6.149734222s
â€¢SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:22:20.374: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6104
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  8 15:22:20.540: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config version --client'
Apr  8 15:22:20.613: INFO: stderr: ""
Apr  8 15:22:20.613: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.3\", GitCommit:\"435f92c719f279a3a67808c80521ea17d5715c66\", GitTreeState:\"clean\", BuildDate:\"2018-11-26T12:57:14Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Apr  8 15:22:20.616: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config create -f - --namespace=kubectl-6104'
Apr  8 15:22:20.976: INFO: stderr: ""
Apr  8 15:22:20.976: INFO: stdout: "replicationcontroller/redis-master created\n"
Apr  8 15:22:20.976: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config create -f - --namespace=kubectl-6104'
Apr  8 15:22:21.203: INFO: stderr: ""
Apr  8 15:22:21.203: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Apr  8 15:22:22.209: INFO: Selector matched 1 pods for map[app:redis]
Apr  8 15:22:22.209: INFO: Found 1 / 1
Apr  8 15:22:22.209: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr  8 15:22:22.213: INFO: Selector matched 1 pods for map[app:redis]
Apr  8 15:22:22.213: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr  8 15:22:22.213: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config describe pod redis-master-b8ghl --namespace=kubectl-6104'
Apr  8 15:22:22.369: INFO: stderr: ""
Apr  8 15:22:22.369: INFO: stdout: "Name:               redis-master-b8ghl\nNamespace:          kubectl-6104\nPriority:           0\nPriorityClassName:  <none>\nNode:               shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw/10.250.0.16\nStart Time:         Mon, 08 Apr 2019 15:22:20 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        cni.projectcalico.org/podIP: 100.96.1.208/32\n                    kubernetes.io/psp: e2e-test-privileged-psp\nStatus:             Running\nIP:                 100.96.1.208\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://cfaa0bac43f28cffba2d3580b0c2c65277c8c9ab926855a7097e9d8066b13714\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 08 Apr 2019 15:22:21 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-ljww9 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-ljww9:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-ljww9\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                                             Message\n  ----    ------     ----  ----                                                             -------\n  Normal  Scheduled  2s    default-scheduler                                                Successfully assigned kubectl-6104/redis-master-b8ghl to shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw\n  Normal  Pulled     1s    kubelet, shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw  Created container redis-master\n  Normal  Started    1s    kubelet, shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw  Started container redis-master\n"
Apr  8 15:22:22.369: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config describe rc redis-master --namespace=kubectl-6104'
Apr  8 15:22:22.492: INFO: stderr: ""
Apr  8 15:22:22.492: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-6104\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-b8ghl\n"
Apr  8 15:22:22.492: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config describe service redis-master --namespace=kubectl-6104'
Apr  8 15:22:22.604: INFO: stderr: ""
Apr  8 15:22:22.604: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-6104\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                100.66.128.55\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         100.96.1.208:6379\nSession Affinity:  None\nEvents:            <none>\n"
Apr  8 15:22:22.609: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config describe node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw'
Apr  8 15:22:22.744: INFO: stderr: ""
Apr  8 15:22:22.744: INFO: stdout: "Name:               shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw\nRoles:              node\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=ecf69421-6238-4433-a0a0-70bb24198e09\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/zone=rot_1_1\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw\n                    kubernetes.io/os=linux\n                    kubernetes.io/role=node\n                    node-role.kubernetes.io/node=\n                    worker.garden.sapcloud.io/group=cpu-worker\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.250.0.13/19\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 08 Apr 2019 13:53:54 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Mon, 08 Apr 2019 15:22:15 +0000   Mon, 08 Apr 2019 13:53:54 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Mon, 08 Apr 2019 15:22:15 +0000   Mon, 08 Apr 2019 13:53:54 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Mon, 08 Apr 2019 15:22:15 +0000   Mon, 08 Apr 2019 13:53:54 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Mon, 08 Apr 2019 15:22:15 +0000   Mon, 08 Apr 2019 13:54:14 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  10.250.0.13\nCapacity:\n attachable-volumes-cinder:  256\n cpu:                        2\n ephemeral-storage:          38216108Ki\n hugepages-1Gi:              0\n hugepages-2Mi:              0\n memory:                     4041244Ki\n pods:                       110\nAllocatable:\n attachable-volumes-cinder:  256\n cpu:                        1920m\n ephemeral-storage:          37176629834\n hugepages-1Gi:              0\n hugepages-2Mi:              0\n memory:                     2857580337\n pods:                       110\nSystem Info:\n Machine ID:                 8c1d6b636b184453b4a9e0080a6f3d2b\n System UUID:                8c1d6b63-6b18-4453-b4a9-e0080a6f3d2b\n Boot ID:                    4e2f9fa4-1e0d-4650-9d79-d7f2e0bb30c6\n Kernel Version:             4.19.25-coreos\n OS Image:                   Container Linux by CoreOS 2023.5.0 (Rhyolite)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.1\n Kubelet Version:            v1.14.0\n Kube-Proxy Version:         v1.14.0\nPodCIDR:                     100.96.0.0/24\nProviderID:                  openstack:///8c1d6b63-6b18-4453-b4a9-e0080a6f3d2b\nNon-terminated Pods:         (11 in total)\n  Namespace                  Name                                                               CPU Requests  CPU Limits  Memory Requests  Memory Limits\n  ---------                  ----                                                               ------------  ----------  ---------------  -------------\n  kube-system                addons-kubernetes-dashboard-665df4b66d-w6dfr                       50m (2%)      100m (5%)   50Mi (1%)        256Mi (9%)\n  kube-system                addons-nginx-ingress-controller-d4f8c9cc5-dz84h                    100m (5%)     2 (104%)    100Mi (3%)       800Mi (29%)\n  kube-system                addons-nginx-ingress-nginx-ingress-k8s-backend-754f8f5dcb-scvf9    0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                blackbox-exporter-6dc58dcffc-kddgs                                 5m (0%)       10m (0%)    5Mi (0%)         35Mi (1%)\n  kube-system                calico-node-rhz9g                                                  100m (5%)     500m (26%)  100Mi (3%)       700Mi (25%)\n  kube-system                coredns-7f7f7978c8-2cw6g                                           50m (2%)      100m (5%)   15Mi (0%)        100Mi (3%)\n  kube-system                coredns-7f7f7978c8-jpqwt                                           50m (2%)      100m (5%)   15Mi (0%)        100Mi (3%)\n  kube-system                kube-proxy-zwjh7                                                   20m (1%)      0 (0%)      64Mi (2%)        0 (0%)\n  kube-system                metrics-server-bbc67f984-2cbzt                                     20m (1%)      80m (4%)    100Mi (3%)       400Mi (14%)\n  kube-system                node-exporter-52tc5                                                5m (0%)       15m (0%)    10Mi (0%)        100Mi (3%)\n  kube-system                vpn-shoot-846bd99d6c-frws7                                         50m (2%)      100m (5%)   50Mi (1%)        100Mi (3%)\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                   Requests     Limits\n  --------                   --------     ------\n  cpu                        450m (23%)   3005m (156%)\n  memory                     509Mi (18%)  2591Mi (95%)\n  attachable-volumes-cinder  0            0\nEvents:                      <none>\n"
Apr  8 15:22:22.744: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config describe namespace kubectl-6104'
Apr  8 15:22:22.864: INFO: stderr: ""
Apr  8 15:22:22.864: INFO: stdout: "Name:         kubectl-6104\nLabels:       e2e-framework=kubectl\n              e2e-run=bd9269f1-5a06-11e9-b9a9-e6698ebc8bdf\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:22:22.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6104" for this suite.
Apr  8 15:22:44.881: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:22:45.002: INFO: namespace kubectl-6104 deletion completed in 22.133558775s
â€¢SSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:22:45.003: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-1583
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-rfvf
STEP: Creating a pod to test atomic-volume-subpath
Apr  8 15:22:45.169: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-rfvf" in namespace "subpath-1583" to be "success or failure"
Apr  8 15:22:45.172: INFO: Pod "pod-subpath-test-configmap-rfvf": Phase="Pending", Reason="", readiness=false. Elapsed: 3.119257ms
Apr  8 15:22:47.178: INFO: Pod "pod-subpath-test-configmap-rfvf": Phase="Running", Reason="", readiness=true. Elapsed: 2.00916629s
Apr  8 15:22:49.183: INFO: Pod "pod-subpath-test-configmap-rfvf": Phase="Running", Reason="", readiness=true. Elapsed: 4.01446923s
Apr  8 15:22:51.189: INFO: Pod "pod-subpath-test-configmap-rfvf": Phase="Running", Reason="", readiness=true. Elapsed: 6.019750867s
Apr  8 15:22:53.194: INFO: Pod "pod-subpath-test-configmap-rfvf": Phase="Running", Reason="", readiness=true. Elapsed: 8.024913203s
Apr  8 15:22:55.199: INFO: Pod "pod-subpath-test-configmap-rfvf": Phase="Running", Reason="", readiness=true. Elapsed: 10.030135119s
Apr  8 15:22:57.205: INFO: Pod "pod-subpath-test-configmap-rfvf": Phase="Running", Reason="", readiness=true. Elapsed: 12.035642193s
Apr  8 15:22:59.209: INFO: Pod "pod-subpath-test-configmap-rfvf": Phase="Running", Reason="", readiness=true. Elapsed: 14.040160741s
Apr  8 15:23:01.215: INFO: Pod "pod-subpath-test-configmap-rfvf": Phase="Running", Reason="", readiness=true. Elapsed: 16.046350341s
Apr  8 15:23:03.221: INFO: Pod "pod-subpath-test-configmap-rfvf": Phase="Running", Reason="", readiness=true. Elapsed: 18.051554831s
Apr  8 15:23:05.226: INFO: Pod "pod-subpath-test-configmap-rfvf": Phase="Running", Reason="", readiness=true. Elapsed: 20.057397535s
Apr  8 15:23:07.232: INFO: Pod "pod-subpath-test-configmap-rfvf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.062571102s
STEP: Saw pod success
Apr  8 15:23:07.232: INFO: Pod "pod-subpath-test-configmap-rfvf" satisfied condition "success or failure"
Apr  8 15:23:07.235: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-subpath-test-configmap-rfvf container test-container-subpath-configmap-rfvf: <nil>
STEP: delete the pod
Apr  8 15:23:07.258: INFO: Waiting for pod pod-subpath-test-configmap-rfvf to disappear
Apr  8 15:23:07.261: INFO: Pod pod-subpath-test-configmap-rfvf no longer exists
STEP: Deleting pod pod-subpath-test-configmap-rfvf
Apr  8 15:23:07.261: INFO: Deleting pod "pod-subpath-test-configmap-rfvf" in namespace "subpath-1583"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:23:07.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1583" for this suite.
Apr  8 15:23:13.282: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:23:13.504: INFO: namespace subpath-1583 deletion completed in 6.2351805s
â€¢SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:23:13.505: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4627
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-4627
Apr  8 15:23:15.704: INFO: Started pod liveness-http in namespace container-probe-4627
STEP: checking the pod's current state and verifying that restartCount is present
Apr  8 15:23:15.708: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:27:16.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4627" for this suite.
Apr  8 15:27:22.520: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:27:22.646: INFO: namespace container-probe-4627 deletion completed in 6.137936707s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:27:22.646: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-529
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-secret-7qcq
STEP: Creating a pod to test atomic-volume-subpath
Apr  8 15:27:22.806: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-7qcq" in namespace "subpath-529" to be "success or failure"
Apr  8 15:27:22.810: INFO: Pod "pod-subpath-test-secret-7qcq": Phase="Pending", Reason="", readiness=false. Elapsed: 3.65734ms
Apr  8 15:27:24.815: INFO: Pod "pod-subpath-test-secret-7qcq": Phase="Running", Reason="", readiness=true. Elapsed: 2.008423992s
Apr  8 15:27:26.820: INFO: Pod "pod-subpath-test-secret-7qcq": Phase="Running", Reason="", readiness=true. Elapsed: 4.013330489s
Apr  8 15:27:28.825: INFO: Pod "pod-subpath-test-secret-7qcq": Phase="Running", Reason="", readiness=true. Elapsed: 6.018339728s
Apr  8 15:27:30.830: INFO: Pod "pod-subpath-test-secret-7qcq": Phase="Running", Reason="", readiness=true. Elapsed: 8.023333997s
Apr  8 15:27:32.834: INFO: Pod "pod-subpath-test-secret-7qcq": Phase="Running", Reason="", readiness=true. Elapsed: 10.028230562s
Apr  8 15:27:34.839: INFO: Pod "pod-subpath-test-secret-7qcq": Phase="Running", Reason="", readiness=true. Elapsed: 12.033195938s
Apr  8 15:27:36.846: INFO: Pod "pod-subpath-test-secret-7qcq": Phase="Running", Reason="", readiness=true. Elapsed: 14.039800131s
Apr  8 15:27:38.851: INFO: Pod "pod-subpath-test-secret-7qcq": Phase="Running", Reason="", readiness=true. Elapsed: 16.045224543s
Apr  8 15:27:40.857: INFO: Pod "pod-subpath-test-secret-7qcq": Phase="Running", Reason="", readiness=true. Elapsed: 18.050654844s
Apr  8 15:27:42.863: INFO: Pod "pod-subpath-test-secret-7qcq": Phase="Running", Reason="", readiness=true. Elapsed: 20.056743547s
Apr  8 15:27:44.868: INFO: Pod "pod-subpath-test-secret-7qcq": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.061998899s
STEP: Saw pod success
Apr  8 15:27:44.868: INFO: Pod "pod-subpath-test-secret-7qcq" satisfied condition "success or failure"
Apr  8 15:27:44.872: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-subpath-test-secret-7qcq container test-container-subpath-secret-7qcq: <nil>
STEP: delete the pod
Apr  8 15:27:44.906: INFO: Waiting for pod pod-subpath-test-secret-7qcq to disappear
Apr  8 15:27:44.909: INFO: Pod pod-subpath-test-secret-7qcq no longer exists
STEP: Deleting pod pod-subpath-test-secret-7qcq
Apr  8 15:27:44.909: INFO: Deleting pod "pod-subpath-test-secret-7qcq" in namespace "subpath-529"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:27:44.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-529" for this suite.
Apr  8 15:27:50.929: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:27:51.049: INFO: namespace subpath-529 deletion completed in 6.131994481s
â€¢SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:27:51.049: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6219
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-df31accf-5a12-11e9-b9a9-e6698ebc8bdf
STEP: Creating a pod to test consume secrets
Apr  8 15:27:51.211: INFO: Waiting up to 5m0s for pod "pod-secrets-df32522d-5a12-11e9-b9a9-e6698ebc8bdf" in namespace "secrets-6219" to be "success or failure"
Apr  8 15:27:51.214: INFO: Pod "pod-secrets-df32522d-5a12-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.946687ms
Apr  8 15:27:53.218: INFO: Pod "pod-secrets-df32522d-5a12-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007468087s
STEP: Saw pod success
Apr  8 15:27:53.218: INFO: Pod "pod-secrets-df32522d-5a12-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:27:53.222: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-secrets-df32522d-5a12-11e9-b9a9-e6698ebc8bdf container secret-env-test: <nil>
STEP: delete the pod
Apr  8 15:27:53.240: INFO: Waiting for pod pod-secrets-df32522d-5a12-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:27:53.243: INFO: Pod pod-secrets-df32522d-5a12-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:27:53.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6219" for this suite.
Apr  8 15:27:59.260: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:27:59.389: INFO: namespace secrets-6219 deletion completed in 6.141821866s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:27:59.390: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-5206
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-5206
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-5206
STEP: Creating statefulset with conflicting port in namespace statefulset-5206
STEP: Waiting until pod test-pod will start running in namespace statefulset-5206
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-5206
Apr  8 15:28:03.610: INFO: Observed stateful pod in namespace: statefulset-5206, name: ss-0, uid: e6980b3e-5a12-11e9-8aed-4ea023eb3a48, status phase: Pending. Waiting for statefulset controller to delete.
Apr  8 15:28:03.627: INFO: Observed stateful pod in namespace: statefulset-5206, name: ss-0, uid: e6980b3e-5a12-11e9-8aed-4ea023eb3a48, status phase: Failed. Waiting for statefulset controller to delete.
Apr  8 15:28:03.711: INFO: Observed stateful pod in namespace: statefulset-5206, name: ss-0, uid: e6980b3e-5a12-11e9-8aed-4ea023eb3a48, status phase: Failed. Waiting for statefulset controller to delete.
Apr  8 15:28:03.712: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-5206
STEP: Removing pod with conflicting port in namespace statefulset-5206
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-5206 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr  8 15:28:05.732: INFO: Deleting all statefulset in ns statefulset-5206
Apr  8 15:28:05.735: INFO: Scaling statefulset ss to 0
Apr  8 15:28:15.752: INFO: Waiting for statefulset status.replicas updated to 0
Apr  8 15:28:15.756: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:28:15.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5206" for this suite.
Apr  8 15:28:21.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:28:21.931: INFO: namespace statefulset-5206 deletion completed in 6.155885186s
â€¢SS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:28:21.931: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-8987
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  8 15:28:22.083: INFO: Creating deployment "test-recreate-deployment"
Apr  8 15:28:22.088: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Apr  8 15:28:22.098: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Apr  8 15:28:24.107: INFO: Waiting deployment "test-recreate-deployment" to complete
Apr  8 15:28:24.110: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Apr  8 15:28:24.118: INFO: Updating deployment test-recreate-deployment
Apr  8 15:28:24.118: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr  8 15:28:24.160: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-8987,SelfLink:/apis/apps/v1/namespaces/deployment-8987/deployments/test-recreate-deployment,UID:f19b7f5e-5a12-11e9-8aed-4ea023eb3a48,ResourceVersion:19913,Generation:2,CreationTimestamp:2019-04-08 15:28:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-04-08 15:28:24 +0000 UTC 2019-04-08 15:28:24 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-04-08 15:28:24 +0000 UTC 2019-04-08 15:28:22 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-c9cbd8684" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Apr  8 15:28:24.168: INFO: New ReplicaSet "test-recreate-deployment-c9cbd8684" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-c9cbd8684,GenerateName:,Namespace:deployment-8987,SelfLink:/apis/apps/v1/namespaces/deployment-8987/replicasets/test-recreate-deployment-c9cbd8684,UID:f2d4d09c-5a12-11e9-8aed-4ea023eb3a48,ResourceVersion:19912,Generation:1,CreationTimestamp:2019-04-08 15:28:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment f19b7f5e-5a12-11e9-8aed-4ea023eb3a48 0xc002eb10a0 0xc002eb10a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr  8 15:28:24.168: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Apr  8 15:28:24.169: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7d57d5ff7c,GenerateName:,Namespace:deployment-8987,SelfLink:/apis/apps/v1/namespaces/deployment-8987/replicasets/test-recreate-deployment-7d57d5ff7c,UID:f19c21d3-5a12-11e9-8aed-4ea023eb3a48,ResourceVersion:19905,Generation:2,CreationTimestamp:2019-04-08 15:28:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment f19b7f5e-5a12-11e9-8aed-4ea023eb3a48 0xc002eb0fd7 0xc002eb0fd8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr  8 15:28:24.173: INFO: Pod "test-recreate-deployment-c9cbd8684-zxbdc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-c9cbd8684-zxbdc,GenerateName:test-recreate-deployment-c9cbd8684-,Namespace:deployment-8987,SelfLink:/api/v1/namespaces/deployment-8987/pods/test-recreate-deployment-c9cbd8684-zxbdc,UID:f2d57b34-5a12-11e9-8aed-4ea023eb3a48,ResourceVersion:19914,Generation:0,CreationTimestamp:2019-04-08 15:28:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-c9cbd8684 f2d4d09c-5a12-11e9-8aed-4ea023eb3a48 0xc002eb18e0 0xc002eb18e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nb7p4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nb7p4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nb7p4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002eb1940} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002eb1970}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:28:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:28:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:28:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:28:24 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.16,PodIP:,StartTime:2019-04-08 15:28:24 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:28:24.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8987" for this suite.
Apr  8 15:28:30.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:28:30.320: INFO: namespace deployment-8987 deletion completed in 6.141902374s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:28:30.320: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-5700
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Apr  8 15:28:32.509: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-f69b8a50-5a12-11e9-b9a9-e6698ebc8bdf,GenerateName:,Namespace:events-5700,SelfLink:/api/v1/namespaces/events-5700/pods/send-events-f69b8a50-5a12-11e9-b9a9-e6698ebc8bdf,UID:f69d33cc-5a12-11e9-8aed-4ea023eb3a48,ResourceVersion:19957,Generation:0,CreationTimestamp:2019-04-08 15:28:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 481064311,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.215/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4vzgc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4vzgc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-4vzgc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001fe5380} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001fe53a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:28:30 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:28:31 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:28:31 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-08 15:28:30 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.16,PodIP:100.96.1.215,StartTime:2019-04-08 15:28:30 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-04-08 15:28:31 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://141d014091974ab01a0cfd27f22a1003ecfdbf3341020d3146b697612b23a80c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Apr  8 15:28:34.515: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Apr  8 15:28:36.521: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:28:36.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-5700" for this suite.
Apr  8 15:29:16.548: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:29:16.689: INFO: namespace events-5700 deletion completed in 40.155297733s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:29:16.689: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9022
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0408 15:29:26.897853    5043 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr  8 15:29:26.897: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:29:26.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9022" for this suite.
Apr  8 15:29:32.912: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:29:33.039: INFO: namespace gc-9022 deletion completed in 6.137961366s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:29:33.039: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7090
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-1bfba38d-5a13-11e9-b9a9-e6698ebc8bdf
STEP: Creating a pod to test consume configMaps
Apr  8 15:29:33.207: INFO: Waiting up to 5m0s for pod "pod-configmaps-1bfc4c64-5a13-11e9-b9a9-e6698ebc8bdf" in namespace "configmap-7090" to be "success or failure"
Apr  8 15:29:33.211: INFO: Pod "pod-configmaps-1bfc4c64-5a13-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.251373ms
Apr  8 15:29:35.217: INFO: Pod "pod-configmaps-1bfc4c64-5a13-11e9-b9a9-e6698ebc8bdf": Phase="Running", Reason="", readiness=true. Elapsed: 2.010537874s
Apr  8 15:29:37.223: INFO: Pod "pod-configmaps-1bfc4c64-5a13-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016854552s
STEP: Saw pod success
Apr  8 15:29:37.224: INFO: Pod "pod-configmaps-1bfc4c64-5a13-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:29:37.227: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-configmaps-1bfc4c64-5a13-11e9-b9a9-e6698ebc8bdf container configmap-volume-test: <nil>
STEP: delete the pod
Apr  8 15:29:37.252: INFO: Waiting for pod pod-configmaps-1bfc4c64-5a13-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:29:37.255: INFO: Pod pod-configmaps-1bfc4c64-5a13-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:29:37.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7090" for this suite.
Apr  8 15:29:43.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:29:43.386: INFO: namespace configmap-7090 deletion completed in 6.126118121s
â€¢SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:29:43.386: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-6352
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Apr  8 15:29:43.599: INFO: Number of nodes with available pods: 0
Apr  8 15:29:43.599: INFO: Node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw is running more than one daemon pod
Apr  8 15:29:44.610: INFO: Number of nodes with available pods: 0
Apr  8 15:29:44.610: INFO: Node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw is running more than one daemon pod
Apr  8 15:29:45.609: INFO: Number of nodes with available pods: 2
Apr  8 15:29:45.609: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Apr  8 15:29:45.632: INFO: Number of nodes with available pods: 1
Apr  8 15:29:45.632: INFO: Node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw is running more than one daemon pod
Apr  8 15:29:46.643: INFO: Number of nodes with available pods: 1
Apr  8 15:29:46.643: INFO: Node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw is running more than one daemon pod
Apr  8 15:29:47.642: INFO: Number of nodes with available pods: 1
Apr  8 15:29:47.642: INFO: Node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw is running more than one daemon pod
Apr  8 15:29:48.641: INFO: Number of nodes with available pods: 1
Apr  8 15:29:48.641: INFO: Node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw is running more than one daemon pod
Apr  8 15:29:49.642: INFO: Number of nodes with available pods: 1
Apr  8 15:29:49.642: INFO: Node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw is running more than one daemon pod
Apr  8 15:29:50.643: INFO: Number of nodes with available pods: 1
Apr  8 15:29:50.643: INFO: Node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw is running more than one daemon pod
Apr  8 15:29:51.643: INFO: Number of nodes with available pods: 1
Apr  8 15:29:51.643: INFO: Node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw is running more than one daemon pod
Apr  8 15:29:52.641: INFO: Number of nodes with available pods: 1
Apr  8 15:29:52.641: INFO: Node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw is running more than one daemon pod
Apr  8 15:29:53.642: INFO: Number of nodes with available pods: 1
Apr  8 15:29:53.642: INFO: Node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw is running more than one daemon pod
Apr  8 15:29:54.641: INFO: Number of nodes with available pods: 1
Apr  8 15:29:54.641: INFO: Node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw is running more than one daemon pod
Apr  8 15:29:55.642: INFO: Number of nodes with available pods: 2
Apr  8 15:29:55.642: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6352, will wait for the garbage collector to delete the pods
Apr  8 15:29:55.705: INFO: Deleting DaemonSet.extensions daemon-set took: 6.774652ms
Apr  8 15:29:55.805: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.246887ms
Apr  8 15:30:04.810: INFO: Number of nodes with available pods: 0
Apr  8 15:30:04.810: INFO: Number of running nodes: 0, number of available pods: 0
Apr  8 15:30:04.814: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6352/daemonsets","resourceVersion":"20264"},"items":null}

Apr  8 15:30:04.817: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6352/pods","resourceVersion":"20264"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:30:04.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6352" for this suite.
Apr  8 15:30:10.848: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:30:10.982: INFO: namespace daemonsets-6352 deletion completed in 6.146758497s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:30:10.982: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-5978
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-zsp9p in namespace proxy-5978
I0408 15:30:11.160154    5043 runners.go:184] Created replication controller with name: proxy-service-zsp9p, namespace: proxy-5978, replica count: 1
I0408 15:30:12.210683    5043 runners.go:184] proxy-service-zsp9p Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0408 15:30:13.210913    5043 runners.go:184] proxy-service-zsp9p Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0408 15:30:14.211150    5043 runners.go:184] proxy-service-zsp9p Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0408 15:30:15.211405    5043 runners.go:184] proxy-service-zsp9p Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0408 15:30:16.211642    5043 runners.go:184] proxy-service-zsp9p Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr  8 15:30:16.215: INFO: setup took 5.080762726s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Apr  8 15:30:16.228: INFO: (0) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:162/proxy/: bar (200; 12.073959ms)
Apr  8 15:30:16.228: INFO: (0) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:1080/proxy/rewriteme">... (200; 12.148221ms)
Apr  8 15:30:16.228: INFO: (0) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc/proxy/rewriteme">test</a> (200; 12.215683ms)
Apr  8 15:30:16.228: INFO: (0) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:160/proxy/: foo (200; 12.314394ms)
Apr  8 15:30:16.229: INFO: (0) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:1080/proxy/rewriteme">test<... (200; 13.761472ms)
Apr  8 15:30:16.230: INFO: (0) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:160/proxy/: foo (200; 14.032179ms)
Apr  8 15:30:16.238: INFO: (0) /api/v1/namespaces/proxy-5978/services/proxy-service-zsp9p:portname2/proxy/: bar (200; 22.93057ms)
Apr  8 15:30:16.239: INFO: (0) /api/v1/namespaces/proxy-5978/services/http:proxy-service-zsp9p:portname2/proxy/: bar (200; 23.084612ms)
Apr  8 15:30:16.239: INFO: (0) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:162/proxy/: bar (200; 24.009147ms)
Apr  8 15:30:16.243: INFO: (0) /api/v1/namespaces/proxy-5978/services/http:proxy-service-zsp9p:portname1/proxy/: foo (200; 27.23483ms)
Apr  8 15:30:16.243: INFO: (0) /api/v1/namespaces/proxy-5978/services/proxy-service-zsp9p:portname1/proxy/: foo (200; 27.351765ms)
Apr  8 15:30:16.246: INFO: (0) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:462/proxy/: tls qux (200; 30.260108ms)
Apr  8 15:30:16.246: INFO: (0) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:443/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:443/proxy/tlsrewritem... (200; 30.792946ms)
Apr  8 15:30:16.246: INFO: (0) /api/v1/namespaces/proxy-5978/services/https:proxy-service-zsp9p:tlsportname2/proxy/: tls qux (200; 30.877101ms)
Apr  8 15:30:16.249: INFO: (0) /api/v1/namespaces/proxy-5978/services/https:proxy-service-zsp9p:tlsportname1/proxy/: tls baz (200; 33.265346ms)
Apr  8 15:30:16.250: INFO: (0) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:460/proxy/: tls baz (200; 34.629511ms)
Apr  8 15:30:16.257: INFO: (1) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:160/proxy/: foo (200; 6.555747ms)
Apr  8 15:30:16.257: INFO: (1) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:1080/proxy/rewriteme">... (200; 6.975703ms)
Apr  8 15:30:16.258: INFO: (1) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:460/proxy/: tls baz (200; 7.686082ms)
Apr  8 15:30:16.258: INFO: (1) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:160/proxy/: foo (200; 7.133201ms)
Apr  8 15:30:16.258: INFO: (1) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:162/proxy/: bar (200; 7.378966ms)
Apr  8 15:30:16.258: INFO: (1) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:443/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:443/proxy/tlsrewritem... (200; 7.205193ms)
Apr  8 15:30:16.259: INFO: (1) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:462/proxy/: tls qux (200; 7.679474ms)
Apr  8 15:30:16.259: INFO: (1) /api/v1/namespaces/proxy-5978/services/https:proxy-service-zsp9p:tlsportname1/proxy/: tls baz (200; 7.964269ms)
Apr  8 15:30:16.259: INFO: (1) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:162/proxy/: bar (200; 7.395767ms)
Apr  8 15:30:16.259: INFO: (1) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc/proxy/rewriteme">test</a> (200; 7.46839ms)
Apr  8 15:30:16.261: INFO: (1) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:1080/proxy/rewriteme">test<... (200; 10.411294ms)
Apr  8 15:30:16.261: INFO: (1) /api/v1/namespaces/proxy-5978/services/proxy-service-zsp9p:portname2/proxy/: bar (200; 10.535521ms)
Apr  8 15:30:16.261: INFO: (1) /api/v1/namespaces/proxy-5978/services/http:proxy-service-zsp9p:portname1/proxy/: foo (200; 10.151335ms)
Apr  8 15:30:16.261: INFO: (1) /api/v1/namespaces/proxy-5978/services/http:proxy-service-zsp9p:portname2/proxy/: bar (200; 10.096691ms)
Apr  8 15:30:16.261: INFO: (1) /api/v1/namespaces/proxy-5978/services/https:proxy-service-zsp9p:tlsportname2/proxy/: tls qux (200; 10.325721ms)
Apr  8 15:30:16.262: INFO: (1) /api/v1/namespaces/proxy-5978/services/proxy-service-zsp9p:portname1/proxy/: foo (200; 10.515429ms)
Apr  8 15:30:16.269: INFO: (2) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:162/proxy/: bar (200; 7.769238ms)
Apr  8 15:30:16.270: INFO: (2) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc/proxy/rewriteme">test</a> (200; 7.840486ms)
Apr  8 15:30:16.270: INFO: (2) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:1080/proxy/rewriteme">test<... (200; 7.820111ms)
Apr  8 15:30:16.270: INFO: (2) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:160/proxy/: foo (200; 8.487612ms)
Apr  8 15:30:16.270: INFO: (2) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:460/proxy/: tls baz (200; 8.428708ms)
Apr  8 15:30:16.270: INFO: (2) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:160/proxy/: foo (200; 8.510529ms)
Apr  8 15:30:16.270: INFO: (2) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:462/proxy/: tls qux (200; 8.52853ms)
Apr  8 15:30:16.270: INFO: (2) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:1080/proxy/rewriteme">... (200; 8.472349ms)
Apr  8 15:30:16.270: INFO: (2) /api/v1/namespaces/proxy-5978/services/proxy-service-zsp9p:portname2/proxy/: bar (200; 8.742499ms)
Apr  8 15:30:16.270: INFO: (2) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:443/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:443/proxy/tlsrewritem... (200; 8.718578ms)
Apr  8 15:30:16.271: INFO: (2) /api/v1/namespaces/proxy-5978/services/https:proxy-service-zsp9p:tlsportname2/proxy/: tls qux (200; 9.718769ms)
Apr  8 15:30:16.271: INFO: (2) /api/v1/namespaces/proxy-5978/services/https:proxy-service-zsp9p:tlsportname1/proxy/: tls baz (200; 9.93452ms)
Apr  8 15:30:16.276: INFO: (2) /api/v1/namespaces/proxy-5978/services/http:proxy-service-zsp9p:portname1/proxy/: foo (200; 14.168258ms)
Apr  8 15:30:16.277: INFO: (2) /api/v1/namespaces/proxy-5978/services/http:proxy-service-zsp9p:portname2/proxy/: bar (200; 14.933275ms)
Apr  8 15:30:16.278: INFO: (2) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:162/proxy/: bar (200; 16.886199ms)
Apr  8 15:30:16.281: INFO: (2) /api/v1/namespaces/proxy-5978/services/proxy-service-zsp9p:portname1/proxy/: foo (200; 19.19757ms)
Apr  8 15:30:16.312: INFO: (3) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:162/proxy/: bar (200; 31.082365ms)
Apr  8 15:30:16.312: INFO: (3) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:162/proxy/: bar (200; 31.334121ms)
Apr  8 15:30:16.315: INFO: (3) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:160/proxy/: foo (200; 33.910065ms)
Apr  8 15:30:16.315: INFO: (3) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:1080/proxy/rewriteme">... (200; 33.884019ms)
Apr  8 15:30:16.315: INFO: (3) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:462/proxy/: tls qux (200; 34.188474ms)
Apr  8 15:30:16.316: INFO: (3) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:160/proxy/: foo (200; 35.376871ms)
Apr  8 15:30:16.317: INFO: (3) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:1080/proxy/rewriteme">test<... (200; 35.467817ms)
Apr  8 15:30:16.320: INFO: (3) /api/v1/namespaces/proxy-5978/services/https:proxy-service-zsp9p:tlsportname1/proxy/: tls baz (200; 38.692404ms)
Apr  8 15:30:16.320: INFO: (3) /api/v1/namespaces/proxy-5978/services/http:proxy-service-zsp9p:portname2/proxy/: bar (200; 38.847095ms)
Apr  8 15:30:16.321: INFO: (3) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:460/proxy/: tls baz (200; 39.891932ms)
Apr  8 15:30:16.321: INFO: (3) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:443/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:443/proxy/tlsrewritem... (200; 39.832852ms)
Apr  8 15:30:16.321: INFO: (3) /api/v1/namespaces/proxy-5978/services/proxy-service-zsp9p:portname1/proxy/: foo (200; 39.914912ms)
Apr  8 15:30:16.321: INFO: (3) /api/v1/namespaces/proxy-5978/services/http:proxy-service-zsp9p:portname1/proxy/: foo (200; 40.405204ms)
Apr  8 15:30:16.326: INFO: (3) /api/v1/namespaces/proxy-5978/services/proxy-service-zsp9p:portname2/proxy/: bar (200; 45.218629ms)
Apr  8 15:30:16.326: INFO: (3) /api/v1/namespaces/proxy-5978/services/https:proxy-service-zsp9p:tlsportname2/proxy/: tls qux (200; 45.121313ms)
Apr  8 15:30:16.413: INFO: (3) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc/proxy/rewriteme">test</a> (200; 132.189279ms)
Apr  8 15:30:16.425: INFO: (4) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:160/proxy/: foo (200; 11.23076ms)
Apr  8 15:30:16.435: INFO: (4) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:160/proxy/: foo (200; 21.545579ms)
Apr  8 15:30:16.435: INFO: (4) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:162/proxy/: bar (200; 21.587177ms)
Apr  8 15:30:16.435: INFO: (4) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:1080/proxy/rewriteme">test<... (200; 21.597795ms)
Apr  8 15:30:16.435: INFO: (4) /api/v1/namespaces/proxy-5978/services/proxy-service-zsp9p:portname2/proxy/: bar (200; 21.67669ms)
Apr  8 15:30:16.436: INFO: (4) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:462/proxy/: tls qux (200; 22.013898ms)
Apr  8 15:30:16.436: INFO: (4) /api/v1/namespaces/proxy-5978/services/https:proxy-service-zsp9p:tlsportname2/proxy/: tls qux (200; 22.134812ms)
Apr  8 15:30:16.436: INFO: (4) /api/v1/namespaces/proxy-5978/services/proxy-service-zsp9p:portname1/proxy/: foo (200; 22.599763ms)
Apr  8 15:30:16.436: INFO: (4) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc/proxy/rewriteme">test</a> (200; 22.582425ms)
Apr  8 15:30:16.436: INFO: (4) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:1080/proxy/rewriteme">... (200; 22.643994ms)
Apr  8 15:30:16.436: INFO: (4) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:460/proxy/: tls baz (200; 22.745099ms)
Apr  8 15:30:16.436: INFO: (4) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:443/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:443/proxy/tlsrewritem... (200; 22.65308ms)
Apr  8 15:30:16.436: INFO: (4) /api/v1/namespaces/proxy-5978/services/https:proxy-service-zsp9p:tlsportname1/proxy/: tls baz (200; 22.71516ms)
Apr  8 15:30:16.505: INFO: (4) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:162/proxy/: bar (200; 90.999225ms)
Apr  8 15:30:16.505: INFO: (4) /api/v1/namespaces/proxy-5978/services/http:proxy-service-zsp9p:portname1/proxy/: foo (200; 90.969353ms)
Apr  8 15:30:16.505: INFO: (4) /api/v1/namespaces/proxy-5978/services/http:proxy-service-zsp9p:portname2/proxy/: bar (200; 91.00405ms)
Apr  8 15:30:16.519: INFO: (5) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:443/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:443/proxy/tlsrewritem... (200; 13.817135ms)
Apr  8 15:30:16.519: INFO: (5) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:1080/proxy/rewriteme">test<... (200; 13.397755ms)
Apr  8 15:30:16.519: INFO: (5) /api/v1/namespaces/proxy-5978/services/proxy-service-zsp9p:portname1/proxy/: foo (200; 13.770227ms)
Apr  8 15:30:16.519: INFO: (5) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc/proxy/rewriteme">test</a> (200; 13.485288ms)
Apr  8 15:30:16.519: INFO: (5) /api/v1/namespaces/proxy-5978/services/https:proxy-service-zsp9p:tlsportname2/proxy/: tls qux (200; 13.718459ms)
Apr  8 15:30:16.519: INFO: (5) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:462/proxy/: tls qux (200; 14.046905ms)
Apr  8 15:30:16.520: INFO: (5) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:160/proxy/: foo (200; 14.603438ms)
Apr  8 15:30:16.520: INFO: (5) /api/v1/namespaces/proxy-5978/services/https:proxy-service-zsp9p:tlsportname1/proxy/: tls baz (200; 15.016969ms)
Apr  8 15:30:16.520: INFO: (5) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:162/proxy/: bar (200; 15.233485ms)
Apr  8 15:30:16.520: INFO: (5) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:460/proxy/: tls baz (200; 14.889709ms)
Apr  8 15:30:16.520: INFO: (5) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:1080/proxy/rewriteme">... (200; 14.414697ms)
Apr  8 15:30:16.520: INFO: (5) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:162/proxy/: bar (200; 15.044033ms)
Apr  8 15:30:16.521: INFO: (5) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:160/proxy/: foo (200; 16.031324ms)
Apr  8 15:30:16.521: INFO: (5) /api/v1/namespaces/proxy-5978/services/http:proxy-service-zsp9p:portname1/proxy/: foo (200; 15.821394ms)
Apr  8 15:30:16.522: INFO: (5) /api/v1/namespaces/proxy-5978/services/proxy-service-zsp9p:portname2/proxy/: bar (200; 16.980672ms)
Apr  8 15:30:16.522: INFO: (5) /api/v1/namespaces/proxy-5978/services/http:proxy-service-zsp9p:portname2/proxy/: bar (200; 16.619667ms)
Apr  8 15:30:16.540: INFO: (6) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:162/proxy/: bar (200; 17.285933ms)
Apr  8 15:30:16.540: INFO: (6) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:160/proxy/: foo (200; 16.695692ms)
Apr  8 15:30:16.540: INFO: (6) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:160/proxy/: foo (200; 16.727067ms)
Apr  8 15:30:16.540: INFO: (6) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:1080/proxy/rewriteme">test<... (200; 17.063569ms)
Apr  8 15:30:16.540: INFO: (6) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:443/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:443/proxy/tlsrewritem... (200; 17.698512ms)
Apr  8 15:30:16.540: INFO: (6) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:162/proxy/: bar (200; 16.996802ms)
Apr  8 15:30:16.540: INFO: (6) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:462/proxy/: tls qux (200; 17.324745ms)
Apr  8 15:30:16.540: INFO: (6) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc/proxy/rewriteme">test</a> (200; 17.597572ms)
Apr  8 15:30:16.540: INFO: (6) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:1080/proxy/rewriteme">... (200; 17.161589ms)
Apr  8 15:30:16.604: INFO: (6) /api/v1/namespaces/proxy-5978/services/https:proxy-service-zsp9p:tlsportname2/proxy/: tls qux (200; 81.368589ms)
Apr  8 15:30:16.604: INFO: (6) /api/v1/namespaces/proxy-5978/services/http:proxy-service-zsp9p:portname2/proxy/: bar (200; 81.134742ms)
Apr  8 15:30:16.604: INFO: (6) /api/v1/namespaces/proxy-5978/services/http:proxy-service-zsp9p:portname1/proxy/: foo (200; 81.187422ms)
Apr  8 15:30:16.604: INFO: (6) /api/v1/namespaces/proxy-5978/services/proxy-service-zsp9p:portname1/proxy/: foo (200; 81.486919ms)
Apr  8 15:30:16.604: INFO: (6) /api/v1/namespaces/proxy-5978/services/proxy-service-zsp9p:portname2/proxy/: bar (200; 81.254006ms)
Apr  8 15:30:16.605: INFO: (6) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:460/proxy/: tls baz (200; 82.428464ms)
Apr  8 15:30:16.605: INFO: (6) /api/v1/namespaces/proxy-5978/services/https:proxy-service-zsp9p:tlsportname1/proxy/: tls baz (200; 81.915758ms)
Apr  8 15:30:16.627: INFO: (7) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:160/proxy/: foo (200; 21.988783ms)
Apr  8 15:30:16.627: INFO: (7) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:462/proxy/: tls qux (200; 22.121391ms)
Apr  8 15:30:16.627: INFO: (7) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc/proxy/rewriteme">test</a> (200; 22.126435ms)
Apr  8 15:30:16.627: INFO: (7) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:1080/proxy/rewriteme">... (200; 22.408301ms)
Apr  8 15:30:16.628: INFO: (7) /api/v1/namespaces/proxy-5978/services/https:proxy-service-zsp9p:tlsportname2/proxy/: tls qux (200; 22.461257ms)
Apr  8 15:30:16.628: INFO: (7) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:443/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:443/proxy/tlsrewritem... (200; 22.85394ms)
Apr  8 15:30:16.628: INFO: (7) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:1080/proxy/rewriteme">test<... (200; 23.222924ms)
Apr  8 15:30:16.628: INFO: (7) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:162/proxy/: bar (200; 23.328377ms)
Apr  8 15:30:16.628: INFO: (7) /api/v1/namespaces/proxy-5978/services/https:proxy-service-zsp9p:tlsportname1/proxy/: tls baz (200; 23.226787ms)
Apr  8 15:30:16.628: INFO: (7) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:460/proxy/: tls baz (200; 23.446945ms)
Apr  8 15:30:16.629: INFO: (7) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:160/proxy/: foo (200; 23.667082ms)
Apr  8 15:30:16.629: INFO: (7) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:162/proxy/: bar (200; 23.698058ms)
Apr  8 15:30:16.630: INFO: (7) /api/v1/namespaces/proxy-5978/services/http:proxy-service-zsp9p:portname1/proxy/: foo (200; 25.223887ms)
Apr  8 15:30:16.630: INFO: (7) /api/v1/namespaces/proxy-5978/services/proxy-service-zsp9p:portname1/proxy/: foo (200; 25.185334ms)
Apr  8 15:30:16.631: INFO: (7) /api/v1/namespaces/proxy-5978/services/http:proxy-service-zsp9p:portname2/proxy/: bar (200; 25.621635ms)
Apr  8 15:30:16.632: INFO: (7) /api/v1/namespaces/proxy-5978/services/proxy-service-zsp9p:portname2/proxy/: bar (200; 26.930215ms)
Apr  8 15:30:16.646: INFO: (8) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:1080/proxy/rewriteme">... (200; 13.884897ms)
Apr  8 15:30:16.646: INFO: (8) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:160/proxy/: foo (200; 13.804706ms)
Apr  8 15:30:16.646: INFO: (8) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc/proxy/rewriteme">test</a> (200; 13.361111ms)
Apr  8 15:30:16.646: INFO: (8) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:160/proxy/: foo (200; 13.651348ms)
Apr  8 15:30:16.646: INFO: (8) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:443/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:443/proxy/tlsrewritem... (200; 13.615129ms)
Apr  8 15:30:16.646: INFO: (8) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:462/proxy/: tls qux (200; 13.411125ms)
Apr  8 15:30:16.646: INFO: (8) /api/v1/namespaces/proxy-5978/services/https:proxy-service-zsp9p:tlsportname1/proxy/: tls baz (200; 13.97529ms)
Apr  8 15:30:16.646: INFO: (8) /api/v1/namespaces/proxy-5978/services/proxy-service-zsp9p:portname2/proxy/: bar (200; 14.052736ms)
Apr  8 15:30:16.647: INFO: (8) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:162/proxy/: bar (200; 14.187203ms)
Apr  8 15:30:16.647: INFO: (8) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:1080/proxy/rewriteme">test<... (200; 14.167432ms)
Apr  8 15:30:16.647: INFO: (8) /api/v1/namespaces/proxy-5978/services/proxy-service-zsp9p:portname1/proxy/: foo (200; 14.570052ms)
Apr  8 15:30:16.648: INFO: (8) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:460/proxy/: tls baz (200; 15.000074ms)
Apr  8 15:30:16.648: INFO: (8) /api/v1/namespaces/proxy-5978/services/https:proxy-service-zsp9p:tlsportname2/proxy/: tls qux (200; 15.238353ms)
Apr  8 15:30:16.648: INFO: (8) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:162/proxy/: bar (200; 15.135738ms)
Apr  8 15:30:16.648: INFO: (8) /api/v1/namespaces/proxy-5978/services/http:proxy-service-zsp9p:portname1/proxy/: foo (200; 15.392941ms)
Apr  8 15:30:16.649: INFO: (8) /api/v1/namespaces/proxy-5978/services/http:proxy-service-zsp9p:portname2/proxy/: bar (200; 16.580486ms)
Apr  8 15:30:16.660: INFO: (9) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:1080/proxy/rewriteme">... (200; 10.790905ms)
Apr  8 15:30:16.660: INFO: (9) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:162/proxy/: bar (200; 10.401728ms)
Apr  8 15:30:16.661: INFO: (9) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:460/proxy/: tls baz (200; 10.771577ms)
Apr  8 15:30:16.661: INFO: (9) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:162/proxy/: bar (200; 11.294ms)
Apr  8 15:30:16.661: INFO: (9) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:1080/proxy/rewriteme">test<... (200; 11.446105ms)
Apr  8 15:30:16.661: INFO: (9) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc/proxy/rewriteme">test</a> (200; 11.583738ms)
Apr  8 15:30:16.661: INFO: (9) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:160/proxy/: foo (200; 11.120082ms)
Apr  8 15:30:16.661: INFO: (9) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:462/proxy/: tls qux (200; 10.905279ms)
Apr  8 15:30:16.663: INFO: (9) /api/v1/namespaces/proxy-5978/services/proxy-service-zsp9p:portname1/proxy/: foo (200; 13.535244ms)
Apr  8 15:30:16.663: INFO: (9) /api/v1/namespaces/proxy-5978/services/http:proxy-service-zsp9p:portname2/proxy/: bar (200; 13.447258ms)
Apr  8 15:30:16.665: INFO: (9) /api/v1/namespaces/proxy-5978/services/https:proxy-service-zsp9p:tlsportname1/proxy/: tls baz (200; 15.114383ms)
Apr  8 15:30:16.665: INFO: (9) /api/v1/namespaces/proxy-5978/services/proxy-service-zsp9p:portname2/proxy/: bar (200; 15.234527ms)
Apr  8 15:30:16.665: INFO: (9) /api/v1/namespaces/proxy-5978/services/http:proxy-service-zsp9p:portname1/proxy/: foo (200; 14.94475ms)
Apr  8 15:30:16.665: INFO: (9) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:443/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:443/proxy/tlsrewritem... (200; 15.274532ms)
Apr  8 15:30:16.665: INFO: (9) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:160/proxy/: foo (200; 15.457646ms)
Apr  8 15:30:16.665: INFO: (9) /api/v1/namespaces/proxy-5978/services/https:proxy-service-zsp9p:tlsportname2/proxy/: tls qux (200; 14.898375ms)
Apr  8 15:30:16.706: INFO: (10) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:1080/proxy/rewriteme">... (200; 40.776666ms)
Apr  8 15:30:16.708: INFO: (10) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:460/proxy/: tls baz (200; 41.997476ms)
Apr  8 15:30:16.708: INFO: (10) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:462/proxy/: tls qux (200; 41.927237ms)
Apr  8 15:30:16.708: INFO: (10) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:160/proxy/: foo (200; 42.900965ms)
Apr  8 15:30:16.708: INFO: (10) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:160/proxy/: foo (200; 42.875134ms)
Apr  8 15:30:16.708: INFO: (10) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:162/proxy/: bar (200; 42.005076ms)
Apr  8 15:30:16.709: INFO: (10) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:1080/proxy/rewriteme">test<... (200; 41.955515ms)
Apr  8 15:30:16.709: INFO: (10) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:162/proxy/: bar (200; 42.789856ms)
Apr  8 15:30:16.709: INFO: (10) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:443/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:443/proxy/tlsrewritem... (200; 43.167059ms)
Apr  8 15:30:16.710: INFO: (10) /api/v1/namespaces/proxy-5978/services/https:proxy-service-zsp9p:tlsportname2/proxy/: tls qux (200; 44.152813ms)
Apr  8 15:30:16.712: INFO: (10) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc/proxy/rewriteme">test</a> (200; 45.900623ms)
Apr  8 15:30:16.712: INFO: (10) /api/v1/namespaces/proxy-5978/services/https:proxy-service-zsp9p:tlsportname1/proxy/: tls baz (200; 46.418226ms)
Apr  8 15:30:16.712: INFO: (10) /api/v1/namespaces/proxy-5978/services/http:proxy-service-zsp9p:portname1/proxy/: foo (200; 45.462599ms)
Apr  8 15:30:16.713: INFO: (10) /api/v1/namespaces/proxy-5978/services/proxy-service-zsp9p:portname1/proxy/: foo (200; 46.416606ms)
Apr  8 15:30:16.713: INFO: (10) /api/v1/namespaces/proxy-5978/services/http:proxy-service-zsp9p:portname2/proxy/: bar (200; 47.58415ms)
Apr  8 15:30:16.713: INFO: (10) /api/v1/namespaces/proxy-5978/services/proxy-service-zsp9p:portname2/proxy/: bar (200; 48.016989ms)
Apr  8 15:30:16.721: INFO: (11) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:160/proxy/: foo (200; 7.570923ms)
Apr  8 15:30:16.721: INFO: (11) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:160/proxy/: foo (200; 7.453582ms)
Apr  8 15:30:16.721: INFO: (11) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:1080/proxy/rewriteme">test<... (200; 7.780815ms)
Apr  8 15:30:16.721: INFO: (11) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:1080/proxy/rewriteme">... (200; 7.739627ms)
Apr  8 15:30:16.721: INFO: (11) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:443/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:443/proxy/tlsrewritem... (200; 7.442014ms)
Apr  8 15:30:16.722: INFO: (11) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:162/proxy/: bar (200; 8.460574ms)
Apr  8 15:30:16.722: INFO: (11) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc/proxy/rewriteme">test</a> (200; 7.849701ms)
Apr  8 15:30:16.722: INFO: (11) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:462/proxy/: tls qux (200; 7.667791ms)
Apr  8 15:30:16.723: INFO: (11) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:162/proxy/: bar (200; 8.884569ms)
Apr  8 15:30:16.723: INFO: (11) /api/v1/namespaces/proxy-5978/services/https:proxy-service-zsp9p:tlsportname2/proxy/: tls qux (200; 9.017978ms)
Apr  8 15:30:16.723: INFO: (11) /api/v1/namespaces/proxy-5978/services/https:proxy-service-zsp9p:tlsportname1/proxy/: tls baz (200; 9.584887ms)
Apr  8 15:30:16.723: INFO: (11) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:460/proxy/: tls baz (200; 9.183906ms)
Apr  8 15:30:16.723: INFO: (11) /api/v1/namespaces/proxy-5978/services/http:proxy-service-zsp9p:portname1/proxy/: foo (200; 10.130334ms)
Apr  8 15:30:16.723: INFO: (11) /api/v1/namespaces/proxy-5978/services/proxy-service-zsp9p:portname1/proxy/: foo (200; 9.083016ms)
Apr  8 15:30:16.724: INFO: (11) /api/v1/namespaces/proxy-5978/services/http:proxy-service-zsp9p:portname2/proxy/: bar (200; 9.634733ms)
Apr  8 15:30:16.725: INFO: (11) /api/v1/namespaces/proxy-5978/services/proxy-service-zsp9p:portname2/proxy/: bar (200; 11.171611ms)
Apr  8 15:30:16.732: INFO: (12) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:160/proxy/: foo (200; 6.552184ms)
Apr  8 15:30:16.732: INFO: (12) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:1080/proxy/rewriteme">... (200; 6.730151ms)
Apr  8 15:30:16.732: INFO: (12) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:160/proxy/: foo (200; 6.830051ms)
Apr  8 15:30:16.732: INFO: (12) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:162/proxy/: bar (200; 6.954163ms)
Apr  8 15:30:16.732: INFO: (12) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:443/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:443/proxy/tlsrewritem... (200; 7.203041ms)
Apr  8 15:30:16.733: INFO: (12) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:462/proxy/: tls qux (200; 7.193636ms)
Apr  8 15:30:16.733: INFO: (12) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:162/proxy/: bar (200; 7.330471ms)
Apr  8 15:30:16.733: INFO: (12) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:460/proxy/: tls baz (200; 7.85421ms)
Apr  8 15:30:16.733: INFO: (12) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc/proxy/rewriteme">test</a> (200; 8.117289ms)
Apr  8 15:30:16.735: INFO: (12) /api/v1/namespaces/proxy-5978/services/https:proxy-service-zsp9p:tlsportname1/proxy/: tls baz (200; 10.177338ms)
Apr  8 15:30:16.736: INFO: (12) /api/v1/namespaces/proxy-5978/services/http:proxy-service-zsp9p:portname1/proxy/: foo (200; 10.910163ms)
Apr  8 15:30:16.737: INFO: (12) /api/v1/namespaces/proxy-5978/services/http:proxy-service-zsp9p:portname2/proxy/: bar (200; 11.526059ms)
Apr  8 15:30:16.737: INFO: (12) /api/v1/namespaces/proxy-5978/services/proxy-service-zsp9p:portname1/proxy/: foo (200; 11.448229ms)
Apr  8 15:30:16.737: INFO: (12) /api/v1/namespaces/proxy-5978/services/https:proxy-service-zsp9p:tlsportname2/proxy/: tls qux (200; 11.540083ms)
Apr  8 15:30:16.737: INFO: (12) /api/v1/namespaces/proxy-5978/services/proxy-service-zsp9p:portname2/proxy/: bar (200; 11.571371ms)
Apr  8 15:30:16.763: INFO: (12) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:1080/proxy/rewriteme">test<... (200; 37.469405ms)
Apr  8 15:30:16.770: INFO: (13) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:462/proxy/: tls qux (200; 7.645153ms)
Apr  8 15:30:16.771: INFO: (13) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:160/proxy/: foo (200; 8.167476ms)
Apr  8 15:30:16.771: INFO: (13) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:160/proxy/: foo (200; 8.500859ms)
Apr  8 15:30:16.771: INFO: (13) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:162/proxy/: bar (200; 8.431548ms)
Apr  8 15:30:16.771: INFO: (13) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:1080/proxy/rewriteme">test<... (200; 8.527925ms)
Apr  8 15:30:16.771: INFO: (13) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc/proxy/rewriteme">test</a> (200; 8.492369ms)
Apr  8 15:30:16.772: INFO: (13) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:460/proxy/: tls baz (200; 9.129172ms)
Apr  8 15:30:16.772: INFO: (13) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:443/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:443/proxy/tlsrewritem... (200; 9.183905ms)
Apr  8 15:30:16.772: INFO: (13) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:162/proxy/: bar (200; 9.015563ms)
Apr  8 15:30:16.772: INFO: (13) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:1080/proxy/rewriteme">... (200; 9.059815ms)
Apr  8 15:30:16.773: INFO: (13) /api/v1/namespaces/proxy-5978/services/proxy-service-zsp9p:portname1/proxy/: foo (200; 10.028806ms)
Apr  8 15:30:16.773: INFO: (13) /api/v1/namespaces/proxy-5978/services/http:proxy-service-zsp9p:portname1/proxy/: foo (200; 10.223926ms)
Apr  8 15:30:16.773: INFO: (13) /api/v1/namespaces/proxy-5978/services/https:proxy-service-zsp9p:tlsportname2/proxy/: tls qux (200; 10.299216ms)
Apr  8 15:30:16.773: INFO: (13) /api/v1/namespaces/proxy-5978/services/http:proxy-service-zsp9p:portname2/proxy/: bar (200; 10.37262ms)
Apr  8 15:30:16.773: INFO: (13) /api/v1/namespaces/proxy-5978/services/https:proxy-service-zsp9p:tlsportname1/proxy/: tls baz (200; 10.270451ms)
Apr  8 15:30:16.773: INFO: (13) /api/v1/namespaces/proxy-5978/services/proxy-service-zsp9p:portname2/proxy/: bar (200; 10.352221ms)
Apr  8 15:30:16.782: INFO: (14) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:162/proxy/: bar (200; 8.53488ms)
Apr  8 15:30:16.782: INFO: (14) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:160/proxy/: foo (200; 8.753082ms)
Apr  8 15:30:16.782: INFO: (14) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:162/proxy/: bar (200; 8.856098ms)
Apr  8 15:30:16.782: INFO: (14) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:1080/proxy/rewriteme">test<... (200; 8.66832ms)
Apr  8 15:30:16.782: INFO: (14) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:1080/proxy/rewriteme">... (200; 8.647148ms)
Apr  8 15:30:16.782: INFO: (14) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:462/proxy/: tls qux (200; 8.863582ms)
Apr  8 15:30:16.782: INFO: (14) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc/proxy/rewriteme">test</a> (200; 8.917975ms)
Apr  8 15:30:16.783: INFO: (14) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:460/proxy/: tls baz (200; 9.114699ms)
Apr  8 15:30:16.783: INFO: (14) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:443/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:443/proxy/tlsrewritem... (200; 9.206069ms)
Apr  8 15:30:16.783: INFO: (14) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:160/proxy/: foo (200; 9.233165ms)
Apr  8 15:30:16.784: INFO: (14) /api/v1/namespaces/proxy-5978/services/http:proxy-service-zsp9p:portname1/proxy/: foo (200; 11.020543ms)
Apr  8 15:30:16.824: INFO: (14) /api/v1/namespaces/proxy-5978/services/https:proxy-service-zsp9p:tlsportname2/proxy/: tls qux (200; 50.617514ms)
Apr  8 15:30:16.824: INFO: (14) /api/v1/namespaces/proxy-5978/services/http:proxy-service-zsp9p:portname2/proxy/: bar (200; 50.482975ms)
Apr  8 15:30:16.824: INFO: (14) /api/v1/namespaces/proxy-5978/services/proxy-service-zsp9p:portname2/proxy/: bar (200; 50.605732ms)
Apr  8 15:30:16.824: INFO: (14) /api/v1/namespaces/proxy-5978/services/https:proxy-service-zsp9p:tlsportname1/proxy/: tls baz (200; 50.582361ms)
Apr  8 15:30:16.824: INFO: (14) /api/v1/namespaces/proxy-5978/services/proxy-service-zsp9p:portname1/proxy/: foo (200; 50.517424ms)
Apr  8 15:30:16.831: INFO: (15) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:162/proxy/: bar (200; 7.168478ms)
Apr  8 15:30:16.833: INFO: (15) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:1080/proxy/rewriteme">test<... (200; 8.286961ms)
Apr  8 15:30:16.833: INFO: (15) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:443/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:443/proxy/tlsrewritem... (200; 8.256507ms)
Apr  8 15:30:16.833: INFO: (15) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc/proxy/rewriteme">test</a> (200; 8.377739ms)
Apr  8 15:30:16.833: INFO: (15) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:462/proxy/: tls qux (200; 8.30927ms)
Apr  8 15:30:16.833: INFO: (15) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:160/proxy/: foo (200; 8.330116ms)
Apr  8 15:30:16.833: INFO: (15) /api/v1/namespaces/proxy-5978/services/https:proxy-service-zsp9p:tlsportname2/proxy/: tls qux (200; 8.340884ms)
Apr  8 15:30:16.833: INFO: (15) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:162/proxy/: bar (200; 8.512181ms)
Apr  8 15:30:16.833: INFO: (15) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:460/proxy/: tls baz (200; 8.944885ms)
Apr  8 15:30:16.833: INFO: (15) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:1080/proxy/rewriteme">... (200; 8.808733ms)
Apr  8 15:30:16.833: INFO: (15) /api/v1/namespaces/proxy-5978/services/http:proxy-service-zsp9p:portname1/proxy/: foo (200; 8.823685ms)
Apr  8 15:30:16.833: INFO: (15) /api/v1/namespaces/proxy-5978/services/http:proxy-service-zsp9p:portname2/proxy/: bar (200; 9.095178ms)
Apr  8 15:30:16.833: INFO: (15) /api/v1/namespaces/proxy-5978/services/https:proxy-service-zsp9p:tlsportname1/proxy/: tls baz (200; 8.999264ms)
Apr  8 15:30:16.834: INFO: (15) /api/v1/namespaces/proxy-5978/services/proxy-service-zsp9p:portname2/proxy/: bar (200; 9.416698ms)
Apr  8 15:30:16.834: INFO: (15) /api/v1/namespaces/proxy-5978/services/proxy-service-zsp9p:portname1/proxy/: foo (200; 9.8835ms)
Apr  8 15:30:16.834: INFO: (15) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:160/proxy/: foo (200; 9.918479ms)
Apr  8 15:30:16.844: INFO: (16) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:1080/proxy/rewriteme">... (200; 9.868308ms)
Apr  8 15:30:16.845: INFO: (16) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:160/proxy/: foo (200; 10.318144ms)
Apr  8 15:30:16.845: INFO: (16) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:162/proxy/: bar (200; 10.3063ms)
Apr  8 15:30:16.845: INFO: (16) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:160/proxy/: foo (200; 10.500367ms)
Apr  8 15:30:16.845: INFO: (16) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc/proxy/rewriteme">test</a> (200; 10.495746ms)
Apr  8 15:30:16.845: INFO: (16) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:443/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:443/proxy/tlsrewritem... (200; 10.391535ms)
Apr  8 15:30:16.845: INFO: (16) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:460/proxy/: tls baz (200; 10.553319ms)
Apr  8 15:30:16.845: INFO: (16) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:462/proxy/: tls qux (200; 10.501999ms)
Apr  8 15:30:16.845: INFO: (16) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:1080/proxy/rewriteme">test<... (200; 10.487519ms)
Apr  8 15:30:16.845: INFO: (16) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:162/proxy/: bar (200; 10.542153ms)
Apr  8 15:30:16.845: INFO: (16) /api/v1/namespaces/proxy-5978/services/https:proxy-service-zsp9p:tlsportname1/proxy/: tls baz (200; 10.795801ms)
Apr  8 15:30:16.846: INFO: (16) /api/v1/namespaces/proxy-5978/services/https:proxy-service-zsp9p:tlsportname2/proxy/: tls qux (200; 11.265329ms)
Apr  8 15:30:16.846: INFO: (16) /api/v1/namespaces/proxy-5978/services/proxy-service-zsp9p:portname1/proxy/: foo (200; 11.333647ms)
Apr  8 15:30:16.846: INFO: (16) /api/v1/namespaces/proxy-5978/services/http:proxy-service-zsp9p:portname2/proxy/: bar (200; 11.304015ms)
Apr  8 15:30:16.846: INFO: (16) /api/v1/namespaces/proxy-5978/services/http:proxy-service-zsp9p:portname1/proxy/: foo (200; 11.34094ms)
Apr  8 15:30:16.846: INFO: (16) /api/v1/namespaces/proxy-5978/services/proxy-service-zsp9p:portname2/proxy/: bar (200; 11.354821ms)
Apr  8 15:30:16.852: INFO: (17) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:162/proxy/: bar (200; 6.237609ms)
Apr  8 15:30:16.852: INFO: (17) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:162/proxy/: bar (200; 6.287578ms)
Apr  8 15:30:16.852: INFO: (17) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:1080/proxy/rewriteme">test<... (200; 6.462548ms)
Apr  8 15:30:16.853: INFO: (17) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:160/proxy/: foo (200; 7.408497ms)
Apr  8 15:30:16.853: INFO: (17) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:462/proxy/: tls qux (200; 7.514783ms)
Apr  8 15:30:16.853: INFO: (17) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:160/proxy/: foo (200; 7.381448ms)
Apr  8 15:30:16.854: INFO: (17) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc/proxy/rewriteme">test</a> (200; 7.743613ms)
Apr  8 15:30:16.854: INFO: (17) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:460/proxy/: tls baz (200; 7.811823ms)
Apr  8 15:30:16.854: INFO: (17) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:1080/proxy/rewriteme">... (200; 7.734974ms)
Apr  8 15:30:16.854: INFO: (17) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:443/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:443/proxy/tlsrewritem... (200; 7.889511ms)
Apr  8 15:30:16.855: INFO: (17) /api/v1/namespaces/proxy-5978/services/http:proxy-service-zsp9p:portname2/proxy/: bar (200; 8.901697ms)
Apr  8 15:30:16.855: INFO: (17) /api/v1/namespaces/proxy-5978/services/proxy-service-zsp9p:portname2/proxy/: bar (200; 8.875932ms)
Apr  8 15:30:16.855: INFO: (17) /api/v1/namespaces/proxy-5978/services/https:proxy-service-zsp9p:tlsportname2/proxy/: tls qux (200; 9.000751ms)
Apr  8 15:30:16.855: INFO: (17) /api/v1/namespaces/proxy-5978/services/https:proxy-service-zsp9p:tlsportname1/proxy/: tls baz (200; 8.896881ms)
Apr  8 15:30:16.855: INFO: (17) /api/v1/namespaces/proxy-5978/services/http:proxy-service-zsp9p:portname1/proxy/: foo (200; 9.421421ms)
Apr  8 15:30:16.855: INFO: (17) /api/v1/namespaces/proxy-5978/services/proxy-service-zsp9p:portname1/proxy/: foo (200; 9.368656ms)
Apr  8 15:30:16.862: INFO: (18) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:443/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:443/proxy/tlsrewritem... (200; 6.421368ms)
Apr  8 15:30:16.862: INFO: (18) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc/proxy/rewriteme">test</a> (200; 6.414938ms)
Apr  8 15:30:16.862: INFO: (18) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:160/proxy/: foo (200; 6.379798ms)
Apr  8 15:30:16.862: INFO: (18) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:1080/proxy/rewriteme">test<... (200; 6.546732ms)
Apr  8 15:30:16.862: INFO: (18) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:160/proxy/: foo (200; 6.402747ms)
Apr  8 15:30:16.863: INFO: (18) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:162/proxy/: bar (200; 6.785296ms)
Apr  8 15:30:16.863: INFO: (18) /api/v1/namespaces/proxy-5978/services/proxy-service-zsp9p:portname2/proxy/: bar (200; 7.39101ms)
Apr  8 15:30:16.864: INFO: (18) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:462/proxy/: tls qux (200; 8.144678ms)
Apr  8 15:30:16.864: INFO: (18) /api/v1/namespaces/proxy-5978/services/https:proxy-service-zsp9p:tlsportname2/proxy/: tls qux (200; 8.223383ms)
Apr  8 15:30:16.864: INFO: (18) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:1080/proxy/rewriteme">... (200; 8.384923ms)
Apr  8 15:30:16.865: INFO: (18) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:460/proxy/: tls baz (200; 8.805899ms)
Apr  8 15:30:16.865: INFO: (18) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:162/proxy/: bar (200; 8.829497ms)
Apr  8 15:30:16.865: INFO: (18) /api/v1/namespaces/proxy-5978/services/http:proxy-service-zsp9p:portname1/proxy/: foo (200; 9.06261ms)
Apr  8 15:30:16.865: INFO: (18) /api/v1/namespaces/proxy-5978/services/https:proxy-service-zsp9p:tlsportname1/proxy/: tls baz (200; 8.832034ms)
Apr  8 15:30:16.865: INFO: (18) /api/v1/namespaces/proxy-5978/services/proxy-service-zsp9p:portname1/proxy/: foo (200; 9.213081ms)
Apr  8 15:30:16.865: INFO: (18) /api/v1/namespaces/proxy-5978/services/http:proxy-service-zsp9p:portname2/proxy/: bar (200; 8.973707ms)
Apr  8 15:30:16.872: INFO: (19) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:1080/proxy/rewriteme">... (200; 6.867121ms)
Apr  8 15:30:16.872: INFO: (19) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:162/proxy/: bar (200; 6.213209ms)
Apr  8 15:30:16.872: INFO: (19) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc/proxy/rewriteme">test</a> (200; 6.299372ms)
Apr  8 15:30:16.872: INFO: (19) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:1080/proxy/rewriteme">test<... (200; 7.29556ms)
Apr  8 15:30:16.872: INFO: (19) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:460/proxy/: tls baz (200; 7.413736ms)
Apr  8 15:30:16.872: INFO: (19) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:162/proxy/: bar (200; 7.217147ms)
Apr  8 15:30:16.872: INFO: (19) /api/v1/namespaces/proxy-5978/pods/http:proxy-service-zsp9p-j5bjc:160/proxy/: foo (200; 7.119938ms)
Apr  8 15:30:16.874: INFO: (19) /api/v1/namespaces/proxy-5978/services/http:proxy-service-zsp9p:portname1/proxy/: foo (200; 8.45475ms)
Apr  8 15:30:16.874: INFO: (19) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:443/proxy/: <a href="/api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:443/proxy/tlsrewritem... (200; 8.645958ms)
Apr  8 15:30:16.874: INFO: (19) /api/v1/namespaces/proxy-5978/pods/https:proxy-service-zsp9p-j5bjc:462/proxy/: tls qux (200; 8.601947ms)
Apr  8 15:30:16.874: INFO: (19) /api/v1/namespaces/proxy-5978/services/https:proxy-service-zsp9p:tlsportname2/proxy/: tls qux (200; 8.359412ms)
Apr  8 15:30:16.874: INFO: (19) /api/v1/namespaces/proxy-5978/services/proxy-service-zsp9p:portname2/proxy/: bar (200; 8.947037ms)
Apr  8 15:30:16.874: INFO: (19) /api/v1/namespaces/proxy-5978/services/https:proxy-service-zsp9p:tlsportname1/proxy/: tls baz (200; 8.900494ms)
Apr  8 15:30:16.874: INFO: (19) /api/v1/namespaces/proxy-5978/services/http:proxy-service-zsp9p:portname2/proxy/: bar (200; 8.483435ms)
Apr  8 15:30:16.874: INFO: (19) /api/v1/namespaces/proxy-5978/pods/proxy-service-zsp9p-j5bjc:160/proxy/: foo (200; 8.801178ms)
Apr  8 15:30:16.876: INFO: (19) /api/v1/namespaces/proxy-5978/services/proxy-service-zsp9p:portname1/proxy/: foo (200; 10.063352ms)
STEP: deleting ReplicationController proxy-service-zsp9p in namespace proxy-5978, will wait for the garbage collector to delete the pods
Apr  8 15:30:16.937: INFO: Deleting ReplicationController proxy-service-zsp9p took: 7.302666ms
Apr  8 15:30:17.337: INFO: Terminating ReplicationController proxy-service-zsp9p pods took: 400.264644ms
[AfterEach] version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:30:18.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-5978" for this suite.
Apr  8 15:30:24.863: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:30:25.000: INFO: namespace proxy-5978 deletion completed in 6.157573494s
â€¢SSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:30:25.001: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-8273
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test hostPath mode
Apr  8 15:30:25.162: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-8273" to be "success or failure"
Apr  8 15:30:25.166: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 3.605873ms
Apr  8 15:30:27.172: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01040415s
STEP: Saw pod success
Apr  8 15:30:27.172: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Apr  8 15:30:27.176: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Apr  8 15:30:27.197: INFO: Waiting for pod pod-host-path-test to disappear
Apr  8 15:30:27.201: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:30:27.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-8273" for this suite.
Apr  8 15:30:33.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:30:33.366: INFO: namespace hostpath-8273 deletion completed in 6.161409417s
â€¢SSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:30:33.366: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-6726
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test env composition
Apr  8 15:30:33.521: INFO: Waiting up to 5m0s for pod "var-expansion-3ff0e7bc-5a13-11e9-b9a9-e6698ebc8bdf" in namespace "var-expansion-6726" to be "success or failure"
Apr  8 15:30:33.524: INFO: Pod "var-expansion-3ff0e7bc-5a13-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.969129ms
Apr  8 15:30:35.530: INFO: Pod "var-expansion-3ff0e7bc-5a13-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008110794s
STEP: Saw pod success
Apr  8 15:30:35.530: INFO: Pod "var-expansion-3ff0e7bc-5a13-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:30:35.533: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod var-expansion-3ff0e7bc-5a13-11e9-b9a9-e6698ebc8bdf container dapi-container: <nil>
STEP: delete the pod
Apr  8 15:30:35.556: INFO: Waiting for pod var-expansion-3ff0e7bc-5a13-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:30:35.559: INFO: Pod var-expansion-3ff0e7bc-5a13-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:30:35.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6726" for this suite.
Apr  8 15:30:41.577: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:30:41.719: INFO: namespace var-expansion-6726 deletion completed in 6.154724214s
â€¢SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:30:41.719: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8104
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  8 15:30:41.875: INFO: Waiting up to 5m0s for pod "downwardapi-volume-44eba2c1-5a13-11e9-b9a9-e6698ebc8bdf" in namespace "downward-api-8104" to be "success or failure"
Apr  8 15:30:41.879: INFO: Pod "downwardapi-volume-44eba2c1-5a13-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 3.691ms
Apr  8 15:30:43.885: INFO: Pod "downwardapi-volume-44eba2c1-5a13-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010165479s
STEP: Saw pod success
Apr  8 15:30:43.885: INFO: Pod "downwardapi-volume-44eba2c1-5a13-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:30:43.890: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod downwardapi-volume-44eba2c1-5a13-11e9-b9a9-e6698ebc8bdf container client-container: <nil>
STEP: delete the pod
Apr  8 15:30:43.941: INFO: Waiting for pod downwardapi-volume-44eba2c1-5a13-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:30:43.945: INFO: Pod downwardapi-volume-44eba2c1-5a13-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:30:43.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8104" for this suite.
Apr  8 15:30:49.966: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:30:50.156: INFO: namespace downward-api-8104 deletion completed in 6.205725847s
â€¢SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:30:50.157: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9611
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-49fc53ba-5a13-11e9-b9a9-e6698ebc8bdf
STEP: Creating a pod to test consume configMaps
Apr  8 15:30:50.379: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-49fcf71d-5a13-11e9-b9a9-e6698ebc8bdf" in namespace "projected-9611" to be "success or failure"
Apr  8 15:30:50.385: INFO: Pod "pod-projected-configmaps-49fcf71d-5a13-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 6.084045ms
Apr  8 15:30:52.390: INFO: Pod "pod-projected-configmaps-49fcf71d-5a13-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010812536s
STEP: Saw pod success
Apr  8 15:30:52.390: INFO: Pod "pod-projected-configmaps-49fcf71d-5a13-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:30:52.394: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-projected-configmaps-49fcf71d-5a13-11e9-b9a9-e6698ebc8bdf container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr  8 15:30:52.414: INFO: Waiting for pod pod-projected-configmaps-49fcf71d-5a13-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:30:52.417: INFO: Pod pod-projected-configmaps-49fcf71d-5a13-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:30:52.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9611" for this suite.
Apr  8 15:30:58.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:30:58.572: INFO: namespace projected-9611 deletion completed in 6.148927494s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:30:58.572: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-3330
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service endpoint-test2 in namespace services-3330
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3330 to expose endpoints map[]
Apr  8 15:30:58.743: INFO: successfully validated that service endpoint-test2 in namespace services-3330 exposes endpoints map[] (4.26638ms elapsed)
STEP: Creating pod pod1 in namespace services-3330
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3330 to expose endpoints map[pod1:[80]]
Apr  8 15:31:00.819: INFO: successfully validated that service endpoint-test2 in namespace services-3330 exposes endpoints map[pod1:[80]] (2.06984111s elapsed)
STEP: Creating pod pod2 in namespace services-3330
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3330 to expose endpoints map[pod1:[80] pod2:[80]]
Apr  8 15:31:03.870: INFO: successfully validated that service endpoint-test2 in namespace services-3330 exposes endpoints map[pod1:[80] pod2:[80]] (3.046256619s elapsed)
STEP: Deleting pod pod1 in namespace services-3330
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3330 to expose endpoints map[pod2:[80]]
Apr  8 15:31:03.884: INFO: successfully validated that service endpoint-test2 in namespace services-3330 exposes endpoints map[pod2:[80]] (7.857536ms elapsed)
STEP: Deleting pod pod2 in namespace services-3330
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3330 to expose endpoints map[]
Apr  8 15:31:03.892: INFO: successfully validated that service endpoint-test2 in namespace services-3330 exposes endpoints map[] (3.587392ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:31:03.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3330" for this suite.
Apr  8 15:31:25.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:31:26.055: INFO: namespace services-3330 deletion completed in 22.139390343s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
â€¢SSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:31:26.055: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-1600
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Apr  8 15:31:26.203: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr  8 15:31:26.212: INFO: Waiting for terminating namespaces to be deleted...
Apr  8 15:31:26.215: INFO: 
Logging pods the kubelet thinks is on node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw before test
Apr  8 15:31:26.229: INFO: metrics-server-bbc67f984-2cbzt from kube-system started at 2019-04-08 13:54:16 +0000 UTC (1 container statuses recorded)
Apr  8 15:31:26.229: INFO: 	Container metrics-server ready: true, restart count 0
Apr  8 15:31:26.229: INFO: coredns-7f7f7978c8-2cw6g from kube-system started at 2019-04-08 13:54:16 +0000 UTC (1 container statuses recorded)
Apr  8 15:31:26.229: INFO: 	Container coredns ready: true, restart count 0
Apr  8 15:31:26.229: INFO: blackbox-exporter-6dc58dcffc-kddgs from kube-system started at 2019-04-08 13:53:56 +0000 UTC (1 container statuses recorded)
Apr  8 15:31:26.229: INFO: 	Container blackbox-exporter ready: true, restart count 0
Apr  8 15:31:26.229: INFO: calico-node-rhz9g from kube-system started at 2019-04-08 13:53:56 +0000 UTC (1 container statuses recorded)
Apr  8 15:31:26.229: INFO: 	Container calico-node ready: true, restart count 0
Apr  8 15:31:26.229: INFO: node-exporter-52tc5 from kube-system started at 2019-04-08 13:53:56 +0000 UTC (1 container statuses recorded)
Apr  8 15:31:26.229: INFO: 	Container node-exporter ready: true, restart count 0
Apr  8 15:31:26.229: INFO: addons-nginx-ingress-controller-d4f8c9cc5-dz84h from kube-system started at 2019-04-08 13:54:14 +0000 UTC (1 container statuses recorded)
Apr  8 15:31:26.229: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Apr  8 15:31:26.229: INFO: vpn-shoot-846bd99d6c-frws7 from kube-system started at 2019-04-08 13:54:14 +0000 UTC (1 container statuses recorded)
Apr  8 15:31:26.229: INFO: 	Container vpn-shoot ready: true, restart count 0
Apr  8 15:31:26.229: INFO: coredns-7f7f7978c8-jpqwt from kube-system started at 2019-04-08 13:54:14 +0000 UTC (1 container statuses recorded)
Apr  8 15:31:26.229: INFO: 	Container coredns ready: true, restart count 0
Apr  8 15:31:26.229: INFO: kube-proxy-zwjh7 from kube-system started at 2019-04-08 13:53:56 +0000 UTC (1 container statuses recorded)
Apr  8 15:31:26.229: INFO: 	Container kube-proxy ready: true, restart count 0
Apr  8 15:31:26.229: INFO: addons-kubernetes-dashboard-665df4b66d-w6dfr from kube-system started at 2019-04-08 13:54:14 +0000 UTC (1 container statuses recorded)
Apr  8 15:31:26.229: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Apr  8 15:31:26.229: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-754f8f5dcb-scvf9 from kube-system started at 2019-04-08 13:54:14 +0000 UTC (1 container statuses recorded)
Apr  8 15:31:26.229: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Apr  8 15:31:26.229: INFO: 
Logging pods the kubelet thinks is on node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw before test
Apr  8 15:31:26.238: INFO: kube-proxy-txjx7 from kube-system started at 2019-04-08 13:53:55 +0000 UTC (1 container statuses recorded)
Apr  8 15:31:26.238: INFO: 	Container kube-proxy ready: true, restart count 0
Apr  8 15:31:26.238: INFO: calico-node-nk88t from kube-system started at 2019-04-08 13:53:55 +0000 UTC (1 container statuses recorded)
Apr  8 15:31:26.238: INFO: 	Container calico-node ready: true, restart count 0
Apr  8 15:31:26.238: INFO: node-exporter-j4f9g from kube-system started at 2019-04-08 13:53:55 +0000 UTC (1 container statuses recorded)
Apr  8 15:31:26.238: INFO: 	Container node-exporter ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: verifying the node has the label node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw
STEP: verifying the node has the label node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw
Apr  8 15:31:26.273: INFO: Pod addons-kubernetes-dashboard-665df4b66d-w6dfr requesting resource cpu=50m on Node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw
Apr  8 15:31:26.273: INFO: Pod addons-nginx-ingress-controller-d4f8c9cc5-dz84h requesting resource cpu=100m on Node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw
Apr  8 15:31:26.273: INFO: Pod addons-nginx-ingress-nginx-ingress-k8s-backend-754f8f5dcb-scvf9 requesting resource cpu=0m on Node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw
Apr  8 15:31:26.273: INFO: Pod blackbox-exporter-6dc58dcffc-kddgs requesting resource cpu=5m on Node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw
Apr  8 15:31:26.273: INFO: Pod calico-node-nk88t requesting resource cpu=100m on Node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw
Apr  8 15:31:26.273: INFO: Pod calico-node-rhz9g requesting resource cpu=100m on Node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw
Apr  8 15:31:26.273: INFO: Pod coredns-7f7f7978c8-2cw6g requesting resource cpu=50m on Node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw
Apr  8 15:31:26.273: INFO: Pod coredns-7f7f7978c8-jpqwt requesting resource cpu=50m on Node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw
Apr  8 15:31:26.273: INFO: Pod kube-proxy-txjx7 requesting resource cpu=20m on Node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw
Apr  8 15:31:26.273: INFO: Pod kube-proxy-zwjh7 requesting resource cpu=20m on Node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw
Apr  8 15:31:26.273: INFO: Pod metrics-server-bbc67f984-2cbzt requesting resource cpu=20m on Node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw
Apr  8 15:31:26.273: INFO: Pod node-exporter-52tc5 requesting resource cpu=5m on Node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw
Apr  8 15:31:26.273: INFO: Pod node-exporter-j4f9g requesting resource cpu=5m on Node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw
Apr  8 15:31:26.273: INFO: Pod vpn-shoot-846bd99d6c-frws7 requesting resource cpu=50m on Node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5f636408-5a13-11e9-b9a9-e6698ebc8bdf.15938981a500afff], Reason = [Scheduled], Message = [Successfully assigned sched-pred-1600/filler-pod-5f636408-5a13-11e9-b9a9-e6698ebc8bdf to shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5f636408-5a13-11e9-b9a9-e6698ebc8bdf.15938981d29249bf], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5f636408-5a13-11e9-b9a9-e6698ebc8bdf.15938981dabe11bc], Reason = [Created], Message = [Created container filler-pod-5f636408-5a13-11e9-b9a9-e6698ebc8bdf]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5f636408-5a13-11e9-b9a9-e6698ebc8bdf.15938981e0927ff2], Reason = [Started], Message = [Started container filler-pod-5f636408-5a13-11e9-b9a9-e6698ebc8bdf]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5f647bb7-5a13-11e9-b9a9-e6698ebc8bdf.15938981a54eb55d], Reason = [Scheduled], Message = [Successfully assigned sched-pred-1600/filler-pod-5f647bb7-5a13-11e9-b9a9-e6698ebc8bdf to shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5f647bb7-5a13-11e9-b9a9-e6698ebc8bdf.15938981ca20e4f5], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5f647bb7-5a13-11e9-b9a9-e6698ebc8bdf.15938981ceeae4a6], Reason = [Created], Message = [Created container filler-pod-5f647bb7-5a13-11e9-b9a9-e6698ebc8bdf]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5f647bb7-5a13-11e9-b9a9-e6698ebc8bdf.15938981d55dae79], Reason = [Started], Message = [Started container filler-pod-5f647bb7-5a13-11e9-b9a9-e6698ebc8bdf]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.159389821ddb8757], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu.]
STEP: removing the label node off the node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:31:29.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1600" for this suite.
Apr  8 15:31:35.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:31:35.495: INFO: namespace sched-pred-1600 deletion completed in 6.140208513s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70
â€¢
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:31:35.495: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-2258
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:31:57.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2258" for this suite.
Apr  8 15:32:03.025: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:32:03.233: INFO: namespace container-runtime-2258 deletion completed in 6.220855688s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:32:03.233: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-360
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  8 15:32:03.389: INFO: Waiting up to 5m0s for pod "downwardapi-volume-758143e5-5a13-11e9-b9a9-e6698ebc8bdf" in namespace "projected-360" to be "success or failure"
Apr  8 15:32:03.393: INFO: Pod "downwardapi-volume-758143e5-5a13-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.076389ms
Apr  8 15:32:05.398: INFO: Pod "downwardapi-volume-758143e5-5a13-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009718818s
STEP: Saw pod success
Apr  8 15:32:05.398: INFO: Pod "downwardapi-volume-758143e5-5a13-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:32:05.402: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod downwardapi-volume-758143e5-5a13-11e9-b9a9-e6698ebc8bdf container client-container: <nil>
STEP: delete the pod
Apr  8 15:32:05.425: INFO: Waiting for pod downwardapi-volume-758143e5-5a13-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:32:05.428: INFO: Pod downwardapi-volume-758143e5-5a13-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:32:05.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-360" for this suite.
Apr  8 15:32:11.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:32:11.623: INFO: namespace projected-360 deletion completed in 6.191446949s
â€¢SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:32:11.623: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1771
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1190
STEP: creating an rc
Apr  8 15:32:11.775: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config create -f - --namespace=kubectl-1771'
Apr  8 15:32:12.853: INFO: stderr: ""
Apr  8 15:32:12.853: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Waiting for Redis master to start.
Apr  8 15:32:13.861: INFO: Selector matched 1 pods for map[app:redis]
Apr  8 15:32:13.861: INFO: Found 0 / 1
Apr  8 15:32:14.859: INFO: Selector matched 1 pods for map[app:redis]
Apr  8 15:32:14.859: INFO: Found 1 / 1
Apr  8 15:32:14.859: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr  8 15:32:14.863: INFO: Selector matched 1 pods for map[app:redis]
Apr  8 15:32:14.863: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Apr  8 15:32:14.863: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config logs redis-master-5hd2s redis-master --namespace=kubectl-1771'
Apr  8 15:32:15.046: INFO: stderr: ""
Apr  8 15:32:15.046: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 08 Apr 15:32:13.639 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 08 Apr 15:32:13.639 # Server started, Redis version 3.2.12\n1:M 08 Apr 15:32:13.639 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 08 Apr 15:32:13.639 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Apr  8 15:32:15.046: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config log redis-master-5hd2s redis-master --namespace=kubectl-1771 --tail=1'
Apr  8 15:32:15.202: INFO: stderr: ""
Apr  8 15:32:15.202: INFO: stdout: "1:M 08 Apr 15:32:13.639 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Apr  8 15:32:15.202: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config log redis-master-5hd2s redis-master --namespace=kubectl-1771 --limit-bytes=1'
Apr  8 15:32:15.405: INFO: stderr: ""
Apr  8 15:32:15.405: INFO: stdout: " "
STEP: exposing timestamps
Apr  8 15:32:15.405: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config log redis-master-5hd2s redis-master --namespace=kubectl-1771 --tail=1 --timestamps'
Apr  8 15:32:15.589: INFO: stderr: ""
Apr  8 15:32:15.589: INFO: stdout: "2019-04-08T15:32:13.639786146Z 1:M 08 Apr 15:32:13.639 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Apr  8 15:32:18.090: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config log redis-master-5hd2s redis-master --namespace=kubectl-1771 --since=1s'
Apr  8 15:32:18.228: INFO: stderr: ""
Apr  8 15:32:18.228: INFO: stdout: ""
Apr  8 15:32:18.228: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config log redis-master-5hd2s redis-master --namespace=kubectl-1771 --since=24h'
Apr  8 15:32:18.351: INFO: stderr: ""
Apr  8 15:32:18.351: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 08 Apr 15:32:13.639 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 08 Apr 15:32:13.639 # Server started, Redis version 3.2.12\n1:M 08 Apr 15:32:13.639 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 08 Apr 15:32:13.639 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1196
STEP: using delete to clean up resources
Apr  8 15:32:18.351: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-1771'
Apr  8 15:32:18.469: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  8 15:32:18.469: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Apr  8 15:32:18.469: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get rc,svc -l name=nginx --no-headers --namespace=kubectl-1771'
Apr  8 15:32:18.588: INFO: stderr: "No resources found.\n"
Apr  8 15:32:18.588: INFO: stdout: ""
Apr  8 15:32:18.588: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods -l name=nginx --namespace=kubectl-1771 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr  8 15:32:18.707: INFO: stderr: ""
Apr  8 15:32:18.707: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:32:18.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1771" for this suite.
Apr  8 15:32:40.747: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:32:40.867: INFO: namespace kubectl-1771 deletion completed in 22.133280796s
â€¢SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:32:40.868: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-5013
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  8 15:33:07.036: INFO: Container started at 2019-04-08 15:32:41 +0000 UTC, pod became ready at 2019-04-08 15:33:04 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:33:07.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5013" for this suite.
Apr  8 15:33:29.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:33:29.219: INFO: namespace container-probe-5013 deletion completed in 22.177872412s
â€¢
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:33:29.220: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8122
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Apr  8 15:33:29.377: INFO: Waiting up to 5m0s for pod "pod-a8c25097-5a13-11e9-b9a9-e6698ebc8bdf" in namespace "emptydir-8122" to be "success or failure"
Apr  8 15:33:29.381: INFO: Pod "pod-a8c25097-5a13-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 3.618716ms
Apr  8 15:33:31.386: INFO: Pod "pod-a8c25097-5a13-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008993336s
Apr  8 15:33:33.391: INFO: Pod "pod-a8c25097-5a13-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014506539s
STEP: Saw pod success
Apr  8 15:33:33.392: INFO: Pod "pod-a8c25097-5a13-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:33:33.395: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-a8c25097-5a13-11e9-b9a9-e6698ebc8bdf container test-container: <nil>
STEP: delete the pod
Apr  8 15:33:33.417: INFO: Waiting for pod pod-a8c25097-5a13-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:33:33.420: INFO: Pod pod-a8c25097-5a13-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:33:33.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8122" for this suite.
Apr  8 15:33:39.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:33:39.563: INFO: namespace emptydir-8122 deletion completed in 6.138804295s
â€¢SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:33:39.564: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-9838
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test use defaults
Apr  8 15:33:39.727: INFO: Waiting up to 5m0s for pod "client-containers-aeedc9fd-5a13-11e9-b9a9-e6698ebc8bdf" in namespace "containers-9838" to be "success or failure"
Apr  8 15:33:39.732: INFO: Pod "client-containers-aeedc9fd-5a13-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.588782ms
Apr  8 15:33:41.737: INFO: Pod "client-containers-aeedc9fd-5a13-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009445048s
STEP: Saw pod success
Apr  8 15:33:41.737: INFO: Pod "client-containers-aeedc9fd-5a13-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:33:41.741: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod client-containers-aeedc9fd-5a13-11e9-b9a9-e6698ebc8bdf container test-container: <nil>
STEP: delete the pod
Apr  8 15:33:41.761: INFO: Waiting for pod client-containers-aeedc9fd-5a13-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:33:41.765: INFO: Pod client-containers-aeedc9fd-5a13-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:33:41.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9838" for this suite.
Apr  8 15:33:47.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:33:48.073: INFO: namespace containers-9838 deletion completed in 6.302867272s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:33:48.074: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6188
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Apr  8 15:33:48.228: INFO: Waiting up to 5m0s for pod "pod-b3fee941-5a13-11e9-b9a9-e6698ebc8bdf" in namespace "emptydir-6188" to be "success or failure"
Apr  8 15:33:48.232: INFO: Pod "pod-b3fee941-5a13-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.156843ms
Apr  8 15:33:50.237: INFO: Pod "pod-b3fee941-5a13-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009510286s
STEP: Saw pod success
Apr  8 15:33:50.238: INFO: Pod "pod-b3fee941-5a13-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:33:50.242: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-b3fee941-5a13-11e9-b9a9-e6698ebc8bdf container test-container: <nil>
STEP: delete the pod
Apr  8 15:33:50.268: INFO: Waiting for pod pod-b3fee941-5a13-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:33:50.273: INFO: Pod pod-b3fee941-5a13-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:33:50.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6188" for this suite.
Apr  8 15:33:56.290: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:33:56.417: INFO: namespace emptydir-6188 deletion completed in 6.139548533s
â€¢SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:33:56.418: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9974
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-b8f856e5-5a13-11e9-b9a9-e6698ebc8bdf
STEP: Creating a pod to test consume configMaps
Apr  8 15:33:56.579: INFO: Waiting up to 5m0s for pod "pod-configmaps-b8f917b8-5a13-11e9-b9a9-e6698ebc8bdf" in namespace "configmap-9974" to be "success or failure"
Apr  8 15:33:56.583: INFO: Pod "pod-configmaps-b8f917b8-5a13-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 3.18245ms
Apr  8 15:33:58.592: INFO: Pod "pod-configmaps-b8f917b8-5a13-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012997857s
STEP: Saw pod success
Apr  8 15:33:58.592: INFO: Pod "pod-configmaps-b8f917b8-5a13-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:33:58.602: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-configmaps-b8f917b8-5a13-11e9-b9a9-e6698ebc8bdf container configmap-volume-test: <nil>
STEP: delete the pod
Apr  8 15:33:58.631: INFO: Waiting for pod pod-configmaps-b8f917b8-5a13-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:33:58.635: INFO: Pod pod-configmaps-b8f917b8-5a13-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:33:58.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9974" for this suite.
Apr  8 15:34:04.654: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:34:04.782: INFO: namespace configmap-9974 deletion completed in 6.141738753s
â€¢SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:34:04.782: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2330
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-bdf91c6d-5a13-11e9-b9a9-e6698ebc8bdf
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:34:09.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2330" for this suite.
Apr  8 15:34:31.106: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:34:31.279: INFO: namespace configmap-2330 deletion completed in 22.187736191s
â€¢SSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:34:31.280: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-3714
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-jc5f
STEP: Creating a pod to test atomic-volume-subpath
Apr  8 15:34:31.441: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-jc5f" in namespace "subpath-3714" to be "success or failure"
Apr  8 15:34:31.453: INFO: Pod "pod-subpath-test-configmap-jc5f": Phase="Pending", Reason="", readiness=false. Elapsed: 11.375052ms
Apr  8 15:34:33.457: INFO: Pod "pod-subpath-test-configmap-jc5f": Phase="Running", Reason="", readiness=true. Elapsed: 2.016224781s
Apr  8 15:34:35.462: INFO: Pod "pod-subpath-test-configmap-jc5f": Phase="Running", Reason="", readiness=true. Elapsed: 4.02080275s
Apr  8 15:34:37.467: INFO: Pod "pod-subpath-test-configmap-jc5f": Phase="Running", Reason="", readiness=true. Elapsed: 6.025940767s
Apr  8 15:34:39.472: INFO: Pod "pod-subpath-test-configmap-jc5f": Phase="Running", Reason="", readiness=true. Elapsed: 8.031116447s
Apr  8 15:34:41.477: INFO: Pod "pod-subpath-test-configmap-jc5f": Phase="Running", Reason="", readiness=true. Elapsed: 10.036116956s
Apr  8 15:34:43.482: INFO: Pod "pod-subpath-test-configmap-jc5f": Phase="Running", Reason="", readiness=true. Elapsed: 12.041159547s
Apr  8 15:34:45.487: INFO: Pod "pod-subpath-test-configmap-jc5f": Phase="Running", Reason="", readiness=true. Elapsed: 14.045514841s
Apr  8 15:34:47.492: INFO: Pod "pod-subpath-test-configmap-jc5f": Phase="Running", Reason="", readiness=true. Elapsed: 16.051066273s
Apr  8 15:34:49.497: INFO: Pod "pod-subpath-test-configmap-jc5f": Phase="Running", Reason="", readiness=true. Elapsed: 18.05620762s
Apr  8 15:34:51.502: INFO: Pod "pod-subpath-test-configmap-jc5f": Phase="Running", Reason="", readiness=true. Elapsed: 20.061202492s
Apr  8 15:34:53.508: INFO: Pod "pod-subpath-test-configmap-jc5f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.066398822s
STEP: Saw pod success
Apr  8 15:34:53.508: INFO: Pod "pod-subpath-test-configmap-jc5f" satisfied condition "success or failure"
Apr  8 15:34:53.512: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-subpath-test-configmap-jc5f container test-container-subpath-configmap-jc5f: <nil>
STEP: delete the pod
Apr  8 15:34:53.542: INFO: Waiting for pod pod-subpath-test-configmap-jc5f to disappear
Apr  8 15:34:53.545: INFO: Pod pod-subpath-test-configmap-jc5f no longer exists
STEP: Deleting pod pod-subpath-test-configmap-jc5f
Apr  8 15:34:53.545: INFO: Deleting pod "pod-subpath-test-configmap-jc5f" in namespace "subpath-3714"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:34:53.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3714" for this suite.
Apr  8 15:34:59.576: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:34:59.709: INFO: namespace subpath-3714 deletion completed in 6.154996282s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:34:59.709: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4762
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-deb17b9d-5a13-11e9-b9a9-e6698ebc8bdf
STEP: Creating a pod to test consume configMaps
Apr  8 15:34:59.868: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-deb20c29-5a13-11e9-b9a9-e6698ebc8bdf" in namespace "projected-4762" to be "success or failure"
Apr  8 15:34:59.872: INFO: Pod "pod-projected-configmaps-deb20c29-5a13-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.472495ms
Apr  8 15:35:01.877: INFO: Pod "pod-projected-configmaps-deb20c29-5a13-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009708586s
STEP: Saw pod success
Apr  8 15:35:01.877: INFO: Pod "pod-projected-configmaps-deb20c29-5a13-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:35:01.881: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-projected-configmaps-deb20c29-5a13-11e9-b9a9-e6698ebc8bdf container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr  8 15:35:01.901: INFO: Waiting for pod pod-projected-configmaps-deb20c29-5a13-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:35:01.905: INFO: Pod pod-projected-configmaps-deb20c29-5a13-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:35:01.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4762" for this suite.
Apr  8 15:35:07.921: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:35:08.064: INFO: namespace projected-4762 deletion completed in 6.154005203s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:35:08.064: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1078
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:177
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:35:08.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1078" for this suite.
Apr  8 15:35:30.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:35:30.369: INFO: namespace pods-1078 deletion completed in 22.13736109s
â€¢SSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:35:30.369: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4441
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Apr  8 15:35:33.069: INFO: Successfully updated pod "annotationupdatef0f8df07-5a13-11e9-b9a9-e6698ebc8bdf"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:35:37.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4441" for this suite.
Apr  8 15:35:59.120: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:35:59.247: INFO: namespace downward-api-4441 deletion completed in 22.140511605s
â€¢S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:35:59.247: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8590
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating api versions
Apr  8 15:35:59.401: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config api-versions'
Apr  8 15:35:59.616: INFO: stderr: ""
Apr  8 15:35:59.616: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:35:59.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8590" for this suite.
Apr  8 15:36:05.636: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:36:05.796: INFO: namespace kubectl-8590 deletion completed in 6.174704117s
â€¢SSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:36:05.796: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5366
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr  8 15:36:05.946: INFO: Waiting up to 5m0s for pod "downward-api-0614f34a-5a14-11e9-b9a9-e6698ebc8bdf" in namespace "downward-api-5366" to be "success or failure"
Apr  8 15:36:05.952: INFO: Pod "downward-api-0614f34a-5a14-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 5.982597ms
Apr  8 15:36:07.957: INFO: Pod "downward-api-0614f34a-5a14-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010565228s
STEP: Saw pod success
Apr  8 15:36:07.957: INFO: Pod "downward-api-0614f34a-5a14-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:36:07.960: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod downward-api-0614f34a-5a14-11e9-b9a9-e6698ebc8bdf container dapi-container: <nil>
STEP: delete the pod
Apr  8 15:36:07.981: INFO: Waiting for pod downward-api-0614f34a-5a14-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:36:07.984: INFO: Pod downward-api-0614f34a-5a14-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:36:07.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5366" for this suite.
Apr  8 15:36:14.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:36:14.130: INFO: namespace downward-api-5366 deletion completed in 6.140846875s
â€¢SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:36:14.130: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-1450
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  8 15:36:14.280: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:36:15.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1450" for this suite.
Apr  8 15:36:21.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:36:21.492: INFO: namespace custom-resource-definition-1450 deletion completed in 6.143114979s
â€¢SSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:36:21.492: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-5584
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Apr  8 15:36:25.706: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5584 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  8 15:36:25.706: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
Apr  8 15:36:26.163: INFO: Exec stderr: ""
Apr  8 15:36:26.163: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5584 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  8 15:36:26.163: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
Apr  8 15:36:26.662: INFO: Exec stderr: ""
Apr  8 15:36:26.662: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5584 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  8 15:36:26.662: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
Apr  8 15:36:27.153: INFO: Exec stderr: ""
Apr  8 15:36:27.153: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5584 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  8 15:36:27.153: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
Apr  8 15:36:27.652: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Apr  8 15:36:27.652: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5584 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  8 15:36:27.652: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
Apr  8 15:36:28.117: INFO: Exec stderr: ""
Apr  8 15:36:28.117: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5584 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  8 15:36:28.117: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
Apr  8 15:36:28.592: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Apr  8 15:36:28.592: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5584 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  8 15:36:28.592: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
Apr  8 15:36:29.102: INFO: Exec stderr: ""
Apr  8 15:36:29.102: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5584 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  8 15:36:29.102: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
Apr  8 15:36:29.587: INFO: Exec stderr: ""
Apr  8 15:36:29.587: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5584 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  8 15:36:29.587: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
Apr  8 15:36:30.050: INFO: Exec stderr: ""
Apr  8 15:36:30.050: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5584 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  8 15:36:30.050: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
Apr  8 15:36:30.455: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:36:30.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-5584" for this suite.
Apr  8 15:37:16.475: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:37:16.601: INFO: namespace e2e-kubelet-etc-hosts-5584 deletion completed in 46.141001822s
â€¢
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:37:16.602: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-388
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-388/configmap-test-30499842-5a14-11e9-b9a9-e6698ebc8bdf
STEP: Creating a pod to test consume configMaps
Apr  8 15:37:16.760: INFO: Waiting up to 5m0s for pod "pod-configmaps-304a2f4c-5a14-11e9-b9a9-e6698ebc8bdf" in namespace "configmap-388" to be "success or failure"
Apr  8 15:37:16.765: INFO: Pod "pod-configmaps-304a2f4c-5a14-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 5.189129ms
Apr  8 15:37:18.770: INFO: Pod "pod-configmaps-304a2f4c-5a14-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010397465s
STEP: Saw pod success
Apr  8 15:37:18.770: INFO: Pod "pod-configmaps-304a2f4c-5a14-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:37:18.776: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-configmaps-304a2f4c-5a14-11e9-b9a9-e6698ebc8bdf container env-test: <nil>
STEP: delete the pod
Apr  8 15:37:18.812: INFO: Waiting for pod pod-configmaps-304a2f4c-5a14-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:37:18.815: INFO: Pod pod-configmaps-304a2f4c-5a14-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:37:18.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-388" for this suite.
Apr  8 15:37:24.833: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:37:24.956: INFO: namespace configmap-388 deletion completed in 6.136500489s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:37:24.957: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2041
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  8 15:37:27.308: INFO: Waiting up to 5m0s for pod "client-envvars-36938c7b-5a14-11e9-b9a9-e6698ebc8bdf" in namespace "pods-2041" to be "success or failure"
Apr  8 15:37:27.314: INFO: Pod "client-envvars-36938c7b-5a14-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 5.681058ms
Apr  8 15:37:29.319: INFO: Pod "client-envvars-36938c7b-5a14-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011023117s
STEP: Saw pod success
Apr  8 15:37:29.319: INFO: Pod "client-envvars-36938c7b-5a14-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:37:29.323: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod client-envvars-36938c7b-5a14-11e9-b9a9-e6698ebc8bdf container env3cont: <nil>
STEP: delete the pod
Apr  8 15:37:29.348: INFO: Waiting for pod client-envvars-36938c7b-5a14-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:37:29.351: INFO: Pod client-envvars-36938c7b-5a14-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:37:29.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2041" for this suite.
Apr  8 15:38:19.367: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:38:19.518: INFO: namespace pods-2041 deletion completed in 50.163236497s
â€¢SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:38:19.518: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2972
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  8 15:38:19.669: INFO: Waiting up to 5m0s for pod "downwardapi-volume-55c98105-5a14-11e9-b9a9-e6698ebc8bdf" in namespace "projected-2972" to be "success or failure"
Apr  8 15:38:19.673: INFO: Pod "downwardapi-volume-55c98105-5a14-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 3.887645ms
Apr  8 15:38:21.679: INFO: Pod "downwardapi-volume-55c98105-5a14-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010587156s
STEP: Saw pod success
Apr  8 15:38:21.679: INFO: Pod "downwardapi-volume-55c98105-5a14-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:38:21.690: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod downwardapi-volume-55c98105-5a14-11e9-b9a9-e6698ebc8bdf container client-container: <nil>
STEP: delete the pod
Apr  8 15:38:21.713: INFO: Waiting for pod downwardapi-volume-55c98105-5a14-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:38:21.716: INFO: Pod downwardapi-volume-55c98105-5a14-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:38:21.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2972" for this suite.
Apr  8 15:38:27.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:38:27.846: INFO: namespace projected-2972 deletion completed in 6.125752542s
â€¢SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:38:27.847: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-712
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  8 15:38:28.174: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5adae1ac-5a14-11e9-b9a9-e6698ebc8bdf" in namespace "downward-api-712" to be "success or failure"
Apr  8 15:38:28.178: INFO: Pod "downwardapi-volume-5adae1ac-5a14-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 3.301128ms
Apr  8 15:38:30.183: INFO: Pod "downwardapi-volume-5adae1ac-5a14-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009137165s
STEP: Saw pod success
Apr  8 15:38:30.183: INFO: Pod "downwardapi-volume-5adae1ac-5a14-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:38:30.187: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod downwardapi-volume-5adae1ac-5a14-11e9-b9a9-e6698ebc8bdf container client-container: <nil>
STEP: delete the pod
Apr  8 15:38:30.207: INFO: Waiting for pod downwardapi-volume-5adae1ac-5a14-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:38:30.210: INFO: Pod downwardapi-volume-5adae1ac-5a14-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:38:30.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-712" for this suite.
Apr  8 15:38:36.231: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:38:36.346: INFO: namespace downward-api-712 deletion completed in 6.129602167s
â€¢SSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:38:36.346: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-1944
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating replication controller my-hostname-basic-5fd1df8b-5a14-11e9-b9a9-e6698ebc8bdf
Apr  8 15:38:36.502: INFO: Pod name my-hostname-basic-5fd1df8b-5a14-11e9-b9a9-e6698ebc8bdf: Found 0 pods out of 1
Apr  8 15:38:41.507: INFO: Pod name my-hostname-basic-5fd1df8b-5a14-11e9-b9a9-e6698ebc8bdf: Found 1 pods out of 1
Apr  8 15:38:41.507: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-5fd1df8b-5a14-11e9-b9a9-e6698ebc8bdf" are running
Apr  8 15:38:41.511: INFO: Pod "my-hostname-basic-5fd1df8b-5a14-11e9-b9a9-e6698ebc8bdf-lgzch" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-08 15:38:36 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-08 15:38:38 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-08 15:38:38 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-08 15:38:36 +0000 UTC Reason: Message:}])
Apr  8 15:38:41.511: INFO: Trying to dial the pod
Apr  8 15:38:46.605: INFO: Controller my-hostname-basic-5fd1df8b-5a14-11e9-b9a9-e6698ebc8bdf: Got expected result from replica 1 [my-hostname-basic-5fd1df8b-5a14-11e9-b9a9-e6698ebc8bdf-lgzch]: "my-hostname-basic-5fd1df8b-5a14-11e9-b9a9-e6698ebc8bdf-lgzch", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:38:46.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1944" for this suite.
Apr  8 15:38:52.628: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:38:52.752: INFO: namespace replication-controller-1944 deletion completed in 6.141295423s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:38:52.752: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8127
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1318
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr  8 15:38:52.896: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-8127'
Apr  8 15:38:53.052: INFO: stderr: "kubectl run --generator=deployment/apps.v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Apr  8 15:38:53.052: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1324
Apr  8 15:38:55.064: INFO: Running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config delete deployment e2e-test-nginx-deployment --namespace=kubectl-8127'
Apr  8 15:38:55.197: INFO: stderr: ""
Apr  8 15:38:55.197: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:38:55.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8127" for this suite.
Apr  8 15:39:17.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:39:17.382: INFO: namespace kubectl-8127 deletion completed in 22.179995555s
â€¢SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:39:17.382: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-3716
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Apr  8 15:39:17.532: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr  8 15:39:17.541: INFO: Waiting for terminating namespaces to be deleted...
Apr  8 15:39:17.544: INFO: 
Logging pods the kubelet thinks is on node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-7dnjw before test
Apr  8 15:39:17.556: INFO: metrics-server-bbc67f984-2cbzt from kube-system started at 2019-04-08 13:54:16 +0000 UTC (1 container statuses recorded)
Apr  8 15:39:17.556: INFO: 	Container metrics-server ready: true, restart count 0
Apr  8 15:39:17.556: INFO: coredns-7f7f7978c8-2cw6g from kube-system started at 2019-04-08 13:54:16 +0000 UTC (1 container statuses recorded)
Apr  8 15:39:17.556: INFO: 	Container coredns ready: true, restart count 0
Apr  8 15:39:17.556: INFO: blackbox-exporter-6dc58dcffc-kddgs from kube-system started at 2019-04-08 13:53:56 +0000 UTC (1 container statuses recorded)
Apr  8 15:39:17.556: INFO: 	Container blackbox-exporter ready: true, restart count 0
Apr  8 15:39:17.556: INFO: calico-node-rhz9g from kube-system started at 2019-04-08 13:53:56 +0000 UTC (1 container statuses recorded)
Apr  8 15:39:17.556: INFO: 	Container calico-node ready: true, restart count 0
Apr  8 15:39:17.556: INFO: node-exporter-52tc5 from kube-system started at 2019-04-08 13:53:56 +0000 UTC (1 container statuses recorded)
Apr  8 15:39:17.556: INFO: 	Container node-exporter ready: true, restart count 0
Apr  8 15:39:17.556: INFO: addons-nginx-ingress-controller-d4f8c9cc5-dz84h from kube-system started at 2019-04-08 13:54:14 +0000 UTC (1 container statuses recorded)
Apr  8 15:39:17.556: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Apr  8 15:39:17.556: INFO: vpn-shoot-846bd99d6c-frws7 from kube-system started at 2019-04-08 13:54:14 +0000 UTC (1 container statuses recorded)
Apr  8 15:39:17.556: INFO: 	Container vpn-shoot ready: true, restart count 0
Apr  8 15:39:17.556: INFO: coredns-7f7f7978c8-jpqwt from kube-system started at 2019-04-08 13:54:14 +0000 UTC (1 container statuses recorded)
Apr  8 15:39:17.556: INFO: 	Container coredns ready: true, restart count 0
Apr  8 15:39:17.556: INFO: kube-proxy-zwjh7 from kube-system started at 2019-04-08 13:53:56 +0000 UTC (1 container statuses recorded)
Apr  8 15:39:17.556: INFO: 	Container kube-proxy ready: true, restart count 0
Apr  8 15:39:17.556: INFO: addons-kubernetes-dashboard-665df4b66d-w6dfr from kube-system started at 2019-04-08 13:54:14 +0000 UTC (1 container statuses recorded)
Apr  8 15:39:17.556: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Apr  8 15:39:17.556: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-754f8f5dcb-scvf9 from kube-system started at 2019-04-08 13:54:14 +0000 UTC (1 container statuses recorded)
Apr  8 15:39:17.556: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Apr  8 15:39:17.556: INFO: 
Logging pods the kubelet thinks is on node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw before test
Apr  8 15:39:17.605: INFO: kube-proxy-txjx7 from kube-system started at 2019-04-08 13:53:55 +0000 UTC (1 container statuses recorded)
Apr  8 15:39:17.605: INFO: 	Container kube-proxy ready: true, restart count 0
Apr  8 15:39:17.605: INFO: calico-node-nk88t from kube-system started at 2019-04-08 13:53:55 +0000 UTC (1 container statuses recorded)
Apr  8 15:39:17.605: INFO: 	Container calico-node ready: true, restart count 0
Apr  8 15:39:17.605: INFO: node-exporter-j4f9g from kube-system started at 2019-04-08 13:53:55 +0000 UTC (1 container statuses recorded)
Apr  8 15:39:17.605: INFO: 	Container node-exporter ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-7988cef2-5a14-11e9-b9a9-e6698ebc8bdf 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-7988cef2-5a14-11e9-b9a9-e6698ebc8bdf off the node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw
STEP: verifying the node doesn't have the label kubernetes.io/e2e-7988cef2-5a14-11e9-b9a9-e6698ebc8bdf
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:39:21.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3716" for this suite.
Apr  8 15:39:39.700: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:39:39.816: INFO: namespace sched-pred-3716 deletion completed in 18.129923578s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70
â€¢SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:39:39.816: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8042
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Starting the proxy
Apr  8 15:39:39.966: INFO: Asynchronously running '/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl kubectl --server=https://api.pub-os-wkqoh.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config proxy --unix-socket=/tmp/kubectl-proxy-unix001410603/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:39:40.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8042" for this suite.
Apr  8 15:39:46.098: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:39:46.449: INFO: namespace kubectl-8042 deletion completed in 6.363239546s
â€¢SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:39:46.449: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9862
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Apr  8 15:39:46.721: INFO: Waiting up to 5m0s for pod "pod-89ab8d6e-5a14-11e9-b9a9-e6698ebc8bdf" in namespace "emptydir-9862" to be "success or failure"
Apr  8 15:39:46.725: INFO: Pod "pod-89ab8d6e-5a14-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 3.682877ms
Apr  8 15:39:48.731: INFO: Pod "pod-89ab8d6e-5a14-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009126847s
STEP: Saw pod success
Apr  8 15:39:48.731: INFO: Pod "pod-89ab8d6e-5a14-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:39:48.734: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-89ab8d6e-5a14-11e9-b9a9-e6698ebc8bdf container test-container: <nil>
STEP: delete the pod
Apr  8 15:39:48.754: INFO: Waiting for pod pod-89ab8d6e-5a14-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:39:48.757: INFO: Pod pod-89ab8d6e-5a14-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:39:48.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9862" for this suite.
Apr  8 15:39:54.772: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:39:54.931: INFO: namespace emptydir-9862 deletion completed in 6.169766525s
â€¢SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:39:54.931: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-6651
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-6651
Apr  8 15:39:57.096: INFO: Started pod liveness-http in namespace container-probe-6651
STEP: checking the pod's current state and verifying that restartCount is present
Apr  8 15:39:57.100: INFO: Initial restart count of pod liveness-http is 0
Apr  8 15:40:09.133: INFO: Restart count of pod container-probe-6651/liveness-http is now 1 (12.033099314s elapsed)
Apr  8 15:40:29.184: INFO: Restart count of pod container-probe-6651/liveness-http is now 2 (32.084401248s elapsed)
Apr  8 15:40:49.238: INFO: Restart count of pod container-probe-6651/liveness-http is now 3 (52.137690115s elapsed)
Apr  8 15:41:09.332: INFO: Restart count of pod container-probe-6651/liveness-http is now 4 (1m12.232494058s elapsed)
Apr  8 15:42:13.552: INFO: Restart count of pod container-probe-6651/liveness-http is now 5 (2m16.452027364s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:42:13.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6651" for this suite.
Apr  8 15:42:19.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:42:19.704: INFO: namespace container-probe-6651 deletion completed in 6.138100956s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:42:19.705: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-1876
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Apr  8 15:42:19.878: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1876,SelfLink:/api/v1/namespaces/watch-1876/configmaps/e2e-watch-test-configmap-a,UID:e4f8377e-5a14-11e9-8aed-4ea023eb3a48,ResourceVersion:22643,Generation:0,CreationTimestamp:2019-04-08 15:42:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr  8 15:42:19.878: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1876,SelfLink:/api/v1/namespaces/watch-1876/configmaps/e2e-watch-test-configmap-a,UID:e4f8377e-5a14-11e9-8aed-4ea023eb3a48,ResourceVersion:22643,Generation:0,CreationTimestamp:2019-04-08 15:42:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Apr  8 15:42:29.887: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1876,SelfLink:/api/v1/namespaces/watch-1876/configmaps/e2e-watch-test-configmap-a,UID:e4f8377e-5a14-11e9-8aed-4ea023eb3a48,ResourceVersion:22666,Generation:0,CreationTimestamp:2019-04-08 15:42:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Apr  8 15:42:29.887: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1876,SelfLink:/api/v1/namespaces/watch-1876/configmaps/e2e-watch-test-configmap-a,UID:e4f8377e-5a14-11e9-8aed-4ea023eb3a48,ResourceVersion:22666,Generation:0,CreationTimestamp:2019-04-08 15:42:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Apr  8 15:42:39.897: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1876,SelfLink:/api/v1/namespaces/watch-1876/configmaps/e2e-watch-test-configmap-a,UID:e4f8377e-5a14-11e9-8aed-4ea023eb3a48,ResourceVersion:22688,Generation:0,CreationTimestamp:2019-04-08 15:42:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr  8 15:42:39.898: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1876,SelfLink:/api/v1/namespaces/watch-1876/configmaps/e2e-watch-test-configmap-a,UID:e4f8377e-5a14-11e9-8aed-4ea023eb3a48,ResourceVersion:22688,Generation:0,CreationTimestamp:2019-04-08 15:42:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Apr  8 15:42:49.905: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1876,SelfLink:/api/v1/namespaces/watch-1876/configmaps/e2e-watch-test-configmap-a,UID:e4f8377e-5a14-11e9-8aed-4ea023eb3a48,ResourceVersion:22711,Generation:0,CreationTimestamp:2019-04-08 15:42:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr  8 15:42:49.905: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1876,SelfLink:/api/v1/namespaces/watch-1876/configmaps/e2e-watch-test-configmap-a,UID:e4f8377e-5a14-11e9-8aed-4ea023eb3a48,ResourceVersion:22711,Generation:0,CreationTimestamp:2019-04-08 15:42:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Apr  8 15:42:59.917: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-1876,SelfLink:/api/v1/namespaces/watch-1876/configmaps/e2e-watch-test-configmap-b,UID:fcd55d5a-5a14-11e9-8aed-4ea023eb3a48,ResourceVersion:22733,Generation:0,CreationTimestamp:2019-04-08 15:42:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr  8 15:42:59.917: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-1876,SelfLink:/api/v1/namespaces/watch-1876/configmaps/e2e-watch-test-configmap-b,UID:fcd55d5a-5a14-11e9-8aed-4ea023eb3a48,ResourceVersion:22733,Generation:0,CreationTimestamp:2019-04-08 15:42:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Apr  8 15:43:09.925: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-1876,SelfLink:/api/v1/namespaces/watch-1876/configmaps/e2e-watch-test-configmap-b,UID:fcd55d5a-5a14-11e9-8aed-4ea023eb3a48,ResourceVersion:22755,Generation:0,CreationTimestamp:2019-04-08 15:42:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr  8 15:43:09.925: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-1876,SelfLink:/api/v1/namespaces/watch-1876/configmaps/e2e-watch-test-configmap-b,UID:fcd55d5a-5a14-11e9-8aed-4ea023eb3a48,ResourceVersion:22755,Generation:0,CreationTimestamp:2019-04-08 15:42:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:43:19.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1876" for this suite.
Apr  8 15:43:25.945: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:43:26.109: INFO: namespace watch-1876 deletion completed in 6.178369936s
â€¢SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:43:26.109: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4793
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-0c975c28-5a15-11e9-b9a9-e6698ebc8bdf
STEP: Creating a pod to test consume configMaps
Apr  8 15:43:26.368: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0c97fdd9-5a15-11e9-b9a9-e6698ebc8bdf" in namespace "projected-4793" to be "success or failure"
Apr  8 15:43:26.441: INFO: Pod "pod-projected-configmaps-0c97fdd9-5a15-11e9-b9a9-e6698ebc8bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 72.373169ms
Apr  8 15:43:28.446: INFO: Pod "pod-projected-configmaps-0c97fdd9-5a15-11e9-b9a9-e6698ebc8bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.078063505s
STEP: Saw pod success
Apr  8 15:43:28.446: INFO: Pod "pod-projected-configmaps-0c97fdd9-5a15-11e9-b9a9-e6698ebc8bdf" satisfied condition "success or failure"
Apr  8 15:43:28.450: INFO: Trying to get logs from node shoot--it--pub-os-wkqoh-cpu-worker-z1-7b994f988b-c6qsw pod pod-projected-configmaps-0c97fdd9-5a15-11e9-b9a9-e6698ebc8bdf container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr  8 15:43:28.471: INFO: Waiting for pod pod-projected-configmaps-0c97fdd9-5a15-11e9-b9a9-e6698ebc8bdf to disappear
Apr  8 15:43:28.474: INFO: Pod pod-projected-configmaps-0c97fdd9-5a15-11e9-b9a9-e6698ebc8bdf no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:43:28.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4793" for this suite.
Apr  8 15:43:34.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:43:34.653: INFO: namespace projected-4793 deletion completed in 6.174757141s
â€¢SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:43:34.654: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-6776
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-6776
Apr  8 15:43:36.950: INFO: Started pod liveness-exec in namespace container-probe-6776
STEP: checking the pod's current state and verifying that restartCount is present
Apr  8 15:43:36.954: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:47:37.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6776" for this suite.
Apr  8 15:47:43.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:47:43.791: INFO: namespace container-probe-6776 deletion completed in 6.133714202s
â€¢SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  8 15:47:43.795: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-7426
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-7426
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr  8 15:47:43.943: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr  8 15:48:08.014: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.5:8080/dial?request=hostName&protocol=udp&host=100.96.1.4&port=8081&tries=1'] Namespace:pod-network-test-7426 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  8 15:48:08.014: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
Apr  8 15:48:08.505: INFO: Waiting for endpoints: map[]
Apr  8 15:48:08.512: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.5:8080/dial?request=hostName&protocol=udp&host=100.96.0.91&port=8081&tries=1'] Namespace:pod-network-test-7426 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  8 15:48:08.512: INFO: >>> kubeConfig: /tmp/build/a8535ce5/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
Apr  8 15:48:08.982: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  8 15:48:08.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7426" for this suite.
Apr  8 15:48:31.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  8 15:48:31.116: INFO: namespace pod-network-test-7426 deletion completed in 22.128143084s
â€¢SSApr  8 15:48:31.116: INFO: Running AfterSuite actions on all nodes
Apr  8 15:48:31.126: INFO: Running AfterSuite actions on node 1
Apr  8 15:48:31.126: INFO: Skipping dumping logs from cluster

Ran 204 of 3584 Specs in 6449.031 seconds
SUCCESS! -- 204 Passed | 0 Failed | 0 Flaked | 0 Pending | 3380 Skipped PASS

Ginkgo ran 1 suite in 1h47m30.412265549s
Test Suite Passed
