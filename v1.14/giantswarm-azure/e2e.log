I0429 08:53:50.024586      15 test_context.go:405] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-244696311
I0429 08:53:50.024789      15 e2e.go:240] Starting e2e run "4db0f8e0-6a5c-11e9-b6b4-b219b18c41e8" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1556528028 - Will randomize all specs
Will run 204 of 3584 specs

Apr 29 08:53:50.227: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
Apr 29 08:53:50.231: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Apr 29 08:53:50.993: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Apr 29 08:53:51.049: INFO: 33 / 33 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Apr 29 08:53:51.049: INFO: expected 10 pod replicas in namespace 'kube-system', 10 are Running and Ready.
Apr 29 08:53:51.049: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Apr 29 08:53:51.059: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Apr 29 08:53:51.059: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'cert-exporter' (0 seconds elapsed)
Apr 29 08:53:51.059: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Apr 29 08:53:51.059: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'net-exporter' (0 seconds elapsed)
Apr 29 08:53:51.059: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'node-exporter' (0 seconds elapsed)
Apr 29 08:53:51.059: INFO: e2e test version: v1.14.1
Apr 29 08:53:51.060: INFO: kube-apiserver version: v1.14.1
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 08:53:51.061: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename kubectl
Apr 29 08:54:01.879: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Apr 29 08:54:02.012: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2622
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 29 08:54:02.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 version --client'
Apr 29 08:54:02.245: INFO: stderr: ""
Apr 29 08:54:02.245: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.1\", GitCommit:\"b7394102d6ef778017f2ca4046abbaa23b88c290\", GitTreeState:\"clean\", BuildDate:\"2019-04-08T17:11:31Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Apr 29 08:54:02.247: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 create -f - --namespace=kubectl-2622'
Apr 29 08:54:03.832: INFO: stderr: ""
Apr 29 08:54:03.832: INFO: stdout: "replicationcontroller/redis-master created\n"
Apr 29 08:54:03.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 create -f - --namespace=kubectl-2622'
Apr 29 08:54:04.273: INFO: stderr: ""
Apr 29 08:54:04.273: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Apr 29 08:54:05.277: INFO: Selector matched 1 pods for map[app:redis]
Apr 29 08:54:05.277: INFO: Found 0 / 1
Apr 29 08:54:06.277: INFO: Selector matched 1 pods for map[app:redis]
Apr 29 08:54:06.277: INFO: Found 0 / 1
Apr 29 08:54:07.278: INFO: Selector matched 1 pods for map[app:redis]
Apr 29 08:54:07.278: INFO: Found 0 / 1
Apr 29 08:54:08.276: INFO: Selector matched 1 pods for map[app:redis]
Apr 29 08:54:08.276: INFO: Found 0 / 1
Apr 29 08:54:09.280: INFO: Selector matched 1 pods for map[app:redis]
Apr 29 08:54:09.280: INFO: Found 0 / 1
Apr 29 08:54:10.277: INFO: Selector matched 1 pods for map[app:redis]
Apr 29 08:54:10.277: INFO: Found 0 / 1
Apr 29 08:54:11.277: INFO: Selector matched 1 pods for map[app:redis]
Apr 29 08:54:11.277: INFO: Found 1 / 1
Apr 29 08:54:11.277: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 29 08:54:11.280: INFO: Selector matched 1 pods for map[app:redis]
Apr 29 08:54:11.280: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 29 08:54:11.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 describe pod redis-master-tgp8q --namespace=kubectl-2622'
Apr 29 08:54:11.391: INFO: stderr: ""
Apr 29 08:54:11.391: INFO: stdout: "Name:               redis-master-tgp8q\nNamespace:          kubectl-2622\nPriority:           0\nPriorityClassName:  <none>\nNode:               0mfg0-worker-000001/10.2.1.5\nStart Time:         Mon, 29 Apr 2019 08:54:03 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        cni.projectcalico.org/podIP: 10.2.130.11/32\n                    kubernetes.io/psp: e2e-test-privileged-psp\nStatus:             Running\nIP:                 10.2.130.11\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://d6628d0e4d40648436151bda1c1d10def84c41869485fbaf904d0fe1b766ea55\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 29 Apr 2019 08:54:10 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-dnbfk (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-dnbfk:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-dnbfk\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                          Message\n  ----    ------     ----  ----                          -------\n  Normal  Scheduled  8s    default-scheduler             Successfully assigned kubectl-2622/redis-master-tgp8q to 0mfg0-worker-000001\n  Normal  Pulling    4s    kubelet, 0mfg0-worker-000001  Pulling image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\"\n  Normal  Pulled     2s    kubelet, 0mfg0-worker-000001  Successfully pulled image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\"\n  Normal  Created    1s    kubelet, 0mfg0-worker-000001  Created container redis-master\n  Normal  Started    1s    kubelet, 0mfg0-worker-000001  Started container redis-master\n"
Apr 29 08:54:11.391: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 describe rc redis-master --namespace=kubectl-2622'
Apr 29 08:54:11.513: INFO: stderr: ""
Apr 29 08:54:11.513: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-2622\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  8s    replication-controller  Created pod: redis-master-tgp8q\n"
Apr 29 08:54:11.513: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 describe service redis-master --namespace=kubectl-2622'
Apr 29 08:54:11.637: INFO: stderr: ""
Apr 29 08:54:11.637: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-2622\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                172.31.46.57\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.2.130.11:6379\nSession Affinity:  None\nEvents:\n  Type     Reason                     Age              From                Message\n  ----     ------                     ----             ----                -------\n  Warning  CleanupLoadBalancerFailed  2s (x2 over 7s)  service-controller  Error cleaning up load balancer (will retry): error getting LB for service kubectl-2622/redis-master: network.LoadBalancersClient#List: Failure responding to request: StatusCode=403 -- Original Error: autorest/azure: Service returned an error. Status=403 Code=\"AuthorizationFailed\" Message=\"The client '0eaac502-a641-4930-a2bf-995b098a505f' with object id '0eaac502-a641-4930-a2bf-995b098a505f' does not have authorization to perform action 'Microsoft.Network/loadBalancers/read' over scope '/subscriptions/1be3b2e6-497b-45b9-915f-eb35cae23c6a/resourceGroups/0mfg0/providers/Microsoft.Network'.\"\n"
Apr 29 08:54:11.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 describe node 0mfg0-master-000000'
Apr 29 08:54:11.784: INFO: stderr: ""
Apr 29 08:54:11.784: INFO: stdout: "Name:               0mfg0-master-000000\nRoles:              master\nLabels:             azure-operator.giantswarm.io/version=2.3.0\n                    beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=Standard_D2s_v3\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=westeurope\n                    failure-domain.beta.kubernetes.io/zone=0\n                    giantswarm.io/provider=azure\n                    ip=10.2.0.5\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=0mfg0-master-000000\n                    kubernetes.io/os=linux\n                    kubernetes.io/role=master\n                    node-role.kubernetes.io/master=\n                    node.kubernetes.io/master=\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 29 Apr 2019 08:38:22 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Mon, 29 Apr 2019 08:40:25 +0000   Mon, 29 Apr 2019 08:40:25 +0000   RouteCreated                 RouteController created a route\n  MemoryPressure       False   Mon, 29 Apr 2019 08:54:03 +0000   Mon, 29 Apr 2019 08:38:06 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Mon, 29 Apr 2019 08:54:03 +0000   Mon, 29 Apr 2019 08:38:06 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Mon, 29 Apr 2019 08:54:03 +0000   Mon, 29 Apr 2019 08:38:06 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Mon, 29 Apr 2019 08:54:03 +0000   Mon, 29 Apr 2019 08:39:24 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  10.2.0.5\n  Hostname:    0mfg0-master-000000\nCapacity:\n attachable-volumes-azure-disk:  4\n cpu:                            2\n ephemeral-storage:              28454196Ki\n hugepages-1Gi:                  0\n hugepages-2Mi:                  0\n memory:                         8146856Ki\n pods:                           110\nAllocatable:\n attachable-volumes-azure-disk:  4\n cpu:                            2\n ephemeral-storage:              28454196Ki\n hugepages-1Gi:                  0\n hugepages-2Mi:                  0\n memory:                         7942056Ki\n pods:                           110\nSystem Info:\n Machine ID:                 c89ced34821242ff8cbd06babe913c3b\n System UUID:                7a6e8c48-ba22-3e45-a8bf-d773dcffcd72\n Boot ID:                    88d4a223-5886-4116-993c-06c6468e7995\n Kernel Version:             4.19.25-coreos\n OS Image:                   Container Linux by CoreOS 2023.5.0 (Rhyolite)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.1\n Kubelet Version:            v1.14.1\n Kube-Proxy Version:         v1.14.1\nPodCIDR:                     10.2.128.0/24\nProviderID:                  azure:///subscriptions/1be3b2e6-497b-45b9-915f-eb35cae23c6a/resourceGroups/0mfg0/providers/Microsoft.Compute/virtualMachineScaleSets/0mfg0-master/virtualMachines/0\nNon-terminated Pods:         (10 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  heptio-sonobuoy            sonobuoy-e2e-job-df96c01fb79543db                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         77s\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-354ce670adf74187-rc4p5    0 (0%)        0 (0%)      0 (0%)           0 (0%)         76s\n  kube-system                calico-node-nsvtp                                          250m (12%)    250m (12%)  150Mi (1%)       150Mi (1%)     15m\n  kube-system                cert-exporter-cfr8v                                        50m (2%)      50m (2%)    50Mi (0%)        50Mi (0%)      8m5s\n  kube-system                k8s-api-server-0mfg0-master-000000                         300m (15%)    0 (0%)      300Mi (3%)       0 (0%)         15m\n  kube-system                k8s-controller-manager-0mfg0-master-000000                 200m (10%)    0 (0%)      200Mi (2%)       0 (0%)         15m\n  kube-system                k8s-scheduler-0mfg0-master-000000                          100m (5%)     0 (0%)      100Mi (1%)       0 (0%)         15m\n  kube-system                kube-proxy-6mxqd                                           75m (3%)      0 (0%)      80Mi (1%)        0 (0%)         14m\n  kube-system                net-exporter-l6fgx                                         50m (2%)      50m (2%)    50Mi (0%)        50Mi (0%)      13m\n  kube-system                node-exporter-2xpxh                                        200m (10%)    200m (10%)  75Mi (0%)        75Mi (0%)      7m31s\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                       Requests      Limits\n  --------                       --------      ------\n  cpu                            1225m (61%)   550m (27%)\n  memory                         1005Mi (12%)  325Mi (4%)\n  ephemeral-storage              0 (0%)        0 (0%)\n  attachable-volumes-azure-disk  0             0\nEvents:\n  Type    Reason                   Age                From                             Message\n  ----    ------                   ----               ----                             -------\n  Normal  Starting                 16m                kubelet, 0mfg0-master-000000     Starting kubelet.\n  Normal  NodeHasSufficientMemory  16m (x8 over 16m)  kubelet, 0mfg0-master-000000     Node 0mfg0-master-000000 status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    16m (x8 over 16m)  kubelet, 0mfg0-master-000000     Node 0mfg0-master-000000 status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     16m (x7 over 16m)  kubelet, 0mfg0-master-000000     Node 0mfg0-master-000000 status is now: NodeHasSufficientPID\n  Normal  NodeAllocatableEnforced  16m                kubelet, 0mfg0-master-000000     Updated Node Allocatable limit across pods\n  Normal  Starting                 15m                kubelet, 0mfg0-master-000000     Starting kubelet.\n  Normal  NodeAllocatableEnforced  15m                kubelet, 0mfg0-master-000000     Updated Node Allocatable limit across pods\n  Normal  NodeHasSufficientMemory  15m                kubelet, 0mfg0-master-000000     Node 0mfg0-master-000000 status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    15m                kubelet, 0mfg0-master-000000     Node 0mfg0-master-000000 status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     15m                kubelet, 0mfg0-master-000000     Node 0mfg0-master-000000 status is now: NodeHasSufficientPID\n  Normal  NodeReady                14m                kubelet, 0mfg0-master-000000     Node 0mfg0-master-000000 status is now: NodeReady\n  Normal  Starting                 14m                kube-proxy, 0mfg0-master-000000  Starting kube-proxy.\n"
Apr 29 08:54:11.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 describe namespace kubectl-2622'
Apr 29 08:54:11.909: INFO: stderr: ""
Apr 29 08:54:11.909: INFO: stdout: "Name:         kubectl-2622\nLabels:       e2e-framework=kubectl\n              e2e-run=4db0f8e0-6a5c-11e9-b6b4-b219b18c41e8\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 08:54:11.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2622" for this suite.
Apr 29 08:54:33.936: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 08:54:34.078: INFO: namespace kubectl-2622 deletion completed in 22.16472632s

• [SLOW TEST:43.017 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 08:54:34.078: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5188
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 29 08:54:34.340: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6909c962-6a5c-11e9-b6b4-b219b18c41e8" in namespace "downward-api-5188" to be "success or failure"
Apr 29 08:54:34.359: INFO: Pod "downwardapi-volume-6909c962-6a5c-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 19.244234ms
Apr 29 08:54:36.363: INFO: Pod "downwardapi-volume-6909c962-6a5c-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023414697s
Apr 29 08:54:38.367: INFO: Pod "downwardapi-volume-6909c962-6a5c-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02741961s
Apr 29 08:54:40.372: INFO: Pod "downwardapi-volume-6909c962-6a5c-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.031801976s
STEP: Saw pod success
Apr 29 08:54:40.372: INFO: Pod "downwardapi-volume-6909c962-6a5c-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 08:54:40.374: INFO: Trying to get logs from node 0mfg0-worker-000000 pod downwardapi-volume-6909c962-6a5c-11e9-b6b4-b219b18c41e8 container client-container: <nil>
STEP: delete the pod
Apr 29 08:54:40.439: INFO: Waiting for pod downwardapi-volume-6909c962-6a5c-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 08:54:40.444: INFO: Pod downwardapi-volume-6909c962-6a5c-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 08:54:40.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5188" for this suite.
Apr 29 08:54:46.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 08:54:46.577: INFO: namespace downward-api-5188 deletion completed in 6.129446997s

• [SLOW TEST:12.499 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 08:54:46.578: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4567
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Starting the proxy
Apr 29 08:54:46.773: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-244696311 proxy --unix-socket=/tmp/kubectl-proxy-unix341890538/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 08:54:46.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4567" for this suite.
Apr 29 08:54:52.863: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 08:54:52.973: INFO: namespace kubectl-4567 deletion completed in 6.123004485s

• [SLOW TEST:6.395 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 08:54:52.973: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-1949
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-1949
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating stateful set ss in namespace statefulset-1949
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-1949
Apr 29 08:54:53.180: INFO: Found 0 stateful pods, waiting for 1
Apr 29 08:55:03.184: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Apr 29 08:55:13.184: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Apr 29 08:55:13.189: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 29 08:55:13.414: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 29 08:55:13.414: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 29 08:55:13.414: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 29 08:55:13.417: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr 29 08:55:23.424: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 29 08:55:23.424: INFO: Waiting for statefulset status.replicas updated to 0
Apr 29 08:55:23.441: INFO: POD   NODE                 PHASE    GRACE  CONDITIONS
Apr 29 08:55:23.441: INFO: ss-0  0mfg0-worker-000001  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:54:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:54:53 +0000 UTC  }]
Apr 29 08:55:23.441: INFO: 
Apr 29 08:55:23.441: INFO: StatefulSet ss has not reached scale 3, at 1
Apr 29 08:55:24.445: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995489771s
Apr 29 08:55:25.449: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.991715157s
Apr 29 08:55:26.453: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.987421652s
Apr 29 08:55:27.459: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.98349766s
Apr 29 08:55:28.463: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.977441966s
Apr 29 08:55:29.468: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.973368295s
Apr 29 08:55:30.472: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.968882733s
Apr 29 08:55:31.476: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.964935186s
Apr 29 08:55:32.480: INFO: Verifying statefulset ss doesn't scale past 3 for another 960.909049ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-1949
Apr 29 08:55:33.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 29 08:55:33.724: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr 29 08:55:33.724: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 29 08:55:33.724: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 29 08:55:33.724: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 29 08:55:33.984: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr 29 08:55:33.984: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 29 08:55:33.984: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 29 08:55:33.984: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 29 08:55:34.250: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr 29 08:55:34.250: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 29 08:55:34.250: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 29 08:55:34.258: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Apr 29 08:55:44.262: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 29 08:55:44.262: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 29 08:55:44.262: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Apr 29 08:55:44.267: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 29 08:55:44.519: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 29 08:55:44.519: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 29 08:55:44.519: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 29 08:55:44.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 29 08:55:44.927: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 29 08:55:44.927: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 29 08:55:44.927: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 29 08:55:44.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 29 08:55:45.128: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 29 08:55:45.128: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 29 08:55:45.128: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 29 08:55:45.128: INFO: Waiting for statefulset status.replicas updated to 0
Apr 29 08:55:45.136: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Apr 29 08:55:55.143: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 29 08:55:55.143: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr 29 08:55:55.143: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr 29 08:55:55.159: INFO: POD   NODE                 PHASE    GRACE  CONDITIONS
Apr 29 08:55:55.159: INFO: ss-0  0mfg0-worker-000001  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:54:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:54:53 +0000 UTC  }]
Apr 29 08:55:55.159: INFO: ss-1  0mfg0-worker-000000  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:23 +0000 UTC  }]
Apr 29 08:55:55.159: INFO: ss-2  0mfg0-worker-000002  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:23 +0000 UTC  }]
Apr 29 08:55:55.159: INFO: 
Apr 29 08:55:55.159: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 29 08:55:56.164: INFO: POD   NODE                 PHASE    GRACE  CONDITIONS
Apr 29 08:55:56.164: INFO: ss-0  0mfg0-worker-000001  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:54:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:54:53 +0000 UTC  }]
Apr 29 08:55:56.164: INFO: ss-1  0mfg0-worker-000000  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:23 +0000 UTC  }]
Apr 29 08:55:56.164: INFO: ss-2  0mfg0-worker-000002  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:23 +0000 UTC  }]
Apr 29 08:55:56.165: INFO: 
Apr 29 08:55:56.165: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 29 08:55:57.170: INFO: POD   NODE                 PHASE    GRACE  CONDITIONS
Apr 29 08:55:57.170: INFO: ss-0  0mfg0-worker-000001  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:54:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:54:53 +0000 UTC  }]
Apr 29 08:55:57.170: INFO: ss-1  0mfg0-worker-000000  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:23 +0000 UTC  }]
Apr 29 08:55:57.170: INFO: ss-2  0mfg0-worker-000002  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:23 +0000 UTC  }]
Apr 29 08:55:57.170: INFO: 
Apr 29 08:55:57.170: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 29 08:55:58.174: INFO: POD   NODE                 PHASE    GRACE  CONDITIONS
Apr 29 08:55:58.174: INFO: ss-0  0mfg0-worker-000001  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:54:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:54:53 +0000 UTC  }]
Apr 29 08:55:58.175: INFO: ss-1  0mfg0-worker-000000  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:23 +0000 UTC  }]
Apr 29 08:55:58.175: INFO: ss-2  0mfg0-worker-000002  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:23 +0000 UTC  }]
Apr 29 08:55:58.176: INFO: 
Apr 29 08:55:58.176: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 29 08:55:59.216: INFO: POD   NODE                 PHASE    GRACE  CONDITIONS
Apr 29 08:55:59.216: INFO: ss-0  0mfg0-worker-000001  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:54:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:54:53 +0000 UTC  }]
Apr 29 08:55:59.216: INFO: ss-1  0mfg0-worker-000000  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:23 +0000 UTC  }]
Apr 29 08:55:59.216: INFO: ss-2  0mfg0-worker-000002  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:23 +0000 UTC  }]
Apr 29 08:55:59.217: INFO: 
Apr 29 08:55:59.217: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 29 08:56:00.220: INFO: POD   NODE                 PHASE    GRACE  CONDITIONS
Apr 29 08:56:00.220: INFO: ss-0  0mfg0-worker-000001  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:54:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:54:53 +0000 UTC  }]
Apr 29 08:56:00.220: INFO: ss-2  0mfg0-worker-000002  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:23 +0000 UTC  }]
Apr 29 08:56:00.221: INFO: 
Apr 29 08:56:00.221: INFO: StatefulSet ss has not reached scale 0, at 2
Apr 29 08:56:01.224: INFO: POD   NODE                 PHASE    GRACE  CONDITIONS
Apr 29 08:56:01.224: INFO: ss-0  0mfg0-worker-000001  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:54:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:54:53 +0000 UTC  }]
Apr 29 08:56:01.224: INFO: ss-2  0mfg0-worker-000002  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:23 +0000 UTC  }]
Apr 29 08:56:01.224: INFO: 
Apr 29 08:56:01.224: INFO: StatefulSet ss has not reached scale 0, at 2
Apr 29 08:56:02.228: INFO: POD   NODE                 PHASE    GRACE  CONDITIONS
Apr 29 08:56:02.228: INFO: ss-0  0mfg0-worker-000001  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:54:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:54:53 +0000 UTC  }]
Apr 29 08:56:02.228: INFO: 
Apr 29 08:56:02.228: INFO: StatefulSet ss has not reached scale 0, at 1
Apr 29 08:56:03.232: INFO: POD   NODE                 PHASE    GRACE  CONDITIONS
Apr 29 08:56:03.232: INFO: ss-0  0mfg0-worker-000001  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:54:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:54:53 +0000 UTC  }]
Apr 29 08:56:03.232: INFO: 
Apr 29 08:56:03.232: INFO: StatefulSet ss has not reached scale 0, at 1
Apr 29 08:56:04.236: INFO: POD   NODE                 PHASE    GRACE  CONDITIONS
Apr 29 08:56:04.236: INFO: ss-0  0mfg0-worker-000001  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:54:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:55:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 08:54:53 +0000 UTC  }]
Apr 29 08:56:04.236: INFO: 
Apr 29 08:56:04.236: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-1949
Apr 29 08:56:05.240: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 29 08:56:05.351: INFO: rc: 1
Apr 29 08:56:05.352: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc0021cd0e0 exit status 1 <nil> <nil> true [0xc001c938c0 0xc001c938d8 0xc001c938f0] [0xc001c938c0 0xc001c938d8 0xc001c938f0] [0xc001c938d0 0xc001c938e8] [0x9bf9f0 0x9bf9f0] 0xc0028b3e00 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Apr 29 08:56:15.352: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 29 08:56:15.425: INFO: rc: 1
Apr 29 08:56:15.425: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0021cd440 exit status 1 <nil> <nil> true [0xc001c938f8 0xc001c93910 0xc001c93928] [0xc001c938f8 0xc001c93910 0xc001c93928] [0xc001c93908 0xc001c93920] [0x9bf9f0 0x9bf9f0] 0xc002608180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 29 08:56:25.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 29 08:56:25.503: INFO: rc: 1
Apr 29 08:56:25.503: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0021cd7a0 exit status 1 <nil> <nil> true [0xc001c93930 0xc001c93948 0xc001c93960] [0xc001c93930 0xc001c93948 0xc001c93960] [0xc001c93940 0xc001c93958] [0x9bf9f0 0x9bf9f0] 0xc002608600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 29 08:56:35.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 29 08:56:35.586: INFO: rc: 1
Apr 29 08:56:35.586: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc003254330 exit status 1 <nil> <nil> true [0xc000ffa098 0xc000ffa268 0xc000ffa460] [0xc000ffa098 0xc000ffa268 0xc000ffa460] [0xc000ffa198 0xc000ffa388] [0x9bf9f0 0x9bf9f0] 0xc002bd63c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 29 08:56:45.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 29 08:56:45.664: INFO: rc: 1
Apr 29 08:56:45.664: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002566300 exit status 1 <nil> <nil> true [0xc000010028 0xc0000104c8 0xc000010578] [0xc000010028 0xc0000104c8 0xc000010578] [0xc0000103e0 0xc000010548] [0x9bf9f0 0x9bf9f0] 0xc0028b2360 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 29 08:56:55.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 29 08:56:55.743: INFO: rc: 1
Apr 29 08:56:55.744: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002566660 exit status 1 <nil> <nil> true [0xc0000107e0 0xc000159c20 0xc000159cd8] [0xc0000107e0 0xc000159c20 0xc000159cd8] [0xc000158000 0xc000159ca0] [0x9bf9f0 0x9bf9f0] 0xc0028b2780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 29 08:57:05.744: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 29 08:57:05.826: INFO: rc: 1
Apr 29 08:57:05.826: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002566cf0 exit status 1 <nil> <nil> true [0xc000159e30 0xc0009961b8 0xc000996810] [0xc000159e30 0xc0009961b8 0xc000996810] [0xc000159f28 0xc0009967a0] [0x9bf9f0 0x9bf9f0] 0xc0028b2b40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 29 08:57:15.826: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 29 08:57:15.905: INFO: rc: 1
Apr 29 08:57:15.905: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0025670e0 exit status 1 <nil> <nil> true [0xc000996898 0xc0009969f8 0xc000996b48] [0xc000996898 0xc0009969f8 0xc000996b48] [0xc0009969c8 0xc000996ac8] [0x9bf9f0 0x9bf9f0] 0xc0028b2fc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 29 08:57:25.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 29 08:57:25.988: INFO: rc: 1
Apr 29 08:57:25.988: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc003254690 exit status 1 <nil> <nil> true [0xc000ffa5a0 0xc000ffa948 0xc000ffa9d0] [0xc000ffa5a0 0xc000ffa948 0xc000ffa9d0] [0xc000ffa868 0xc000ffa970] [0x9bf9f0 0x9bf9f0] 0xc002bd6ae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 29 08:57:35.988: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 29 08:57:36.067: INFO: rc: 1
Apr 29 08:57:36.068: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0032549f0 exit status 1 <nil> <nil> true [0xc000ffabf0 0xc000ffae00 0xc000ffaf78] [0xc000ffabf0 0xc000ffae00 0xc000ffaf78] [0xc000ffadb8 0xc000ffaec0] [0x9bf9f0 0x9bf9f0] 0xc002bd70e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 29 08:57:46.068: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 29 08:57:46.144: INFO: rc: 1
Apr 29 08:57:46.144: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc003254d50 exit status 1 <nil> <nil> true [0xc000ffaff0 0xc000ffb2f8 0xc000ffb5b8] [0xc000ffaff0 0xc000ffb2f8 0xc000ffb5b8] [0xc000ffb260 0xc000ffb528] [0x9bf9f0 0x9bf9f0] 0xc002bd76e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 29 08:57:56.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 29 08:57:56.220: INFO: rc: 1
Apr 29 08:57:56.220: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0032550b0 exit status 1 <nil> <nil> true [0xc000ffb5d8 0xc000ffb768 0xc000ffb828] [0xc000ffb5d8 0xc000ffb768 0xc000ffb828] [0xc000ffb728 0xc000ffb7d8] [0x9bf9f0 0x9bf9f0] 0xc002bd7c20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 29 08:58:06.220: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 29 08:58:06.302: INFO: rc: 1
Apr 29 08:58:06.302: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002567470 exit status 1 <nil> <nil> true [0xc000996ea8 0xc000997098 0xc0009971b0] [0xc000996ea8 0xc000997098 0xc0009971b0] [0xc000996f68 0xc000997118] [0x9bf9f0 0x9bf9f0] 0xc0028b3380 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 29 08:58:16.303: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 29 08:58:16.378: INFO: rc: 1
Apr 29 08:58:16.379: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc003255440 exit status 1 <nil> <nil> true [0xc000ffb848 0xc000ffb8f8 0xc000ffb958] [0xc000ffb848 0xc000ffb8f8 0xc000ffb958] [0xc000ffb8d8 0xc000ffb940] [0x9bf9f0 0x9bf9f0] 0xc0026720c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 29 08:58:26.379: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 29 08:58:26.451: INFO: rc: 1
Apr 29 08:58:26.451: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0032557a0 exit status 1 <nil> <nil> true [0xc000ffb960 0xc000ffb9c0 0xc000ffbbc0] [0xc000ffb960 0xc000ffb9c0 0xc000ffbbc0] [0xc000ffb9a0 0xc000ffba00] [0x9bf9f0 0x9bf9f0] 0xc002672480 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 29 08:58:36.452: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 29 08:58:36.540: INFO: rc: 1
Apr 29 08:58:36.540: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0025677a0 exit status 1 <nil> <nil> true [0xc000997388 0xc0009974b0 0xc000997798] [0xc000997388 0xc0009974b0 0xc000997798] [0xc000997408 0xc000997650] [0x9bf9f0 0x9bf9f0] 0xc0028b36e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 29 08:58:46.540: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 29 08:58:46.618: INFO: rc: 1
Apr 29 08:58:46.618: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002566330 exit status 1 <nil> <nil> true [0xc000158000 0xc000159ca0 0xc000159e88] [0xc000158000 0xc000159ca0 0xc000159e88] [0xc000159c70 0xc000159e30] [0x9bf9f0 0x9bf9f0] 0xc002bd63c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 29 08:58:56.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 29 08:58:56.697: INFO: rc: 1
Apr 29 08:58:56.697: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc003254360 exit status 1 <nil> <nil> true [0xc000010028 0xc0000104c8 0xc000010578] [0xc000010028 0xc0000104c8 0xc000010578] [0xc0000103e0 0xc000010548] [0x9bf9f0 0x9bf9f0] 0xc002672300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 29 08:59:06.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 29 08:59:06.771: INFO: rc: 1
Apr 29 08:59:06.772: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0032546f0 exit status 1 <nil> <nil> true [0xc0000107e0 0xc000ffa098 0xc000ffa268] [0xc0000107e0 0xc000ffa098 0xc000ffa268] [0xc000ffa008 0xc000ffa198] [0x9bf9f0 0x9bf9f0] 0xc0026726c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 29 08:59:16.772: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 29 08:59:16.859: INFO: rc: 1
Apr 29 08:59:16.859: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc003254a80 exit status 1 <nil> <nil> true [0xc000ffa338 0xc000ffa5a0 0xc000ffa948] [0xc000ffa338 0xc000ffa5a0 0xc000ffa948] [0xc000ffa460 0xc000ffa868] [0x9bf9f0 0x9bf9f0] 0xc002672a20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 29 08:59:26.859: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 29 08:59:26.934: INFO: rc: 1
Apr 29 08:59:26.934: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0025666c0 exit status 1 <nil> <nil> true [0xc000159f28 0xc0009967a0 0xc000996958] [0xc000159f28 0xc0009967a0 0xc000996958] [0xc000996778 0xc000996898] [0x9bf9f0 0x9bf9f0] 0xc002bd6ae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 29 08:59:36.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 29 08:59:37.017: INFO: rc: 1
Apr 29 08:59:37.018: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc003254e10 exit status 1 <nil> <nil> true [0xc000ffa960 0xc000ffabf0 0xc000ffae00] [0xc000ffa960 0xc000ffabf0 0xc000ffae00] [0xc000ffa9d0 0xc000ffadb8] [0x9bf9f0 0x9bf9f0] 0xc002672d80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 29 08:59:47.018: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 29 08:59:47.128: INFO: rc: 1
Apr 29 08:59:47.129: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0032551a0 exit status 1 <nil> <nil> true [0xc000ffae88 0xc000ffaff0 0xc000ffb2f8] [0xc000ffae88 0xc000ffaff0 0xc000ffb2f8] [0xc000ffaf78 0xc000ffb260] [0x9bf9f0 0x9bf9f0] 0xc0026730e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 29 08:59:57.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 29 08:59:57.246: INFO: rc: 1
Apr 29 08:59:57.246: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002566db0 exit status 1 <nil> <nil> true [0xc0009969c8 0xc000996ac8 0xc000996ef8] [0xc0009969c8 0xc000996ac8 0xc000996ef8] [0xc000996a70 0xc000996ea8] [0x9bf9f0 0x9bf9f0] 0xc002bd70e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 29 09:00:07.247: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 29 09:00:07.327: INFO: rc: 1
Apr 29 09:00:07.328: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc003255530 exit status 1 <nil> <nil> true [0xc000ffb4b8 0xc000ffb5d8 0xc000ffb768] [0xc000ffb4b8 0xc000ffb5d8 0xc000ffb768] [0xc000ffb5b8 0xc000ffb728] [0x9bf9f0 0x9bf9f0] 0xc002673440 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 29 09:00:17.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 29 09:00:17.423: INFO: rc: 1
Apr 29 09:00:17.423: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc003255890 exit status 1 <nil> <nil> true [0xc000ffb7a8 0xc000ffb848 0xc000ffb8f8] [0xc000ffb7a8 0xc000ffb848 0xc000ffb8f8] [0xc000ffb828 0xc000ffb8d8] [0x9bf9f0 0x9bf9f0] 0xc002673800 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 29 09:00:27.424: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 29 09:00:27.511: INFO: rc: 1
Apr 29 09:00:27.511: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc003255c20 exit status 1 <nil> <nil> true [0xc000ffb918 0xc000ffb960 0xc000ffb9c0] [0xc000ffb918 0xc000ffb960 0xc000ffb9c0] [0xc000ffb958 0xc000ffb9a0] [0x9bf9f0 0x9bf9f0] 0xc002673bc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 29 09:00:37.512: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 29 09:00:37.613: INFO: rc: 1
Apr 29 09:00:37.613: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc003255f50 exit status 1 <nil> <nil> true [0xc000ffba00 0xc000ffbbd8 0xc000ffbc40] [0xc000ffba00 0xc000ffbbd8 0xc000ffbc40] [0xc000ffbbc8 0xc000ffbc30] [0x9bf9f0 0x9bf9f0] 0xc002673f20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 29 09:00:47.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 29 09:00:47.692: INFO: rc: 1
Apr 29 09:00:47.692: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002566300 exit status 1 <nil> <nil> true [0xc000010028 0xc0000104c8 0xc000010578] [0xc000010028 0xc0000104c8 0xc000010578] [0xc0000103e0 0xc000010548] [0x9bf9f0 0x9bf9f0] 0xc002672300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 29 09:00:57.692: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 29 09:00:57.781: INFO: rc: 1
Apr 29 09:00:57.781: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc003254390 exit status 1 <nil> <nil> true [0xc000158000 0xc000159ca0 0xc000159e88] [0xc000158000 0xc000159ca0 0xc000159e88] [0xc000159c70 0xc000159e30] [0x9bf9f0 0x9bf9f0] 0xc002bd63c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 29 09:01:07.781: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-1949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 29 09:01:07.859: INFO: rc: 1
Apr 29 09:01:07.859: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: 
Apr 29 09:01:07.859: INFO: Scaling statefulset ss to 0
Apr 29 09:01:07.871: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr 29 09:01:07.875: INFO: Deleting all statefulset in ns statefulset-1949
Apr 29 09:01:07.879: INFO: Scaling statefulset ss to 0
Apr 29 09:01:07.888: INFO: Waiting for statefulset status.replicas updated to 0
Apr 29 09:01:07.893: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:01:07.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1949" for this suite.
Apr 29 09:01:13.943: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:01:14.099: INFO: namespace statefulset-1949 deletion completed in 6.174623421s

• [SLOW TEST:381.126 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:01:14.100: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-4351
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4351.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-4351.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4351.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-4351.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4351.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-4351.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4351.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-4351.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4351.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-4351.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4351.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-4351.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4351.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 209.251.31.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.31.251.209_udp@PTR;check="$$(dig +tcp +noall +answer +search 209.251.31.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.31.251.209_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4351.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-4351.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4351.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-4351.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4351.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-4351.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4351.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-4351.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4351.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-4351.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4351.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-4351.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4351.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 209.251.31.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.31.251.209_udp@PTR;check="$$(dig +tcp +noall +answer +search 209.251.31.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.31.251.209_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 29 09:01:44.434: INFO: Unable to read wheezy_udp@dns-test-service.dns-4351.svc.cluster.local from pod dns-4351/dns-test-577588c7-6a5d-11e9-b6b4-b219b18c41e8: the server could not find the requested resource (get pods dns-test-577588c7-6a5d-11e9-b6b4-b219b18c41e8)
Apr 29 09:01:44.438: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4351.svc.cluster.local from pod dns-4351/dns-test-577588c7-6a5d-11e9-b6b4-b219b18c41e8: the server could not find the requested resource (get pods dns-test-577588c7-6a5d-11e9-b6b4-b219b18c41e8)
Apr 29 09:01:44.442: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4351.svc.cluster.local from pod dns-4351/dns-test-577588c7-6a5d-11e9-b6b4-b219b18c41e8: the server could not find the requested resource (get pods dns-test-577588c7-6a5d-11e9-b6b4-b219b18c41e8)
Apr 29 09:01:44.446: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4351.svc.cluster.local from pod dns-4351/dns-test-577588c7-6a5d-11e9-b6b4-b219b18c41e8: the server could not find the requested resource (get pods dns-test-577588c7-6a5d-11e9-b6b4-b219b18c41e8)
Apr 29 09:01:44.478: INFO: Unable to read jessie_udp@dns-test-service.dns-4351.svc.cluster.local from pod dns-4351/dns-test-577588c7-6a5d-11e9-b6b4-b219b18c41e8: the server could not find the requested resource (get pods dns-test-577588c7-6a5d-11e9-b6b4-b219b18c41e8)
Apr 29 09:01:44.482: INFO: Unable to read jessie_tcp@dns-test-service.dns-4351.svc.cluster.local from pod dns-4351/dns-test-577588c7-6a5d-11e9-b6b4-b219b18c41e8: the server could not find the requested resource (get pods dns-test-577588c7-6a5d-11e9-b6b4-b219b18c41e8)
Apr 29 09:01:44.486: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4351.svc.cluster.local from pod dns-4351/dns-test-577588c7-6a5d-11e9-b6b4-b219b18c41e8: the server could not find the requested resource (get pods dns-test-577588c7-6a5d-11e9-b6b4-b219b18c41e8)
Apr 29 09:01:44.489: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4351.svc.cluster.local from pod dns-4351/dns-test-577588c7-6a5d-11e9-b6b4-b219b18c41e8: the server could not find the requested resource (get pods dns-test-577588c7-6a5d-11e9-b6b4-b219b18c41e8)
Apr 29 09:01:44.513: INFO: Lookups using dns-4351/dns-test-577588c7-6a5d-11e9-b6b4-b219b18c41e8 failed for: [wheezy_udp@dns-test-service.dns-4351.svc.cluster.local wheezy_tcp@dns-test-service.dns-4351.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4351.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4351.svc.cluster.local jessie_udp@dns-test-service.dns-4351.svc.cluster.local jessie_tcp@dns-test-service.dns-4351.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4351.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4351.svc.cluster.local]

Apr 29 09:01:49.591: INFO: DNS probes using dns-4351/dns-test-577588c7-6a5d-11e9-b6b4-b219b18c41e8 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:01:49.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4351" for this suite.
Apr 29 09:01:55.750: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:01:55.891: INFO: namespace dns-4351 deletion completed in 6.172210116s

• [SLOW TEST:41.791 seconds]
[sig-network] DNS
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:01:55.891: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-6625
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:69
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Registering the sample API server.
Apr 29 09:01:56.730: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Apr 29 09:01:58.827: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692125316, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692125316, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692125316, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692125316, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 29 09:02:00.831: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692125316, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692125316, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692125316, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692125316, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 29 09:02:02.831: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692125316, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692125316, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692125316, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692125316, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 29 09:02:04.843: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692125316, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692125316, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692125316, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692125316, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 29 09:02:06.832: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692125316, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692125316, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692125316, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692125316, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 29 09:02:08.831: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692125316, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692125316, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692125316, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692125316, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 29 09:02:10.831: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692125316, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692125316, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692125316, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692125316, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 29 09:02:12.832: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692125316, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692125316, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692125316, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692125316, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 29 09:02:15.960: INFO: Waited 1.124483663s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:60
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:02:16.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-6625" for this suite.
Apr 29 09:02:23.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:02:23.178: INFO: namespace aggregator-6625 deletion completed in 6.201775459s

• [SLOW TEST:27.287 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:02:23.179: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8897
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-809eaf81-6a5d-11e9-b6b4-b219b18c41e8
STEP: Creating a pod to test consume configMaps
Apr 29 09:02:23.407: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-809f4f0d-6a5d-11e9-b6b4-b219b18c41e8" in namespace "projected-8897" to be "success or failure"
Apr 29 09:02:23.417: INFO: Pod "pod-projected-configmaps-809f4f0d-6a5d-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 9.23783ms
Apr 29 09:02:25.420: INFO: Pod "pod-projected-configmaps-809f4f0d-6a5d-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012694667s
Apr 29 09:02:27.425: INFO: Pod "pod-projected-configmaps-809f4f0d-6a5d-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016874587s
STEP: Saw pod success
Apr 29 09:02:27.425: INFO: Pod "pod-projected-configmaps-809f4f0d-6a5d-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:02:27.428: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-projected-configmaps-809f4f0d-6a5d-11e9-b6b4-b219b18c41e8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 29 09:02:27.504: INFO: Waiting for pod pod-projected-configmaps-809f4f0d-6a5d-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:02:27.506: INFO: Pod pod-projected-configmaps-809f4f0d-6a5d-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:02:27.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8897" for this suite.
Apr 29 09:02:33.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:02:33.640: INFO: namespace projected-8897 deletion completed in 6.129338211s

• [SLOW TEST:10.461 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:02:33.641: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1119
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Apr 29 09:02:36.333: INFO: Successfully updated pod "pod-update-activedeadlineseconds-86d2a306-6a5d-11e9-b6b4-b219b18c41e8"
Apr 29 09:02:36.333: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-86d2a306-6a5d-11e9-b6b4-b219b18c41e8" in namespace "pods-1119" to be "terminated due to deadline exceeded"
Apr 29 09:02:36.338: INFO: Pod "pod-update-activedeadlineseconds-86d2a306-6a5d-11e9-b6b4-b219b18c41e8": Phase="Running", Reason="", readiness=true. Elapsed: 4.891015ms
Apr 29 09:02:38.342: INFO: Pod "pod-update-activedeadlineseconds-86d2a306-6a5d-11e9-b6b4-b219b18c41e8": Phase="Running", Reason="", readiness=true. Elapsed: 2.009250931s
Apr 29 09:02:40.346: INFO: Pod "pod-update-activedeadlineseconds-86d2a306-6a5d-11e9-b6b4-b219b18c41e8": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.013318126s
Apr 29 09:02:40.347: INFO: Pod "pod-update-activedeadlineseconds-86d2a306-6a5d-11e9-b6b4-b219b18c41e8" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:02:40.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1119" for this suite.
Apr 29 09:02:46.364: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:02:46.467: INFO: namespace pods-1119 deletion completed in 6.11474329s

• [SLOW TEST:12.826 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:02:46.467: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-4289
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 29 09:02:46.664: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Apr 29 09:02:46.681: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:02:46.683: INFO: Number of nodes with available pods: 0
Apr 29 09:02:46.684: INFO: Node 0mfg0-worker-000000 is running more than one daemon pod
Apr 29 09:02:47.689: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:02:47.694: INFO: Number of nodes with available pods: 0
Apr 29 09:02:47.694: INFO: Node 0mfg0-worker-000000 is running more than one daemon pod
Apr 29 09:02:48.689: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:02:48.693: INFO: Number of nodes with available pods: 0
Apr 29 09:02:48.693: INFO: Node 0mfg0-worker-000000 is running more than one daemon pod
Apr 29 09:02:49.688: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:02:49.692: INFO: Number of nodes with available pods: 2
Apr 29 09:02:49.692: INFO: Node 0mfg0-worker-000002 is running more than one daemon pod
Apr 29 09:02:50.692: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:02:50.697: INFO: Number of nodes with available pods: 3
Apr 29 09:02:50.698: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Apr 29 09:02:50.770: INFO: Wrong image for pod: daemon-set-ckf57. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:02:50.770: INFO: Wrong image for pod: daemon-set-fbfl9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:02:50.771: INFO: Wrong image for pod: daemon-set-k4hq9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:02:50.779: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:02:51.783: INFO: Wrong image for pod: daemon-set-ckf57. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:02:51.783: INFO: Wrong image for pod: daemon-set-fbfl9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:02:51.783: INFO: Wrong image for pod: daemon-set-k4hq9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:02:51.787: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:02:52.783: INFO: Wrong image for pod: daemon-set-ckf57. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:02:52.783: INFO: Wrong image for pod: daemon-set-fbfl9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:02:52.783: INFO: Wrong image for pod: daemon-set-k4hq9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:02:52.787: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:02:53.783: INFO: Wrong image for pod: daemon-set-ckf57. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:02:53.783: INFO: Wrong image for pod: daemon-set-fbfl9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:02:53.783: INFO: Wrong image for pod: daemon-set-k4hq9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:02:53.786: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:02:54.783: INFO: Wrong image for pod: daemon-set-ckf57. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:02:54.783: INFO: Wrong image for pod: daemon-set-fbfl9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:02:54.783: INFO: Wrong image for pod: daemon-set-k4hq9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:02:54.786: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:02:55.784: INFO: Wrong image for pod: daemon-set-ckf57. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:02:55.784: INFO: Pod daemon-set-ckf57 is not available
Apr 29 09:02:55.784: INFO: Wrong image for pod: daemon-set-fbfl9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:02:55.784: INFO: Wrong image for pod: daemon-set-k4hq9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:02:55.787: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:02:56.783: INFO: Wrong image for pod: daemon-set-ckf57. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:02:56.783: INFO: Pod daemon-set-ckf57 is not available
Apr 29 09:02:56.783: INFO: Wrong image for pod: daemon-set-fbfl9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:02:56.783: INFO: Wrong image for pod: daemon-set-k4hq9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:02:56.786: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:02:57.784: INFO: Wrong image for pod: daemon-set-ckf57. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:02:57.784: INFO: Pod daemon-set-ckf57 is not available
Apr 29 09:02:57.784: INFO: Wrong image for pod: daemon-set-fbfl9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:02:57.784: INFO: Wrong image for pod: daemon-set-k4hq9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:02:57.798: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:02:58.783: INFO: Wrong image for pod: daemon-set-ckf57. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:02:58.783: INFO: Pod daemon-set-ckf57 is not available
Apr 29 09:02:58.783: INFO: Wrong image for pod: daemon-set-fbfl9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:02:58.783: INFO: Wrong image for pod: daemon-set-k4hq9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:02:58.786: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:02:59.787: INFO: Wrong image for pod: daemon-set-ckf57. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:02:59.788: INFO: Pod daemon-set-ckf57 is not available
Apr 29 09:02:59.788: INFO: Wrong image for pod: daemon-set-fbfl9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:02:59.788: INFO: Wrong image for pod: daemon-set-k4hq9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:02:59.791: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:03:00.783: INFO: Wrong image for pod: daemon-set-ckf57. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:00.783: INFO: Pod daemon-set-ckf57 is not available
Apr 29 09:03:00.783: INFO: Wrong image for pod: daemon-set-fbfl9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:00.783: INFO: Wrong image for pod: daemon-set-k4hq9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:00.786: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:03:01.783: INFO: Wrong image for pod: daemon-set-fbfl9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:01.783: INFO: Wrong image for pod: daemon-set-k4hq9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:01.783: INFO: Pod daemon-set-qllh9 is not available
Apr 29 09:03:01.787: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:03:02.783: INFO: Wrong image for pod: daemon-set-fbfl9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:02.784: INFO: Wrong image for pod: daemon-set-k4hq9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:02.784: INFO: Pod daemon-set-qllh9 is not available
Apr 29 09:03:02.791: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:03:03.783: INFO: Wrong image for pod: daemon-set-fbfl9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:03.783: INFO: Wrong image for pod: daemon-set-k4hq9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:03.783: INFO: Pod daemon-set-qllh9 is not available
Apr 29 09:03:03.787: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:03:04.783: INFO: Wrong image for pod: daemon-set-fbfl9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:04.783: INFO: Wrong image for pod: daemon-set-k4hq9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:04.783: INFO: Pod daemon-set-qllh9 is not available
Apr 29 09:03:04.788: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:03:05.783: INFO: Wrong image for pod: daemon-set-fbfl9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:05.783: INFO: Wrong image for pod: daemon-set-k4hq9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:05.783: INFO: Pod daemon-set-qllh9 is not available
Apr 29 09:03:05.787: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:03:06.783: INFO: Wrong image for pod: daemon-set-fbfl9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:06.783: INFO: Wrong image for pod: daemon-set-k4hq9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:06.783: INFO: Pod daemon-set-qllh9 is not available
Apr 29 09:03:06.826: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:03:07.783: INFO: Wrong image for pod: daemon-set-fbfl9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:07.783: INFO: Wrong image for pod: daemon-set-k4hq9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:07.787: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:03:08.783: INFO: Wrong image for pod: daemon-set-fbfl9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:08.783: INFO: Wrong image for pod: daemon-set-k4hq9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:08.783: INFO: Pod daemon-set-k4hq9 is not available
Apr 29 09:03:08.787: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:03:09.783: INFO: Wrong image for pod: daemon-set-fbfl9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:09.783: INFO: Wrong image for pod: daemon-set-k4hq9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:09.783: INFO: Pod daemon-set-k4hq9 is not available
Apr 29 09:03:09.787: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:03:10.783: INFO: Wrong image for pod: daemon-set-fbfl9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:10.783: INFO: Wrong image for pod: daemon-set-k4hq9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:10.783: INFO: Pod daemon-set-k4hq9 is not available
Apr 29 09:03:10.786: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:03:11.784: INFO: Wrong image for pod: daemon-set-fbfl9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:11.784: INFO: Wrong image for pod: daemon-set-k4hq9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:11.784: INFO: Pod daemon-set-k4hq9 is not available
Apr 29 09:03:11.787: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:03:12.783: INFO: Wrong image for pod: daemon-set-fbfl9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:12.783: INFO: Wrong image for pod: daemon-set-k4hq9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:12.783: INFO: Pod daemon-set-k4hq9 is not available
Apr 29 09:03:12.786: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:03:13.783: INFO: Wrong image for pod: daemon-set-fbfl9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:13.783: INFO: Wrong image for pod: daemon-set-k4hq9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:13.783: INFO: Pod daemon-set-k4hq9 is not available
Apr 29 09:03:13.787: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:03:14.783: INFO: Wrong image for pod: daemon-set-fbfl9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:14.783: INFO: Wrong image for pod: daemon-set-k4hq9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:14.783: INFO: Pod daemon-set-k4hq9 is not available
Apr 29 09:03:14.787: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:03:15.784: INFO: Wrong image for pod: daemon-set-fbfl9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:15.784: INFO: Wrong image for pod: daemon-set-k4hq9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:15.784: INFO: Pod daemon-set-k4hq9 is not available
Apr 29 09:03:15.788: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:03:16.790: INFO: Wrong image for pod: daemon-set-fbfl9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:16.790: INFO: Wrong image for pod: daemon-set-k4hq9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:16.790: INFO: Pod daemon-set-k4hq9 is not available
Apr 29 09:03:16.794: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:03:17.783: INFO: Wrong image for pod: daemon-set-fbfl9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:17.783: INFO: Wrong image for pod: daemon-set-k4hq9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:17.783: INFO: Pod daemon-set-k4hq9 is not available
Apr 29 09:03:17.789: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:03:18.783: INFO: Wrong image for pod: daemon-set-fbfl9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:18.783: INFO: Wrong image for pod: daemon-set-k4hq9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:18.783: INFO: Pod daemon-set-k4hq9 is not available
Apr 29 09:03:18.787: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:03:19.788: INFO: Pod daemon-set-f5n7l is not available
Apr 29 09:03:19.788: INFO: Wrong image for pod: daemon-set-fbfl9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:19.792: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:03:20.787: INFO: Pod daemon-set-f5n7l is not available
Apr 29 09:03:20.787: INFO: Wrong image for pod: daemon-set-fbfl9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:20.793: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:03:21.783: INFO: Pod daemon-set-f5n7l is not available
Apr 29 09:03:21.783: INFO: Wrong image for pod: daemon-set-fbfl9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:21.787: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:03:22.783: INFO: Pod daemon-set-f5n7l is not available
Apr 29 09:03:22.783: INFO: Wrong image for pod: daemon-set-fbfl9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:22.788: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:03:23.790: INFO: Wrong image for pod: daemon-set-fbfl9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:23.795: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:03:24.783: INFO: Wrong image for pod: daemon-set-fbfl9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:24.787: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:03:25.783: INFO: Wrong image for pod: daemon-set-fbfl9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:25.783: INFO: Pod daemon-set-fbfl9 is not available
Apr 29 09:03:25.787: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:03:26.784: INFO: Wrong image for pod: daemon-set-fbfl9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:26.784: INFO: Pod daemon-set-fbfl9 is not available
Apr 29 09:03:26.788: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:03:27.783: INFO: Wrong image for pod: daemon-set-fbfl9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:27.783: INFO: Pod daemon-set-fbfl9 is not available
Apr 29 09:03:27.787: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:03:28.783: INFO: Wrong image for pod: daemon-set-fbfl9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:28.783: INFO: Pod daemon-set-fbfl9 is not available
Apr 29 09:03:28.789: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:03:29.798: INFO: Wrong image for pod: daemon-set-fbfl9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:29.798: INFO: Pod daemon-set-fbfl9 is not available
Apr 29 09:03:29.801: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:03:30.783: INFO: Wrong image for pod: daemon-set-fbfl9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:30.783: INFO: Pod daemon-set-fbfl9 is not available
Apr 29 09:03:30.786: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:03:31.783: INFO: Wrong image for pod: daemon-set-fbfl9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:31.783: INFO: Pod daemon-set-fbfl9 is not available
Apr 29 09:03:31.788: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:03:32.783: INFO: Wrong image for pod: daemon-set-fbfl9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:32.784: INFO: Pod daemon-set-fbfl9 is not available
Apr 29 09:03:32.794: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:03:33.783: INFO: Wrong image for pod: daemon-set-fbfl9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:33.783: INFO: Pod daemon-set-fbfl9 is not available
Apr 29 09:03:33.787: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:03:34.783: INFO: Wrong image for pod: daemon-set-fbfl9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:34.783: INFO: Pod daemon-set-fbfl9 is not available
Apr 29 09:03:34.786: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:03:35.782: INFO: Wrong image for pod: daemon-set-fbfl9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:35.782: INFO: Pod daemon-set-fbfl9 is not available
Apr 29 09:03:35.787: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:03:36.783: INFO: Wrong image for pod: daemon-set-fbfl9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 29 09:03:36.783: INFO: Pod daemon-set-fbfl9 is not available
Apr 29 09:03:36.787: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:03:37.783: INFO: Pod daemon-set-c22zm is not available
Apr 29 09:03:37.790: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Apr 29 09:03:37.800: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:03:37.805: INFO: Number of nodes with available pods: 2
Apr 29 09:03:37.805: INFO: Node 0mfg0-worker-000001 is running more than one daemon pod
Apr 29 09:03:38.810: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:03:38.818: INFO: Number of nodes with available pods: 2
Apr 29 09:03:38.818: INFO: Node 0mfg0-worker-000001 is running more than one daemon pod
Apr 29 09:03:39.810: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:03:39.813: INFO: Number of nodes with available pods: 3
Apr 29 09:03:39.813: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4289, will wait for the garbage collector to delete the pods
Apr 29 09:03:39.894: INFO: Deleting DaemonSet.extensions daemon-set took: 7.666522ms
Apr 29 09:03:40.004: INFO: Terminating DaemonSet.extensions daemon-set pods took: 109.529514ms
Apr 29 09:03:43.807: INFO: Number of nodes with available pods: 0
Apr 29 09:03:43.807: INFO: Number of running nodes: 0, number of available pods: 0
Apr 29 09:03:43.810: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4289/daemonsets","resourceVersion":"5154"},"items":null}

Apr 29 09:03:43.812: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4289/pods","resourceVersion":"5154"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:03:43.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4289" for this suite.
Apr 29 09:03:49.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:03:49.965: INFO: namespace daemonsets-4289 deletion completed in 6.136765835s

• [SLOW TEST:63.498 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:03:49.965: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8743
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating cluster-info
Apr 29 09:03:50.117: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 cluster-info'
Apr 29 09:03:50.208: INFO: stderr: ""
Apr 29 09:03:50.208: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://172.31.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://172.31.0.1:443/api/v1/namespaces/kube-system/services/coredns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:03:50.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8743" for this suite.
Apr 29 09:03:56.228: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:03:56.341: INFO: namespace kubectl-8743 deletion completed in 6.128010347s

• [SLOW TEST:6.375 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:03:56.341: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-7148
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 29 09:03:56.503: INFO: Creating deployment "nginx-deployment"
Apr 29 09:03:56.511: INFO: Waiting for observed generation 1
Apr 29 09:03:58.531: INFO: Waiting for all required pods to come up
Apr 29 09:03:58.535: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Apr 29 09:04:06.566: INFO: Waiting for deployment "nginx-deployment" to complete
Apr 29 09:04:06.571: INFO: Updating deployment "nginx-deployment" with a non-existent image
Apr 29 09:04:06.583: INFO: Updating deployment nginx-deployment
Apr 29 09:04:06.583: INFO: Waiting for observed generation 2
Apr 29 09:04:08.601: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Apr 29 09:04:08.604: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Apr 29 09:04:08.606: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Apr 29 09:04:08.614: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Apr 29 09:04:08.614: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Apr 29 09:04:08.617: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Apr 29 09:04:08.621: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Apr 29 09:04:08.621: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Apr 29 09:04:08.629: INFO: Updating deployment nginx-deployment
Apr 29 09:04:08.629: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Apr 29 09:04:08.705: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Apr 29 09:04:08.820: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr 29 09:04:10.902: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-7148,SelfLink:/apis/apps/v1/namespaces/deployment-7148/deployments/nginx-deployment,UID:b81f1b07-6a5d-11e9-9890-000d3a4710ea,ResourceVersion:5523,Generation:3,CreationTimestamp:2019-04-29 09:03:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-04-29 09:04:08 +0000 UTC 2019-04-29 09:04:08 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-04-29 09:04:08 +0000 UTC 2019-04-29 09:03:56 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-5f9595f595" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Apr 29 09:04:10.908: INFO: New ReplicaSet "nginx-deployment-5f9595f595" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595,GenerateName:,Namespace:deployment-7148,SelfLink:/apis/apps/v1/namespaces/deployment-7148/replicasets/nginx-deployment-5f9595f595,UID:be2076fa-6a5d-11e9-9890-000d3a4710ea,ResourceVersion:5513,Generation:3,CreationTimestamp:2019-04-29 09:04:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment b81f1b07-6a5d-11e9-9890-000d3a4710ea 0xc002c4f297 0xc002c4f298}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 29 09:04:10.908: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Apr 29 09:04:10.908: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8,GenerateName:,Namespace:deployment-7148,SelfLink:/apis/apps/v1/namespaces/deployment-7148/replicasets/nginx-deployment-6f478d8d8,UID:b821ce66-6a5d-11e9-9890-000d3a4710ea,ResourceVersion:5518,Generation:3,CreationTimestamp:2019-04-29 09:03:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment b81f1b07-6a5d-11e9-9890-000d3a4710ea 0xc002c4f367 0xc002c4f368}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Apr 29 09:04:10.915: INFO: Pod "nginx-deployment-5f9595f595-7rjnh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-7rjnh,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-7148,SelfLink:/api/v1/namespaces/deployment-7148/pods/nginx-deployment-5f9595f595-7rjnh,UID:bf639a62-6a5d-11e9-9890-000d3a4710ea,ResourceVersion:5520,Generation:0,CreationTimestamp:2019-04-29 09:04:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 be2076fa-6a5d-11e9-9890-000d3a4710ea 0xc002c4fc90 0xc002c4fc91}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-7gd7m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7gd7m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7gd7m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:0mfg0-worker-000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c4fd00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c4fd20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.5,PodIP:,StartTime:2019-04-29 09:04:08 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 29 09:04:10.915: INFO: Pod "nginx-deployment-5f9595f595-b27dr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-b27dr,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-7148,SelfLink:/api/v1/namespaces/deployment-7148/pods/nginx-deployment-5f9595f595-b27dr,UID:be273299-6a5d-11e9-9890-000d3a4710ea,ResourceVersion:5570,Generation:0,CreationTimestamp:2019-04-29 09:04:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.130.22/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 be2076fa-6a5d-11e9-9890-000d3a4710ea 0xc002c4fe00 0xc002c4fe01}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-7gd7m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7gd7m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7gd7m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:0mfg0-worker-000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c4fe70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c4fe90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:06 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.5,PodIP:10.2.130.22,StartTime:2019-04-29 09:04:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 29 09:04:10.915: INFO: Pod "nginx-deployment-5f9595f595-b4jvn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-b4jvn,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-7148,SelfLink:/api/v1/namespaces/deployment-7148/pods/nginx-deployment-5f9595f595-b4jvn,UID:bf77cb65-6a5d-11e9-9890-000d3a4710ea,ResourceVersion:5562,Generation:0,CreationTimestamp:2019-04-29 09:04:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 be2076fa-6a5d-11e9-9890-000d3a4710ea 0xc002c4ff80 0xc002c4ff81}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-7gd7m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7gd7m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7gd7m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:0mfg0-worker-000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c4fff0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002892050}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.5,PodIP:,StartTime:2019-04-29 09:04:08 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 29 09:04:10.916: INFO: Pod "nginx-deployment-5f9595f595-b59pt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-b59pt,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-7148,SelfLink:/api/v1/namespaces/deployment-7148/pods/nginx-deployment-5f9595f595-b59pt,UID:bf6d8bd3-6a5d-11e9-9890-000d3a4710ea,ResourceVersion:5497,Generation:0,CreationTimestamp:2019-04-29 09:04:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 be2076fa-6a5d-11e9-9890-000d3a4710ea 0xc002892170 0xc002892171}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-7gd7m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7gd7m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7gd7m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:0mfg0-worker-000002,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002892260} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002892280}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 29 09:04:10.916: INFO: Pod "nginx-deployment-5f9595f595-dg2w8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-dg2w8,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-7148,SelfLink:/api/v1/namespaces/deployment-7148/pods/nginx-deployment-5f9595f595-dg2w8,UID:bf5e4147-6a5d-11e9-9890-000d3a4710ea,ResourceVersion:5571,Generation:0,CreationTimestamp:2019-04-29 09:04:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 be2076fa-6a5d-11e9-9890-000d3a4710ea 0xc002892350 0xc002892351}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-7gd7m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7gd7m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7gd7m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:0mfg0-worker-000002,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002892460} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002892480}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.6,PodIP:,StartTime:2019-04-29 09:04:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 29 09:04:10.916: INFO: Pod "nginx-deployment-5f9595f595-ffrrl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-ffrrl,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-7148,SelfLink:/api/v1/namespaces/deployment-7148/pods/nginx-deployment-5f9595f595-ffrrl,UID:be280910-6a5d-11e9-9890-000d3a4710ea,ResourceVersion:5426,Generation:0,CreationTimestamp:2019-04-29 09:04:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 be2076fa-6a5d-11e9-9890-000d3a4710ea 0xc0028925d0 0xc0028925d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-7gd7m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7gd7m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7gd7m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:0mfg0-worker-000002,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002892690} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028926c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:06 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.6,PodIP:,StartTime:2019-04-29 09:04:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 29 09:04:10.916: INFO: Pod "nginx-deployment-5f9595f595-g6pfq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-g6pfq,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-7148,SelfLink:/api/v1/namespaces/deployment-7148/pods/nginx-deployment-5f9595f595-g6pfq,UID:be367417-6a5d-11e9-9890-000d3a4710ea,ResourceVersion:5452,Generation:0,CreationTimestamp:2019-04-29 09:04:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.130.23/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 be2076fa-6a5d-11e9-9890-000d3a4710ea 0xc002892810 0xc002892811}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-7gd7m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7gd7m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7gd7m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:0mfg0-worker-000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028928c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028928e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:06 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.5,PodIP:,StartTime:2019-04-29 09:04:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 29 09:04:10.916: INFO: Pod "nginx-deployment-5f9595f595-gtxcg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-gtxcg,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-7148,SelfLink:/api/v1/namespaces/deployment-7148/pods/nginx-deployment-5f9595f595-gtxcg,UID:bf6ceeef-6a5d-11e9-9890-000d3a4710ea,ResourceVersion:5539,Generation:0,CreationTimestamp:2019-04-29 09:04:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 be2076fa-6a5d-11e9-9890-000d3a4710ea 0xc002892aa0 0xc002892aa1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-7gd7m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7gd7m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7gd7m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:0mfg0-worker-000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002892b60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002892b80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.4,PodIP:,StartTime:2019-04-29 09:04:08 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 29 09:04:10.917: INFO: Pod "nginx-deployment-5f9595f595-hpxfp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-hpxfp,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-7148,SelfLink:/api/v1/namespaces/deployment-7148/pods/nginx-deployment-5f9595f595-hpxfp,UID:bf645532-6a5d-11e9-9890-000d3a4710ea,ResourceVersion:5533,Generation:0,CreationTimestamp:2019-04-29 09:04:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 be2076fa-6a5d-11e9-9890-000d3a4710ea 0xc002892c50 0xc002892c51}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-7gd7m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7gd7m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7gd7m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:0mfg0-worker-000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002892cc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002892ce0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.4,PodIP:,StartTime:2019-04-29 09:04:08 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 29 09:04:10.917: INFO: Pod "nginx-deployment-5f9595f595-rt9jd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-rt9jd,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-7148,SelfLink:/api/v1/namespaces/deployment-7148/pods/nginx-deployment-5f9595f595-rt9jd,UID:be3d0305-6a5d-11e9-9890-000d3a4710ea,ResourceVersion:5454,Generation:0,CreationTimestamp:2019-04-29 09:04:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.131.22/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 be2076fa-6a5d-11e9-9890-000d3a4710ea 0xc002892dc0 0xc002892dc1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-7gd7m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7gd7m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7gd7m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:0mfg0-worker-000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002892e30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002892e50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:06 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.4,PodIP:,StartTime:2019-04-29 09:04:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 29 09:04:10.918: INFO: Pod "nginx-deployment-5f9595f595-tp5c4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-tp5c4,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-7148,SelfLink:/api/v1/namespaces/deployment-7148/pods/nginx-deployment-5f9595f595-tp5c4,UID:bf6dd170-6a5d-11e9-9890-000d3a4710ea,ResourceVersion:5532,Generation:0,CreationTimestamp:2019-04-29 09:04:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 be2076fa-6a5d-11e9-9890-000d3a4710ea 0xc002892f20 0xc002892f21}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-7gd7m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7gd7m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7gd7m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:0mfg0-worker-000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002892f90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002892fb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.5,PodIP:,StartTime:2019-04-29 09:04:08 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 29 09:04:10.919: INFO: Pod "nginx-deployment-5f9595f595-wpnd8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-wpnd8,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-7148,SelfLink:/api/v1/namespaces/deployment-7148/pods/nginx-deployment-5f9595f595-wpnd8,UID:be22a9b3-6a5d-11e9-9890-000d3a4710ea,ResourceVersion:5448,Generation:0,CreationTimestamp:2019-04-29 09:04:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.131.21/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 be2076fa-6a5d-11e9-9890-000d3a4710ea 0xc002893090 0xc002893091}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-7gd7m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7gd7m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7gd7m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:0mfg0-worker-000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002893100} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002893120}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:06 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.4,PodIP:,StartTime:2019-04-29 09:04:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 29 09:04:10.920: INFO: Pod "nginx-deployment-5f9595f595-zjrf9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-zjrf9,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-7148,SelfLink:/api/v1/namespaces/deployment-7148/pods/nginx-deployment-5f9595f595-zjrf9,UID:bf6c6535-6a5d-11e9-9890-000d3a4710ea,ResourceVersion:5494,Generation:0,CreationTimestamp:2019-04-29 09:04:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 be2076fa-6a5d-11e9-9890-000d3a4710ea 0xc0028931f0 0xc0028931f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-7gd7m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7gd7m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7gd7m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:0mfg0-worker-000002,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002893260} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002893280}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 29 09:04:10.920: INFO: Pod "nginx-deployment-6f478d8d8-4n9f8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-4n9f8,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-7148,SelfLink:/api/v1/namespaces/deployment-7148/pods/nginx-deployment-6f478d8d8-4n9f8,UID:bf682dd9-6a5d-11e9-9890-000d3a4710ea,ResourceVersion:5548,Generation:0,CreationTimestamp:2019-04-29 09:04:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 b821ce66-6a5d-11e9-9890-000d3a4710ea 0xc0028933b0 0xc0028933b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-7gd7m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7gd7m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7gd7m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:0mfg0-worker-000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002893460} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028934b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.4,PodIP:,StartTime:2019-04-29 09:04:08 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 29 09:04:10.921: INFO: Pod "nginx-deployment-6f478d8d8-64hh2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-64hh2,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-7148,SelfLink:/api/v1/namespaces/deployment-7148/pods/nginx-deployment-6f478d8d8-64hh2,UID:bf6716ed-6a5d-11e9-9890-000d3a4710ea,ResourceVersion:5491,Generation:0,CreationTimestamp:2019-04-29 09:04:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 b821ce66-6a5d-11e9-9890-000d3a4710ea 0xc0028935e0 0xc0028935e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-7gd7m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7gd7m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7gd7m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:0mfg0-worker-000002,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002893660} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028936a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 29 09:04:10.921: INFO: Pod "nginx-deployment-6f478d8d8-6hjzh" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-6hjzh,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-7148,SelfLink:/api/v1/namespaces/deployment-7148/pods/nginx-deployment-6f478d8d8-6hjzh,UID:b831c448-6a5d-11e9-9890-000d3a4710ea,ResourceVersion:5343,Generation:0,CreationTimestamp:2019-04-29 09:03:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.131.20/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 b821ce66-6a5d-11e9-9890-000d3a4710ea 0xc002893750 0xc002893751}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-7gd7m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7gd7m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7gd7m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:0mfg0-worker-000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028937b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002893800}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:03:56 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:03:59 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:03:59 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:03:56 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.4,PodIP:10.2.131.20,StartTime:2019-04-29 09:03:56 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-29 09:03:59 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://707c35e03ddc05ae2a7309b3ff0ea4ef35ae0aa3165b99965eb8a8767f844335}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 29 09:04:10.921: INFO: Pod "nginx-deployment-6f478d8d8-7hhmx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-7hhmx,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-7148,SelfLink:/api/v1/namespaces/deployment-7148/pods/nginx-deployment-6f478d8d8-7hhmx,UID:bf6573c3-6a5d-11e9-9890-000d3a4710ea,ResourceVersion:5528,Generation:0,CreationTimestamp:2019-04-29 09:04:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 b821ce66-6a5d-11e9-9890-000d3a4710ea 0xc002893a10 0xc002893a11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-7gd7m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7gd7m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7gd7m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:0mfg0-worker-000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002893aa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002893ac0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.5,PodIP:,StartTime:2019-04-29 09:04:08 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 29 09:04:10.922: INFO: Pod "nginx-deployment-6f478d8d8-7wrpq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-7wrpq,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-7148,SelfLink:/api/v1/namespaces/deployment-7148/pods/nginx-deployment-6f478d8d8-7wrpq,UID:bf5fceaf-6a5d-11e9-9890-000d3a4710ea,ResourceVersion:5504,Generation:0,CreationTimestamp:2019-04-29 09:04:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 b821ce66-6a5d-11e9-9890-000d3a4710ea 0xc002893bd0 0xc002893bd1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-7gd7m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7gd7m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7gd7m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:0mfg0-worker-000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002893c30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002893ca0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.5,PodIP:,StartTime:2019-04-29 09:04:08 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 29 09:04:10.922: INFO: Pod "nginx-deployment-6f478d8d8-9jlzm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-9jlzm,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-7148,SelfLink:/api/v1/namespaces/deployment-7148/pods/nginx-deployment-6f478d8d8-9jlzm,UID:bf750644-6a5d-11e9-9890-000d3a4710ea,ResourceVersion:5512,Generation:0,CreationTimestamp:2019-04-29 09:04:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 b821ce66-6a5d-11e9-9890-000d3a4710ea 0xc002893e20 0xc002893e21}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-7gd7m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7gd7m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7gd7m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:0mfg0-worker-000002,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002893ee0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002893f00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 29 09:04:10.922: INFO: Pod "nginx-deployment-6f478d8d8-bwf6r" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-bwf6r,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-7148,SelfLink:/api/v1/namespaces/deployment-7148/pods/nginx-deployment-6f478d8d8-bwf6r,UID:b8322aac-6a5d-11e9-9890-000d3a4710ea,ResourceVersion:5390,Generation:0,CreationTimestamp:2019-04-29 09:03:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.129.17/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 b821ce66-6a5d-11e9-9890-000d3a4710ea 0xc002893fc0 0xc002893fc1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-7gd7m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7gd7m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7gd7m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:0mfg0-worker-000002,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002424020} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002424040}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:03:56 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:06 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:06 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:03:56 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.6,PodIP:10.2.129.17,StartTime:2019-04-29 09:03:56 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-29 09:04:05 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://b7cb67d52a8a06740e35d0e998387fbdeeaa9a789baf048b0401a1f29991a845}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 29 09:04:10.926: INFO: Pod "nginx-deployment-6f478d8d8-d48f2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-d48f2,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-7148,SelfLink:/api/v1/namespaces/deployment-7148/pods/nginx-deployment-6f478d8d8-d48f2,UID:b82d0eec-6a5d-11e9-9890-000d3a4710ea,ResourceVersion:5346,Generation:0,CreationTimestamp:2019-04-29 09:03:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.131.19/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 b821ce66-6a5d-11e9-9890-000d3a4710ea 0xc002424120 0xc002424121}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-7gd7m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7gd7m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7gd7m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:0mfg0-worker-000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002424180} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024241a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:03:56 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:03:59 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:03:59 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:03:56 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.4,PodIP:10.2.131.19,StartTime:2019-04-29 09:03:56 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-29 09:03:59 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://d7bfd07301e0dbae3deb0acfa5e13b50ee884ebd10469c89be7d9be24deaf0a7}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 29 09:04:10.927: INFO: Pod "nginx-deployment-6f478d8d8-g77vw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-g77vw,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-7148,SelfLink:/api/v1/namespaces/deployment-7148/pods/nginx-deployment-6f478d8d8-g77vw,UID:bf730816-6a5d-11e9-9890-000d3a4710ea,ResourceVersion:5553,Generation:0,CreationTimestamp:2019-04-29 09:04:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 b821ce66-6a5d-11e9-9890-000d3a4710ea 0xc002424270 0xc002424271}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-7gd7m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7gd7m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7gd7m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:0mfg0-worker-000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024242d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024242f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.4,PodIP:,StartTime:2019-04-29 09:04:08 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 29 09:04:10.927: INFO: Pod "nginx-deployment-6f478d8d8-gqx27" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-gqx27,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-7148,SelfLink:/api/v1/namespaces/deployment-7148/pods/nginx-deployment-6f478d8d8-gqx27,UID:b8289a3a-6a5d-11e9-9890-000d3a4710ea,ResourceVersion:5349,Generation:0,CreationTimestamp:2019-04-29 09:03:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.131.18/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 b821ce66-6a5d-11e9-9890-000d3a4710ea 0xc0024243c0 0xc0024243c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-7gd7m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7gd7m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7gd7m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:0mfg0-worker-000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002424420} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002424440}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:03:56 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:03:59 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:03:59 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:03:56 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.4,PodIP:10.2.131.18,StartTime:2019-04-29 09:03:56 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-29 09:03:59 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://f30c33c0e33cb517c8226a31494a2e22d2fd25b69497defbcd3c5380606ecf8d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 29 09:04:10.927: INFO: Pod "nginx-deployment-6f478d8d8-jrzwq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-jrzwq,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-7148,SelfLink:/api/v1/namespaces/deployment-7148/pods/nginx-deployment-6f478d8d8-jrzwq,UID:bf6500b9-6a5d-11e9-9890-000d3a4710ea,ResourceVersion:5576,Generation:0,CreationTimestamp:2019-04-29 09:04:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 b821ce66-6a5d-11e9-9890-000d3a4710ea 0xc002424510 0xc002424511}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-7gd7m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7gd7m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7gd7m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:0mfg0-worker-000002,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002424570} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002424590}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.6,PodIP:,StartTime:2019-04-29 09:04:10 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 29 09:04:10.928: INFO: Pod "nginx-deployment-6f478d8d8-kp8nm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-kp8nm,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-7148,SelfLink:/api/v1/namespaces/deployment-7148/pods/nginx-deployment-6f478d8d8-kp8nm,UID:bf5feaca-6a5d-11e9-9890-000d3a4710ea,ResourceVersion:5503,Generation:0,CreationTimestamp:2019-04-29 09:04:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 b821ce66-6a5d-11e9-9890-000d3a4710ea 0xc002424650 0xc002424651}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-7gd7m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7gd7m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7gd7m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:0mfg0-worker-000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024246b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024246d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.4,PodIP:,StartTime:2019-04-29 09:04:08 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 29 09:04:10.928: INFO: Pod "nginx-deployment-6f478d8d8-lzlb5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-lzlb5,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-7148,SelfLink:/api/v1/namespaces/deployment-7148/pods/nginx-deployment-6f478d8d8-lzlb5,UID:bf75b5bb-6a5d-11e9-9890-000d3a4710ea,ResourceVersion:5517,Generation:0,CreationTimestamp:2019-04-29 09:04:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 b821ce66-6a5d-11e9-9890-000d3a4710ea 0xc002424790 0xc002424791}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-7gd7m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7gd7m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7gd7m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:0mfg0-worker-000002,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024247f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002424810}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 29 09:04:10.928: INFO: Pod "nginx-deployment-6f478d8d8-nkbzz" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-nkbzz,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-7148,SelfLink:/api/v1/namespaces/deployment-7148/pods/nginx-deployment-6f478d8d8-nkbzz,UID:b825e329-6a5d-11e9-9890-000d3a4710ea,ResourceVersion:5336,Generation:0,CreationTimestamp:2019-04-29 09:03:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.130.19/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 b821ce66-6a5d-11e9-9890-000d3a4710ea 0xc0024248a0 0xc0024248a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-7gd7m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7gd7m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7gd7m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:0mfg0-worker-000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002424900} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002424920}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:03:56 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:03:59 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:03:59 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:03:56 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.5,PodIP:10.2.130.19,StartTime:2019-04-29 09:03:56 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-29 09:03:58 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://f005eb5c621b242aa4d967c69b523c214ff21c57dd2347148709c74dee828c1b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 29 09:04:10.928: INFO: Pod "nginx-deployment-6f478d8d8-r8fbz" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-r8fbz,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-7148,SelfLink:/api/v1/namespaces/deployment-7148/pods/nginx-deployment-6f478d8d8-r8fbz,UID:b82caa85-6a5d-11e9-9890-000d3a4710ea,ResourceVersion:5340,Generation:0,CreationTimestamp:2019-04-29 09:03:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.130.20/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 b821ce66-6a5d-11e9-9890-000d3a4710ea 0xc002424a00 0xc002424a01}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-7gd7m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7gd7m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7gd7m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:0mfg0-worker-000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002424a60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002424a80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:03:56 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:03:59 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:03:59 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:03:56 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.5,PodIP:10.2.130.20,StartTime:2019-04-29 09:03:56 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-29 09:03:58 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://390730999f256318ccd94c842865813c806b0002f11d2ff23671821fd91d6a49}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 29 09:04:10.928: INFO: Pod "nginx-deployment-6f478d8d8-slwqx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-slwqx,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-7148,SelfLink:/api/v1/namespaces/deployment-7148/pods/nginx-deployment-6f478d8d8-slwqx,UID:bf5be743-6a5d-11e9-9890-000d3a4710ea,ResourceVersion:5478,Generation:0,CreationTimestamp:2019-04-29 09:04:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 b821ce66-6a5d-11e9-9890-000d3a4710ea 0xc002424b50 0xc002424b51}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-7gd7m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7gd7m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7gd7m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:0mfg0-worker-000002,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002424bb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002424bd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.6,PodIP:,StartTime:2019-04-29 09:04:08 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 29 09:04:10.929: INFO: Pod "nginx-deployment-6f478d8d8-wb59b" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-wb59b,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-7148,SelfLink:/api/v1/namespaces/deployment-7148/pods/nginx-deployment-6f478d8d8-wb59b,UID:bf749aab-6a5d-11e9-9890-000d3a4710ea,ResourceVersion:5542,Generation:0,CreationTimestamp:2019-04-29 09:04:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 b821ce66-6a5d-11e9-9890-000d3a4710ea 0xc002424c90 0xc002424c91}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-7gd7m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7gd7m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7gd7m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:0mfg0-worker-000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002424d30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002424d50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.5,PodIP:,StartTime:2019-04-29 09:04:08 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 29 09:04:10.929: INFO: Pod "nginx-deployment-6f478d8d8-wjl5m" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-wjl5m,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-7148,SelfLink:/api/v1/namespaces/deployment-7148/pods/nginx-deployment-6f478d8d8-wjl5m,UID:b8297136-6a5d-11e9-9890-000d3a4710ea,ResourceVersion:5382,Generation:0,CreationTimestamp:2019-04-29 09:03:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.129.16/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 b821ce66-6a5d-11e9-9890-000d3a4710ea 0xc002424fd0 0xc002424fd1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-7gd7m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7gd7m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7gd7m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:0mfg0-worker-000002,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002425070} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024250a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:03:56 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:05 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:05 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:03:56 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.6,PodIP:10.2.129.16,StartTime:2019-04-29 09:03:56 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-29 09:04:05 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://3417547b2050ef879c40d707adfaa7c84131c39eacf3f1399e4a38dbe0123f6d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 29 09:04:10.929: INFO: Pod "nginx-deployment-6f478d8d8-wk8xn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-wk8xn,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-7148,SelfLink:/api/v1/namespaces/deployment-7148/pods/nginx-deployment-6f478d8d8-wk8xn,UID:bf754d8c-6a5d-11e9-9890-000d3a4710ea,ResourceVersion:5563,Generation:0,CreationTimestamp:2019-04-29 09:04:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 b821ce66-6a5d-11e9-9890-000d3a4710ea 0xc002425240 0xc002425241}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-7gd7m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7gd7m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7gd7m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:0mfg0-worker-000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024252b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024252d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:04:08 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.4,PodIP:,StartTime:2019-04-29 09:04:08 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 29 09:04:10.929: INFO: Pod "nginx-deployment-6f478d8d8-zxdz9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-zxdz9,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-7148,SelfLink:/api/v1/namespaces/deployment-7148/pods/nginx-deployment-6f478d8d8-zxdz9,UID:b82dd2f4-6a5d-11e9-9890-000d3a4710ea,ResourceVersion:5334,Generation:0,CreationTimestamp:2019-04-29 09:03:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.130.21/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 b821ce66-6a5d-11e9-9890-000d3a4710ea 0xc002425410 0xc002425411}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-7gd7m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7gd7m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7gd7m true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:0mfg0-worker-000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002425470} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002425490}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:03:56 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:03:59 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:03:59 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:03:56 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.5,PodIP:10.2.130.21,StartTime:2019-04-29 09:03:56 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-29 09:03:59 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://fb845482e0255362246055013c1d60e374687c496104255e48bfed5653a649c4}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:04:10.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7148" for this suite.
Apr 29 09:04:18.981: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:04:19.103: INFO: namespace deployment-7148 deletion completed in 8.159646053s

• [SLOW TEST:22.762 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:04:19.104: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-802
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-802.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-802.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-802.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-802.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-802.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-802.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 29 09:04:25.335: INFO: DNS probes using dns-802/dns-test-c5ae7309-6a5d-11e9-b6b4-b219b18c41e8 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:04:25.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-802" for this suite.
Apr 29 09:04:31.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:04:31.489: INFO: namespace dns-802 deletion completed in 6.117860065s

• [SLOW TEST:12.386 seconds]
[sig-network] DNS
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:04:31.490: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-7407
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 29 09:04:31.710: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"cd15f9d1-6a5d-11e9-9890-000d3a4710ea", Controller:(*bool)(0xc0020fc70e), BlockOwnerDeletion:(*bool)(0xc0020fc70f)}}
Apr 29 09:04:31.719: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"cd13c1cd-6a5d-11e9-9890-000d3a4710ea", Controller:(*bool)(0xc002b9ab3e), BlockOwnerDeletion:(*bool)(0xc002b9ab3f)}}
Apr 29 09:04:31.737: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"cd14e412-6a5d-11e9-9890-000d3a4710ea", Controller:(*bool)(0xc0020fc98e), BlockOwnerDeletion:(*bool)(0xc0020fc98f)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:04:36.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7407" for this suite.
Apr 29 09:04:42.794: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:04:42.897: INFO: namespace gc-7407 deletion completed in 6.118503203s

• [SLOW TEST:11.408 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:04:42.899: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1428
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Apr 29 09:04:43.062: INFO: Waiting up to 5m0s for pod "pod-d3dd12f6-6a5d-11e9-b6b4-b219b18c41e8" in namespace "emptydir-1428" to be "success or failure"
Apr 29 09:04:43.077: INFO: Pod "pod-d3dd12f6-6a5d-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 14.130937ms
Apr 29 09:04:45.081: INFO: Pod "pod-d3dd12f6-6a5d-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018277279s
STEP: Saw pod success
Apr 29 09:04:45.081: INFO: Pod "pod-d3dd12f6-6a5d-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:04:45.086: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-d3dd12f6-6a5d-11e9-b6b4-b219b18c41e8 container test-container: <nil>
STEP: delete the pod
Apr 29 09:04:45.125: INFO: Waiting for pod pod-d3dd12f6-6a5d-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:04:45.128: INFO: Pod pod-d3dd12f6-6a5d-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:04:45.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1428" for this suite.
Apr 29 09:04:51.147: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:04:51.273: INFO: namespace emptydir-1428 deletion completed in 6.139248766s

• [SLOW TEST:8.374 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:04:51.274: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-452
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Apr 29 09:04:51.442: INFO: Waiting up to 5m0s for pod "pod-d8dc76d8-6a5d-11e9-b6b4-b219b18c41e8" in namespace "emptydir-452" to be "success or failure"
Apr 29 09:04:51.448: INFO: Pod "pod-d8dc76d8-6a5d-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.363316ms
Apr 29 09:04:53.452: INFO: Pod "pod-d8dc76d8-6a5d-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010452897s
Apr 29 09:04:55.457: INFO: Pod "pod-d8dc76d8-6a5d-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015097964s
STEP: Saw pod success
Apr 29 09:04:55.457: INFO: Pod "pod-d8dc76d8-6a5d-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:04:55.460: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-d8dc76d8-6a5d-11e9-b6b4-b219b18c41e8 container test-container: <nil>
STEP: delete the pod
Apr 29 09:04:55.499: INFO: Waiting for pod pod-d8dc76d8-6a5d-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:04:55.502: INFO: Pod pod-d8dc76d8-6a5d-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:04:55.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-452" for this suite.
Apr 29 09:05:01.520: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:05:01.628: INFO: namespace emptydir-452 deletion completed in 6.121626289s

• [SLOW TEST:10.354 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:05:01.630: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-965
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:05:04.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-965" for this suite.
Apr 29 09:05:26.865: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:05:27.002: INFO: namespace replication-controller-965 deletion completed in 22.149568902s

• [SLOW TEST:25.372 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:05:27.004: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2012
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-ee26e9a3-6a5d-11e9-b6b4-b219b18c41e8
STEP: Creating a pod to test consume configMaps
Apr 29 09:05:27.173: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ee27a5ce-6a5d-11e9-b6b4-b219b18c41e8" in namespace "projected-2012" to be "success or failure"
Apr 29 09:05:27.183: INFO: Pod "pod-projected-configmaps-ee27a5ce-6a5d-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 10.437926ms
Apr 29 09:05:29.188: INFO: Pod "pod-projected-configmaps-ee27a5ce-6a5d-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015409756s
STEP: Saw pod success
Apr 29 09:05:29.188: INFO: Pod "pod-projected-configmaps-ee27a5ce-6a5d-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:05:29.197: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-projected-configmaps-ee27a5ce-6a5d-11e9-b6b4-b219b18c41e8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 29 09:05:29.263: INFO: Waiting for pod pod-projected-configmaps-ee27a5ce-6a5d-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:05:29.281: INFO: Pod pod-projected-configmaps-ee27a5ce-6a5d-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:05:29.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2012" for this suite.
Apr 29 09:05:35.302: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:05:35.439: INFO: namespace projected-2012 deletion completed in 6.151541338s

• [SLOW TEST:8.435 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:05:35.439: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1700
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 29 09:05:39.681: INFO: Waiting up to 5m0s for pod "client-envvars-f599946f-6a5d-11e9-b6b4-b219b18c41e8" in namespace "pods-1700" to be "success or failure"
Apr 29 09:05:39.707: INFO: Pod "client-envvars-f599946f-6a5d-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 26.244264ms
Apr 29 09:05:41.712: INFO: Pod "client-envvars-f599946f-6a5d-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030604407s
Apr 29 09:05:43.716: INFO: Pod "client-envvars-f599946f-6a5d-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.034490236s
Apr 29 09:05:45.720: INFO: Pod "client-envvars-f599946f-6a5d-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.038514953s
STEP: Saw pod success
Apr 29 09:05:45.720: INFO: Pod "client-envvars-f599946f-6a5d-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:05:45.723: INFO: Trying to get logs from node 0mfg0-worker-000000 pod client-envvars-f599946f-6a5d-11e9-b6b4-b219b18c41e8 container env3cont: <nil>
STEP: delete the pod
Apr 29 09:05:45.753: INFO: Waiting for pod client-envvars-f599946f-6a5d-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:05:45.767: INFO: Pod client-envvars-f599946f-6a5d-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:05:45.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1700" for this suite.
Apr 29 09:06:29.785: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:06:29.886: INFO: namespace pods-1700 deletion completed in 44.115346251s

• [SLOW TEST:54.447 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:06:29.887: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-9669
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 29 09:06:54.098: INFO: Container started at 2019-04-29 09:06:31 +0000 UTC, pod became ready at 2019-04-29 09:06:52 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:06:54.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9669" for this suite.
Apr 29 09:07:16.120: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:07:16.258: INFO: namespace container-probe-9669 deletion completed in 22.155623899s

• [SLOW TEST:46.371 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:07:16.264: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7548
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating pod
Apr 29 09:07:20.468: INFO: Pod pod-hostip-2f4aa2f5-6a5e-11e9-b6b4-b219b18c41e8 has hostIP: 10.2.1.5
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:07:20.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7548" for this suite.
Apr 29 09:07:42.488: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:07:42.593: INFO: namespace pods-7548 deletion completed in 22.121989124s

• [SLOW TEST:26.330 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:07:42.594: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-4452
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
STEP: reading a file in the container
Apr 29 09:07:49.305: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4452 pod-service-account-3f480250-6a5e-11e9-b6b4-b219b18c41e8 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Apr 29 09:07:49.490: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4452 pod-service-account-3f480250-6a5e-11e9-b6b4-b219b18c41e8 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Apr 29 09:07:49.695: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4452 pod-service-account-3f480250-6a5e-11e9-b6b4-b219b18c41e8 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:07:49.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4452" for this suite.
Apr 29 09:07:55.903: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:07:56.017: INFO: namespace svcaccounts-4452 deletion completed in 6.128831833s

• [SLOW TEST:13.423 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:07:56.019: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-5720
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-2tcx
STEP: Creating a pod to test atomic-volume-subpath
Apr 29 09:07:56.238: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-2tcx" in namespace "subpath-5720" to be "success or failure"
Apr 29 09:07:56.257: INFO: Pod "pod-subpath-test-configmap-2tcx": Phase="Pending", Reason="", readiness=false. Elapsed: 18.480537ms
Apr 29 09:07:58.261: INFO: Pod "pod-subpath-test-configmap-2tcx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022656081s
Apr 29 09:08:00.265: INFO: Pod "pod-subpath-test-configmap-2tcx": Phase="Running", Reason="", readiness=true. Elapsed: 4.026343013s
Apr 29 09:08:02.270: INFO: Pod "pod-subpath-test-configmap-2tcx": Phase="Running", Reason="", readiness=true. Elapsed: 6.031944539s
Apr 29 09:08:04.275: INFO: Pod "pod-subpath-test-configmap-2tcx": Phase="Running", Reason="", readiness=true. Elapsed: 8.036209753s
Apr 29 09:08:06.279: INFO: Pod "pod-subpath-test-configmap-2tcx": Phase="Running", Reason="", readiness=true. Elapsed: 10.040019655s
Apr 29 09:08:08.282: INFO: Pod "pod-subpath-test-configmap-2tcx": Phase="Running", Reason="", readiness=true. Elapsed: 12.043776847s
Apr 29 09:08:10.287: INFO: Pod "pod-subpath-test-configmap-2tcx": Phase="Running", Reason="", readiness=true. Elapsed: 14.04805593s
Apr 29 09:08:12.291: INFO: Pod "pod-subpath-test-configmap-2tcx": Phase="Running", Reason="", readiness=true. Elapsed: 16.052590204s
Apr 29 09:08:14.296: INFO: Pod "pod-subpath-test-configmap-2tcx": Phase="Running", Reason="", readiness=true. Elapsed: 18.057769569s
Apr 29 09:08:16.300: INFO: Pod "pod-subpath-test-configmap-2tcx": Phase="Running", Reason="", readiness=true. Elapsed: 20.061764222s
Apr 29 09:08:18.304: INFO: Pod "pod-subpath-test-configmap-2tcx": Phase="Running", Reason="", readiness=true. Elapsed: 22.065687364s
Apr 29 09:08:20.308: INFO: Pod "pod-subpath-test-configmap-2tcx": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.069639097s
STEP: Saw pod success
Apr 29 09:08:20.308: INFO: Pod "pod-subpath-test-configmap-2tcx" satisfied condition "success or failure"
Apr 29 09:08:20.311: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-subpath-test-configmap-2tcx container test-container-subpath-configmap-2tcx: <nil>
STEP: delete the pod
Apr 29 09:08:20.343: INFO: Waiting for pod pod-subpath-test-configmap-2tcx to disappear
Apr 29 09:08:20.357: INFO: Pod pod-subpath-test-configmap-2tcx no longer exists
STEP: Deleting pod pod-subpath-test-configmap-2tcx
Apr 29 09:08:20.357: INFO: Deleting pod "pod-subpath-test-configmap-2tcx" in namespace "subpath-5720"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:08:20.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5720" for this suite.
Apr 29 09:08:26.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:08:26.490: INFO: namespace subpath-5720 deletion completed in 6.126181962s

• [SLOW TEST:30.471 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:08:26.490: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3265
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 29 09:08:26.650: INFO: Waiting up to 5m0s for pod "downwardapi-volume-59225cee-6a5e-11e9-b6b4-b219b18c41e8" in namespace "projected-3265" to be "success or failure"
Apr 29 09:08:26.659: INFO: Pod "downwardapi-volume-59225cee-6a5e-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.090816ms
Apr 29 09:08:28.663: INFO: Pod "downwardapi-volume-59225cee-6a5e-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011964408s
Apr 29 09:08:30.666: INFO: Pod "downwardapi-volume-59225cee-6a5e-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01563449s
STEP: Saw pod success
Apr 29 09:08:30.667: INFO: Pod "downwardapi-volume-59225cee-6a5e-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:08:30.669: INFO: Trying to get logs from node 0mfg0-worker-000001 pod downwardapi-volume-59225cee-6a5e-11e9-b6b4-b219b18c41e8 container client-container: <nil>
STEP: delete the pod
Apr 29 09:08:30.693: INFO: Waiting for pod downwardapi-volume-59225cee-6a5e-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:08:30.698: INFO: Pod downwardapi-volume-59225cee-6a5e-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:08:30.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3265" for this suite.
Apr 29 09:08:36.718: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:08:36.825: INFO: namespace projected-3265 deletion completed in 6.122976604s

• [SLOW TEST:10.335 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:08:36.826: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2948
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1108
STEP: creating the pod
Apr 29 09:08:36.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 create -f - --namespace=kubectl-2948'
Apr 29 09:08:38.396: INFO: stderr: ""
Apr 29 09:08:38.396: INFO: stdout: "pod/pause created\n"
Apr 29 09:08:38.396: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Apr 29 09:08:38.397: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-2948" to be "running and ready"
Apr 29 09:08:38.408: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 11.448622ms
Apr 29 09:08:40.412: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.014890557s
Apr 29 09:08:40.412: INFO: Pod "pause" satisfied condition "running and ready"
Apr 29 09:08:40.412: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: adding the label testing-label with value testing-label-value to a pod
Apr 29 09:08:40.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 label pods pause testing-label=testing-label-value --namespace=kubectl-2948'
Apr 29 09:08:40.505: INFO: stderr: ""
Apr 29 09:08:40.505: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Apr 29 09:08:40.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pod pause -L testing-label --namespace=kubectl-2948'
Apr 29 09:08:40.594: INFO: stderr: ""
Apr 29 09:08:40.594: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Apr 29 09:08:40.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 label pods pause testing-label- --namespace=kubectl-2948'
Apr 29 09:08:40.739: INFO: stderr: ""
Apr 29 09:08:40.739: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Apr 29 09:08:40.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pod pause -L testing-label --namespace=kubectl-2948'
Apr 29 09:08:40.836: INFO: stderr: ""
Apr 29 09:08:40.836: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1115
STEP: using delete to clean up resources
Apr 29 09:08:40.836: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 delete --grace-period=0 --force -f - --namespace=kubectl-2948'
Apr 29 09:08:40.936: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 29 09:08:40.936: INFO: stdout: "pod \"pause\" force deleted\n"
Apr 29 09:08:40.937: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get rc,svc -l name=pause --no-headers --namespace=kubectl-2948'
Apr 29 09:08:41.042: INFO: stderr: "No resources found.\n"
Apr 29 09:08:41.042: INFO: stdout: ""
Apr 29 09:08:41.043: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods -l name=pause --namespace=kubectl-2948 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 29 09:08:41.145: INFO: stderr: ""
Apr 29 09:08:41.145: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:08:41.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2948" for this suite.
Apr 29 09:08:47.161: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:08:47.282: INFO: namespace kubectl-2948 deletion completed in 6.133692373s

• [SLOW TEST:10.456 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:08:47.282: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-7485
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-7485
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 29 09:08:47.448: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr 29 09:09:17.579: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.2.129.21 8081 | grep -v '^\s*$'] Namespace:pod-network-test-7485 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 29 09:09:17.579: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
Apr 29 09:09:18.714: INFO: Found all expected endpoints: [netserver-0]
Apr 29 09:09:18.718: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.2.131.30 8081 | grep -v '^\s*$'] Namespace:pod-network-test-7485 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 29 09:09:18.718: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
Apr 29 09:09:19.824: INFO: Found all expected endpoints: [netserver-1]
Apr 29 09:09:19.827: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.2.130.42 8081 | grep -v '^\s*$'] Namespace:pod-network-test-7485 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 29 09:09:19.827: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
Apr 29 09:09:20.942: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:09:20.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7485" for this suite.
Apr 29 09:09:42.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:09:43.079: INFO: namespace pod-network-test-7485 deletion completed in 22.132193676s

• [SLOW TEST:55.796 seconds]
[sig-network] Networking
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:09:43.079: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-402
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Apr 29 09:09:49.360: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 29 09:09:49.363: INFO: Pod pod-with-poststart-http-hook still exists
Apr 29 09:09:51.363: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 29 09:09:51.368: INFO: Pod pod-with-poststart-http-hook still exists
Apr 29 09:09:53.364: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 29 09:09:53.367: INFO: Pod pod-with-poststart-http-hook still exists
Apr 29 09:09:55.364: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 29 09:09:55.368: INFO: Pod pod-with-poststart-http-hook still exists
Apr 29 09:09:57.363: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 29 09:09:57.367: INFO: Pod pod-with-poststart-http-hook still exists
Apr 29 09:09:59.363: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 29 09:09:59.367: INFO: Pod pod-with-poststart-http-hook still exists
Apr 29 09:10:01.363: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 29 09:10:01.367: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:10:01.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-402" for this suite.
Apr 29 09:10:23.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:10:23.493: INFO: namespace container-lifecycle-hook-402 deletion completed in 22.123091838s

• [SLOW TEST:40.414 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:10:23.495: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-9529
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Apr 29 09:10:23.667: INFO: Pod name pod-release: Found 0 pods out of 1
Apr 29 09:10:28.670: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:10:28.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9529" for this suite.
Apr 29 09:10:34.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:10:34.865: INFO: namespace replication-controller-9529 deletion completed in 6.134253491s

• [SLOW TEST:11.370 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:10:34.866: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8206
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:177
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:10:35.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8206" for this suite.
Apr 29 09:10:57.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:10:57.212: INFO: namespace pods-8206 deletion completed in 22.152219574s

• [SLOW TEST:22.346 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:10:57.212: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-262
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:10:59.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-262" for this suite.
Apr 29 09:11:51.613: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:11:51.725: INFO: namespace kubelet-test-262 deletion completed in 52.136146562s

• [SLOW TEST:54.512 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:11:51.732: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-3392
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-3392
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Apr 29 09:11:51.978: INFO: Found 0 stateful pods, waiting for 3
Apr 29 09:12:01.982: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 29 09:12:01.982: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 29 09:12:01.982: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Apr 29 09:12:11.983: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 29 09:12:11.983: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 29 09:12:11.983: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Apr 29 09:12:11.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-3392 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 29 09:12:12.234: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 29 09:12:12.234: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 29 09:12:12.234: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Apr 29 09:12:22.267: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Apr 29 09:12:32.310: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-3392 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 29 09:12:32.539: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr 29 09:12:32.539: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 29 09:12:32.539: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 29 09:12:42.568: INFO: Waiting for StatefulSet statefulset-3392/ss2 to complete update
Apr 29 09:12:42.568: INFO: Waiting for Pod statefulset-3392/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 29 09:12:42.568: INFO: Waiting for Pod statefulset-3392/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 29 09:12:52.575: INFO: Waiting for StatefulSet statefulset-3392/ss2 to complete update
Apr 29 09:12:52.575: INFO: Waiting for Pod statefulset-3392/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 29 09:12:52.575: INFO: Waiting for Pod statefulset-3392/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 29 09:13:02.575: INFO: Waiting for StatefulSet statefulset-3392/ss2 to complete update
Apr 29 09:13:02.575: INFO: Waiting for Pod statefulset-3392/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 29 09:13:12.575: INFO: Waiting for StatefulSet statefulset-3392/ss2 to complete update
Apr 29 09:13:12.575: INFO: Waiting for Pod statefulset-3392/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Apr 29 09:13:22.575: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-3392 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 29 09:13:22.847: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 29 09:13:22.847: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 29 09:13:22.847: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 29 09:13:32.879: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Apr 29 09:13:42.913: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-3392 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 29 09:13:43.115: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr 29 09:13:43.115: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 29 09:13:43.115: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 29 09:13:53.135: INFO: Waiting for StatefulSet statefulset-3392/ss2 to complete update
Apr 29 09:13:53.135: INFO: Waiting for Pod statefulset-3392/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Apr 29 09:13:53.135: INFO: Waiting for Pod statefulset-3392/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Apr 29 09:14:03.142: INFO: Waiting for StatefulSet statefulset-3392/ss2 to complete update
Apr 29 09:14:03.142: INFO: Waiting for Pod statefulset-3392/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr 29 09:14:13.142: INFO: Deleting all statefulset in ns statefulset-3392
Apr 29 09:14:13.145: INFO: Scaling statefulset ss2 to 0
Apr 29 09:14:43.168: INFO: Waiting for statefulset status.replicas updated to 0
Apr 29 09:14:43.171: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:14:43.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3392" for this suite.
Apr 29 09:14:49.230: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:14:49.340: INFO: namespace statefulset-3392 deletion completed in 6.12431086s

• [SLOW TEST:177.608 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:14:49.340: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-8224
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:14:49.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8224" for this suite.
Apr 29 09:14:55.521: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:14:55.650: INFO: namespace services-8224 deletion completed in 6.145717345s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:6.311 seconds]
[sig-network] Services
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:14:55.652: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-553
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 29 09:14:55.844: INFO: Pod name rollover-pod: Found 0 pods out of 1
Apr 29 09:15:00.848: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr 29 09:15:00.848: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Apr 29 09:15:02.853: INFO: Creating deployment "test-rollover-deployment"
Apr 29 09:15:02.863: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Apr 29 09:15:04.871: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Apr 29 09:15:04.879: INFO: Ensure that both replica sets have 1 created replica
Apr 29 09:15:04.886: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Apr 29 09:15:04.907: INFO: Updating deployment test-rollover-deployment
Apr 29 09:15:04.907: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Apr 29 09:15:06.946: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Apr 29 09:15:06.952: INFO: Make sure deployment "test-rollover-deployment" is complete
Apr 29 09:15:06.957: INFO: all replica sets need to contain the pod-template-hash label
Apr 29 09:15:06.957: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692126102, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692126102, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692126105, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692126102, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 29 09:15:08.964: INFO: all replica sets need to contain the pod-template-hash label
Apr 29 09:15:08.964: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692126102, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692126102, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692126108, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692126102, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 29 09:15:10.965: INFO: all replica sets need to contain the pod-template-hash label
Apr 29 09:15:10.965: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692126102, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692126102, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692126108, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692126102, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 29 09:15:12.966: INFO: all replica sets need to contain the pod-template-hash label
Apr 29 09:15:12.966: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692126102, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692126102, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692126108, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692126102, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 29 09:15:14.964: INFO: all replica sets need to contain the pod-template-hash label
Apr 29 09:15:14.964: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692126102, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692126102, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692126108, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692126102, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 29 09:15:16.964: INFO: all replica sets need to contain the pod-template-hash label
Apr 29 09:15:16.964: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692126102, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692126102, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692126108, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692126102, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 29 09:15:18.971: INFO: 
Apr 29 09:15:18.971: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr 29 09:15:18.981: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-553,SelfLink:/apis/apps/v1/namespaces/deployment-553/deployments/test-rollover-deployment,UID:454be078-6a5f-11e9-9890-000d3a4710ea,ResourceVersion:8092,Generation:2,CreationTimestamp:2019-04-29 09:15:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-04-29 09:15:02 +0000 UTC 2019-04-29 09:15:02 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-04-29 09:15:18 +0000 UTC 2019-04-29 09:15:02 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-766b4d6c9d" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Apr 29 09:15:18.984: INFO: New ReplicaSet "test-rollover-deployment-766b4d6c9d" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-766b4d6c9d,GenerateName:,Namespace:deployment-553,SelfLink:/apis/apps/v1/namespaces/deployment-553/replicasets/test-rollover-deployment-766b4d6c9d,UID:46844d83-6a5f-11e9-9890-000d3a4710ea,ResourceVersion:8082,Generation:2,CreationTimestamp:2019-04-29 09:15:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 454be078-6a5f-11e9-9890-000d3a4710ea 0xc000ab9307 0xc000ab9308}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Apr 29 09:15:18.984: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Apr 29 09:15:18.984: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-553,SelfLink:/apis/apps/v1/namespaces/deployment-553/replicasets/test-rollover-controller,UID:411af1df-6a5f-11e9-9890-000d3a4710ea,ResourceVersion:8091,Generation:2,CreationTimestamp:2019-04-29 09:14:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 454be078-6a5f-11e9-9890-000d3a4710ea 0xc000ab9177 0xc000ab9178}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 29 09:15:18.985: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6455657675,GenerateName:,Namespace:deployment-553,SelfLink:/apis/apps/v1/namespaces/deployment-553/replicasets/test-rollover-deployment-6455657675,UID:454ec4ca-6a5f-11e9-9890-000d3a4710ea,ResourceVersion:8044,Generation:2,CreationTimestamp:2019-04-29 09:15:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 454be078-6a5f-11e9-9890-000d3a4710ea 0xc000ab9237 0xc000ab9238}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 29 09:15:18.988: INFO: Pod "test-rollover-deployment-766b4d6c9d-7t9dp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-766b4d6c9d-7t9dp,GenerateName:test-rollover-deployment-766b4d6c9d-,Namespace:deployment-553,SelfLink:/api/v1/namespaces/deployment-553/pods/test-rollover-deployment-766b4d6c9d-7t9dp,UID:468dada9-6a5f-11e9-9890-000d3a4710ea,ResourceVersion:8063,Generation:0,CreationTimestamp:2019-04-29 09:15:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.131.36/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-766b4d6c9d 46844d83-6a5f-11e9-9890-000d3a4710ea 0xc000a8c4e7 0xc000a8c4e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdvhd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdvhd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-xdvhd true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:0mfg0-worker-000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000a8c6b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000a8c6d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:15:05 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:15:08 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:15:08 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:15:04 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.4,PodIP:10.2.131.36,StartTime:2019-04-29 09:15:05 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-04-29 09:15:08 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://4ea370e7146144976b707fc2a7190b375381d941896bb44bacf1171cc1546b24}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:15:18.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-553" for this suite.
Apr 29 09:15:25.015: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:15:25.128: INFO: namespace deployment-553 deletion completed in 6.136191033s

• [SLOW TEST:29.476 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:15:25.128: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6745
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-4361
STEP: Creating secret with name secret-test-52aa42d9-6a5f-11e9-b6b4-b219b18c41e8
STEP: Creating a pod to test consume secrets
Apr 29 09:15:25.474: INFO: Waiting up to 5m0s for pod "pod-secrets-52c469c8-6a5f-11e9-b6b4-b219b18c41e8" in namespace "secrets-6745" to be "success or failure"
Apr 29 09:15:25.484: INFO: Pod "pod-secrets-52c469c8-6a5f-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.145808ms
Apr 29 09:15:27.489: INFO: Pod "pod-secrets-52c469c8-6a5f-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010838625s
Apr 29 09:15:29.492: INFO: Pod "pod-secrets-52c469c8-6a5f-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014209936s
STEP: Saw pod success
Apr 29 09:15:29.492: INFO: Pod "pod-secrets-52c469c8-6a5f-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:15:29.495: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-secrets-52c469c8-6a5f-11e9-b6b4-b219b18c41e8 container secret-volume-test: <nil>
STEP: delete the pod
Apr 29 09:15:29.523: INFO: Waiting for pod pod-secrets-52c469c8-6a5f-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:15:29.535: INFO: Pod pod-secrets-52c469c8-6a5f-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:15:29.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6745" for this suite.
Apr 29 09:15:35.551: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:15:35.686: INFO: namespace secrets-6745 deletion completed in 6.147288278s
STEP: Destroying namespace "secret-namespace-4361" for this suite.
Apr 29 09:15:41.700: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:15:41.806: INFO: namespace secret-namespace-4361 deletion completed in 6.119054104s

• [SLOW TEST:16.677 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:15:41.807: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-758
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-758/configmap-test-5c9b5d70-6a5f-11e9-b6b4-b219b18c41e8
STEP: Creating a pod to test consume configMaps
Apr 29 09:15:41.992: INFO: Waiting up to 5m0s for pod "pod-configmaps-5c9bfa1a-6a5f-11e9-b6b4-b219b18c41e8" in namespace "configmap-758" to be "success or failure"
Apr 29 09:15:41.995: INFO: Pod "pod-configmaps-5c9bfa1a-6a5f-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.095104ms
Apr 29 09:15:43.998: INFO: Pod "pod-configmaps-5c9bfa1a-6a5f-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006765685s
Apr 29 09:15:46.002: INFO: Pod "pod-configmaps-5c9bfa1a-6a5f-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010699363s
STEP: Saw pod success
Apr 29 09:15:46.002: INFO: Pod "pod-configmaps-5c9bfa1a-6a5f-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:15:46.005: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-configmaps-5c9bfa1a-6a5f-11e9-b6b4-b219b18c41e8 container env-test: <nil>
STEP: delete the pod
Apr 29 09:15:46.030: INFO: Waiting for pod pod-configmaps-5c9bfa1a-6a5f-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:15:46.033: INFO: Pod pod-configmaps-5c9bfa1a-6a5f-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:15:46.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-758" for this suite.
Apr 29 09:15:52.049: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:15:52.272: INFO: namespace configmap-758 deletion completed in 6.235238182s

• [SLOW TEST:10.465 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:15:52.277: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6089
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-62dc0d33-6a5f-11e9-b6b4-b219b18c41e8
STEP: Creating a pod to test consume configMaps
Apr 29 09:15:52.467: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-62dc92b1-6a5f-11e9-b6b4-b219b18c41e8" in namespace "projected-6089" to be "success or failure"
Apr 29 09:15:52.485: INFO: Pod "pod-projected-configmaps-62dc92b1-6a5f-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 18.140823ms
Apr 29 09:15:54.489: INFO: Pod "pod-projected-configmaps-62dc92b1-6a5f-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022186483s
Apr 29 09:15:56.493: INFO: Pod "pod-projected-configmaps-62dc92b1-6a5f-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025953339s
STEP: Saw pod success
Apr 29 09:15:56.493: INFO: Pod "pod-projected-configmaps-62dc92b1-6a5f-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:15:56.496: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-projected-configmaps-62dc92b1-6a5f-11e9-b6b4-b219b18c41e8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 29 09:15:56.523: INFO: Waiting for pod pod-projected-configmaps-62dc92b1-6a5f-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:15:56.533: INFO: Pod pod-projected-configmaps-62dc92b1-6a5f-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:15:56.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6089" for this suite.
Apr 29 09:16:02.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:16:02.661: INFO: namespace projected-6089 deletion completed in 6.124349781s

• [SLOW TEST:10.384 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:16:02.662: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-2203
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:16:40.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2203" for this suite.
Apr 29 09:16:46.205: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:16:46.312: INFO: namespace container-runtime-2203 deletion completed in 6.119894121s

• [SLOW TEST:43.651 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  blackbox test
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:16:46.313: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8178
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Apr 29 09:16:51.001: INFO: Successfully updated pod "pod-update-830d5dbd-6a5f-11e9-b6b4-b219b18c41e8"
STEP: verifying the updated pod is in kubernetes
Apr 29 09:16:51.026: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:16:51.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8178" for this suite.
Apr 29 09:17:13.046: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:17:13.171: INFO: namespace pods-8178 deletion completed in 22.141852354s

• [SLOW TEST:26.859 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:17:13.172: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-7722
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 29 09:17:13.345: INFO: Creating deployment "test-recreate-deployment"
Apr 29 09:17:13.353: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Apr 29 09:17:13.399: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Apr 29 09:17:15.427: INFO: Waiting deployment "test-recreate-deployment" to complete
Apr 29 09:17:15.431: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692126233, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692126233, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692126233, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692126233, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d57d5ff7c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 29 09:17:17.435: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692126233, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692126233, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692126233, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692126233, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d57d5ff7c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 29 09:17:19.434: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692126233, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692126233, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692126233, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692126233, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d57d5ff7c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 29 09:17:21.434: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Apr 29 09:17:21.442: INFO: Updating deployment test-recreate-deployment
Apr 29 09:17:21.443: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr 29 09:17:21.594: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-7722,SelfLink:/apis/apps/v1/namespaces/deployment-7722/deployments/test-recreate-deployment,UID:931376f5-6a5f-11e9-9890-000d3a4710ea,ResourceVersion:8588,Generation:2,CreationTimestamp:2019-04-29 09:17:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-04-29 09:17:21 +0000 UTC 2019-04-29 09:17:21 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-04-29 09:17:21 +0000 UTC 2019-04-29 09:17:13 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-c9cbd8684" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Apr 29 09:17:21.607: INFO: New ReplicaSet "test-recreate-deployment-c9cbd8684" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-c9cbd8684,GenerateName:,Namespace:deployment-7722,SelfLink:/apis/apps/v1/namespaces/deployment-7722/replicasets/test-recreate-deployment-c9cbd8684,UID:97f1da14-6a5f-11e9-9890-000d3a4710ea,ResourceVersion:8586,Generation:1,CreationTimestamp:2019-04-29 09:17:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 931376f5-6a5f-11e9-9890-000d3a4710ea 0xc0027bbab0 0xc0027bbab1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 29 09:17:21.607: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Apr 29 09:17:21.608: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7d57d5ff7c,GenerateName:,Namespace:deployment-7722,SelfLink:/apis/apps/v1/namespaces/deployment-7722/replicasets/test-recreate-deployment-7d57d5ff7c,UID:93147bd7-6a5f-11e9-9890-000d3a4710ea,ResourceVersion:8577,Generation:2,CreationTimestamp:2019-04-29 09:17:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 931376f5-6a5f-11e9-9890-000d3a4710ea 0xc0027bb9f7 0xc0027bb9f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 29 09:17:21.611: INFO: Pod "test-recreate-deployment-c9cbd8684-h5fq6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-c9cbd8684-h5fq6,GenerateName:test-recreate-deployment-c9cbd8684-,Namespace:deployment-7722,SelfLink:/api/v1/namespaces/deployment-7722/pods/test-recreate-deployment-c9cbd8684-h5fq6,UID:97f34d4e-6a5f-11e9-9890-000d3a4710ea,ResourceVersion:8589,Generation:0,CreationTimestamp:2019-04-29 09:17:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-c9cbd8684 97f1da14-6a5f-11e9-9890-000d3a4710ea 0xc001dde2e0 0xc001dde2e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-h6cp7 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-h6cp7,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-h6cp7 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:0mfg0-worker-000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001dde340} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001dde360}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:17:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:17:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:17:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:17:21 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.5,PodIP:,StartTime:2019-04-29 09:17:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:17:21.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7722" for this suite.
Apr 29 09:17:27.628: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:17:27.747: INFO: namespace deployment-7722 deletion completed in 6.131176112s

• [SLOW TEST:14.574 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:17:27.748: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9833
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Apr 29 09:17:27.914: INFO: Waiting up to 5m0s for pod "pod-9bc06856-6a5f-11e9-b6b4-b219b18c41e8" in namespace "emptydir-9833" to be "success or failure"
Apr 29 09:17:27.921: INFO: Pod "pod-9bc06856-6a5f-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 7.335108ms
Apr 29 09:17:29.926: INFO: Pod "pod-9bc06856-6a5f-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011925994s
STEP: Saw pod success
Apr 29 09:17:29.926: INFO: Pod "pod-9bc06856-6a5f-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:17:29.929: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-9bc06856-6a5f-11e9-b6b4-b219b18c41e8 container test-container: <nil>
STEP: delete the pod
Apr 29 09:17:29.954: INFO: Waiting for pod pod-9bc06856-6a5f-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:17:29.964: INFO: Pod pod-9bc06856-6a5f-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:17:29.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9833" for this suite.
Apr 29 09:17:35.991: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:17:36.096: INFO: namespace emptydir-9833 deletion completed in 6.127681666s

• [SLOW TEST:8.348 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:17:36.097: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8329
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1583
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 29 09:17:36.267: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-8329'
Apr 29 09:17:36.414: INFO: stderr: ""
Apr 29 09:17:36.414: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1588
Apr 29 09:17:36.421: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 delete pods e2e-test-nginx-pod --namespace=kubectl-8329'
Apr 29 09:17:47.629: INFO: stderr: ""
Apr 29 09:17:47.629: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:17:47.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8329" for this suite.
Apr 29 09:17:53.651: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:17:53.771: INFO: namespace kubectl-8329 deletion completed in 6.137419389s

• [SLOW TEST:17.674 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:17:53.771: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-3588
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 29 09:17:53.927: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Apr 29 09:17:53.937: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr 29 09:17:58.942: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr 29 09:17:58.942: INFO: Creating deployment "test-rolling-update-deployment"
Apr 29 09:17:58.950: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Apr 29 09:17:59.069: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Apr 29 09:18:01.076: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Apr 29 09:18:01.079: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692126279, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692126279, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692126279, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692126279, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-67599b4d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 29 09:18:03.083: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr 29 09:18:03.091: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-3588,SelfLink:/apis/apps/v1/namespaces/deployment-3588/deployments/test-rolling-update-deployment,UID:ae40df39-6a5f-11e9-9890-000d3a4710ea,ResourceVersion:8784,Generation:1,CreationTimestamp:2019-04-29 09:17:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-04-29 09:17:59 +0000 UTC 2019-04-29 09:17:59 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-04-29 09:18:01 +0000 UTC 2019-04-29 09:17:59 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-67599b4d9" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Apr 29 09:18:03.094: INFO: New ReplicaSet "test-rolling-update-deployment-67599b4d9" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-67599b4d9,GenerateName:,Namespace:deployment-3588,SelfLink:/apis/apps/v1/namespaces/deployment-3588/replicasets/test-rolling-update-deployment-67599b4d9,UID:ae487f86-6a5f-11e9-9890-000d3a4710ea,ResourceVersion:8772,Generation:1,CreationTimestamp:2019-04-29 09:17:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment ae40df39-6a5f-11e9-9890-000d3a4710ea 0xc002edfb90 0xc002edfb91}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Apr 29 09:18:03.094: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Apr 29 09:18:03.095: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-3588,SelfLink:/apis/apps/v1/namespaces/deployment-3588/replicasets/test-rolling-update-controller,UID:ab43ba5d-6a5f-11e9-9890-000d3a4710ea,ResourceVersion:8782,Generation:2,CreationTimestamp:2019-04-29 09:17:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment ae40df39-6a5f-11e9-9890-000d3a4710ea 0xc002edfabf 0xc002edfad0}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 29 09:18:03.098: INFO: Pod "test-rolling-update-deployment-67599b4d9-g94l9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-67599b4d9-g94l9,GenerateName:test-rolling-update-deployment-67599b4d9-,Namespace:deployment-3588,SelfLink:/api/v1/namespaces/deployment-3588/pods/test-rolling-update-deployment-67599b4d9-g94l9,UID:ae4b9238-6a5f-11e9-9890-000d3a4710ea,ResourceVersion:8771,Generation:0,CreationTimestamp:2019-04-29 09:17:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.130.64/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-67599b4d9 ae487f86-6a5f-11e9-9890-000d3a4710ea 0xc0020fd360 0xc0020fd361}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-hxx5c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hxx5c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-hxx5c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:0mfg0-worker-000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020fd3c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020fd3e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:17:59 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:18:01 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:18:01 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 09:17:59 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.5,PodIP:10.2.130.64,StartTime:2019-04-29 09:17:59 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-04-29 09:18:00 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://cc3481550fac21da039bf5fd91e69f66b3439c6065ae9841f56648a7a6e88788}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:18:03.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3588" for this suite.
Apr 29 09:18:09.113: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:18:09.241: INFO: namespace deployment-3588 deletion completed in 6.139796016s

• [SLOW TEST:15.470 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:18:09.242: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2522
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr 29 09:18:09.467: INFO: Waiting up to 5m0s for pod "downward-api-b4850031-6a5f-11e9-b6b4-b219b18c41e8" in namespace "downward-api-2522" to be "success or failure"
Apr 29 09:18:09.482: INFO: Pod "downward-api-b4850031-6a5f-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 14.221015ms
Apr 29 09:18:11.489: INFO: Pod "downward-api-b4850031-6a5f-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021602637s
Apr 29 09:18:13.493: INFO: Pod "downward-api-b4850031-6a5f-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.025369252s
Apr 29 09:18:15.497: INFO: Pod "downward-api-b4850031-6a5f-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.029870265s
STEP: Saw pod success
Apr 29 09:18:15.498: INFO: Pod "downward-api-b4850031-6a5f-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:18:15.501: INFO: Trying to get logs from node 0mfg0-worker-000000 pod downward-api-b4850031-6a5f-11e9-b6b4-b219b18c41e8 container dapi-container: <nil>
STEP: delete the pod
Apr 29 09:18:15.540: INFO: Waiting for pod downward-api-b4850031-6a5f-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:18:15.543: INFO: Pod downward-api-b4850031-6a5f-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:18:15.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2522" for this suite.
Apr 29 09:18:21.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:18:21.668: INFO: namespace downward-api-2522 deletion completed in 6.121943738s

• [SLOW TEST:12.427 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:18:21.669: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3180
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating api versions
Apr 29 09:18:21.833: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 api-versions'
Apr 29 09:18:21.957: INFO: stderr: ""
Apr 29 09:18:21.957: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napplication.giantswarm.io/v1alpha1\napps/v1\napps/v1beta1\napps/v1beta2\nauditregistration.k8s.io/v1alpha1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\nbatch/v2alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncore.giantswarm.io/v1alpha1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1alpha1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1alpha1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1alpha1\nscheduling.k8s.io/v1beta1\nsettings.k8s.io/v1alpha1\nstorage.k8s.io/v1\nstorage.k8s.io/v1alpha1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:18:21.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3180" for this suite.
Apr 29 09:18:27.973: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:18:28.085: INFO: namespace kubectl-3180 deletion completed in 6.12318151s

• [SLOW TEST:6.416 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:18:28.086: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8195
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 29 09:18:28.254: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bfb75963-6a5f-11e9-b6b4-b219b18c41e8" in namespace "downward-api-8195" to be "success or failure"
Apr 29 09:18:28.259: INFO: Pod "downwardapi-volume-bfb75963-6a5f-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.007505ms
Apr 29 09:18:30.265: INFO: Pod "downwardapi-volume-bfb75963-6a5f-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011131498s
Apr 29 09:18:32.272: INFO: Pod "downwardapi-volume-bfb75963-6a5f-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018106788s
STEP: Saw pod success
Apr 29 09:18:32.272: INFO: Pod "downwardapi-volume-bfb75963-6a5f-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:18:32.276: INFO: Trying to get logs from node 0mfg0-worker-000001 pod downwardapi-volume-bfb75963-6a5f-11e9-b6b4-b219b18c41e8 container client-container: <nil>
STEP: delete the pod
Apr 29 09:18:32.325: INFO: Waiting for pod downwardapi-volume-bfb75963-6a5f-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:18:32.328: INFO: Pod downwardapi-volume-bfb75963-6a5f-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:18:32.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8195" for this suite.
Apr 29 09:18:38.345: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:18:38.456: INFO: namespace downward-api-8195 deletion completed in 6.123477764s

• [SLOW TEST:10.370 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:18:38.457: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2788
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-c5e58a33-6a5f-11e9-b6b4-b219b18c41e8
STEP: Creating secret with name s-test-opt-upd-c5e58a72-6a5f-11e9-b6b4-b219b18c41e8
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-c5e58a33-6a5f-11e9-b6b4-b219b18c41e8
STEP: Updating secret s-test-opt-upd-c5e58a72-6a5f-11e9-b6b4-b219b18c41e8
STEP: Creating secret with name s-test-opt-create-c5e58a88-6a5f-11e9-b6b4-b219b18c41e8
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:18:46.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2788" for this suite.
Apr 29 09:19:08.795: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:19:08.919: INFO: namespace projected-2788 deletion completed in 22.136583434s

• [SLOW TEST:30.462 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:19:08.919: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8168
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr 29 09:19:09.087: INFO: Waiting up to 5m0s for pod "downward-api-d80e2c3a-6a5f-11e9-b6b4-b219b18c41e8" in namespace "downward-api-8168" to be "success or failure"
Apr 29 09:19:09.099: INFO: Pod "downward-api-d80e2c3a-6a5f-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 10.884712ms
Apr 29 09:19:11.102: INFO: Pod "downward-api-d80e2c3a-6a5f-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014574943s
Apr 29 09:19:13.106: INFO: Pod "downward-api-d80e2c3a-6a5f-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018605572s
STEP: Saw pod success
Apr 29 09:19:13.106: INFO: Pod "downward-api-d80e2c3a-6a5f-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:19:13.109: INFO: Trying to get logs from node 0mfg0-worker-000001 pod downward-api-d80e2c3a-6a5f-11e9-b6b4-b219b18c41e8 container dapi-container: <nil>
STEP: delete the pod
Apr 29 09:19:13.138: INFO: Waiting for pod downward-api-d80e2c3a-6a5f-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:19:13.143: INFO: Pod downward-api-d80e2c3a-6a5f-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:19:13.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8168" for this suite.
Apr 29 09:19:19.162: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:19:19.317: INFO: namespace downward-api-8168 deletion completed in 6.169351636s

• [SLOW TEST:10.397 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:19:19.318: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-3027
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-3027
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-3027
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-3027
Apr 29 09:19:19.524: INFO: Found 0 stateful pods, waiting for 1
Apr 29 09:19:29.535: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Apr 29 09:19:29.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-3027 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 29 09:19:29.731: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 29 09:19:29.731: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 29 09:19:29.731: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 29 09:19:29.736: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr 29 09:19:39.740: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 29 09:19:39.741: INFO: Waiting for statefulset status.replicas updated to 0
Apr 29 09:19:39.778: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.9999995s
Apr 29 09:19:40.788: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.992106948s
Apr 29 09:19:41.791: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.982343095s
Apr 29 09:19:42.795: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.978677049s
Apr 29 09:19:43.799: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.974903703s
Apr 29 09:19:44.802: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.971429459s
Apr 29 09:19:45.806: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.967591514s
Apr 29 09:19:46.810: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.963836871s
Apr 29 09:19:47.823: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.959882427s
Apr 29 09:19:48.827: INFO: Verifying statefulset ss doesn't scale past 1 for another 947.222576ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-3027
Apr 29 09:19:49.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-3027 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 29 09:19:50.034: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr 29 09:19:50.034: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 29 09:19:50.034: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 29 09:19:50.038: INFO: Found 1 stateful pods, waiting for 3
Apr 29 09:20:00.042: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 29 09:20:00.042: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 29 09:20:00.042: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=false
Apr 29 09:20:10.041: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 29 09:20:10.042: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 29 09:20:10.042: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Apr 29 09:20:10.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-3027 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 29 09:20:10.239: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 29 09:20:10.239: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 29 09:20:10.239: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 29 09:20:10.240: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-3027 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 29 09:20:10.465: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 29 09:20:10.465: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 29 09:20:10.465: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 29 09:20:10.466: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-3027 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 29 09:20:10.672: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 29 09:20:10.672: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 29 09:20:10.672: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 29 09:20:10.672: INFO: Waiting for statefulset status.replicas updated to 0
Apr 29 09:20:10.676: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Apr 29 09:20:20.683: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 29 09:20:20.683: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr 29 09:20:20.683: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr 29 09:20:20.707: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.9999996s
Apr 29 09:20:21.711: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.984144466s
Apr 29 09:20:22.716: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.980268344s
Apr 29 09:20:23.725: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.974296721s
Apr 29 09:20:24.729: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.966903697s
Apr 29 09:20:25.732: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.962809277s
Apr 29 09:20:26.736: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.959400758s
Apr 29 09:20:27.740: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.95574824s
Apr 29 09:20:28.755: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.951764622s
Apr 29 09:20:29.760: INFO: Verifying statefulset ss doesn't scale past 3 for another 936.071793ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-3027
Apr 29 09:20:30.766: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-3027 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 29 09:20:30.966: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr 29 09:20:30.966: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 29 09:20:30.966: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 29 09:20:30.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-3027 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 29 09:20:31.227: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr 29 09:20:31.227: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 29 09:20:31.227: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 29 09:20:31.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 exec --namespace=statefulset-3027 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 29 09:20:31.424: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr 29 09:20:31.424: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 29 09:20:31.424: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 29 09:20:31.424: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr 29 09:21:01.444: INFO: Deleting all statefulset in ns statefulset-3027
Apr 29 09:21:01.447: INFO: Scaling statefulset ss to 0
Apr 29 09:21:01.456: INFO: Waiting for statefulset status.replicas updated to 0
Apr 29 09:21:01.459: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:21:01.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3027" for this suite.
Apr 29 09:21:07.515: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:21:07.627: INFO: namespace statefulset-3027 deletion completed in 6.128062288s

• [SLOW TEST:108.309 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:21:07.628: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9668
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0429 09:21:37.900841      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 29 09:21:37.900: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:21:37.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9668" for this suite.
Apr 29 09:21:43.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:21:44.019: INFO: namespace gc-9668 deletion completed in 6.114492657s

• [SLOW TEST:36.391 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:21:44.019: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6767
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0429 09:22:24.213346      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 29 09:22:24.213: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:22:24.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6767" for this suite.
Apr 29 09:22:32.230: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:22:32.400: INFO: namespace gc-6767 deletion completed in 8.183810385s

• [SLOW TEST:48.381 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:22:32.406: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6872
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 29 09:22:32.602: INFO: Waiting up to 5m0s for pod "downwardapi-volume-515c91ff-6a60-11e9-b6b4-b219b18c41e8" in namespace "downward-api-6872" to be "success or failure"
Apr 29 09:22:32.612: INFO: Pod "downwardapi-volume-515c91ff-6a60-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 9.635909ms
Apr 29 09:22:34.616: INFO: Pod "downwardapi-volume-515c91ff-6a60-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013920511s
Apr 29 09:22:36.621: INFO: Pod "downwardapi-volume-515c91ff-6a60-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018174311s
Apr 29 09:22:38.624: INFO: Pod "downwardapi-volume-515c91ff-6a60-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.021835908s
STEP: Saw pod success
Apr 29 09:22:38.624: INFO: Pod "downwardapi-volume-515c91ff-6a60-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:22:38.627: INFO: Trying to get logs from node 0mfg0-worker-000001 pod downwardapi-volume-515c91ff-6a60-11e9-b6b4-b219b18c41e8 container client-container: <nil>
STEP: delete the pod
Apr 29 09:22:38.658: INFO: Waiting for pod downwardapi-volume-515c91ff-6a60-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:22:38.662: INFO: Pod downwardapi-volume-515c91ff-6a60-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:22:38.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6872" for this suite.
Apr 29 09:22:44.694: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:22:45.003: INFO: namespace downward-api-6872 deletion completed in 6.322122575s

• [SLOW TEST:12.597 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:22:45.004: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5079
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on tmpfs
Apr 29 09:22:45.177: INFO: Waiting up to 5m0s for pod "pod-58db1d65-6a60-11e9-b6b4-b219b18c41e8" in namespace "emptydir-5079" to be "success or failure"
Apr 29 09:22:45.182: INFO: Pod "pod-58db1d65-6a60-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.829005ms
Apr 29 09:22:47.186: INFO: Pod "pod-58db1d65-6a60-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009364495s
Apr 29 09:22:49.189: INFO: Pod "pod-58db1d65-6a60-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012806383s
STEP: Saw pod success
Apr 29 09:22:49.189: INFO: Pod "pod-58db1d65-6a60-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:22:49.196: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-58db1d65-6a60-11e9-b6b4-b219b18c41e8 container test-container: <nil>
STEP: delete the pod
Apr 29 09:22:49.231: INFO: Waiting for pod pod-58db1d65-6a60-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:22:49.236: INFO: Pod pod-58db1d65-6a60-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:22:49.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5079" for this suite.
Apr 29 09:22:55.255: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:22:55.362: INFO: namespace emptydir-5079 deletion completed in 6.121126756s

• [SLOW TEST:10.359 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:22:55.362: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-1876
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Apr 29 09:23:03.650: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 29 09:23:03.656: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 29 09:23:05.656: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 29 09:23:05.660: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 29 09:23:07.656: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 29 09:23:07.660: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 29 09:23:09.656: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 29 09:23:09.660: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 29 09:23:11.656: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 29 09:23:11.660: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 29 09:23:13.656: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 29 09:23:13.660: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 29 09:23:15.656: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 29 09:23:15.660: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 29 09:23:17.656: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 29 09:23:17.663: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 29 09:23:19.656: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 29 09:23:19.660: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 29 09:23:21.656: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 29 09:23:21.659: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 29 09:23:23.656: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 29 09:23:23.660: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 29 09:23:25.656: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 29 09:23:25.660: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 29 09:23:27.656: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 29 09:23:27.660: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 29 09:23:29.656: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 29 09:23:29.664: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 29 09:23:31.656: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 29 09:23:31.660: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:23:31.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1876" for this suite.
Apr 29 09:23:53.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:23:53.788: INFO: namespace container-lifecycle-hook-1876 deletion completed in 22.123963134s

• [SLOW TEST:58.425 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:23:53.788: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-5674
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0429 09:24:04.047693      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 29 09:24:04.047: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:24:04.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5674" for this suite.
Apr 29 09:24:10.065: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:24:10.190: INFO: namespace gc-5674 deletion completed in 6.138686983s

• [SLOW TEST:16.402 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:24:10.191: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3442
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr 29 09:24:10.355: INFO: Waiting up to 5m0s for pod "downward-api-8b9ff45c-6a60-11e9-b6b4-b219b18c41e8" in namespace "downward-api-3442" to be "success or failure"
Apr 29 09:24:10.374: INFO: Pod "downward-api-8b9ff45c-6a60-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 19.346718ms
Apr 29 09:24:12.378: INFO: Pod "downward-api-8b9ff45c-6a60-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023651938s
Apr 29 09:24:14.383: INFO: Pod "downward-api-8b9ff45c-6a60-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.027837656s
Apr 29 09:24:16.387: INFO: Pod "downward-api-8b9ff45c-6a60-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.031935672s
STEP: Saw pod success
Apr 29 09:24:16.387: INFO: Pod "downward-api-8b9ff45c-6a60-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:24:16.390: INFO: Trying to get logs from node 0mfg0-worker-000001 pod downward-api-8b9ff45c-6a60-11e9-b6b4-b219b18c41e8 container dapi-container: <nil>
STEP: delete the pod
Apr 29 09:24:16.427: INFO: Waiting for pod downward-api-8b9ff45c-6a60-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:24:16.430: INFO: Pod downward-api-8b9ff45c-6a60-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:24:16.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3442" for this suite.
Apr 29 09:24:22.455: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:24:22.561: INFO: namespace downward-api-3442 deletion completed in 6.124550942s

• [SLOW TEST:12.371 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:24:22.561: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8940
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Apr 29 09:24:22.733: INFO: Waiting up to 5m0s for pod "pod-930136b7-6a60-11e9-b6b4-b219b18c41e8" in namespace "emptydir-8940" to be "success or failure"
Apr 29 09:24:22.754: INFO: Pod "pod-930136b7-6a60-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 20.159418ms
Apr 29 09:24:24.762: INFO: Pod "pod-930136b7-6a60-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028153132s
Apr 29 09:24:26.765: INFO: Pod "pod-930136b7-6a60-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.03187704s
Apr 29 09:24:28.769: INFO: Pod "pod-930136b7-6a60-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.035543347s
STEP: Saw pod success
Apr 29 09:24:28.769: INFO: Pod "pod-930136b7-6a60-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:24:28.772: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-930136b7-6a60-11e9-b6b4-b219b18c41e8 container test-container: <nil>
STEP: delete the pod
Apr 29 09:24:28.804: INFO: Waiting for pod pod-930136b7-6a60-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:24:28.808: INFO: Pod pod-930136b7-6a60-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:24:28.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8940" for this suite.
Apr 29 09:24:34.834: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:24:34.950: INFO: namespace emptydir-8940 deletion completed in 6.135106624s

• [SLOW TEST:12.389 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:24:34.952: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9785
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Apr 29 09:24:35.165: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 create -f - --namespace=kubectl-9785'
Apr 29 09:24:36.409: INFO: stderr: ""
Apr 29 09:24:36.409: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 29 09:24:36.409: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9785'
Apr 29 09:24:36.583: INFO: stderr: ""
Apr 29 09:24:36.583: INFO: stdout: "update-demo-nautilus-7zmq8 update-demo-nautilus-gf76d "
Apr 29 09:24:36.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods update-demo-nautilus-7zmq8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9785'
Apr 29 09:24:36.674: INFO: stderr: ""
Apr 29 09:24:36.674: INFO: stdout: ""
Apr 29 09:24:36.674: INFO: update-demo-nautilus-7zmq8 is created but not running
Apr 29 09:24:41.674: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9785'
Apr 29 09:24:41.766: INFO: stderr: ""
Apr 29 09:24:41.766: INFO: stdout: "update-demo-nautilus-7zmq8 update-demo-nautilus-gf76d "
Apr 29 09:24:41.766: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods update-demo-nautilus-7zmq8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9785'
Apr 29 09:24:41.853: INFO: stderr: ""
Apr 29 09:24:41.853: INFO: stdout: ""
Apr 29 09:24:41.853: INFO: update-demo-nautilus-7zmq8 is created but not running
Apr 29 09:24:46.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9785'
Apr 29 09:24:46.984: INFO: stderr: ""
Apr 29 09:24:46.984: INFO: stdout: "update-demo-nautilus-7zmq8 update-demo-nautilus-gf76d "
Apr 29 09:24:46.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods update-demo-nautilus-7zmq8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9785'
Apr 29 09:24:47.090: INFO: stderr: ""
Apr 29 09:24:47.090: INFO: stdout: "true"
Apr 29 09:24:47.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods update-demo-nautilus-7zmq8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9785'
Apr 29 09:24:47.184: INFO: stderr: ""
Apr 29 09:24:47.184: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 29 09:24:47.184: INFO: validating pod update-demo-nautilus-7zmq8
Apr 29 09:24:47.198: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 29 09:24:47.198: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 29 09:24:47.198: INFO: update-demo-nautilus-7zmq8 is verified up and running
Apr 29 09:24:47.199: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods update-demo-nautilus-gf76d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9785'
Apr 29 09:24:47.314: INFO: stderr: ""
Apr 29 09:24:47.314: INFO: stdout: "true"
Apr 29 09:24:47.314: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods update-demo-nautilus-gf76d -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9785'
Apr 29 09:24:47.407: INFO: stderr: ""
Apr 29 09:24:47.407: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 29 09:24:47.407: INFO: validating pod update-demo-nautilus-gf76d
Apr 29 09:24:47.412: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 29 09:24:47.412: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 29 09:24:47.412: INFO: update-demo-nautilus-gf76d is verified up and running
STEP: scaling down the replication controller
Apr 29 09:24:47.416: INFO: scanned /root for discovery docs: <nil>
Apr 29 09:24:47.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-9785'
Apr 29 09:24:47.578: INFO: stderr: ""
Apr 29 09:24:47.578: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 29 09:24:47.578: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9785'
Apr 29 09:24:47.695: INFO: stderr: ""
Apr 29 09:24:47.695: INFO: stdout: "update-demo-nautilus-7zmq8 update-demo-nautilus-gf76d "
STEP: Replicas for name=update-demo: expected=1 actual=2
Apr 29 09:24:52.695: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9785'
Apr 29 09:24:52.789: INFO: stderr: ""
Apr 29 09:24:52.789: INFO: stdout: "update-demo-nautilus-7zmq8 update-demo-nautilus-gf76d "
STEP: Replicas for name=update-demo: expected=1 actual=2
Apr 29 09:24:57.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9785'
Apr 29 09:24:57.886: INFO: stderr: ""
Apr 29 09:24:57.886: INFO: stdout: "update-demo-nautilus-gf76d "
Apr 29 09:24:57.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods update-demo-nautilus-gf76d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9785'
Apr 29 09:24:57.975: INFO: stderr: ""
Apr 29 09:24:57.975: INFO: stdout: "true"
Apr 29 09:24:57.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods update-demo-nautilus-gf76d -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9785'
Apr 29 09:24:58.059: INFO: stderr: ""
Apr 29 09:24:58.059: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 29 09:24:58.059: INFO: validating pod update-demo-nautilus-gf76d
Apr 29 09:24:58.063: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 29 09:24:58.064: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 29 09:24:58.064: INFO: update-demo-nautilus-gf76d is verified up and running
STEP: scaling up the replication controller
Apr 29 09:24:58.066: INFO: scanned /root for discovery docs: <nil>
Apr 29 09:24:58.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-9785'
Apr 29 09:24:59.214: INFO: stderr: ""
Apr 29 09:24:59.214: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 29 09:24:59.214: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9785'
Apr 29 09:24:59.335: INFO: stderr: ""
Apr 29 09:24:59.335: INFO: stdout: "update-demo-nautilus-gf76d update-demo-nautilus-lkk7z "
Apr 29 09:24:59.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods update-demo-nautilus-gf76d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9785'
Apr 29 09:24:59.425: INFO: stderr: ""
Apr 29 09:24:59.425: INFO: stdout: "true"
Apr 29 09:24:59.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods update-demo-nautilus-gf76d -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9785'
Apr 29 09:24:59.519: INFO: stderr: ""
Apr 29 09:24:59.519: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 29 09:24:59.519: INFO: validating pod update-demo-nautilus-gf76d
Apr 29 09:24:59.524: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 29 09:24:59.524: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 29 09:24:59.524: INFO: update-demo-nautilus-gf76d is verified up and running
Apr 29 09:24:59.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods update-demo-nautilus-lkk7z -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9785'
Apr 29 09:24:59.612: INFO: stderr: ""
Apr 29 09:24:59.612: INFO: stdout: ""
Apr 29 09:24:59.613: INFO: update-demo-nautilus-lkk7z is created but not running
Apr 29 09:25:04.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9785'
Apr 29 09:25:04.706: INFO: stderr: ""
Apr 29 09:25:04.707: INFO: stdout: "update-demo-nautilus-gf76d update-demo-nautilus-lkk7z "
Apr 29 09:25:04.707: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods update-demo-nautilus-gf76d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9785'
Apr 29 09:25:04.799: INFO: stderr: ""
Apr 29 09:25:04.799: INFO: stdout: "true"
Apr 29 09:25:04.800: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods update-demo-nautilus-gf76d -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9785'
Apr 29 09:25:04.891: INFO: stderr: ""
Apr 29 09:25:04.891: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 29 09:25:04.891: INFO: validating pod update-demo-nautilus-gf76d
Apr 29 09:25:04.896: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 29 09:25:04.896: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 29 09:25:04.896: INFO: update-demo-nautilus-gf76d is verified up and running
Apr 29 09:25:04.896: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods update-demo-nautilus-lkk7z -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9785'
Apr 29 09:25:04.989: INFO: stderr: ""
Apr 29 09:25:04.989: INFO: stdout: "true"
Apr 29 09:25:04.989: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods update-demo-nautilus-lkk7z -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9785'
Apr 29 09:25:05.098: INFO: stderr: ""
Apr 29 09:25:05.099: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 29 09:25:05.099: INFO: validating pod update-demo-nautilus-lkk7z
Apr 29 09:25:05.109: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 29 09:25:05.109: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 29 09:25:05.109: INFO: update-demo-nautilus-lkk7z is verified up and running
STEP: using delete to clean up resources
Apr 29 09:25:05.109: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 delete --grace-period=0 --force -f - --namespace=kubectl-9785'
Apr 29 09:25:05.227: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 29 09:25:05.227: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr 29 09:25:05.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-9785'
Apr 29 09:25:05.365: INFO: stderr: "No resources found.\n"
Apr 29 09:25:05.365: INFO: stdout: ""
Apr 29 09:25:05.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods -l name=update-demo --namespace=kubectl-9785 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 29 09:25:05.466: INFO: stderr: ""
Apr 29 09:25:05.466: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:25:05.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9785" for this suite.
Apr 29 09:25:11.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:25:11.586: INFO: namespace kubectl-9785 deletion completed in 6.115549426s

• [SLOW TEST:36.634 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:25:11.587: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5444
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating all guestbook components
Apr 29 09:25:11.743: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Apr 29 09:25:11.743: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 create -f - --namespace=kubectl-5444'
Apr 29 09:25:12.139: INFO: stderr: ""
Apr 29 09:25:12.139: INFO: stdout: "service/redis-slave created\n"
Apr 29 09:25:12.148: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Apr 29 09:25:12.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 create -f - --namespace=kubectl-5444'
Apr 29 09:25:12.619: INFO: stderr: ""
Apr 29 09:25:12.619: INFO: stdout: "service/redis-master created\n"
Apr 29 09:25:12.619: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Apr 29 09:25:12.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 create -f - --namespace=kubectl-5444'
Apr 29 09:25:13.085: INFO: stderr: ""
Apr 29 09:25:13.085: INFO: stdout: "service/frontend created\n"
Apr 29 09:25:13.086: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Apr 29 09:25:13.086: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 create -f - --namespace=kubectl-5444'
Apr 29 09:25:13.554: INFO: stderr: ""
Apr 29 09:25:13.554: INFO: stdout: "deployment.apps/frontend created\n"
Apr 29 09:25:13.555: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Apr 29 09:25:13.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 create -f - --namespace=kubectl-5444'
Apr 29 09:25:13.997: INFO: stderr: ""
Apr 29 09:25:13.997: INFO: stdout: "deployment.apps/redis-master created\n"
Apr 29 09:25:13.998: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Apr 29 09:25:14.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 create -f - --namespace=kubectl-5444'
Apr 29 09:25:14.427: INFO: stderr: ""
Apr 29 09:25:14.427: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Apr 29 09:25:14.427: INFO: Waiting for all frontend pods to be Running.
Apr 29 09:26:24.497: INFO: Waiting for frontend to serve content.
Apr 29 09:26:24.513: INFO: Trying to add a new entry to the guestbook.
Apr 29 09:26:24.530: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Apr 29 09:26:24.541: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 delete --grace-period=0 --force -f - --namespace=kubectl-5444'
Apr 29 09:26:24.663: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 29 09:26:24.663: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Apr 29 09:26:24.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 delete --grace-period=0 --force -f - --namespace=kubectl-5444'
Apr 29 09:26:24.852: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 29 09:26:24.852: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Apr 29 09:26:24.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 delete --grace-period=0 --force -f - --namespace=kubectl-5444'
Apr 29 09:26:25.031: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 29 09:26:25.031: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Apr 29 09:26:25.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 delete --grace-period=0 --force -f - --namespace=kubectl-5444'
Apr 29 09:26:25.183: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 29 09:26:25.183: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Apr 29 09:26:25.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 delete --grace-period=0 --force -f - --namespace=kubectl-5444'
Apr 29 09:26:25.317: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 29 09:26:25.317: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Apr 29 09:26:25.318: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 delete --grace-period=0 --force -f - --namespace=kubectl-5444'
Apr 29 09:26:25.419: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 29 09:26:25.419: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:26:25.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5444" for this suite.
Apr 29 09:27:11.436: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:27:11.539: INFO: namespace kubectl-5444 deletion completed in 46.115716331s

• [SLOW TEST:119.952 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:27:11.540: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6735
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-f7b7eb34-6a60-11e9-b6b4-b219b18c41e8
STEP: Creating a pod to test consume secrets
Apr 29 09:27:11.709: INFO: Waiting up to 5m0s for pod "pod-secrets-f7b88f5a-6a60-11e9-b6b4-b219b18c41e8" in namespace "secrets-6735" to be "success or failure"
Apr 29 09:27:11.716: INFO: Pod "pod-secrets-f7b88f5a-6a60-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.958849ms
Apr 29 09:27:13.720: INFO: Pod "pod-secrets-f7b88f5a-6a60-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011349328s
Apr 29 09:27:15.724: INFO: Pod "pod-secrets-f7b88f5a-6a60-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015549959s
Apr 29 09:27:17.728: INFO: Pod "pod-secrets-f7b88f5a-6a60-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.019782048s
STEP: Saw pod success
Apr 29 09:27:17.728: INFO: Pod "pod-secrets-f7b88f5a-6a60-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:27:17.732: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-secrets-f7b88f5a-6a60-11e9-b6b4-b219b18c41e8 container secret-volume-test: <nil>
STEP: delete the pod
Apr 29 09:27:17.829: INFO: Waiting for pod pod-secrets-f7b88f5a-6a60-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:27:17.838: INFO: Pod pod-secrets-f7b88f5a-6a60-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:27:17.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6735" for this suite.
Apr 29 09:27:23.872: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:27:24.190: INFO: namespace secrets-6735 deletion completed in 6.33753719s

• [SLOW TEST:12.650 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:27:24.190: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8651
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-ff4196bc-6a60-11e9-b6b4-b219b18c41e8
STEP: Creating a pod to test consume configMaps
Apr 29 09:27:24.357: INFO: Waiting up to 5m0s for pod "pod-configmaps-ff426081-6a60-11e9-b6b4-b219b18c41e8" in namespace "configmap-8651" to be "success or failure"
Apr 29 09:27:24.371: INFO: Pod "pod-configmaps-ff426081-6a60-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 14.029394ms
Apr 29 09:27:26.375: INFO: Pod "pod-configmaps-ff426081-6a60-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017517757s
Apr 29 09:27:28.379: INFO: Pod "pod-configmaps-ff426081-6a60-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021340987s
Apr 29 09:27:30.382: INFO: Pod "pod-configmaps-ff426081-6a60-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.025092676s
STEP: Saw pod success
Apr 29 09:27:30.382: INFO: Pod "pod-configmaps-ff426081-6a60-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:27:30.386: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-configmaps-ff426081-6a60-11e9-b6b4-b219b18c41e8 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 29 09:27:30.416: INFO: Waiting for pod pod-configmaps-ff426081-6a60-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:27:30.421: INFO: Pod pod-configmaps-ff426081-6a60-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:27:30.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8651" for this suite.
Apr 29 09:27:36.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:27:36.574: INFO: namespace configmap-8651 deletion completed in 6.148314339s

• [SLOW TEST:12.384 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:27:36.575: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-7658
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Apr 29 09:27:43.796: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:27:44.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-7658" for this suite.
Apr 29 09:28:06.844: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:28:06.956: INFO: namespace replicaset-7658 deletion completed in 22.123859917s

• [SLOW TEST:30.380 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:28:06.956: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-8440
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:28:15.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8440" for this suite.
Apr 29 09:28:21.225: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:28:21.507: INFO: namespace kubelet-test-8440 deletion completed in 6.303016021s

• [SLOW TEST:14.551 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:28:21.509: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8123
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-216c9328-6a61-11e9-b6b4-b219b18c41e8
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-216c9328-6a61-11e9-b6b4-b219b18c41e8
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:29:32.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8123" for this suite.
Apr 29 09:29:54.051: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:29:54.201: INFO: namespace configmap-8123 deletion completed in 22.164828979s

• [SLOW TEST:92.693 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:29:54.201: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7118
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating secret secrets-7118/secret-test-58b0709e-6a61-11e9-b6b4-b219b18c41e8
STEP: Creating a pod to test consume secrets
Apr 29 09:29:54.404: INFO: Waiting up to 5m0s for pod "pod-configmaps-58b138bd-6a61-11e9-b6b4-b219b18c41e8" in namespace "secrets-7118" to be "success or failure"
Apr 29 09:29:54.416: INFO: Pod "pod-configmaps-58b138bd-6a61-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 11.930996ms
Apr 29 09:29:56.421: INFO: Pod "pod-configmaps-58b138bd-6a61-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016216573s
Apr 29 09:29:58.424: INFO: Pod "pod-configmaps-58b138bd-6a61-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019692232s
Apr 29 09:30:00.428: INFO: Pod "pod-configmaps-58b138bd-6a61-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.023256989s
STEP: Saw pod success
Apr 29 09:30:00.428: INFO: Pod "pod-configmaps-58b138bd-6a61-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:30:00.430: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-configmaps-58b138bd-6a61-11e9-b6b4-b219b18c41e8 container env-test: <nil>
STEP: delete the pod
Apr 29 09:30:00.457: INFO: Waiting for pod pod-configmaps-58b138bd-6a61-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:30:00.473: INFO: Pod pod-configmaps-58b138bd-6a61-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:30:00.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7118" for this suite.
Apr 29 09:30:06.495: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:30:06.647: INFO: namespace secrets-7118 deletion completed in 6.168756682s

• [SLOW TEST:12.445 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:30:06.647: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9187
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1619
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 29 09:30:06.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-9187'
Apr 29 09:30:06.991: INFO: stderr: ""
Apr 29 09:30:06.991: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Apr 29 09:30:12.043: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pod e2e-test-nginx-pod --namespace=kubectl-9187 -o json'
Apr 29 09:30:12.161: INFO: stderr: ""
Apr 29 09:30:12.161: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"10.2.130.93/32\",\n            \"kubernetes.io/psp\": \"cert-exporter-psp\"\n        },\n        \"creationTimestamp\": \"2019-04-29T09:30:06Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-9187\",\n        \"resourceVersion\": \"11497\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-9187/pods/e2e-test-nginx-pod\",\n        \"uid\": \"602f3ce2-6a61-11e9-9890-000d3a4710ea\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-wlhfr\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"0mfg0-worker-000001\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-wlhfr\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-wlhfr\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-29T09:30:06Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-29T09:30:11Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-29T09:30:11Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-29T09:30:06Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://a313a549f562d513d028071d0513388e10bbd6c471d50d4360c518f5697087b6\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-04-29T09:30:10Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.2.1.5\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.2.130.93\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-04-29T09:30:06Z\"\n    }\n}\n"
STEP: replace the image in the pod
Apr 29 09:30:12.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 replace -f - --namespace=kubectl-9187'
Apr 29 09:30:12.556: INFO: stderr: ""
Apr 29 09:30:12.556: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1624
Apr 29 09:30:12.561: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 delete pods e2e-test-nginx-pod --namespace=kubectl-9187'
Apr 29 09:30:17.860: INFO: stderr: ""
Apr 29 09:30:17.860: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:30:17.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9187" for this suite.
Apr 29 09:30:23.881: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:30:23.986: INFO: namespace kubectl-9187 deletion completed in 6.118961202s

• [SLOW TEST:17.339 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:30:23.987: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-9504
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service endpoint-test2 in namespace services-9504
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9504 to expose endpoints map[]
Apr 29 09:30:24.172: INFO: Get endpoints failed (9.353246ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Apr 29 09:30:25.176: INFO: successfully validated that service endpoint-test2 in namespace services-9504 exposes endpoints map[] (1.012692911s elapsed)
STEP: Creating pod pod1 in namespace services-9504
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9504 to expose endpoints map[pod1:[80]]
Apr 29 09:30:29.255: INFO: successfully validated that service endpoint-test2 in namespace services-9504 exposes endpoints map[pod1:[80]] (4.069040674s elapsed)
STEP: Creating pod pod2 in namespace services-9504
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9504 to expose endpoints map[pod1:[80] pod2:[80]]
Apr 29 09:30:33.320: INFO: successfully validated that service endpoint-test2 in namespace services-9504 exposes endpoints map[pod1:[80] pod2:[80]] (4.056257673s elapsed)
STEP: Deleting pod pod1 in namespace services-9504
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9504 to expose endpoints map[pod2:[80]]
Apr 29 09:30:34.355: INFO: successfully validated that service endpoint-test2 in namespace services-9504 exposes endpoints map[pod2:[80]] (1.026343795s elapsed)
STEP: Deleting pod pod2 in namespace services-9504
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9504 to expose endpoints map[]
Apr 29 09:30:34.378: INFO: successfully validated that service endpoint-test2 in namespace services-9504 exposes endpoints map[] (11.817382ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:30:34.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9504" for this suite.
Apr 29 09:30:56.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:30:56.579: INFO: namespace services-9504 deletion completed in 22.147303481s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:32.592 seconds]
[sig-network] Services
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:30:56.579: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3020
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 29 09:30:56.769: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7dddf4d6-6a61-11e9-b6b4-b219b18c41e8" in namespace "projected-3020" to be "success or failure"
Apr 29 09:30:56.782: INFO: Pod "downwardapi-volume-7dddf4d6-6a61-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 13.534901ms
Apr 29 09:30:58.787: INFO: Pod "downwardapi-volume-7dddf4d6-6a61-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017733712s
Apr 29 09:31:00.791: INFO: Pod "downwardapi-volume-7dddf4d6-6a61-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022423037s
STEP: Saw pod success
Apr 29 09:31:00.791: INFO: Pod "downwardapi-volume-7dddf4d6-6a61-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:31:00.794: INFO: Trying to get logs from node 0mfg0-worker-000000 pod downwardapi-volume-7dddf4d6-6a61-11e9-b6b4-b219b18c41e8 container client-container: <nil>
STEP: delete the pod
Apr 29 09:31:00.827: INFO: Waiting for pod downwardapi-volume-7dddf4d6-6a61-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:31:00.830: INFO: Pod downwardapi-volume-7dddf4d6-6a61-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:31:00.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3020" for this suite.
Apr 29 09:31:06.848: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:31:06.960: INFO: namespace projected-3020 deletion completed in 6.126102658s

• [SLOW TEST:10.381 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:31:06.962: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-8365
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Apr 29 09:31:07.156: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-8365,SelfLink:/api/v1/namespaces/watch-8365/configmaps/e2e-watch-test-watch-closed,UID:840eaac8-6a61-11e9-9890-000d3a4710ea,ResourceVersion:11706,Generation:0,CreationTimestamp:2019-04-29 09:31:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr 29 09:31:07.156: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-8365,SelfLink:/api/v1/namespaces/watch-8365/configmaps/e2e-watch-test-watch-closed,UID:840eaac8-6a61-11e9-9890-000d3a4710ea,ResourceVersion:11707,Generation:0,CreationTimestamp:2019-04-29 09:31:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Apr 29 09:31:07.173: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-8365,SelfLink:/api/v1/namespaces/watch-8365/configmaps/e2e-watch-test-watch-closed,UID:840eaac8-6a61-11e9-9890-000d3a4710ea,ResourceVersion:11708,Generation:0,CreationTimestamp:2019-04-29 09:31:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr 29 09:31:07.173: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-8365,SelfLink:/api/v1/namespaces/watch-8365/configmaps/e2e-watch-test-watch-closed,UID:840eaac8-6a61-11e9-9890-000d3a4710ea,ResourceVersion:11709,Generation:0,CreationTimestamp:2019-04-29 09:31:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:31:07.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8365" for this suite.
Apr 29 09:31:13.207: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:31:13.315: INFO: namespace watch-8365 deletion completed in 6.129132718s

• [SLOW TEST:6.354 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:31:13.316: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5605
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-87d825e6-6a61-11e9-b6b4-b219b18c41e8
STEP: Creating a pod to test consume configMaps
Apr 29 09:31:13.531: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-87d8d628-6a61-11e9-b6b4-b219b18c41e8" in namespace "projected-5605" to be "success or failure"
Apr 29 09:31:13.545: INFO: Pod "pod-projected-configmaps-87d8d628-6a61-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 13.699698ms
Apr 29 09:31:15.575: INFO: Pod "pod-projected-configmaps-87d8d628-6a61-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044164425s
Apr 29 09:31:17.597: INFO: Pod "pod-projected-configmaps-87d8d628-6a61-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.06619314s
Apr 29 09:31:19.601: INFO: Pod "pod-projected-configmaps-87d8d628-6a61-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.069928301s
STEP: Saw pod success
Apr 29 09:31:19.601: INFO: Pod "pod-projected-configmaps-87d8d628-6a61-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:31:19.604: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-projected-configmaps-87d8d628-6a61-11e9-b6b4-b219b18c41e8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 29 09:31:19.778: INFO: Waiting for pod pod-projected-configmaps-87d8d628-6a61-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:31:19.781: INFO: Pod pod-projected-configmaps-87d8d628-6a61-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:31:19.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5605" for this suite.
Apr 29 09:31:25.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:31:25.921: INFO: namespace projected-5605 deletion completed in 6.136338106s

• [SLOW TEST:12.605 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:31:25.922: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-3005
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service multi-endpoint-test in namespace services-3005
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3005 to expose endpoints map[]
Apr 29 09:31:26.113: INFO: successfully validated that service multi-endpoint-test in namespace services-3005 exposes endpoints map[] (5.535178ms elapsed)
STEP: Creating pod pod1 in namespace services-3005
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3005 to expose endpoints map[pod1:[100]]
Apr 29 09:31:30.187: INFO: successfully validated that service multi-endpoint-test in namespace services-3005 exposes endpoints map[pod1:[100]] (4.045345718s elapsed)
STEP: Creating pod pod2 in namespace services-3005
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3005 to expose endpoints map[pod1:[100] pod2:[101]]
Apr 29 09:31:34.278: INFO: successfully validated that service multi-endpoint-test in namespace services-3005 exposes endpoints map[pod1:[100] pod2:[101]] (4.081739773s elapsed)
STEP: Deleting pod pod1 in namespace services-3005
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3005 to expose endpoints map[pod2:[101]]
Apr 29 09:31:34.320: INFO: successfully validated that service multi-endpoint-test in namespace services-3005 exposes endpoints map[pod2:[101]] (33.761573ms elapsed)
STEP: Deleting pod pod2 in namespace services-3005
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3005 to expose endpoints map[]
Apr 29 09:31:35.343: INFO: successfully validated that service multi-endpoint-test in namespace services-3005 exposes endpoints map[] (1.013618391s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:31:35.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3005" for this suite.
Apr 29 09:31:41.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:31:41.562: INFO: namespace services-3005 deletion completed in 6.16346061s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:15.640 seconds]
[sig-network] Services
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:31:41.563: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1858
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting the proxy server
Apr 29 09:31:41.732: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-244696311 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:31:41.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1858" for this suite.
Apr 29 09:31:47.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:31:47.953: INFO: namespace kubectl-1858 deletion completed in 6.137545418s

• [SLOW TEST:6.391 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:31:47.954: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-4553
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Apr 29 09:31:48.107: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:31:57.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4553" for this suite.
Apr 29 09:32:19.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:32:19.398: INFO: namespace init-container-4553 deletion completed in 22.118721299s

• [SLOW TEST:31.444 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:32:19.398: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-9388
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 29 09:32:19.601: INFO: Create a RollingUpdate DaemonSet
Apr 29 09:32:19.611: INFO: Check that daemon pods launch on every node of the cluster
Apr 29 09:32:19.619: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:32:19.633: INFO: Number of nodes with available pods: 0
Apr 29 09:32:19.633: INFO: Node 0mfg0-worker-000000 is running more than one daemon pod
Apr 29 09:32:20.638: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:32:20.642: INFO: Number of nodes with available pods: 0
Apr 29 09:32:20.642: INFO: Node 0mfg0-worker-000000 is running more than one daemon pod
Apr 29 09:32:21.639: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:32:21.644: INFO: Number of nodes with available pods: 0
Apr 29 09:32:21.644: INFO: Node 0mfg0-worker-000000 is running more than one daemon pod
Apr 29 09:32:22.638: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:32:22.642: INFO: Number of nodes with available pods: 0
Apr 29 09:32:22.642: INFO: Node 0mfg0-worker-000000 is running more than one daemon pod
Apr 29 09:32:23.638: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:32:23.642: INFO: Number of nodes with available pods: 0
Apr 29 09:32:23.642: INFO: Node 0mfg0-worker-000000 is running more than one daemon pod
Apr 29 09:32:24.638: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:32:24.642: INFO: Number of nodes with available pods: 3
Apr 29 09:32:24.642: INFO: Number of running nodes: 3, number of available pods: 3
Apr 29 09:32:24.642: INFO: Update the DaemonSet to trigger a rollout
Apr 29 09:32:24.650: INFO: Updating DaemonSet daemon-set
Apr 29 09:32:29.702: INFO: Roll back the DaemonSet before rollout is complete
Apr 29 09:32:29.714: INFO: Updating DaemonSet daemon-set
Apr 29 09:32:29.714: INFO: Make sure DaemonSet rollback is complete
Apr 29 09:32:29.735: INFO: Wrong image for pod: daemon-set-gc9hr. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr 29 09:32:29.735: INFO: Pod daemon-set-gc9hr is not available
Apr 29 09:32:29.748: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:32:30.753: INFO: Wrong image for pod: daemon-set-gc9hr. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr 29 09:32:30.753: INFO: Pod daemon-set-gc9hr is not available
Apr 29 09:32:30.757: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:32:31.753: INFO: Wrong image for pod: daemon-set-gc9hr. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr 29 09:32:31.753: INFO: Pod daemon-set-gc9hr is not available
Apr 29 09:32:31.756: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:32:32.753: INFO: Wrong image for pod: daemon-set-gc9hr. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr 29 09:32:32.753: INFO: Pod daemon-set-gc9hr is not available
Apr 29 09:32:32.757: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:32:33.753: INFO: Wrong image for pod: daemon-set-gc9hr. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr 29 09:32:33.753: INFO: Pod daemon-set-gc9hr is not available
Apr 29 09:32:33.757: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:32:34.753: INFO: Wrong image for pod: daemon-set-gc9hr. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr 29 09:32:34.753: INFO: Pod daemon-set-gc9hr is not available
Apr 29 09:32:34.757: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 09:32:35.753: INFO: Pod daemon-set-bxtzx is not available
Apr 29 09:32:35.757: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9388, will wait for the garbage collector to delete the pods
Apr 29 09:32:35.839: INFO: Deleting DaemonSet.extensions daemon-set took: 23.109996ms
Apr 29 09:32:35.940: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.98269ms
Apr 29 09:32:49.744: INFO: Number of nodes with available pods: 0
Apr 29 09:32:49.744: INFO: Number of running nodes: 0, number of available pods: 0
Apr 29 09:32:49.746: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9388/daemonsets","resourceVersion":"12123"},"items":null}

Apr 29 09:32:49.749: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9388/pods","resourceVersion":"12123"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:32:49.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9388" for this suite.
Apr 29 09:32:55.779: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:32:55.875: INFO: namespace daemonsets-9388 deletion completed in 6.108251142s

• [SLOW TEST:36.477 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:32:55.875: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-7357
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Apr 29 09:33:08.091: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 29 09:33:08.095: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 29 09:33:10.095: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 29 09:33:10.099: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 29 09:33:12.095: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 29 09:33:12.100: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 29 09:33:14.095: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 29 09:33:14.117: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 29 09:33:16.095: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 29 09:33:16.099: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 29 09:33:18.095: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 29 09:33:18.099: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 29 09:33:20.095: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 29 09:33:20.099: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 29 09:33:22.095: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 29 09:33:22.099: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 29 09:33:24.096: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 29 09:33:24.098: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 29 09:33:26.095: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 29 09:33:26.099: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 29 09:33:28.095: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 29 09:33:28.099: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 29 09:33:30.095: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 29 09:33:30.099: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:33:30.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7357" for this suite.
Apr 29 09:33:52.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:33:52.284: INFO: namespace container-lifecycle-hook-7357 deletion completed in 22.171092676s

• [SLOW TEST:56.409 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:33:52.285: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-8562
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override command
Apr 29 09:33:52.444: INFO: Waiting up to 5m0s for pod "client-containers-e6944904-6a61-11e9-b6b4-b219b18c41e8" in namespace "containers-8562" to be "success or failure"
Apr 29 09:33:52.456: INFO: Pod "client-containers-e6944904-6a61-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 12.287741ms
Apr 29 09:33:54.460: INFO: Pod "client-containers-e6944904-6a61-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015795073s
Apr 29 09:33:56.464: INFO: Pod "client-containers-e6944904-6a61-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019687544s
Apr 29 09:33:58.479: INFO: Pod "client-containers-e6944904-6a61-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.034639474s
Apr 29 09:34:00.483: INFO: Pod "client-containers-e6944904-6a61-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.038389313s
STEP: Saw pod success
Apr 29 09:34:00.483: INFO: Pod "client-containers-e6944904-6a61-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:34:00.486: INFO: Trying to get logs from node 0mfg0-worker-000001 pod client-containers-e6944904-6a61-11e9-b6b4-b219b18c41e8 container test-container: <nil>
STEP: delete the pod
Apr 29 09:34:00.508: INFO: Waiting for pod client-containers-e6944904-6a61-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:34:00.514: INFO: Pod client-containers-e6944904-6a61-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:34:00.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8562" for this suite.
Apr 29 09:34:06.542: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:34:06.700: INFO: namespace containers-8562 deletion completed in 6.180604319s

• [SLOW TEST:14.415 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:34:06.700: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5658
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Apr 29 09:34:06.907: INFO: Waiting up to 5m0s for pod "pod-ef30be69-6a61-11e9-b6b4-b219b18c41e8" in namespace "emptydir-5658" to be "success or failure"
Apr 29 09:34:06.925: INFO: Pod "pod-ef30be69-6a61-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 18.444206ms
Apr 29 09:34:08.929: INFO: Pod "pod-ef30be69-6a61-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022546977s
Apr 29 09:34:10.933: INFO: Pod "pod-ef30be69-6a61-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026514484s
STEP: Saw pod success
Apr 29 09:34:10.933: INFO: Pod "pod-ef30be69-6a61-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:34:10.936: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-ef30be69-6a61-11e9-b6b4-b219b18c41e8 container test-container: <nil>
STEP: delete the pod
Apr 29 09:34:10.990: INFO: Waiting for pod pod-ef30be69-6a61-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:34:10.993: INFO: Pod pod-ef30be69-6a61-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:34:10.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5658" for this suite.
Apr 29 09:34:17.015: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:34:17.146: INFO: namespace emptydir-5658 deletion completed in 6.148774839s

• [SLOW TEST:10.446 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:34:17.148: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7572
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the initial replication controller
Apr 29 09:34:17.341: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 create -f - --namespace=kubectl-7572'
Apr 29 09:34:17.713: INFO: stderr: ""
Apr 29 09:34:17.713: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 29 09:34:17.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7572'
Apr 29 09:34:17.892: INFO: stderr: ""
Apr 29 09:34:17.892: INFO: stdout: "update-demo-nautilus-gnfr2 update-demo-nautilus-ksvph "
Apr 29 09:34:17.892: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods update-demo-nautilus-gnfr2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7572'
Apr 29 09:34:17.993: INFO: stderr: ""
Apr 29 09:34:17.993: INFO: stdout: ""
Apr 29 09:34:17.993: INFO: update-demo-nautilus-gnfr2 is created but not running
Apr 29 09:34:22.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7572'
Apr 29 09:34:23.090: INFO: stderr: ""
Apr 29 09:34:23.090: INFO: stdout: "update-demo-nautilus-gnfr2 update-demo-nautilus-ksvph "
Apr 29 09:34:23.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods update-demo-nautilus-gnfr2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7572'
Apr 29 09:34:23.180: INFO: stderr: ""
Apr 29 09:34:23.180: INFO: stdout: "true"
Apr 29 09:34:23.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods update-demo-nautilus-gnfr2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7572'
Apr 29 09:34:23.292: INFO: stderr: ""
Apr 29 09:34:23.292: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 29 09:34:23.292: INFO: validating pod update-demo-nautilus-gnfr2
Apr 29 09:34:23.298: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 29 09:34:23.298: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 29 09:34:23.298: INFO: update-demo-nautilus-gnfr2 is verified up and running
Apr 29 09:34:23.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods update-demo-nautilus-ksvph -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7572'
Apr 29 09:34:23.383: INFO: stderr: ""
Apr 29 09:34:23.383: INFO: stdout: "true"
Apr 29 09:34:23.383: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods update-demo-nautilus-ksvph -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7572'
Apr 29 09:34:23.467: INFO: stderr: ""
Apr 29 09:34:23.467: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 29 09:34:23.467: INFO: validating pod update-demo-nautilus-ksvph
Apr 29 09:34:23.472: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 29 09:34:23.472: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 29 09:34:23.472: INFO: update-demo-nautilus-ksvph is verified up and running
STEP: rolling-update to new replication controller
Apr 29 09:34:23.475: INFO: scanned /root for discovery docs: <nil>
Apr 29 09:34:23.475: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-7572'
Apr 29 09:34:47.239: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Apr 29 09:34:47.239: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 29 09:34:47.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7572'
Apr 29 09:34:47.346: INFO: stderr: ""
Apr 29 09:34:47.346: INFO: stdout: "update-demo-kitten-g948j update-demo-kitten-xbh5j update-demo-nautilus-ksvph "
STEP: Replicas for name=update-demo: expected=2 actual=3
Apr 29 09:34:52.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7572'
Apr 29 09:34:52.433: INFO: stderr: ""
Apr 29 09:34:52.433: INFO: stdout: "update-demo-kitten-g948j update-demo-kitten-xbh5j "
Apr 29 09:34:52.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods update-demo-kitten-g948j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7572'
Apr 29 09:34:52.518: INFO: stderr: ""
Apr 29 09:34:52.518: INFO: stdout: "true"
Apr 29 09:34:52.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods update-demo-kitten-g948j -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7572'
Apr 29 09:34:52.608: INFO: stderr: ""
Apr 29 09:34:52.608: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Apr 29 09:34:52.608: INFO: validating pod update-demo-kitten-g948j
Apr 29 09:34:52.614: INFO: got data: {
  "image": "kitten.jpg"
}

Apr 29 09:34:52.614: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Apr 29 09:34:52.614: INFO: update-demo-kitten-g948j is verified up and running
Apr 29 09:34:52.621: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods update-demo-kitten-xbh5j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7572'
Apr 29 09:34:52.712: INFO: stderr: ""
Apr 29 09:34:52.712: INFO: stdout: "true"
Apr 29 09:34:52.712: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods update-demo-kitten-xbh5j -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7572'
Apr 29 09:34:52.809: INFO: stderr: ""
Apr 29 09:34:52.809: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Apr 29 09:34:52.809: INFO: validating pod update-demo-kitten-xbh5j
Apr 29 09:34:52.815: INFO: got data: {
  "image": "kitten.jpg"
}

Apr 29 09:34:52.815: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Apr 29 09:34:52.815: INFO: update-demo-kitten-xbh5j is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:34:52.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7572" for this suite.
Apr 29 09:35:16.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:35:16.988: INFO: namespace kubectl-7572 deletion completed in 24.1697563s

• [SLOW TEST:59.841 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:35:16.989: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3140
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-1911837f-6a62-11e9-b6b4-b219b18c41e8
STEP: Creating a pod to test consume secrets
Apr 29 09:35:17.161: INFO: Waiting up to 5m0s for pod "pod-secrets-191225a2-6a62-11e9-b6b4-b219b18c41e8" in namespace "secrets-3140" to be "success or failure"
Apr 29 09:35:17.182: INFO: Pod "pod-secrets-191225a2-6a62-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 20.890612ms
Apr 29 09:35:19.186: INFO: Pod "pod-secrets-191225a2-6a62-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024688789s
Apr 29 09:35:21.195: INFO: Pod "pod-secrets-191225a2-6a62-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034234467s
STEP: Saw pod success
Apr 29 09:35:21.195: INFO: Pod "pod-secrets-191225a2-6a62-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:35:21.204: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-secrets-191225a2-6a62-11e9-b6b4-b219b18c41e8 container secret-volume-test: <nil>
STEP: delete the pod
Apr 29 09:35:21.249: INFO: Waiting for pod pod-secrets-191225a2-6a62-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:35:21.264: INFO: Pod pod-secrets-191225a2-6a62-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:35:21.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3140" for this suite.
Apr 29 09:35:27.283: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:35:27.390: INFO: namespace secrets-3140 deletion completed in 6.12003831s

• [SLOW TEST:10.402 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:35:27.391: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6133
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0429 09:35:37.601988      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 29 09:35:37.602: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:35:37.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6133" for this suite.
Apr 29 09:35:43.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:35:43.734: INFO: namespace gc-6133 deletion completed in 6.129137054s

• [SLOW TEST:16.344 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:35:43.735: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-8096
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating replication controller svc-latency-rc in namespace svc-latency-8096
I0429 09:35:43.931672      15 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-8096, replica count: 1
I0429 09:35:44.982277      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0429 09:35:45.982535      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0429 09:35:46.983163      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0429 09:35:47.983879      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0429 09:35:48.984263      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 29 09:35:49.111: INFO: Created: latency-svc-4cwng
Apr 29 09:35:49.323: INFO: Got endpoints: latency-svc-4cwng [238.278511ms]
Apr 29 09:35:49.356: INFO: Created: latency-svc-mpjng
Apr 29 09:35:49.370: INFO: Got endpoints: latency-svc-mpjng [46.130748ms]
Apr 29 09:35:49.381: INFO: Created: latency-svc-sc8dm
Apr 29 09:35:49.407: INFO: Created: latency-svc-7wwcv
Apr 29 09:35:49.408: INFO: Got endpoints: latency-svc-sc8dm [81.46929ms]
Apr 29 09:35:49.486: INFO: Got endpoints: latency-svc-7wwcv [159.484947ms]
Apr 29 09:35:49.489: INFO: Created: latency-svc-6fzpq
Apr 29 09:35:49.489: INFO: Got endpoints: latency-svc-6fzpq [158.138134ms]
Apr 29 09:35:49.492: INFO: Created: latency-svc-jn5zl
Apr 29 09:35:49.493: INFO: Got endpoints: latency-svc-jn5zl [160.952861ms]
Apr 29 09:35:49.517: INFO: Created: latency-svc-9gqg2
Apr 29 09:35:49.518: INFO: Created: latency-svc-899ms
Apr 29 09:35:49.518: INFO: Got endpoints: latency-svc-899ms [183.781282ms]
Apr 29 09:35:49.518: INFO: Got endpoints: latency-svc-9gqg2 [185.472598ms]
Apr 29 09:35:49.531: INFO: Created: latency-svc-dvkmn
Apr 29 09:35:49.554: INFO: Got endpoints: latency-svc-dvkmn [221.416648ms]
Apr 29 09:35:49.557: INFO: Created: latency-svc-g2fvj
Apr 29 09:35:49.579: INFO: Got endpoints: latency-svc-g2fvj [245.290479ms]
Apr 29 09:35:49.595: INFO: Created: latency-svc-pwmkm
Apr 29 09:35:49.614: INFO: Got endpoints: latency-svc-pwmkm [280.399319ms]
Apr 29 09:35:49.615: INFO: Created: latency-svc-vjwj6
Apr 29 09:35:49.640: INFO: Created: latency-svc-5lw65
Apr 29 09:35:49.640: INFO: Got endpoints: latency-svc-5lw65 [304.12405ms]
Apr 29 09:35:49.643: INFO: Got endpoints: latency-svc-vjwj6 [308.024487ms]
Apr 29 09:35:49.673: INFO: Created: latency-svc-sq77l
Apr 29 09:35:49.673: INFO: Got endpoints: latency-svc-sq77l [336.772666ms]
Apr 29 09:35:49.723: INFO: Created: latency-svc-f7pfs
Apr 29 09:35:49.728: INFO: Created: latency-svc-v79bz
Apr 29 09:35:49.747: INFO: Got endpoints: latency-svc-f7pfs [411.165688ms]
Apr 29 09:35:49.760: INFO: Created: latency-svc-wjxxz
Apr 29 09:35:49.771: INFO: Got endpoints: latency-svc-v79bz [443.900505ms]
Apr 29 09:35:49.785: INFO: Created: latency-svc-ggst8
Apr 29 09:35:49.786: INFO: Got endpoints: latency-svc-wjxxz [415.934934ms]
Apr 29 09:35:49.796: INFO: Got endpoints: latency-svc-ggst8 [387.943563ms]
Apr 29 09:35:49.809: INFO: Created: latency-svc-v7qhn
Apr 29 09:35:49.848: INFO: Created: latency-svc-lgcxv
Apr 29 09:35:49.848: INFO: Got endpoints: latency-svc-v7qhn [361.479606ms]
Apr 29 09:35:49.885: INFO: Created: latency-svc-htnfq
Apr 29 09:35:49.885: INFO: Got endpoints: latency-svc-htnfq [392.922611ms]
Apr 29 09:35:49.886: INFO: Got endpoints: latency-svc-lgcxv [396.334844ms]
Apr 29 09:35:49.903: INFO: Created: latency-svc-cz97z
Apr 29 09:35:49.926: INFO: Got endpoints: latency-svc-cz97z [407.30185ms]
Apr 29 09:35:49.928: INFO: Created: latency-svc-trtpz
Apr 29 09:35:49.940: INFO: Created: latency-svc-ln6tv
Apr 29 09:35:49.940: INFO: Got endpoints: latency-svc-trtpz [421.202185ms]
Apr 29 09:35:49.970: INFO: Got endpoints: latency-svc-ln6tv [415.274328ms]
Apr 29 09:35:49.983: INFO: Created: latency-svc-rd5kr
Apr 29 09:35:50.003: INFO: Got endpoints: latency-svc-rd5kr [424.243714ms]
Apr 29 09:35:50.005: INFO: Created: latency-svc-c8jtb
Apr 29 09:35:50.013: INFO: Created: latency-svc-6vdft
Apr 29 09:35:50.023: INFO: Got endpoints: latency-svc-c8jtb [408.183259ms]
Apr 29 09:35:50.045: INFO: Got endpoints: latency-svc-6vdft [404.845626ms]
Apr 29 09:35:50.055: INFO: Created: latency-svc-bcffc
Apr 29 09:35:50.056: INFO: Created: latency-svc-srd85
Apr 29 09:35:50.056: INFO: Got endpoints: latency-svc-bcffc [413.360609ms]
Apr 29 09:35:50.109: INFO: Created: latency-svc-bp5z5
Apr 29 09:35:50.110: INFO: Got endpoints: latency-svc-srd85 [436.804735ms]
Apr 29 09:35:50.113: INFO: Got endpoints: latency-svc-bp5z5 [365.401942ms]
Apr 29 09:35:50.134: INFO: Created: latency-svc-vjkt6
Apr 29 09:35:50.155: INFO: Created: latency-svc-m7bdz
Apr 29 09:35:50.155: INFO: Got endpoints: latency-svc-vjkt6 [384.546027ms]
Apr 29 09:35:50.174: INFO: Got endpoints: latency-svc-m7bdz [388.243863ms]
Apr 29 09:35:50.175: INFO: Created: latency-svc-qmvd4
Apr 29 09:35:50.191: INFO: Got endpoints: latency-svc-qmvd4 [379.844982ms]
Apr 29 09:35:50.242: INFO: Created: latency-svc-gsv4s
Apr 29 09:35:50.243: INFO: Created: latency-svc-r5rjx
Apr 29 09:35:50.243: INFO: Got endpoints: latency-svc-gsv4s [395.544433ms]
Apr 29 09:35:50.261: INFO: Created: latency-svc-wkb6x
Apr 29 09:35:50.263: INFO: Got endpoints: latency-svc-r5rjx [377.607159ms]
Apr 29 09:35:50.269: INFO: Got endpoints: latency-svc-wkb6x [383.677617ms]
Apr 29 09:35:50.291: INFO: Created: latency-svc-h6kjs
Apr 29 09:35:50.314: INFO: Got endpoints: latency-svc-h6kjs [388.762966ms]
Apr 29 09:35:50.319: INFO: Created: latency-svc-976h8
Apr 29 09:35:50.372: INFO: Got endpoints: latency-svc-976h8 [432.322388ms]
Apr 29 09:35:50.414: INFO: Created: latency-svc-xwxrp
Apr 29 09:35:50.415: INFO: Created: latency-svc-l9qhg
Apr 29 09:35:50.416: INFO: Got endpoints: latency-svc-xwxrp [445.423314ms]
Apr 29 09:35:50.416: INFO: Got endpoints: latency-svc-l9qhg [412.855598ms]
Apr 29 09:35:50.430: INFO: Created: latency-svc-vbb6v
Apr 29 09:35:50.443: INFO: Got endpoints: latency-svc-vbb6v [420.731275ms]
Apr 29 09:35:50.458: INFO: Created: latency-svc-p6tq2
Apr 29 09:35:50.508: INFO: Got endpoints: latency-svc-p6tq2 [462.469479ms]
Apr 29 09:35:50.508: INFO: Created: latency-svc-7jdnc
Apr 29 09:35:50.520: INFO: Got endpoints: latency-svc-7jdnc [463.63809ms]
Apr 29 09:35:50.521: INFO: Created: latency-svc-wp76x
Apr 29 09:35:50.550: INFO: Created: latency-svc-qvr9k
Apr 29 09:35:50.551: INFO: Got endpoints: latency-svc-wp76x [441.024171ms]
Apr 29 09:35:50.568: INFO: Got endpoints: latency-svc-qvr9k [455.780015ms]
Apr 29 09:35:50.569: INFO: Created: latency-svc-xvbbw
Apr 29 09:35:50.578: INFO: Got endpoints: latency-svc-xvbbw [422.909896ms]
Apr 29 09:35:50.587: INFO: Created: latency-svc-bqx5x
Apr 29 09:35:50.629: INFO: Got endpoints: latency-svc-bqx5x [455.002607ms]
Apr 29 09:35:50.639: INFO: Created: latency-svc-kl995
Apr 29 09:35:50.639: INFO: Got endpoints: latency-svc-kl995 [448.752246ms]
Apr 29 09:35:50.669: INFO: Created: latency-svc-znfqq
Apr 29 09:35:50.669: INFO: Got endpoints: latency-svc-znfqq [424.932216ms]
Apr 29 09:35:50.683: INFO: Created: latency-svc-87rtf
Apr 29 09:35:50.709: INFO: Got endpoints: latency-svc-87rtf [444.635006ms]
Apr 29 09:35:50.713: INFO: Created: latency-svc-swdwj
Apr 29 09:35:50.731: INFO: Got endpoints: latency-svc-swdwj [461.490169ms]
Apr 29 09:35:50.731: INFO: Created: latency-svc-t9t7n
Apr 29 09:35:50.771: INFO: Got endpoints: latency-svc-t9t7n [454.3326ms]
Apr 29 09:35:50.787: INFO: Created: latency-svc-w4zs6
Apr 29 09:35:50.808: INFO: Got endpoints: latency-svc-w4zs6 [434.675409ms]
Apr 29 09:35:50.810: INFO: Created: latency-svc-d6lb6
Apr 29 09:35:50.827: INFO: Got endpoints: latency-svc-d6lb6 [410.162072ms]
Apr 29 09:35:50.829: INFO: Created: latency-svc-l62br
Apr 29 09:35:50.837: INFO: Got endpoints: latency-svc-l62br [421.333181ms]
Apr 29 09:35:50.857: INFO: Created: latency-svc-n6kzr
Apr 29 09:35:50.899: INFO: Created: latency-svc-s8mqn
Apr 29 09:35:50.899: INFO: Got endpoints: latency-svc-n6kzr [455.857115ms]
Apr 29 09:35:50.913: INFO: Got endpoints: latency-svc-s8mqn [404.69292ms]
Apr 29 09:35:50.915: INFO: Created: latency-svc-sln25
Apr 29 09:35:50.935: INFO: Created: latency-svc-ksgdm
Apr 29 09:35:50.935: INFO: Got endpoints: latency-svc-sln25 [414.04501ms]
Apr 29 09:35:50.961: INFO: Got endpoints: latency-svc-ksgdm [409.137662ms]
Apr 29 09:35:50.961: INFO: Created: latency-svc-qz5z4
Apr 29 09:35:50.976: INFO: Created: latency-svc-fzr88
Apr 29 09:35:50.981: INFO: Got endpoints: latency-svc-qz5z4 [411.641687ms]
Apr 29 09:35:51.019: INFO: Created: latency-svc-fxf78
Apr 29 09:35:51.019: INFO: Got endpoints: latency-svc-fzr88 [432.265786ms]
Apr 29 09:35:51.045: INFO: Created: latency-svc-ch9zr
Apr 29 09:35:51.045: INFO: Got endpoints: latency-svc-fxf78 [408.188753ms]
Apr 29 09:35:51.078: INFO: Got endpoints: latency-svc-ch9zr [438.844449ms]
Apr 29 09:35:51.079: INFO: Created: latency-svc-7fc9w
Apr 29 09:35:51.080: INFO: Got endpoints: latency-svc-7fc9w [411.123481ms]
Apr 29 09:35:51.103: INFO: Created: latency-svc-46xcq
Apr 29 09:35:51.146: INFO: Created: latency-svc-tfn52
Apr 29 09:35:51.148: INFO: Got endpoints: latency-svc-46xcq [439.396954ms]
Apr 29 09:35:51.178: INFO: Created: latency-svc-92fmn
Apr 29 09:35:51.178: INFO: Got endpoints: latency-svc-tfn52 [447.012427ms]
Apr 29 09:35:51.179: INFO: Got endpoints: latency-svc-92fmn [407.494744ms]
Apr 29 09:35:51.196: INFO: Created: latency-svc-n5bcq
Apr 29 09:35:51.218: INFO: Got endpoints: latency-svc-n5bcq [410.253471ms]
Apr 29 09:35:51.247: INFO: Created: latency-svc-vrc9h
Apr 29 09:35:51.272: INFO: Got endpoints: latency-svc-vrc9h [445.671712ms]
Apr 29 09:35:51.273: INFO: Created: latency-svc-x4jlw
Apr 29 09:35:51.286: INFO: Created: latency-svc-b48gm
Apr 29 09:35:51.313: INFO: Got endpoints: latency-svc-x4jlw [474.729094ms]
Apr 29 09:35:51.314: INFO: Created: latency-svc-wv849
Apr 29 09:35:51.331: INFO: Created: latency-svc-4m6wh
Apr 29 09:35:51.347: INFO: Created: latency-svc-7vlmg
Apr 29 09:35:51.366: INFO: Created: latency-svc-fv8h2
Apr 29 09:35:51.366: INFO: Got endpoints: latency-svc-b48gm [466.671315ms]
Apr 29 09:35:51.408: INFO: Created: latency-svc-bkz8s
Apr 29 09:35:51.425: INFO: Got endpoints: latency-svc-wv849 [512.545059ms]
Apr 29 09:35:51.437: INFO: Created: latency-svc-65wbf
Apr 29 09:35:51.451: INFO: Created: latency-svc-zjsxh
Apr 29 09:35:51.472: INFO: Got endpoints: latency-svc-4m6wh [536.866694ms]
Apr 29 09:35:51.478: INFO: Created: latency-svc-2cq55
Apr 29 09:35:51.532: INFO: Created: latency-svc-swf5k
Apr 29 09:35:51.532: INFO: Got endpoints: latency-svc-7vlmg [571.034924ms]
Apr 29 09:35:51.547: INFO: Created: latency-svc-jgfcg
Apr 29 09:35:51.568: INFO: Created: latency-svc-wjvvz
Apr 29 09:35:51.570: INFO: Got endpoints: latency-svc-fv8h2 [588.712194ms]
Apr 29 09:35:51.591: INFO: Created: latency-svc-2pqx5
Apr 29 09:35:51.619: INFO: Got endpoints: latency-svc-bkz8s [598.902192ms]
Apr 29 09:35:51.621: INFO: Created: latency-svc-9rttv
Apr 29 09:35:51.656: INFO: Created: latency-svc-wbzxt
Apr 29 09:35:51.670: INFO: Got endpoints: latency-svc-65wbf [624.44604ms]
Apr 29 09:35:51.673: INFO: Created: latency-svc-rbgfk
Apr 29 09:35:51.683: INFO: Created: latency-svc-gcgxv
Apr 29 09:35:51.945: INFO: Created: latency-svc-v5lcp
Apr 29 09:35:51.945: INFO: Created: latency-svc-bq82l
Apr 29 09:35:51.945: INFO: Got endpoints: latency-svc-2cq55 [865.127368ms]
Apr 29 09:35:51.945: INFO: Got endpoints: latency-svc-zjsxh [866.603182ms]
Apr 29 09:35:51.947: INFO: Got endpoints: latency-svc-jgfcg [768.16673ms]
Apr 29 09:35:51.948: INFO: Got endpoints: latency-svc-swf5k [799.26983ms]
Apr 29 09:35:51.948: INFO: Got endpoints: latency-svc-wjvvz [769.090539ms]
Apr 29 09:35:51.965: INFO: Got endpoints: latency-svc-2pqx5 [746.627321ms]
Apr 29 09:35:51.965: INFO: Created: latency-svc-djr94
Apr 29 09:35:51.978: INFO: Created: latency-svc-9pxj9
Apr 29 09:35:52.000: INFO: Created: latency-svc-vb84q
Apr 29 09:35:52.021: INFO: Got endpoints: latency-svc-9rttv [746.707622ms]
Apr 29 09:35:52.028: INFO: Created: latency-svc-qdf2r
Apr 29 09:35:52.070: INFO: Created: latency-svc-rw4t4
Apr 29 09:35:52.076: INFO: Got endpoints: latency-svc-wbzxt [762.569275ms]
Apr 29 09:35:52.093: INFO: Created: latency-svc-9hw65
Apr 29 09:35:52.171: INFO: Created: latency-svc-f24q7
Apr 29 09:35:52.172: INFO: Created: latency-svc-jf8jm
Apr 29 09:35:52.172: INFO: Created: latency-svc-6qb27
Apr 29 09:35:52.172: INFO: Got endpoints: latency-svc-rbgfk [805.399388ms]
Apr 29 09:35:52.204: INFO: Got endpoints: latency-svc-gcgxv [778.149024ms]
Apr 29 09:35:52.209: INFO: Created: latency-svc-t5tnt
Apr 29 09:35:52.227: INFO: Created: latency-svc-4nm5v
Apr 29 09:35:52.300: INFO: Got endpoints: latency-svc-bq82l [824.130767ms]
Apr 29 09:35:52.305: INFO: Created: latency-svc-7kx64
Apr 29 09:35:52.305: INFO: Got endpoints: latency-svc-v5lcp [773.078174ms]
Apr 29 09:35:52.305: INFO: Created: latency-svc-fmwf5
Apr 29 09:35:52.322: INFO: Got endpoints: latency-svc-djr94 [752.446373ms]
Apr 29 09:35:52.333: INFO: Created: latency-svc-28fql
Apr 29 09:35:52.346: INFO: Created: latency-svc-wjwpk
Apr 29 09:35:52.368: INFO: Created: latency-svc-9d97g
Apr 29 09:35:52.368: INFO: Got endpoints: latency-svc-9pxj9 [749.276242ms]
Apr 29 09:35:52.399: INFO: Created: latency-svc-4fthh
Apr 29 09:35:52.451: INFO: Got endpoints: latency-svc-vb84q [780.933347ms]
Apr 29 09:35:52.471: INFO: Got endpoints: latency-svc-qdf2r [526.193684ms]
Apr 29 09:35:52.485: INFO: Created: latency-svc-4kdhr
Apr 29 09:35:52.507: INFO: Created: latency-svc-nkrjg
Apr 29 09:35:52.512: INFO: Got endpoints: latency-svc-rw4t4 [564.850257ms]
Apr 29 09:35:52.557: INFO: Created: latency-svc-gftsn
Apr 29 09:35:52.559: INFO: Got endpoints: latency-svc-9hw65 [613.86183ms]
Apr 29 09:35:52.580: INFO: Created: latency-svc-vlfn7
Apr 29 09:35:52.610: INFO: Got endpoints: latency-svc-jf8jm [662.104596ms]
Apr 29 09:35:52.629: INFO: Created: latency-svc-6l8ms
Apr 29 09:35:52.682: INFO: Got endpoints: latency-svc-6qb27 [734.557596ms]
Apr 29 09:35:52.712: INFO: Got endpoints: latency-svc-f24q7 [747.48122ms]
Apr 29 09:35:52.719: INFO: Created: latency-svc-v5b2t
Apr 29 09:35:52.738: INFO: Created: latency-svc-n2znl
Apr 29 09:35:52.761: INFO: Got endpoints: latency-svc-t5tnt [735.162802ms]
Apr 29 09:35:52.842: INFO: Got endpoints: latency-svc-4nm5v [766.515903ms]
Apr 29 09:35:52.843: INFO: Created: latency-svc-2w7d2
Apr 29 09:35:52.895: INFO: Got endpoints: latency-svc-7kx64 [722.782682ms]
Apr 29 09:35:52.896: INFO: Created: latency-svc-xdp98
Apr 29 09:35:52.941: INFO: Created: latency-svc-4g77b
Apr 29 09:35:52.984: INFO: Got endpoints: latency-svc-28fql [679.13526ms]
Apr 29 09:35:52.984: INFO: Got endpoints: latency-svc-fmwf5 [780.398538ms]
Apr 29 09:35:53.107: INFO: Created: latency-svc-rvd7f
Apr 29 09:35:53.107: INFO: Created: latency-svc-sqzrh
Apr 29 09:35:53.107: INFO: Got endpoints: latency-svc-9d97g [784.336975ms]
Apr 29 09:35:53.134: INFO: Got endpoints: latency-svc-wjwpk [833.272947ms]
Apr 29 09:35:53.135: INFO: Got endpoints: latency-svc-4fthh [767.269809ms]
Apr 29 09:35:53.187: INFO: Got endpoints: latency-svc-4kdhr [735.873106ms]
Apr 29 09:35:53.204: INFO: Created: latency-svc-t674v
Apr 29 09:35:53.245: INFO: Got endpoints: latency-svc-nkrjg [773.191566ms]
Apr 29 09:35:53.245: INFO: Created: latency-svc-nn2ht
Apr 29 09:35:53.272: INFO: Got endpoints: latency-svc-gftsn [760.006237ms]
Apr 29 09:35:53.290: INFO: Created: latency-svc-bxk2t
Apr 29 09:35:53.291: INFO: Created: latency-svc-cdvqn
Apr 29 09:35:53.339: INFO: Created: latency-svc-whnqb
Apr 29 09:35:53.340: INFO: Got endpoints: latency-svc-vlfn7 [780.661336ms]
Apr 29 09:35:53.361: INFO: Created: latency-svc-nx8n2
Apr 29 09:35:53.372: INFO: Got endpoints: latency-svc-6l8ms [762.759163ms]
Apr 29 09:35:53.373: INFO: Created: latency-svc-c5d4t
Apr 29 09:35:53.398: INFO: Created: latency-svc-ct4w5
Apr 29 09:35:53.411: INFO: Got endpoints: latency-svc-v5b2t [728.049127ms]
Apr 29 09:35:53.457: INFO: Created: latency-svc-7b8x5
Apr 29 09:35:53.462: INFO: Got endpoints: latency-svc-n2znl [749.910038ms]
Apr 29 09:35:53.488: INFO: Created: latency-svc-5dv5q
Apr 29 09:35:53.510: INFO: Got endpoints: latency-svc-2w7d2 [748.262421ms]
Apr 29 09:35:53.545: INFO: Created: latency-svc-97jcx
Apr 29 09:35:53.594: INFO: Got endpoints: latency-svc-xdp98 [751.869455ms]
Apr 29 09:35:53.619: INFO: Created: latency-svc-2jngl
Apr 29 09:35:53.620: INFO: Got endpoints: latency-svc-4g77b [724.56229ms]
Apr 29 09:35:53.647: INFO: Created: latency-svc-xd82j
Apr 29 09:35:53.673: INFO: Got endpoints: latency-svc-sqzrh [660.868675ms]
Apr 29 09:35:53.742: INFO: Created: latency-svc-c9wrz
Apr 29 09:35:53.743: INFO: Got endpoints: latency-svc-rvd7f [724.063784ms]
Apr 29 09:35:53.766: INFO: Got endpoints: latency-svc-t674v [631.619893ms]
Apr 29 09:35:53.767: INFO: Created: latency-svc-fp46c
Apr 29 09:35:53.788: INFO: Created: latency-svc-655ps
Apr 29 09:35:53.816: INFO: Got endpoints: latency-svc-nn2ht [680.972469ms]
Apr 29 09:35:53.860: INFO: Created: latency-svc-v7fpl
Apr 29 09:35:53.868: INFO: Got endpoints: latency-svc-bxk2t [680.379963ms]
Apr 29 09:35:53.891: INFO: Created: latency-svc-kt8x6
Apr 29 09:35:53.911: INFO: Got endpoints: latency-svc-cdvqn [804.45986ms]
Apr 29 09:35:53.938: INFO: Created: latency-svc-j6jtr
Apr 29 09:35:53.961: INFO: Got endpoints: latency-svc-whnqb [716.39421ms]
Apr 29 09:35:54.021: INFO: Got endpoints: latency-svc-nx8n2 [748.719822ms]
Apr 29 09:35:54.007: INFO: Created: latency-svc-kzjm9
Apr 29 09:35:54.045: INFO: Created: latency-svc-68nn7
Apr 29 09:35:54.060: INFO: Got endpoints: latency-svc-c5d4t [719.392439ms]
Apr 29 09:35:54.128: INFO: Got endpoints: latency-svc-ct4w5 [755.651788ms]
Apr 29 09:35:54.130: INFO: Created: latency-svc-qnrll
Apr 29 09:35:54.164: INFO: Got endpoints: latency-svc-7b8x5 [753.692268ms]
Apr 29 09:35:54.184: INFO: Created: latency-svc-7p8st
Apr 29 09:35:54.201: INFO: Created: latency-svc-nfnsg
Apr 29 09:35:54.209: INFO: Got endpoints: latency-svc-5dv5q [746.940402ms]
Apr 29 09:35:54.265: INFO: Got endpoints: latency-svc-97jcx [752.564556ms]
Apr 29 09:35:54.272: INFO: Created: latency-svc-cl6sb
Apr 29 09:35:54.295: INFO: Created: latency-svc-5j5r9
Apr 29 09:35:54.314: INFO: Got endpoints: latency-svc-2jngl [719.028631ms]
Apr 29 09:35:54.336: INFO: Created: latency-svc-zjxqc
Apr 29 09:35:54.383: INFO: Got endpoints: latency-svc-xd82j [761.607842ms]
Apr 29 09:35:54.407: INFO: Created: latency-svc-lbv7r
Apr 29 09:35:54.413: INFO: Got endpoints: latency-svc-c9wrz [739.181125ms]
Apr 29 09:35:54.435: INFO: Created: latency-svc-xg8gv
Apr 29 09:35:54.458: INFO: Got endpoints: latency-svc-fp46c [714.84629ms]
Apr 29 09:35:54.526: INFO: Got endpoints: latency-svc-655ps [759.55542ms]
Apr 29 09:35:54.533: INFO: Created: latency-svc-lxdm7
Apr 29 09:35:54.550: INFO: Created: latency-svc-vl49v
Apr 29 09:35:54.562: INFO: Got endpoints: latency-svc-v7fpl [745.581884ms]
Apr 29 09:35:54.586: INFO: Created: latency-svc-9hg5x
Apr 29 09:35:54.612: INFO: Got endpoints: latency-svc-kt8x6 [744.660975ms]
Apr 29 09:35:54.662: INFO: Got endpoints: latency-svc-j6jtr [749.934325ms]
Apr 29 09:35:54.667: INFO: Created: latency-svc-dpkjl
Apr 29 09:35:54.681: INFO: Created: latency-svc-pjn2z
Apr 29 09:35:54.708: INFO: Got endpoints: latency-svc-kzjm9 [746.790094ms]
Apr 29 09:35:54.737: INFO: Created: latency-svc-tn4gn
Apr 29 09:35:54.790: INFO: Got endpoints: latency-svc-68nn7 [769.135109ms]
Apr 29 09:35:54.819: INFO: Got endpoints: latency-svc-qnrll [758.403506ms]
Apr 29 09:35:54.820: INFO: Created: latency-svc-fkl4h
Apr 29 09:35:54.835: INFO: Created: latency-svc-4mqp5
Apr 29 09:35:54.874: INFO: Got endpoints: latency-svc-7p8st [745.200679ms]
Apr 29 09:35:54.925: INFO: Created: latency-svc-8r5tq
Apr 29 09:35:54.925: INFO: Got endpoints: latency-svc-nfnsg [760.426726ms]
Apr 29 09:35:54.948: INFO: Created: latency-svc-hsk94
Apr 29 09:35:54.959: INFO: Got endpoints: latency-svc-cl6sb [749.55892ms]
Apr 29 09:35:54.982: INFO: Created: latency-svc-sd9nf
Apr 29 09:35:55.039: INFO: Got endpoints: latency-svc-5j5r9 [774.145257ms]
Apr 29 09:35:55.070: INFO: Created: latency-svc-54bmt
Apr 29 09:35:55.070: INFO: Got endpoints: latency-svc-zjxqc [755.84708ms]
Apr 29 09:35:55.094: INFO: Created: latency-svc-g7qm2
Apr 29 09:35:55.110: INFO: Got endpoints: latency-svc-lbv7r [727.030402ms]
Apr 29 09:35:55.140: INFO: Created: latency-svc-qnmsl
Apr 29 09:35:55.163: INFO: Got endpoints: latency-svc-xg8gv [750.71763ms]
Apr 29 09:35:55.189: INFO: Created: latency-svc-gl767
Apr 29 09:35:55.213: INFO: Got endpoints: latency-svc-lxdm7 [755.068771ms]
Apr 29 09:35:55.246: INFO: Created: latency-svc-9xbdb
Apr 29 09:35:55.257: INFO: Got endpoints: latency-svc-vl49v [730.539034ms]
Apr 29 09:35:55.306: INFO: Created: latency-svc-klmsg
Apr 29 09:35:55.316: INFO: Got endpoints: latency-svc-9hg5x [754.205861ms]
Apr 29 09:35:55.339: INFO: Created: latency-svc-4x2ht
Apr 29 09:35:55.361: INFO: Got endpoints: latency-svc-dpkjl [748.057502ms]
Apr 29 09:35:55.387: INFO: Created: latency-svc-bzx6d
Apr 29 09:35:55.418: INFO: Got endpoints: latency-svc-pjn2z [756.607083ms]
Apr 29 09:35:55.441: INFO: Created: latency-svc-v6bzq
Apr 29 09:35:55.463: INFO: Got endpoints: latency-svc-tn4gn [754.157559ms]
Apr 29 09:35:55.485: INFO: Created: latency-svc-vf8tm
Apr 29 09:35:55.510: INFO: Got endpoints: latency-svc-fkl4h [719.837928ms]
Apr 29 09:35:55.559: INFO: Created: latency-svc-dfhwj
Apr 29 09:35:55.560: INFO: Got endpoints: latency-svc-4mqp5 [741.042032ms]
Apr 29 09:35:55.585: INFO: Created: latency-svc-hw6bl
Apr 29 09:35:55.615: INFO: Got endpoints: latency-svc-8r5tq [740.614927ms]
Apr 29 09:35:55.642: INFO: Created: latency-svc-nfpkx
Apr 29 09:35:55.671: INFO: Got endpoints: latency-svc-hsk94 [746.477482ms]
Apr 29 09:35:55.695: INFO: Created: latency-svc-bwb85
Apr 29 09:35:55.712: INFO: Got endpoints: latency-svc-sd9nf [752.642042ms]
Apr 29 09:35:55.735: INFO: Created: latency-svc-vbf5v
Apr 29 09:35:55.759: INFO: Got endpoints: latency-svc-54bmt [719.36362ms]
Apr 29 09:35:55.812: INFO: Created: latency-svc-x6dxh
Apr 29 09:35:55.813: INFO: Got endpoints: latency-svc-g7qm2 [742.806546ms]
Apr 29 09:35:55.838: INFO: Created: latency-svc-x2448
Apr 29 09:35:55.863: INFO: Got endpoints: latency-svc-qnmsl [752.929544ms]
Apr 29 09:35:55.887: INFO: Created: latency-svc-jrjfv
Apr 29 09:35:55.935: INFO: Got endpoints: latency-svc-gl767 [771.184419ms]
Apr 29 09:35:55.960: INFO: Created: latency-svc-266m8
Apr 29 09:35:55.964: INFO: Got endpoints: latency-svc-9xbdb [750.920324ms]
Apr 29 09:35:55.988: INFO: Created: latency-svc-s55dt
Apr 29 09:35:56.012: INFO: Got endpoints: latency-svc-klmsg [754.69286ms]
Apr 29 09:35:56.068: INFO: Created: latency-svc-7jq7z
Apr 29 09:35:56.068: INFO: Got endpoints: latency-svc-4x2ht [751.339927ms]
Apr 29 09:35:56.113: INFO: Created: latency-svc-sc4fv
Apr 29 09:35:56.113: INFO: Got endpoints: latency-svc-bzx6d [752.323336ms]
Apr 29 09:35:56.138: INFO: Created: latency-svc-gdpsf
Apr 29 09:35:56.188: INFO: Got endpoints: latency-svc-v6bzq [769.584301ms]
Apr 29 09:35:56.217: INFO: Got endpoints: latency-svc-vf8tm [754.219753ms]
Apr 29 09:35:56.224: INFO: Created: latency-svc-r6694
Apr 29 09:35:56.247: INFO: Created: latency-svc-7sv7p
Apr 29 09:35:56.261: INFO: Got endpoints: latency-svc-dfhwj [750.412316ms]
Apr 29 09:35:56.285: INFO: Created: latency-svc-ggwqm
Apr 29 09:35:56.319: INFO: Got endpoints: latency-svc-hw6bl [759.1417ms]
Apr 29 09:35:56.348: INFO: Created: latency-svc-58kml
Apr 29 09:35:56.362: INFO: Got endpoints: latency-svc-nfpkx [747.104582ms]
Apr 29 09:35:56.385: INFO: Created: latency-svc-ln4lg
Apr 29 09:35:56.412: INFO: Got endpoints: latency-svc-bwb85 [740.941922ms]
Apr 29 09:35:56.463: INFO: Created: latency-svc-gqcbn
Apr 29 09:35:56.472: INFO: Got endpoints: latency-svc-vbf5v [759.019396ms]
Apr 29 09:35:56.494: INFO: Created: latency-svc-b5jbm
Apr 29 09:35:56.511: INFO: Got endpoints: latency-svc-x6dxh [752.020128ms]
Apr 29 09:35:56.534: INFO: Created: latency-svc-8cr6z
Apr 29 09:35:56.589: INFO: Got endpoints: latency-svc-x2448 [776.348761ms]
Apr 29 09:35:56.617: INFO: Got endpoints: latency-svc-jrjfv [753.42764ms]
Apr 29 09:35:56.619: INFO: Created: latency-svc-4cqqf
Apr 29 09:35:56.638: INFO: Created: latency-svc-lbgnj
Apr 29 09:35:56.661: INFO: Got endpoints: latency-svc-266m8 [724.622463ms]
Apr 29 09:35:56.684: INFO: Created: latency-svc-57hvq
Apr 29 09:35:56.712: INFO: Got endpoints: latency-svc-s55dt [747.542683ms]
Apr 29 09:35:56.740: INFO: Created: latency-svc-d5phc
Apr 29 09:35:56.765: INFO: Got endpoints: latency-svc-7jq7z [753.499339ms]
Apr 29 09:35:56.791: INFO: Created: latency-svc-226qf
Apr 29 09:35:56.811: INFO: Got endpoints: latency-svc-sc4fv [743.22884ms]
Apr 29 09:35:56.865: INFO: Got endpoints: latency-svc-gdpsf [751.894424ms]
Apr 29 09:35:56.865: INFO: Created: latency-svc-9sgpl
Apr 29 09:35:56.886: INFO: Created: latency-svc-76znc
Apr 29 09:35:56.932: INFO: Got endpoints: latency-svc-r6694 [743.304042ms]
Apr 29 09:35:56.971: INFO: Got endpoints: latency-svc-7sv7p [747.235879ms]
Apr 29 09:35:57.013: INFO: Got endpoints: latency-svc-ggwqm [752.009125ms]
Apr 29 09:35:57.072: INFO: Created: latency-svc-642w2
Apr 29 09:35:57.072: INFO: Created: latency-svc-6cbjd
Apr 29 09:35:57.072: INFO: Got endpoints: latency-svc-58kml [752.386128ms]
Apr 29 09:35:57.114: INFO: Created: latency-svc-ffd5f
Apr 29 09:35:57.126: INFO: Got endpoints: latency-svc-ln4lg [763.470533ms]
Apr 29 09:35:57.140: INFO: Created: latency-svc-4hsrr
Apr 29 09:35:57.177: INFO: Got endpoints: latency-svc-gqcbn [764.470443ms]
Apr 29 09:35:57.180: INFO: Created: latency-svc-ldt2f
Apr 29 09:35:57.235: INFO: Got endpoints: latency-svc-b5jbm [763.873336ms]
Apr 29 09:35:57.262: INFO: Got endpoints: latency-svc-8cr6z [750.619608ms]
Apr 29 09:35:57.311: INFO: Got endpoints: latency-svc-4cqqf [721.268825ms]
Apr 29 09:35:57.358: INFO: Got endpoints: latency-svc-lbgnj [740.448909ms]
Apr 29 09:35:57.414: INFO: Got endpoints: latency-svc-57hvq [752.296622ms]
Apr 29 09:35:57.462: INFO: Got endpoints: latency-svc-d5phc [749.364193ms]
Apr 29 09:35:57.514: INFO: Got endpoints: latency-svc-226qf [748.588685ms]
Apr 29 09:35:57.575: INFO: Got endpoints: latency-svc-9sgpl [764.109133ms]
Apr 29 09:35:57.618: INFO: Got endpoints: latency-svc-76znc [753.010827ms]
Apr 29 09:35:57.665: INFO: Got endpoints: latency-svc-6cbjd [660.019133ms]
Apr 29 09:35:57.715: INFO: Got endpoints: latency-svc-642w2 [710.599318ms]
Apr 29 09:35:57.762: INFO: Got endpoints: latency-svc-ffd5f [748.772884ms]
Apr 29 09:35:57.818: INFO: Got endpoints: latency-svc-4hsrr [745.747955ms]
Apr 29 09:35:57.859: INFO: Got endpoints: latency-svc-ldt2f [733.383337ms]
Apr 29 09:35:57.859: INFO: Latencies: [46.130748ms 81.46929ms 158.138134ms 159.484947ms 160.952861ms 183.781282ms 185.472598ms 221.416648ms 245.290479ms 280.399319ms 304.12405ms 308.024487ms 336.772666ms 361.479606ms 365.401942ms 377.607159ms 379.844982ms 383.677617ms 384.546027ms 387.943563ms 388.243863ms 388.762966ms 392.922611ms 395.544433ms 396.334844ms 404.69292ms 404.845626ms 407.30185ms 407.494744ms 408.183259ms 408.188753ms 409.137662ms 410.162072ms 410.253471ms 411.123481ms 411.165688ms 411.641687ms 412.855598ms 413.360609ms 414.04501ms 415.274328ms 415.934934ms 420.731275ms 421.202185ms 421.333181ms 422.909896ms 424.243714ms 424.932216ms 432.265786ms 432.322388ms 434.675409ms 436.804735ms 438.844449ms 439.396954ms 441.024171ms 443.900505ms 444.635006ms 445.423314ms 445.671712ms 447.012427ms 448.752246ms 454.3326ms 455.002607ms 455.780015ms 455.857115ms 461.490169ms 462.469479ms 463.63809ms 466.671315ms 474.729094ms 512.545059ms 526.193684ms 536.866694ms 564.850257ms 571.034924ms 588.712194ms 598.902192ms 613.86183ms 624.44604ms 631.619893ms 660.019133ms 660.868675ms 662.104596ms 679.13526ms 680.379963ms 680.972469ms 710.599318ms 714.84629ms 716.39421ms 719.028631ms 719.36362ms 719.392439ms 719.837928ms 721.268825ms 722.782682ms 724.063784ms 724.56229ms 724.622463ms 727.030402ms 728.049127ms 730.539034ms 733.383337ms 734.557596ms 735.162802ms 735.873106ms 739.181125ms 740.448909ms 740.614927ms 740.941922ms 741.042032ms 742.806546ms 743.22884ms 743.304042ms 744.660975ms 745.200679ms 745.581884ms 745.747955ms 746.477482ms 746.627321ms 746.707622ms 746.790094ms 746.940402ms 747.104582ms 747.235879ms 747.48122ms 747.542683ms 748.057502ms 748.262421ms 748.588685ms 748.719822ms 748.772884ms 749.276242ms 749.364193ms 749.55892ms 749.910038ms 749.934325ms 750.412316ms 750.619608ms 750.71763ms 750.920324ms 751.339927ms 751.869455ms 751.894424ms 752.009125ms 752.020128ms 752.296622ms 752.323336ms 752.386128ms 752.446373ms 752.564556ms 752.642042ms 752.929544ms 753.010827ms 753.42764ms 753.499339ms 753.692268ms 754.157559ms 754.205861ms 754.219753ms 754.69286ms 755.068771ms 755.651788ms 755.84708ms 756.607083ms 758.403506ms 759.019396ms 759.1417ms 759.55542ms 760.006237ms 760.426726ms 761.607842ms 762.569275ms 762.759163ms 763.470533ms 763.873336ms 764.109133ms 764.470443ms 766.515903ms 767.269809ms 768.16673ms 769.090539ms 769.135109ms 769.584301ms 771.184419ms 773.078174ms 773.191566ms 774.145257ms 776.348761ms 778.149024ms 780.398538ms 780.661336ms 780.933347ms 784.336975ms 799.26983ms 804.45986ms 805.399388ms 824.130767ms 833.272947ms 865.127368ms 866.603182ms]
Apr 29 09:35:57.860: INFO: 50 %ile: 730.539034ms
Apr 29 09:35:57.860: INFO: 90 %ile: 769.090539ms
Apr 29 09:35:57.860: INFO: 99 %ile: 865.127368ms
Apr 29 09:35:57.860: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:35:57.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-8096" for this suite.
Apr 29 09:36:21.884: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:36:21.991: INFO: namespace svc-latency-8096 deletion completed in 24.123726372s

• [SLOW TEST:38.257 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:36:21.993: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9185
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
Apr 29 09:36:28.210: INFO: 0 pods remaining
Apr 29 09:36:28.210: INFO: 0 pods has nil DeletionTimestamp
Apr 29 09:36:28.210: INFO: 
STEP: Gathering metrics
W0429 09:36:29.193383      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 29 09:36:29.193: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:36:29.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9185" for this suite.
Apr 29 09:36:35.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:36:35.314: INFO: namespace gc-9185 deletion completed in 6.117092053s

• [SLOW TEST:13.321 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:36:35.315: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7218
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-47c208ff-6a62-11e9-b6b4-b219b18c41e8
STEP: Creating a pod to test consume secrets
Apr 29 09:36:35.515: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-47c2dbfe-6a62-11e9-b6b4-b219b18c41e8" in namespace "projected-7218" to be "success or failure"
Apr 29 09:36:35.521: INFO: Pod "pod-projected-secrets-47c2dbfe-6a62-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.713961ms
Apr 29 09:36:37.525: INFO: Pod "pod-projected-secrets-47c2dbfe-6a62-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010524021s
Apr 29 09:36:39.529: INFO: Pod "pod-projected-secrets-47c2dbfe-6a62-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014450434s
Apr 29 09:36:41.533: INFO: Pod "pod-projected-secrets-47c2dbfe-6a62-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.018025997s
STEP: Saw pod success
Apr 29 09:36:41.533: INFO: Pod "pod-projected-secrets-47c2dbfe-6a62-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:36:41.536: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-projected-secrets-47c2dbfe-6a62-11e9-b6b4-b219b18c41e8 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 29 09:36:41.582: INFO: Waiting for pod pod-projected-secrets-47c2dbfe-6a62-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:36:41.584: INFO: Pod pod-projected-secrets-47c2dbfe-6a62-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:36:41.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7218" for this suite.
Apr 29 09:36:47.602: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:36:47.714: INFO: namespace projected-7218 deletion completed in 6.125855435s

• [SLOW TEST:12.399 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:36:47.716: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-960
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-4f287b71-6a62-11e9-b6b4-b219b18c41e8
STEP: Creating a pod to test consume configMaps
Apr 29 09:36:47.912: INFO: Waiting up to 5m0s for pod "pod-configmaps-4f29313a-6a62-11e9-b6b4-b219b18c41e8" in namespace "configmap-960" to be "success or failure"
Apr 29 09:36:47.927: INFO: Pod "pod-configmaps-4f29313a-6a62-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 14.47223ms
Apr 29 09:36:49.931: INFO: Pod "pod-configmaps-4f29313a-6a62-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018343699s
Apr 29 09:36:51.935: INFO: Pod "pod-configmaps-4f29313a-6a62-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.022264721s
Apr 29 09:36:53.939: INFO: Pod "pod-configmaps-4f29313a-6a62-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.0265297s
STEP: Saw pod success
Apr 29 09:36:53.939: INFO: Pod "pod-configmaps-4f29313a-6a62-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:36:53.942: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-configmaps-4f29313a-6a62-11e9-b6b4-b219b18c41e8 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 29 09:36:53.968: INFO: Waiting for pod pod-configmaps-4f29313a-6a62-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:36:53.974: INFO: Pod pod-configmaps-4f29313a-6a62-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:36:53.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-960" for this suite.
Apr 29 09:37:00.003: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:37:00.111: INFO: namespace configmap-960 deletion completed in 6.133150121s

• [SLOW TEST:12.396 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:37:00.112: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9496
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name projected-secret-test-568b2a4d-6a62-11e9-b6b4-b219b18c41e8
STEP: Creating a pod to test consume secrets
Apr 29 09:37:00.295: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-568bd29b-6a62-11e9-b6b4-b219b18c41e8" in namespace "projected-9496" to be "success or failure"
Apr 29 09:37:00.308: INFO: Pod "pod-projected-secrets-568bd29b-6a62-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 13.48142ms
Apr 29 09:37:02.313: INFO: Pod "pod-projected-secrets-568bd29b-6a62-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01806711s
Apr 29 09:37:04.317: INFO: Pod "pod-projected-secrets-568bd29b-6a62-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021714446s
Apr 29 09:37:06.320: INFO: Pod "pod-projected-secrets-568bd29b-6a62-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.02565284s
STEP: Saw pod success
Apr 29 09:37:06.321: INFO: Pod "pod-projected-secrets-568bd29b-6a62-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:37:06.324: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-projected-secrets-568bd29b-6a62-11e9-b6b4-b219b18c41e8 container secret-volume-test: <nil>
STEP: delete the pod
Apr 29 09:37:06.357: INFO: Waiting for pod pod-projected-secrets-568bd29b-6a62-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:37:06.361: INFO: Pod pod-projected-secrets-568bd29b-6a62-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:37:06.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9496" for this suite.
Apr 29 09:37:12.381: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:37:12.489: INFO: namespace projected-9496 deletion completed in 6.120650056s

• [SLOW TEST:12.377 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:37:12.490: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2672
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Apr 29 09:37:12.661: INFO: Waiting up to 5m0s for pod "pod-5deb1759-6a62-11e9-b6b4-b219b18c41e8" in namespace "emptydir-2672" to be "success or failure"
Apr 29 09:37:12.672: INFO: Pod "pod-5deb1759-6a62-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 10.738494ms
Apr 29 09:37:14.677: INFO: Pod "pod-5deb1759-6a62-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014825402s
Apr 29 09:37:16.681: INFO: Pod "pod-5deb1759-6a62-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019217269s
STEP: Saw pod success
Apr 29 09:37:16.681: INFO: Pod "pod-5deb1759-6a62-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:37:16.688: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-5deb1759-6a62-11e9-b6b4-b219b18c41e8 container test-container: <nil>
STEP: delete the pod
Apr 29 09:37:16.731: INFO: Waiting for pod pod-5deb1759-6a62-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:37:16.735: INFO: Pod pod-5deb1759-6a62-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:37:16.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2672" for this suite.
Apr 29 09:37:22.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:37:22.860: INFO: namespace emptydir-2672 deletion completed in 6.118089233s

• [SLOW TEST:10.370 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:37:22.861: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5039
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 29 09:37:23.037: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6419f1d6-6a62-11e9-b6b4-b219b18c41e8" in namespace "downward-api-5039" to be "success or failure"
Apr 29 09:37:23.042: INFO: Pod "downwardapi-volume-6419f1d6-6a62-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.269445ms
Apr 29 09:37:25.047: INFO: Pod "downwardapi-volume-6419f1d6-6a62-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009881031s
Apr 29 09:37:27.051: INFO: Pod "downwardapi-volume-6419f1d6-6a62-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013796567s
STEP: Saw pod success
Apr 29 09:37:27.051: INFO: Pod "downwardapi-volume-6419f1d6-6a62-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:37:27.054: INFO: Trying to get logs from node 0mfg0-worker-000001 pod downwardapi-volume-6419f1d6-6a62-11e9-b6b4-b219b18c41e8 container client-container: <nil>
STEP: delete the pod
Apr 29 09:37:27.115: INFO: Waiting for pod downwardapi-volume-6419f1d6-6a62-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:37:27.118: INFO: Pod downwardapi-volume-6419f1d6-6a62-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:37:27.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5039" for this suite.
Apr 29 09:37:33.134: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:37:33.256: INFO: namespace downward-api-5039 deletion completed in 6.13394128s

• [SLOW TEST:10.395 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:37:33.257: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-6501
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Apr 29 09:37:33.432: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 29 09:37:33.443: INFO: Waiting for terminating namespaces to be deleted...
Apr 29 09:37:33.446: INFO: 
Logging pods the kubelet thinks is on node 0mfg0-worker-000000 before test
Apr 29 09:37:33.455: INFO: calico-node-dlr6h from kube-system started at 2019-04-29 08:38:55 +0000 UTC (1 container statuses recorded)
Apr 29 09:37:33.455: INFO: 	Container calico-node ready: true, restart count 0
Apr 29 09:37:33.455: INFO: cert-exporter-6krvn from kube-system started at 2019-04-29 08:46:06 +0000 UTC (1 container statuses recorded)
Apr 29 09:37:33.455: INFO: 	Container cert-exporter ready: true, restart count 0
Apr 29 09:37:33.455: INFO: nginx-ingress-controller-65f568886b-w7wpr from kube-system started at 2019-04-29 08:47:56 +0000 UTC (1 container statuses recorded)
Apr 29 09:37:33.455: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Apr 29 09:37:33.455: INFO: chart-operator-78bf665f65-mz82s from giantswarm started at 2019-04-29 08:40:17 +0000 UTC (1 container statuses recorded)
Apr 29 09:37:33.455: INFO: 	Container chart-operator ready: true, restart count 0
Apr 29 09:37:33.455: INFO: metrics-server-b94b95fb4-td6lg from kube-system started at 2019-04-29 08:46:24 +0000 UTC (1 container statuses recorded)
Apr 29 09:37:33.455: INFO: 	Container metrics-server ready: true, restart count 0
Apr 29 09:37:33.455: INFO: external-dns-7fc5fdc459-p572q from kube-system started at 2019-04-29 08:46:42 +0000 UTC (1 container statuses recorded)
Apr 29 09:37:33.455: INFO: 	Container external-dns ready: true, restart count 0
Apr 29 09:37:33.455: INFO: sonobuoy-systemd-logs-daemon-set-354ce670adf74187-6wk5n from heptio-sonobuoy started at 2019-04-29 08:52:55 +0000 UTC (2 container statuses recorded)
Apr 29 09:37:33.455: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 29 09:37:33.455: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 29 09:37:33.455: INFO: default-http-backend-64bbffc5c4-vnglb from kube-system started at 2019-04-29 08:46:29 +0000 UTC (1 container statuses recorded)
Apr 29 09:37:33.455: INFO: 	Container default-http-backend ready: true, restart count 0
Apr 29 09:37:33.455: INFO: kube-proxy-cxrpf from kube-system started at 2019-04-29 08:39:19 +0000 UTC (1 container statuses recorded)
Apr 29 09:37:33.455: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 29 09:37:33.455: INFO: net-exporter-99sc7 from kube-system started at 2019-04-29 08:41:08 +0000 UTC (1 container statuses recorded)
Apr 29 09:37:33.455: INFO: 	Container net-exporter ready: true, restart count 0
Apr 29 09:37:33.455: INFO: node-exporter-ndh5s from kube-system started at 2019-04-29 08:46:40 +0000 UTC (1 container statuses recorded)
Apr 29 09:37:33.455: INFO: 	Container node-exporter ready: true, restart count 0
Apr 29 09:37:33.455: INFO: 
Logging pods the kubelet thinks is on node 0mfg0-worker-000001 before test
Apr 29 09:37:33.464: INFO: default-http-backend-64bbffc5c4-wzr4c from kube-system started at 2019-04-29 08:47:04 +0000 UTC (1 container statuses recorded)
Apr 29 09:37:33.464: INFO: 	Container default-http-backend ready: true, restart count 0
Apr 29 09:37:33.464: INFO: sonobuoy-systemd-logs-daemon-set-354ce670adf74187-k945v from heptio-sonobuoy started at 2019-04-29 08:52:55 +0000 UTC (2 container statuses recorded)
Apr 29 09:37:33.464: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 29 09:37:33.464: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 29 09:37:33.464: INFO: nginx-ingress-controller-65f568886b-49sp4 from kube-system started at 2019-04-29 08:48:36 +0000 UTC (1 container statuses recorded)
Apr 29 09:37:33.464: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Apr 29 09:37:33.464: INFO: coredns-58f7d854b4-hxq5q from kube-system started at 2019-04-29 08:40:50 +0000 UTC (1 container statuses recorded)
Apr 29 09:37:33.464: INFO: 	Container coredns ready: true, restart count 0
Apr 29 09:37:33.464: INFO: cert-exporter-774sr from kube-system started at 2019-04-29 08:46:06 +0000 UTC (1 container statuses recorded)
Apr 29 09:37:33.464: INFO: 	Container cert-exporter ready: true, restart count 0
Apr 29 09:37:33.464: INFO: net-exporter-s8qvt from kube-system started at 2019-04-29 08:41:07 +0000 UTC (1 container statuses recorded)
Apr 29 09:37:33.464: INFO: 	Container net-exporter ready: true, restart count 0
Apr 29 09:37:33.464: INFO: kube-proxy-8vxcc from kube-system started at 2019-04-29 08:39:19 +0000 UTC (1 container statuses recorded)
Apr 29 09:37:33.464: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 29 09:37:33.464: INFO: sonobuoy from heptio-sonobuoy started at 2019-04-29 08:52:41 +0000 UTC (1 container statuses recorded)
Apr 29 09:37:33.464: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 29 09:37:33.464: INFO: node-exporter-nsbd5 from kube-system started at 2019-04-29 08:46:40 +0000 UTC (1 container statuses recorded)
Apr 29 09:37:33.464: INFO: 	Container node-exporter ready: true, restart count 0
Apr 29 09:37:33.465: INFO: calico-node-pcf74 from kube-system started at 2019-04-29 08:38:55 +0000 UTC (1 container statuses recorded)
Apr 29 09:37:33.465: INFO: 	Container calico-node ready: true, restart count 0
Apr 29 09:37:33.465: INFO: 
Logging pods the kubelet thinks is on node 0mfg0-worker-000002 before test
Apr 29 09:37:33.474: INFO: kube-proxy-crdnv from kube-system started at 2019-04-29 08:39:15 +0000 UTC (1 container statuses recorded)
Apr 29 09:37:33.474: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 29 09:37:33.474: INFO: net-exporter-zvnc8 from kube-system started at 2019-04-29 08:41:07 +0000 UTC (1 container statuses recorded)
Apr 29 09:37:33.474: INFO: 	Container net-exporter ready: true, restart count 0
Apr 29 09:37:33.475: INFO: cert-exporter-rdxbx from kube-system started at 2019-04-29 08:46:06 +0000 UTC (1 container statuses recorded)
Apr 29 09:37:33.475: INFO: 	Container cert-exporter ready: true, restart count 0
Apr 29 09:37:33.475: INFO: nginx-ingress-controller-65f568886b-lkq5t from kube-system started at 2019-04-29 08:46:31 +0000 UTC (1 container statuses recorded)
Apr 29 09:37:33.476: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Apr 29 09:37:33.476: INFO: node-exporter-5kgvm from kube-system started at 2019-04-29 08:46:40 +0000 UTC (1 container statuses recorded)
Apr 29 09:37:33.476: INFO: 	Container node-exporter ready: true, restart count 0
Apr 29 09:37:33.476: INFO: calico-node-t2xwm from kube-system started at 2019-04-29 08:38:56 +0000 UTC (1 container statuses recorded)
Apr 29 09:37:33.488: INFO: 	Container calico-node ready: true, restart count 0
Apr 29 09:37:33.488: INFO: tiller-deploy-54494c4fb6-dqfjq from giantswarm started at 2019-04-29 08:39:17 +0000 UTC (1 container statuses recorded)
Apr 29 09:37:33.488: INFO: 	Container tiller ready: true, restart count 0
Apr 29 09:37:33.488: INFO: sonobuoy-systemd-logs-daemon-set-354ce670adf74187-727pj from heptio-sonobuoy started at 2019-04-29 08:52:55 +0000 UTC (2 container statuses recorded)
Apr 29 09:37:33.488: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 29 09:37:33.488: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 29 09:37:33.488: INFO: coredns-58f7d854b4-tgdc8 from kube-system started at 2019-04-29 08:40:50 +0000 UTC (1 container statuses recorded)
Apr 29 09:37:33.488: INFO: 	Container coredns ready: true, restart count 0
Apr 29 09:37:33.488: INFO: kube-state-metrics-5fdb649879-b799g from kube-system started at 2019-04-29 08:46:29 +0000 UTC (2 container statuses recorded)
Apr 29 09:37:33.488: INFO: 	Container addon-resizer ready: true, restart count 0
Apr 29 09:37:33.488: INFO: 	Container kube-state-metrics ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: verifying the node has the label node 0mfg0-worker-000000
STEP: verifying the node has the label node 0mfg0-worker-000001
STEP: verifying the node has the label node 0mfg0-worker-000002
Apr 29 09:37:33.580: INFO: Pod chart-operator-78bf665f65-mz82s requesting resource cpu=250m on Node 0mfg0-worker-000000
Apr 29 09:37:33.580: INFO: Pod tiller-deploy-54494c4fb6-dqfjq requesting resource cpu=0m on Node 0mfg0-worker-000002
Apr 29 09:37:33.580: INFO: Pod sonobuoy requesting resource cpu=0m on Node 0mfg0-worker-000001
Apr 29 09:37:33.580: INFO: Pod sonobuoy-systemd-logs-daemon-set-354ce670adf74187-6wk5n requesting resource cpu=0m on Node 0mfg0-worker-000000
Apr 29 09:37:33.580: INFO: Pod sonobuoy-systemd-logs-daemon-set-354ce670adf74187-727pj requesting resource cpu=0m on Node 0mfg0-worker-000002
Apr 29 09:37:33.580: INFO: Pod sonobuoy-systemd-logs-daemon-set-354ce670adf74187-k945v requesting resource cpu=0m on Node 0mfg0-worker-000001
Apr 29 09:37:33.580: INFO: Pod calico-node-dlr6h requesting resource cpu=250m on Node 0mfg0-worker-000000
Apr 29 09:37:33.580: INFO: Pod calico-node-pcf74 requesting resource cpu=250m on Node 0mfg0-worker-000001
Apr 29 09:37:33.580: INFO: Pod calico-node-t2xwm requesting resource cpu=250m on Node 0mfg0-worker-000002
Apr 29 09:37:33.580: INFO: Pod cert-exporter-6krvn requesting resource cpu=50m on Node 0mfg0-worker-000000
Apr 29 09:37:33.580: INFO: Pod cert-exporter-774sr requesting resource cpu=50m on Node 0mfg0-worker-000001
Apr 29 09:37:33.580: INFO: Pod cert-exporter-rdxbx requesting resource cpu=50m on Node 0mfg0-worker-000002
Apr 29 09:37:33.580: INFO: Pod coredns-58f7d854b4-hxq5q requesting resource cpu=250m on Node 0mfg0-worker-000001
Apr 29 09:37:33.580: INFO: Pod coredns-58f7d854b4-tgdc8 requesting resource cpu=250m on Node 0mfg0-worker-000002
Apr 29 09:37:33.580: INFO: Pod default-http-backend-64bbffc5c4-vnglb requesting resource cpu=10m on Node 0mfg0-worker-000000
Apr 29 09:37:33.580: INFO: Pod default-http-backend-64bbffc5c4-wzr4c requesting resource cpu=10m on Node 0mfg0-worker-000001
Apr 29 09:37:33.580: INFO: Pod external-dns-7fc5fdc459-p572q requesting resource cpu=50m on Node 0mfg0-worker-000000
Apr 29 09:37:33.580: INFO: Pod kube-proxy-8vxcc requesting resource cpu=75m on Node 0mfg0-worker-000001
Apr 29 09:37:33.580: INFO: Pod kube-proxy-crdnv requesting resource cpu=75m on Node 0mfg0-worker-000002
Apr 29 09:37:33.580: INFO: Pod kube-proxy-cxrpf requesting resource cpu=75m on Node 0mfg0-worker-000000
Apr 29 09:37:33.580: INFO: Pod kube-state-metrics-5fdb649879-b799g requesting resource cpu=354m on Node 0mfg0-worker-000002
Apr 29 09:37:33.580: INFO: Pod metrics-server-b94b95fb4-td6lg requesting resource cpu=0m on Node 0mfg0-worker-000000
Apr 29 09:37:33.580: INFO: Pod net-exporter-99sc7 requesting resource cpu=50m on Node 0mfg0-worker-000000
Apr 29 09:37:33.580: INFO: Pod net-exporter-s8qvt requesting resource cpu=50m on Node 0mfg0-worker-000001
Apr 29 09:37:33.580: INFO: Pod net-exporter-zvnc8 requesting resource cpu=50m on Node 0mfg0-worker-000002
Apr 29 09:37:33.580: INFO: Pod nginx-ingress-controller-65f568886b-49sp4 requesting resource cpu=500m on Node 0mfg0-worker-000001
Apr 29 09:37:33.580: INFO: Pod nginx-ingress-controller-65f568886b-lkq5t requesting resource cpu=500m on Node 0mfg0-worker-000002
Apr 29 09:37:33.580: INFO: Pod nginx-ingress-controller-65f568886b-w7wpr requesting resource cpu=500m on Node 0mfg0-worker-000000
Apr 29 09:37:33.580: INFO: Pod node-exporter-5kgvm requesting resource cpu=200m on Node 0mfg0-worker-000002
Apr 29 09:37:33.580: INFO: Pod node-exporter-ndh5s requesting resource cpu=200m on Node 0mfg0-worker-000000
Apr 29 09:37:33.580: INFO: Pod node-exporter-nsbd5 requesting resource cpu=200m on Node 0mfg0-worker-000001
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6a645438-6a62-11e9-b6b4-b219b18c41e8.1599e861f1a80417], Reason = [Scheduled], Message = [Successfully assigned sched-pred-6501/filler-pod-6a645438-6a62-11e9-b6b4-b219b18c41e8 to 0mfg0-worker-000002]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6a645438-6a62-11e9-b6b4-b219b18c41e8.1599e8625f923c63], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6a645438-6a62-11e9-b6b4-b219b18c41e8.1599e862ae8462a2], Reason = [Created], Message = [Created container filler-pod-6a645438-6a62-11e9-b6b4-b219b18c41e8]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6a645438-6a62-11e9-b6b4-b219b18c41e8.1599e862b9721d38], Reason = [Started], Message = [Started container filler-pod-6a645438-6a62-11e9-b6b4-b219b18c41e8]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6a65abd1-6a62-11e9-b6b4-b219b18c41e8.1599e861f29a2c69], Reason = [Scheduled], Message = [Successfully assigned sched-pred-6501/filler-pod-6a65abd1-6a62-11e9-b6b4-b219b18c41e8 to 0mfg0-worker-000000]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6a65abd1-6a62-11e9-b6b4-b219b18c41e8.1599e86266976c38], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6a65abd1-6a62-11e9-b6b4-b219b18c41e8.1599e862a4988266], Reason = [Created], Message = [Created container filler-pod-6a65abd1-6a62-11e9-b6b4-b219b18c41e8]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6a65abd1-6a62-11e9-b6b4-b219b18c41e8.1599e862b42e34db], Reason = [Started], Message = [Started container filler-pod-6a65abd1-6a62-11e9-b6b4-b219b18c41e8]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6a67e979-6a62-11e9-b6b4-b219b18c41e8.1599e861f3bb0b6e], Reason = [Scheduled], Message = [Successfully assigned sched-pred-6501/filler-pod-6a67e979-6a62-11e9-b6b4-b219b18c41e8 to 0mfg0-worker-000001]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6a67e979-6a62-11e9-b6b4-b219b18c41e8.1599e86263316175], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6a67e979-6a62-11e9-b6b4-b219b18c41e8.1599e862a5b5f798], Reason = [Created], Message = [Created container filler-pod-6a67e979-6a62-11e9-b6b4-b219b18c41e8]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6a67e979-6a62-11e9-b6b4-b219b18c41e8.1599e862b0851dcf], Reason = [Started], Message = [Started container filler-pod-6a67e979-6a62-11e9-b6b4-b219b18c41e8]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1599e862e42fdd75], Reason = [FailedScheduling], Message = [0/4 nodes are available: 4 Insufficient cpu.]
STEP: removing the label node off the node 0mfg0-worker-000002
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 0mfg0-worker-000000
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 0mfg0-worker-000001
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:37:38.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6501" for this suite.
Apr 29 09:37:44.797: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:37:44.919: INFO: namespace sched-pred-6501 deletion completed in 6.13824536s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:11.662 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:37:44.920: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8791
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Apr 29 09:37:51.623: INFO: Successfully updated pod "labelsupdate713deb5f-6a62-11e9-b6b4-b219b18c41e8"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:37:53.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8791" for this suite.
Apr 29 09:38:15.679: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:38:15.782: INFO: namespace projected-8791 deletion completed in 22.118263756s

• [SLOW TEST:30.862 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:38:15.783: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7835
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 29 09:38:15.955: INFO: Waiting up to 5m0s for pod "downwardapi-volume-83a34b66-6a62-11e9-b6b4-b219b18c41e8" in namespace "projected-7835" to be "success or failure"
Apr 29 09:38:15.988: INFO: Pod "downwardapi-volume-83a34b66-6a62-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 29.741939ms
Apr 29 09:38:17.992: INFO: Pod "downwardapi-volume-83a34b66-6a62-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033876828s
Apr 29 09:38:19.996: INFO: Pod "downwardapi-volume-83a34b66-6a62-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.037589875s
Apr 29 09:38:21.999: INFO: Pod "downwardapi-volume-83a34b66-6a62-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.041255582s
STEP: Saw pod success
Apr 29 09:38:21.999: INFO: Pod "downwardapi-volume-83a34b66-6a62-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:38:22.003: INFO: Trying to get logs from node 0mfg0-worker-000001 pod downwardapi-volume-83a34b66-6a62-11e9-b6b4-b219b18c41e8 container client-container: <nil>
STEP: delete the pod
Apr 29 09:38:22.057: INFO: Waiting for pod downwardapi-volume-83a34b66-6a62-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:38:22.061: INFO: Pod downwardapi-volume-83a34b66-6a62-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:38:22.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7835" for this suite.
Apr 29 09:38:28.077: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:38:28.221: INFO: namespace projected-7835 deletion completed in 6.156173435s

• [SLOW TEST:12.438 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:38:28.222: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-9362
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-9362
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-9362
STEP: Creating statefulset with conflicting port in namespace statefulset-9362
STEP: Waiting until pod test-pod will start running in namespace statefulset-9362
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-9362
Apr 29 09:38:34.463: INFO: Observed stateful pod in namespace: statefulset-9362, name: ss-0, uid: 8e6e5809-6a62-11e9-9890-000d3a4710ea, status phase: Pending. Waiting for statefulset controller to delete.
Apr 29 09:38:34.619: INFO: Observed stateful pod in namespace: statefulset-9362, name: ss-0, uid: 8e6e5809-6a62-11e9-9890-000d3a4710ea, status phase: Failed. Waiting for statefulset controller to delete.
Apr 29 09:38:34.626: INFO: Observed stateful pod in namespace: statefulset-9362, name: ss-0, uid: 8e6e5809-6a62-11e9-9890-000d3a4710ea, status phase: Failed. Waiting for statefulset controller to delete.
Apr 29 09:38:34.636: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-9362
STEP: Removing pod with conflicting port in namespace statefulset-9362
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-9362 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr 29 09:38:42.693: INFO: Deleting all statefulset in ns statefulset-9362
Apr 29 09:38:42.695: INFO: Scaling statefulset ss to 0
Apr 29 09:38:52.768: INFO: Waiting for statefulset status.replicas updated to 0
Apr 29 09:38:52.790: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:38:52.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9362" for this suite.
Apr 29 09:38:58.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:38:59.067: INFO: namespace statefulset-9362 deletion completed in 6.138524528s

• [SLOW TEST:30.845 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:38:59.069: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2298
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr 29 09:38:59.249: INFO: Waiting up to 5m0s for pod "downward-api-9d721ab6-6a62-11e9-b6b4-b219b18c41e8" in namespace "downward-api-2298" to be "success or failure"
Apr 29 09:38:59.263: INFO: Pod "downward-api-9d721ab6-6a62-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 13.784705ms
Apr 29 09:39:01.266: INFO: Pod "downward-api-9d721ab6-6a62-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017244177s
Apr 29 09:39:03.273: INFO: Pod "downward-api-9d721ab6-6a62-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024021137s
Apr 29 09:39:05.277: INFO: Pod "downward-api-9d721ab6-6a62-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.027710139s
STEP: Saw pod success
Apr 29 09:39:05.277: INFO: Pod "downward-api-9d721ab6-6a62-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:39:05.280: INFO: Trying to get logs from node 0mfg0-worker-000001 pod downward-api-9d721ab6-6a62-11e9-b6b4-b219b18c41e8 container dapi-container: <nil>
STEP: delete the pod
Apr 29 09:39:05.302: INFO: Waiting for pod downward-api-9d721ab6-6a62-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:39:05.306: INFO: Pod downward-api-9d721ab6-6a62-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:39:05.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2298" for this suite.
Apr 29 09:39:11.322: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:39:11.433: INFO: namespace downward-api-2298 deletion completed in 6.123595536s

• [SLOW TEST:12.365 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:39:11.434: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3573
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-a4d189cc-6a62-11e9-b6b4-b219b18c41e8
STEP: Creating a pod to test consume configMaps
Apr 29 09:39:11.626: INFO: Waiting up to 5m0s for pod "pod-configmaps-a4d23a5c-6a62-11e9-b6b4-b219b18c41e8" in namespace "configmap-3573" to be "success or failure"
Apr 29 09:39:11.642: INFO: Pod "pod-configmaps-a4d23a5c-6a62-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 16.175422ms
Apr 29 09:39:13.646: INFO: Pod "pod-configmaps-a4d23a5c-6a62-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020269778s
Apr 29 09:39:15.651: INFO: Pod "pod-configmaps-a4d23a5c-6a62-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024722202s
STEP: Saw pod success
Apr 29 09:39:15.651: INFO: Pod "pod-configmaps-a4d23a5c-6a62-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:39:15.654: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-configmaps-a4d23a5c-6a62-11e9-b6b4-b219b18c41e8 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 29 09:39:15.687: INFO: Waiting for pod pod-configmaps-a4d23a5c-6a62-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:39:15.691: INFO: Pod pod-configmaps-a4d23a5c-6a62-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:39:15.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3573" for this suite.
Apr 29 09:39:21.712: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:39:21.861: INFO: namespace configmap-3573 deletion completed in 6.164559984s

• [SLOW TEST:10.426 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:39:21.863: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1127
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Apr 29 09:39:22.037: INFO: Waiting up to 5m0s for pod "pod-ab07d17b-6a62-11e9-b6b4-b219b18c41e8" in namespace "emptydir-1127" to be "success or failure"
Apr 29 09:39:22.052: INFO: Pod "pod-ab07d17b-6a62-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 13.265798ms
Apr 29 09:39:24.058: INFO: Pod "pod-ab07d17b-6a62-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018827885s
Apr 29 09:39:26.062: INFO: Pod "pod-ab07d17b-6a62-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022697324s
STEP: Saw pod success
Apr 29 09:39:26.062: INFO: Pod "pod-ab07d17b-6a62-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:39:26.065: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-ab07d17b-6a62-11e9-b6b4-b219b18c41e8 container test-container: <nil>
STEP: delete the pod
Apr 29 09:39:26.097: INFO: Waiting for pod pod-ab07d17b-6a62-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:39:26.100: INFO: Pod pod-ab07d17b-6a62-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:39:26.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1127" for this suite.
Apr 29 09:39:32.119: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:39:32.273: INFO: namespace emptydir-1127 deletion completed in 6.169457369s

• [SLOW TEST:10.409 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:39:32.273: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-2376
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Apr 29 09:39:32.439: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 29 09:39:32.449: INFO: Waiting for terminating namespaces to be deleted...
Apr 29 09:39:32.451: INFO: 
Logging pods the kubelet thinks is on node 0mfg0-worker-000000 before test
Apr 29 09:39:32.461: INFO: kube-proxy-cxrpf from kube-system started at 2019-04-29 08:39:19 +0000 UTC (1 container statuses recorded)
Apr 29 09:39:32.461: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 29 09:39:32.461: INFO: net-exporter-99sc7 from kube-system started at 2019-04-29 08:41:08 +0000 UTC (1 container statuses recorded)
Apr 29 09:39:32.461: INFO: 	Container net-exporter ready: true, restart count 0
Apr 29 09:39:32.461: INFO: node-exporter-ndh5s from kube-system started at 2019-04-29 08:46:40 +0000 UTC (1 container statuses recorded)
Apr 29 09:39:32.461: INFO: 	Container node-exporter ready: true, restart count 0
Apr 29 09:39:32.461: INFO: calico-node-dlr6h from kube-system started at 2019-04-29 08:38:55 +0000 UTC (1 container statuses recorded)
Apr 29 09:39:32.461: INFO: 	Container calico-node ready: true, restart count 0
Apr 29 09:39:32.461: INFO: cert-exporter-6krvn from kube-system started at 2019-04-29 08:46:06 +0000 UTC (1 container statuses recorded)
Apr 29 09:39:32.461: INFO: 	Container cert-exporter ready: true, restart count 0
Apr 29 09:39:32.461: INFO: nginx-ingress-controller-65f568886b-w7wpr from kube-system started at 2019-04-29 08:47:56 +0000 UTC (1 container statuses recorded)
Apr 29 09:39:32.461: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Apr 29 09:39:32.461: INFO: chart-operator-78bf665f65-mz82s from giantswarm started at 2019-04-29 08:40:17 +0000 UTC (1 container statuses recorded)
Apr 29 09:39:32.461: INFO: 	Container chart-operator ready: true, restart count 0
Apr 29 09:39:32.461: INFO: metrics-server-b94b95fb4-td6lg from kube-system started at 2019-04-29 08:46:24 +0000 UTC (1 container statuses recorded)
Apr 29 09:39:32.461: INFO: 	Container metrics-server ready: true, restart count 0
Apr 29 09:39:32.461: INFO: external-dns-7fc5fdc459-p572q from kube-system started at 2019-04-29 08:46:42 +0000 UTC (1 container statuses recorded)
Apr 29 09:39:32.461: INFO: 	Container external-dns ready: true, restart count 0
Apr 29 09:39:32.461: INFO: sonobuoy-systemd-logs-daemon-set-354ce670adf74187-6wk5n from heptio-sonobuoy started at 2019-04-29 08:52:55 +0000 UTC (2 container statuses recorded)
Apr 29 09:39:32.461: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 29 09:39:32.461: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 29 09:39:32.461: INFO: default-http-backend-64bbffc5c4-vnglb from kube-system started at 2019-04-29 08:46:29 +0000 UTC (1 container statuses recorded)
Apr 29 09:39:32.461: INFO: 	Container default-http-backend ready: true, restart count 0
Apr 29 09:39:32.461: INFO: 
Logging pods the kubelet thinks is on node 0mfg0-worker-000001 before test
Apr 29 09:39:32.469: INFO: sonobuoy-systemd-logs-daemon-set-354ce670adf74187-k945v from heptio-sonobuoy started at 2019-04-29 08:52:55 +0000 UTC (2 container statuses recorded)
Apr 29 09:39:32.469: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 29 09:39:32.469: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 29 09:39:32.469: INFO: nginx-ingress-controller-65f568886b-49sp4 from kube-system started at 2019-04-29 08:48:36 +0000 UTC (1 container statuses recorded)
Apr 29 09:39:32.469: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Apr 29 09:39:32.469: INFO: default-http-backend-64bbffc5c4-wzr4c from kube-system started at 2019-04-29 08:47:04 +0000 UTC (1 container statuses recorded)
Apr 29 09:39:32.469: INFO: 	Container default-http-backend ready: true, restart count 0
Apr 29 09:39:32.469: INFO: cert-exporter-774sr from kube-system started at 2019-04-29 08:46:06 +0000 UTC (1 container statuses recorded)
Apr 29 09:39:32.469: INFO: 	Container cert-exporter ready: true, restart count 0
Apr 29 09:39:32.469: INFO: net-exporter-s8qvt from kube-system started at 2019-04-29 08:41:07 +0000 UTC (1 container statuses recorded)
Apr 29 09:39:32.469: INFO: 	Container net-exporter ready: true, restart count 0
Apr 29 09:39:32.469: INFO: coredns-58f7d854b4-hxq5q from kube-system started at 2019-04-29 08:40:50 +0000 UTC (1 container statuses recorded)
Apr 29 09:39:32.469: INFO: 	Container coredns ready: true, restart count 0
Apr 29 09:39:32.469: INFO: sonobuoy from heptio-sonobuoy started at 2019-04-29 08:52:41 +0000 UTC (1 container statuses recorded)
Apr 29 09:39:32.469: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 29 09:39:32.469: INFO: node-exporter-nsbd5 from kube-system started at 2019-04-29 08:46:40 +0000 UTC (1 container statuses recorded)
Apr 29 09:39:32.469: INFO: 	Container node-exporter ready: true, restart count 0
Apr 29 09:39:32.469: INFO: calico-node-pcf74 from kube-system started at 2019-04-29 08:38:55 +0000 UTC (1 container statuses recorded)
Apr 29 09:39:32.469: INFO: 	Container calico-node ready: true, restart count 0
Apr 29 09:39:32.469: INFO: kube-proxy-8vxcc from kube-system started at 2019-04-29 08:39:19 +0000 UTC (1 container statuses recorded)
Apr 29 09:39:32.469: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 29 09:39:32.469: INFO: 
Logging pods the kubelet thinks is on node 0mfg0-worker-000002 before test
Apr 29 09:39:32.481: INFO: coredns-58f7d854b4-tgdc8 from kube-system started at 2019-04-29 08:40:50 +0000 UTC (1 container statuses recorded)
Apr 29 09:39:32.481: INFO: 	Container coredns ready: true, restart count 0
Apr 29 09:39:32.481: INFO: kube-state-metrics-5fdb649879-b799g from kube-system started at 2019-04-29 08:46:29 +0000 UTC (2 container statuses recorded)
Apr 29 09:39:32.481: INFO: 	Container addon-resizer ready: true, restart count 0
Apr 29 09:39:32.481: INFO: 	Container kube-state-metrics ready: true, restart count 0
Apr 29 09:39:32.481: INFO: nginx-ingress-controller-65f568886b-lkq5t from kube-system started at 2019-04-29 08:46:31 +0000 UTC (1 container statuses recorded)
Apr 29 09:39:32.482: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Apr 29 09:39:32.482: INFO: node-exporter-5kgvm from kube-system started at 2019-04-29 08:46:40 +0000 UTC (1 container statuses recorded)
Apr 29 09:39:32.482: INFO: 	Container node-exporter ready: true, restart count 0
Apr 29 09:39:32.482: INFO: kube-proxy-crdnv from kube-system started at 2019-04-29 08:39:15 +0000 UTC (1 container statuses recorded)
Apr 29 09:39:32.482: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 29 09:39:32.482: INFO: net-exporter-zvnc8 from kube-system started at 2019-04-29 08:41:07 +0000 UTC (1 container statuses recorded)
Apr 29 09:39:32.482: INFO: 	Container net-exporter ready: true, restart count 0
Apr 29 09:39:32.482: INFO: cert-exporter-rdxbx from kube-system started at 2019-04-29 08:46:06 +0000 UTC (1 container statuses recorded)
Apr 29 09:39:32.482: INFO: 	Container cert-exporter ready: true, restart count 0
Apr 29 09:39:32.482: INFO: calico-node-t2xwm from kube-system started at 2019-04-29 08:38:56 +0000 UTC (1 container statuses recorded)
Apr 29 09:39:32.482: INFO: 	Container calico-node ready: true, restart count 0
Apr 29 09:39:32.482: INFO: tiller-deploy-54494c4fb6-dqfjq from giantswarm started at 2019-04-29 08:39:17 +0000 UTC (1 container statuses recorded)
Apr 29 09:39:32.482: INFO: 	Container tiller ready: true, restart count 0
Apr 29 09:39:32.482: INFO: sonobuoy-systemd-logs-daemon-set-354ce670adf74187-727pj from heptio-sonobuoy started at 2019-04-29 08:52:55 +0000 UTC (2 container statuses recorded)
Apr 29 09:39:32.482: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 29 09:39:32.482: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1599e87da134ded4], Reason = [FailedScheduling], Message = [0/4 nodes are available: 4 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:39:33.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2376" for this suite.
Apr 29 09:39:39.546: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:39:39.658: INFO: namespace sched-pred-2376 deletion completed in 6.130964304s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.385 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:39:39.660: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8897
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Apr 29 09:39:39.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 create -f - --namespace=kubectl-8897'
Apr 29 09:39:40.214: INFO: stderr: ""
Apr 29 09:39:40.214: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Apr 29 09:39:41.218: INFO: Selector matched 1 pods for map[app:redis]
Apr 29 09:39:41.218: INFO: Found 0 / 1
Apr 29 09:39:42.219: INFO: Selector matched 1 pods for map[app:redis]
Apr 29 09:39:42.219: INFO: Found 0 / 1
Apr 29 09:39:43.218: INFO: Selector matched 1 pods for map[app:redis]
Apr 29 09:39:43.218: INFO: Found 0 / 1
Apr 29 09:39:44.218: INFO: Selector matched 1 pods for map[app:redis]
Apr 29 09:39:44.219: INFO: Found 0 / 1
Apr 29 09:39:45.218: INFO: Selector matched 1 pods for map[app:redis]
Apr 29 09:39:45.218: INFO: Found 1 / 1
Apr 29 09:39:45.218: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Apr 29 09:39:45.222: INFO: Selector matched 1 pods for map[app:redis]
Apr 29 09:39:45.222: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 29 09:39:45.224: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 patch pod redis-master-vm2jx --namespace=kubectl-8897 -p {"metadata":{"annotations":{"x":"y"}}}'
Apr 29 09:39:45.329: INFO: stderr: ""
Apr 29 09:39:45.329: INFO: stdout: "pod/redis-master-vm2jx patched\n"
STEP: checking annotations
Apr 29 09:39:45.332: INFO: Selector matched 1 pods for map[app:redis]
Apr 29 09:39:45.332: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:39:45.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8897" for this suite.
Apr 29 09:40:07.349: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:40:07.493: INFO: namespace kubectl-8897 deletion completed in 22.15658702s

• [SLOW TEST:27.833 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:40:07.494: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-934
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-c63a930d-6a62-11e9-b6b4-b219b18c41e8
STEP: Creating a pod to test consume secrets
Apr 29 09:40:07.674: INFO: Waiting up to 5m0s for pod "pod-secrets-c63b59ba-6a62-11e9-b6b4-b219b18c41e8" in namespace "secrets-934" to be "success or failure"
Apr 29 09:40:07.687: INFO: Pod "pod-secrets-c63b59ba-6a62-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 13.109093ms
Apr 29 09:40:09.691: INFO: Pod "pod-secrets-c63b59ba-6a62-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016544012s
Apr 29 09:40:11.695: INFO: Pod "pod-secrets-c63b59ba-6a62-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020225102s
Apr 29 09:40:13.698: INFO: Pod "pod-secrets-c63b59ba-6a62-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.024174262s
STEP: Saw pod success
Apr 29 09:40:13.699: INFO: Pod "pod-secrets-c63b59ba-6a62-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:40:13.702: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-secrets-c63b59ba-6a62-11e9-b6b4-b219b18c41e8 container secret-volume-test: <nil>
STEP: delete the pod
Apr 29 09:40:13.755: INFO: Waiting for pod pod-secrets-c63b59ba-6a62-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:40:13.760: INFO: Pod pod-secrets-c63b59ba-6a62-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:40:13.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-934" for this suite.
Apr 29 09:40:19.781: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:40:19.889: INFO: namespace secrets-934 deletion completed in 6.125458382s

• [SLOW TEST:12.395 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:40:19.890: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8929
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-cd9ef816-6a62-11e9-b6b4-b219b18c41e8
STEP: Creating a pod to test consume secrets
Apr 29 09:40:20.072: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-cd9fbd86-6a62-11e9-b6b4-b219b18c41e8" in namespace "projected-8929" to be "success or failure"
Apr 29 09:40:20.090: INFO: Pod "pod-projected-secrets-cd9fbd86-6a62-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 14.3912ms
Apr 29 09:40:22.106: INFO: Pod "pod-projected-secrets-cd9fbd86-6a62-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030886018s
Apr 29 09:40:24.109: INFO: Pod "pod-projected-secrets-cd9fbd86-6a62-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.033975411s
Apr 29 09:40:26.113: INFO: Pod "pod-projected-secrets-cd9fbd86-6a62-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.038176481s
STEP: Saw pod success
Apr 29 09:40:26.113: INFO: Pod "pod-projected-secrets-cd9fbd86-6a62-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:40:26.116: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-projected-secrets-cd9fbd86-6a62-11e9-b6b4-b219b18c41e8 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 29 09:40:26.204: INFO: Waiting for pod pod-projected-secrets-cd9fbd86-6a62-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:40:26.212: INFO: Pod pod-projected-secrets-cd9fbd86-6a62-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:40:26.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8929" for this suite.
Apr 29 09:40:32.244: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:40:32.376: INFO: namespace projected-8929 deletion completed in 6.159285731s

• [SLOW TEST:12.486 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:40:32.377: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3360
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap that has name configmap-test-emptyKey-d50e9a02-6a62-11e9-b6b4-b219b18c41e8
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:40:32.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3360" for this suite.
Apr 29 09:40:38.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:40:38.679: INFO: namespace configmap-3360 deletion completed in 6.136121782s

• [SLOW TEST:6.302 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:40:38.680: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-569
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 29 09:40:38.849: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:40:42.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-569" for this suite.
Apr 29 09:41:22.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:41:23.038: INFO: namespace pods-569 deletion completed in 40.130880434s

• [SLOW TEST:44.359 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:41:23.040: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5959
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on node default medium
Apr 29 09:41:23.233: INFO: Waiting up to 5m0s for pod "pod-f344e0df-6a62-11e9-b6b4-b219b18c41e8" in namespace "emptydir-5959" to be "success or failure"
Apr 29 09:41:23.246: INFO: Pod "pod-f344e0df-6a62-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 12.676382ms
Apr 29 09:41:25.265: INFO: Pod "pod-f344e0df-6a62-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031176694s
Apr 29 09:41:27.269: INFO: Pod "pod-f344e0df-6a62-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.035455387s
Apr 29 09:41:29.272: INFO: Pod "pod-f344e0df-6a62-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.038775646s
STEP: Saw pod success
Apr 29 09:41:29.272: INFO: Pod "pod-f344e0df-6a62-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:41:29.274: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-f344e0df-6a62-11e9-b6b4-b219b18c41e8 container test-container: <nil>
STEP: delete the pod
Apr 29 09:41:29.302: INFO: Waiting for pod pod-f344e0df-6a62-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:41:29.305: INFO: Pod pod-f344e0df-6a62-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:41:29.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5959" for this suite.
Apr 29 09:41:35.322: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:41:35.435: INFO: namespace emptydir-5959 deletion completed in 6.126142061s

• [SLOW TEST:12.396 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:41:35.436: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-657
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test hostPath mode
Apr 29 09:41:35.599: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-657" to be "success or failure"
Apr 29 09:41:35.629: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 29.797392ms
Apr 29 09:41:37.634: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034940851s
Apr 29 09:41:39.638: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.038901276s
Apr 29 09:41:41.641: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 6.042354672s
Apr 29 09:41:43.646: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.046746247s
STEP: Saw pod success
Apr 29 09:41:43.646: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Apr 29 09:41:43.649: INFO: Trying to get logs from node 0mfg0-worker-000000 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Apr 29 09:41:43.679: INFO: Waiting for pod pod-host-path-test to disappear
Apr 29 09:41:43.683: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:41:43.683: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-657" for this suite.
Apr 29 09:41:49.701: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:41:49.815: INFO: namespace hostpath-657 deletion completed in 6.128322896s

• [SLOW TEST:14.379 seconds]
[sig-storage] HostPath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:41:49.815: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-160
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1190
STEP: creating an rc
Apr 29 09:41:49.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 create -f - --namespace=kubectl-160'
Apr 29 09:41:50.346: INFO: stderr: ""
Apr 29 09:41:50.347: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Waiting for Redis master to start.
Apr 29 09:41:51.351: INFO: Selector matched 1 pods for map[app:redis]
Apr 29 09:41:51.351: INFO: Found 0 / 1
Apr 29 09:41:52.351: INFO: Selector matched 1 pods for map[app:redis]
Apr 29 09:41:52.351: INFO: Found 0 / 1
Apr 29 09:41:53.351: INFO: Selector matched 1 pods for map[app:redis]
Apr 29 09:41:53.351: INFO: Found 0 / 1
Apr 29 09:41:54.359: INFO: Selector matched 1 pods for map[app:redis]
Apr 29 09:41:54.359: INFO: Found 1 / 1
Apr 29 09:41:54.359: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 29 09:41:54.363: INFO: Selector matched 1 pods for map[app:redis]
Apr 29 09:41:54.363: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Apr 29 09:41:54.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 logs redis-master-cwbpw redis-master --namespace=kubectl-160'
Apr 29 09:41:54.469: INFO: stderr: ""
Apr 29 09:41:54.469: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 29 Apr 09:41:54.117 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 29 Apr 09:41:54.117 # Server started, Redis version 3.2.12\n1:M 29 Apr 09:41:54.117 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 29 Apr 09:41:54.117 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Apr 29 09:41:54.469: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 log redis-master-cwbpw redis-master --namespace=kubectl-160 --tail=1'
Apr 29 09:41:54.573: INFO: stderr: ""
Apr 29 09:41:54.573: INFO: stdout: "1:M 29 Apr 09:41:54.117 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Apr 29 09:41:54.573: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 log redis-master-cwbpw redis-master --namespace=kubectl-160 --limit-bytes=1'
Apr 29 09:41:54.688: INFO: stderr: ""
Apr 29 09:41:54.688: INFO: stdout: " "
STEP: exposing timestamps
Apr 29 09:41:54.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 log redis-master-cwbpw redis-master --namespace=kubectl-160 --tail=1 --timestamps'
Apr 29 09:41:54.795: INFO: stderr: ""
Apr 29 09:41:54.795: INFO: stdout: "2019-04-29T09:41:54.117726342Z 1:M 29 Apr 09:41:54.117 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Apr 29 09:41:57.295: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 log redis-master-cwbpw redis-master --namespace=kubectl-160 --since=1s'
Apr 29 09:41:57.419: INFO: stderr: ""
Apr 29 09:41:57.419: INFO: stdout: ""
Apr 29 09:41:57.419: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 log redis-master-cwbpw redis-master --namespace=kubectl-160 --since=24h'
Apr 29 09:41:57.526: INFO: stderr: ""
Apr 29 09:41:57.526: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 29 Apr 09:41:54.117 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 29 Apr 09:41:54.117 # Server started, Redis version 3.2.12\n1:M 29 Apr 09:41:54.117 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 29 Apr 09:41:54.117 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1196
STEP: using delete to clean up resources
Apr 29 09:41:57.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 delete --grace-period=0 --force -f - --namespace=kubectl-160'
Apr 29 09:41:57.617: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 29 09:41:57.617: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Apr 29 09:41:57.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get rc,svc -l name=nginx --no-headers --namespace=kubectl-160'
Apr 29 09:41:57.736: INFO: stderr: "No resources found.\n"
Apr 29 09:41:57.736: INFO: stdout: ""
Apr 29 09:41:57.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods -l name=nginx --namespace=kubectl-160 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 29 09:41:57.820: INFO: stderr: ""
Apr 29 09:41:57.820: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:41:57.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-160" for this suite.
Apr 29 09:42:03.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:42:03.956: INFO: namespace kubectl-160 deletion completed in 6.131626063s

• [SLOW TEST:14.140 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:42:03.956: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-4566
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override arguments
Apr 29 09:42:04.133: INFO: Waiting up to 5m0s for pod "client-containers-0ba6205f-6a63-11e9-b6b4-b219b18c41e8" in namespace "containers-4566" to be "success or failure"
Apr 29 09:42:04.169: INFO: Pod "client-containers-0ba6205f-6a63-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 35.874024ms
Apr 29 09:42:06.176: INFO: Pod "client-containers-0ba6205f-6a63-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042481424s
Apr 29 09:42:08.184: INFO: Pod "client-containers-0ba6205f-6a63-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.050962911s
Apr 29 09:42:10.188: INFO: Pod "client-containers-0ba6205f-6a63-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.054460242s
STEP: Saw pod success
Apr 29 09:42:10.188: INFO: Pod "client-containers-0ba6205f-6a63-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:42:10.190: INFO: Trying to get logs from node 0mfg0-worker-000001 pod client-containers-0ba6205f-6a63-11e9-b6b4-b219b18c41e8 container test-container: <nil>
STEP: delete the pod
Apr 29 09:42:10.216: INFO: Waiting for pod client-containers-0ba6205f-6a63-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:42:10.220: INFO: Pod client-containers-0ba6205f-6a63-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:42:10.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-4566" for this suite.
Apr 29 09:42:16.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:42:16.354: INFO: namespace containers-4566 deletion completed in 6.123365337s

• [SLOW TEST:12.398 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:42:16.355: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7232
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Apr 29 09:42:16.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 create -f - --namespace=kubectl-7232'
Apr 29 09:42:16.858: INFO: stderr: ""
Apr 29 09:42:16.858: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 29 09:42:16.858: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7232'
Apr 29 09:42:17.005: INFO: stderr: ""
Apr 29 09:42:17.005: INFO: stdout: "update-demo-nautilus-d9rcq update-demo-nautilus-qs2gt "
Apr 29 09:42:17.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods update-demo-nautilus-d9rcq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7232'
Apr 29 09:42:17.102: INFO: stderr: ""
Apr 29 09:42:17.102: INFO: stdout: ""
Apr 29 09:42:17.102: INFO: update-demo-nautilus-d9rcq is created but not running
Apr 29 09:42:22.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7232'
Apr 29 09:42:22.256: INFO: stderr: ""
Apr 29 09:42:22.256: INFO: stdout: "update-demo-nautilus-d9rcq update-demo-nautilus-qs2gt "
Apr 29 09:42:22.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods update-demo-nautilus-d9rcq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7232'
Apr 29 09:42:22.356: INFO: stderr: ""
Apr 29 09:42:22.356: INFO: stdout: "true"
Apr 29 09:42:22.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods update-demo-nautilus-d9rcq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7232'
Apr 29 09:42:22.483: INFO: stderr: ""
Apr 29 09:42:22.483: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 29 09:42:22.483: INFO: validating pod update-demo-nautilus-d9rcq
Apr 29 09:42:22.489: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 29 09:42:22.489: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 29 09:42:22.489: INFO: update-demo-nautilus-d9rcq is verified up and running
Apr 29 09:42:22.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods update-demo-nautilus-qs2gt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7232'
Apr 29 09:42:22.579: INFO: stderr: ""
Apr 29 09:42:22.579: INFO: stdout: "true"
Apr 29 09:42:22.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods update-demo-nautilus-qs2gt -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7232'
Apr 29 09:42:22.681: INFO: stderr: ""
Apr 29 09:42:22.681: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 29 09:42:22.681: INFO: validating pod update-demo-nautilus-qs2gt
Apr 29 09:42:22.687: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 29 09:42:22.687: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 29 09:42:22.687: INFO: update-demo-nautilus-qs2gt is verified up and running
STEP: using delete to clean up resources
Apr 29 09:42:22.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 delete --grace-period=0 --force -f - --namespace=kubectl-7232'
Apr 29 09:42:22.782: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 29 09:42:22.784: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr 29 09:42:22.784: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7232'
Apr 29 09:42:22.917: INFO: stderr: "No resources found.\n"
Apr 29 09:42:22.917: INFO: stdout: ""
Apr 29 09:42:22.917: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods -l name=update-demo --namespace=kubectl-7232 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 29 09:42:23.011: INFO: stderr: ""
Apr 29 09:42:23.011: INFO: stdout: "update-demo-nautilus-d9rcq\nupdate-demo-nautilus-qs2gt\n"
Apr 29 09:42:23.511: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7232'
Apr 29 09:42:23.649: INFO: stderr: "No resources found.\n"
Apr 29 09:42:23.649: INFO: stdout: ""
Apr 29 09:42:23.649: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods -l name=update-demo --namespace=kubectl-7232 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 29 09:42:23.747: INFO: stderr: ""
Apr 29 09:42:23.747: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:42:23.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7232" for this suite.
Apr 29 09:42:45.767: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:42:45.886: INFO: namespace kubectl-7232 deletion completed in 22.133209198s

• [SLOW TEST:29.530 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:42:45.886: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-6686
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating replication controller my-hostname-basic-24a20efa-6a63-11e9-b6b4-b219b18c41e8
Apr 29 09:42:46.063: INFO: Pod name my-hostname-basic-24a20efa-6a63-11e9-b6b4-b219b18c41e8: Found 0 pods out of 1
Apr 29 09:42:51.067: INFO: Pod name my-hostname-basic-24a20efa-6a63-11e9-b6b4-b219b18c41e8: Found 1 pods out of 1
Apr 29 09:42:51.067: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-24a20efa-6a63-11e9-b6b4-b219b18c41e8" are running
Apr 29 09:42:51.070: INFO: Pod "my-hostname-basic-24a20efa-6a63-11e9-b6b4-b219b18c41e8-mwpls" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-29 09:42:46 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-29 09:42:50 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-29 09:42:50 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-29 09:42:46 +0000 UTC Reason: Message:}])
Apr 29 09:42:51.070: INFO: Trying to dial the pod
Apr 29 09:42:56.082: INFO: Controller my-hostname-basic-24a20efa-6a63-11e9-b6b4-b219b18c41e8: Got expected result from replica 1 [my-hostname-basic-24a20efa-6a63-11e9-b6b4-b219b18c41e8-mwpls]: "my-hostname-basic-24a20efa-6a63-11e9-b6b4-b219b18c41e8-mwpls", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:42:56.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6686" for this suite.
Apr 29 09:43:02.106: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:43:02.265: INFO: namespace replication-controller-6686 deletion completed in 6.179442615s

• [SLOW TEST:16.380 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:43:02.266: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5460
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 29 09:43:02.451: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2e68407e-6a63-11e9-b6b4-b219b18c41e8" in namespace "projected-5460" to be "success or failure"
Apr 29 09:43:02.464: INFO: Pod "downwardapi-volume-2e68407e-6a63-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 13.101277ms
Apr 29 09:43:04.467: INFO: Pod "downwardapi-volume-2e68407e-6a63-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016537968s
Apr 29 09:43:06.471: INFO: Pod "downwardapi-volume-2e68407e-6a63-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02076874s
Apr 29 09:43:08.475: INFO: Pod "downwardapi-volume-2e68407e-6a63-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.024521588s
STEP: Saw pod success
Apr 29 09:43:08.475: INFO: Pod "downwardapi-volume-2e68407e-6a63-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:43:08.478: INFO: Trying to get logs from node 0mfg0-worker-000001 pod downwardapi-volume-2e68407e-6a63-11e9-b6b4-b219b18c41e8 container client-container: <nil>
STEP: delete the pod
Apr 29 09:43:08.510: INFO: Waiting for pod downwardapi-volume-2e68407e-6a63-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:43:08.513: INFO: Pod downwardapi-volume-2e68407e-6a63-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:43:08.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5460" for this suite.
Apr 29 09:43:14.532: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:43:14.654: INFO: namespace projected-5460 deletion completed in 6.137635544s

• [SLOW TEST:12.389 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:43:14.655: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2090
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-projected-all-test-volume-35c9c07d-6a63-11e9-b6b4-b219b18c41e8
STEP: Creating secret with name secret-projected-all-test-volume-35c9c05f-6a63-11e9-b6b4-b219b18c41e8
STEP: Creating a pod to test Check all projections for projected volume plugin
Apr 29 09:43:14.844: INFO: Waiting up to 5m0s for pod "projected-volume-35c9c01e-6a63-11e9-b6b4-b219b18c41e8" in namespace "projected-2090" to be "success or failure"
Apr 29 09:43:14.860: INFO: Pod "projected-volume-35c9c01e-6a63-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 15.775192ms
Apr 29 09:43:16.866: INFO: Pod "projected-volume-35c9c01e-6a63-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021065356s
Apr 29 09:43:18.874: INFO: Pod "projected-volume-35c9c01e-6a63-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.028936113s
Apr 29 09:43:20.878: INFO: Pod "projected-volume-35c9c01e-6a63-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.032806726s
STEP: Saw pod success
Apr 29 09:43:20.878: INFO: Pod "projected-volume-35c9c01e-6a63-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:43:20.880: INFO: Trying to get logs from node 0mfg0-worker-000001 pod projected-volume-35c9c01e-6a63-11e9-b6b4-b219b18c41e8 container projected-all-volume-test: <nil>
STEP: delete the pod
Apr 29 09:43:20.927: INFO: Waiting for pod projected-volume-35c9c01e-6a63-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:43:20.952: INFO: Pod projected-volume-35c9c01e-6a63-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:43:20.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2090" for this suite.
Apr 29 09:43:27.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:43:27.113: INFO: namespace projected-2090 deletion completed in 6.133602206s

• [SLOW TEST:12.459 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:43:27.114: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4030
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-3d36dfb5-6a63-11e9-b6b4-b219b18c41e8
STEP: Creating a pod to test consume secrets
Apr 29 09:43:27.306: INFO: Waiting up to 5m0s for pod "pod-secrets-3d3778dd-6a63-11e9-b6b4-b219b18c41e8" in namespace "secrets-4030" to be "success or failure"
Apr 29 09:43:27.318: INFO: Pod "pod-secrets-3d3778dd-6a63-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 11.059863ms
Apr 29 09:43:29.321: INFO: Pod "pod-secrets-3d3778dd-6a63-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014608283s
Apr 29 09:43:31.325: INFO: Pod "pod-secrets-3d3778dd-6a63-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018289682s
Apr 29 09:43:33.328: INFO: Pod "pod-secrets-3d3778dd-6a63-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.021408557s
STEP: Saw pod success
Apr 29 09:43:33.328: INFO: Pod "pod-secrets-3d3778dd-6a63-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:43:33.331: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-secrets-3d3778dd-6a63-11e9-b6b4-b219b18c41e8 container secret-env-test: <nil>
STEP: delete the pod
Apr 29 09:43:33.361: INFO: Waiting for pod pod-secrets-3d3778dd-6a63-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:43:33.364: INFO: Pod pod-secrets-3d3778dd-6a63-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:43:33.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4030" for this suite.
Apr 29 09:43:39.382: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:43:39.503: INFO: namespace secrets-4030 deletion completed in 6.133867105s

• [SLOW TEST:12.389 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:43:39.504: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-7910
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0429 09:43:40.736002      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 29 09:43:40.736: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:43:40.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7910" for this suite.
Apr 29 09:43:46.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:43:46.866: INFO: namespace gc-7910 deletion completed in 6.126543829s

• [SLOW TEST:7.363 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:43:46.874: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-641
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-641
Apr 29 09:43:51.073: INFO: Started pod liveness-http in namespace container-probe-641
STEP: checking the pod's current state and verifying that restartCount is present
Apr 29 09:43:51.076: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:47:51.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-641" for this suite.
Apr 29 09:47:57.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:47:57.786: INFO: namespace container-probe-641 deletion completed in 6.147672761s

• [SLOW TEST:250.913 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:47:57.787: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7608
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-de8cfb5a-6a63-11e9-b6b4-b219b18c41e8
STEP: Creating a pod to test consume secrets
Apr 29 09:47:57.977: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-de8e0f57-6a63-11e9-b6b4-b219b18c41e8" in namespace "projected-7608" to be "success or failure"
Apr 29 09:47:57.994: INFO: Pod "pod-projected-secrets-de8e0f57-6a63-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 16.319176ms
Apr 29 09:47:59.997: INFO: Pod "pod-projected-secrets-de8e0f57-6a63-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020018058s
Apr 29 09:48:02.001: INFO: Pod "pod-projected-secrets-de8e0f57-6a63-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.023837528s
Apr 29 09:48:04.005: INFO: Pod "pod-projected-secrets-de8e0f57-6a63-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.027902886s
STEP: Saw pod success
Apr 29 09:48:04.005: INFO: Pod "pod-projected-secrets-de8e0f57-6a63-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:48:04.008: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-projected-secrets-de8e0f57-6a63-11e9-b6b4-b219b18c41e8 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 29 09:48:04.145: INFO: Waiting for pod pod-projected-secrets-de8e0f57-6a63-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:48:04.158: INFO: Pod pod-projected-secrets-de8e0f57-6a63-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:48:04.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7608" for this suite.
Apr 29 09:48:10.177: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:48:10.307: INFO: namespace projected-7608 deletion completed in 6.143275601s

• [SLOW TEST:12.519 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:48:10.307: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9336
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Apr 29 09:48:10.467: INFO: Waiting up to 5m0s for pod "pod-e600161d-6a63-11e9-b6b4-b219b18c41e8" in namespace "emptydir-9336" to be "success or failure"
Apr 29 09:48:10.473: INFO: Pod "pod-e600161d-6a63-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.830631ms
Apr 29 09:48:12.479: INFO: Pod "pod-e600161d-6a63-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011970942s
Apr 29 09:48:14.484: INFO: Pod "pod-e600161d-6a63-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017416143s
Apr 29 09:48:16.489: INFO: Pod "pod-e600161d-6a63-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.022791931s
STEP: Saw pod success
Apr 29 09:48:16.490: INFO: Pod "pod-e600161d-6a63-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:48:16.493: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-e600161d-6a63-11e9-b6b4-b219b18c41e8 container test-container: <nil>
STEP: delete the pod
Apr 29 09:48:16.518: INFO: Waiting for pod pod-e600161d-6a63-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:48:16.523: INFO: Pod pod-e600161d-6a63-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:48:16.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9336" for this suite.
Apr 29 09:48:22.540: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:48:22.650: INFO: namespace emptydir-9336 deletion completed in 6.122271274s

• [SLOW TEST:12.343 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:48:22.650: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-7631
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-7631
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 29 09:48:22.816: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr 29 09:48:50.984: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.131.63:8080/dial?request=hostName&protocol=http&host=10.2.129.40&port=8080&tries=1'] Namespace:pod-network-test-7631 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 29 09:48:50.984: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
Apr 29 09:48:51.094: INFO: Waiting for endpoints: map[]
Apr 29 09:48:51.098: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.131.63:8080/dial?request=hostName&protocol=http&host=10.2.131.62&port=8080&tries=1'] Namespace:pod-network-test-7631 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 29 09:48:51.098: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
Apr 29 09:48:51.198: INFO: Waiting for endpoints: map[]
Apr 29 09:48:51.203: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.131.63:8080/dial?request=hostName&protocol=http&host=10.2.130.136&port=8080&tries=1'] Namespace:pod-network-test-7631 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 29 09:48:51.203: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
Apr 29 09:48:51.309: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:48:51.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7631" for this suite.
Apr 29 09:49:07.328: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:49:07.444: INFO: namespace pod-network-test-7631 deletion completed in 16.12888864s

• [SLOW TEST:44.794 seconds]
[sig-network] Networking
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:49:07.452: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5440
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-08106c68-6a64-11e9-b6b4-b219b18c41e8
STEP: Creating a pod to test consume secrets
Apr 29 09:49:07.624: INFO: Waiting up to 5m0s for pod "pod-secrets-08113459-6a64-11e9-b6b4-b219b18c41e8" in namespace "secrets-5440" to be "success or failure"
Apr 29 09:49:07.630: INFO: Pod "pod-secrets-08113459-6a64-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.333528ms
Apr 29 09:49:09.633: INFO: Pod "pod-secrets-08113459-6a64-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009893801s
Apr 29 09:49:11.640: INFO: Pod "pod-secrets-08113459-6a64-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016184475s
STEP: Saw pod success
Apr 29 09:49:11.640: INFO: Pod "pod-secrets-08113459-6a64-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:49:11.643: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-secrets-08113459-6a64-11e9-b6b4-b219b18c41e8 container secret-volume-test: <nil>
STEP: delete the pod
Apr 29 09:49:11.682: INFO: Waiting for pod pod-secrets-08113459-6a64-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:49:11.685: INFO: Pod pod-secrets-08113459-6a64-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:49:11.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5440" for this suite.
Apr 29 09:49:17.702: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:49:17.837: INFO: namespace secrets-5440 deletion completed in 6.147314121s

• [SLOW TEST:10.385 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:49:17.837: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9317
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 29 09:49:18.003: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0e40def0-6a64-11e9-b6b4-b219b18c41e8" in namespace "projected-9317" to be "success or failure"
Apr 29 09:49:18.020: INFO: Pod "downwardapi-volume-0e40def0-6a64-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 16.972975ms
Apr 29 09:49:20.041: INFO: Pod "downwardapi-volume-0e40def0-6a64-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038239469s
Apr 29 09:49:22.045: INFO: Pod "downwardapi-volume-0e40def0-6a64-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042062476s
STEP: Saw pod success
Apr 29 09:49:22.045: INFO: Pod "downwardapi-volume-0e40def0-6a64-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:49:22.048: INFO: Trying to get logs from node 0mfg0-worker-000001 pod downwardapi-volume-0e40def0-6a64-11e9-b6b4-b219b18c41e8 container client-container: <nil>
STEP: delete the pod
Apr 29 09:49:22.105: INFO: Waiting for pod downwardapi-volume-0e40def0-6a64-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:49:22.120: INFO: Pod downwardapi-volume-0e40def0-6a64-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:49:22.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9317" for this suite.
Apr 29 09:49:28.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:49:28.246: INFO: namespace projected-9317 deletion completed in 6.120429832s

• [SLOW TEST:10.409 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:49:28.247: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-875
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 29 09:49:28.406: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 version'
Apr 29 09:49:28.501: INFO: stderr: ""
Apr 29 09:49:28.501: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.1\", GitCommit:\"b7394102d6ef778017f2ca4046abbaa23b88c290\", GitTreeState:\"clean\", BuildDate:\"2019-04-08T17:11:31Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.1\", GitCommit:\"b7394102d6ef778017f2ca4046abbaa23b88c290\", GitTreeState:\"clean\", BuildDate:\"2019-04-08T17:02:58Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:49:28.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-875" for this suite.
Apr 29 09:49:34.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:49:34.647: INFO: namespace kubectl-875 deletion completed in 6.140951719s

• [SLOW TEST:6.400 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:49:34.648: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-3086
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-3086
Apr 29 09:49:38.847: INFO: Started pod liveness-exec in namespace container-probe-3086
STEP: checking the pod's current state and verifying that restartCount is present
Apr 29 09:49:38.850: INFO: Initial restart count of pod liveness-exec is 0
Apr 29 09:50:32.964: INFO: Restart count of pod container-probe-3086/liveness-exec is now 1 (54.114734169s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:50:32.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3086" for this suite.
Apr 29 09:50:39.026: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:50:39.134: INFO: namespace container-probe-3086 deletion completed in 6.128319093s

• [SLOW TEST:64.487 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:50:39.135: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-7051
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 29 09:50:39.294: INFO: (0) /api/v1/nodes/0mfg0-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 4.023017ms)
Apr 29 09:50:39.297: INFO: (1) /api/v1/nodes/0mfg0-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 3.790616ms)
Apr 29 09:50:39.302: INFO: (2) /api/v1/nodes/0mfg0-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 4.378118ms)
Apr 29 09:50:39.306: INFO: (3) /api/v1/nodes/0mfg0-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 4.006617ms)
Apr 29 09:50:39.310: INFO: (4) /api/v1/nodes/0mfg0-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 3.896417ms)
Apr 29 09:50:39.314: INFO: (5) /api/v1/nodes/0mfg0-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 3.709115ms)
Apr 29 09:50:39.318: INFO: (6) /api/v1/nodes/0mfg0-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 3.881116ms)
Apr 29 09:50:39.322: INFO: (7) /api/v1/nodes/0mfg0-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 3.884516ms)
Apr 29 09:50:39.325: INFO: (8) /api/v1/nodes/0mfg0-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 3.805315ms)
Apr 29 09:50:39.329: INFO: (9) /api/v1/nodes/0mfg0-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 3.496414ms)
Apr 29 09:50:39.333: INFO: (10) /api/v1/nodes/0mfg0-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 3.259114ms)
Apr 29 09:50:39.338: INFO: (11) /api/v1/nodes/0mfg0-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 5.274222ms)
Apr 29 09:50:39.342: INFO: (12) /api/v1/nodes/0mfg0-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 3.913317ms)
Apr 29 09:50:39.346: INFO: (13) /api/v1/nodes/0mfg0-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 4.161917ms)
Apr 29 09:50:39.351: INFO: (14) /api/v1/nodes/0mfg0-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 4.425618ms)
Apr 29 09:50:39.355: INFO: (15) /api/v1/nodes/0mfg0-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 4.089617ms)
Apr 29 09:50:39.359: INFO: (16) /api/v1/nodes/0mfg0-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 4.558619ms)
Apr 29 09:50:39.363: INFO: (17) /api/v1/nodes/0mfg0-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 3.575215ms)
Apr 29 09:50:39.367: INFO: (18) /api/v1/nodes/0mfg0-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 3.742916ms)
Apr 29 09:50:39.370: INFO: (19) /api/v1/nodes/0mfg0-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 3.561815ms)
[AfterEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:50:39.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-7051" for this suite.
Apr 29 09:50:45.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:50:45.495: INFO: namespace proxy-7051 deletion completed in 6.12021347s

• [SLOW TEST:6.360 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:50:45.496: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-489
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test env composition
Apr 29 09:50:45.666: INFO: Waiting up to 5m0s for pod "var-expansion-42814ed8-6a64-11e9-b6b4-b219b18c41e8" in namespace "var-expansion-489" to be "success or failure"
Apr 29 09:50:45.682: INFO: Pod "var-expansion-42814ed8-6a64-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 15.672466ms
Apr 29 09:50:47.686: INFO: Pod "var-expansion-42814ed8-6a64-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019634352s
Apr 29 09:50:49.689: INFO: Pod "var-expansion-42814ed8-6a64-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.023162027s
Apr 29 09:50:51.694: INFO: Pod "var-expansion-42814ed8-6a64-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.027621197s
STEP: Saw pod success
Apr 29 09:50:51.694: INFO: Pod "var-expansion-42814ed8-6a64-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:50:51.697: INFO: Trying to get logs from node 0mfg0-worker-000001 pod var-expansion-42814ed8-6a64-11e9-b6b4-b219b18c41e8 container dapi-container: <nil>
STEP: delete the pod
Apr 29 09:50:51.729: INFO: Waiting for pod var-expansion-42814ed8-6a64-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:50:51.732: INFO: Pod var-expansion-42814ed8-6a64-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:50:51.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-489" for this suite.
Apr 29 09:50:57.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:50:57.940: INFO: namespace var-expansion-489 deletion completed in 6.191944099s

• [SLOW TEST:12.444 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:50:57.940: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-2535
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:51:58.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2535" for this suite.
Apr 29 09:52:20.136: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:52:20.248: INFO: namespace container-probe-2535 deletion completed in 22.123416879s

• [SLOW TEST:82.308 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:52:20.249: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-8512
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Apr 29 09:52:32.467: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 29 09:52:32.475: INFO: Pod pod-with-prestop-http-hook still exists
Apr 29 09:52:34.475: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 29 09:52:34.479: INFO: Pod pod-with-prestop-http-hook still exists
Apr 29 09:52:36.475: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 29 09:52:36.479: INFO: Pod pod-with-prestop-http-hook still exists
Apr 29 09:52:38.475: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 29 09:52:38.479: INFO: Pod pod-with-prestop-http-hook still exists
Apr 29 09:52:40.475: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 29 09:52:40.479: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:52:40.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8512" for this suite.
Apr 29 09:53:02.507: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:53:02.618: INFO: namespace container-lifecycle-hook-8512 deletion completed in 22.124678357s

• [SLOW TEST:42.369 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:53:02.621: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7056
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr 29 09:53:02.782: INFO: Waiting up to 5m0s for pod "downward-api-943ba085-6a64-11e9-b6b4-b219b18c41e8" in namespace "downward-api-7056" to be "success or failure"
Apr 29 09:53:02.788: INFO: Pod "downward-api-943ba085-6a64-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.049324ms
Apr 29 09:53:04.808: INFO: Pod "downward-api-943ba085-6a64-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02622563s
Apr 29 09:53:06.812: INFO: Pod "downward-api-943ba085-6a64-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029946564s
Apr 29 09:53:08.815: INFO: Pod "downward-api-943ba085-6a64-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.033587891s
STEP: Saw pod success
Apr 29 09:53:08.815: INFO: Pod "downward-api-943ba085-6a64-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:53:08.818: INFO: Trying to get logs from node 0mfg0-worker-000001 pod downward-api-943ba085-6a64-11e9-b6b4-b219b18c41e8 container dapi-container: <nil>
STEP: delete the pod
Apr 29 09:53:08.842: INFO: Waiting for pod downward-api-943ba085-6a64-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:53:08.845: INFO: Pod downward-api-943ba085-6a64-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:53:08.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7056" for this suite.
Apr 29 09:53:14.914: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:53:15.018: INFO: namespace downward-api-7056 deletion completed in 6.117114253s

• [SLOW TEST:12.397 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:53:15.019: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-3902
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:53:21.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3902" for this suite.
Apr 29 09:54:01.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:54:01.355: INFO: namespace kubelet-test-3902 deletion completed in 40.12006121s

• [SLOW TEST:46.336 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a read only busybox container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:54:01.356: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-885
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-b73ff9dd-6a64-11e9-b6b4-b219b18c41e8
STEP: Creating a pod to test consume configMaps
Apr 29 09:54:01.535: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b740a9ba-6a64-11e9-b6b4-b219b18c41e8" in namespace "projected-885" to be "success or failure"
Apr 29 09:54:01.563: INFO: Pod "pod-projected-configmaps-b740a9ba-6a64-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 27.246304ms
Apr 29 09:54:03.569: INFO: Pod "pod-projected-configmaps-b740a9ba-6a64-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034025465s
Apr 29 09:54:05.573: INFO: Pod "pod-projected-configmaps-b740a9ba-6a64-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.037880809s
Apr 29 09:54:07.577: INFO: Pod "pod-projected-configmaps-b740a9ba-6a64-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.041560846s
STEP: Saw pod success
Apr 29 09:54:07.577: INFO: Pod "pod-projected-configmaps-b740a9ba-6a64-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:54:07.580: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-projected-configmaps-b740a9ba-6a64-11e9-b6b4-b219b18c41e8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 29 09:54:07.607: INFO: Waiting for pod pod-projected-configmaps-b740a9ba-6a64-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:54:07.622: INFO: Pod pod-projected-configmaps-b740a9ba-6a64-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:54:07.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-885" for this suite.
Apr 29 09:54:13.744: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:54:13.845: INFO: namespace projected-885 deletion completed in 6.198042984s

• [SLOW TEST:12.489 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:54:13.846: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-2209
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Apr 29 09:54:14.035: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2209,SelfLink:/api/v1/namespaces/watch-2209/configmaps/e2e-watch-test-label-changed,UID:beb2f81c-6a64-11e9-9890-000d3a4710ea,ResourceVersion:17676,Generation:0,CreationTimestamp:2019-04-29 09:54:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr 29 09:54:14.036: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2209,SelfLink:/api/v1/namespaces/watch-2209/configmaps/e2e-watch-test-label-changed,UID:beb2f81c-6a64-11e9-9890-000d3a4710ea,ResourceVersion:17677,Generation:0,CreationTimestamp:2019-04-29 09:54:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Apr 29 09:54:14.036: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2209,SelfLink:/api/v1/namespaces/watch-2209/configmaps/e2e-watch-test-label-changed,UID:beb2f81c-6a64-11e9-9890-000d3a4710ea,ResourceVersion:17678,Generation:0,CreationTimestamp:2019-04-29 09:54:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Apr 29 09:54:24.066: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2209,SelfLink:/api/v1/namespaces/watch-2209/configmaps/e2e-watch-test-label-changed,UID:beb2f81c-6a64-11e9-9890-000d3a4710ea,ResourceVersion:17698,Generation:0,CreationTimestamp:2019-04-29 09:54:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr 29 09:54:24.067: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2209,SelfLink:/api/v1/namespaces/watch-2209/configmaps/e2e-watch-test-label-changed,UID:beb2f81c-6a64-11e9-9890-000d3a4710ea,ResourceVersion:17699,Generation:0,CreationTimestamp:2019-04-29 09:54:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Apr 29 09:54:24.067: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2209,SelfLink:/api/v1/namespaces/watch-2209/configmaps/e2e-watch-test-label-changed,UID:beb2f81c-6a64-11e9-9890-000d3a4710ea,ResourceVersion:17700,Generation:0,CreationTimestamp:2019-04-29 09:54:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:54:24.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2209" for this suite.
Apr 29 09:54:30.083: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:54:30.210: INFO: namespace watch-2209 deletion completed in 6.138421608s

• [SLOW TEST:16.363 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:54:30.210: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-6675
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 29 09:54:30.381: INFO: (0) /api/v1/nodes/0mfg0-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 4.156016ms)
Apr 29 09:54:30.384: INFO: (1) /api/v1/nodes/0mfg0-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 3.164011ms)
Apr 29 09:54:30.388: INFO: (2) /api/v1/nodes/0mfg0-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 3.418312ms)
Apr 29 09:54:30.391: INFO: (3) /api/v1/nodes/0mfg0-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 3.434213ms)
Apr 29 09:54:30.395: INFO: (4) /api/v1/nodes/0mfg0-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 3.454813ms)
Apr 29 09:54:30.398: INFO: (5) /api/v1/nodes/0mfg0-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 3.549314ms)
Apr 29 09:54:30.402: INFO: (6) /api/v1/nodes/0mfg0-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 3.390413ms)
Apr 29 09:54:30.406: INFO: (7) /api/v1/nodes/0mfg0-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 4.107816ms)
Apr 29 09:54:30.409: INFO: (8) /api/v1/nodes/0mfg0-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 3.138211ms)
Apr 29 09:54:30.413: INFO: (9) /api/v1/nodes/0mfg0-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 3.731414ms)
Apr 29 09:54:30.417: INFO: (10) /api/v1/nodes/0mfg0-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 3.946815ms)
Apr 29 09:54:30.421: INFO: (11) /api/v1/nodes/0mfg0-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 4.242916ms)
Apr 29 09:54:30.427: INFO: (12) /api/v1/nodes/0mfg0-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 5.453021ms)
Apr 29 09:54:30.430: INFO: (13) /api/v1/nodes/0mfg0-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 3.461513ms)
Apr 29 09:54:30.434: INFO: (14) /api/v1/nodes/0mfg0-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 3.294212ms)
Apr 29 09:54:30.437: INFO: (15) /api/v1/nodes/0mfg0-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 3.209412ms)
Apr 29 09:54:30.440: INFO: (16) /api/v1/nodes/0mfg0-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 3.355912ms)
Apr 29 09:54:30.444: INFO: (17) /api/v1/nodes/0mfg0-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 3.217712ms)
Apr 29 09:54:30.448: INFO: (18) /api/v1/nodes/0mfg0-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 4.855518ms)
Apr 29 09:54:30.452: INFO: (19) /api/v1/nodes/0mfg0-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 3.211912ms)
[AfterEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:54:30.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6675" for this suite.
Apr 29 09:54:36.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:54:36.585: INFO: namespace proxy-6675 deletion completed in 6.129847318s

• [SLOW TEST:6.376 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:54:36.586: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-6841
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:54:36.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6841" for this suite.
Apr 29 09:54:42.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:54:42.951: INFO: namespace kubelet-test-6841 deletion completed in 6.162408985s

• [SLOW TEST:6.365 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:54:42.957: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8759
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-8759
Apr 29 09:54:51.150: INFO: Started pod liveness-http in namespace container-probe-8759
STEP: checking the pod's current state and verifying that restartCount is present
Apr 29 09:54:51.152: INFO: Initial restart count of pod liveness-http is 0
Apr 29 09:55:09.193: INFO: Restart count of pod container-probe-8759/liveness-http is now 1 (18.040401359s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:55:09.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8759" for this suite.
Apr 29 09:55:15.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:55:15.365: INFO: namespace container-probe-8759 deletion completed in 6.125831771s

• [SLOW TEST:32.408 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:55:15.365: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1676
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Apr 29 09:55:22.223: INFO: Successfully updated pod "labelsupdatee3700e9a-6a64-11e9-b6b4-b219b18c41e8"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:55:24.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1676" for this suite.
Apr 29 09:55:46.279: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:55:46.398: INFO: namespace downward-api-1676 deletion completed in 22.131345101s

• [SLOW TEST:31.033 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:55:46.399: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1064
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 29 09:55:46.560: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f5da4269-6a64-11e9-b6b4-b219b18c41e8" in namespace "downward-api-1064" to be "success or failure"
Apr 29 09:55:46.570: INFO: Pod "downwardapi-volume-f5da4269-6a64-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 9.859136ms
Apr 29 09:55:48.575: INFO: Pod "downwardapi-volume-f5da4269-6a64-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014535897s
Apr 29 09:55:50.579: INFO: Pod "downwardapi-volume-f5da4269-6a64-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018433249s
Apr 29 09:55:52.583: INFO: Pod "downwardapi-volume-f5da4269-6a64-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.022587797s
STEP: Saw pod success
Apr 29 09:55:52.583: INFO: Pod "downwardapi-volume-f5da4269-6a64-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:55:52.587: INFO: Trying to get logs from node 0mfg0-worker-000001 pod downwardapi-volume-f5da4269-6a64-11e9-b6b4-b219b18c41e8 container client-container: <nil>
STEP: delete the pod
Apr 29 09:55:52.611: INFO: Waiting for pod downwardapi-volume-f5da4269-6a64-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:55:52.614: INFO: Pod downwardapi-volume-f5da4269-6a64-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:55:52.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1064" for this suite.
Apr 29 09:55:58.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:55:58.750: INFO: namespace downward-api-1064 deletion completed in 6.132347253s

• [SLOW TEST:12.352 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:55:58.752: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-2436
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-2436
Apr 29 09:56:04.930: INFO: Started pod liveness-http in namespace container-probe-2436
STEP: checking the pod's current state and verifying that restartCount is present
Apr 29 09:56:04.933: INFO: Initial restart count of pod liveness-http is 0
Apr 29 09:56:20.969: INFO: Restart count of pod container-probe-2436/liveness-http is now 1 (16.035510378s elapsed)
Apr 29 09:56:41.007: INFO: Restart count of pod container-probe-2436/liveness-http is now 2 (36.073719105s elapsed)
Apr 29 09:57:01.047: INFO: Restart count of pod container-probe-2436/liveness-http is now 3 (56.113337584s elapsed)
Apr 29 09:57:21.084: INFO: Restart count of pod container-probe-2436/liveness-http is now 4 (1m16.150603218s elapsed)
Apr 29 09:58:29.231: INFO: Restart count of pod container-probe-2436/liveness-http is now 5 (2m24.297387507s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:58:29.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2436" for this suite.
Apr 29 09:58:35.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:58:35.370: INFO: namespace container-probe-2436 deletion completed in 6.114638471s

• [SLOW TEST:156.618 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:58:35.371: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2517
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1455
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 29 09:58:35.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=kubectl-2517'
Apr 29 09:58:36.540: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr 29 09:58:36.540: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1460
Apr 29 09:58:38.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 delete deployment e2e-test-nginx-deployment --namespace=kubectl-2517'
Apr 29 09:58:38.707: INFO: stderr: ""
Apr 29 09:58:38.707: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:58:38.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2517" for this suite.
Apr 29 09:58:44.738: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:58:44.847: INFO: namespace kubectl-2517 deletion completed in 6.127139063s

• [SLOW TEST:9.477 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:58:44.848: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5038
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Apr 29 09:58:45.036: INFO: Waiting up to 5m0s for pod "pod-6039fd54-6a65-11e9-b6b4-b219b18c41e8" in namespace "emptydir-5038" to be "success or failure"
Apr 29 09:58:45.044: INFO: Pod "pod-6039fd54-6a65-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 7.216625ms
Apr 29 09:58:47.048: INFO: Pod "pod-6039fd54-6a65-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011391005s
Apr 29 09:58:49.052: INFO: Pod "pod-6039fd54-6a65-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01498418s
Apr 29 09:58:51.058: INFO: Pod "pod-6039fd54-6a65-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.021631761s
STEP: Saw pod success
Apr 29 09:58:51.058: INFO: Pod "pod-6039fd54-6a65-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 09:58:51.062: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-6039fd54-6a65-11e9-b6b4-b219b18c41e8 container test-container: <nil>
STEP: delete the pod
Apr 29 09:58:51.104: INFO: Waiting for pod pod-6039fd54-6a65-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 09:58:51.107: INFO: Pod pod-6039fd54-6a65-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:58:51.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5038" for this suite.
Apr 29 09:58:57.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:58:57.266: INFO: namespace emptydir-5038 deletion completed in 6.154785392s

• [SLOW TEST:12.419 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:58:57.267: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-3739
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Apr 29 09:58:57.441: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 29 09:58:57.453: INFO: Waiting for terminating namespaces to be deleted...
Apr 29 09:58:57.456: INFO: 
Logging pods the kubelet thinks is on node 0mfg0-worker-000000 before test
Apr 29 09:58:57.464: INFO: chart-operator-78bf665f65-mz82s from giantswarm started at 2019-04-29 08:40:17 +0000 UTC (1 container statuses recorded)
Apr 29 09:58:57.464: INFO: 	Container chart-operator ready: true, restart count 0
Apr 29 09:58:57.464: INFO: metrics-server-b94b95fb4-td6lg from kube-system started at 2019-04-29 08:46:24 +0000 UTC (1 container statuses recorded)
Apr 29 09:58:57.464: INFO: 	Container metrics-server ready: true, restart count 0
Apr 29 09:58:57.464: INFO: external-dns-7fc5fdc459-p572q from kube-system started at 2019-04-29 08:46:42 +0000 UTC (1 container statuses recorded)
Apr 29 09:58:57.464: INFO: 	Container external-dns ready: true, restart count 0
Apr 29 09:58:57.464: INFO: sonobuoy-systemd-logs-daemon-set-354ce670adf74187-6wk5n from heptio-sonobuoy started at 2019-04-29 08:52:55 +0000 UTC (2 container statuses recorded)
Apr 29 09:58:57.464: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Apr 29 09:58:57.464: INFO: 	Container systemd-logs ready: true, restart count 1
Apr 29 09:58:57.464: INFO: default-http-backend-64bbffc5c4-vnglb from kube-system started at 2019-04-29 08:46:29 +0000 UTC (1 container statuses recorded)
Apr 29 09:58:57.464: INFO: 	Container default-http-backend ready: true, restart count 0
Apr 29 09:58:57.464: INFO: kube-proxy-cxrpf from kube-system started at 2019-04-29 08:39:19 +0000 UTC (1 container statuses recorded)
Apr 29 09:58:57.464: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 29 09:58:57.464: INFO: net-exporter-99sc7 from kube-system started at 2019-04-29 08:41:08 +0000 UTC (1 container statuses recorded)
Apr 29 09:58:57.464: INFO: 	Container net-exporter ready: true, restart count 0
Apr 29 09:58:57.464: INFO: node-exporter-ndh5s from kube-system started at 2019-04-29 08:46:40 +0000 UTC (1 container statuses recorded)
Apr 29 09:58:57.464: INFO: 	Container node-exporter ready: true, restart count 0
Apr 29 09:58:57.464: INFO: calico-node-dlr6h from kube-system started at 2019-04-29 08:38:55 +0000 UTC (1 container statuses recorded)
Apr 29 09:58:57.465: INFO: 	Container calico-node ready: true, restart count 0
Apr 29 09:58:57.465: INFO: cert-exporter-6krvn from kube-system started at 2019-04-29 08:46:06 +0000 UTC (1 container statuses recorded)
Apr 29 09:58:57.465: INFO: 	Container cert-exporter ready: true, restart count 0
Apr 29 09:58:57.465: INFO: nginx-ingress-controller-65f568886b-w7wpr from kube-system started at 2019-04-29 08:47:56 +0000 UTC (1 container statuses recorded)
Apr 29 09:58:57.465: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Apr 29 09:58:57.465: INFO: 
Logging pods the kubelet thinks is on node 0mfg0-worker-000001 before test
Apr 29 09:58:57.475: INFO: net-exporter-s8qvt from kube-system started at 2019-04-29 08:41:07 +0000 UTC (1 container statuses recorded)
Apr 29 09:58:57.475: INFO: 	Container net-exporter ready: true, restart count 0
Apr 29 09:58:57.475: INFO: coredns-58f7d854b4-hxq5q from kube-system started at 2019-04-29 08:40:50 +0000 UTC (1 container statuses recorded)
Apr 29 09:58:57.475: INFO: 	Container coredns ready: true, restart count 0
Apr 29 09:58:57.475: INFO: cert-exporter-774sr from kube-system started at 2019-04-29 08:46:06 +0000 UTC (1 container statuses recorded)
Apr 29 09:58:57.475: INFO: 	Container cert-exporter ready: true, restart count 0
Apr 29 09:58:57.475: INFO: calico-node-pcf74 from kube-system started at 2019-04-29 08:38:55 +0000 UTC (1 container statuses recorded)
Apr 29 09:58:57.475: INFO: 	Container calico-node ready: true, restart count 0
Apr 29 09:58:57.475: INFO: kube-proxy-8vxcc from kube-system started at 2019-04-29 08:39:19 +0000 UTC (1 container statuses recorded)
Apr 29 09:58:57.475: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 29 09:58:57.475: INFO: sonobuoy from heptio-sonobuoy started at 2019-04-29 08:52:41 +0000 UTC (1 container statuses recorded)
Apr 29 09:58:57.475: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 29 09:58:57.475: INFO: node-exporter-nsbd5 from kube-system started at 2019-04-29 08:46:40 +0000 UTC (1 container statuses recorded)
Apr 29 09:58:57.475: INFO: 	Container node-exporter ready: true, restart count 0
Apr 29 09:58:57.475: INFO: nginx-ingress-controller-65f568886b-49sp4 from kube-system started at 2019-04-29 08:48:36 +0000 UTC (1 container statuses recorded)
Apr 29 09:58:57.475: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Apr 29 09:58:57.475: INFO: default-http-backend-64bbffc5c4-wzr4c from kube-system started at 2019-04-29 08:47:04 +0000 UTC (1 container statuses recorded)
Apr 29 09:58:57.475: INFO: 	Container default-http-backend ready: true, restart count 0
Apr 29 09:58:57.475: INFO: sonobuoy-systemd-logs-daemon-set-354ce670adf74187-k945v from heptio-sonobuoy started at 2019-04-29 08:52:55 +0000 UTC (2 container statuses recorded)
Apr 29 09:58:57.475: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Apr 29 09:58:57.475: INFO: 	Container systemd-logs ready: true, restart count 1
Apr 29 09:58:57.475: INFO: 
Logging pods the kubelet thinks is on node 0mfg0-worker-000002 before test
Apr 29 09:58:57.493: INFO: nginx-ingress-controller-65f568886b-lkq5t from kube-system started at 2019-04-29 08:46:31 +0000 UTC (1 container statuses recorded)
Apr 29 09:58:57.493: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Apr 29 09:58:57.493: INFO: node-exporter-5kgvm from kube-system started at 2019-04-29 08:46:40 +0000 UTC (1 container statuses recorded)
Apr 29 09:58:57.493: INFO: 	Container node-exporter ready: true, restart count 0
Apr 29 09:58:57.493: INFO: kube-proxy-crdnv from kube-system started at 2019-04-29 08:39:15 +0000 UTC (1 container statuses recorded)
Apr 29 09:58:57.493: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 29 09:58:57.493: INFO: net-exporter-zvnc8 from kube-system started at 2019-04-29 08:41:07 +0000 UTC (1 container statuses recorded)
Apr 29 09:58:57.493: INFO: 	Container net-exporter ready: true, restart count 0
Apr 29 09:58:57.493: INFO: cert-exporter-rdxbx from kube-system started at 2019-04-29 08:46:06 +0000 UTC (1 container statuses recorded)
Apr 29 09:58:57.493: INFO: 	Container cert-exporter ready: true, restart count 0
Apr 29 09:58:57.493: INFO: calico-node-t2xwm from kube-system started at 2019-04-29 08:38:56 +0000 UTC (1 container statuses recorded)
Apr 29 09:58:57.493: INFO: 	Container calico-node ready: true, restart count 0
Apr 29 09:58:57.493: INFO: tiller-deploy-54494c4fb6-dqfjq from giantswarm started at 2019-04-29 08:39:17 +0000 UTC (1 container statuses recorded)
Apr 29 09:58:57.493: INFO: 	Container tiller ready: true, restart count 0
Apr 29 09:58:57.493: INFO: sonobuoy-systemd-logs-daemon-set-354ce670adf74187-727pj from heptio-sonobuoy started at 2019-04-29 08:52:55 +0000 UTC (2 container statuses recorded)
Apr 29 09:58:57.493: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Apr 29 09:58:57.493: INFO: 	Container systemd-logs ready: true, restart count 1
Apr 29 09:58:57.493: INFO: coredns-58f7d854b4-tgdc8 from kube-system started at 2019-04-29 08:40:50 +0000 UTC (1 container statuses recorded)
Apr 29 09:58:57.493: INFO: 	Container coredns ready: true, restart count 0
Apr 29 09:58:57.493: INFO: kube-state-metrics-5fdb649879-b799g from kube-system started at 2019-04-29 08:46:29 +0000 UTC (2 container statuses recorded)
Apr 29 09:58:57.493: INFO: 	Container addon-resizer ready: true, restart count 0
Apr 29 09:58:57.493: INFO: 	Container kube-state-metrics ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-6b44f351-6a65-11e9-b6b4-b219b18c41e8 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-6b44f351-6a65-11e9-b6b4-b219b18c41e8 off the node 0mfg0-worker-000001
STEP: verifying the node doesn't have the label kubernetes.io/e2e-6b44f351-6a65-11e9-b6b4-b219b18c41e8
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:59:09.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3739" for this suite.
Apr 29 09:59:19.655: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 09:59:19.762: INFO: namespace sched-pred-3739 deletion completed in 10.133183543s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:22.495 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 09:59:19.762: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7539
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1414
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 29 09:59:19.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-7539'
Apr 29 09:59:20.043: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr 29 09:59:20.043: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: rolling-update to same image controller
Apr 29 09:59:20.070: INFO: scanned /root for discovery docs: <nil>
Apr 29 09:59:20.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-7539'
Apr 29 09:59:35.168: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Apr 29 09:59:35.168: INFO: stdout: "Created e2e-test-nginx-rc-13977018d377189119d599655e401c3c\nScaling up e2e-test-nginx-rc-13977018d377189119d599655e401c3c from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-13977018d377189119d599655e401c3c up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-13977018d377189119d599655e401c3c to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Apr 29 09:59:35.168: INFO: stdout: "Created e2e-test-nginx-rc-13977018d377189119d599655e401c3c\nScaling up e2e-test-nginx-rc-13977018d377189119d599655e401c3c from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-13977018d377189119d599655e401c3c up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-13977018d377189119d599655e401c3c to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Apr 29 09:59:35.168: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-7539'
Apr 29 09:59:35.287: INFO: stderr: ""
Apr 29 09:59:35.287: INFO: stdout: "e2e-test-nginx-rc-13977018d377189119d599655e401c3c-67kg4 e2e-test-nginx-rc-gg65l "
STEP: Replicas for run=e2e-test-nginx-rc: expected=1 actual=2
Apr 29 09:59:40.287: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-7539'
Apr 29 09:59:40.394: INFO: stderr: ""
Apr 29 09:59:40.394: INFO: stdout: "e2e-test-nginx-rc-13977018d377189119d599655e401c3c-67kg4 "
Apr 29 09:59:40.394: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods e2e-test-nginx-rc-13977018d377189119d599655e401c3c-67kg4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7539'
Apr 29 09:59:40.494: INFO: stderr: ""
Apr 29 09:59:40.494: INFO: stdout: "true"
Apr 29 09:59:40.494: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 get pods e2e-test-nginx-rc-13977018d377189119d599655e401c3c-67kg4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7539'
Apr 29 09:59:40.587: INFO: stderr: ""
Apr 29 09:59:40.587: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Apr 29 09:59:40.587: INFO: e2e-test-nginx-rc-13977018d377189119d599655e401c3c-67kg4 is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1420
Apr 29 09:59:40.587: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 delete rc e2e-test-nginx-rc --namespace=kubectl-7539'
Apr 29 09:59:40.701: INFO: stderr: ""
Apr 29 09:59:40.701: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 09:59:40.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7539" for this suite.
Apr 29 10:00:02.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:00:02.903: INFO: namespace kubectl-7539 deletion completed in 22.166369592s

• [SLOW TEST:43.141 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:00:02.903: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-6099
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Apr 29 10:00:03.071: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:00:09.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6099" for this suite.
Apr 29 10:00:15.948: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:00:16.069: INFO: namespace init-container-6099 deletion completed in 6.139159348s

• [SLOW TEST:13.166 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:00:16.071: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7058
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-9699acee-6a65-11e9-b6b4-b219b18c41e8
STEP: Creating a pod to test consume configMaps
Apr 29 10:00:16.255: INFO: Waiting up to 5m0s for pod "pod-configmaps-969a810f-6a65-11e9-b6b4-b219b18c41e8" in namespace "configmap-7058" to be "success or failure"
Apr 29 10:00:16.269: INFO: Pod "pod-configmaps-969a810f-6a65-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 13.525246ms
Apr 29 10:00:18.272: INFO: Pod "pod-configmaps-969a810f-6a65-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017090776s
Apr 29 10:00:20.276: INFO: Pod "pod-configmaps-969a810f-6a65-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020924304s
Apr 29 10:00:22.281: INFO: Pod "pod-configmaps-969a810f-6a65-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.025643132s
STEP: Saw pod success
Apr 29 10:00:22.281: INFO: Pod "pod-configmaps-969a810f-6a65-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 10:00:22.285: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-configmaps-969a810f-6a65-11e9-b6b4-b219b18c41e8 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 29 10:00:22.331: INFO: Waiting for pod pod-configmaps-969a810f-6a65-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 10:00:22.341: INFO: Pod pod-configmaps-969a810f-6a65-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:00:22.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7058" for this suite.
Apr 29 10:00:28.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:00:28.481: INFO: namespace configmap-7058 deletion completed in 6.136351082s

• [SLOW TEST:12.410 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:00:28.483: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-5872
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5872.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5872.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 29 10:00:36.730: INFO: DNS probes using dns-5872/dns-test-9dfc91a4-6a65-11e9-b6b4-b219b18c41e8 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:00:36.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5872" for this suite.
Apr 29 10:00:42.786: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:00:42.912: INFO: namespace dns-5872 deletion completed in 6.139308028s

• [SLOW TEST:14.430 seconds]
[sig-network] DNS
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:00:42.914: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2843
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 29 10:00:43.113: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a69c3430-6a65-11e9-b6b4-b219b18c41e8" in namespace "projected-2843" to be "success or failure"
Apr 29 10:00:43.121: INFO: Pod "downwardapi-volume-a69c3430-6a65-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.431728ms
Apr 29 10:00:45.133: INFO: Pod "downwardapi-volume-a69c3430-6a65-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02090605s
Apr 29 10:00:47.137: INFO: Pod "downwardapi-volume-a69c3430-6a65-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024627239s
Apr 29 10:00:49.142: INFO: Pod "downwardapi-volume-a69c3430-6a65-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.028951927s
STEP: Saw pod success
Apr 29 10:00:49.142: INFO: Pod "downwardapi-volume-a69c3430-6a65-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 10:00:49.145: INFO: Trying to get logs from node 0mfg0-worker-000001 pod downwardapi-volume-a69c3430-6a65-11e9-b6b4-b219b18c41e8 container client-container: <nil>
STEP: delete the pod
Apr 29 10:00:49.182: INFO: Waiting for pod downwardapi-volume-a69c3430-6a65-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 10:00:49.185: INFO: Pod downwardapi-volume-a69c3430-6a65-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:00:49.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2843" for this suite.
Apr 29 10:00:55.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:00:55.335: INFO: namespace projected-2843 deletion completed in 6.146461799s

• [SLOW TEST:12.421 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:00:55.336: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5450
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 29 10:00:55.516: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ae00c02e-6a65-11e9-b6b4-b219b18c41e8" in namespace "projected-5450" to be "success or failure"
Apr 29 10:00:55.529: INFO: Pod "downwardapi-volume-ae00c02e-6a65-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.018527ms
Apr 29 10:00:57.533: INFO: Pod "downwardapi-volume-ae00c02e-6a65-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011717901s
Apr 29 10:00:59.537: INFO: Pod "downwardapi-volume-ae00c02e-6a65-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015683674s
Apr 29 10:01:01.541: INFO: Pod "downwardapi-volume-ae00c02e-6a65-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.019689544s
STEP: Saw pod success
Apr 29 10:01:01.541: INFO: Pod "downwardapi-volume-ae00c02e-6a65-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 10:01:01.544: INFO: Trying to get logs from node 0mfg0-worker-000001 pod downwardapi-volume-ae00c02e-6a65-11e9-b6b4-b219b18c41e8 container client-container: <nil>
STEP: delete the pod
Apr 29 10:01:01.587: INFO: Waiting for pod downwardapi-volume-ae00c02e-6a65-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 10:01:01.591: INFO: Pod downwardapi-volume-ae00c02e-6a65-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:01:01.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5450" for this suite.
Apr 29 10:01:07.607: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:01:07.716: INFO: namespace projected-5450 deletion completed in 6.121350463s

• [SLOW TEST:12.381 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:01:07.717: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5916
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-b55f261b-6a65-11e9-b6b4-b219b18c41e8
STEP: Creating a pod to test consume secrets
Apr 29 10:01:07.889: INFO: Waiting up to 5m0s for pod "pod-secrets-b55fdb16-6a65-11e9-b6b4-b219b18c41e8" in namespace "secrets-5916" to be "success or failure"
Apr 29 10:01:07.900: INFO: Pod "pod-secrets-b55fdb16-6a65-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 10.914537ms
Apr 29 10:01:09.908: INFO: Pod "pod-secrets-b55fdb16-6a65-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018502208s
Apr 29 10:01:11.914: INFO: Pod "pod-secrets-b55fdb16-6a65-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024406571s
Apr 29 10:01:13.917: INFO: Pod "pod-secrets-b55fdb16-6a65-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.028105523s
STEP: Saw pod success
Apr 29 10:01:13.917: INFO: Pod "pod-secrets-b55fdb16-6a65-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 10:01:13.921: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-secrets-b55fdb16-6a65-11e9-b6b4-b219b18c41e8 container secret-volume-test: <nil>
STEP: delete the pod
Apr 29 10:01:13.965: INFO: Waiting for pod pod-secrets-b55fdb16-6a65-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 10:01:13.968: INFO: Pod pod-secrets-b55fdb16-6a65-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:01:13.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5916" for this suite.
Apr 29 10:01:19.985: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:01:20.093: INFO: namespace secrets-5916 deletion completed in 6.120768965s

• [SLOW TEST:12.376 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:01:20.094: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-392
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-bcc1b975-6a65-11e9-b6b4-b219b18c41e8
STEP: Creating a pod to test consume configMaps
Apr 29 10:01:20.270: INFO: Waiting up to 5m0s for pod "pod-configmaps-bcc24f27-6a65-11e9-b6b4-b219b18c41e8" in namespace "configmap-392" to be "success or failure"
Apr 29 10:01:20.285: INFO: Pod "pod-configmaps-bcc24f27-6a65-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 13.483466ms
Apr 29 10:01:22.296: INFO: Pod "pod-configmaps-bcc24f27-6a65-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025231438s
Apr 29 10:01:24.300: INFO: Pod "pod-configmaps-bcc24f27-6a65-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02929665s
Apr 29 10:01:26.304: INFO: Pod "pod-configmaps-bcc24f27-6a65-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.033353698s
STEP: Saw pod success
Apr 29 10:01:26.304: INFO: Pod "pod-configmaps-bcc24f27-6a65-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 10:01:26.307: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-configmaps-bcc24f27-6a65-11e9-b6b4-b219b18c41e8 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 29 10:01:26.331: INFO: Waiting for pod pod-configmaps-bcc24f27-6a65-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 10:01:26.336: INFO: Pod pod-configmaps-bcc24f27-6a65-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:01:26.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-392" for this suite.
Apr 29 10:01:32.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:01:32.458: INFO: namespace configmap-392 deletion completed in 6.117389434s

• [SLOW TEST:12.365 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:01:32.459: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9560
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 29 10:01:32.620: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c41ed163-6a65-11e9-b6b4-b219b18c41e8" in namespace "projected-9560" to be "success or failure"
Apr 29 10:01:32.632: INFO: Pod "downwardapi-volume-c41ed163-6a65-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 11.446339ms
Apr 29 10:01:34.635: INFO: Pod "downwardapi-volume-c41ed163-6a65-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015194519s
Apr 29 10:01:36.639: INFO: Pod "downwardapi-volume-c41ed163-6a65-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019056837s
Apr 29 10:01:38.647: INFO: Pod "downwardapi-volume-c41ed163-6a65-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.026633036s
STEP: Saw pod success
Apr 29 10:01:38.647: INFO: Pod "downwardapi-volume-c41ed163-6a65-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 10:01:38.650: INFO: Trying to get logs from node 0mfg0-worker-000001 pod downwardapi-volume-c41ed163-6a65-11e9-b6b4-b219b18c41e8 container client-container: <nil>
STEP: delete the pod
Apr 29 10:01:38.678: INFO: Waiting for pod downwardapi-volume-c41ed163-6a65-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 10:01:38.685: INFO: Pod downwardapi-volume-c41ed163-6a65-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:01:38.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9560" for this suite.
Apr 29 10:01:44.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:01:44.812: INFO: namespace projected-9560 deletion completed in 6.122169508s

• [SLOW TEST:12.353 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:01:44.813: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5005
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-cb7cc8d9-6a65-11e9-b6b4-b219b18c41e8
STEP: Creating a pod to test consume secrets
Apr 29 10:01:44.988: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-cb7d538c-6a65-11e9-b6b4-b219b18c41e8" in namespace "projected-5005" to be "success or failure"
Apr 29 10:01:45.002: INFO: Pod "pod-projected-secrets-cb7d538c-6a65-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 14.424872ms
Apr 29 10:01:47.006: INFO: Pod "pod-projected-secrets-cb7d538c-6a65-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018130866s
Apr 29 10:01:49.010: INFO: Pod "pod-projected-secrets-cb7d538c-6a65-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021891599s
Apr 29 10:01:51.014: INFO: Pod "pod-projected-secrets-cb7d538c-6a65-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.026054176s
STEP: Saw pod success
Apr 29 10:01:51.014: INFO: Pod "pod-projected-secrets-cb7d538c-6a65-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 10:01:51.017: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-projected-secrets-cb7d538c-6a65-11e9-b6b4-b219b18c41e8 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 29 10:01:51.050: INFO: Waiting for pod pod-projected-secrets-cb7d538c-6a65-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 10:01:51.053: INFO: Pod pod-projected-secrets-cb7d538c-6a65-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:01:51.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5005" for this suite.
Apr 29 10:01:57.070: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:01:57.175: INFO: namespace projected-5005 deletion completed in 6.117748498s

• [SLOW TEST:12.362 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:01:57.175: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2748
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Apr 29 10:01:57.342: INFO: namespace kubectl-2748
Apr 29 10:01:57.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 create -f - --namespace=kubectl-2748'
Apr 29 10:01:57.665: INFO: stderr: ""
Apr 29 10:01:57.665: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Apr 29 10:01:58.681: INFO: Selector matched 1 pods for map[app:redis]
Apr 29 10:01:58.681: INFO: Found 0 / 1
Apr 29 10:01:59.670: INFO: Selector matched 1 pods for map[app:redis]
Apr 29 10:01:59.670: INFO: Found 0 / 1
Apr 29 10:02:00.670: INFO: Selector matched 1 pods for map[app:redis]
Apr 29 10:02:00.670: INFO: Found 0 / 1
Apr 29 10:02:01.670: INFO: Selector matched 1 pods for map[app:redis]
Apr 29 10:02:01.670: INFO: Found 0 / 1
Apr 29 10:02:02.670: INFO: Selector matched 1 pods for map[app:redis]
Apr 29 10:02:02.670: INFO: Found 1 / 1
Apr 29 10:02:02.670: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 29 10:02:02.673: INFO: Selector matched 1 pods for map[app:redis]
Apr 29 10:02:02.673: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 29 10:02:02.673: INFO: wait on redis-master startup in kubectl-2748 
Apr 29 10:02:02.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 logs redis-master-zfn8j redis-master --namespace=kubectl-2748'
Apr 29 10:02:02.774: INFO: stderr: ""
Apr 29 10:02:02.774: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 29 Apr 10:02:01.860 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 29 Apr 10:02:01.860 # Server started, Redis version 3.2.12\n1:M 29 Apr 10:02:01.860 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 29 Apr 10:02:01.860 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Apr 29 10:02:02.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-2748'
Apr 29 10:02:02.903: INFO: stderr: ""
Apr 29 10:02:02.903: INFO: stdout: "service/rm2 exposed\n"
Apr 29 10:02:02.909: INFO: Service rm2 in namespace kubectl-2748 found.
STEP: exposing service
Apr 29 10:02:04.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-2748'
Apr 29 10:02:05.041: INFO: stderr: ""
Apr 29 10:02:05.041: INFO: stdout: "service/rm3 exposed\n"
Apr 29 10:02:05.046: INFO: Service rm3 in namespace kubectl-2748 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:02:07.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2748" for this suite.
Apr 29 10:02:29.080: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:02:29.187: INFO: namespace kubectl-2748 deletion completed in 22.125537084s

• [SLOW TEST:32.012 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create services for rc  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:02:29.188: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-942
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Apr 29 10:02:39.923: INFO: Successfully updated pod "annotationupdatee5f34591-6a65-11e9-b6b4-b219b18c41e8"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:02:41.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-942" for this suite.
Apr 29 10:03:04.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:03:04.146: INFO: namespace projected-942 deletion completed in 22.17259643s

• [SLOW TEST:34.957 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:03:04.147: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5740
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-5740/configmap-test-fac4c739-6a65-11e9-b6b4-b219b18c41e8
STEP: Creating a pod to test consume configMaps
Apr 29 10:03:04.311: INFO: Waiting up to 5m0s for pod "pod-configmaps-fac56f41-6a65-11e9-b6b4-b219b18c41e8" in namespace "configmap-5740" to be "success or failure"
Apr 29 10:03:04.344: INFO: Pod "pod-configmaps-fac56f41-6a65-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 32.555952ms
Apr 29 10:03:06.348: INFO: Pod "pod-configmaps-fac56f41-6a65-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037002094s
Apr 29 10:03:08.353: INFO: Pod "pod-configmaps-fac56f41-6a65-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.041726286s
Apr 29 10:03:10.357: INFO: Pod "pod-configmaps-fac56f41-6a65-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.045459615s
STEP: Saw pod success
Apr 29 10:03:10.357: INFO: Pod "pod-configmaps-fac56f41-6a65-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 10:03:10.360: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-configmaps-fac56f41-6a65-11e9-b6b4-b219b18c41e8 container env-test: <nil>
STEP: delete the pod
Apr 29 10:03:10.385: INFO: Waiting for pod pod-configmaps-fac56f41-6a65-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 10:03:10.390: INFO: Pod pod-configmaps-fac56f41-6a65-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:03:10.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5740" for this suite.
Apr 29 10:03:16.412: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:03:16.531: INFO: namespace configmap-5740 deletion completed in 6.137638519s

• [SLOW TEST:12.384 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:03:16.532: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-8376
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-downwardapi-4hrn
STEP: Creating a pod to test atomic-volume-subpath
Apr 29 10:03:16.703: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-4hrn" in namespace "subpath-8376" to be "success or failure"
Apr 29 10:03:16.736: INFO: Pod "pod-subpath-test-downwardapi-4hrn": Phase="Pending", Reason="", readiness=false. Elapsed: 33.482257ms
Apr 29 10:03:18.746: INFO: Pod "pod-subpath-test-downwardapi-4hrn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043363434s
Apr 29 10:03:20.750: INFO: Pod "pod-subpath-test-downwardapi-4hrn": Phase="Pending", Reason="", readiness=false. Elapsed: 4.047045493s
Apr 29 10:03:22.754: INFO: Pod "pod-subpath-test-downwardapi-4hrn": Phase="Running", Reason="", readiness=true. Elapsed: 6.050964704s
Apr 29 10:03:24.758: INFO: Pod "pod-subpath-test-downwardapi-4hrn": Phase="Running", Reason="", readiness=true. Elapsed: 8.054949765s
Apr 29 10:03:26.762: INFO: Pod "pod-subpath-test-downwardapi-4hrn": Phase="Running", Reason="", readiness=true. Elapsed: 10.059322779s
Apr 29 10:03:28.766: INFO: Pod "pod-subpath-test-downwardapi-4hrn": Phase="Running", Reason="", readiness=true. Elapsed: 12.063122836s
Apr 29 10:03:30.770: INFO: Pod "pod-subpath-test-downwardapi-4hrn": Phase="Running", Reason="", readiness=true. Elapsed: 14.06668434s
Apr 29 10:03:32.774: INFO: Pod "pod-subpath-test-downwardapi-4hrn": Phase="Running", Reason="", readiness=true. Elapsed: 16.070943602s
Apr 29 10:03:34.778: INFO: Pod "pod-subpath-test-downwardapi-4hrn": Phase="Running", Reason="", readiness=true. Elapsed: 18.074748708s
Apr 29 10:03:36.781: INFO: Pod "pod-subpath-test-downwardapi-4hrn": Phase="Running", Reason="", readiness=true. Elapsed: 20.078542365s
Apr 29 10:03:38.785: INFO: Pod "pod-subpath-test-downwardapi-4hrn": Phase="Running", Reason="", readiness=true. Elapsed: 22.082569774s
Apr 29 10:03:40.789: INFO: Pod "pod-subpath-test-downwardapi-4hrn": Phase="Running", Reason="", readiness=true. Elapsed: 24.086528434s
Apr 29 10:03:42.793: INFO: Pod "pod-subpath-test-downwardapi-4hrn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.090373143s
STEP: Saw pod success
Apr 29 10:03:42.793: INFO: Pod "pod-subpath-test-downwardapi-4hrn" satisfied condition "success or failure"
Apr 29 10:03:42.796: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-subpath-test-downwardapi-4hrn container test-container-subpath-downwardapi-4hrn: <nil>
STEP: delete the pod
Apr 29 10:03:42.863: INFO: Waiting for pod pod-subpath-test-downwardapi-4hrn to disappear
Apr 29 10:03:42.868: INFO: Pod pod-subpath-test-downwardapi-4hrn no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-4hrn
Apr 29 10:03:42.868: INFO: Deleting pod "pod-subpath-test-downwardapi-4hrn" in namespace "subpath-8376"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:03:42.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8376" for this suite.
Apr 29 10:03:48.888: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:03:48.996: INFO: namespace subpath-8376 deletion completed in 6.121388553s

• [SLOW TEST:32.465 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:03:48.998: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-8276
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating server pod server in namespace prestop-8276
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-8276
STEP: Deleting pre-stop pod
Apr 29 10:04:10.244: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:04:10.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-8276" for this suite.
Apr 29 10:04:50.277: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:04:50.415: INFO: namespace prestop-8276 deletion completed in 40.150652839s

• [SLOW TEST:61.418 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:04:50.416: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-3542
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Apr 29 10:04:50.588: INFO: PodSpec: initContainers in spec.initContainers
Apr 29 10:05:42.469: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-3a1fe789-6a66-11e9-b6b4-b219b18c41e8", GenerateName:"", Namespace:"init-container-3542", SelfLink:"/api/v1/namespaces/init-container-3542/pods/pod-init-3a1fe789-6a66-11e9-b6b4-b219b18c41e8", UID:"3a20fd2a-6a66-11e9-9890-000d3a4710ea", ResourceVersion:"19728", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63692129090, loc:(*time.Location)(0x8a060e0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"588873861"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"10.2.130.170/32", "kubernetes.io/psp":"cert-exporter-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-xkq6g", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002eda300), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-xkq6g", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-xkq6g", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-xkq6g", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc000055c98), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"0mfg0-worker-000001", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00283e6c0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc000055d10)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc000055d30)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc000055d38), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc000055d3c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692129091, loc:(*time.Location)(0x8a060e0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692129091, loc:(*time.Location)(0x8a060e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692129091, loc:(*time.Location)(0x8a060e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692129090, loc:(*time.Location)(0x8a060e0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.2.1.5", PodIP:"10.2.130.170", StartTime:(*v1.Time)(0xc001ea1be0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00241b650)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00241b6c0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://86ca0fa1af8136f088527eaae632fbcab1f86d3eefeb924c4ff89bac1464cd22"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001ea1c20), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001ea1c00), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:05:42.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3542" for this suite.
Apr 29 10:06:04.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:06:04.655: INFO: namespace init-container-3542 deletion completed in 22.178938785s

• [SLOW TEST:74.239 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:06:04.655: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-5681
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-6710
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-3063
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:06:11.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-5681" for this suite.
Apr 29 10:06:17.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:06:17.304: INFO: namespace namespaces-5681 deletion completed in 6.142883873s
STEP: Destroying namespace "nsdeletetest-6710" for this suite.
Apr 29 10:06:17.306: INFO: Namespace nsdeletetest-6710 was already deleted
STEP: Destroying namespace "nsdeletetest-3063" for this suite.
Apr 29 10:06:23.322: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:06:23.437: INFO: namespace nsdeletetest-3063 deletion completed in 6.130112322s

• [SLOW TEST:18.782 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:06:23.438: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2114
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 29 10:06:23.604: INFO: Waiting up to 5m0s for pod "downwardapi-volume-718f7027-6a66-11e9-b6b4-b219b18c41e8" in namespace "downward-api-2114" to be "success or failure"
Apr 29 10:06:23.615: INFO: Pod "downwardapi-volume-718f7027-6a66-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 11.197597ms
Apr 29 10:06:25.620: INFO: Pod "downwardapi-volume-718f7027-6a66-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015606291s
Apr 29 10:06:27.624: INFO: Pod "downwardapi-volume-718f7027-6a66-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019372243s
Apr 29 10:06:29.629: INFO: Pod "downwardapi-volume-718f7027-6a66-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.024965376s
STEP: Saw pod success
Apr 29 10:06:29.629: INFO: Pod "downwardapi-volume-718f7027-6a66-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 10:06:29.632: INFO: Trying to get logs from node 0mfg0-worker-000001 pod downwardapi-volume-718f7027-6a66-11e9-b6b4-b219b18c41e8 container client-container: <nil>
STEP: delete the pod
Apr 29 10:06:29.732: INFO: Waiting for pod downwardapi-volume-718f7027-6a66-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 10:06:29.736: INFO: Pod downwardapi-volume-718f7027-6a66-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:06:29.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2114" for this suite.
Apr 29 10:06:35.773: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:06:35.876: INFO: namespace downward-api-2114 deletion completed in 6.13523539s

• [SLOW TEST:12.439 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:06:35.877: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-641
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 29 10:06:36.037: INFO: Waiting up to 5m0s for pod "downwardapi-volume-78f7f384-6a66-11e9-b6b4-b219b18c41e8" in namespace "downward-api-641" to be "success or failure"
Apr 29 10:06:36.047: INFO: Pod "downwardapi-volume-78f7f384-6a66-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 9.162978ms
Apr 29 10:06:38.051: INFO: Pod "downwardapi-volume-78f7f384-6a66-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013985056s
Apr 29 10:06:40.059: INFO: Pod "downwardapi-volume-78f7f384-6a66-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021349621s
Apr 29 10:06:42.063: INFO: Pod "downwardapi-volume-78f7f384-6a66-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.025409423s
STEP: Saw pod success
Apr 29 10:06:42.063: INFO: Pod "downwardapi-volume-78f7f384-6a66-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 10:06:42.066: INFO: Trying to get logs from node 0mfg0-worker-000001 pod downwardapi-volume-78f7f384-6a66-11e9-b6b4-b219b18c41e8 container client-container: <nil>
STEP: delete the pod
Apr 29 10:06:42.112: INFO: Waiting for pod downwardapi-volume-78f7f384-6a66-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 10:06:42.117: INFO: Pod downwardapi-volume-78f7f384-6a66-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:06:42.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-641" for this suite.
Apr 29 10:06:48.142: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:06:48.254: INFO: namespace downward-api-641 deletion completed in 6.132502309s

• [SLOW TEST:12.377 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:06:48.255: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5770
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-805997fc-6a66-11e9-b6b4-b219b18c41e8
STEP: Creating a pod to test consume secrets
Apr 29 10:06:48.452: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-805a7c2e-6a66-11e9-b6b4-b219b18c41e8" in namespace "projected-5770" to be "success or failure"
Apr 29 10:06:48.466: INFO: Pod "pod-projected-secrets-805a7c2e-6a66-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 13.521414ms
Apr 29 10:06:50.469: INFO: Pod "pod-projected-secrets-805a7c2e-6a66-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016992367s
Apr 29 10:06:52.473: INFO: Pod "pod-projected-secrets-805a7c2e-6a66-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020447086s
Apr 29 10:06:54.477: INFO: Pod "pod-projected-secrets-805a7c2e-6a66-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.024330374s
STEP: Saw pod success
Apr 29 10:06:54.477: INFO: Pod "pod-projected-secrets-805a7c2e-6a66-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 10:06:54.480: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-projected-secrets-805a7c2e-6a66-11e9-b6b4-b219b18c41e8 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 29 10:06:54.509: INFO: Waiting for pod pod-projected-secrets-805a7c2e-6a66-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 10:06:54.512: INFO: Pod pod-projected-secrets-805a7c2e-6a66-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:06:54.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5770" for this suite.
Apr 29 10:07:00.531: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:07:00.643: INFO: namespace projected-5770 deletion completed in 6.126942521s

• [SLOW TEST:12.389 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:07:00.645: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-42
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's args
Apr 29 10:07:00.815: INFO: Waiting up to 5m0s for pod "var-expansion-87bc6847-6a66-11e9-b6b4-b219b18c41e8" in namespace "var-expansion-42" to be "success or failure"
Apr 29 10:07:00.841: INFO: Pod "var-expansion-87bc6847-6a66-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 25.413112ms
Apr 29 10:07:02.844: INFO: Pod "var-expansion-87bc6847-6a66-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028951958s
Apr 29 10:07:04.848: INFO: Pod "var-expansion-87bc6847-6a66-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.032325669s
Apr 29 10:07:06.851: INFO: Pod "var-expansion-87bc6847-6a66-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.035655847s
STEP: Saw pod success
Apr 29 10:07:06.851: INFO: Pod "var-expansion-87bc6847-6a66-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 10:07:06.854: INFO: Trying to get logs from node 0mfg0-worker-000001 pod var-expansion-87bc6847-6a66-11e9-b6b4-b219b18c41e8 container dapi-container: <nil>
STEP: delete the pod
Apr 29 10:07:06.881: INFO: Waiting for pod var-expansion-87bc6847-6a66-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 10:07:06.883: INFO: Pod var-expansion-87bc6847-6a66-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:07:06.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-42" for this suite.
Apr 29 10:07:12.900: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:07:13.007: INFO: namespace var-expansion-42 deletion completed in 6.119002531s

• [SLOW TEST:12.362 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:07:13.008: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-6833
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Apr 29 10:07:13.546: INFO: Pod name wrapped-volume-race-8f5290a1-6a66-11e9-b6b4-b219b18c41e8: Found 0 pods out of 5
Apr 29 10:07:18.553: INFO: Pod name wrapped-volume-race-8f5290a1-6a66-11e9-b6b4-b219b18c41e8: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-8f5290a1-6a66-11e9-b6b4-b219b18c41e8 in namespace emptydir-wrapper-6833, will wait for the garbage collector to delete the pods
Apr 29 10:07:36.664: INFO: Deleting ReplicationController wrapped-volume-race-8f5290a1-6a66-11e9-b6b4-b219b18c41e8 took: 12.946204ms
Apr 29 10:07:36.765: INFO: Terminating ReplicationController wrapped-volume-race-8f5290a1-6a66-11e9-b6b4-b219b18c41e8 pods took: 100.191205ms
STEP: Creating RC which spawns configmap-volume pods
Apr 29 10:08:20.188: INFO: Pod name wrapped-volume-race-b70abe84-6a66-11e9-b6b4-b219b18c41e8: Found 0 pods out of 5
Apr 29 10:08:25.212: INFO: Pod name wrapped-volume-race-b70abe84-6a66-11e9-b6b4-b219b18c41e8: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-b70abe84-6a66-11e9-b6b4-b219b18c41e8 in namespace emptydir-wrapper-6833, will wait for the garbage collector to delete the pods
Apr 29 10:08:47.319: INFO: Deleting ReplicationController wrapped-volume-race-b70abe84-6a66-11e9-b6b4-b219b18c41e8 took: 22.559369ms
Apr 29 10:08:47.420: INFO: Terminating ReplicationController wrapped-volume-race-b70abe84-6a66-11e9-b6b4-b219b18c41e8 pods took: 100.366455ms
STEP: Creating RC which spawns configmap-volume pods
Apr 29 10:09:30.760: INFO: Pod name wrapped-volume-race-e11a5298-6a66-11e9-b6b4-b219b18c41e8: Found 0 pods out of 5
Apr 29 10:09:35.766: INFO: Pod name wrapped-volume-race-e11a5298-6a66-11e9-b6b4-b219b18c41e8: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-e11a5298-6a66-11e9-b6b4-b219b18c41e8 in namespace emptydir-wrapper-6833, will wait for the garbage collector to delete the pods
Apr 29 10:09:55.853: INFO: Deleting ReplicationController wrapped-volume-race-e11a5298-6a66-11e9-b6b4-b219b18c41e8 took: 7.822255ms
Apr 29 10:09:56.053: INFO: Terminating ReplicationController wrapped-volume-race-e11a5298-6a66-11e9-b6b4-b219b18c41e8 pods took: 200.24882ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:10:40.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-6833" for this suite.
Apr 29 10:10:48.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:10:48.730: INFO: namespace emptydir-wrapper-6833 deletion completed in 8.124857256s

• [SLOW TEST:215.723 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:10:48.733: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7705
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-0fb1d9b4-6a67-11e9-b6b4-b219b18c41e8
STEP: Creating a pod to test consume configMaps
Apr 29 10:10:48.924: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0fb37d0e-6a67-11e9-b6b4-b219b18c41e8" in namespace "projected-7705" to be "success or failure"
Apr 29 10:10:48.939: INFO: Pod "pod-projected-configmaps-0fb37d0e-6a67-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 14.188097ms
Apr 29 10:10:50.943: INFO: Pod "pod-projected-configmaps-0fb37d0e-6a67-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017901192s
Apr 29 10:10:52.946: INFO: Pod "pod-projected-configmaps-0fb37d0e-6a67-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021307464s
Apr 29 10:10:54.950: INFO: Pod "pod-projected-configmaps-0fb37d0e-6a67-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.024954516s
STEP: Saw pod success
Apr 29 10:10:54.950: INFO: Pod "pod-projected-configmaps-0fb37d0e-6a67-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 10:10:54.953: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-projected-configmaps-0fb37d0e-6a67-11e9-b6b4-b219b18c41e8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 29 10:10:54.998: INFO: Waiting for pod pod-projected-configmaps-0fb37d0e-6a67-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 10:10:55.001: INFO: Pod pod-projected-configmaps-0fb37d0e-6a67-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:10:55.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7705" for this suite.
Apr 29 10:11:01.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:11:01.126: INFO: namespace projected-7705 deletion completed in 6.120272164s

• [SLOW TEST:12.394 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:11:01.128: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-2648
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 29 10:11:01.278: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:11:02.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2648" for this suite.
Apr 29 10:11:08.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:11:08.465: INFO: namespace custom-resource-definition-2648 deletion completed in 6.124245958s

• [SLOW TEST:7.337 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:11:08.466: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9424
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-1b74c6e3-6a67-11e9-b6b4-b219b18c41e8
STEP: Creating configMap with name cm-test-opt-upd-1b74c72f-6a67-11e9-b6b4-b219b18c41e8
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-1b74c6e3-6a67-11e9-b6b4-b219b18c41e8
STEP: Updating configmap cm-test-opt-upd-1b74c72f-6a67-11e9-b6b4-b219b18c41e8
STEP: Creating configMap with name cm-test-opt-create-1b74c74e-6a67-11e9-b6b4-b219b18c41e8
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:11:20.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9424" for this suite.
Apr 29 10:11:42.806: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:11:42.934: INFO: namespace configmap-9424 deletion completed in 22.144778234s

• [SLOW TEST:34.468 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:11:42.934: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3973
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Apr 29 10:11:43.111: INFO: Waiting up to 5m0s for pod "pod-300049e0-6a67-11e9-b6b4-b219b18c41e8" in namespace "emptydir-3973" to be "success or failure"
Apr 29 10:11:43.123: INFO: Pod "pod-300049e0-6a67-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 11.121873ms
Apr 29 10:11:45.126: INFO: Pod "pod-300049e0-6a67-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014918923s
Apr 29 10:11:47.133: INFO: Pod "pod-300049e0-6a67-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021513172s
Apr 29 10:11:49.146: INFO: Pod "pod-300049e0-6a67-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.034923446s
STEP: Saw pod success
Apr 29 10:11:49.146: INFO: Pod "pod-300049e0-6a67-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 10:11:49.149: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-300049e0-6a67-11e9-b6b4-b219b18c41e8 container test-container: <nil>
STEP: delete the pod
Apr 29 10:11:49.173: INFO: Waiting for pod pod-300049e0-6a67-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 10:11:49.199: INFO: Pod pod-300049e0-6a67-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:11:49.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3973" for this suite.
Apr 29 10:11:55.221: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:11:55.319: INFO: namespace emptydir-3973 deletion completed in 6.112081369s

• [SLOW TEST:12.385 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:11:55.320: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-8086
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override all
Apr 29 10:11:55.506: INFO: Waiting up to 5m0s for pod "client-containers-3763aa46-6a67-11e9-b6b4-b219b18c41e8" in namespace "containers-8086" to be "success or failure"
Apr 29 10:11:55.529: INFO: Pod "client-containers-3763aa46-6a67-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 22.279943ms
Apr 29 10:11:57.532: INFO: Pod "client-containers-3763aa46-6a67-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026094776s
Apr 29 10:11:59.536: INFO: Pod "client-containers-3763aa46-6a67-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029591988s
Apr 29 10:12:01.539: INFO: Pod "client-containers-3763aa46-6a67-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.033194483s
STEP: Saw pod success
Apr 29 10:12:01.540: INFO: Pod "client-containers-3763aa46-6a67-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 10:12:01.542: INFO: Trying to get logs from node 0mfg0-worker-000001 pod client-containers-3763aa46-6a67-11e9-b6b4-b219b18c41e8 container test-container: <nil>
STEP: delete the pod
Apr 29 10:12:01.566: INFO: Waiting for pod client-containers-3763aa46-6a67-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 10:12:01.569: INFO: Pod client-containers-3763aa46-6a67-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:12:01.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8086" for this suite.
Apr 29 10:12:07.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:12:07.701: INFO: namespace containers-8086 deletion completed in 6.125652307s

• [SLOW TEST:12.381 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:12:07.702: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2815
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1354
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 29 10:12:07.866: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-2815'
Apr 29 10:12:08.876: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr 29 10:12:08.876: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Apr 29 10:12:08.895: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-c6x9z]
Apr 29 10:12:08.895: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-c6x9z" in namespace "kubectl-2815" to be "running and ready"
Apr 29 10:12:08.919: INFO: Pod "e2e-test-nginx-rc-c6x9z": Phase="Pending", Reason="", readiness=false. Elapsed: 23.922753ms
Apr 29 10:12:10.923: INFO: Pod "e2e-test-nginx-rc-c6x9z": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027594062s
Apr 29 10:12:12.927: INFO: Pod "e2e-test-nginx-rc-c6x9z": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031289052s
Apr 29 10:12:14.931: INFO: Pod "e2e-test-nginx-rc-c6x9z": Phase="Running", Reason="", readiness=true. Elapsed: 6.035078626s
Apr 29 10:12:14.931: INFO: Pod "e2e-test-nginx-rc-c6x9z" satisfied condition "running and ready"
Apr 29 10:12:14.931: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-c6x9z]
Apr 29 10:12:14.931: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 logs rc/e2e-test-nginx-rc --namespace=kubectl-2815'
Apr 29 10:12:15.050: INFO: stderr: ""
Apr 29 10:12:15.050: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1359
Apr 29 10:12:15.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 delete rc e2e-test-nginx-rc --namespace=kubectl-2815'
Apr 29 10:12:15.163: INFO: stderr: ""
Apr 29 10:12:15.164: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:12:15.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2815" for this suite.
Apr 29 10:12:21.179: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:12:21.313: INFO: namespace kubectl-2815 deletion completed in 6.145326154s

• [SLOW TEST:13.611 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:12:21.314: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4240
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-46dedb21-6a67-11e9-b6b4-b219b18c41e8
STEP: Creating a pod to test consume configMaps
Apr 29 10:12:21.483: INFO: Waiting up to 5m0s for pod "pod-configmaps-46df8420-6a67-11e9-b6b4-b219b18c41e8" in namespace "configmap-4240" to be "success or failure"
Apr 29 10:12:21.506: INFO: Pod "pod-configmaps-46df8420-6a67-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 22.09334ms
Apr 29 10:12:23.511: INFO: Pod "pod-configmaps-46df8420-6a67-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026996544s
Apr 29 10:12:25.515: INFO: Pod "pod-configmaps-46df8420-6a67-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.030969024s
Apr 29 10:12:27.518: INFO: Pod "pod-configmaps-46df8420-6a67-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.034845785s
STEP: Saw pod success
Apr 29 10:12:27.518: INFO: Pod "pod-configmaps-46df8420-6a67-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 10:12:27.521: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-configmaps-46df8420-6a67-11e9-b6b4-b219b18c41e8 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 29 10:12:27.564: INFO: Waiting for pod pod-configmaps-46df8420-6a67-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 10:12:27.572: INFO: Pod pod-configmaps-46df8420-6a67-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:12:27.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4240" for this suite.
Apr 29 10:12:33.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:12:33.706: INFO: namespace configmap-4240 deletion completed in 6.130059924s

• [SLOW TEST:12.392 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:12:33.707: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1670
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 29 10:12:33.891: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4e42fbd1-6a67-11e9-b6b4-b219b18c41e8" in namespace "projected-1670" to be "success or failure"
Apr 29 10:12:33.908: INFO: Pod "downwardapi-volume-4e42fbd1-6a67-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 7.450047ms
Apr 29 10:12:35.921: INFO: Pod "downwardapi-volume-4e42fbd1-6a67-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020944396s
Apr 29 10:12:37.928: INFO: Pod "downwardapi-volume-4e42fbd1-6a67-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.027688785s
Apr 29 10:12:39.932: INFO: Pod "downwardapi-volume-4e42fbd1-6a67-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.031636839s
STEP: Saw pod success
Apr 29 10:12:39.932: INFO: Pod "downwardapi-volume-4e42fbd1-6a67-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 10:12:39.935: INFO: Trying to get logs from node 0mfg0-worker-000001 pod downwardapi-volume-4e42fbd1-6a67-11e9-b6b4-b219b18c41e8 container client-container: <nil>
STEP: delete the pod
Apr 29 10:12:39.962: INFO: Waiting for pod downwardapi-volume-4e42fbd1-6a67-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 10:12:39.977: INFO: Pod downwardapi-volume-4e42fbd1-6a67-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:12:39.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1670" for this suite.
Apr 29 10:12:45.993: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:12:46.104: INFO: namespace projected-1670 deletion completed in 6.122542449s

• [SLOW TEST:12.397 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:12:46.104: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-677
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 29 10:12:46.284: INFO: Waiting up to 5m0s for pod "downwardapi-volume-55a7b58f-6a67-11e9-b6b4-b219b18c41e8" in namespace "downward-api-677" to be "success or failure"
Apr 29 10:12:46.296: INFO: Pod "downwardapi-volume-55a7b58f-6a67-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 11.540872ms
Apr 29 10:12:48.302: INFO: Pod "downwardapi-volume-55a7b58f-6a67-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017316267s
Apr 29 10:12:50.305: INFO: Pod "downwardapi-volume-55a7b58f-6a67-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020935531s
Apr 29 10:12:52.311: INFO: Pod "downwardapi-volume-55a7b58f-6a67-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.026099888s
STEP: Saw pod success
Apr 29 10:12:52.311: INFO: Pod "downwardapi-volume-55a7b58f-6a67-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 10:12:52.314: INFO: Trying to get logs from node 0mfg0-worker-000001 pod downwardapi-volume-55a7b58f-6a67-11e9-b6b4-b219b18c41e8 container client-container: <nil>
STEP: delete the pod
Apr 29 10:12:52.350: INFO: Waiting for pod downwardapi-volume-55a7b58f-6a67-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 10:12:52.353: INFO: Pod downwardapi-volume-55a7b58f-6a67-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:12:52.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-677" for this suite.
Apr 29 10:12:58.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:12:58.478: INFO: namespace downward-api-677 deletion completed in 6.120856621s

• [SLOW TEST:12.374 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:12:58.479: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-4470
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-4470
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 29 10:12:58.656: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr 29 10:13:28.814: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.2.131.81:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4470 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 29 10:13:28.814: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
Apr 29 10:13:28.931: INFO: Found all expected endpoints: [netserver-0]
Apr 29 10:13:28.934: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.2.130.183:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4470 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 29 10:13:28.934: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
Apr 29 10:13:29.062: INFO: Found all expected endpoints: [netserver-1]
Apr 29 10:13:29.068: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.2.129.41:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4470 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 29 10:13:29.068: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
Apr 29 10:13:29.200: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:13:29.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4470" for this suite.
Apr 29 10:13:51.226: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:13:51.330: INFO: namespace pod-network-test-4470 deletion completed in 22.123742628s

• [SLOW TEST:52.851 seconds]
[sig-network] Networking
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:13:51.331: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-7428
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-q6sk
STEP: Creating a pod to test atomic-volume-subpath
Apr 29 10:13:51.500: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-q6sk" in namespace "subpath-7428" to be "success or failure"
Apr 29 10:13:51.511: INFO: Pod "pod-subpath-test-configmap-q6sk": Phase="Pending", Reason="", readiness=false. Elapsed: 11.367268ms
Apr 29 10:13:53.514: INFO: Pod "pod-subpath-test-configmap-q6sk": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014387329s
Apr 29 10:13:55.519: INFO: Pod "pod-subpath-test-configmap-q6sk": Phase="Running", Reason="", readiness=true. Elapsed: 4.018631682s
Apr 29 10:13:57.522: INFO: Pod "pod-subpath-test-configmap-q6sk": Phase="Running", Reason="", readiness=true. Elapsed: 6.022524318s
Apr 29 10:13:59.526: INFO: Pod "pod-subpath-test-configmap-q6sk": Phase="Running", Reason="", readiness=true. Elapsed: 8.02650684s
Apr 29 10:14:01.531: INFO: Pod "pod-subpath-test-configmap-q6sk": Phase="Running", Reason="", readiness=true. Elapsed: 10.030740149s
Apr 29 10:14:03.535: INFO: Pod "pod-subpath-test-configmap-q6sk": Phase="Running", Reason="", readiness=true. Elapsed: 12.034865042s
Apr 29 10:14:05.539: INFO: Pod "pod-subpath-test-configmap-q6sk": Phase="Running", Reason="", readiness=true. Elapsed: 14.03869862s
Apr 29 10:14:07.543: INFO: Pod "pod-subpath-test-configmap-q6sk": Phase="Running", Reason="", readiness=true. Elapsed: 16.042642483s
Apr 29 10:14:09.548: INFO: Pod "pod-subpath-test-configmap-q6sk": Phase="Running", Reason="", readiness=true. Elapsed: 18.047682838s
Apr 29 10:14:11.552: INFO: Pod "pod-subpath-test-configmap-q6sk": Phase="Running", Reason="", readiness=true. Elapsed: 20.051628573s
Apr 29 10:14:13.555: INFO: Pod "pod-subpath-test-configmap-q6sk": Phase="Running", Reason="", readiness=true. Elapsed: 22.054899589s
Apr 29 10:14:15.564: INFO: Pod "pod-subpath-test-configmap-q6sk": Phase="Running", Reason="", readiness=true. Elapsed: 24.064067826s
Apr 29 10:14:17.568: INFO: Pod "pod-subpath-test-configmap-q6sk": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.067771216s
STEP: Saw pod success
Apr 29 10:14:17.568: INFO: Pod "pod-subpath-test-configmap-q6sk" satisfied condition "success or failure"
Apr 29 10:14:17.571: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-subpath-test-configmap-q6sk container test-container-subpath-configmap-q6sk: <nil>
STEP: delete the pod
Apr 29 10:14:17.601: INFO: Waiting for pod pod-subpath-test-configmap-q6sk to disappear
Apr 29 10:14:17.604: INFO: Pod pod-subpath-test-configmap-q6sk no longer exists
STEP: Deleting pod pod-subpath-test-configmap-q6sk
Apr 29 10:14:17.604: INFO: Deleting pod "pod-subpath-test-configmap-q6sk" in namespace "subpath-7428"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:14:17.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7428" for this suite.
Apr 29 10:14:23.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:14:23.741: INFO: namespace subpath-7428 deletion completed in 6.115444695s

• [SLOW TEST:32.410 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:14:23.741: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-459
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-8fd88154-6a67-11e9-b6b4-b219b18c41e8
STEP: Creating a pod to test consume configMaps
Apr 29 10:14:23.917: INFO: Waiting up to 5m0s for pod "pod-configmaps-8fd93183-6a67-11e9-b6b4-b219b18c41e8" in namespace "configmap-459" to be "success or failure"
Apr 29 10:14:23.933: INFO: Pod "pod-configmaps-8fd93183-6a67-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 15.50109ms
Apr 29 10:14:25.937: INFO: Pod "pod-configmaps-8fd93183-6a67-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019414623s
Apr 29 10:14:27.941: INFO: Pod "pod-configmaps-8fd93183-6a67-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.023417242s
Apr 29 10:14:29.945: INFO: Pod "pod-configmaps-8fd93183-6a67-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.027359347s
STEP: Saw pod success
Apr 29 10:14:29.945: INFO: Pod "pod-configmaps-8fd93183-6a67-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 10:14:29.948: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-configmaps-8fd93183-6a67-11e9-b6b4-b219b18c41e8 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 29 10:14:30.085: INFO: Waiting for pod pod-configmaps-8fd93183-6a67-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 10:14:30.097: INFO: Pod pod-configmaps-8fd93183-6a67-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:14:30.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-459" for this suite.
Apr 29 10:14:36.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:14:36.226: INFO: namespace configmap-459 deletion completed in 6.123680879s

• [SLOW TEST:12.485 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:14:36.226: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-224
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Apr 29 10:14:36.436: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 10:14:36.441: INFO: Number of nodes with available pods: 0
Apr 29 10:14:36.441: INFO: Node 0mfg0-worker-000000 is running more than one daemon pod
Apr 29 10:14:37.446: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 10:14:37.450: INFO: Number of nodes with available pods: 0
Apr 29 10:14:37.450: INFO: Node 0mfg0-worker-000000 is running more than one daemon pod
Apr 29 10:14:38.446: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 10:14:38.450: INFO: Number of nodes with available pods: 0
Apr 29 10:14:38.450: INFO: Node 0mfg0-worker-000000 is running more than one daemon pod
Apr 29 10:14:39.446: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 10:14:39.449: INFO: Number of nodes with available pods: 0
Apr 29 10:14:39.449: INFO: Node 0mfg0-worker-000000 is running more than one daemon pod
Apr 29 10:14:40.446: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 10:14:40.449: INFO: Number of nodes with available pods: 2
Apr 29 10:14:40.449: INFO: Node 0mfg0-worker-000000 is running more than one daemon pod
Apr 29 10:14:41.446: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 10:14:41.450: INFO: Number of nodes with available pods: 3
Apr 29 10:14:41.450: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Apr 29 10:14:41.470: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 10:14:41.473: INFO: Number of nodes with available pods: 2
Apr 29 10:14:41.473: INFO: Node 0mfg0-worker-000001 is running more than one daemon pod
Apr 29 10:14:42.478: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 10:14:42.481: INFO: Number of nodes with available pods: 2
Apr 29 10:14:42.481: INFO: Node 0mfg0-worker-000001 is running more than one daemon pod
Apr 29 10:14:43.479: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 10:14:43.482: INFO: Number of nodes with available pods: 2
Apr 29 10:14:43.482: INFO: Node 0mfg0-worker-000001 is running more than one daemon pod
Apr 29 10:14:44.479: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 10:14:44.482: INFO: Number of nodes with available pods: 2
Apr 29 10:14:44.482: INFO: Node 0mfg0-worker-000001 is running more than one daemon pod
Apr 29 10:14:45.479: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 10:14:45.482: INFO: Number of nodes with available pods: 2
Apr 29 10:14:45.482: INFO: Node 0mfg0-worker-000001 is running more than one daemon pod
Apr 29 10:14:46.478: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 10:14:46.482: INFO: Number of nodes with available pods: 2
Apr 29 10:14:46.482: INFO: Node 0mfg0-worker-000001 is running more than one daemon pod
Apr 29 10:14:47.478: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 10:14:47.482: INFO: Number of nodes with available pods: 2
Apr 29 10:14:47.482: INFO: Node 0mfg0-worker-000001 is running more than one daemon pod
Apr 29 10:14:48.479: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 10:14:48.482: INFO: Number of nodes with available pods: 2
Apr 29 10:14:48.482: INFO: Node 0mfg0-worker-000001 is running more than one daemon pod
Apr 29 10:14:49.479: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 10:14:49.496: INFO: Number of nodes with available pods: 2
Apr 29 10:14:49.496: INFO: Node 0mfg0-worker-000001 is running more than one daemon pod
Apr 29 10:14:50.478: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 10:14:50.481: INFO: Number of nodes with available pods: 2
Apr 29 10:14:50.481: INFO: Node 0mfg0-worker-000001 is running more than one daemon pod
Apr 29 10:14:51.478: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 10:14:51.482: INFO: Number of nodes with available pods: 2
Apr 29 10:14:51.482: INFO: Node 0mfg0-worker-000001 is running more than one daemon pod
Apr 29 10:14:52.478: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 10:14:52.482: INFO: Number of nodes with available pods: 2
Apr 29 10:14:52.482: INFO: Node 0mfg0-worker-000001 is running more than one daemon pod
Apr 29 10:14:53.486: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 10:14:53.489: INFO: Number of nodes with available pods: 2
Apr 29 10:14:53.489: INFO: Node 0mfg0-worker-000001 is running more than one daemon pod
Apr 29 10:14:54.479: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 10:14:54.483: INFO: Number of nodes with available pods: 2
Apr 29 10:14:54.483: INFO: Node 0mfg0-worker-000001 is running more than one daemon pod
Apr 29 10:14:55.478: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 10:14:55.481: INFO: Number of nodes with available pods: 2
Apr 29 10:14:55.481: INFO: Node 0mfg0-worker-000001 is running more than one daemon pod
Apr 29 10:14:56.478: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 10:14:56.482: INFO: Number of nodes with available pods: 2
Apr 29 10:14:56.482: INFO: Node 0mfg0-worker-000001 is running more than one daemon pod
Apr 29 10:14:57.478: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 10:14:57.481: INFO: Number of nodes with available pods: 2
Apr 29 10:14:57.481: INFO: Node 0mfg0-worker-000001 is running more than one daemon pod
Apr 29 10:14:58.481: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 10:14:58.485: INFO: Number of nodes with available pods: 2
Apr 29 10:14:58.485: INFO: Node 0mfg0-worker-000001 is running more than one daemon pod
Apr 29 10:14:59.479: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 10:14:59.482: INFO: Number of nodes with available pods: 2
Apr 29 10:14:59.482: INFO: Node 0mfg0-worker-000001 is running more than one daemon pod
Apr 29 10:15:00.479: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 10:15:00.483: INFO: Number of nodes with available pods: 2
Apr 29 10:15:00.483: INFO: Node 0mfg0-worker-000001 is running more than one daemon pod
Apr 29 10:15:01.479: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 10:15:01.483: INFO: Number of nodes with available pods: 2
Apr 29 10:15:01.483: INFO: Node 0mfg0-worker-000001 is running more than one daemon pod
Apr 29 10:15:02.478: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 10:15:02.482: INFO: Number of nodes with available pods: 3
Apr 29 10:15:02.482: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-224, will wait for the garbage collector to delete the pods
Apr 29 10:15:02.545: INFO: Deleting DaemonSet.extensions daemon-set took: 7.652944ms
Apr 29 10:15:02.645: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.240074ms
Apr 29 10:15:11.349: INFO: Number of nodes with available pods: 0
Apr 29 10:15:11.349: INFO: Number of running nodes: 0, number of available pods: 0
Apr 29 10:15:11.353: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-224/daemonsets","resourceVersion":"22200"},"items":null}

Apr 29 10:15:11.355: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-224/pods","resourceVersion":"22200"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:15:11.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-224" for this suite.
Apr 29 10:15:17.392: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:15:17.499: INFO: namespace daemonsets-224 deletion completed in 6.123860148s

• [SLOW TEST:41.273 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:15:17.500: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-6565
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:15:21.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6565" for this suite.
Apr 29 10:16:13.765: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:16:13.915: INFO: namespace kubelet-test-6565 deletion completed in 52.163561147s

• [SLOW TEST:56.415 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:16:13.916: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-8106
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Apr 29 10:16:18.106: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-d18313a1-6a67-11e9-b6b4-b219b18c41e8,GenerateName:,Namespace:events-8106,SelfLink:/api/v1/namespaces/events-8106/pods/send-events-d18313a1-6a67-11e9-b6b4-b219b18c41e8,UID:d183c557-6a67-11e9-9890-000d3a4710ea,ResourceVersion:22383,Generation:0,CreationTimestamp:2019-04-29 10:16:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 71497453,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.130.189/32,kubernetes.io/psp: cert-exporter-psp,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-7zv5p {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7zv5p,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-7zv5p true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:0mfg0-worker-000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001fe8500} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001fe8520}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 10:16:14 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 10:16:18 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 10:16:18 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 10:16:14 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.5,PodIP:10.2.130.189,StartTime:2019-04-29 10:16:14 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-04-29 10:16:17 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://64127fff89777e60504f7c86e3b74ef1449493e04ef3caa12a20a60a115960c4}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Apr 29 10:16:20.110: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Apr 29 10:16:22.115: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:16:22.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-8106" for this suite.
Apr 29 10:17:00.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:17:00.261: INFO: namespace events-8106 deletion completed in 38.130823084s

• [SLOW TEST:46.345 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:17:00.262: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2968
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Apr 29 10:17:00.420: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:17:17.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2968" for this suite.
Apr 29 10:17:23.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:17:23.799: INFO: namespace pods-2968 deletion completed in 6.140695473s

• [SLOW TEST:23.537 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:17:23.799: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8964
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-8964
Apr 29 10:17:30.004: INFO: Started pod liveness-exec in namespace container-probe-8964
STEP: checking the pod's current state and verifying that restartCount is present
Apr 29 10:17:30.007: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:21:30.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8964" for this suite.
Apr 29 10:21:36.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:21:36.662: INFO: namespace container-probe-8964 deletion completed in 6.115800528s

• [SLOW TEST:252.863 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:21:36.663: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2807
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-91e307e5-6a68-11e9-b6b4-b219b18c41e8
STEP: Creating secret with name s-test-opt-upd-91e30853-6a68-11e9-b6b4-b219b18c41e8
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-91e307e5-6a68-11e9-b6b4-b219b18c41e8
STEP: Updating secret s-test-opt-upd-91e30853-6a68-11e9-b6b4-b219b18c41e8
STEP: Creating secret with name s-test-opt-create-91e30884-6a68-11e9-b6b4-b219b18c41e8
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:23:11.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2807" for this suite.
Apr 29 10:23:33.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:23:33.530: INFO: namespace secrets-2807 deletion completed in 22.117837686s

• [SLOW TEST:116.867 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:23:33.531: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3109
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Apr 29 10:23:33.695: INFO: Waiting up to 5m0s for pod "pod-d78ad297-6a68-11e9-b6b4-b219b18c41e8" in namespace "emptydir-3109" to be "success or failure"
Apr 29 10:23:33.706: INFO: Pod "pod-d78ad297-6a68-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 10.104148ms
Apr 29 10:23:35.709: INFO: Pod "pod-d78ad297-6a68-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013609928s
Apr 29 10:23:37.714: INFO: Pod "pod-d78ad297-6a68-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01840721s
Apr 29 10:23:39.718: INFO: Pod "pod-d78ad297-6a68-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.022032682s
STEP: Saw pod success
Apr 29 10:23:39.718: INFO: Pod "pod-d78ad297-6a68-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 10:23:39.720: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-d78ad297-6a68-11e9-b6b4-b219b18c41e8 container test-container: <nil>
STEP: delete the pod
Apr 29 10:23:39.745: INFO: Waiting for pod pod-d78ad297-6a68-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 10:23:39.751: INFO: Pod pod-d78ad297-6a68-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:23:39.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3109" for this suite.
Apr 29 10:23:45.787: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:23:45.894: INFO: namespace emptydir-3109 deletion completed in 6.125378721s

• [SLOW TEST:12.363 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:23:45.895: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-5508
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 29 10:23:46.146: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Apr 29 10:23:46.177: INFO: Number of nodes with available pods: 0
Apr 29 10:23:46.177: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Apr 29 10:23:46.271: INFO: Number of nodes with available pods: 0
Apr 29 10:23:46.271: INFO: Node 0mfg0-worker-000000 is running more than one daemon pod
Apr 29 10:23:47.275: INFO: Number of nodes with available pods: 0
Apr 29 10:23:47.275: INFO: Node 0mfg0-worker-000000 is running more than one daemon pod
Apr 29 10:23:48.275: INFO: Number of nodes with available pods: 0
Apr 29 10:23:48.275: INFO: Node 0mfg0-worker-000000 is running more than one daemon pod
Apr 29 10:23:49.285: INFO: Number of nodes with available pods: 0
Apr 29 10:23:49.285: INFO: Node 0mfg0-worker-000000 is running more than one daemon pod
Apr 29 10:23:50.276: INFO: Number of nodes with available pods: 0
Apr 29 10:23:50.276: INFO: Node 0mfg0-worker-000000 is running more than one daemon pod
Apr 29 10:23:51.275: INFO: Number of nodes with available pods: 1
Apr 29 10:23:51.275: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Apr 29 10:23:51.332: INFO: Number of nodes with available pods: 0
Apr 29 10:23:51.332: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Apr 29 10:23:51.352: INFO: Number of nodes with available pods: 0
Apr 29 10:23:51.352: INFO: Node 0mfg0-worker-000000 is running more than one daemon pod
Apr 29 10:23:52.356: INFO: Number of nodes with available pods: 0
Apr 29 10:23:52.356: INFO: Node 0mfg0-worker-000000 is running more than one daemon pod
Apr 29 10:23:53.356: INFO: Number of nodes with available pods: 0
Apr 29 10:23:53.356: INFO: Node 0mfg0-worker-000000 is running more than one daemon pod
Apr 29 10:23:54.362: INFO: Number of nodes with available pods: 0
Apr 29 10:23:54.362: INFO: Node 0mfg0-worker-000000 is running more than one daemon pod
Apr 29 10:23:55.362: INFO: Number of nodes with available pods: 0
Apr 29 10:23:55.362: INFO: Node 0mfg0-worker-000000 is running more than one daemon pod
Apr 29 10:23:56.355: INFO: Number of nodes with available pods: 0
Apr 29 10:23:56.355: INFO: Node 0mfg0-worker-000000 is running more than one daemon pod
Apr 29 10:23:57.356: INFO: Number of nodes with available pods: 0
Apr 29 10:23:57.356: INFO: Node 0mfg0-worker-000000 is running more than one daemon pod
Apr 29 10:23:58.362: INFO: Number of nodes with available pods: 0
Apr 29 10:23:58.362: INFO: Node 0mfg0-worker-000000 is running more than one daemon pod
Apr 29 10:23:59.356: INFO: Number of nodes with available pods: 0
Apr 29 10:23:59.356: INFO: Node 0mfg0-worker-000000 is running more than one daemon pod
Apr 29 10:24:00.356: INFO: Number of nodes with available pods: 0
Apr 29 10:24:00.356: INFO: Node 0mfg0-worker-000000 is running more than one daemon pod
Apr 29 10:24:01.356: INFO: Number of nodes with available pods: 1
Apr 29 10:24:01.356: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5508, will wait for the garbage collector to delete the pods
Apr 29 10:24:01.419: INFO: Deleting DaemonSet.extensions daemon-set took: 6.273529ms
Apr 29 10:24:01.520: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.407567ms
Apr 29 10:24:06.425: INFO: Number of nodes with available pods: 0
Apr 29 10:24:06.425: INFO: Number of running nodes: 0, number of available pods: 0
Apr 29 10:24:06.428: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5508/daemonsets","resourceVersion":"23378"},"items":null}

Apr 29 10:24:06.431: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5508/pods","resourceVersion":"23378"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:24:06.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5508" for this suite.
Apr 29 10:24:12.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:24:12.571: INFO: namespace daemonsets-5508 deletion completed in 6.111960172s

• [SLOW TEST:26.676 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:24:12.572: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2538
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Apr 29 10:24:19.293: INFO: Successfully updated pod "annotationupdateeecfcae2-6a68-11e9-b6b4-b219b18c41e8"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:24:21.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2538" for this suite.
Apr 29 10:24:43.326: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:24:43.444: INFO: namespace downward-api-2538 deletion completed in 22.129694082s

• [SLOW TEST:30.871 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:24:43.445: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-5540
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-5540
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Apr 29 10:24:43.664: INFO: Found 0 stateful pods, waiting for 3
Apr 29 10:24:53.668: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 29 10:24:53.668: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 29 10:24:53.668: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Apr 29 10:25:03.668: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 29 10:25:03.668: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 29 10:25:03.668: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Apr 29 10:25:03.695: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Apr 29 10:25:13.736: INFO: Updating stateful set ss2
Apr 29 10:25:13.768: INFO: Waiting for Pod statefulset-5540/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Apr 29 10:25:23.880: INFO: Found 2 stateful pods, waiting for 3
Apr 29 10:25:33.886: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 29 10:25:33.886: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 29 10:25:33.886: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=false
Apr 29 10:25:43.884: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 29 10:25:43.884: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 29 10:25:43.884: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Apr 29 10:25:43.910: INFO: Updating stateful set ss2
Apr 29 10:25:43.945: INFO: Waiting for Pod statefulset-5540/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 29 10:25:53.972: INFO: Updating stateful set ss2
Apr 29 10:25:53.984: INFO: Waiting for StatefulSet statefulset-5540/ss2 to complete update
Apr 29 10:25:53.984: INFO: Waiting for Pod statefulset-5540/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 29 10:26:03.991: INFO: Waiting for StatefulSet statefulset-5540/ss2 to complete update
Apr 29 10:26:03.991: INFO: Waiting for Pod statefulset-5540/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr 29 10:26:13.995: INFO: Deleting all statefulset in ns statefulset-5540
Apr 29 10:26:13.998: INFO: Scaling statefulset ss2 to 0
Apr 29 10:26:44.020: INFO: Waiting for statefulset status.replicas updated to 0
Apr 29 10:26:44.023: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:26:44.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5540" for this suite.
Apr 29 10:26:50.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:26:50.443: INFO: namespace statefulset-5540 deletion completed in 6.371303017s

• [SLOW TEST:126.998 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:26:50.445: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-9178
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-9178
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 29 10:26:50.615: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr 29 10:27:16.766: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.130.199:8080/dial?request=hostName&protocol=udp&host=10.2.129.46&port=8081&tries=1'] Namespace:pod-network-test-9178 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 29 10:27:16.766: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
Apr 29 10:27:16.876: INFO: Waiting for endpoints: map[]
Apr 29 10:27:16.879: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.130.199:8080/dial?request=hostName&protocol=udp&host=10.2.131.88&port=8081&tries=1'] Namespace:pod-network-test-9178 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 29 10:27:16.879: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
Apr 29 10:27:16.999: INFO: Waiting for endpoints: map[]
Apr 29 10:27:17.002: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.130.199:8080/dial?request=hostName&protocol=udp&host=10.2.130.198&port=8081&tries=1'] Namespace:pod-network-test-9178 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 29 10:27:17.002: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
Apr 29 10:27:17.121: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:27:17.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9178" for this suite.
Apr 29 10:27:39.140: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:27:39.286: INFO: namespace pod-network-test-9178 deletion completed in 22.15961512s

• [SLOW TEST:48.841 seconds]
[sig-network] Networking
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:27:39.287: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9414
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: executing a command with run --rm and attach with stdin
Apr 29 10:27:39.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 --namespace=kubectl-9414 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Apr 29 10:27:45.306: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Apr 29 10:27:45.306: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:27:47.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9414" for this suite.
Apr 29 10:27:53.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:27:53.450: INFO: namespace kubectl-9414 deletion completed in 6.133699552s

• [SLOW TEST:14.163 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:27:53.450: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-8695
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Apr 29 10:28:07.672: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8695 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 29 10:28:07.672: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
Apr 29 10:28:07.802: INFO: Exec stderr: ""
Apr 29 10:28:07.802: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8695 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 29 10:28:07.802: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
Apr 29 10:28:07.897: INFO: Exec stderr: ""
Apr 29 10:28:07.898: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8695 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 29 10:28:07.898: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
Apr 29 10:28:08.003: INFO: Exec stderr: ""
Apr 29 10:28:08.003: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8695 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 29 10:28:08.004: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
Apr 29 10:28:08.101: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Apr 29 10:28:08.101: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8695 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 29 10:28:08.101: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
Apr 29 10:28:08.197: INFO: Exec stderr: ""
Apr 29 10:28:08.197: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8695 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 29 10:28:08.197: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
Apr 29 10:28:08.290: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Apr 29 10:28:08.290: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8695 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 29 10:28:08.290: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
Apr 29 10:28:08.456: INFO: Exec stderr: ""
Apr 29 10:28:08.456: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8695 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 29 10:28:08.456: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
Apr 29 10:28:08.593: INFO: Exec stderr: ""
Apr 29 10:28:08.593: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8695 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 29 10:28:08.594: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
Apr 29 10:28:08.699: INFO: Exec stderr: ""
Apr 29 10:28:08.700: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8695 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 29 10:28:08.700: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
Apr 29 10:28:08.798: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:28:08.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-8695" for this suite.
Apr 29 10:28:50.817: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:28:50.931: INFO: namespace e2e-kubelet-etc-hosts-8695 deletion completed in 42.125799618s

• [SLOW TEST:57.481 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:28:50.931: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-9583
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
Apr 29 10:28:51.629: INFO: created pod pod-service-account-defaultsa
Apr 29 10:28:51.630: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Apr 29 10:28:51.649: INFO: created pod pod-service-account-mountsa
Apr 29 10:28:51.649: INFO: pod pod-service-account-mountsa service account token volume mount: true
Apr 29 10:28:51.670: INFO: created pod pod-service-account-nomountsa
Apr 29 10:28:51.670: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Apr 29 10:28:51.721: INFO: created pod pod-service-account-defaultsa-mountspec
Apr 29 10:28:51.721: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Apr 29 10:28:51.736: INFO: created pod pod-service-account-mountsa-mountspec
Apr 29 10:28:51.741: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Apr 29 10:28:51.754: INFO: created pod pod-service-account-nomountsa-mountspec
Apr 29 10:28:51.754: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Apr 29 10:28:51.770: INFO: created pod pod-service-account-defaultsa-nomountspec
Apr 29 10:28:51.771: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Apr 29 10:28:51.791: INFO: created pod pod-service-account-mountsa-nomountspec
Apr 29 10:28:51.793: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Apr 29 10:28:51.844: INFO: created pod pod-service-account-nomountsa-nomountspec
Apr 29 10:28:51.844: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:28:51.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-9583" for this suite.
Apr 29 10:29:23.881: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:29:24.007: INFO: namespace svcaccounts-9583 deletion completed in 32.151680187s

• [SLOW TEST:33.076 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:29:24.008: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7777
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-a876af3c-6a69-11e9-b6b4-b219b18c41e8
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:29:32.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7777" for this suite.
Apr 29 10:29:54.265: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:29:54.376: INFO: namespace configmap-7777 deletion completed in 22.129861309s

• [SLOW TEST:30.368 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:29:54.377: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3351
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Apr 29 10:29:54.555: INFO: Waiting up to 5m0s for pod "pod-ba8da37e-6a69-11e9-b6b4-b219b18c41e8" in namespace "emptydir-3351" to be "success or failure"
Apr 29 10:29:54.571: INFO: Pod "pod-ba8da37e-6a69-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 15.163367ms
Apr 29 10:29:56.589: INFO: Pod "pod-ba8da37e-6a69-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033440472s
Apr 29 10:29:58.593: INFO: Pod "pod-ba8da37e-6a69-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.037581514s
Apr 29 10:30:00.597: INFO: Pod "pod-ba8da37e-6a69-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.041835654s
STEP: Saw pod success
Apr 29 10:30:00.597: INFO: Pod "pod-ba8da37e-6a69-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 10:30:00.600: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-ba8da37e-6a69-11e9-b6b4-b219b18c41e8 container test-container: <nil>
STEP: delete the pod
Apr 29 10:30:00.622: INFO: Waiting for pod pod-ba8da37e-6a69-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 10:30:00.628: INFO: Pod pod-ba8da37e-6a69-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:30:00.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3351" for this suite.
Apr 29 10:30:06.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:30:06.758: INFO: namespace emptydir-3351 deletion completed in 6.125863899s

• [SLOW TEST:12.382 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:30:06.759: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-419
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test use defaults
Apr 29 10:30:06.939: INFO: Waiting up to 5m0s for pod "client-containers-c1eecdf5-6a69-11e9-b6b4-b219b18c41e8" in namespace "containers-419" to be "success or failure"
Apr 29 10:30:06.943: INFO: Pod "client-containers-c1eecdf5-6a69-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.672116ms
Apr 29 10:30:08.947: INFO: Pod "client-containers-c1eecdf5-6a69-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008313248s
Apr 29 10:30:10.951: INFO: Pod "client-containers-c1eecdf5-6a69-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011813774s
Apr 29 10:30:12.955: INFO: Pod "client-containers-c1eecdf5-6a69-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.015879399s
STEP: Saw pod success
Apr 29 10:30:12.955: INFO: Pod "client-containers-c1eecdf5-6a69-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 10:30:12.961: INFO: Trying to get logs from node 0mfg0-worker-000001 pod client-containers-c1eecdf5-6a69-11e9-b6b4-b219b18c41e8 container test-container: <nil>
STEP: delete the pod
Apr 29 10:30:12.992: INFO: Waiting for pod client-containers-c1eecdf5-6a69-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 10:30:12.995: INFO: Pod client-containers-c1eecdf5-6a69-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:30:12.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-419" for this suite.
Apr 29 10:30:19.025: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:30:19.162: INFO: namespace containers-419 deletion completed in 6.163570522s

• [SLOW TEST:12.404 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:30:19.163: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-3658
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 29 10:30:19.351: INFO: Creating ReplicaSet my-hostname-basic-c956a1bc-6a69-11e9-b6b4-b219b18c41e8
Apr 29 10:30:19.366: INFO: Pod name my-hostname-basic-c956a1bc-6a69-11e9-b6b4-b219b18c41e8: Found 0 pods out of 1
Apr 29 10:30:24.370: INFO: Pod name my-hostname-basic-c956a1bc-6a69-11e9-b6b4-b219b18c41e8: Found 1 pods out of 1
Apr 29 10:30:24.370: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-c956a1bc-6a69-11e9-b6b4-b219b18c41e8" is running
Apr 29 10:30:24.373: INFO: Pod "my-hostname-basic-c956a1bc-6a69-11e9-b6b4-b219b18c41e8-dh27l" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-29 10:30:19 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-29 10:30:23 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-29 10:30:23 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-29 10:30:19 +0000 UTC Reason: Message:}])
Apr 29 10:30:24.373: INFO: Trying to dial the pod
Apr 29 10:30:29.385: INFO: Controller my-hostname-basic-c956a1bc-6a69-11e9-b6b4-b219b18c41e8: Got expected result from replica 1 [my-hostname-basic-c956a1bc-6a69-11e9-b6b4-b219b18c41e8-dh27l]: "my-hostname-basic-c956a1bc-6a69-11e9-b6b4-b219b18c41e8-dh27l", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:30:29.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-3658" for this suite.
Apr 29 10:30:35.401: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:30:35.508: INFO: namespace replicaset-3658 deletion completed in 6.119228176s

• [SLOW TEST:16.346 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:30:35.509: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-4039
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 29 10:30:35.673: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Apr 29 10:30:40.677: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr 29 10:30:42.684: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr 29 10:30:42.713: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-4039,SelfLink:/apis/apps/v1/namespaces/deployment-4039/deployments/test-cleanup-deployment,UID:d73fa403-6a69-11e9-9890-000d3a4710ea,ResourceVersion:24822,Generation:1,CreationTimestamp:2019-04-29 10:30:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Apr 29 10:30:42.737: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Apr 29 10:30:42.753: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Apr 29 10:30:42.767: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:deployment-4039,SelfLink:/apis/apps/v1/namespaces/deployment-4039/replicasets/test-cleanup-controller,UID:d30f2006-6a69-11e9-9890-000d3a4710ea,ResourceVersion:24823,Generation:1,CreationTimestamp:2019-04-29 10:30:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment d73fa403-6a69-11e9-9890-000d3a4710ea 0xc000f3bab7 0xc000f3bab8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Apr 29 10:30:42.779: INFO: Pod "test-cleanup-controller-4qzw9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-4qzw9,GenerateName:test-cleanup-controller-,Namespace:deployment-4039,SelfLink:/api/v1/namespaces/deployment-4039/pods/test-cleanup-controller-4qzw9,UID:d310f1e3-6a69-11e9-9890-000d3a4710ea,ResourceVersion:24819,Generation:0,CreationTimestamp:2019-04-29 10:30:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.130.209/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller d30f2006-6a69-11e9-9890-000d3a4710ea 0xc002711637 0xc002711638}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-rjkfd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rjkfd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rjkfd true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:0mfg0-worker-000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027116a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027116c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 10:30:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 10:30:41 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 10:30:41 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-29 10:30:35 +0000 UTC  }],Message:,Reason:,HostIP:10.2.1.5,PodIP:10.2.130.209,StartTime:2019-04-29 10:30:35 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-29 10:30:40 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://b7a1a4922c7bd3f89ffc71ed8055c1ff9a095133af1db07e95d2289527bbd396}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:30:42.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4039" for this suite.
Apr 29 10:30:48.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:30:48.986: INFO: namespace deployment-4039 deletion completed in 6.184212915s

• [SLOW TEST:13.478 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:30:48.989: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3232
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-db187a5d-6a69-11e9-b6b4-b219b18c41e8
STEP: Creating a pod to test consume secrets
Apr 29 10:30:49.162: INFO: Waiting up to 5m0s for pod "pod-secrets-db193057-6a69-11e9-b6b4-b219b18c41e8" in namespace "secrets-3232" to be "success or failure"
Apr 29 10:30:49.167: INFO: Pod "pod-secrets-db193057-6a69-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.705221ms
Apr 29 10:30:51.171: INFO: Pod "pod-secrets-db193057-6a69-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008562705s
Apr 29 10:30:53.182: INFO: Pod "pod-secrets-db193057-6a69-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019631619s
Apr 29 10:30:55.185: INFO: Pod "pod-secrets-db193057-6a69-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.023369698s
STEP: Saw pod success
Apr 29 10:30:55.186: INFO: Pod "pod-secrets-db193057-6a69-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 10:30:55.189: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-secrets-db193057-6a69-11e9-b6b4-b219b18c41e8 container secret-volume-test: <nil>
STEP: delete the pod
Apr 29 10:30:55.222: INFO: Waiting for pod pod-secrets-db193057-6a69-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 10:30:55.230: INFO: Pod pod-secrets-db193057-6a69-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:30:55.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3232" for this suite.
Apr 29 10:31:01.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:31:01.353: INFO: namespace secrets-3232 deletion completed in 6.117491287s

• [SLOW TEST:12.364 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:31:01.353: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4167
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1318
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 29 10:31:01.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-4167'
Apr 29 10:31:01.644: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr 29 10:31:01.644: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1324
Apr 29 10:31:01.659: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 delete deployment e2e-test-nginx-deployment --namespace=kubectl-4167'
Apr 29 10:31:01.778: INFO: stderr: ""
Apr 29 10:31:01.778: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:31:01.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4167" for this suite.
Apr 29 10:31:23.817: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:31:23.916: INFO: namespace kubectl-4167 deletion completed in 22.115225195s

• [SLOW TEST:22.563 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:31:23.917: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-8081
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-8637
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-8886
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:31:52.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8081" for this suite.
Apr 29 10:31:58.484: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:31:58.593: INFO: namespace namespaces-8081 deletion completed in 6.129512973s
STEP: Destroying namespace "nsdeletetest-8637" for this suite.
Apr 29 10:31:58.596: INFO: Namespace nsdeletetest-8637 was already deleted
STEP: Destroying namespace "nsdeletetest-8886" for this suite.
Apr 29 10:32:04.671: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:32:04.778: INFO: namespace nsdeletetest-8886 deletion completed in 6.181941682s

• [SLOW TEST:40.860 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:32:04.778: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3964
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with configMap that has name projected-configmap-test-upd-08472a02-6a6a-11e9-b6b4-b219b18c41e8
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-08472a02-6a6a-11e9-b6b4-b219b18c41e8
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:33:29.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3964" for this suite.
Apr 29 10:33:51.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:33:51.580: INFO: namespace projected-3964 deletion completed in 22.12024174s

• [SLOW TEST:106.802 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:33:51.580: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6467
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-47ed8edc-6a6a-11e9-b6b4-b219b18c41e8
STEP: Creating configMap with name cm-test-opt-upd-47ed8f28-6a6a-11e9-b6b4-b219b18c41e8
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-47ed8edc-6a6a-11e9-b6b4-b219b18c41e8
STEP: Updating configmap cm-test-opt-upd-47ed8f28-6a6a-11e9-b6b4-b219b18c41e8
STEP: Creating configMap with name cm-test-opt-create-47ed8f8b-6a6a-11e9-b6b4-b219b18c41e8
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:34:03.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6467" for this suite.
Apr 29 10:34:25.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:34:26.022: INFO: namespace projected-6467 deletion completed in 22.127703604s

• [SLOW TEST:34.442 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:34:26.024: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-3747
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-4v8ss in namespace proxy-3747
I0429 10:34:26.255894      15 runners.go:184] Created replication controller with name: proxy-service-4v8ss, namespace: proxy-3747, replica count: 1
I0429 10:34:27.308859      15 runners.go:184] proxy-service-4v8ss Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0429 10:34:28.309101      15 runners.go:184] proxy-service-4v8ss Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0429 10:34:29.309350      15 runners.go:184] proxy-service-4v8ss Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0429 10:34:30.309590      15 runners.go:184] proxy-service-4v8ss Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0429 10:34:31.309863      15 runners.go:184] proxy-service-4v8ss Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0429 10:34:32.310079      15 runners.go:184] proxy-service-4v8ss Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0429 10:34:33.310230      15 runners.go:184] proxy-service-4v8ss Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0429 10:34:34.310434      15 runners.go:184] proxy-service-4v8ss Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 29 10:34:34.313: INFO: setup took 8.124167272s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Apr 29 10:34:34.329: INFO: (0) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:162/proxy/: bar (200; 15.733566ms)
Apr 29 10:34:34.331: INFO: (0) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:160/proxy/: foo (200; 17.302573ms)
Apr 29 10:34:34.331: INFO: (0) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:1080/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:1080/proxy/rewriteme">test<... (200; 16.49437ms)
Apr 29 10:34:34.332: INFO: (0) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:162/proxy/: bar (200; 17.856376ms)
Apr 29 10:34:34.340: INFO: (0) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:160/proxy/: foo (200; 24.968406ms)
Apr 29 10:34:34.340: INFO: (0) /api/v1/namespaces/proxy-3747/services/http:proxy-service-4v8ss:portname1/proxy/: foo (200; 24.544904ms)
Apr 29 10:34:34.340: INFO: (0) /api/v1/namespaces/proxy-3747/services/proxy-service-4v8ss:portname1/proxy/: foo (200; 26.202211ms)
Apr 29 10:34:34.340: INFO: (0) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4/proxy/rewriteme">test</a> (200; 24.943106ms)
Apr 29 10:34:34.340: INFO: (0) /api/v1/namespaces/proxy-3747/services/http:proxy-service-4v8ss:portname2/proxy/: bar (200; 26.090711ms)
Apr 29 10:34:34.340: INFO: (0) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:1080/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:1080/proxy/rewriteme">... (200; 25.257307ms)
Apr 29 10:34:34.341: INFO: (0) /api/v1/namespaces/proxy-3747/services/proxy-service-4v8ss:portname2/proxy/: bar (200; 26.429812ms)
Apr 29 10:34:34.346: INFO: (0) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:443/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:443/proxy/tlsrewritem... (200; 31.374733ms)
Apr 29 10:34:34.350: INFO: (0) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:460/proxy/: tls baz (200; 35.123949ms)
Apr 29 10:34:34.351: INFO: (0) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:462/proxy/: tls qux (200; 36.202154ms)
Apr 29 10:34:34.353: INFO: (0) /api/v1/namespaces/proxy-3747/services/https:proxy-service-4v8ss:tlsportname1/proxy/: tls baz (200; 38.675864ms)
Apr 29 10:34:34.355: INFO: (0) /api/v1/namespaces/proxy-3747/services/https:proxy-service-4v8ss:tlsportname2/proxy/: tls qux (200; 40.285771ms)
Apr 29 10:34:34.377: INFO: (1) /api/v1/namespaces/proxy-3747/services/http:proxy-service-4v8ss:portname1/proxy/: foo (200; 21.772792ms)
Apr 29 10:34:34.378: INFO: (1) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:162/proxy/: bar (200; 21.887392ms)
Apr 29 10:34:34.378: INFO: (1) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:160/proxy/: foo (200; 22.385495ms)
Apr 29 10:34:34.378: INFO: (1) /api/v1/namespaces/proxy-3747/services/proxy-service-4v8ss:portname1/proxy/: foo (200; 21.874393ms)
Apr 29 10:34:34.378: INFO: (1) /api/v1/namespaces/proxy-3747/services/proxy-service-4v8ss:portname2/proxy/: bar (200; 22.305195ms)
Apr 29 10:34:34.378: INFO: (1) /api/v1/namespaces/proxy-3747/services/http:proxy-service-4v8ss:portname2/proxy/: bar (200; 22.289395ms)
Apr 29 10:34:34.378: INFO: (1) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:1080/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:1080/proxy/rewriteme">... (200; 21.134189ms)
Apr 29 10:34:34.378: INFO: (1) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4/proxy/rewriteme">test</a> (200; 21.32729ms)
Apr 29 10:34:34.378: INFO: (1) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:162/proxy/: bar (200; 21.30519ms)
Apr 29 10:34:34.378: INFO: (1) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:443/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:443/proxy/tlsrewritem... (200; 21.734092ms)
Apr 29 10:34:34.378: INFO: (1) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:462/proxy/: tls qux (200; 21.473391ms)
Apr 29 10:34:34.378: INFO: (1) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:460/proxy/: tls baz (200; 22.441995ms)
Apr 29 10:34:34.378: INFO: (1) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:1080/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:1080/proxy/rewriteme">test<... (200; 21.731892ms)
Apr 29 10:34:34.378: INFO: (1) /api/v1/namespaces/proxy-3747/services/https:proxy-service-4v8ss:tlsportname2/proxy/: tls qux (200; 22.161994ms)
Apr 29 10:34:34.378: INFO: (1) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:160/proxy/: foo (200; 22.249795ms)
Apr 29 10:34:34.378: INFO: (1) /api/v1/namespaces/proxy-3747/services/https:proxy-service-4v8ss:tlsportname1/proxy/: tls baz (200; 22.122294ms)
Apr 29 10:34:34.399: INFO: (2) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:443/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:443/proxy/tlsrewritem... (200; 18.84178ms)
Apr 29 10:34:34.400: INFO: (2) /api/v1/namespaces/proxy-3747/services/proxy-service-4v8ss:portname1/proxy/: foo (200; 20.832289ms)
Apr 29 10:34:34.400: INFO: (2) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:162/proxy/: bar (200; 20.400587ms)
Apr 29 10:34:34.400: INFO: (2) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:160/proxy/: foo (200; 20.526387ms)
Apr 29 10:34:34.400: INFO: (2) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:160/proxy/: foo (200; 20.216885ms)
Apr 29 10:34:34.400: INFO: (2) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4/proxy/rewriteme">test</a> (200; 21.407191ms)
Apr 29 10:34:34.400: INFO: (2) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:1080/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:1080/proxy/rewriteme">test<... (200; 20.077985ms)
Apr 29 10:34:34.401: INFO: (2) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:460/proxy/: tls baz (200; 20.893588ms)
Apr 29 10:34:34.401: INFO: (2) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:1080/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:1080/proxy/rewriteme">... (200; 20.591587ms)
Apr 29 10:34:34.401: INFO: (2) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:162/proxy/: bar (200; 21.976093ms)
Apr 29 10:34:34.402: INFO: (2) /api/v1/namespaces/proxy-3747/services/https:proxy-service-4v8ss:tlsportname2/proxy/: tls qux (200; 21.998994ms)
Apr 29 10:34:34.403: INFO: (2) /api/v1/namespaces/proxy-3747/services/http:proxy-service-4v8ss:portname1/proxy/: foo (200; 23.759201ms)
Apr 29 10:34:34.403: INFO: (2) /api/v1/namespaces/proxy-3747/services/proxy-service-4v8ss:portname2/proxy/: bar (200; 23.410399ms)
Apr 29 10:34:34.403: INFO: (2) /api/v1/namespaces/proxy-3747/services/https:proxy-service-4v8ss:tlsportname1/proxy/: tls baz (200; 23.5294ms)
Apr 29 10:34:34.404: INFO: (2) /api/v1/namespaces/proxy-3747/services/http:proxy-service-4v8ss:portname2/proxy/: bar (200; 24.316603ms)
Apr 29 10:34:34.405: INFO: (2) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:462/proxy/: tls qux (200; 25.325107ms)
Apr 29 10:34:34.416: INFO: (3) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4/proxy/rewriteme">test</a> (200; 10.897247ms)
Apr 29 10:34:34.416: INFO: (3) /api/v1/namespaces/proxy-3747/services/http:proxy-service-4v8ss:portname1/proxy/: foo (200; 11.021447ms)
Apr 29 10:34:34.416: INFO: (3) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:1080/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:1080/proxy/rewriteme">... (200; 11.320548ms)
Apr 29 10:34:34.420: INFO: (3) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:160/proxy/: foo (200; 14.456061ms)
Apr 29 10:34:34.427: INFO: (3) /api/v1/namespaces/proxy-3747/services/http:proxy-service-4v8ss:portname2/proxy/: bar (200; 21.21579ms)
Apr 29 10:34:34.428: INFO: (3) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:162/proxy/: bar (200; 22.394795ms)
Apr 29 10:34:34.428: INFO: (3) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:462/proxy/: tls qux (200; 22.239594ms)
Apr 29 10:34:34.428: INFO: (3) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:160/proxy/: foo (200; 21.888993ms)
Apr 29 10:34:34.428: INFO: (3) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:1080/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:1080/proxy/rewriteme">test<... (200; 21.857593ms)
Apr 29 10:34:34.428: INFO: (3) /api/v1/namespaces/proxy-3747/services/proxy-service-4v8ss:portname2/proxy/: bar (200; 22.787596ms)
Apr 29 10:34:34.428: INFO: (3) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:460/proxy/: tls baz (200; 21.499691ms)
Apr 29 10:34:34.429: INFO: (3) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:443/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:443/proxy/tlsrewritem... (200; 22.314894ms)
Apr 29 10:34:34.429: INFO: (3) /api/v1/namespaces/proxy-3747/services/proxy-service-4v8ss:portname1/proxy/: foo (200; 23.197899ms)
Apr 29 10:34:34.430: INFO: (3) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:162/proxy/: bar (200; 24.694205ms)
Apr 29 10:34:34.430: INFO: (3) /api/v1/namespaces/proxy-3747/services/https:proxy-service-4v8ss:tlsportname2/proxy/: tls qux (200; 24.214803ms)
Apr 29 10:34:34.431: INFO: (3) /api/v1/namespaces/proxy-3747/services/https:proxy-service-4v8ss:tlsportname1/proxy/: tls baz (200; 24.952806ms)
Apr 29 10:34:34.448: INFO: (4) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4/proxy/rewriteme">test</a> (200; 16.376569ms)
Apr 29 10:34:34.449: INFO: (4) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:160/proxy/: foo (200; 17.730875ms)
Apr 29 10:34:34.449: INFO: (4) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:160/proxy/: foo (200; 17.506874ms)
Apr 29 10:34:34.450: INFO: (4) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:443/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:443/proxy/tlsrewritem... (200; 18.218478ms)
Apr 29 10:34:34.450: INFO: (4) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:460/proxy/: tls baz (200; 19.126381ms)
Apr 29 10:34:34.451: INFO: (4) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:1080/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:1080/proxy/rewriteme">... (200; 18.86628ms)
Apr 29 10:34:34.451: INFO: (4) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:1080/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:1080/proxy/rewriteme">test<... (200; 19.195381ms)
Apr 29 10:34:34.451: INFO: (4) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:162/proxy/: bar (200; 18.93638ms)
Apr 29 10:34:34.452: INFO: (4) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:462/proxy/: tls qux (200; 19.693583ms)
Apr 29 10:34:34.452: INFO: (4) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:162/proxy/: bar (200; 20.056585ms)
Apr 29 10:34:34.456: INFO: (4) /api/v1/namespaces/proxy-3747/services/proxy-service-4v8ss:portname1/proxy/: foo (200; 23.184899ms)
Apr 29 10:34:34.456: INFO: (4) /api/v1/namespaces/proxy-3747/services/https:proxy-service-4v8ss:tlsportname2/proxy/: tls qux (200; 24.370203ms)
Apr 29 10:34:34.456: INFO: (4) /api/v1/namespaces/proxy-3747/services/http:proxy-service-4v8ss:portname2/proxy/: bar (200; 23.091198ms)
Apr 29 10:34:34.456: INFO: (4) /api/v1/namespaces/proxy-3747/services/https:proxy-service-4v8ss:tlsportname1/proxy/: tls baz (200; 24.548304ms)
Apr 29 10:34:34.456: INFO: (4) /api/v1/namespaces/proxy-3747/services/http:proxy-service-4v8ss:portname1/proxy/: foo (200; 24.017302ms)
Apr 29 10:34:34.456: INFO: (4) /api/v1/namespaces/proxy-3747/services/proxy-service-4v8ss:portname2/proxy/: bar (200; 23.729501ms)
Apr 29 10:34:34.476: INFO: (5) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:1080/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:1080/proxy/rewriteme">test<... (200; 19.448883ms)
Apr 29 10:34:34.477: INFO: (5) /api/v1/namespaces/proxy-3747/services/proxy-service-4v8ss:portname2/proxy/: bar (200; 19.484583ms)
Apr 29 10:34:34.477: INFO: (5) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:160/proxy/: foo (200; 19.391382ms)
Apr 29 10:34:34.477: INFO: (5) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:462/proxy/: tls qux (200; 20.279586ms)
Apr 29 10:34:34.477: INFO: (5) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:162/proxy/: bar (200; 20.447486ms)
Apr 29 10:34:34.477: INFO: (5) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:162/proxy/: bar (200; 19.818384ms)
Apr 29 10:34:34.477: INFO: (5) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:160/proxy/: foo (200; 19.962985ms)
Apr 29 10:34:34.477: INFO: (5) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:1080/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:1080/proxy/rewriteme">... (200; 19.124281ms)
Apr 29 10:34:34.477: INFO: (5) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:460/proxy/: tls baz (200; 19.450083ms)
Apr 29 10:34:34.477: INFO: (5) /api/v1/namespaces/proxy-3747/services/proxy-service-4v8ss:portname1/proxy/: foo (200; 19.879084ms)
Apr 29 10:34:34.477: INFO: (5) /api/v1/namespaces/proxy-3747/services/https:proxy-service-4v8ss:tlsportname2/proxy/: tls qux (200; 19.820484ms)
Apr 29 10:34:34.477: INFO: (5) /api/v1/namespaces/proxy-3747/services/https:proxy-service-4v8ss:tlsportname1/proxy/: tls baz (200; 19.458382ms)
Apr 29 10:34:34.478: INFO: (5) /api/v1/namespaces/proxy-3747/services/http:proxy-service-4v8ss:portname2/proxy/: bar (200; 20.268686ms)
Apr 29 10:34:34.478: INFO: (5) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:443/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:443/proxy/tlsrewritem... (200; 19.706684ms)
Apr 29 10:34:34.478: INFO: (5) /api/v1/namespaces/proxy-3747/services/http:proxy-service-4v8ss:portname1/proxy/: foo (200; 20.489087ms)
Apr 29 10:34:34.478: INFO: (5) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4/proxy/rewriteme">test</a> (200; 21.035089ms)
Apr 29 10:34:34.488: INFO: (6) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:1080/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:1080/proxy/rewriteme">test<... (200; 9.39604ms)
Apr 29 10:34:34.497: INFO: (6) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:1080/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:1080/proxy/rewriteme">... (200; 19.00128ms)
Apr 29 10:34:34.498: INFO: (6) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:162/proxy/: bar (200; 19.123981ms)
Apr 29 10:34:34.498: INFO: (6) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:462/proxy/: tls qux (200; 19.371682ms)
Apr 29 10:34:34.498: INFO: (6) /api/v1/namespaces/proxy-3747/services/proxy-service-4v8ss:portname2/proxy/: bar (200; 20.371887ms)
Apr 29 10:34:34.499: INFO: (6) /api/v1/namespaces/proxy-3747/services/http:proxy-service-4v8ss:portname1/proxy/: foo (200; 20.242186ms)
Apr 29 10:34:34.499: INFO: (6) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4/proxy/rewriteme">test</a> (200; 20.455686ms)
Apr 29 10:34:34.501: INFO: (6) /api/v1/namespaces/proxy-3747/services/proxy-service-4v8ss:portname1/proxy/: foo (200; 21.875592ms)
Apr 29 10:34:34.501: INFO: (6) /api/v1/namespaces/proxy-3747/services/http:proxy-service-4v8ss:portname2/proxy/: bar (200; 22.096194ms)
Apr 29 10:34:34.501: INFO: (6) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:443/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:443/proxy/tlsrewritem... (200; 21.643391ms)
Apr 29 10:34:34.501: INFO: (6) /api/v1/namespaces/proxy-3747/services/https:proxy-service-4v8ss:tlsportname1/proxy/: tls baz (200; 22.271195ms)
Apr 29 10:34:34.501: INFO: (6) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:160/proxy/: foo (200; 22.158994ms)
Apr 29 10:34:34.501: INFO: (6) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:162/proxy/: bar (200; 22.138694ms)
Apr 29 10:34:34.501: INFO: (6) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:160/proxy/: foo (200; 22.171294ms)
Apr 29 10:34:34.502: INFO: (6) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:460/proxy/: tls baz (200; 23.773801ms)
Apr 29 10:34:34.504: INFO: (6) /api/v1/namespaces/proxy-3747/services/https:proxy-service-4v8ss:tlsportname2/proxy/: tls qux (200; 24.333203ms)
Apr 29 10:34:34.515: INFO: (7) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:460/proxy/: tls baz (200; 11.053347ms)
Apr 29 10:34:34.528: INFO: (7) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:160/proxy/: foo (200; 23.957902ms)
Apr 29 10:34:34.529: INFO: (7) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:1080/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:1080/proxy/rewriteme">... (200; 23.5904ms)
Apr 29 10:34:34.529: INFO: (7) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:160/proxy/: foo (200; 24.141103ms)
Apr 29 10:34:34.529: INFO: (7) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:162/proxy/: bar (200; 19.140181ms)
Apr 29 10:34:34.529: INFO: (7) /api/v1/namespaces/proxy-3747/services/proxy-service-4v8ss:portname2/proxy/: bar (200; 25.176707ms)
Apr 29 10:34:34.529: INFO: (7) /api/v1/namespaces/proxy-3747/services/http:proxy-service-4v8ss:portname2/proxy/: bar (200; 25.000606ms)
Apr 29 10:34:34.529: INFO: (7) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4/proxy/rewriteme">test</a> (200; 24.402604ms)
Apr 29 10:34:34.529: INFO: (7) /api/v1/namespaces/proxy-3747/services/https:proxy-service-4v8ss:tlsportname1/proxy/: tls baz (200; 24.761605ms)
Apr 29 10:34:34.529: INFO: (7) /api/v1/namespaces/proxy-3747/services/https:proxy-service-4v8ss:tlsportname2/proxy/: tls qux (200; 24.708105ms)
Apr 29 10:34:34.529: INFO: (7) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:162/proxy/: bar (200; 24.902006ms)
Apr 29 10:34:34.529: INFO: (7) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:443/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:443/proxy/tlsrewritem... (200; 24.645104ms)
Apr 29 10:34:34.529: INFO: (7) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:1080/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:1080/proxy/rewriteme">test<... (200; 25.362107ms)
Apr 29 10:34:34.529: INFO: (7) /api/v1/namespaces/proxy-3747/services/proxy-service-4v8ss:portname1/proxy/: foo (200; 19.465183ms)
Apr 29 10:34:34.529: INFO: (7) /api/v1/namespaces/proxy-3747/services/http:proxy-service-4v8ss:portname1/proxy/: foo (200; 19.839784ms)
Apr 29 10:34:34.530: INFO: (7) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:462/proxy/: tls qux (200; 19.827884ms)
Apr 29 10:34:34.541: INFO: (8) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:162/proxy/: bar (200; 11.374248ms)
Apr 29 10:34:34.541: INFO: (8) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:443/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:443/proxy/tlsrewritem... (200; 11.195248ms)
Apr 29 10:34:34.541: INFO: (8) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:160/proxy/: foo (200; 11.554249ms)
Apr 29 10:34:34.545: INFO: (8) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:162/proxy/: bar (200; 13.820859ms)
Apr 29 10:34:34.545: INFO: (8) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:462/proxy/: tls qux (200; 14.581362ms)
Apr 29 10:34:34.551: INFO: (8) /api/v1/namespaces/proxy-3747/services/http:proxy-service-4v8ss:portname2/proxy/: bar (200; 20.361786ms)
Apr 29 10:34:34.551: INFO: (8) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:1080/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:1080/proxy/rewriteme">... (200; 20.754588ms)
Apr 29 10:34:34.552: INFO: (8) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4/proxy/rewriteme">test</a> (200; 20.619888ms)
Apr 29 10:34:34.552: INFO: (8) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:160/proxy/: foo (200; 20.922489ms)
Apr 29 10:34:34.553: INFO: (8) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:1080/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:1080/proxy/rewriteme">test<... (200; 22.151194ms)
Apr 29 10:34:34.553: INFO: (8) /api/v1/namespaces/proxy-3747/services/proxy-service-4v8ss:portname2/proxy/: bar (200; 23.357599ms)
Apr 29 10:34:34.553: INFO: (8) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:460/proxy/: tls baz (200; 23.074198ms)
Apr 29 10:34:34.553: INFO: (8) /api/v1/namespaces/proxy-3747/services/http:proxy-service-4v8ss:portname1/proxy/: foo (200; 22.416995ms)
Apr 29 10:34:34.554: INFO: (8) /api/v1/namespaces/proxy-3747/services/https:proxy-service-4v8ss:tlsportname2/proxy/: tls qux (200; 23.475699ms)
Apr 29 10:34:34.553: INFO: (8) /api/v1/namespaces/proxy-3747/services/https:proxy-service-4v8ss:tlsportname1/proxy/: tls baz (200; 22.772697ms)
Apr 29 10:34:34.555: INFO: (8) /api/v1/namespaces/proxy-3747/services/proxy-service-4v8ss:portname1/proxy/: foo (200; 23.367299ms)
Apr 29 10:34:34.572: INFO: (9) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:162/proxy/: bar (200; 17.557474ms)
Apr 29 10:34:34.573: INFO: (9) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:1080/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:1080/proxy/rewriteme">... (200; 18.037576ms)
Apr 29 10:34:34.573: INFO: (9) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:462/proxy/: tls qux (200; 17.923876ms)
Apr 29 10:34:34.573: INFO: (9) /api/v1/namespaces/proxy-3747/services/http:proxy-service-4v8ss:portname2/proxy/: bar (200; 17.875676ms)
Apr 29 10:34:34.573: INFO: (9) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:162/proxy/: bar (200; 17.876276ms)
Apr 29 10:34:34.574: INFO: (9) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:160/proxy/: foo (200; 18.085377ms)
Apr 29 10:34:34.574: INFO: (9) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4/proxy/rewriteme">test</a> (200; 18.350078ms)
Apr 29 10:34:34.574: INFO: (9) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:160/proxy/: foo (200; 17.928776ms)
Apr 29 10:34:34.574: INFO: (9) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:1080/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:1080/proxy/rewriteme">test<... (200; 17.565874ms)
Apr 29 10:34:34.575: INFO: (9) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:460/proxy/: tls baz (200; 19.100782ms)
Apr 29 10:34:34.575: INFO: (9) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:443/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:443/proxy/tlsrewritem... (200; 19.450683ms)
Apr 29 10:34:34.576: INFO: (9) /api/v1/namespaces/proxy-3747/services/http:proxy-service-4v8ss:portname1/proxy/: foo (200; 20.969189ms)
Apr 29 10:34:34.580: INFO: (9) /api/v1/namespaces/proxy-3747/services/https:proxy-service-4v8ss:tlsportname2/proxy/: tls qux (200; 24.056302ms)
Apr 29 10:34:34.581: INFO: (9) /api/v1/namespaces/proxy-3747/services/https:proxy-service-4v8ss:tlsportname1/proxy/: tls baz (200; 24.473804ms)
Apr 29 10:34:34.581: INFO: (9) /api/v1/namespaces/proxy-3747/services/proxy-service-4v8ss:portname1/proxy/: foo (200; 25.050906ms)
Apr 29 10:34:34.581: INFO: (9) /api/v1/namespaces/proxy-3747/services/proxy-service-4v8ss:portname2/proxy/: bar (200; 25.373408ms)
Apr 29 10:34:34.599: INFO: (10) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:443/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:443/proxy/tlsrewritem... (200; 17.496975ms)
Apr 29 10:34:34.599: INFO: (10) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:1080/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:1080/proxy/rewriteme">... (200; 17.658175ms)
Apr 29 10:34:34.600: INFO: (10) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:462/proxy/: tls qux (200; 17.489774ms)
Apr 29 10:34:34.601: INFO: (10) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:162/proxy/: bar (200; 19.115081ms)
Apr 29 10:34:34.602: INFO: (10) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:460/proxy/: tls baz (200; 20.060985ms)
Apr 29 10:34:34.602: INFO: (10) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:160/proxy/: foo (200; 20.467487ms)
Apr 29 10:34:34.602: INFO: (10) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:1080/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:1080/proxy/rewriteme">test<... (200; 19.911184ms)
Apr 29 10:34:34.602: INFO: (10) /api/v1/namespaces/proxy-3747/services/http:proxy-service-4v8ss:portname2/proxy/: bar (200; 18.568078ms)
Apr 29 10:34:34.602: INFO: (10) /api/v1/namespaces/proxy-3747/services/https:proxy-service-4v8ss:tlsportname2/proxy/: tls qux (200; 20.159086ms)
Apr 29 10:34:34.602: INFO: (10) /api/v1/namespaces/proxy-3747/services/http:proxy-service-4v8ss:portname1/proxy/: foo (200; 19.906785ms)
Apr 29 10:34:34.602: INFO: (10) /api/v1/namespaces/proxy-3747/services/https:proxy-service-4v8ss:tlsportname1/proxy/: tls baz (200; 20.341186ms)
Apr 29 10:34:34.602: INFO: (10) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:160/proxy/: foo (200; 20.262086ms)
Apr 29 10:34:34.602: INFO: (10) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4/proxy/rewriteme">test</a> (200; 20.014485ms)
Apr 29 10:34:34.602: INFO: (10) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:162/proxy/: bar (200; 19.968884ms)
Apr 29 10:34:34.602: INFO: (10) /api/v1/namespaces/proxy-3747/services/proxy-service-4v8ss:portname1/proxy/: foo (200; 19.706783ms)
Apr 29 10:34:34.602: INFO: (10) /api/v1/namespaces/proxy-3747/services/proxy-service-4v8ss:portname2/proxy/: bar (200; 20.001285ms)
Apr 29 10:34:34.607: INFO: (11) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:460/proxy/: tls baz (200; 4.132618ms)
Apr 29 10:34:34.628: INFO: (11) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:162/proxy/: bar (200; 25.040307ms)
Apr 29 10:34:34.629: INFO: (11) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:1080/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:1080/proxy/rewriteme">test<... (200; 25.680308ms)
Apr 29 10:34:34.629: INFO: (11) /api/v1/namespaces/proxy-3747/services/http:proxy-service-4v8ss:portname2/proxy/: bar (200; 26.069311ms)
Apr 29 10:34:34.629: INFO: (11) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:1080/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:1080/proxy/rewriteme">... (200; 26.188411ms)
Apr 29 10:34:34.630: INFO: (11) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4/proxy/rewriteme">test</a> (200; 26.389112ms)
Apr 29 10:34:34.634: INFO: (11) /api/v1/namespaces/proxy-3747/services/http:proxy-service-4v8ss:portname1/proxy/: foo (200; 30.70233ms)
Apr 29 10:34:34.635: INFO: (11) /api/v1/namespaces/proxy-3747/services/https:proxy-service-4v8ss:tlsportname1/proxy/: tls baz (200; 31.741634ms)
Apr 29 10:34:34.639: INFO: (11) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:162/proxy/: bar (200; 35.903952ms)
Apr 29 10:34:34.639: INFO: (11) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:160/proxy/: foo (200; 35.975152ms)
Apr 29 10:34:34.640: INFO: (11) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:462/proxy/: tls qux (200; 36.106654ms)
Apr 29 10:34:34.640: INFO: (11) /api/v1/namespaces/proxy-3747/services/proxy-service-4v8ss:portname1/proxy/: foo (200; 36.101653ms)
Apr 29 10:34:34.640: INFO: (11) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:160/proxy/: foo (200; 36.004253ms)
Apr 29 10:34:34.655: INFO: (11) /api/v1/namespaces/proxy-3747/services/proxy-service-4v8ss:portname2/proxy/: bar (200; 52.775624ms)
Apr 29 10:34:34.656: INFO: (11) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:443/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:443/proxy/tlsrewritem... (200; 52.160222ms)
Apr 29 10:34:34.656: INFO: (11) /api/v1/namespaces/proxy-3747/services/https:proxy-service-4v8ss:tlsportname2/proxy/: tls qux (200; 52.442123ms)
Apr 29 10:34:34.667: INFO: (12) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:1080/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:1080/proxy/rewriteme">... (200; 10.788445ms)
Apr 29 10:34:34.668: INFO: (12) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:462/proxy/: tls qux (200; 10.686545ms)
Apr 29 10:34:34.668: INFO: (12) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4/proxy/rewriteme">test</a> (200; 11.387049ms)
Apr 29 10:34:34.672: INFO: (12) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:162/proxy/: bar (200; 15.031664ms)
Apr 29 10:34:34.678: INFO: (12) /api/v1/namespaces/proxy-3747/services/http:proxy-service-4v8ss:portname1/proxy/: foo (200; 21.38349ms)
Apr 29 10:34:34.680: INFO: (12) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:1080/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:1080/proxy/rewriteme">test<... (200; 22.320294ms)
Apr 29 10:34:34.680: INFO: (12) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:162/proxy/: bar (200; 23.190398ms)
Apr 29 10:34:34.681: INFO: (12) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:443/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:443/proxy/tlsrewritem... (200; 23.6339ms)
Apr 29 10:34:34.681: INFO: (12) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:460/proxy/: tls baz (200; 23.6075ms)
Apr 29 10:34:34.681: INFO: (12) /api/v1/namespaces/proxy-3747/services/proxy-service-4v8ss:portname1/proxy/: foo (200; 24.133503ms)
Apr 29 10:34:34.681: INFO: (12) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:160/proxy/: foo (200; 24.102902ms)
Apr 29 10:34:34.682: INFO: (12) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:160/proxy/: foo (200; 24.150003ms)
Apr 29 10:34:34.682: INFO: (12) /api/v1/namespaces/proxy-3747/services/proxy-service-4v8ss:portname2/proxy/: bar (200; 24.495704ms)
Apr 29 10:34:34.682: INFO: (12) /api/v1/namespaces/proxy-3747/services/https:proxy-service-4v8ss:tlsportname1/proxy/: tls baz (200; 24.913606ms)
Apr 29 10:34:34.682: INFO: (12) /api/v1/namespaces/proxy-3747/services/http:proxy-service-4v8ss:portname2/proxy/: bar (200; 24.920005ms)
Apr 29 10:34:34.682: INFO: (12) /api/v1/namespaces/proxy-3747/services/https:proxy-service-4v8ss:tlsportname2/proxy/: tls qux (200; 24.856906ms)
Apr 29 10:34:34.699: INFO: (13) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:460/proxy/: tls baz (200; 15.599266ms)
Apr 29 10:34:34.699: INFO: (13) /api/v1/namespaces/proxy-3747/services/http:proxy-service-4v8ss:portname1/proxy/: foo (200; 16.779071ms)
Apr 29 10:34:34.699: INFO: (13) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4/proxy/rewriteme">test</a> (200; 16.738771ms)
Apr 29 10:34:34.699: INFO: (13) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:162/proxy/: bar (200; 16.713071ms)
Apr 29 10:34:34.699: INFO: (13) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:1080/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:1080/proxy/rewriteme">test<... (200; 15.710467ms)
Apr 29 10:34:34.699: INFO: (13) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:462/proxy/: tls qux (200; 16.688271ms)
Apr 29 10:34:34.699: INFO: (13) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:1080/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:1080/proxy/rewriteme">... (200; 15.735766ms)
Apr 29 10:34:34.699: INFO: (13) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:162/proxy/: bar (200; 17.045473ms)
Apr 29 10:34:34.699: INFO: (13) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:160/proxy/: foo (200; 15.716467ms)
Apr 29 10:34:34.705: INFO: (13) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:160/proxy/: foo (200; 22.301594ms)
Apr 29 10:34:34.705: INFO: (13) /api/v1/namespaces/proxy-3747/services/proxy-service-4v8ss:portname1/proxy/: foo (200; 22.674796ms)
Apr 29 10:34:34.705: INFO: (13) /api/v1/namespaces/proxy-3747/services/https:proxy-service-4v8ss:tlsportname2/proxy/: tls qux (200; 21.561591ms)
Apr 29 10:34:34.705: INFO: (13) /api/v1/namespaces/proxy-3747/services/https:proxy-service-4v8ss:tlsportname1/proxy/: tls baz (200; 21.530291ms)
Apr 29 10:34:34.705: INFO: (13) /api/v1/namespaces/proxy-3747/services/proxy-service-4v8ss:portname2/proxy/: bar (200; 22.479795ms)
Apr 29 10:34:34.705: INFO: (13) /api/v1/namespaces/proxy-3747/services/http:proxy-service-4v8ss:portname2/proxy/: bar (200; 22.407595ms)
Apr 29 10:34:34.708: INFO: (13) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:443/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:443/proxy/tlsrewritem... (200; 25.414708ms)
Apr 29 10:34:34.722: INFO: (14) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:160/proxy/: foo (200; 12.790754ms)
Apr 29 10:34:34.722: INFO: (14) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:160/proxy/: foo (200; 13.674558ms)
Apr 29 10:34:34.722: INFO: (14) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:162/proxy/: bar (200; 13.709759ms)
Apr 29 10:34:34.723: INFO: (14) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:460/proxy/: tls baz (200; 13.347056ms)
Apr 29 10:34:34.723: INFO: (14) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:443/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:443/proxy/tlsrewritem... (200; 13.688458ms)
Apr 29 10:34:34.723: INFO: (14) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:1080/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:1080/proxy/rewriteme">... (200; 14.818963ms)
Apr 29 10:34:34.730: INFO: (14) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:1080/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:1080/proxy/rewriteme">test<... (200; 20.661788ms)
Apr 29 10:34:34.731: INFO: (14) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:162/proxy/: bar (200; 21.535792ms)
Apr 29 10:34:34.732: INFO: (14) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4/proxy/rewriteme">test</a> (200; 21.901093ms)
Apr 29 10:34:34.734: INFO: (14) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:462/proxy/: tls qux (200; 24.745405ms)
Apr 29 10:34:34.735: INFO: (14) /api/v1/namespaces/proxy-3747/services/https:proxy-service-4v8ss:tlsportname2/proxy/: tls qux (200; 25.522909ms)
Apr 29 10:34:34.735: INFO: (14) /api/v1/namespaces/proxy-3747/services/https:proxy-service-4v8ss:tlsportname1/proxy/: tls baz (200; 25.668909ms)
Apr 29 10:34:34.735: INFO: (14) /api/v1/namespaces/proxy-3747/services/proxy-service-4v8ss:portname1/proxy/: foo (200; 24.685105ms)
Apr 29 10:34:34.735: INFO: (14) /api/v1/namespaces/proxy-3747/services/http:proxy-service-4v8ss:portname2/proxy/: bar (200; 25.299507ms)
Apr 29 10:34:34.736: INFO: (14) /api/v1/namespaces/proxy-3747/services/proxy-service-4v8ss:portname2/proxy/: bar (200; 26.127511ms)
Apr 29 10:34:34.737: INFO: (14) /api/v1/namespaces/proxy-3747/services/http:proxy-service-4v8ss:portname1/proxy/: foo (200; 13.293356ms)
Apr 29 10:34:34.760: INFO: (15) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:162/proxy/: bar (200; 22.308695ms)
Apr 29 10:34:34.760: INFO: (15) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:162/proxy/: bar (200; 23.177799ms)
Apr 29 10:34:34.761: INFO: (15) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:462/proxy/: tls qux (200; 23.866001ms)
Apr 29 10:34:34.760: INFO: (15) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4/proxy/rewriteme">test</a> (200; 22.476296ms)
Apr 29 10:34:34.760: INFO: (15) /api/v1/namespaces/proxy-3747/services/http:proxy-service-4v8ss:portname1/proxy/: foo (200; 22.576296ms)
Apr 29 10:34:34.760: INFO: (15) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:460/proxy/: tls baz (200; 20.838188ms)
Apr 29 10:34:34.760: INFO: (15) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:160/proxy/: foo (200; 20.759988ms)
Apr 29 10:34:34.760: INFO: (15) /api/v1/namespaces/proxy-3747/services/proxy-service-4v8ss:portname1/proxy/: foo (200; 21.13859ms)
Apr 29 10:34:34.760: INFO: (15) /api/v1/namespaces/proxy-3747/services/https:proxy-service-4v8ss:tlsportname1/proxy/: tls baz (200; 20.701388ms)
Apr 29 10:34:34.761: INFO: (15) /api/v1/namespaces/proxy-3747/services/proxy-service-4v8ss:portname2/proxy/: bar (200; 21.20899ms)
Apr 29 10:34:34.761: INFO: (15) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:160/proxy/: foo (200; 23.414599ms)
Apr 29 10:34:34.761: INFO: (15) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:1080/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:1080/proxy/rewriteme">test<... (200; 23.250799ms)
Apr 29 10:34:34.761: INFO: (15) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:1080/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:1080/proxy/rewriteme">... (200; 23.7622ms)
Apr 29 10:34:34.761: INFO: (15) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:443/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:443/proxy/tlsrewritem... (200; 24.179303ms)
Apr 29 10:34:34.762: INFO: (15) /api/v1/namespaces/proxy-3747/services/http:proxy-service-4v8ss:portname2/proxy/: bar (200; 23.696501ms)
Apr 29 10:34:34.762: INFO: (15) /api/v1/namespaces/proxy-3747/services/https:proxy-service-4v8ss:tlsportname2/proxy/: tls qux (200; 24.717705ms)
Apr 29 10:34:34.772: INFO: (16) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:160/proxy/: foo (200; 10.439444ms)
Apr 29 10:34:34.779: INFO: (16) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:160/proxy/: foo (200; 16.45307ms)
Apr 29 10:34:34.779: INFO: (16) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:162/proxy/: bar (200; 16.792572ms)
Apr 29 10:34:34.779: INFO: (16) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:162/proxy/: bar (200; 12.992755ms)
Apr 29 10:34:34.780: INFO: (16) /api/v1/namespaces/proxy-3747/services/https:proxy-service-4v8ss:tlsportname1/proxy/: tls baz (200; 17.069072ms)
Apr 29 10:34:34.783: INFO: (16) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:460/proxy/: tls baz (200; 18.502778ms)
Apr 29 10:34:34.783: INFO: (16) /api/v1/namespaces/proxy-3747/services/proxy-service-4v8ss:portname1/proxy/: foo (200; 20.715388ms)
Apr 29 10:34:34.783: INFO: (16) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:1080/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:1080/proxy/rewriteme">... (200; 20.648388ms)
Apr 29 10:34:34.784: INFO: (16) /api/v1/namespaces/proxy-3747/services/https:proxy-service-4v8ss:tlsportname2/proxy/: tls qux (200; 20.865889ms)
Apr 29 10:34:34.784: INFO: (16) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4/proxy/rewriteme">test</a> (200; 19.204081ms)
Apr 29 10:34:34.784: INFO: (16) /api/v1/namespaces/proxy-3747/services/http:proxy-service-4v8ss:portname2/proxy/: bar (200; 21.40559ms)
Apr 29 10:34:34.784: INFO: (16) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:462/proxy/: tls qux (200; 22.274095ms)
Apr 29 10:34:34.784: INFO: (16) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:443/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:443/proxy/tlsrewritem... (200; 19.993785ms)
Apr 29 10:34:34.784: INFO: (16) /api/v1/namespaces/proxy-3747/services/proxy-service-4v8ss:portname2/proxy/: bar (200; 22.025194ms)
Apr 29 10:34:34.784: INFO: (16) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:1080/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:1080/proxy/rewriteme">test<... (200; 19.936685ms)
Apr 29 10:34:34.784: INFO: (16) /api/v1/namespaces/proxy-3747/services/http:proxy-service-4v8ss:portname1/proxy/: foo (200; 19.816285ms)
Apr 29 10:34:34.792: INFO: (17) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:160/proxy/: foo (200; 7.630032ms)
Apr 29 10:34:34.796: INFO: (17) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:162/proxy/: bar (200; 11.013846ms)
Apr 29 10:34:34.796: INFO: (17) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4/proxy/rewriteme">test</a> (200; 11.364348ms)
Apr 29 10:34:34.796: INFO: (17) /api/v1/namespaces/proxy-3747/services/http:proxy-service-4v8ss:portname1/proxy/: foo (200; 11.77565ms)
Apr 29 10:34:34.806: INFO: (17) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:462/proxy/: tls qux (200; 20.993789ms)
Apr 29 10:34:34.808: INFO: (17) /api/v1/namespaces/proxy-3747/services/http:proxy-service-4v8ss:portname2/proxy/: bar (200; 22.442295ms)
Apr 29 10:34:34.810: INFO: (17) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:160/proxy/: foo (200; 24.792106ms)
Apr 29 10:34:34.811: INFO: (17) /api/v1/namespaces/proxy-3747/services/proxy-service-4v8ss:portname1/proxy/: foo (200; 25.222907ms)
Apr 29 10:34:34.811: INFO: (17) /api/v1/namespaces/proxy-3747/services/proxy-service-4v8ss:portname2/proxy/: bar (200; 25.197907ms)
Apr 29 10:34:34.808: INFO: (17) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:162/proxy/: bar (200; 22.767597ms)
Apr 29 10:34:34.817: INFO: (17) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:460/proxy/: tls baz (200; 32.128036ms)
Apr 29 10:34:34.818: INFO: (17) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:1080/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:1080/proxy/rewriteme">... (200; 31.069432ms)
Apr 29 10:34:34.818: INFO: (17) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:1080/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:1080/proxy/rewriteme">test<... (200; 32.269537ms)
Apr 29 10:34:34.822: INFO: (17) /api/v1/namespaces/proxy-3747/services/https:proxy-service-4v8ss:tlsportname2/proxy/: tls qux (200; 35.783452ms)
Apr 29 10:34:34.822: INFO: (17) /api/v1/namespaces/proxy-3747/services/https:proxy-service-4v8ss:tlsportname1/proxy/: tls baz (200; 35.999752ms)
Apr 29 10:34:34.822: INFO: (17) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:443/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:443/proxy/tlsrewritem... (200; 34.745748ms)
Apr 29 10:34:34.847: INFO: (18) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4/proxy/rewriteme">test</a> (200; 24.819505ms)
Apr 29 10:34:34.848: INFO: (18) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:162/proxy/: bar (200; 24.678005ms)
Apr 29 10:34:34.848: INFO: (18) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:160/proxy/: foo (200; 19.956284ms)
Apr 29 10:34:34.848: INFO: (18) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:1080/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:1080/proxy/rewriteme">... (200; 25.114706ms)
Apr 29 10:34:34.852: INFO: (18) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:162/proxy/: bar (200; 29.223124ms)
Apr 29 10:34:34.852: INFO: (18) /api/v1/namespaces/proxy-3747/services/https:proxy-service-4v8ss:tlsportname2/proxy/: tls qux (200; 24.348303ms)
Apr 29 10:34:34.852: INFO: (18) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:460/proxy/: tls baz (200; 30.108228ms)
Apr 29 10:34:34.853: INFO: (18) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:160/proxy/: foo (200; 30.845031ms)
Apr 29 10:34:34.853: INFO: (18) /api/v1/namespaces/proxy-3747/services/https:proxy-service-4v8ss:tlsportname1/proxy/: tls baz (200; 25.003206ms)
Apr 29 10:34:34.853: INFO: (18) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:443/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:443/proxy/tlsrewritem... (200; 30.79183ms)
Apr 29 10:34:34.853: INFO: (18) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:462/proxy/: tls qux (200; 31.507033ms)
Apr 29 10:34:34.857: INFO: (18) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:1080/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:1080/proxy/rewriteme">test<... (200; 34.824547ms)
Apr 29 10:34:34.858: INFO: (18) /api/v1/namespaces/proxy-3747/services/proxy-service-4v8ss:portname2/proxy/: bar (200; 30.265828ms)
Apr 29 10:34:34.858: INFO: (18) /api/v1/namespaces/proxy-3747/services/http:proxy-service-4v8ss:portname1/proxy/: foo (200; 35.33305ms)
Apr 29 10:34:34.858: INFO: (18) /api/v1/namespaces/proxy-3747/services/proxy-service-4v8ss:portname1/proxy/: foo (200; 36.088553ms)
Apr 29 10:34:34.858: INFO: (18) /api/v1/namespaces/proxy-3747/services/http:proxy-service-4v8ss:portname2/proxy/: bar (200; 35.288149ms)
Apr 29 10:34:34.872: INFO: (19) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:462/proxy/: tls qux (200; 13.467757ms)
Apr 29 10:34:34.884: INFO: (19) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:443/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:443/proxy/tlsrewritem... (200; 20.006485ms)
Apr 29 10:34:34.884: INFO: (19) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4/proxy/rewriteme">test</a> (200; 16.45927ms)
Apr 29 10:34:34.889: INFO: (19) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:1080/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:1080/proxy/rewriteme">... (200; 22.120894ms)
Apr 29 10:34:34.890: INFO: (19) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:162/proxy/: bar (200; 28.27042ms)
Apr 29 10:34:34.890: INFO: (19) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:160/proxy/: foo (200; 29.531925ms)
Apr 29 10:34:34.891: INFO: (19) /api/v1/namespaces/proxy-3747/pods/https:proxy-service-4v8ss-gm9z4:460/proxy/: tls baz (200; 26.220011ms)
Apr 29 10:34:34.892: INFO: (19) /api/v1/namespaces/proxy-3747/services/http:proxy-service-4v8ss:portname2/proxy/: bar (200; 31.673735ms)
Apr 29 10:34:34.892: INFO: (19) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:1080/proxy/: <a href="/api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:1080/proxy/rewriteme">test<... (200; 25.462008ms)
Apr 29 10:34:34.892: INFO: (19) /api/v1/namespaces/proxy-3747/services/proxy-service-4v8ss:portname1/proxy/: foo (200; 33.518742ms)
Apr 29 10:34:34.892: INFO: (19) /api/v1/namespaces/proxy-3747/pods/proxy-service-4v8ss-gm9z4:160/proxy/: foo (200; 28.911023ms)
Apr 29 10:34:34.892: INFO: (19) /api/v1/namespaces/proxy-3747/services/proxy-service-4v8ss:portname2/proxy/: bar (200; 32.725139ms)
Apr 29 10:34:34.892: INFO: (19) /api/v1/namespaces/proxy-3747/services/https:proxy-service-4v8ss:tlsportname2/proxy/: tls qux (200; 29.915727ms)
Apr 29 10:34:34.892: INFO: (19) /api/v1/namespaces/proxy-3747/services/https:proxy-service-4v8ss:tlsportname1/proxy/: tls baz (200; 29.994527ms)
Apr 29 10:34:34.893: INFO: (19) /api/v1/namespaces/proxy-3747/pods/http:proxy-service-4v8ss-gm9z4:162/proxy/: bar (200; 25.290807ms)
Apr 29 10:34:34.893: INFO: (19) /api/v1/namespaces/proxy-3747/services/http:proxy-service-4v8ss:portname1/proxy/: foo (200; 25.889309ms)
STEP: deleting ReplicationController proxy-service-4v8ss in namespace proxy-3747, will wait for the garbage collector to delete the pods
Apr 29 10:34:34.954: INFO: Deleting ReplicationController proxy-service-4v8ss took: 8.030934ms
Apr 29 10:34:35.055: INFO: Terminating ReplicationController proxy-service-4v8ss pods took: 100.577927ms
[AfterEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:34:47.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3747" for this suite.
Apr 29 10:34:53.674: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:34:53.794: INFO: namespace proxy-3747 deletion completed in 6.132967782s

• [SLOW TEST:27.770 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:34:53.795: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-3688
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Apr 29 10:34:53.972: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3688,SelfLink:/api/v1/namespaces/watch-3688/configmaps/e2e-watch-test-configmap-a,UID:6d05b926-6a6a-11e9-9890-000d3a4710ea,ResourceVersion:25545,Generation:0,CreationTimestamp:2019-04-29 10:34:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr 29 10:34:53.973: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3688,SelfLink:/api/v1/namespaces/watch-3688/configmaps/e2e-watch-test-configmap-a,UID:6d05b926-6a6a-11e9-9890-000d3a4710ea,ResourceVersion:25545,Generation:0,CreationTimestamp:2019-04-29 10:34:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Apr 29 10:35:04.046: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3688,SelfLink:/api/v1/namespaces/watch-3688/configmaps/e2e-watch-test-configmap-a,UID:6d05b926-6a6a-11e9-9890-000d3a4710ea,ResourceVersion:25563,Generation:0,CreationTimestamp:2019-04-29 10:34:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Apr 29 10:35:04.047: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3688,SelfLink:/api/v1/namespaces/watch-3688/configmaps/e2e-watch-test-configmap-a,UID:6d05b926-6a6a-11e9-9890-000d3a4710ea,ResourceVersion:25563,Generation:0,CreationTimestamp:2019-04-29 10:34:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Apr 29 10:35:14.055: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3688,SelfLink:/api/v1/namespaces/watch-3688/configmaps/e2e-watch-test-configmap-a,UID:6d05b926-6a6a-11e9-9890-000d3a4710ea,ResourceVersion:25580,Generation:0,CreationTimestamp:2019-04-29 10:34:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr 29 10:35:14.055: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3688,SelfLink:/api/v1/namespaces/watch-3688/configmaps/e2e-watch-test-configmap-a,UID:6d05b926-6a6a-11e9-9890-000d3a4710ea,ResourceVersion:25580,Generation:0,CreationTimestamp:2019-04-29 10:34:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Apr 29 10:35:24.063: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3688,SelfLink:/api/v1/namespaces/watch-3688/configmaps/e2e-watch-test-configmap-a,UID:6d05b926-6a6a-11e9-9890-000d3a4710ea,ResourceVersion:25599,Generation:0,CreationTimestamp:2019-04-29 10:34:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr 29 10:35:24.063: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3688,SelfLink:/api/v1/namespaces/watch-3688/configmaps/e2e-watch-test-configmap-a,UID:6d05b926-6a6a-11e9-9890-000d3a4710ea,ResourceVersion:25599,Generation:0,CreationTimestamp:2019-04-29 10:34:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Apr 29 10:35:34.070: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-3688,SelfLink:/api/v1/namespaces/watch-3688/configmaps/e2e-watch-test-configmap-b,UID:84ec02b9-6a6a-11e9-9890-000d3a4710ea,ResourceVersion:25617,Generation:0,CreationTimestamp:2019-04-29 10:35:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr 29 10:35:34.070: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-3688,SelfLink:/api/v1/namespaces/watch-3688/configmaps/e2e-watch-test-configmap-b,UID:84ec02b9-6a6a-11e9-9890-000d3a4710ea,ResourceVersion:25617,Generation:0,CreationTimestamp:2019-04-29 10:35:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Apr 29 10:35:44.079: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-3688,SelfLink:/api/v1/namespaces/watch-3688/configmaps/e2e-watch-test-configmap-b,UID:84ec02b9-6a6a-11e9-9890-000d3a4710ea,ResourceVersion:25635,Generation:0,CreationTimestamp:2019-04-29 10:35:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr 29 10:35:44.079: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-3688,SelfLink:/api/v1/namespaces/watch-3688/configmaps/e2e-watch-test-configmap-b,UID:84ec02b9-6a6a-11e9-9890-000d3a4710ea,ResourceVersion:25635,Generation:0,CreationTimestamp:2019-04-29 10:35:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:35:54.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3688" for this suite.
Apr 29 10:36:00.109: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:36:00.237: INFO: namespace watch-3688 deletion completed in 6.142330176s

• [SLOW TEST:66.443 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:36:00.238: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-8952
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's command
Apr 29 10:36:00.423: INFO: Waiting up to 5m0s for pod "var-expansion-949fe802-6a6a-11e9-b6b4-b219b18c41e8" in namespace "var-expansion-8952" to be "success or failure"
Apr 29 10:36:00.430: INFO: Pod "var-expansion-949fe802-6a6a-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 7.862973ms
Apr 29 10:36:02.434: INFO: Pod "var-expansion-949fe802-6a6a-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011429286s
Apr 29 10:36:04.439: INFO: Pod "var-expansion-949fe802-6a6a-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01657168s
Apr 29 10:36:06.443: INFO: Pod "var-expansion-949fe802-6a6a-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.019962024s
STEP: Saw pod success
Apr 29 10:36:06.443: INFO: Pod "var-expansion-949fe802-6a6a-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 10:36:06.445: INFO: Trying to get logs from node 0mfg0-worker-000001 pod var-expansion-949fe802-6a6a-11e9-b6b4-b219b18c41e8 container dapi-container: <nil>
STEP: delete the pod
Apr 29 10:36:06.469: INFO: Waiting for pod var-expansion-949fe802-6a6a-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 10:36:06.472: INFO: Pod var-expansion-949fe802-6a6a-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:36:06.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8952" for this suite.
Apr 29 10:36:12.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:36:12.597: INFO: namespace var-expansion-8952 deletion completed in 6.120373138s

• [SLOW TEST:12.359 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:36:12.598: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-4098
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-secret-lnbh
STEP: Creating a pod to test atomic-volume-subpath
Apr 29 10:36:12.802: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-lnbh" in namespace "subpath-4098" to be "success or failure"
Apr 29 10:36:12.812: INFO: Pod "pod-subpath-test-secret-lnbh": Phase="Pending", Reason="", readiness=false. Elapsed: 9.90329ms
Apr 29 10:36:14.816: INFO: Pod "pod-subpath-test-secret-lnbh": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013587898s
Apr 29 10:36:16.820: INFO: Pod "pod-subpath-test-secret-lnbh": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017489875s
Apr 29 10:36:18.823: INFO: Pod "pod-subpath-test-secret-lnbh": Phase="Running", Reason="", readiness=true. Elapsed: 6.020817714s
Apr 29 10:36:20.827: INFO: Pod "pod-subpath-test-secret-lnbh": Phase="Running", Reason="", readiness=true. Elapsed: 8.024352823s
Apr 29 10:36:22.831: INFO: Pod "pod-subpath-test-secret-lnbh": Phase="Running", Reason="", readiness=true. Elapsed: 10.029004409s
Apr 29 10:36:24.835: INFO: Pod "pod-subpath-test-secret-lnbh": Phase="Running", Reason="", readiness=true. Elapsed: 12.032617853s
Apr 29 10:36:26.839: INFO: Pod "pod-subpath-test-secret-lnbh": Phase="Running", Reason="", readiness=true. Elapsed: 14.03678107s
Apr 29 10:36:28.843: INFO: Pod "pod-subpath-test-secret-lnbh": Phase="Running", Reason="", readiness=true. Elapsed: 16.040523351s
Apr 29 10:36:30.847: INFO: Pod "pod-subpath-test-secret-lnbh": Phase="Running", Reason="", readiness=true. Elapsed: 18.044501802s
Apr 29 10:36:32.851: INFO: Pod "pod-subpath-test-secret-lnbh": Phase="Running", Reason="", readiness=true. Elapsed: 20.048562023s
Apr 29 10:36:34.855: INFO: Pod "pod-subpath-test-secret-lnbh": Phase="Running", Reason="", readiness=true. Elapsed: 22.052628911s
Apr 29 10:36:36.859: INFO: Pod "pod-subpath-test-secret-lnbh": Phase="Running", Reason="", readiness=true. Elapsed: 24.056441566s
Apr 29 10:36:38.863: INFO: Pod "pod-subpath-test-secret-lnbh": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.060938995s
STEP: Saw pod success
Apr 29 10:36:38.863: INFO: Pod "pod-subpath-test-secret-lnbh" satisfied condition "success or failure"
Apr 29 10:36:38.867: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-subpath-test-secret-lnbh container test-container-subpath-secret-lnbh: <nil>
STEP: delete the pod
Apr 29 10:36:38.889: INFO: Waiting for pod pod-subpath-test-secret-lnbh to disappear
Apr 29 10:36:38.893: INFO: Pod pod-subpath-test-secret-lnbh no longer exists
STEP: Deleting pod pod-subpath-test-secret-lnbh
Apr 29 10:36:38.893: INFO: Deleting pod "pod-subpath-test-secret-lnbh" in namespace "subpath-4098"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:36:38.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4098" for this suite.
Apr 29 10:36:44.913: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:36:45.009: INFO: namespace subpath-4098 deletion completed in 6.108030639s

• [SLOW TEST:32.411 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:36:45.009: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5359
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-af4c6214-6a6a-11e9-b6b4-b219b18c41e8
STEP: Creating a pod to test consume configMaps
Apr 29 10:36:45.175: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-af4cfafc-6a6a-11e9-b6b4-b219b18c41e8" in namespace "projected-5359" to be "success or failure"
Apr 29 10:36:45.207: INFO: Pod "pod-projected-configmaps-af4cfafc-6a6a-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 32.161986ms
Apr 29 10:36:47.213: INFO: Pod "pod-projected-configmaps-af4cfafc-6a6a-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038031997s
Apr 29 10:36:49.219: INFO: Pod "pod-projected-configmaps-af4cfafc-6a6a-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.044059379s
Apr 29 10:36:51.223: INFO: Pod "pod-projected-configmaps-af4cfafc-6a6a-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.048193114s
STEP: Saw pod success
Apr 29 10:36:51.223: INFO: Pod "pod-projected-configmaps-af4cfafc-6a6a-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 10:36:51.226: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-projected-configmaps-af4cfafc-6a6a-11e9-b6b4-b219b18c41e8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 29 10:36:51.252: INFO: Waiting for pod pod-projected-configmaps-af4cfafc-6a6a-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 10:36:51.255: INFO: Pod pod-projected-configmaps-af4cfafc-6a6a-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:36:51.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5359" for this suite.
Apr 29 10:36:57.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:36:57.576: INFO: namespace projected-5359 deletion completed in 6.316583294s

• [SLOW TEST:12.567 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:36:57.577: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-2793
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Apr 29 10:36:57.807: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-2793,SelfLink:/api/v1/namespaces/watch-2793/configmaps/e2e-watch-test-resource-version,UID:b6d1bede-6a6a-11e9-9890-000d3a4710ea,ResourceVersion:25859,Generation:0,CreationTimestamp:2019-04-29 10:36:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr 29 10:36:57.807: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-2793,SelfLink:/api/v1/namespaces/watch-2793/configmaps/e2e-watch-test-resource-version,UID:b6d1bede-6a6a-11e9-9890-000d3a4710ea,ResourceVersion:25860,Generation:0,CreationTimestamp:2019-04-29 10:36:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:36:57.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2793" for this suite.
Apr 29 10:37:03.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:37:03.959: INFO: namespace watch-2793 deletion completed in 6.144384776s

• [SLOW TEST:6.382 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:37:03.960: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-9041
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Apr 29 10:37:04.179: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 10:37:04.237: INFO: Number of nodes with available pods: 0
Apr 29 10:37:04.237: INFO: Node 0mfg0-worker-000000 is running more than one daemon pod
Apr 29 10:37:05.243: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 10:37:05.247: INFO: Number of nodes with available pods: 0
Apr 29 10:37:05.247: INFO: Node 0mfg0-worker-000000 is running more than one daemon pod
Apr 29 10:37:06.246: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 10:37:06.249: INFO: Number of nodes with available pods: 0
Apr 29 10:37:06.249: INFO: Node 0mfg0-worker-000000 is running more than one daemon pod
Apr 29 10:37:07.244: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 10:37:07.248: INFO: Number of nodes with available pods: 0
Apr 29 10:37:07.248: INFO: Node 0mfg0-worker-000000 is running more than one daemon pod
Apr 29 10:37:08.242: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 10:37:08.245: INFO: Number of nodes with available pods: 2
Apr 29 10:37:08.245: INFO: Node 0mfg0-worker-000000 is running more than one daemon pod
Apr 29 10:37:09.243: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 10:37:09.248: INFO: Number of nodes with available pods: 3
Apr 29 10:37:09.248: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Apr 29 10:37:09.271: INFO: DaemonSet pods can't tolerate node 0mfg0-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 29 10:37:09.280: INFO: Number of nodes with available pods: 3
Apr 29 10:37:09.280: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9041, will wait for the garbage collector to delete the pods
Apr 29 10:37:10.368: INFO: Deleting DaemonSet.extensions daemon-set took: 9.426082ms
Apr 29 10:37:10.468: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.203971ms
Apr 29 10:37:17.672: INFO: Number of nodes with available pods: 0
Apr 29 10:37:17.672: INFO: Number of running nodes: 0, number of available pods: 0
Apr 29 10:37:17.675: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9041/daemonsets","resourceVersion":"25978"},"items":null}

Apr 29 10:37:17.677: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9041/pods","resourceVersion":"25978"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:37:17.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9041" for this suite.
Apr 29 10:37:23.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:37:23.826: INFO: namespace daemonsets-9041 deletion completed in 6.133227184s

• [SLOW TEST:19.867 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:37:23.827: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-1815
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Apr 29 10:37:23.992: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:37:32.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1815" for this suite.
Apr 29 10:37:38.956: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:37:39.083: INFO: namespace init-container-1815 deletion completed in 6.138556566s

• [SLOW TEST:15.256 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:37:39.092: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-2440
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:37:43.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-2440" for this suite.
Apr 29 10:37:49.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:37:49.517: INFO: namespace emptydir-wrapper-2440 deletion completed in 6.156911678s

• [SLOW TEST:10.426 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:37:49.518: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-4741
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-projected-5bms
STEP: Creating a pod to test atomic-volume-subpath
Apr 29 10:37:49.692: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-5bms" in namespace "subpath-4741" to be "success or failure"
Apr 29 10:37:49.708: INFO: Pod "pod-subpath-test-projected-5bms": Phase="Pending", Reason="", readiness=false. Elapsed: 15.851934ms
Apr 29 10:37:51.713: INFO: Pod "pod-subpath-test-projected-5bms": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021202305s
Apr 29 10:37:53.717: INFO: Pod "pod-subpath-test-projected-5bms": Phase="Pending", Reason="", readiness=false. Elapsed: 4.025096437s
Apr 29 10:37:55.721: INFO: Pod "pod-subpath-test-projected-5bms": Phase="Running", Reason="", readiness=true. Elapsed: 6.028956842s
Apr 29 10:37:57.726: INFO: Pod "pod-subpath-test-projected-5bms": Phase="Running", Reason="", readiness=true. Elapsed: 8.034009429s
Apr 29 10:37:59.730: INFO: Pod "pod-subpath-test-projected-5bms": Phase="Running", Reason="", readiness=true. Elapsed: 10.038232383s
Apr 29 10:38:01.735: INFO: Pod "pod-subpath-test-projected-5bms": Phase="Running", Reason="", readiness=true. Elapsed: 12.042810313s
Apr 29 10:38:03.739: INFO: Pod "pod-subpath-test-projected-5bms": Phase="Running", Reason="", readiness=true. Elapsed: 14.046833812s
Apr 29 10:38:05.743: INFO: Pod "pod-subpath-test-projected-5bms": Phase="Running", Reason="", readiness=true. Elapsed: 16.051105786s
Apr 29 10:38:07.747: INFO: Pod "pod-subpath-test-projected-5bms": Phase="Running", Reason="", readiness=true. Elapsed: 18.054856629s
Apr 29 10:38:09.750: INFO: Pod "pod-subpath-test-projected-5bms": Phase="Running", Reason="", readiness=true. Elapsed: 20.058672946s
Apr 29 10:38:11.754: INFO: Pod "pod-subpath-test-projected-5bms": Phase="Running", Reason="", readiness=true. Elapsed: 22.062521538s
Apr 29 10:38:13.758: INFO: Pod "pod-subpath-test-projected-5bms": Phase="Running", Reason="", readiness=true. Elapsed: 24.066746906s
Apr 29 10:38:15.800: INFO: Pod "pod-subpath-test-projected-5bms": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.107850253s
STEP: Saw pod success
Apr 29 10:38:15.812: INFO: Pod "pod-subpath-test-projected-5bms" satisfied condition "success or failure"
Apr 29 10:38:15.835: INFO: Trying to get logs from node 0mfg0-worker-000001 pod pod-subpath-test-projected-5bms container test-container-subpath-projected-5bms: <nil>
STEP: delete the pod
Apr 29 10:38:15.864: INFO: Waiting for pod pod-subpath-test-projected-5bms to disappear
Apr 29 10:38:15.866: INFO: Pod pod-subpath-test-projected-5bms no longer exists
STEP: Deleting pod pod-subpath-test-projected-5bms
Apr 29 10:38:15.866: INFO: Deleting pod "pod-subpath-test-projected-5bms" in namespace "subpath-4741"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:38:15.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4741" for this suite.
Apr 29 10:38:21.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:38:21.989: INFO: namespace subpath-4741 deletion completed in 6.115689314s

• [SLOW TEST:32.472 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:38:21.991: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8101
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 29 10:38:22.168: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:38:28.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8101" for this suite.
Apr 29 10:39:20.337: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:39:20.444: INFO: namespace pods-8101 deletion completed in 52.124491126s

• [SLOW TEST:58.453 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:39:20.445: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4464
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1510
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 29 10:39:20.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-4464'
Apr 29 10:39:21.567: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr 29 10:39:21.567: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1515
Apr 29 10:39:21.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-244696311 delete jobs e2e-test-nginx-job --namespace=kubectl-4464'
Apr 29 10:39:21.700: INFO: stderr: ""
Apr 29 10:39:21.700: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:39:21.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4464" for this suite.
Apr 29 10:39:43.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:39:43.887: INFO: namespace kubectl-4464 deletion completed in 22.18125859s

• [SLOW TEST:23.442 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 29 10:39:43.888: INFO: >>> kubeConfig: /tmp/kubeconfig-244696311
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1040
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 29 10:39:44.049: INFO: Waiting up to 5m0s for pod "downwardapi-volume-19eafb67-6a6b-11e9-b6b4-b219b18c41e8" in namespace "downward-api-1040" to be "success or failure"
Apr 29 10:39:44.059: INFO: Pod "downwardapi-volume-19eafb67-6a6b-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 10.122379ms
Apr 29 10:39:46.068: INFO: Pod "downwardapi-volume-19eafb67-6a6b-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019061783s
Apr 29 10:39:48.072: INFO: Pod "downwardapi-volume-19eafb67-6a6b-11e9-b6b4-b219b18c41e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02331783s
Apr 29 10:39:50.076: INFO: Pod "downwardapi-volume-19eafb67-6a6b-11e9-b6b4-b219b18c41e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.027455154s
STEP: Saw pod success
Apr 29 10:39:50.076: INFO: Pod "downwardapi-volume-19eafb67-6a6b-11e9-b6b4-b219b18c41e8" satisfied condition "success or failure"
Apr 29 10:39:50.079: INFO: Trying to get logs from node 0mfg0-worker-000001 pod downwardapi-volume-19eafb67-6a6b-11e9-b6b4-b219b18c41e8 container client-container: <nil>
STEP: delete the pod
Apr 29 10:39:50.109: INFO: Waiting for pod downwardapi-volume-19eafb67-6a6b-11e9-b6b4-b219b18c41e8 to disappear
Apr 29 10:39:50.111: INFO: Pod downwardapi-volume-19eafb67-6a6b-11e9-b6b4-b219b18c41e8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 29 10:39:50.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1040" for this suite.
Apr 29 10:39:56.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 29 10:39:56.256: INFO: namespace downward-api-1040 deletion completed in 6.140942126s

• [SLOW TEST:12.369 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSApr 29 10:39:56.257: INFO: Running AfterSuite actions on all nodes
Apr 29 10:39:56.257: INFO: Running AfterSuite actions on node 1
Apr 29 10:39:56.257: INFO: Skipping dumping logs from cluster

Ran 204 of 3584 Specs in 6366.031 seconds
SUCCESS! -- 204 Passed | 0 Failed | 0 Pending | 3380 Skipped PASS

Ginkgo ran 1 suite in 1h46m8.171913052s
Test Suite Passed
