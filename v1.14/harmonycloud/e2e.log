I0430 06:41:32.828116      17 test_context.go:405] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-610946863
I0430 06:41:32.831656      17 e2e.go:240] Starting e2e run "fbbd8dd1-6b12-11e9-845c-f234dad8a085" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1556606487 - Will randomize all specs
Will run 204 of 3584 specs

Apr 30 06:41:33.387: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
Apr 30 06:41:33.405: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Apr 30 06:41:33.469: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Apr 30 06:41:33.585: INFO: 13 / 13 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Apr 30 06:41:33.585: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
Apr 30 06:41:33.585: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Apr 30 06:41:33.607: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Apr 30 06:41:33.607: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Apr 30 06:41:33.607: INFO: e2e test version: v1.14.1
Apr 30 06:41:33.610: INFO: kube-apiserver version: v1.14.1
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:41:33.611: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename downward-api
Apr 30 06:41:33.691: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Apr 30 06:41:40.305: INFO: Successfully updated pod "annotationupdatefe9f3873-6b12-11e9-845c-f234dad8a085"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 06:41:42.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7361" for this suite.
Apr 30 06:42:04.387: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:42:04.608: INFO: namespace downward-api-7361 deletion completed in 22.241498146s

• [SLOW TEST:30.997 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:42:04.609: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 06:42:30.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-786" for this suite.
Apr 30 06:42:36.881: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:42:37.040: INFO: namespace namespaces-786 deletion completed in 6.176638674s
STEP: Destroying namespace "nsdeletetest-5551" for this suite.
Apr 30 06:42:37.044: INFO: Namespace nsdeletetest-5551 was already deleted
STEP: Destroying namespace "nsdeletetest-4594" for this suite.
Apr 30 06:42:43.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:42:43.224: INFO: namespace nsdeletetest-4594 deletion completed in 6.18007127s

• [SLOW TEST:38.616 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:42:43.225: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 30 06:42:43.311: INFO: Waiting up to 5m0s for pod "downwardapi-volume-281bc34f-6b13-11e9-845c-f234dad8a085" in namespace "downward-api-4087" to be "success or failure"
Apr 30 06:42:43.320: INFO: Pod "downwardapi-volume-281bc34f-6b13-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 8.62952ms
Apr 30 06:42:45.328: INFO: Pod "downwardapi-volume-281bc34f-6b13-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016953697s
Apr 30 06:42:47.336: INFO: Pod "downwardapi-volume-281bc34f-6b13-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02473154s
Apr 30 06:42:49.344: INFO: Pod "downwardapi-volume-281bc34f-6b13-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.032858673s
STEP: Saw pod success
Apr 30 06:42:49.344: INFO: Pod "downwardapi-volume-281bc34f-6b13-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 06:42:49.349: INFO: Trying to get logs from node 10.10.101.14-slave pod downwardapi-volume-281bc34f-6b13-11e9-845c-f234dad8a085 container client-container: <nil>
STEP: delete the pod
Apr 30 06:42:49.383: INFO: Waiting for pod downwardapi-volume-281bc34f-6b13-11e9-845c-f234dad8a085 to disappear
Apr 30 06:42:49.389: INFO: Pod downwardapi-volume-281bc34f-6b13-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 06:42:49.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4087" for this suite.
Apr 30 06:42:55.420: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:42:55.596: INFO: namespace downward-api-4087 deletion completed in 6.197071384s

• [SLOW TEST:12.371 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:42:55.597: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 30 06:42:55.690: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2f7ce886-6b13-11e9-845c-f234dad8a085" in namespace "projected-9423" to be "success or failure"
Apr 30 06:42:55.696: INFO: Pod "downwardapi-volume-2f7ce886-6b13-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 6.20224ms
Apr 30 06:42:57.703: INFO: Pod "downwardapi-volume-2f7ce886-6b13-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013312056s
Apr 30 06:42:59.710: INFO: Pod "downwardapi-volume-2f7ce886-6b13-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020871236s
STEP: Saw pod success
Apr 30 06:42:59.711: INFO: Pod "downwardapi-volume-2f7ce886-6b13-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 06:42:59.716: INFO: Trying to get logs from node 10.10.101.13-slave pod downwardapi-volume-2f7ce886-6b13-11e9-845c-f234dad8a085 container client-container: <nil>
STEP: delete the pod
Apr 30 06:42:59.748: INFO: Waiting for pod downwardapi-volume-2f7ce886-6b13-11e9-845c-f234dad8a085 to disappear
Apr 30 06:42:59.757: INFO: Pod downwardapi-volume-2f7ce886-6b13-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 06:42:59.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9423" for this suite.
Apr 30 06:43:05.787: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:43:05.960: INFO: namespace projected-9423 deletion completed in 6.195886657s

• [SLOW TEST:10.363 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:43:05.960: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Apr 30 06:43:06.063: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 06:43:07.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-270" for this suite.
Apr 30 06:43:13.140: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:43:13.327: INFO: namespace replication-controller-270 deletion completed in 6.210529546s

• [SLOW TEST:7.367 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:43:13.329: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-3491/configmap-test-3a0bb18c-6b13-11e9-845c-f234dad8a085
STEP: Creating a pod to test consume configMaps
Apr 30 06:43:13.425: INFO: Waiting up to 5m0s for pod "pod-configmaps-3a0f1375-6b13-11e9-845c-f234dad8a085" in namespace "configmap-3491" to be "success or failure"
Apr 30 06:43:13.435: INFO: Pod "pod-configmaps-3a0f1375-6b13-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 10.573796ms
Apr 30 06:43:15.443: INFO: Pod "pod-configmaps-3a0f1375-6b13-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018572213s
Apr 30 06:43:17.450: INFO: Pod "pod-configmaps-3a0f1375-6b13-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025555183s
STEP: Saw pod success
Apr 30 06:43:17.451: INFO: Pod "pod-configmaps-3a0f1375-6b13-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 06:43:17.456: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-configmaps-3a0f1375-6b13-11e9-845c-f234dad8a085 container env-test: <nil>
STEP: delete the pod
Apr 30 06:43:17.490: INFO: Waiting for pod pod-configmaps-3a0f1375-6b13-11e9-845c-f234dad8a085 to disappear
Apr 30 06:43:17.494: INFO: Pod pod-configmaps-3a0f1375-6b13-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 06:43:17.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3491" for this suite.
Apr 30 06:43:23.520: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:43:23.690: INFO: namespace configmap-3491 deletion completed in 6.188794207s

• [SLOW TEST:10.361 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:43:23.690: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-9512
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-9512
STEP: Creating statefulset with conflicting port in namespace statefulset-9512
STEP: Waiting until pod test-pod will start running in namespace statefulset-9512
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-9512
Apr 30 06:43:27.864: INFO: Observed stateful pod in namespace: statefulset-9512, name: ss-0, uid: 43e9018c-6b13-11e9-924a-005056bc1aae, status phase: Pending. Waiting for statefulset controller to delete.
Apr 30 06:43:29.803: INFO: Observed stateful pod in namespace: statefulset-9512, name: ss-0, uid: 43e9018c-6b13-11e9-924a-005056bc1aae, status phase: Failed. Waiting for statefulset controller to delete.
Apr 30 06:43:29.815: INFO: Observed stateful pod in namespace: statefulset-9512, name: ss-0, uid: 43e9018c-6b13-11e9-924a-005056bc1aae, status phase: Failed. Waiting for statefulset controller to delete.
Apr 30 06:43:29.823: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-9512
STEP: Removing pod with conflicting port in namespace statefulset-9512
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-9512 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr 30 06:43:33.890: INFO: Deleting all statefulset in ns statefulset-9512
Apr 30 06:43:33.895: INFO: Scaling statefulset ss to 0
Apr 30 06:43:43.923: INFO: Waiting for statefulset status.replicas updated to 0
Apr 30 06:43:43.929: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 06:43:43.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9512" for this suite.
Apr 30 06:43:49.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:43:50.294: INFO: namespace statefulset-9512 deletion completed in 6.331430557s

• [SLOW TEST:26.605 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:43:50.295: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
STEP: reading a file in the container
Apr 30 06:43:54.915: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5134 pod-service-account-5063ae79-6b13-11e9-845c-f234dad8a085 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Apr 30 06:43:55.956: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5134 pod-service-account-5063ae79-6b13-11e9-845c-f234dad8a085 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Apr 30 06:43:56.417: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5134 pod-service-account-5063ae79-6b13-11e9-845c-f234dad8a085 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 06:43:56.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-5134" for this suite.
Apr 30 06:44:02.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:44:03.079: INFO: namespace svcaccounts-5134 deletion completed in 6.188088806s

• [SLOW TEST:12.784 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:44:03.079: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: executing a command with run --rm and attach with stdin
Apr 30 06:44:03.155: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 --namespace=kubectl-3684 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Apr 30 06:44:06.806: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Apr 30 06:44:06.806: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 06:44:08.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3684" for this suite.
Apr 30 06:44:22.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:44:23.027: INFO: namespace kubectl-3684 deletion completed in 14.202718864s

• [SLOW TEST:19.948 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:44:23.028: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 30 06:44:23.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 version'
Apr 30 06:44:23.292: INFO: stderr: ""
Apr 30 06:44:23.293: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.1\", GitCommit:\"b7394102d6ef778017f2ca4046abbaa23b88c290\", GitTreeState:\"clean\", BuildDate:\"2019-04-08T17:11:31Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.1\", GitCommit:\"b7394102d6ef778017f2ca4046abbaa23b88c290\", GitTreeState:\"clean\", BuildDate:\"2019-04-08T17:02:58Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 06:44:23.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7396" for this suite.
Apr 30 06:44:29.318: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:44:29.471: INFO: namespace kubectl-7396 deletion completed in 6.17133831s

• [SLOW TEST:6.443 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:44:29.472: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating secret secrets-1367/secret-test-676f6743-6b13-11e9-845c-f234dad8a085
STEP: Creating a pod to test consume secrets
Apr 30 06:44:29.562: INFO: Waiting up to 5m0s for pod "pod-configmaps-677076e9-6b13-11e9-845c-f234dad8a085" in namespace "secrets-1367" to be "success or failure"
Apr 30 06:44:29.576: INFO: Pod "pod-configmaps-677076e9-6b13-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 14.194677ms
Apr 30 06:44:31.583: INFO: Pod "pod-configmaps-677076e9-6b13-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021000037s
Apr 30 06:44:33.591: INFO: Pod "pod-configmaps-677076e9-6b13-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028900257s
STEP: Saw pod success
Apr 30 06:44:33.591: INFO: Pod "pod-configmaps-677076e9-6b13-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 06:44:33.596: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-configmaps-677076e9-6b13-11e9-845c-f234dad8a085 container env-test: <nil>
STEP: delete the pod
Apr 30 06:44:33.637: INFO: Waiting for pod pod-configmaps-677076e9-6b13-11e9-845c-f234dad8a085 to disappear
Apr 30 06:44:33.643: INFO: Pod pod-configmaps-677076e9-6b13-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 06:44:33.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1367" for this suite.
Apr 30 06:44:39.666: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:44:39.827: INFO: namespace secrets-1367 deletion completed in 6.177514436s

• [SLOW TEST:10.356 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:44:39.827: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1318
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 30 06:44:39.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-9095'
Apr 30 06:44:40.160: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr 30 06:44:40.160: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1324
Apr 30 06:44:40.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 delete deployment e2e-test-nginx-deployment --namespace=kubectl-9095'
Apr 30 06:44:40.436: INFO: stderr: ""
Apr 30 06:44:40.436: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 06:44:40.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9095" for this suite.
Apr 30 06:44:46.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:44:46.653: INFO: namespace kubectl-9095 deletion completed in 6.205665367s

• [SLOW TEST:6.825 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:44:46.654: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 30 06:44:46.727: INFO: Waiting up to 5m0s for pod "downwardapi-volume-71ac30e1-6b13-11e9-845c-f234dad8a085" in namespace "projected-3152" to be "success or failure"
Apr 30 06:44:46.732: INFO: Pod "downwardapi-volume-71ac30e1-6b13-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 5.004053ms
Apr 30 06:44:48.739: INFO: Pod "downwardapi-volume-71ac30e1-6b13-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011403273s
Apr 30 06:44:50.746: INFO: Pod "downwardapi-volume-71ac30e1-6b13-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018677003s
STEP: Saw pod success
Apr 30 06:44:50.746: INFO: Pod "downwardapi-volume-71ac30e1-6b13-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 06:44:50.753: INFO: Trying to get logs from node 10.10.101.13-slave pod downwardapi-volume-71ac30e1-6b13-11e9-845c-f234dad8a085 container client-container: <nil>
STEP: delete the pod
Apr 30 06:44:50.860: INFO: Waiting for pod downwardapi-volume-71ac30e1-6b13-11e9-845c-f234dad8a085 to disappear
Apr 30 06:44:50.865: INFO: Pod downwardapi-volume-71ac30e1-6b13-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 06:44:50.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3152" for this suite.
Apr 30 06:44:56.906: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:44:57.056: INFO: namespace projected-3152 deletion completed in 6.184123296s

• [SLOW TEST:10.402 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:44:57.058: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 30 06:44:57.169: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Apr 30 06:44:57.184: INFO: Number of nodes with available pods: 0
Apr 30 06:44:57.184: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Apr 30 06:44:57.235: INFO: Number of nodes with available pods: 0
Apr 30 06:44:57.235: INFO: Node 10.10.101.13-slave is running more than one daemon pod
Apr 30 06:44:58.254: INFO: Number of nodes with available pods: 0
Apr 30 06:44:58.254: INFO: Node 10.10.101.13-slave is running more than one daemon pod
Apr 30 06:44:59.243: INFO: Number of nodes with available pods: 0
Apr 30 06:44:59.243: INFO: Node 10.10.101.13-slave is running more than one daemon pod
Apr 30 06:45:00.242: INFO: Number of nodes with available pods: 0
Apr 30 06:45:00.242: INFO: Node 10.10.101.13-slave is running more than one daemon pod
Apr 30 06:45:01.246: INFO: Number of nodes with available pods: 1
Apr 30 06:45:01.246: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Apr 30 06:45:01.278: INFO: Number of nodes with available pods: 1
Apr 30 06:45:01.278: INFO: Number of running nodes: 0, number of available pods: 1
Apr 30 06:45:02.285: INFO: Number of nodes with available pods: 0
Apr 30 06:45:02.285: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Apr 30 06:45:02.301: INFO: Number of nodes with available pods: 0
Apr 30 06:45:02.301: INFO: Node 10.10.101.13-slave is running more than one daemon pod
Apr 30 06:45:03.309: INFO: Number of nodes with available pods: 0
Apr 30 06:45:03.309: INFO: Node 10.10.101.13-slave is running more than one daemon pod
Apr 30 06:45:04.308: INFO: Number of nodes with available pods: 0
Apr 30 06:45:04.308: INFO: Node 10.10.101.13-slave is running more than one daemon pod
Apr 30 06:45:05.309: INFO: Number of nodes with available pods: 0
Apr 30 06:45:05.309: INFO: Node 10.10.101.13-slave is running more than one daemon pod
Apr 30 06:45:06.322: INFO: Number of nodes with available pods: 0
Apr 30 06:45:06.322: INFO: Node 10.10.101.13-slave is running more than one daemon pod
Apr 30 06:45:07.310: INFO: Number of nodes with available pods: 0
Apr 30 06:45:07.310: INFO: Node 10.10.101.13-slave is running more than one daemon pod
Apr 30 06:45:08.308: INFO: Number of nodes with available pods: 0
Apr 30 06:45:08.309: INFO: Node 10.10.101.13-slave is running more than one daemon pod
Apr 30 06:45:09.308: INFO: Number of nodes with available pods: 0
Apr 30 06:45:09.308: INFO: Node 10.10.101.13-slave is running more than one daemon pod
Apr 30 06:45:10.309: INFO: Number of nodes with available pods: 1
Apr 30 06:45:10.309: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1946, will wait for the garbage collector to delete the pods
Apr 30 06:45:10.388: INFO: Deleting DaemonSet.extensions daemon-set took: 16.384504ms
Apr 30 06:45:10.689: INFO: Terminating DaemonSet.extensions daemon-set pods took: 301.025836ms
Apr 30 06:45:13.897: INFO: Number of nodes with available pods: 0
Apr 30 06:45:13.897: INFO: Number of running nodes: 0, number of available pods: 0
Apr 30 06:45:13.927: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1946/daemonsets","resourceVersion":"664834"},"items":null}

Apr 30 06:45:13.934: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1946/pods","resourceVersion":"664835"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 06:45:13.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1946" for this suite.
Apr 30 06:45:19.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:45:20.163: INFO: namespace daemonsets-1946 deletion completed in 6.189334584s

• [SLOW TEST:23.105 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:45:20.163: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 30 06:45:20.225: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 version --client'
Apr 30 06:45:20.435: INFO: stderr: ""
Apr 30 06:45:20.435: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.1\", GitCommit:\"b7394102d6ef778017f2ca4046abbaa23b88c290\", GitTreeState:\"clean\", BuildDate:\"2019-04-08T17:11:31Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Apr 30 06:45:20.439: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 create -f - --namespace=kubectl-8000'
Apr 30 06:45:21.120: INFO: stderr: ""
Apr 30 06:45:21.120: INFO: stdout: "replicationcontroller/redis-master created\n"
Apr 30 06:45:21.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 create -f - --namespace=kubectl-8000'
Apr 30 06:45:21.572: INFO: stderr: ""
Apr 30 06:45:21.572: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Apr 30 06:45:22.579: INFO: Selector matched 1 pods for map[app:redis]
Apr 30 06:45:22.579: INFO: Found 0 / 1
Apr 30 06:45:23.579: INFO: Selector matched 1 pods for map[app:redis]
Apr 30 06:45:23.579: INFO: Found 0 / 1
Apr 30 06:45:24.579: INFO: Selector matched 1 pods for map[app:redis]
Apr 30 06:45:24.579: INFO: Found 0 / 1
Apr 30 06:45:25.579: INFO: Selector matched 1 pods for map[app:redis]
Apr 30 06:45:25.580: INFO: Found 1 / 1
Apr 30 06:45:25.580: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 30 06:45:25.586: INFO: Selector matched 1 pods for map[app:redis]
Apr 30 06:45:25.586: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 30 06:45:25.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 describe pod redis-master-fkzdl --namespace=kubectl-8000'
Apr 30 06:45:25.893: INFO: stderr: ""
Apr 30 06:45:25.893: INFO: stdout: "Name:               redis-master-fkzdl\nNamespace:          kubectl-8000\nPriority:           0\nPriorityClassName:  <none>\nNode:               10.10.101.13-slave/10.10.101.13\nStart Time:         Tue, 30 Apr 2019 06:45:27 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.168.6.172\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://e66e5f56caeb62b42a2511b002a49f2a6b19b60b06908c9ac8196fa0b53d41b7\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 30 Apr 2019 06:45:29 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-zp8z7 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-zp8z7:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-zp8z7\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age        From                         Message\n  ----    ------     ----       ----                         -------\n  Normal  Scheduled  0s         default-scheduler            Successfully assigned kubectl-8000/redis-master-fkzdl to 10.10.101.13-slave\n  Normal  Pulled     <invalid>  kubelet, 10.10.101.13-slave  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    <invalid>  kubelet, 10.10.101.13-slave  Created container redis-master\n  Normal  Started    <invalid>  kubelet, 10.10.101.13-slave  Started container redis-master\n"
Apr 30 06:45:25.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 describe rc redis-master --namespace=kubectl-8000'
Apr 30 06:45:26.182: INFO: stderr: ""
Apr 30 06:45:26.182: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-8000\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  0s    replication-controller  Created pod: redis-master-fkzdl\n"
Apr 30 06:45:26.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 describe service redis-master --namespace=kubectl-8000'
Apr 30 06:45:26.414: INFO: stderr: ""
Apr 30 06:45:26.414: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-8000\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.109.229.198\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.168.6.172:6379\nSession Affinity:  None\nEvents:            <none>\n"
Apr 30 06:45:26.421: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 describe node 10.10.101.12-master'
Apr 30 06:45:26.680: INFO: stderr: ""
Apr 30 06:45:26.680: INFO: stdout: "Name:               10.10.101.12-master\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=10.10.101.12-master\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/master=\nAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Thu, 14 Feb 2019 03:50:30 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Tue, 30 Apr 2019 01:49:55 +0000   Tue, 30 Apr 2019 01:49:55 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Tue, 30 Apr 2019 06:45:22 +0000   Thu, 14 Feb 2019 03:50:30 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Tue, 30 Apr 2019 06:45:22 +0000   Thu, 14 Feb 2019 03:50:30 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Tue, 30 Apr 2019 06:45:22 +0000   Thu, 14 Feb 2019 03:50:30 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Tue, 30 Apr 2019 06:45:22 +0000   Thu, 14 Feb 2019 03:57:37 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  10.10.101.12\n  Hostname:    10.10.101.12-master\nCapacity:\n cpu:                4\n ephemeral-storage:  99688900Ki\n hugepages-2Mi:      0\n memory:             8010576Ki\n pods:               63\nAllocatable:\n cpu:                4\n ephemeral-storage:  91873290088\n hugepages-2Mi:      0\n memory:             7498576Ki\n pods:               63\nSystem Info:\n Machine ID:                 b0a9be79668f4797a761637ca2925876\n System UUID:                423C6EC1-97EF-D80E-6C40-C3E0DFF52D35\n Boot ID:                    06fe2b60-b0d8-45b7-9627-fe42fabd188c\n Kernel Version:             3.10.0-693.el7.x86_64\n OS Image:                   CentOS Linux 7 (Core)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.1\n Kubelet Version:            v1.14.1\n Kube-Proxy Version:         v1.14.1\nNon-terminated Pods:         (10 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-c9c03b5e3ad84999-ts5lr    0 (0%)        0 (0%)      0 (0%)           0 (0%)         4m9s\n  kube-system                calico-kube-controllers-6f6fcd8bdf-xhmxh                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         75d\n  kube-system                calico-node-8g7lm                                          250m (6%)     0 (0%)      0 (0%)           0 (0%)         75d\n  kube-system                coredns-674dcd74f8-kmr29                                   100m (2%)     0 (0%)      70Mi (0%)        170Mi (2%)     75d\n  kube-system                coredns-674dcd74f8-xtsvx                                   100m (2%)     0 (0%)      70Mi (0%)        170Mi (2%)     75d\n  kube-system                etcd-10.10.101.12-master                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         75d\n  kube-system                kube-apiserver-10.10.101.12-master                         250m (6%)     0 (0%)      0 (0%)           0 (0%)         75d\n  kube-system                kube-controller-manager-10.10.101.12-master                200m (5%)     0 (0%)      0 (0%)           0 (0%)         75d\n  kube-system                kube-proxy-ftmpw                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         75d\n  kube-system                kube-scheduler-10.10.101.12-master                         100m (2%)     0 (0%)      0 (0%)           0 (0%)         75d\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                1 (25%)     0 (0%)\n  memory             140Mi (1%)  340Mi (4%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:              <none>\n"
Apr 30 06:45:26.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 describe namespace kubectl-8000'
Apr 30 06:45:26.901: INFO: stderr: ""
Apr 30 06:45:26.901: INFO: stdout: "Name:         kubectl-8000\nLabels:       e2e-framework=kubectl\n              e2e-run=fbbd8dd1-6b12-11e9-845c-f234dad8a085\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 06:45:26.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8000" for this suite.
Apr 30 06:45:48.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:45:49.094: INFO: namespace kubectl-8000 deletion completed in 22.185314907s

• [SLOW TEST:28.931 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:45:49.095: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Apr 30 06:45:49.161: INFO: Waiting up to 5m0s for pod "pod-96e2bb5a-6b13-11e9-845c-f234dad8a085" in namespace "emptydir-6597" to be "success or failure"
Apr 30 06:45:49.169: INFO: Pod "pod-96e2bb5a-6b13-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 7.463044ms
Apr 30 06:45:51.176: INFO: Pod "pod-96e2bb5a-6b13-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0143661s
Apr 30 06:45:53.183: INFO: Pod "pod-96e2bb5a-6b13-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02134717s
STEP: Saw pod success
Apr 30 06:45:53.183: INFO: Pod "pod-96e2bb5a-6b13-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 06:45:53.188: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-96e2bb5a-6b13-11e9-845c-f234dad8a085 container test-container: <nil>
STEP: delete the pod
Apr 30 06:45:53.222: INFO: Waiting for pod pod-96e2bb5a-6b13-11e9-845c-f234dad8a085 to disappear
Apr 30 06:45:53.226: INFO: Pod pod-96e2bb5a-6b13-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 06:45:53.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6597" for this suite.
Apr 30 06:45:59.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:45:59.442: INFO: namespace emptydir-6597 deletion completed in 6.2095004s

• [SLOW TEST:10.348 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:45:59.444: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Apr 30 06:45:59.515: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 30 06:45:59.532: INFO: Waiting for terminating namespaces to be deleted...
Apr 30 06:45:59.543: INFO: 
Logging pods the kubelet thinks is on node 10.10.101.13-slave before test
Apr 30 06:45:59.555: INFO: kube-proxy-wdhkq from kube-system started at 2019-04-26 12:57:53 +0000 UTC (1 container statuses recorded)
Apr 30 06:45:59.556: INFO: 	Container kube-proxy ready: true, restart count 2
Apr 30 06:45:59.556: INFO: calico-node-xcvhz from kube-system started at 2019-04-26 12:57:53 +0000 UTC (2 container statuses recorded)
Apr 30 06:45:59.556: INFO: 	Container calico-node ready: true, restart count 1
Apr 30 06:45:59.556: INFO: 	Container install-cni ready: true, restart count 1
Apr 30 06:45:59.556: INFO: sonobuoy-systemd-logs-daemon-set-c9c03b5e3ad84999-rnw89 from heptio-sonobuoy started at 2019-04-30 06:41:17 +0000 UTC (2 container statuses recorded)
Apr 30 06:45:59.556: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 30 06:45:59.556: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 30 06:45:59.556: INFO: 
Logging pods the kubelet thinks is on node 10.10.101.14-slave before test
Apr 30 06:45:59.570: INFO: sonobuoy from heptio-sonobuoy started at 2019-04-30 06:41:03 +0000 UTC (1 container statuses recorded)
Apr 30 06:45:59.570: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 30 06:45:59.570: INFO: sonobuoy-systemd-logs-daemon-set-c9c03b5e3ad84999-6hg7k from heptio-sonobuoy started at 2019-04-30 06:41:11 +0000 UTC (2 container statuses recorded)
Apr 30 06:45:59.570: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 30 06:45:59.570: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 30 06:45:59.570: INFO: kube-proxy-4v6l9 from kube-system started at 2019-04-26 13:01:00 +0000 UTC (1 container statuses recorded)
Apr 30 06:45:59.570: INFO: 	Container kube-proxy ready: true, restart count 2
Apr 30 06:45:59.570: INFO: calico-node-mpdg4 from kube-system started at 2019-04-26 13:01:00 +0000 UTC (2 container statuses recorded)
Apr 30 06:45:59.570: INFO: 	Container calico-node ready: true, restart count 1
Apr 30 06:45:59.570: INFO: 	Container install-cni ready: true, restart count 1
Apr 30 06:45:59.570: INFO: sonobuoy-e2e-job-ac74e570148b466e from heptio-sonobuoy started at 2019-04-30 06:41:11 +0000 UTC (2 container statuses recorded)
Apr 30 06:45:59.570: INFO: 	Container e2e ready: true, restart count 0
Apr 30 06:45:59.570: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.159a2d9b275bd3f5], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 06:46:00.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-737" for this suite.
Apr 30 06:46:06.681: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:46:06.860: INFO: namespace sched-pred-737 deletion completed in 6.199910413s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.417 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:46:06.861: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the initial replication controller
Apr 30 06:46:06.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 create -f - --namespace=kubectl-3238'
Apr 30 06:46:07.329: INFO: stderr: ""
Apr 30 06:46:07.329: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 30 06:46:07.329: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3238'
Apr 30 06:46:07.594: INFO: stderr: ""
Apr 30 06:46:07.595: INFO: stdout: "update-demo-nautilus-wjngq update-demo-nautilus-x49b5 "
Apr 30 06:46:07.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pods update-demo-nautilus-wjngq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3238'
Apr 30 06:46:07.829: INFO: stderr: ""
Apr 30 06:46:07.829: INFO: stdout: ""
Apr 30 06:46:07.829: INFO: update-demo-nautilus-wjngq is created but not running
Apr 30 06:46:12.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3238'
Apr 30 06:46:13.076: INFO: stderr: ""
Apr 30 06:46:13.076: INFO: stdout: "update-demo-nautilus-wjngq update-demo-nautilus-x49b5 "
Apr 30 06:46:13.076: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pods update-demo-nautilus-wjngq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3238'
Apr 30 06:46:13.289: INFO: stderr: ""
Apr 30 06:46:13.289: INFO: stdout: "true"
Apr 30 06:46:13.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pods update-demo-nautilus-wjngq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3238'
Apr 30 06:46:13.481: INFO: stderr: ""
Apr 30 06:46:13.481: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 30 06:46:13.481: INFO: validating pod update-demo-nautilus-wjngq
Apr 30 06:46:13.494: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 30 06:46:13.494: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 30 06:46:13.494: INFO: update-demo-nautilus-wjngq is verified up and running
Apr 30 06:46:13.495: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pods update-demo-nautilus-x49b5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3238'
Apr 30 06:46:13.707: INFO: stderr: ""
Apr 30 06:46:13.707: INFO: stdout: "true"
Apr 30 06:46:13.707: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pods update-demo-nautilus-x49b5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3238'
Apr 30 06:46:13.919: INFO: stderr: ""
Apr 30 06:46:13.919: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 30 06:46:13.919: INFO: validating pod update-demo-nautilus-x49b5
Apr 30 06:46:13.932: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 30 06:46:13.932: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 30 06:46:13.932: INFO: update-demo-nautilus-x49b5 is verified up and running
STEP: rolling-update to new replication controller
Apr 30 06:46:13.937: INFO: scanned /root for discovery docs: <nil>
Apr 30 06:46:13.937: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-3238'
Apr 30 06:46:36.692: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Apr 30 06:46:36.692: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 30 06:46:36.693: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3238'
Apr 30 06:46:36.915: INFO: stderr: ""
Apr 30 06:46:36.915: INFO: stdout: "update-demo-kitten-ddcd8 update-demo-kitten-hrwqj update-demo-nautilus-x49b5 "
STEP: Replicas for name=update-demo: expected=2 actual=3
Apr 30 06:46:41.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3238'
Apr 30 06:46:42.140: INFO: stderr: ""
Apr 30 06:46:42.140: INFO: stdout: "update-demo-kitten-ddcd8 update-demo-kitten-hrwqj "
Apr 30 06:46:42.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pods update-demo-kitten-ddcd8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3238'
Apr 30 06:46:42.386: INFO: stderr: ""
Apr 30 06:46:42.386: INFO: stdout: "true"
Apr 30 06:46:42.386: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pods update-demo-kitten-ddcd8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3238'
Apr 30 06:46:42.630: INFO: stderr: ""
Apr 30 06:46:42.630: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Apr 30 06:46:42.630: INFO: validating pod update-demo-kitten-ddcd8
Apr 30 06:46:42.644: INFO: got data: {
  "image": "kitten.jpg"
}

Apr 30 06:46:42.644: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Apr 30 06:46:42.644: INFO: update-demo-kitten-ddcd8 is verified up and running
Apr 30 06:46:42.644: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pods update-demo-kitten-hrwqj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3238'
Apr 30 06:46:42.894: INFO: stderr: ""
Apr 30 06:46:42.894: INFO: stdout: "true"
Apr 30 06:46:42.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pods update-demo-kitten-hrwqj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3238'
Apr 30 06:46:43.129: INFO: stderr: ""
Apr 30 06:46:43.129: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Apr 30 06:46:43.129: INFO: validating pod update-demo-kitten-hrwqj
Apr 30 06:46:43.140: INFO: got data: {
  "image": "kitten.jpg"
}

Apr 30 06:46:43.140: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Apr 30 06:46:43.140: INFO: update-demo-kitten-hrwqj is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 06:46:43.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3238" for this suite.
Apr 30 06:47:05.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:47:05.375: INFO: namespace kubectl-3238 deletion completed in 22.227817157s

• [SLOW TEST:58.515 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:47:05.376: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-c45c9ade-6b13-11e9-845c-f234dad8a085
STEP: Creating a pod to test consume configMaps
Apr 30 06:47:05.474: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c45da4ec-6b13-11e9-845c-f234dad8a085" in namespace "projected-4593" to be "success or failure"
Apr 30 06:47:05.483: INFO: Pod "pod-projected-configmaps-c45da4ec-6b13-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 9.567766ms
Apr 30 06:47:07.492: INFO: Pod "pod-projected-configmaps-c45da4ec-6b13-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018093393s
Apr 30 06:47:09.499: INFO: Pod "pod-projected-configmaps-c45da4ec-6b13-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024797046s
STEP: Saw pod success
Apr 30 06:47:09.499: INFO: Pod "pod-projected-configmaps-c45da4ec-6b13-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 06:47:09.505: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-projected-configmaps-c45da4ec-6b13-11e9-845c-f234dad8a085 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 30 06:47:09.546: INFO: Waiting for pod pod-projected-configmaps-c45da4ec-6b13-11e9-845c-f234dad8a085 to disappear
Apr 30 06:47:09.551: INFO: Pod pod-projected-configmaps-c45da4ec-6b13-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 06:47:09.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4593" for this suite.
Apr 30 06:47:15.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:47:15.770: INFO: namespace projected-4593 deletion completed in 6.21076008s

• [SLOW TEST:10.394 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:47:15.770: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-1413
Apr 30 06:47:19.858: INFO: Started pod liveness-exec in namespace container-probe-1413
STEP: checking the pod's current state and verifying that restartCount is present
Apr 30 06:47:19.863: INFO: Initial restart count of pod liveness-exec is 0
Apr 30 06:48:08.060: INFO: Restart count of pod container-probe-1413/liveness-exec is now 1 (48.19644658s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 06:48:08.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1413" for this suite.
Apr 30 06:48:14.108: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:48:14.272: INFO: namespace container-probe-1413 deletion completed in 6.18479293s

• [SLOW TEST:58.502 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:48:14.272: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Apr 30 06:48:14.350: INFO: Waiting up to 5m0s for pod "pod-ed6c9ba4-6b13-11e9-845c-f234dad8a085" in namespace "emptydir-6932" to be "success or failure"
Apr 30 06:48:14.361: INFO: Pod "pod-ed6c9ba4-6b13-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 11.683207ms
Apr 30 06:48:16.369: INFO: Pod "pod-ed6c9ba4-6b13-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018763457s
Apr 30 06:48:18.375: INFO: Pod "pod-ed6c9ba4-6b13-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025362477s
STEP: Saw pod success
Apr 30 06:48:18.375: INFO: Pod "pod-ed6c9ba4-6b13-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 06:48:18.380: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-ed6c9ba4-6b13-11e9-845c-f234dad8a085 container test-container: <nil>
STEP: delete the pod
Apr 30 06:48:18.452: INFO: Waiting for pod pod-ed6c9ba4-6b13-11e9-845c-f234dad8a085 to disappear
Apr 30 06:48:18.457: INFO: Pod pod-ed6c9ba4-6b13-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 06:48:18.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6932" for this suite.
Apr 30 06:48:24.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:48:24.656: INFO: namespace emptydir-6932 deletion completed in 6.192388334s

• [SLOW TEST:10.384 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:48:24.656: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-f39e72a4-6b13-11e9-845c-f234dad8a085
STEP: Creating a pod to test consume secrets
Apr 30 06:48:24.747: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f39f40bf-6b13-11e9-845c-f234dad8a085" in namespace "projected-8267" to be "success or failure"
Apr 30 06:48:24.753: INFO: Pod "pod-projected-secrets-f39f40bf-6b13-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 6.025133ms
Apr 30 06:48:26.761: INFO: Pod "pod-projected-secrets-f39f40bf-6b13-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01403352s
Apr 30 06:48:28.770: INFO: Pod "pod-projected-secrets-f39f40bf-6b13-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023170837s
STEP: Saw pod success
Apr 30 06:48:28.770: INFO: Pod "pod-projected-secrets-f39f40bf-6b13-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 06:48:28.778: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-projected-secrets-f39f40bf-6b13-11e9-845c-f234dad8a085 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 30 06:48:28.814: INFO: Waiting for pod pod-projected-secrets-f39f40bf-6b13-11e9-845c-f234dad8a085 to disappear
Apr 30 06:48:28.818: INFO: Pod pod-projected-secrets-f39f40bf-6b13-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 06:48:28.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8267" for this suite.
Apr 30 06:48:34.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:48:35.018: INFO: namespace projected-8267 deletion completed in 6.191290877s

• [SLOW TEST:10.362 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:48:35.019: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1455
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 30 06:48:35.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=kubectl-6381'
Apr 30 06:48:35.324: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr 30 06:48:35.325: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1460
Apr 30 06:48:39.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 delete deployment e2e-test-nginx-deployment --namespace=kubectl-6381'
Apr 30 06:48:39.608: INFO: stderr: ""
Apr 30 06:48:39.608: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 06:48:39.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6381" for this suite.
Apr 30 06:49:01.636: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:49:01.802: INFO: namespace kubectl-6381 deletion completed in 22.18722072s

• [SLOW TEST:26.783 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:49:01.802: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr 30 06:49:01.893: INFO: Waiting up to 5m0s for pod "downward-api-09c2acd6-6b14-11e9-845c-f234dad8a085" in namespace "downward-api-5643" to be "success or failure"
Apr 30 06:49:01.902: INFO: Pod "downward-api-09c2acd6-6b14-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 7.961383ms
Apr 30 06:49:03.910: INFO: Pod "downward-api-09c2acd6-6b14-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016243513s
Apr 30 06:49:05.918: INFO: Pod "downward-api-09c2acd6-6b14-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024470446s
STEP: Saw pod success
Apr 30 06:49:05.918: INFO: Pod "downward-api-09c2acd6-6b14-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 06:49:05.924: INFO: Trying to get logs from node 10.10.101.13-slave pod downward-api-09c2acd6-6b14-11e9-845c-f234dad8a085 container dapi-container: <nil>
STEP: delete the pod
Apr 30 06:49:05.963: INFO: Waiting for pod downward-api-09c2acd6-6b14-11e9-845c-f234dad8a085 to disappear
Apr 30 06:49:05.967: INFO: Pod downward-api-09c2acd6-6b14-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 06:49:05.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5643" for this suite.
Apr 30 06:49:11.995: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:49:12.155: INFO: namespace downward-api-5643 deletion completed in 6.17982964s

• [SLOW TEST:10.353 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:49:12.155: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr 30 06:49:12.227: INFO: Waiting up to 5m0s for pod "downward-api-0fec2029-6b14-11e9-845c-f234dad8a085" in namespace "downward-api-906" to be "success or failure"
Apr 30 06:49:12.232: INFO: Pod "downward-api-0fec2029-6b14-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 4.99136ms
Apr 30 06:49:14.238: INFO: Pod "downward-api-0fec2029-6b14-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010982337s
Apr 30 06:49:16.246: INFO: Pod "downward-api-0fec2029-6b14-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019277663s
STEP: Saw pod success
Apr 30 06:49:16.246: INFO: Pod "downward-api-0fec2029-6b14-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 06:49:16.254: INFO: Trying to get logs from node 10.10.101.14-slave pod downward-api-0fec2029-6b14-11e9-845c-f234dad8a085 container dapi-container: <nil>
STEP: delete the pod
Apr 30 06:49:16.291: INFO: Waiting for pod downward-api-0fec2029-6b14-11e9-845c-f234dad8a085 to disappear
Apr 30 06:49:16.300: INFO: Pod downward-api-0fec2029-6b14-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 06:49:16.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-906" for this suite.
Apr 30 06:49:22.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:49:22.489: INFO: namespace downward-api-906 deletion completed in 6.18233371s

• [SLOW TEST:10.334 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:49:22.489: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-1308
Apr 30 06:49:26.578: INFO: Started pod liveness-http in namespace container-probe-1308
STEP: checking the pod's current state and verifying that restartCount is present
Apr 30 06:49:26.583: INFO: Initial restart count of pod liveness-http is 0
Apr 30 06:49:50.686: INFO: Restart count of pod container-probe-1308/liveness-http is now 1 (24.103179423s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 06:49:50.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1308" for this suite.
Apr 30 06:49:56.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:49:56.905: INFO: namespace container-probe-1308 deletion completed in 6.192280344s

• [SLOW TEST:34.416 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:49:56.907: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-2a98f8bf-6b14-11e9-845c-f234dad8a085
STEP: Creating a pod to test consume configMaps
Apr 30 06:49:56.987: INFO: Waiting up to 5m0s for pod "pod-configmaps-2a9a0913-6b14-11e9-845c-f234dad8a085" in namespace "configmap-7570" to be "success or failure"
Apr 30 06:49:56.992: INFO: Pod "pod-configmaps-2a9a0913-6b14-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 5.476206ms
Apr 30 06:49:59.000: INFO: Pod "pod-configmaps-2a9a0913-6b14-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01307033s
Apr 30 06:50:01.007: INFO: Pod "pod-configmaps-2a9a0913-6b14-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019822313s
STEP: Saw pod success
Apr 30 06:50:01.007: INFO: Pod "pod-configmaps-2a9a0913-6b14-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 06:50:01.012: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-configmaps-2a9a0913-6b14-11e9-845c-f234dad8a085 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 30 06:50:01.050: INFO: Waiting for pod pod-configmaps-2a9a0913-6b14-11e9-845c-f234dad8a085 to disappear
Apr 30 06:50:01.056: INFO: Pod pod-configmaps-2a9a0913-6b14-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 06:50:01.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7570" for this suite.
Apr 30 06:50:07.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:50:07.238: INFO: namespace configmap-7570 deletion completed in 6.174421776s

• [SLOW TEST:10.331 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:50:07.239: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-downwardapi-zpwt
STEP: Creating a pod to test atomic-volume-subpath
Apr 30 06:50:07.324: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-zpwt" in namespace "subpath-7200" to be "success or failure"
Apr 30 06:50:07.329: INFO: Pod "pod-subpath-test-downwardapi-zpwt": Phase="Pending", Reason="", readiness=false. Elapsed: 4.85107ms
Apr 30 06:50:09.335: INFO: Pod "pod-subpath-test-downwardapi-zpwt": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011431947s
Apr 30 06:50:11.342: INFO: Pod "pod-subpath-test-downwardapi-zpwt": Phase="Running", Reason="", readiness=true. Elapsed: 4.01881556s
Apr 30 06:50:13.349: INFO: Pod "pod-subpath-test-downwardapi-zpwt": Phase="Running", Reason="", readiness=true. Elapsed: 6.02507797s
Apr 30 06:50:15.358: INFO: Pod "pod-subpath-test-downwardapi-zpwt": Phase="Running", Reason="", readiness=true. Elapsed: 8.034489507s
Apr 30 06:50:17.366: INFO: Pod "pod-subpath-test-downwardapi-zpwt": Phase="Running", Reason="", readiness=true. Elapsed: 10.04186663s
Apr 30 06:50:19.374: INFO: Pod "pod-subpath-test-downwardapi-zpwt": Phase="Running", Reason="", readiness=true. Elapsed: 12.04997725s
Apr 30 06:50:21.381: INFO: Pod "pod-subpath-test-downwardapi-zpwt": Phase="Running", Reason="", readiness=true. Elapsed: 14.057829784s
Apr 30 06:50:23.390: INFO: Pod "pod-subpath-test-downwardapi-zpwt": Phase="Running", Reason="", readiness=true. Elapsed: 16.066400384s
Apr 30 06:50:25.398: INFO: Pod "pod-subpath-test-downwardapi-zpwt": Phase="Running", Reason="", readiness=true. Elapsed: 18.074399474s
Apr 30 06:50:27.406: INFO: Pod "pod-subpath-test-downwardapi-zpwt": Phase="Running", Reason="", readiness=true. Elapsed: 20.08192945s
Apr 30 06:50:29.414: INFO: Pod "pod-subpath-test-downwardapi-zpwt": Phase="Running", Reason="", readiness=true. Elapsed: 22.090252727s
Apr 30 06:50:31.422: INFO: Pod "pod-subpath-test-downwardapi-zpwt": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.09818211s
STEP: Saw pod success
Apr 30 06:50:31.422: INFO: Pod "pod-subpath-test-downwardapi-zpwt" satisfied condition "success or failure"
Apr 30 06:50:31.427: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-subpath-test-downwardapi-zpwt container test-container-subpath-downwardapi-zpwt: <nil>
STEP: delete the pod
Apr 30 06:50:31.467: INFO: Waiting for pod pod-subpath-test-downwardapi-zpwt to disappear
Apr 30 06:50:31.477: INFO: Pod pod-subpath-test-downwardapi-zpwt no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-zpwt
Apr 30 06:50:31.477: INFO: Deleting pod "pod-subpath-test-downwardapi-zpwt" in namespace "subpath-7200"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 06:50:31.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7200" for this suite.
Apr 30 06:50:37.510: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:50:37.738: INFO: namespace subpath-7200 deletion completed in 6.249442726s

• [SLOW TEST:30.499 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:50:37.738: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Apr 30 06:50:37.833: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 30 06:50:37.868: INFO: Waiting for terminating namespaces to be deleted...
Apr 30 06:50:37.877: INFO: 
Logging pods the kubelet thinks is on node 10.10.101.13-slave before test
Apr 30 06:50:37.890: INFO: sonobuoy-systemd-logs-daemon-set-c9c03b5e3ad84999-rnw89 from heptio-sonobuoy started at 2019-04-30 06:41:17 +0000 UTC (2 container statuses recorded)
Apr 30 06:50:37.890: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 30 06:50:37.890: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 30 06:50:37.890: INFO: kube-proxy-wdhkq from kube-system started at 2019-04-26 12:57:53 +0000 UTC (1 container statuses recorded)
Apr 30 06:50:37.890: INFO: 	Container kube-proxy ready: true, restart count 2
Apr 30 06:50:37.890: INFO: calico-node-xcvhz from kube-system started at 2019-04-26 12:57:53 +0000 UTC (2 container statuses recorded)
Apr 30 06:50:37.890: INFO: 	Container calico-node ready: true, restart count 1
Apr 30 06:50:37.890: INFO: 	Container install-cni ready: true, restart count 1
Apr 30 06:50:37.890: INFO: 
Logging pods the kubelet thinks is on node 10.10.101.14-slave before test
Apr 30 06:50:37.905: INFO: sonobuoy from heptio-sonobuoy started at 2019-04-30 06:41:03 +0000 UTC (1 container statuses recorded)
Apr 30 06:50:37.905: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 30 06:50:37.905: INFO: sonobuoy-systemd-logs-daemon-set-c9c03b5e3ad84999-6hg7k from heptio-sonobuoy started at 2019-04-30 06:41:11 +0000 UTC (2 container statuses recorded)
Apr 30 06:50:37.905: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 30 06:50:37.905: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 30 06:50:37.905: INFO: kube-proxy-4v6l9 from kube-system started at 2019-04-26 13:01:00 +0000 UTC (1 container statuses recorded)
Apr 30 06:50:37.905: INFO: 	Container kube-proxy ready: true, restart count 2
Apr 30 06:50:37.905: INFO: calico-node-mpdg4 from kube-system started at 2019-04-26 13:01:00 +0000 UTC (2 container statuses recorded)
Apr 30 06:50:37.905: INFO: 	Container calico-node ready: true, restart count 1
Apr 30 06:50:37.905: INFO: 	Container install-cni ready: true, restart count 1
Apr 30 06:50:37.905: INFO: sonobuoy-e2e-job-ac74e570148b466e from heptio-sonobuoy started at 2019-04-30 06:41:11 +0000 UTC (2 container statuses recorded)
Apr 30 06:50:37.905: INFO: 	Container e2e ready: true, restart count 0
Apr 30 06:50:37.905: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: verifying the node has the label node 10.10.101.13-slave
STEP: verifying the node has the label node 10.10.101.14-slave
Apr 30 06:50:38.030: INFO: Pod sonobuoy requesting resource cpu=0m on Node 10.10.101.14-slave
Apr 30 06:50:38.030: INFO: Pod sonobuoy-e2e-job-ac74e570148b466e requesting resource cpu=0m on Node 10.10.101.14-slave
Apr 30 06:50:38.030: INFO: Pod sonobuoy-systemd-logs-daemon-set-c9c03b5e3ad84999-6hg7k requesting resource cpu=0m on Node 10.10.101.14-slave
Apr 30 06:50:38.030: INFO: Pod sonobuoy-systemd-logs-daemon-set-c9c03b5e3ad84999-rnw89 requesting resource cpu=0m on Node 10.10.101.13-slave
Apr 30 06:50:38.030: INFO: Pod calico-node-mpdg4 requesting resource cpu=250m on Node 10.10.101.14-slave
Apr 30 06:50:38.030: INFO: Pod calico-node-xcvhz requesting resource cpu=250m on Node 10.10.101.13-slave
Apr 30 06:50:38.030: INFO: Pod kube-proxy-4v6l9 requesting resource cpu=0m on Node 10.10.101.14-slave
Apr 30 06:50:38.030: INFO: Pod kube-proxy-wdhkq requesting resource cpu=0m on Node 10.10.101.13-slave
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-431265de-6b14-11e9-845c-f234dad8a085.159a2ddbf9a29306], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3076/filler-pod-431265de-6b14-11e9-845c-f234dad8a085 to 10.10.101.13-slave]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-431265de-6b14-11e9-845c-f234dad8a085.159a2ddc5e69af05], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-431265de-6b14-11e9-845c-f234dad8a085.159a2ddc7293d073], Reason = [Created], Message = [Created container filler-pod-431265de-6b14-11e9-845c-f234dad8a085]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-431265de-6b14-11e9-845c-f234dad8a085.159a2ddc8e78d1a5], Reason = [Started], Message = [Started container filler-pod-431265de-6b14-11e9-845c-f234dad8a085]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-431417b0-6b14-11e9-845c-f234dad8a085.159a2ddafe8b61de], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-431417b0-6b14-11e9-845c-f234dad8a085.159a2ddb12b2511b], Reason = [Created], Message = [Created container filler-pod-431417b0-6b14-11e9-845c-f234dad8a085]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-431417b0-6b14-11e9-845c-f234dad8a085.159a2ddb2cf7a4bd], Reason = [Started], Message = [Started container filler-pod-431417b0-6b14-11e9-845c-f234dad8a085]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-431417b0-6b14-11e9-845c-f234dad8a085.159a2ddbfa5838f5], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3076/filler-pod-431417b0-6b14-11e9-845c-f234dad8a085 to 10.10.101.14-slave]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.159a2ddceabee16c], Reason = [FailedScheduling], Message = [0/3 nodes are available: 1 node(s) had taints that the pod didn't tolerate, 2 Insufficient cpu.]
STEP: removing the label node off the node 10.10.101.13-slave
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.10.101.14-slave
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 06:50:43.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3076" for this suite.
Apr 30 06:50:49.179: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:50:49.389: INFO: namespace sched-pred-3076 deletion completed in 6.226862354s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:11.650 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:50:49.389: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-6984
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 30 06:50:49.465: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr 30 06:51:19.616: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.168.6.164:8080/dial?request=hostName&protocol=udp&host=10.168.84.220&port=8081&tries=1'] Namespace:pod-network-test-6984 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 30 06:51:19.616: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
Apr 30 06:51:19.952: INFO: Waiting for endpoints: map[]
Apr 30 06:51:19.962: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.168.6.164:8080/dial?request=hostName&protocol=udp&host=10.168.6.186&port=8081&tries=1'] Namespace:pod-network-test-6984 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 30 06:51:19.962: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
Apr 30 06:51:20.254: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 06:51:20.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6984" for this suite.
Apr 30 06:51:44.287: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:51:44.513: INFO: namespace pod-network-test-6984 deletion completed in 24.250645426s

• [SLOW TEST:55.124 seconds]
[sig-network] Networking
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:51:44.514: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test use defaults
Apr 30 06:51:44.587: INFO: Waiting up to 5m0s for pod "client-containers-6abc8d1a-6b14-11e9-845c-f234dad8a085" in namespace "containers-1921" to be "success or failure"
Apr 30 06:51:44.597: INFO: Pod "client-containers-6abc8d1a-6b14-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 9.608517ms
Apr 30 06:51:46.604: INFO: Pod "client-containers-6abc8d1a-6b14-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01739623s
Apr 30 06:51:48.611: INFO: Pod "client-containers-6abc8d1a-6b14-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0237282s
STEP: Saw pod success
Apr 30 06:51:48.611: INFO: Pod "client-containers-6abc8d1a-6b14-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 06:51:48.616: INFO: Trying to get logs from node 10.10.101.13-slave pod client-containers-6abc8d1a-6b14-11e9-845c-f234dad8a085 container test-container: <nil>
STEP: delete the pod
Apr 30 06:51:48.650: INFO: Waiting for pod client-containers-6abc8d1a-6b14-11e9-845c-f234dad8a085 to disappear
Apr 30 06:51:48.655: INFO: Pod client-containers-6abc8d1a-6b14-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 06:51:48.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1921" for this suite.
Apr 30 06:51:54.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:51:54.887: INFO: namespace containers-1921 deletion completed in 6.21683267s

• [SLOW TEST:10.374 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:51:54.888: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-1229.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-1229.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1229.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-1229.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-1229.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1229.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 30 06:52:01.076: INFO: DNS probes using dns-1229/dns-test-70ec9bfa-6b14-11e9-845c-f234dad8a085 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 06:52:01.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1229" for this suite.
Apr 30 06:52:07.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:52:07.288: INFO: namespace dns-1229 deletion completed in 6.182264176s

• [SLOW TEST:12.400 seconds]
[sig-network] DNS
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:52:07.289: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-6jp8
STEP: Creating a pod to test atomic-volume-subpath
Apr 30 06:52:07.384: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-6jp8" in namespace "subpath-783" to be "success or failure"
Apr 30 06:52:07.394: INFO: Pod "pod-subpath-test-configmap-6jp8": Phase="Pending", Reason="", readiness=false. Elapsed: 10.132064ms
Apr 30 06:52:09.401: INFO: Pod "pod-subpath-test-configmap-6jp8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01745127s
Apr 30 06:52:11.409: INFO: Pod "pod-subpath-test-configmap-6jp8": Phase="Running", Reason="", readiness=true. Elapsed: 4.025084437s
Apr 30 06:52:13.417: INFO: Pod "pod-subpath-test-configmap-6jp8": Phase="Running", Reason="", readiness=true. Elapsed: 6.033507114s
Apr 30 06:52:15.426: INFO: Pod "pod-subpath-test-configmap-6jp8": Phase="Running", Reason="", readiness=true. Elapsed: 8.04201681s
Apr 30 06:52:17.433: INFO: Pod "pod-subpath-test-configmap-6jp8": Phase="Running", Reason="", readiness=true. Elapsed: 10.048797844s
Apr 30 06:52:19.440: INFO: Pod "pod-subpath-test-configmap-6jp8": Phase="Running", Reason="", readiness=true. Elapsed: 12.056151537s
Apr 30 06:52:21.447: INFO: Pod "pod-subpath-test-configmap-6jp8": Phase="Running", Reason="", readiness=true. Elapsed: 14.063652577s
Apr 30 06:52:23.455: INFO: Pod "pod-subpath-test-configmap-6jp8": Phase="Running", Reason="", readiness=true. Elapsed: 16.070846057s
Apr 30 06:52:25.462: INFO: Pod "pod-subpath-test-configmap-6jp8": Phase="Running", Reason="", readiness=true. Elapsed: 18.078213064s
Apr 30 06:52:27.468: INFO: Pod "pod-subpath-test-configmap-6jp8": Phase="Running", Reason="", readiness=true. Elapsed: 20.084560027s
Apr 30 06:52:29.476: INFO: Pod "pod-subpath-test-configmap-6jp8": Phase="Running", Reason="", readiness=true. Elapsed: 22.092301267s
Apr 30 06:52:31.483: INFO: Pod "pod-subpath-test-configmap-6jp8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.099038827s
STEP: Saw pod success
Apr 30 06:52:31.483: INFO: Pod "pod-subpath-test-configmap-6jp8" satisfied condition "success or failure"
Apr 30 06:52:31.489: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-subpath-test-configmap-6jp8 container test-container-subpath-configmap-6jp8: <nil>
STEP: delete the pod
Apr 30 06:52:31.525: INFO: Waiting for pod pod-subpath-test-configmap-6jp8 to disappear
Apr 30 06:52:31.530: INFO: Pod pod-subpath-test-configmap-6jp8 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-6jp8
Apr 30 06:52:31.530: INFO: Deleting pod "pod-subpath-test-configmap-6jp8" in namespace "subpath-783"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 06:52:31.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-783" for this suite.
Apr 30 06:52:37.561: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:52:37.730: INFO: namespace subpath-783 deletion completed in 6.187782523s

• [SLOW TEST:30.441 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:52:37.730: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1108
STEP: creating the pod
Apr 30 06:52:37.805: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 create -f - --namespace=kubectl-9453'
Apr 30 06:52:38.202: INFO: stderr: ""
Apr 30 06:52:38.202: INFO: stdout: "pod/pause created\n"
Apr 30 06:52:38.202: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Apr 30 06:52:38.202: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-9453" to be "running and ready"
Apr 30 06:52:38.210: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 7.392593ms
Apr 30 06:52:40.216: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01391804s
Apr 30 06:52:42.223: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.02088314s
Apr 30 06:52:42.223: INFO: Pod "pause" satisfied condition "running and ready"
Apr 30 06:52:42.223: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: adding the label testing-label with value testing-label-value to a pod
Apr 30 06:52:42.223: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 label pods pause testing-label=testing-label-value --namespace=kubectl-9453'
Apr 30 06:52:42.461: INFO: stderr: ""
Apr 30 06:52:42.461: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Apr 30 06:52:42.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pod pause -L testing-label --namespace=kubectl-9453'
Apr 30 06:52:42.698: INFO: stderr: ""
Apr 30 06:52:42.698: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Apr 30 06:52:42.698: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 label pods pause testing-label- --namespace=kubectl-9453'
Apr 30 06:52:42.953: INFO: stderr: ""
Apr 30 06:52:42.953: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Apr 30 06:52:42.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pod pause -L testing-label --namespace=kubectl-9453'
Apr 30 06:52:43.217: INFO: stderr: ""
Apr 30 06:52:43.217: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1115
STEP: using delete to clean up resources
Apr 30 06:52:43.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 delete --grace-period=0 --force -f - --namespace=kubectl-9453'
Apr 30 06:52:43.433: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 30 06:52:43.433: INFO: stdout: "pod \"pause\" force deleted\n"
Apr 30 06:52:43.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get rc,svc -l name=pause --no-headers --namespace=kubectl-9453'
Apr 30 06:52:43.671: INFO: stderr: "No resources found.\n"
Apr 30 06:52:43.671: INFO: stdout: ""
Apr 30 06:52:43.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pods -l name=pause --namespace=kubectl-9453 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 30 06:52:43.908: INFO: stderr: ""
Apr 30 06:52:43.908: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 06:52:43.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9453" for this suite.
Apr 30 06:52:49.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:52:50.132: INFO: namespace kubectl-9453 deletion completed in 6.21632759s

• [SLOW TEST:12.402 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:52:50.133: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Apr 30 06:52:54.757: INFO: Successfully updated pod "labelsupdate91d8eb21-6b14-11e9-845c-f234dad8a085"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 06:52:58.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-99" for this suite.
Apr 30 06:53:20.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:53:21.106: INFO: namespace projected-99 deletion completed in 22.268520463s

• [SLOW TEST:30.973 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:53:21.107: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-a452a8dd-6b14-11e9-845c-f234dad8a085
STEP: Creating a pod to test consume configMaps
Apr 30 06:53:21.211: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a45389f3-6b14-11e9-845c-f234dad8a085" in namespace "projected-8673" to be "success or failure"
Apr 30 06:53:21.219: INFO: Pod "pod-projected-configmaps-a45389f3-6b14-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 7.855353ms
Apr 30 06:53:23.227: INFO: Pod "pod-projected-configmaps-a45389f3-6b14-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015981467s
Apr 30 06:53:25.235: INFO: Pod "pod-projected-configmaps-a45389f3-6b14-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023596493s
STEP: Saw pod success
Apr 30 06:53:25.235: INFO: Pod "pod-projected-configmaps-a45389f3-6b14-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 06:53:25.240: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-projected-configmaps-a45389f3-6b14-11e9-845c-f234dad8a085 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 30 06:53:25.282: INFO: Waiting for pod pod-projected-configmaps-a45389f3-6b14-11e9-845c-f234dad8a085 to disappear
Apr 30 06:53:25.287: INFO: Pod pod-projected-configmaps-a45389f3-6b14-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 06:53:25.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8673" for this suite.
Apr 30 06:53:31.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:53:31.505: INFO: namespace projected-8673 deletion completed in 6.209918253s

• [SLOW TEST:10.398 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:53:31.506: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 30 06:53:31.606: INFO: (0) /api/v1/nodes/10.10.101.13-slave:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 16.118523ms)
Apr 30 06:53:31.618: INFO: (1) /api/v1/nodes/10.10.101.13-slave:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 11.917613ms)
Apr 30 06:53:31.629: INFO: (2) /api/v1/nodes/10.10.101.13-slave:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 11.021294ms)
Apr 30 06:53:31.639: INFO: (3) /api/v1/nodes/10.10.101.13-slave:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.45042ms)
Apr 30 06:53:31.666: INFO: (4) /api/v1/nodes/10.10.101.13-slave:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 27.53881ms)
Apr 30 06:53:31.693: INFO: (5) /api/v1/nodes/10.10.101.13-slave:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 26.839463ms)
Apr 30 06:53:31.711: INFO: (6) /api/v1/nodes/10.10.101.13-slave:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 14.20656ms)
Apr 30 06:53:31.722: INFO: (7) /api/v1/nodes/10.10.101.13-slave:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 10.63734ms)
Apr 30 06:53:31.730: INFO: (8) /api/v1/nodes/10.10.101.13-slave:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.482703ms)
Apr 30 06:53:31.738: INFO: (9) /api/v1/nodes/10.10.101.13-slave:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.61487ms)
Apr 30 06:53:31.745: INFO: (10) /api/v1/nodes/10.10.101.13-slave:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.022973ms)
Apr 30 06:53:31.753: INFO: (11) /api/v1/nodes/10.10.101.13-slave:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.671536ms)
Apr 30 06:53:31.760: INFO: (12) /api/v1/nodes/10.10.101.13-slave:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.134844ms)
Apr 30 06:53:31.767: INFO: (13) /api/v1/nodes/10.10.101.13-slave:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.195567ms)
Apr 30 06:53:31.774: INFO: (14) /api/v1/nodes/10.10.101.13-slave:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.703416ms)
Apr 30 06:53:31.782: INFO: (15) /api/v1/nodes/10.10.101.13-slave:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.648853ms)
Apr 30 06:53:31.789: INFO: (16) /api/v1/nodes/10.10.101.13-slave:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.777787ms)
Apr 30 06:53:31.795: INFO: (17) /api/v1/nodes/10.10.101.13-slave:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.253054ms)
Apr 30 06:53:31.802: INFO: (18) /api/v1/nodes/10.10.101.13-slave:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.986133ms)
Apr 30 06:53:31.809: INFO: (19) /api/v1/nodes/10.10.101.13-slave:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.15658ms)
[AfterEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 06:53:31.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-7545" for this suite.
Apr 30 06:53:37.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:53:38.020: INFO: namespace proxy-7545 deletion completed in 6.203855943s

• [SLOW TEST:6.514 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:53:38.020: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 06:53:38.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2539" for this suite.
Apr 30 06:53:44.140: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:53:44.301: INFO: namespace kubelet-test-2539 deletion completed in 6.177903047s

• [SLOW TEST:6.281 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:53:44.302: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Apr 30 06:54:15.048: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
	[quantile=0.5] = 12
	[quantile=0.9] = 32
	[quantile=0.99] = 32
For garbage_collector_attempt_to_delete_work_duration:
	[quantile=0.5] = 18
	[quantile=0.9] = 20590
	[quantile=0.99] = 20590
For garbage_collector_attempt_to_orphan_queue_latency:
	[quantile=0.5] = 11
	[quantile=0.9] = 14
	[quantile=0.99] = 14
For garbage_collector_attempt_to_orphan_work_duration:
	[quantile=0.5] = 226062
	[quantile=0.9] = 240269
	[quantile=0.99] = 240269
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
	[quantile=0.5] = 9
	[quantile=0.9] = 15
	[quantile=0.99] = 82
For garbage_collector_graph_changes_work_duration:
	[quantile=0.5] = 28
	[quantile=0.9] = 51
	[quantile=0.99] = 124
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
	[quantile=0.5] = 29
	[quantile=0.9] = 70
	[quantile=0.99] = 149
For namespace_queue_latency_sum:
	[] = 34406
For namespace_queue_latency_count:
	[] = 969
For namespace_retries:
	[] = 981
For namespace_work_duration:
	[quantile=0.5] = 327025
	[quantile=0.9] = 431071
	[quantile=0.99] = 589033
For namespace_work_duration_sum:
	[] = 265556959
For namespace_work_duration_count:
	[] = 969
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 06:54:15.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2427" for this suite.
Apr 30 06:54:21.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:54:21.316: INFO: namespace gc-2427 deletion completed in 6.260764484s

• [SLOW TEST:37.014 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:54:21.316: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 30 06:54:21.454: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c83a9a0d-6b14-11e9-845c-f234dad8a085" in namespace "downward-api-6406" to be "success or failure"
Apr 30 06:54:21.464: INFO: Pod "downwardapi-volume-c83a9a0d-6b14-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 10.201913ms
Apr 30 06:54:23.473: INFO: Pod "downwardapi-volume-c83a9a0d-6b14-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019230916s
Apr 30 06:54:25.481: INFO: Pod "downwardapi-volume-c83a9a0d-6b14-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02661441s
STEP: Saw pod success
Apr 30 06:54:25.481: INFO: Pod "downwardapi-volume-c83a9a0d-6b14-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 06:54:25.486: INFO: Trying to get logs from node 10.10.101.13-slave pod downwardapi-volume-c83a9a0d-6b14-11e9-845c-f234dad8a085 container client-container: <nil>
STEP: delete the pod
Apr 30 06:54:25.569: INFO: Waiting for pod downwardapi-volume-c83a9a0d-6b14-11e9-845c-f234dad8a085 to disappear
Apr 30 06:54:25.580: INFO: Pod downwardapi-volume-c83a9a0d-6b14-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 06:54:25.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6406" for this suite.
Apr 30 06:54:31.625: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:54:31.790: INFO: namespace downward-api-6406 deletion completed in 6.198944177s

• [SLOW TEST:10.474 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:54:31.790: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-4452
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 30 06:54:31.852: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr 30 06:54:53.999: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.168.6.191 8081 | grep -v '^\s*$'] Namespace:pod-network-test-4452 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 30 06:54:54.000: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
Apr 30 06:54:55.284: INFO: Found all expected endpoints: [netserver-0]
Apr 30 06:54:55.290: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.168.84.255 8081 | grep -v '^\s*$'] Namespace:pod-network-test-4452 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 30 06:54:55.290: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
Apr 30 06:54:56.533: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 06:54:56.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4452" for this suite.
Apr 30 06:55:18.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:55:18.729: INFO: namespace pod-network-test-4452 deletion completed in 22.186735577s

• [SLOW TEST:46.939 seconds]
[sig-network] Networking
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:55:18.729: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Apr 30 06:55:18.858: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 06:55:18.863: INFO: Number of nodes with available pods: 0
Apr 30 06:55:18.863: INFO: Node 10.10.101.13-slave is running more than one daemon pod
Apr 30 06:55:19.871: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 06:55:19.876: INFO: Number of nodes with available pods: 0
Apr 30 06:55:19.876: INFO: Node 10.10.101.13-slave is running more than one daemon pod
Apr 30 06:55:20.874: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 06:55:20.889: INFO: Number of nodes with available pods: 0
Apr 30 06:55:20.889: INFO: Node 10.10.101.13-slave is running more than one daemon pod
Apr 30 06:55:21.873: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 06:55:21.879: INFO: Number of nodes with available pods: 0
Apr 30 06:55:21.879: INFO: Node 10.10.101.13-slave is running more than one daemon pod
Apr 30 06:55:22.873: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 06:55:22.881: INFO: Number of nodes with available pods: 0
Apr 30 06:55:22.881: INFO: Node 10.10.101.13-slave is running more than one daemon pod
Apr 30 06:55:23.871: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 06:55:23.878: INFO: Number of nodes with available pods: 2
Apr 30 06:55:23.878: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Apr 30 06:55:23.909: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 06:55:23.915: INFO: Number of nodes with available pods: 1
Apr 30 06:55:23.915: INFO: Node 10.10.101.14-slave is running more than one daemon pod
Apr 30 06:55:24.933: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 06:55:24.940: INFO: Number of nodes with available pods: 1
Apr 30 06:55:24.940: INFO: Node 10.10.101.14-slave is running more than one daemon pod
Apr 30 06:55:25.940: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 06:55:25.947: INFO: Number of nodes with available pods: 1
Apr 30 06:55:25.947: INFO: Node 10.10.101.14-slave is running more than one daemon pod
Apr 30 06:55:26.924: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 06:55:26.929: INFO: Number of nodes with available pods: 1
Apr 30 06:55:26.929: INFO: Node 10.10.101.14-slave is running more than one daemon pod
Apr 30 06:55:27.923: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 06:55:27.929: INFO: Number of nodes with available pods: 1
Apr 30 06:55:27.929: INFO: Node 10.10.101.14-slave is running more than one daemon pod
Apr 30 06:55:28.924: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 06:55:28.929: INFO: Number of nodes with available pods: 1
Apr 30 06:55:28.929: INFO: Node 10.10.101.14-slave is running more than one daemon pod
Apr 30 06:55:29.923: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 06:55:29.929: INFO: Number of nodes with available pods: 1
Apr 30 06:55:29.929: INFO: Node 10.10.101.14-slave is running more than one daemon pod
Apr 30 06:55:30.923: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 06:55:30.929: INFO: Number of nodes with available pods: 1
Apr 30 06:55:30.929: INFO: Node 10.10.101.14-slave is running more than one daemon pod
Apr 30 06:55:31.923: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 06:55:31.929: INFO: Number of nodes with available pods: 1
Apr 30 06:55:31.929: INFO: Node 10.10.101.14-slave is running more than one daemon pod
Apr 30 06:55:32.923: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 06:55:32.929: INFO: Number of nodes with available pods: 1
Apr 30 06:55:32.929: INFO: Node 10.10.101.14-slave is running more than one daemon pod
Apr 30 06:55:33.924: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 06:55:33.929: INFO: Number of nodes with available pods: 1
Apr 30 06:55:33.929: INFO: Node 10.10.101.14-slave is running more than one daemon pod
Apr 30 06:55:34.925: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 06:55:34.931: INFO: Number of nodes with available pods: 1
Apr 30 06:55:34.931: INFO: Node 10.10.101.14-slave is running more than one daemon pod
Apr 30 06:55:35.924: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 06:55:35.930: INFO: Number of nodes with available pods: 1
Apr 30 06:55:35.930: INFO: Node 10.10.101.14-slave is running more than one daemon pod
Apr 30 06:55:36.923: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 06:55:36.930: INFO: Number of nodes with available pods: 1
Apr 30 06:55:36.930: INFO: Node 10.10.101.14-slave is running more than one daemon pod
Apr 30 06:55:37.925: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 06:55:37.932: INFO: Number of nodes with available pods: 1
Apr 30 06:55:37.932: INFO: Node 10.10.101.14-slave is running more than one daemon pod
Apr 30 06:55:38.924: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 06:55:38.930: INFO: Number of nodes with available pods: 1
Apr 30 06:55:38.930: INFO: Node 10.10.101.14-slave is running more than one daemon pod
Apr 30 06:55:39.923: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 06:55:39.928: INFO: Number of nodes with available pods: 1
Apr 30 06:55:39.928: INFO: Node 10.10.101.14-slave is running more than one daemon pod
Apr 30 06:55:40.922: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 06:55:40.929: INFO: Number of nodes with available pods: 1
Apr 30 06:55:40.929: INFO: Node 10.10.101.14-slave is running more than one daemon pod
Apr 30 06:55:41.924: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 06:55:41.931: INFO: Number of nodes with available pods: 1
Apr 30 06:55:41.931: INFO: Node 10.10.101.14-slave is running more than one daemon pod
Apr 30 06:55:42.925: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 06:55:42.931: INFO: Number of nodes with available pods: 2
Apr 30 06:55:42.931: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7109, will wait for the garbage collector to delete the pods
Apr 30 06:55:43.008: INFO: Deleting DaemonSet.extensions daemon-set took: 13.356413ms
Apr 30 06:55:43.309: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.928693ms
Apr 30 06:55:59.316: INFO: Number of nodes with available pods: 0
Apr 30 06:55:59.316: INFO: Number of running nodes: 0, number of available pods: 0
Apr 30 06:55:59.320: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7109/daemonsets","resourceVersion":"667361"},"items":null}

Apr 30 06:55:59.325: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7109/pods","resourceVersion":"667361"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 06:55:59.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7109" for this suite.
Apr 30 06:56:05.375: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:56:05.580: INFO: namespace daemonsets-7109 deletion completed in 6.226326983s

• [SLOW TEST:46.851 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:56:05.580: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-06635310-6b15-11e9-845c-f234dad8a085
STEP: Creating a pod to test consume secrets
Apr 30 06:56:05.761: INFO: Waiting up to 5m0s for pod "pod-secrets-06647ad4-6b15-11e9-845c-f234dad8a085" in namespace "secrets-9127" to be "success or failure"
Apr 30 06:56:05.781: INFO: Pod "pod-secrets-06647ad4-6b15-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 20.385216ms
Apr 30 06:56:07.796: INFO: Pod "pod-secrets-06647ad4-6b15-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03499519s
Apr 30 06:56:09.803: INFO: Pod "pod-secrets-06647ad4-6b15-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042493273s
STEP: Saw pod success
Apr 30 06:56:09.804: INFO: Pod "pod-secrets-06647ad4-6b15-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 06:56:09.809: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-secrets-06647ad4-6b15-11e9-845c-f234dad8a085 container secret-volume-test: <nil>
STEP: delete the pod
Apr 30 06:56:09.841: INFO: Waiting for pod pod-secrets-06647ad4-6b15-11e9-845c-f234dad8a085 to disappear
Apr 30 06:56:09.845: INFO: Pod pod-secrets-06647ad4-6b15-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 06:56:09.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9127" for this suite.
Apr 30 06:56:15.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:56:16.049: INFO: namespace secrets-9127 deletion completed in 6.196265527s

• [SLOW TEST:10.468 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:56:16.049: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 30 06:56:36.149: INFO: Container started at 2019-04-30 06:56:24 +0000 UTC, pod became ready at 2019-04-30 06:56:41 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 06:56:36.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2732" for this suite.
Apr 30 06:56:58.175: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:56:58.347: INFO: namespace container-probe-2732 deletion completed in 22.192194387s

• [SLOW TEST:42.298 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:56:58.349: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 30 06:56:58.431: INFO: Pod name rollover-pod: Found 0 pods out of 1
Apr 30 06:57:03.439: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr 30 06:57:03.440: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Apr 30 06:57:05.462: INFO: Creating deployment "test-rollover-deployment"
Apr 30 06:57:05.484: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Apr 30 06:57:07.502: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Apr 30 06:57:07.512: INFO: Ensure that both replica sets have 1 created replica
Apr 30 06:57:07.521: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Apr 30 06:57:07.533: INFO: Updating deployment test-rollover-deployment
Apr 30 06:57:07.533: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Apr 30 06:57:09.547: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Apr 30 06:57:09.558: INFO: Make sure deployment "test-rollover-deployment" is complete
Apr 30 06:57:09.575: INFO: all replica sets need to contain the pod-template-hash label
Apr 30 06:57:09.575: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692204231, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692204231, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692204233, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692204231, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 30 06:57:11.588: INFO: all replica sets need to contain the pod-template-hash label
Apr 30 06:57:11.589: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692204231, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692204231, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692204237, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692204231, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 30 06:57:13.604: INFO: all replica sets need to contain the pod-template-hash label
Apr 30 06:57:13.604: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692204231, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692204231, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692204237, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692204231, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 30 06:57:15.592: INFO: all replica sets need to contain the pod-template-hash label
Apr 30 06:57:15.593: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692204231, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692204231, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692204237, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692204231, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 30 06:57:17.589: INFO: all replica sets need to contain the pod-template-hash label
Apr 30 06:57:17.589: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692204231, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692204231, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692204237, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692204231, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 30 06:57:19.589: INFO: all replica sets need to contain the pod-template-hash label
Apr 30 06:57:19.589: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692204231, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692204231, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692204237, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692204231, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 30 06:57:21.589: INFO: 
Apr 30 06:57:21.589: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr 30 06:57:21.625: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-4614,SelfLink:/apis/apps/v1/namespaces/deployment-4614/deployments/test-rollover-deployment,UID:2d9036a2-6b15-11e9-924a-005056bc1aae,ResourceVersion:667683,Generation:2,CreationTimestamp:2019-04-30 06:57:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-04-30 06:57:11 +0000 UTC 2019-04-30 06:57:11 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-04-30 06:57:27 +0000 UTC 2019-04-30 06:57:11 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-766b4d6c9d" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Apr 30 06:57:21.632: INFO: New ReplicaSet "test-rollover-deployment-766b4d6c9d" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-766b4d6c9d,GenerateName:,Namespace:deployment-4614,SelfLink:/apis/apps/v1/namespaces/deployment-4614/replicasets/test-rollover-deployment-766b4d6c9d,UID:2ecc5c86-6b15-11e9-924a-005056bc1aae,ResourceVersion:667671,Generation:2,CreationTimestamp:2019-04-30 06:57:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 2d9036a2-6b15-11e9-924a-005056bc1aae 0xc000a1e7c7 0xc000a1e7c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Apr 30 06:57:21.632: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Apr 30 06:57:21.632: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-4614,SelfLink:/apis/apps/v1/namespaces/deployment-4614/replicasets/test-rollover-controller,UID:295c1926-6b15-11e9-924a-005056bc1aae,ResourceVersion:667682,Generation:2,CreationTimestamp:2019-04-30 06:57:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 2d9036a2-6b15-11e9-924a-005056bc1aae 0xc000a1e5d7 0xc000a1e5d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 30 06:57:21.633: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6455657675,GenerateName:,Namespace:deployment-4614,SelfLink:/apis/apps/v1/namespaces/deployment-4614/replicasets/test-rollover-deployment-6455657675,UID:2d95c646-6b15-11e9-924a-005056bc1aae,ResourceVersion:667628,Generation:2,CreationTimestamp:2019-04-30 06:57:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 2d9036a2-6b15-11e9-924a-005056bc1aae 0xc000a1e6c7 0xc000a1e6c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 30 06:57:21.639: INFO: Pod "test-rollover-deployment-766b4d6c9d-xz2bv" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-766b4d6c9d-xz2bv,GenerateName:test-rollover-deployment-766b4d6c9d-,Namespace:deployment-4614,SelfLink:/api/v1/namespaces/deployment-4614/pods/test-rollover-deployment-766b4d6c9d-xz2bv,UID:2ed28ff1-6b15-11e9-924a-005056bc1aae,ResourceVersion:667652,Generation:0,CreationTimestamp:2019-04-30 06:57:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-766b4d6c9d 2ecc5c86-6b15-11e9-924a-005056bc1aae 0xc000a1f367 0xc000a1f368}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vc8qc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vc8qc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-vc8qc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.101.14-slave,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000a1f3d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000a1f3f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 06:57:07 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 06:57:11 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 06:57:11 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 06:57:13 +0000 UTC  }],Message:,Reason:,HostIP:10.10.101.14,PodIP:10.168.84.254,StartTime:2019-04-30 06:57:07 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-04-30 06:57:10 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://81db9ad99a3d499a513a4b91cee604406e0b2a1cad5a88b26cbfb9e8a3a24c08}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 06:57:21.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4614" for this suite.
Apr 30 06:57:27.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:57:27.948: INFO: namespace deployment-4614 deletion completed in 6.30180807s

• [SLOW TEST:29.600 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:57:27.949: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test hostPath mode
Apr 30 06:57:28.038: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-4035" to be "success or failure"
Apr 30 06:57:28.044: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 6.01635ms
Apr 30 06:57:30.050: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0123855s
Apr 30 06:57:32.061: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022866244s
STEP: Saw pod success
Apr 30 06:57:32.061: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Apr 30 06:57:32.068: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Apr 30 06:57:32.133: INFO: Waiting for pod pod-host-path-test to disappear
Apr 30 06:57:32.138: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 06:57:32.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-4035" for this suite.
Apr 30 06:57:38.191: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:57:38.357: INFO: namespace hostpath-4035 deletion completed in 6.20847978s

• [SLOW TEST:10.409 seconds]
[sig-storage] HostPath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:57:38.358: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-3da52a4c-6b15-11e9-845c-f234dad8a085
STEP: Creating a pod to test consume secrets
Apr 30 06:57:38.440: INFO: Waiting up to 5m0s for pod "pod-secrets-3da629fe-6b15-11e9-845c-f234dad8a085" in namespace "secrets-5593" to be "success or failure"
Apr 30 06:57:38.450: INFO: Pod "pod-secrets-3da629fe-6b15-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 9.577574ms
Apr 30 06:57:40.457: INFO: Pod "pod-secrets-3da629fe-6b15-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016704584s
Apr 30 06:57:42.464: INFO: Pod "pod-secrets-3da629fe-6b15-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02395523s
STEP: Saw pod success
Apr 30 06:57:42.464: INFO: Pod "pod-secrets-3da629fe-6b15-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 06:57:42.470: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-secrets-3da629fe-6b15-11e9-845c-f234dad8a085 container secret-volume-test: <nil>
STEP: delete the pod
Apr 30 06:57:42.509: INFO: Waiting for pod pod-secrets-3da629fe-6b15-11e9-845c-f234dad8a085 to disappear
Apr 30 06:57:42.515: INFO: Pod pod-secrets-3da629fe-6b15-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 06:57:42.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5593" for this suite.
Apr 30 06:57:48.545: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 06:57:48.728: INFO: namespace secrets-5593 deletion completed in 6.20470425s

• [SLOW TEST:10.370 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 06:57:48.729: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-2155
Apr 30 06:57:52.842: INFO: Started pod liveness-exec in namespace container-probe-2155
STEP: checking the pod's current state and verifying that restartCount is present
Apr 30 06:57:52.848: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:01:53.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2155" for this suite.
Apr 30 07:01:59.824: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:01:59.987: INFO: namespace container-probe-2155 deletion completed in 6.191425077s

• [SLOW TEST:251.259 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:01:59.989: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service endpoint-test2 in namespace services-4984
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4984 to expose endpoints map[]
Apr 30 07:02:00.082: INFO: Get endpoints failed (7.604466ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Apr 30 07:02:01.090: INFO: successfully validated that service endpoint-test2 in namespace services-4984 exposes endpoints map[] (1.01548716s elapsed)
STEP: Creating pod pod1 in namespace services-4984
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4984 to expose endpoints map[pod1:[80]]
Apr 30 07:02:05.172: INFO: successfully validated that service endpoint-test2 in namespace services-4984 exposes endpoints map[pod1:[80]] (4.068510412s elapsed)
STEP: Creating pod pod2 in namespace services-4984
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4984 to expose endpoints map[pod1:[80] pod2:[80]]
Apr 30 07:02:08.345: INFO: successfully validated that service endpoint-test2 in namespace services-4984 exposes endpoints map[pod1:[80] pod2:[80]] (3.167554328s elapsed)
STEP: Deleting pod pod1 in namespace services-4984
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4984 to expose endpoints map[pod2:[80]]
Apr 30 07:02:09.382: INFO: successfully validated that service endpoint-test2 in namespace services-4984 exposes endpoints map[pod2:[80]] (1.02759899s elapsed)
STEP: Deleting pod pod2 in namespace services-4984
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4984 to expose endpoints map[]
Apr 30 07:02:09.400: INFO: successfully validated that service endpoint-test2 in namespace services-4984 exposes endpoints map[] (8.762ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:02:09.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4984" for this suite.
Apr 30 07:02:31.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:02:31.642: INFO: namespace services-4984 deletion completed in 22.196731014s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:31.653 seconds]
[sig-network] Services
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:02:31.642: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-ec73442b-6b15-11e9-845c-f234dad8a085
STEP: Creating a pod to test consume configMaps
Apr 30 07:02:31.714: INFO: Waiting up to 5m0s for pod "pod-configmaps-ec7438b5-6b15-11e9-845c-f234dad8a085" in namespace "configmap-3971" to be "success or failure"
Apr 30 07:02:31.721: INFO: Pod "pod-configmaps-ec7438b5-6b15-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 6.845363ms
Apr 30 07:02:33.728: INFO: Pod "pod-configmaps-ec7438b5-6b15-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013833323s
Apr 30 07:02:35.736: INFO: Pod "pod-configmaps-ec7438b5-6b15-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02100195s
STEP: Saw pod success
Apr 30 07:02:35.736: INFO: Pod "pod-configmaps-ec7438b5-6b15-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 07:02:35.741: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-configmaps-ec7438b5-6b15-11e9-845c-f234dad8a085 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 30 07:02:35.774: INFO: Waiting for pod pod-configmaps-ec7438b5-6b15-11e9-845c-f234dad8a085 to disappear
Apr 30 07:02:35.779: INFO: Pod pod-configmaps-ec7438b5-6b15-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:02:35.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3971" for this suite.
Apr 30 07:02:41.806: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:02:42.043: INFO: namespace configmap-3971 deletion completed in 6.254626867s

• [SLOW TEST:10.401 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:02:42.044: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-1668
Apr 30 07:02:48.140: INFO: Started pod liveness-http in namespace container-probe-1668
STEP: checking the pod's current state and verifying that restartCount is present
Apr 30 07:02:48.146: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:06:49.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1668" for this suite.
Apr 30 07:06:55.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:06:55.268: INFO: namespace container-probe-1668 deletion completed in 6.198208573s

• [SLOW TEST:253.224 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:06:55.268: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Apr 30 07:06:55.331: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 30 07:06:55.346: INFO: Waiting for terminating namespaces to be deleted...
Apr 30 07:06:55.352: INFO: 
Logging pods the kubelet thinks is on node 10.10.101.13-slave before test
Apr 30 07:06:55.364: INFO: sonobuoy-systemd-logs-daemon-set-c9c03b5e3ad84999-rnw89 from heptio-sonobuoy started at 2019-04-30 06:41:17 +0000 UTC (2 container statuses recorded)
Apr 30 07:06:55.364: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 30 07:06:55.364: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 30 07:06:55.364: INFO: calico-node-xcvhz from kube-system started at 2019-04-26 12:57:53 +0000 UTC (2 container statuses recorded)
Apr 30 07:06:55.364: INFO: 	Container calico-node ready: true, restart count 1
Apr 30 07:06:55.364: INFO: 	Container install-cni ready: true, restart count 1
Apr 30 07:06:55.364: INFO: kube-proxy-wdhkq from kube-system started at 2019-04-26 12:57:53 +0000 UTC (1 container statuses recorded)
Apr 30 07:06:55.364: INFO: 	Container kube-proxy ready: true, restart count 2
Apr 30 07:06:55.364: INFO: 
Logging pods the kubelet thinks is on node 10.10.101.14-slave before test
Apr 30 07:06:55.377: INFO: kube-proxy-4v6l9 from kube-system started at 2019-04-26 13:01:00 +0000 UTC (1 container statuses recorded)
Apr 30 07:06:55.377: INFO: 	Container kube-proxy ready: true, restart count 2
Apr 30 07:06:55.377: INFO: calico-node-mpdg4 from kube-system started at 2019-04-26 13:01:00 +0000 UTC (2 container statuses recorded)
Apr 30 07:06:55.377: INFO: 	Container calico-node ready: true, restart count 1
Apr 30 07:06:55.377: INFO: 	Container install-cni ready: true, restart count 1
Apr 30 07:06:55.377: INFO: sonobuoy-e2e-job-ac74e570148b466e from heptio-sonobuoy started at 2019-04-30 06:41:11 +0000 UTC (2 container statuses recorded)
Apr 30 07:06:55.378: INFO: 	Container e2e ready: true, restart count 0
Apr 30 07:06:55.378: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 30 07:06:55.378: INFO: sonobuoy from heptio-sonobuoy started at 2019-04-30 06:41:03 +0000 UTC (1 container statuses recorded)
Apr 30 07:06:55.378: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 30 07:06:55.378: INFO: sonobuoy-systemd-logs-daemon-set-c9c03b5e3ad84999-6hg7k from heptio-sonobuoy started at 2019-04-30 06:41:11 +0000 UTC (2 container statuses recorded)
Apr 30 07:06:55.378: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 30 07:06:55.378: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-8c087a8b-6b16-11e9-845c-f234dad8a085 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-8c087a8b-6b16-11e9-845c-f234dad8a085 off the node 10.10.101.13-slave
STEP: verifying the node doesn't have the label kubernetes.io/e2e-8c087a8b-6b16-11e9-845c-f234dad8a085
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:07:03.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6467" for this suite.
Apr 30 07:07:23.552: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:07:23.710: INFO: namespace sched-pred-6467 deletion completed in 20.184503714s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:28.442 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:07:23.710: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1414
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 30 07:07:23.778: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-6200'
Apr 30 07:07:24.253: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr 30 07:07:24.253: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: rolling-update to same image controller
Apr 30 07:07:24.267: INFO: scanned /root for discovery docs: <nil>
Apr 30 07:07:24.267: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-6200'
Apr 30 07:07:40.311: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Apr 30 07:07:40.311: INFO: stdout: "Created e2e-test-nginx-rc-3340735a1a33c0d8ada3f877605a0eb7\nScaling up e2e-test-nginx-rc-3340735a1a33c0d8ada3f877605a0eb7 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-3340735a1a33c0d8ada3f877605a0eb7 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-3340735a1a33c0d8ada3f877605a0eb7 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Apr 30 07:07:40.311: INFO: stdout: "Created e2e-test-nginx-rc-3340735a1a33c0d8ada3f877605a0eb7\nScaling up e2e-test-nginx-rc-3340735a1a33c0d8ada3f877605a0eb7 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-3340735a1a33c0d8ada3f877605a0eb7 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-3340735a1a33c0d8ada3f877605a0eb7 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Apr 30 07:07:40.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-6200'
Apr 30 07:07:40.542: INFO: stderr: ""
Apr 30 07:07:40.542: INFO: stdout: "e2e-test-nginx-rc-3340735a1a33c0d8ada3f877605a0eb7-4hbd4 "
Apr 30 07:07:40.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pods e2e-test-nginx-rc-3340735a1a33c0d8ada3f877605a0eb7-4hbd4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6200'
Apr 30 07:07:40.761: INFO: stderr: ""
Apr 30 07:07:40.761: INFO: stdout: "true"
Apr 30 07:07:40.762: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pods e2e-test-nginx-rc-3340735a1a33c0d8ada3f877605a0eb7-4hbd4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6200'
Apr 30 07:07:40.973: INFO: stderr: ""
Apr 30 07:07:40.973: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Apr 30 07:07:40.973: INFO: e2e-test-nginx-rc-3340735a1a33c0d8ada3f877605a0eb7-4hbd4 is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1420
Apr 30 07:07:40.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 delete rc e2e-test-nginx-rc --namespace=kubectl-6200'
Apr 30 07:07:41.197: INFO: stderr: ""
Apr 30 07:07:41.197: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:07:41.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6200" for this suite.
Apr 30 07:07:47.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:07:47.430: INFO: namespace kubectl-6200 deletion completed in 6.225647963s

• [SLOW TEST:23.719 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:07:47.430: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Apr 30 07:07:52.078: INFO: Successfully updated pod "labelsupdatea8af95b8-6b16-11e9-845c-f234dad8a085"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:07:54.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5076" for this suite.
Apr 30 07:08:16.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:08:16.328: INFO: namespace downward-api-5076 deletion completed in 22.202654186s

• [SLOW TEST:28.898 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:08:16.329: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-b9e89fdd-6b16-11e9-845c-f234dad8a085
STEP: Creating a pod to test consume secrets
Apr 30 07:08:16.414: INFO: Waiting up to 5m0s for pod "pod-secrets-b9e963aa-6b16-11e9-845c-f234dad8a085" in namespace "secrets-2831" to be "success or failure"
Apr 30 07:08:16.419: INFO: Pod "pod-secrets-b9e963aa-6b16-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 4.155587ms
Apr 30 07:08:18.426: INFO: Pod "pod-secrets-b9e963aa-6b16-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011267187s
Apr 30 07:08:20.432: INFO: Pod "pod-secrets-b9e963aa-6b16-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017108747s
STEP: Saw pod success
Apr 30 07:08:20.432: INFO: Pod "pod-secrets-b9e963aa-6b16-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 07:08:20.437: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-secrets-b9e963aa-6b16-11e9-845c-f234dad8a085 container secret-env-test: <nil>
STEP: delete the pod
Apr 30 07:08:20.500: INFO: Waiting for pod pod-secrets-b9e963aa-6b16-11e9-845c-f234dad8a085 to disappear
Apr 30 07:08:20.505: INFO: Pod pod-secrets-b9e963aa-6b16-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:08:20.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2831" for this suite.
Apr 30 07:08:26.543: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:08:26.728: INFO: namespace secrets-2831 deletion completed in 6.214943033s

• [SLOW TEST:10.399 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:08:26.728: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-c019dbe2-6b16-11e9-845c-f234dad8a085
STEP: Creating a pod to test consume secrets
Apr 30 07:08:26.809: INFO: Waiting up to 5m0s for pod "pod-secrets-c01ae855-6b16-11e9-845c-f234dad8a085" in namespace "secrets-7826" to be "success or failure"
Apr 30 07:08:26.820: INFO: Pod "pod-secrets-c01ae855-6b16-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 10.9422ms
Apr 30 07:08:28.827: INFO: Pod "pod-secrets-c01ae855-6b16-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018395837s
Apr 30 07:08:30.835: INFO: Pod "pod-secrets-c01ae855-6b16-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0256385s
STEP: Saw pod success
Apr 30 07:08:30.835: INFO: Pod "pod-secrets-c01ae855-6b16-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 07:08:30.840: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-secrets-c01ae855-6b16-11e9-845c-f234dad8a085 container secret-volume-test: <nil>
STEP: delete the pod
Apr 30 07:08:30.875: INFO: Waiting for pod pod-secrets-c01ae855-6b16-11e9-845c-f234dad8a085 to disappear
Apr 30 07:08:30.880: INFO: Pod pod-secrets-c01ae855-6b16-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:08:30.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7826" for this suite.
Apr 30 07:08:36.907: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:08:37.075: INFO: namespace secrets-7826 deletion completed in 6.188253214s

• [SLOW TEST:10.347 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:08:37.076: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override all
Apr 30 07:08:37.149: INFO: Waiting up to 5m0s for pod "client-containers-c645304e-6b16-11e9-845c-f234dad8a085" in namespace "containers-6092" to be "success or failure"
Apr 30 07:08:37.164: INFO: Pod "client-containers-c645304e-6b16-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 14.474243ms
Apr 30 07:08:39.171: INFO: Pod "client-containers-c645304e-6b16-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021719163s
Apr 30 07:08:41.179: INFO: Pod "client-containers-c645304e-6b16-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029983163s
STEP: Saw pod success
Apr 30 07:08:41.179: INFO: Pod "client-containers-c645304e-6b16-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 07:08:41.185: INFO: Trying to get logs from node 10.10.101.13-slave pod client-containers-c645304e-6b16-11e9-845c-f234dad8a085 container test-container: <nil>
STEP: delete the pod
Apr 30 07:08:41.229: INFO: Waiting for pod client-containers-c645304e-6b16-11e9-845c-f234dad8a085 to disappear
Apr 30 07:08:41.234: INFO: Pod client-containers-c645304e-6b16-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:08:41.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6092" for this suite.
Apr 30 07:08:47.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:08:47.424: INFO: namespace containers-6092 deletion completed in 6.183503053s

• [SLOW TEST:10.348 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:08:47.424: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-1974
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 30 07:08:47.488: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr 30 07:09:17.610: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.168.6.137:8080/dial?request=hostName&protocol=http&host=10.168.84.206&port=8080&tries=1'] Namespace:pod-network-test-1974 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 30 07:09:17.610: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
Apr 30 07:09:17.995: INFO: Waiting for endpoints: map[]
Apr 30 07:09:18.001: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.168.6.137:8080/dial?request=hostName&protocol=http&host=10.168.6.189&port=8080&tries=1'] Namespace:pod-network-test-1974 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 30 07:09:18.001: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
Apr 30 07:09:18.260: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:09:18.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1974" for this suite.
Apr 30 07:09:42.293: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:09:42.483: INFO: namespace pod-network-test-1974 deletion completed in 24.214609727s

• [SLOW TEST:55.059 seconds]
[sig-network] Networking
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:09:42.484: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Apr 30 07:09:50.628: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 30 07:09:50.634: INFO: Pod pod-with-prestop-http-hook still exists
Apr 30 07:09:52.635: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 30 07:09:52.642: INFO: Pod pod-with-prestop-http-hook still exists
Apr 30 07:09:54.635: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 30 07:09:54.643: INFO: Pod pod-with-prestop-http-hook still exists
Apr 30 07:09:56.635: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 30 07:09:56.644: INFO: Pod pod-with-prestop-http-hook still exists
Apr 30 07:09:58.635: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 30 07:09:58.642: INFO: Pod pod-with-prestop-http-hook still exists
Apr 30 07:10:00.635: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 30 07:10:00.642: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:10:00.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4945" for this suite.
Apr 30 07:10:22.686: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:10:22.852: INFO: namespace container-lifecycle-hook-4945 deletion completed in 22.185011607s

• [SLOW TEST:40.368 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:10:22.853: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 30 07:10:22.928: INFO: Creating ReplicaSet my-hostname-basic-055373c4-6b17-11e9-845c-f234dad8a085
Apr 30 07:10:22.943: INFO: Pod name my-hostname-basic-055373c4-6b17-11e9-845c-f234dad8a085: Found 0 pods out of 1
Apr 30 07:10:27.950: INFO: Pod name my-hostname-basic-055373c4-6b17-11e9-845c-f234dad8a085: Found 1 pods out of 1
Apr 30 07:10:27.950: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-055373c4-6b17-11e9-845c-f234dad8a085" is running
Apr 30 07:10:27.959: INFO: Pod "my-hostname-basic-055373c4-6b17-11e9-845c-f234dad8a085-n4fn9" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-30 07:10:28 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-30 07:10:32 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-30 07:10:32 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-30 07:10:28 +0000 UTC Reason: Message:}])
Apr 30 07:10:27.959: INFO: Trying to dial the pod
Apr 30 07:10:32.981: INFO: Controller my-hostname-basic-055373c4-6b17-11e9-845c-f234dad8a085: Got expected result from replica 1 [my-hostname-basic-055373c4-6b17-11e9-845c-f234dad8a085-n4fn9]: "my-hostname-basic-055373c4-6b17-11e9-845c-f234dad8a085-n4fn9", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:10:32.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-7670" for this suite.
Apr 30 07:10:39.006: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:10:39.174: INFO: namespace replicaset-7670 deletion completed in 6.185796627s

• [SLOW TEST:16.321 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:10:39.175: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap that has name configmap-test-emptyKey-0f0c521b-6b17-11e9-845c-f234dad8a085
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:10:39.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5190" for this suite.
Apr 30 07:10:45.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:10:45.523: INFO: namespace configmap-5190 deletion completed in 6.273798797s

• [SLOW TEST:6.348 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:10:45.524: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1190
STEP: creating an rc
Apr 30 07:10:45.627: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 create -f - --namespace=kubectl-7186'
Apr 30 07:10:46.126: INFO: stderr: ""
Apr 30 07:10:46.126: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Waiting for Redis master to start.
Apr 30 07:10:47.135: INFO: Selector matched 1 pods for map[app:redis]
Apr 30 07:10:47.135: INFO: Found 0 / 1
Apr 30 07:10:48.135: INFO: Selector matched 1 pods for map[app:redis]
Apr 30 07:10:48.135: INFO: Found 0 / 1
Apr 30 07:10:49.134: INFO: Selector matched 1 pods for map[app:redis]
Apr 30 07:10:49.134: INFO: Found 0 / 1
Apr 30 07:10:50.133: INFO: Selector matched 1 pods for map[app:redis]
Apr 30 07:10:50.133: INFO: Found 1 / 1
Apr 30 07:10:50.133: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 30 07:10:50.140: INFO: Selector matched 1 pods for map[app:redis]
Apr 30 07:10:50.140: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Apr 30 07:10:50.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 logs redis-master-vsqs5 redis-master --namespace=kubectl-7186'
Apr 30 07:10:50.403: INFO: stderr: ""
Apr 30 07:10:50.403: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 30 Apr 07:10:54.767 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 30 Apr 07:10:54.768 # Server started, Redis version 3.2.12\n1:M 30 Apr 07:10:54.769 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 30 Apr 07:10:54.769 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Apr 30 07:10:50.403: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 log redis-master-vsqs5 redis-master --namespace=kubectl-7186 --tail=1'
Apr 30 07:10:50.687: INFO: stderr: ""
Apr 30 07:10:50.688: INFO: stdout: "1:M 30 Apr 07:10:54.769 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Apr 30 07:10:50.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 log redis-master-vsqs5 redis-master --namespace=kubectl-7186 --limit-bytes=1'
Apr 30 07:10:50.997: INFO: stderr: ""
Apr 30 07:10:50.997: INFO: stdout: " "
STEP: exposing timestamps
Apr 30 07:10:50.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 log redis-master-vsqs5 redis-master --namespace=kubectl-7186 --tail=1 --timestamps'
Apr 30 07:10:51.274: INFO: stderr: ""
Apr 30 07:10:51.274: INFO: stdout: "2019-04-30T07:10:54.769575087Z 1:M 30 Apr 07:10:54.769 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Apr 30 07:10:53.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 log redis-master-vsqs5 redis-master --namespace=kubectl-7186 --since=1s'
Apr 30 07:10:54.024: INFO: stderr: ""
Apr 30 07:10:54.024: INFO: stdout: ""
Apr 30 07:10:54.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 log redis-master-vsqs5 redis-master --namespace=kubectl-7186 --since=24h'
Apr 30 07:10:54.274: INFO: stderr: ""
Apr 30 07:10:54.274: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 30 Apr 07:10:54.767 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 30 Apr 07:10:54.768 # Server started, Redis version 3.2.12\n1:M 30 Apr 07:10:54.769 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 30 Apr 07:10:54.769 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1196
STEP: using delete to clean up resources
Apr 30 07:10:54.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 delete --grace-period=0 --force -f - --namespace=kubectl-7186'
Apr 30 07:10:54.507: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 30 07:10:54.507: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Apr 30 07:10:54.507: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get rc,svc -l name=nginx --no-headers --namespace=kubectl-7186'
Apr 30 07:10:54.750: INFO: stderr: "No resources found.\n"
Apr 30 07:10:54.750: INFO: stdout: ""
Apr 30 07:10:54.751: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pods -l name=nginx --namespace=kubectl-7186 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 30 07:10:54.976: INFO: stderr: ""
Apr 30 07:10:54.976: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:10:54.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7186" for this suite.
Apr 30 07:11:01.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:11:01.205: INFO: namespace kubectl-7186 deletion completed in 6.22201693s

• [SLOW TEST:15.681 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:11:01.206: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 30 07:11:01.303: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1c310b7e-6b17-11e9-845c-f234dad8a085" in namespace "projected-3449" to be "success or failure"
Apr 30 07:11:01.311: INFO: Pod "downwardapi-volume-1c310b7e-6b17-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 8.049726ms
Apr 30 07:11:03.318: INFO: Pod "downwardapi-volume-1c310b7e-6b17-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01489138s
Apr 30 07:11:05.325: INFO: Pod "downwardapi-volume-1c310b7e-6b17-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022456236s
STEP: Saw pod success
Apr 30 07:11:05.325: INFO: Pod "downwardapi-volume-1c310b7e-6b17-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 07:11:05.331: INFO: Trying to get logs from node 10.10.101.14-slave pod downwardapi-volume-1c310b7e-6b17-11e9-845c-f234dad8a085 container client-container: <nil>
STEP: delete the pod
Apr 30 07:11:05.377: INFO: Waiting for pod downwardapi-volume-1c310b7e-6b17-11e9-845c-f234dad8a085 to disappear
Apr 30 07:11:05.387: INFO: Pod downwardapi-volume-1c310b7e-6b17-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:11:05.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3449" for this suite.
Apr 30 07:11:11.428: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:11:11.597: INFO: namespace projected-3449 deletion completed in 6.201549s

• [SLOW TEST:10.391 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:11:11.598: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 30 07:11:11.658: INFO: Creating deployment "nginx-deployment"
Apr 30 07:11:11.665: INFO: Waiting for observed generation 1
Apr 30 07:11:13.678: INFO: Waiting for all required pods to come up
Apr 30 07:11:13.686: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Apr 30 07:11:21.710: INFO: Waiting for deployment "nginx-deployment" to complete
Apr 30 07:11:21.721: INFO: Updating deployment "nginx-deployment" with a non-existent image
Apr 30 07:11:21.733: INFO: Updating deployment nginx-deployment
Apr 30 07:11:21.733: INFO: Waiting for observed generation 2
Apr 30 07:11:23.753: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Apr 30 07:11:23.762: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Apr 30 07:11:23.768: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Apr 30 07:11:23.800: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Apr 30 07:11:23.800: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Apr 30 07:11:23.807: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Apr 30 07:11:23.838: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Apr 30 07:11:23.838: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Apr 30 07:11:23.854: INFO: Updating deployment nginx-deployment
Apr 30 07:11:23.854: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Apr 30 07:11:23.870: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Apr 30 07:11:23.884: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr 30 07:11:23.913: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-3432,SelfLink:/apis/apps/v1/namespaces/deployment-3432/deployments/nginx-deployment,UID:25f1a363-6b17-11e9-924a-005056bc1aae,ResourceVersion:670309,Generation:3,CreationTimestamp:2019-04-30 07:11:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[{Progressing True 2019-04-30 07:11:27 +0000 UTC 2019-04-30 07:11:17 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-5f9595f595" is progressing.} {Available False 2019-04-30 07:11:29 +0000 UTC 2019-04-30 07:11:29 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Apr 30 07:11:23.945: INFO: New ReplicaSet "nginx-deployment-5f9595f595" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595,GenerateName:,Namespace:deployment-3432,SelfLink:/apis/apps/v1/namespaces/deployment-3432/replicasets/nginx-deployment-5f9595f595,UID:2bf31c74-6b17-11e9-924a-005056bc1aae,ResourceVersion:670302,Generation:3,CreationTimestamp:2019-04-30 07:11:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 25f1a363-6b17-11e9-924a-005056bc1aae 0xc0022ffd07 0xc0022ffd08}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 30 07:11:23.945: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Apr 30 07:11:23.946: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8,GenerateName:,Namespace:deployment-3432,SelfLink:/apis/apps/v1/namespaces/deployment-3432/replicasets/nginx-deployment-6f478d8d8,UID:25f2d77b-6b17-11e9-924a-005056bc1aae,ResourceVersion:670300,Generation:3,CreationTimestamp:2019-04-30 07:11:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 25f1a363-6b17-11e9-924a-005056bc1aae 0xc0022ffdd7 0xc0022ffdd8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Apr 30 07:11:23.981: INFO: Pod "nginx-deployment-5f9595f595-8mr7r" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-8mr7r,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-3432,SelfLink:/api/v1/namespaces/deployment-3432/pods/nginx-deployment-5f9595f595-8mr7r,UID:2bf55b05-6b17-11e9-924a-005056bc1aae,ResourceVersion:670277,Generation:0,CreationTimestamp:2019-04-30 07:11:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 2bf31c74-6b17-11e9-924a-005056bc1aae 0xc0030fe6b7 0xc0030fe6b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6f2wj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6f2wj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6f2wj true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.101.13-slave,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0030fe720} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0030fe740}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:27 +0000 UTC  }],Message:,Reason:,HostIP:10.10.101.13,PodIP:,StartTime:2019-04-30 07:11:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 07:11:23.982: INFO: Pod "nginx-deployment-5f9595f595-gzqgv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-gzqgv,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-3432,SelfLink:/api/v1/namespaces/deployment-3432/pods/nginx-deployment-5f9595f595-gzqgv,UID:2d445f75-6b17-11e9-924a-005056bc1aae,ResourceVersion:670332,Generation:0,CreationTimestamp:2019-04-30 07:11:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 2bf31c74-6b17-11e9-924a-005056bc1aae 0xc0030fe810 0xc0030fe811}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6f2wj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6f2wj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6f2wj true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0030fe880} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0030fe8a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 07:11:23.982: INFO: Pod "nginx-deployment-5f9595f595-jmmcw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-jmmcw,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-3432,SelfLink:/api/v1/namespaces/deployment-3432/pods/nginx-deployment-5f9595f595-jmmcw,UID:2bf4275e-6b17-11e9-924a-005056bc1aae,ResourceVersion:670260,Generation:0,CreationTimestamp:2019-04-30 07:11:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 2bf31c74-6b17-11e9-924a-005056bc1aae 0xc0030fe910 0xc0030fe911}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6f2wj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6f2wj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6f2wj true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.101.14-slave,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0030fe980} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0030fe9a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:27 +0000 UTC  }],Message:,Reason:,HostIP:10.10.101.14,PodIP:,StartTime:2019-04-30 07:11:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 07:11:23.983: INFO: Pod "nginx-deployment-5f9595f595-nsvcc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-nsvcc,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-3432,SelfLink:/api/v1/namespaces/deployment-3432/pods/nginx-deployment-5f9595f595-nsvcc,UID:2d3e1d38-6b17-11e9-924a-005056bc1aae,ResourceVersion:670336,Generation:0,CreationTimestamp:2019-04-30 07:11:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 2bf31c74-6b17-11e9-924a-005056bc1aae 0xc0030fea70 0xc0030fea71}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6f2wj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6f2wj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6f2wj true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.101.14-slave,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0030feae0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0030feb00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:29 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 07:11:23.984: INFO: Pod "nginx-deployment-5f9595f595-p52bm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-p52bm,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-3432,SelfLink:/api/v1/namespaces/deployment-3432/pods/nginx-deployment-5f9595f595-p52bm,UID:2d3d8602-6b17-11e9-924a-005056bc1aae,ResourceVersion:670323,Generation:0,CreationTimestamp:2019-04-30 07:11:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 2bf31c74-6b17-11e9-924a-005056bc1aae 0xc0030feb80 0xc0030feb81}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6f2wj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6f2wj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6f2wj true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.101.13-slave,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0030febf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0030fec10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:29 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 07:11:23.984: INFO: Pod "nginx-deployment-5f9595f595-pzbw9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-pzbw9,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-3432,SelfLink:/api/v1/namespaces/deployment-3432/pods/nginx-deployment-5f9595f595-pzbw9,UID:2c0243d6-6b17-11e9-924a-005056bc1aae,ResourceVersion:670287,Generation:0,CreationTimestamp:2019-04-30 07:11:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 2bf31c74-6b17-11e9-924a-005056bc1aae 0xc0030fec90 0xc0030fec91}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6f2wj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6f2wj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6f2wj true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.101.13-slave,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0030fed00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0030fed20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:27 +0000 UTC  }],Message:,Reason:,HostIP:10.10.101.13,PodIP:,StartTime:2019-04-30 07:11:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 07:11:23.985: INFO: Pod "nginx-deployment-5f9595f595-q8zq4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-q8zq4,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-3432,SelfLink:/api/v1/namespaces/deployment-3432/pods/nginx-deployment-5f9595f595-q8zq4,UID:2d44d1a8-6b17-11e9-924a-005056bc1aae,ResourceVersion:670333,Generation:0,CreationTimestamp:2019-04-30 07:11:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 2bf31c74-6b17-11e9-924a-005056bc1aae 0xc0030fedf0 0xc0030fedf1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6f2wj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6f2wj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6f2wj true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0030fee60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0030fee80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 07:11:23.985: INFO: Pod "nginx-deployment-5f9595f595-qmddq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-qmddq,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-3432,SelfLink:/api/v1/namespaces/deployment-3432/pods/nginx-deployment-5f9595f595-qmddq,UID:2d44a28b-6b17-11e9-924a-005056bc1aae,ResourceVersion:670334,Generation:0,CreationTimestamp:2019-04-30 07:11:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 2bf31c74-6b17-11e9-924a-005056bc1aae 0xc0030feef0 0xc0030feef1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6f2wj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6f2wj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6f2wj true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0030fef60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0030fef80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 07:11:23.986: INFO: Pod "nginx-deployment-5f9595f595-qmgnq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-qmgnq,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-3432,SelfLink:/api/v1/namespaces/deployment-3432/pods/nginx-deployment-5f9595f595-qmgnq,UID:2bfeb9cd-6b17-11e9-924a-005056bc1aae,ResourceVersion:670279,Generation:0,CreationTimestamp:2019-04-30 07:11:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 2bf31c74-6b17-11e9-924a-005056bc1aae 0xc0030feff0 0xc0030feff1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6f2wj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6f2wj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6f2wj true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.101.14-slave,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0030ff060} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0030ff080}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:27 +0000 UTC  }],Message:,Reason:,HostIP:10.10.101.14,PodIP:,StartTime:2019-04-30 07:11:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 07:11:23.986: INFO: Pod "nginx-deployment-5f9595f595-rv5q8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-rv5q8,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-3432,SelfLink:/api/v1/namespaces/deployment-3432/pods/nginx-deployment-5f9595f595-rv5q8,UID:2d43f758-6b17-11e9-924a-005056bc1aae,ResourceVersion:670331,Generation:0,CreationTimestamp:2019-04-30 07:11:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 2bf31c74-6b17-11e9-924a-005056bc1aae 0xc0030ff150 0xc0030ff151}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6f2wj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6f2wj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6f2wj true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0030ff1c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0030ff1e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 07:11:23.987: INFO: Pod "nginx-deployment-5f9595f595-v866l" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-v866l,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-3432,SelfLink:/api/v1/namespaces/deployment-3432/pods/nginx-deployment-5f9595f595-v866l,UID:2d3a930a-6b17-11e9-924a-005056bc1aae,ResourceVersion:670317,Generation:0,CreationTimestamp:2019-04-30 07:11:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 2bf31c74-6b17-11e9-924a-005056bc1aae 0xc0030ff250 0xc0030ff251}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6f2wj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6f2wj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6f2wj true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.101.14-slave,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0030ff2c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0030ff2e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:29 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 07:11:23.987: INFO: Pod "nginx-deployment-5f9595f595-wsz64" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-wsz64,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-3432,SelfLink:/api/v1/namespaces/deployment-3432/pods/nginx-deployment-5f9595f595-wsz64,UID:2bf5a49f-6b17-11e9-924a-005056bc1aae,ResourceVersion:670265,Generation:0,CreationTimestamp:2019-04-30 07:11:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 2bf31c74-6b17-11e9-924a-005056bc1aae 0xc0030ff360 0xc0030ff361}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6f2wj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6f2wj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6f2wj true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.101.13-slave,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0030ff3d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0030ff3f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:27 +0000 UTC  }],Message:,Reason:,HostIP:10.10.101.13,PodIP:,StartTime:2019-04-30 07:11:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 07:11:23.988: INFO: Pod "nginx-deployment-6f478d8d8-2dj7x" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-2dj7x,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-3432,SelfLink:/api/v1/namespaces/deployment-3432/pods/nginx-deployment-6f478d8d8-2dj7x,UID:25f70999-6b17-11e9-924a-005056bc1aae,ResourceVersion:670200,Generation:0,CreationTimestamp:2019-04-30 07:11:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 25f2d77b-6b17-11e9-924a-005056bc1aae 0xc0030ff4c0 0xc0030ff4c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6f2wj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6f2wj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6f2wj true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.101.14-slave,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0030ff520} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0030ff540}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:19 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:19 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:17 +0000 UTC  }],Message:,Reason:,HostIP:10.10.101.14,PodIP:10.168.84.219,StartTime:2019-04-30 07:11:11 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-30 07:11:18 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://8fa663fabb75aa58d3f80c5f3796f4030f9b56916017a5a0a38ae962be9f4911}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 07:11:23.988: INFO: Pod "nginx-deployment-6f478d8d8-6thwj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-6thwj,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-3432,SelfLink:/api/v1/namespaces/deployment-3432/pods/nginx-deployment-6f478d8d8-6thwj,UID:25f4ed24-6b17-11e9-924a-005056bc1aae,ResourceVersion:670212,Generation:0,CreationTimestamp:2019-04-30 07:11:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 25f2d77b-6b17-11e9-924a-005056bc1aae 0xc0030ff617 0xc0030ff618}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6f2wj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6f2wj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6f2wj true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.101.13-slave,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0030ff680} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0030ff6a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:17 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:25 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:25 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:17 +0000 UTC  }],Message:,Reason:,HostIP:10.10.101.13,PodIP:10.168.6.142,StartTime:2019-04-30 07:11:17 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-30 07:11:24 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://a76a6e1f88c03f8e501cbbea174afc86637057a28c2fb03c3546c84ed2f8c0fa}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 07:11:23.989: INFO: Pod "nginx-deployment-6f478d8d8-8pdr5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-8pdr5,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-3432,SelfLink:/api/v1/namespaces/deployment-3432/pods/nginx-deployment-6f478d8d8-8pdr5,UID:25f6b1aa-6b17-11e9-924a-005056bc1aae,ResourceVersion:670203,Generation:0,CreationTimestamp:2019-04-30 07:11:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 25f2d77b-6b17-11e9-924a-005056bc1aae 0xc0030ff777 0xc0030ff778}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6f2wj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6f2wj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6f2wj true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.101.14-slave,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0030ff7e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0030ff800}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:19 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:19 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:17 +0000 UTC  }],Message:,Reason:,HostIP:10.10.101.14,PodIP:10.168.84.222,StartTime:2019-04-30 07:11:11 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-30 07:11:16 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://7580a8ed39bc70017c0689512afcb04b35b0fe474bbd380f34247b0226fac87e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 07:11:23.990: INFO: Pod "nginx-deployment-6f478d8d8-gt5f8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-gt5f8,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-3432,SelfLink:/api/v1/namespaces/deployment-3432/pods/nginx-deployment-6f478d8d8-gt5f8,UID:2d3dcef7-6b17-11e9-924a-005056bc1aae,ResourceVersion:670327,Generation:0,CreationTimestamp:2019-04-30 07:11:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 25f2d77b-6b17-11e9-924a-005056bc1aae 0xc0030ff8d7 0xc0030ff8d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6f2wj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6f2wj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6f2wj true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.101.13-slave,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0030ff940} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0030ff960}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:29 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 07:11:23.997: INFO: Pod "nginx-deployment-6f478d8d8-j5mxz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-j5mxz,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-3432,SelfLink:/api/v1/namespaces/deployment-3432/pods/nginx-deployment-6f478d8d8-j5mxz,UID:2d37e00b-6b17-11e9-924a-005056bc1aae,ResourceVersion:670325,Generation:0,CreationTimestamp:2019-04-30 07:11:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 25f2d77b-6b17-11e9-924a-005056bc1aae 0xc0030ff9e0 0xc0030ff9e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6f2wj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6f2wj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6f2wj true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.101.13-slave,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0030ffa40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0030ffa60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:29 +0000 UTC  }],Message:,Reason:,HostIP:10.10.101.13,PodIP:,StartTime:2019-04-30 07:11:29 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 07:11:23.998: INFO: Pod "nginx-deployment-6f478d8d8-jml69" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-jml69,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-3432,SelfLink:/api/v1/namespaces/deployment-3432/pods/nginx-deployment-6f478d8d8-jml69,UID:2d3df2d4-6b17-11e9-924a-005056bc1aae,ResourceVersion:670329,Generation:0,CreationTimestamp:2019-04-30 07:11:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 25f2d77b-6b17-11e9-924a-005056bc1aae 0xc0030ffb27 0xc0030ffb28}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6f2wj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6f2wj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6f2wj true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.101.14-slave,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0030ffb90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0030ffbb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:29 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 07:11:23.998: INFO: Pod "nginx-deployment-6f478d8d8-m8w2n" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-m8w2n,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-3432,SelfLink:/api/v1/namespaces/deployment-3432/pods/nginx-deployment-6f478d8d8-m8w2n,UID:25fd61e7-6b17-11e9-924a-005056bc1aae,ResourceVersion:670231,Generation:0,CreationTimestamp:2019-04-30 07:11:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 25f2d77b-6b17-11e9-924a-005056bc1aae 0xc0030ffc30 0xc0030ffc31}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6f2wj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6f2wj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6f2wj true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.101.14-slave,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0030ffc90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0030ffcb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:20 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:20 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:17 +0000 UTC  }],Message:,Reason:,HostIP:10.10.101.14,PodIP:10.168.84.217,StartTime:2019-04-30 07:11:11 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-30 07:11:19 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://ce2fe4da146b8ba13617f4c6ee3052f03783885f3fee29cd6faf19a5155fffef}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 07:11:23.999: INFO: Pod "nginx-deployment-6f478d8d8-ph2xr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-ph2xr,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-3432,SelfLink:/api/v1/namespaces/deployment-3432/pods/nginx-deployment-6f478d8d8-ph2xr,UID:2d39abd6-6b17-11e9-924a-005056bc1aae,ResourceVersion:670314,Generation:0,CreationTimestamp:2019-04-30 07:11:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 25f2d77b-6b17-11e9-924a-005056bc1aae 0xc0030ffd87 0xc0030ffd88}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6f2wj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6f2wj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6f2wj true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.101.13-slave,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0030ffdf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0030ffe10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:29 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 07:11:24.000: INFO: Pod "nginx-deployment-6f478d8d8-q7xwm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-q7xwm,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-3432,SelfLink:/api/v1/namespaces/deployment-3432/pods/nginx-deployment-6f478d8d8-q7xwm,UID:25faac4b-6b17-11e9-924a-005056bc1aae,ResourceVersion:670218,Generation:0,CreationTimestamp:2019-04-30 07:11:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 25f2d77b-6b17-11e9-924a-005056bc1aae 0xc0030ffe90 0xc0030ffe91}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6f2wj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6f2wj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6f2wj true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.101.13-slave,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0030ffef0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0030fff10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:17 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:26 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:26 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:17 +0000 UTC  }],Message:,Reason:,HostIP:10.10.101.13,PodIP:10.168.6.158,StartTime:2019-04-30 07:11:17 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-30 07:11:24 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://b77425c063eebe322a20d4565e850450bb1f4a9aad3cf178a60296a4897470cb}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 07:11:24.001: INFO: Pod "nginx-deployment-6f478d8d8-sgzqw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-sgzqw,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-3432,SelfLink:/api/v1/namespaces/deployment-3432/pods/nginx-deployment-6f478d8d8-sgzqw,UID:2d3de1d7-6b17-11e9-924a-005056bc1aae,ResourceVersion:670326,Generation:0,CreationTimestamp:2019-04-30 07:11:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 25f2d77b-6b17-11e9-924a-005056bc1aae 0xc0030fffe7 0xc0030fffe8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6f2wj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6f2wj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6f2wj true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.101.14-slave,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002184050} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002184070}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:29 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 07:11:24.002: INFO: Pod "nginx-deployment-6f478d8d8-sr2sh" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-sr2sh,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-3432,SelfLink:/api/v1/namespaces/deployment-3432/pods/nginx-deployment-6f478d8d8-sr2sh,UID:25facdf4-6b17-11e9-924a-005056bc1aae,ResourceVersion:670227,Generation:0,CreationTimestamp:2019-04-30 07:11:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 25f2d77b-6b17-11e9-924a-005056bc1aae 0xc0021840f0 0xc0021840f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6f2wj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6f2wj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6f2wj true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.101.14-slave,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002184150} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002184170}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:20 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:20 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:17 +0000 UTC  }],Message:,Reason:,HostIP:10.10.101.14,PodIP:10.168.84.212,StartTime:2019-04-30 07:11:11 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-30 07:11:18 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://b1feafb4960d0de8a94d9c36bcf7664b6b7d6fa3609a45779c84274b62ae35b1}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 07:11:24.002: INFO: Pod "nginx-deployment-6f478d8d8-stnkx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-stnkx,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-3432,SelfLink:/api/v1/namespaces/deployment-3432/pods/nginx-deployment-6f478d8d8-stnkx,UID:2d39d6a7-6b17-11e9-924a-005056bc1aae,ResourceVersion:670316,Generation:0,CreationTimestamp:2019-04-30 07:11:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 25f2d77b-6b17-11e9-924a-005056bc1aae 0xc002184247 0xc002184248}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6f2wj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6f2wj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6f2wj true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.101.13-slave,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021842b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021842d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:29 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 07:11:24.003: INFO: Pod "nginx-deployment-6f478d8d8-svlsz" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-svlsz,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-3432,SelfLink:/api/v1/namespaces/deployment-3432/pods/nginx-deployment-6f478d8d8-svlsz,UID:25fa2040-6b17-11e9-924a-005056bc1aae,ResourceVersion:670224,Generation:0,CreationTimestamp:2019-04-30 07:11:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 25f2d77b-6b17-11e9-924a-005056bc1aae 0xc002184350 0xc002184351}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6f2wj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6f2wj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6f2wj true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.101.13-slave,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021843b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021843d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:17 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:26 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:26 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:17 +0000 UTC  }],Message:,Reason:,HostIP:10.10.101.13,PodIP:10.168.6.154,StartTime:2019-04-30 07:11:17 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-30 07:11:25 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://c8a1d4b787c3d4e54b7006d55677f5507bdc4ea223bfba307bb9672509600506}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 07:11:24.004: INFO: Pod "nginx-deployment-6f478d8d8-tczwm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-tczwm,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-3432,SelfLink:/api/v1/namespaces/deployment-3432/pods/nginx-deployment-6f478d8d8-tczwm,UID:25fd0020-6b17-11e9-924a-005056bc1aae,ResourceVersion:670206,Generation:0,CreationTimestamp:2019-04-30 07:11:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 25f2d77b-6b17-11e9-924a-005056bc1aae 0xc0021844a7 0xc0021844a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6f2wj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6f2wj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6f2wj true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.101.14-slave,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002184510} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002184530}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:19 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:19 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:17 +0000 UTC  }],Message:,Reason:,HostIP:10.10.101.14,PodIP:10.168.84.216,StartTime:2019-04-30 07:11:11 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-30 07:11:17 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://48336014f1cb9c15b5aaefbabc11639ed8fcfaa9c6f3c82aeca13b58c26a0923}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 30 07:11:24.004: INFO: Pod "nginx-deployment-6f478d8d8-v5bml" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-v5bml,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-3432,SelfLink:/api/v1/namespaces/deployment-3432/pods/nginx-deployment-6f478d8d8-v5bml,UID:2d3e1af6-6b17-11e9-924a-005056bc1aae,ResourceVersion:670335,Generation:0,CreationTimestamp:2019-04-30 07:11:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 25f2d77b-6b17-11e9-924a-005056bc1aae 0xc002184607 0xc002184608}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6f2wj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6f2wj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6f2wj true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.101.13-slave,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002184670} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002184690}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:11:29 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:11:24.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3432" for this suite.
Apr 30 07:11:32.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:11:32.447: INFO: namespace deployment-3432 deletion completed in 8.383023694s

• [SLOW TEST:20.850 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:11:32.447: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-6688
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Apr 30 07:11:32.559: INFO: Found 0 stateful pods, waiting for 3
Apr 30 07:11:42.579: INFO: Found 1 stateful pods, waiting for 3
Apr 30 07:11:52.568: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 30 07:11:52.568: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 30 07:11:52.568: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Apr 30 07:11:52.612: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Apr 30 07:12:02.668: INFO: Updating stateful set ss2
Apr 30 07:12:02.694: INFO: Waiting for Pod statefulset-6688/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Apr 30 07:12:12.800: INFO: Found 2 stateful pods, waiting for 3
Apr 30 07:12:22.808: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 30 07:12:22.808: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 30 07:12:22.808: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Apr 30 07:12:22.849: INFO: Updating stateful set ss2
Apr 30 07:12:22.877: INFO: Waiting for Pod statefulset-6688/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 30 07:12:32.915: INFO: Updating stateful set ss2
Apr 30 07:12:32.935: INFO: Waiting for StatefulSet statefulset-6688/ss2 to complete update
Apr 30 07:12:32.935: INFO: Waiting for Pod statefulset-6688/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr 30 07:12:42.949: INFO: Deleting all statefulset in ns statefulset-6688
Apr 30 07:12:42.953: INFO: Scaling statefulset ss2 to 0
Apr 30 07:13:02.992: INFO: Waiting for statefulset status.replicas updated to 0
Apr 30 07:13:03.000: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:13:03.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6688" for this suite.
Apr 30 07:13:09.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:13:09.222: INFO: namespace statefulset-6688 deletion completed in 6.185995947s

• [SLOW TEST:96.774 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:13:09.222: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-687f08e0-6b17-11e9-845c-f234dad8a085
STEP: Creating secret with name s-test-opt-upd-687f098d-6b17-11e9-845c-f234dad8a085
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-687f08e0-6b17-11e9-845c-f234dad8a085
STEP: Updating secret s-test-opt-upd-687f098d-6b17-11e9-845c-f234dad8a085
STEP: Creating secret with name s-test-opt-create-687f09c7-6b17-11e9-845c-f234dad8a085
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:13:17.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7170" for this suite.
Apr 30 07:13:39.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:13:39.724: INFO: namespace projected-7170 deletion completed in 22.189889643s

• [SLOW TEST:30.502 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:13:39.724: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Apr 30 07:13:39.791: INFO: namespace kubectl-1931
Apr 30 07:13:39.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 create -f - --namespace=kubectl-1931'
Apr 30 07:13:40.251: INFO: stderr: ""
Apr 30 07:13:40.251: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Apr 30 07:13:41.258: INFO: Selector matched 1 pods for map[app:redis]
Apr 30 07:13:41.259: INFO: Found 0 / 1
Apr 30 07:13:42.259: INFO: Selector matched 1 pods for map[app:redis]
Apr 30 07:13:42.259: INFO: Found 0 / 1
Apr 30 07:13:43.259: INFO: Selector matched 1 pods for map[app:redis]
Apr 30 07:13:43.259: INFO: Found 0 / 1
Apr 30 07:13:44.261: INFO: Selector matched 1 pods for map[app:redis]
Apr 30 07:13:44.261: INFO: Found 1 / 1
Apr 30 07:13:44.261: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 30 07:13:44.268: INFO: Selector matched 1 pods for map[app:redis]
Apr 30 07:13:44.268: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 30 07:13:44.268: INFO: wait on redis-master startup in kubectl-1931 
Apr 30 07:13:44.268: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 logs redis-master-9rkzf redis-master --namespace=kubectl-1931'
Apr 30 07:13:44.542: INFO: stderr: ""
Apr 30 07:13:44.542: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 30 Apr 07:13:49.013 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 30 Apr 07:13:49.014 # Server started, Redis version 3.2.12\n1:M 30 Apr 07:13:49.015 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 30 Apr 07:13:49.015 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Apr 30 07:13:44.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-1931'
Apr 30 07:13:44.798: INFO: stderr: ""
Apr 30 07:13:44.798: INFO: stdout: "service/rm2 exposed\n"
Apr 30 07:13:44.806: INFO: Service rm2 in namespace kubectl-1931 found.
STEP: exposing service
Apr 30 07:13:46.819: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-1931'
Apr 30 07:13:47.060: INFO: stderr: ""
Apr 30 07:13:47.060: INFO: stdout: "service/rm3 exposed\n"
Apr 30 07:13:47.070: INFO: Service rm3 in namespace kubectl-1931 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:13:49.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1931" for this suite.
Apr 30 07:14:11.107: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:14:11.278: INFO: namespace kubectl-1931 deletion completed in 22.18980979s

• [SLOW TEST:31.554 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create services for rc  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:14:11.280: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-8d782ce3-6b17-11e9-845c-f234dad8a085
STEP: Creating a pod to test consume configMaps
Apr 30 07:14:11.355: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8d790c6c-6b17-11e9-845c-f234dad8a085" in namespace "projected-6311" to be "success or failure"
Apr 30 07:14:11.361: INFO: Pod "pod-projected-configmaps-8d790c6c-6b17-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 5.934037ms
Apr 30 07:14:13.368: INFO: Pod "pod-projected-configmaps-8d790c6c-6b17-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01311316s
Apr 30 07:14:15.376: INFO: Pod "pod-projected-configmaps-8d790c6c-6b17-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020984097s
STEP: Saw pod success
Apr 30 07:14:15.376: INFO: Pod "pod-projected-configmaps-8d790c6c-6b17-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 07:14:15.383: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-projected-configmaps-8d790c6c-6b17-11e9-845c-f234dad8a085 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 30 07:14:15.425: INFO: Waiting for pod pod-projected-configmaps-8d790c6c-6b17-11e9-845c-f234dad8a085 to disappear
Apr 30 07:14:15.432: INFO: Pod pod-projected-configmaps-8d790c6c-6b17-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:14:15.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6311" for this suite.
Apr 30 07:14:21.474: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:14:21.673: INFO: namespace projected-6311 deletion completed in 6.233664836s

• [SLOW TEST:10.393 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:14:21.673: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:177
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:14:21.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1609" for this suite.
Apr 30 07:14:43.785: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:14:43.971: INFO: namespace pods-1609 deletion completed in 22.20589792s

• [SLOW TEST:22.298 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:14:43.971: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 30 07:14:44.074: INFO: (0) /api/v1/nodes/10.10.101.13-slave/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 14.598194ms)
Apr 30 07:14:44.084: INFO: (1) /api/v1/nodes/10.10.101.13-slave/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.564963ms)
Apr 30 07:14:44.092: INFO: (2) /api/v1/nodes/10.10.101.13-slave/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.840536ms)
Apr 30 07:14:44.098: INFO: (3) /api/v1/nodes/10.10.101.13-slave/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.50535ms)
Apr 30 07:14:44.106: INFO: (4) /api/v1/nodes/10.10.101.13-slave/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.904147ms)
Apr 30 07:14:44.122: INFO: (5) /api/v1/nodes/10.10.101.13-slave/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 15.666243ms)
Apr 30 07:14:44.131: INFO: (6) /api/v1/nodes/10.10.101.13-slave/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.441486ms)
Apr 30 07:14:44.137: INFO: (7) /api/v1/nodes/10.10.101.13-slave/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.571356ms)
Apr 30 07:14:44.143: INFO: (8) /api/v1/nodes/10.10.101.13-slave/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.14892ms)
Apr 30 07:14:44.150: INFO: (9) /api/v1/nodes/10.10.101.13-slave/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.08619ms)
Apr 30 07:14:44.158: INFO: (10) /api/v1/nodes/10.10.101.13-slave/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.196634ms)
Apr 30 07:14:44.165: INFO: (11) /api/v1/nodes/10.10.101.13-slave/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.111277ms)
Apr 30 07:14:44.174: INFO: (12) /api/v1/nodes/10.10.101.13-slave/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.165254ms)
Apr 30 07:14:44.181: INFO: (13) /api/v1/nodes/10.10.101.13-slave/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.417943ms)
Apr 30 07:14:44.187: INFO: (14) /api/v1/nodes/10.10.101.13-slave/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.22664ms)
Apr 30 07:14:44.193: INFO: (15) /api/v1/nodes/10.10.101.13-slave/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.485193ms)
Apr 30 07:14:44.201: INFO: (16) /api/v1/nodes/10.10.101.13-slave/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.321797ms)
Apr 30 07:14:44.209: INFO: (17) /api/v1/nodes/10.10.101.13-slave/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.85708ms)
Apr 30 07:14:44.217: INFO: (18) /api/v1/nodes/10.10.101.13-slave/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.003944ms)
Apr 30 07:14:44.230: INFO: (19) /api/v1/nodes/10.10.101.13-slave/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 13.537553ms)
[AfterEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:14:44.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6385" for this suite.
Apr 30 07:14:50.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:14:50.507: INFO: namespace proxy-6385 deletion completed in 6.268177117s

• [SLOW TEST:6.536 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:14:50.507: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-a4dc4148-6b17-11e9-845c-f234dad8a085
STEP: Creating secret with name s-test-opt-upd-a4dc4267-6b17-11e9-845c-f234dad8a085
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-a4dc4148-6b17-11e9-845c-f234dad8a085
STEP: Updating secret s-test-opt-upd-a4dc4267-6b17-11e9-845c-f234dad8a085
STEP: Creating secret with name s-test-opt-create-a4dc42a4-6b17-11e9-845c-f234dad8a085
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:16:19.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1422" for this suite.
Apr 30 07:16:41.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:16:41.868: INFO: namespace secrets-1422 deletion completed in 22.205407366s

• [SLOW TEST:111.361 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:16:41.869: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating all guestbook components
Apr 30 07:16:41.938: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Apr 30 07:16:41.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 create -f - --namespace=kubectl-2015'
Apr 30 07:16:42.369: INFO: stderr: ""
Apr 30 07:16:42.369: INFO: stdout: "service/redis-slave created\n"
Apr 30 07:16:42.370: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Apr 30 07:16:42.370: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 create -f - --namespace=kubectl-2015'
Apr 30 07:16:42.741: INFO: stderr: ""
Apr 30 07:16:42.741: INFO: stdout: "service/redis-master created\n"
Apr 30 07:16:42.750: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Apr 30 07:16:42.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 create -f - --namespace=kubectl-2015'
Apr 30 07:16:43.139: INFO: stderr: ""
Apr 30 07:16:43.139: INFO: stdout: "service/frontend created\n"
Apr 30 07:16:43.139: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Apr 30 07:16:43.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 create -f - --namespace=kubectl-2015'
Apr 30 07:16:43.511: INFO: stderr: ""
Apr 30 07:16:43.511: INFO: stdout: "deployment.apps/frontend created\n"
Apr 30 07:16:43.512: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Apr 30 07:16:43.512: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 create -f - --namespace=kubectl-2015'
Apr 30 07:16:43.878: INFO: stderr: ""
Apr 30 07:16:43.878: INFO: stdout: "deployment.apps/redis-master created\n"
Apr 30 07:16:43.879: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Apr 30 07:16:43.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 create -f - --namespace=kubectl-2015'
Apr 30 07:16:44.238: INFO: stderr: ""
Apr 30 07:16:44.238: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Apr 30 07:16:44.239: INFO: Waiting for all frontend pods to be Running.
Apr 30 07:16:54.292: INFO: Waiting for frontend to serve content.
Apr 30 07:16:54.429: INFO: Trying to add a new entry to the guestbook.
Apr 30 07:16:54.475: INFO: Verifying that added entry can be retrieved.
Apr 30 07:16:54.549: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Apr 30 07:16:59.683: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Apr 30 07:17:04.724: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Apr 30 07:17:09.755: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Apr 30 07:17:14.789: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Apr 30 07:17:19.829: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Apr 30 07:17:24.864: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Apr 30 07:17:29.894: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Apr 30 07:17:34.930: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Apr 30 07:17:39.964: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Apr 30 07:17:44.998: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Apr 30 07:17:50.036: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
STEP: using delete to clean up resources
Apr 30 07:17:55.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 delete --grace-period=0 --force -f - --namespace=kubectl-2015'
Apr 30 07:17:55.658: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 30 07:17:55.658: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Apr 30 07:17:55.659: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 delete --grace-period=0 --force -f - --namespace=kubectl-2015'
Apr 30 07:17:55.981: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 30 07:17:55.982: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Apr 30 07:17:55.982: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 delete --grace-period=0 --force -f - --namespace=kubectl-2015'
Apr 30 07:17:56.257: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 30 07:17:56.257: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Apr 30 07:17:56.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 delete --grace-period=0 --force -f - --namespace=kubectl-2015'
Apr 30 07:17:56.492: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 30 07:17:56.492: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Apr 30 07:17:56.492: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 delete --grace-period=0 --force -f - --namespace=kubectl-2015'
Apr 30 07:17:56.726: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 30 07:17:56.726: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Apr 30 07:17:56.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 delete --grace-period=0 --force -f - --namespace=kubectl-2015'
Apr 30 07:17:56.991: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 30 07:17:56.991: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:17:56.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2015" for this suite.
Apr 30 07:18:41.029: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:18:41.240: INFO: namespace kubectl-2015 deletion completed in 44.242643526s

• [SLOW TEST:119.372 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:18:41.241: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating api versions
Apr 30 07:18:41.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 api-versions'
Apr 30 07:18:41.510: INFO: stderr: ""
Apr 30 07:18:41.511: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:18:41.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2580" for this suite.
Apr 30 07:18:47.540: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:18:47.771: INFO: namespace kubectl-2580 deletion completed in 6.252475037s

• [SLOW TEST:6.530 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:18:47.772: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-325552c9-6b18-11e9-845c-f234dad8a085
STEP: Creating a pod to test consume configMaps
Apr 30 07:18:48.078: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-325760a1-6b18-11e9-845c-f234dad8a085" in namespace "projected-6193" to be "success or failure"
Apr 30 07:18:48.091: INFO: Pod "pod-projected-configmaps-325760a1-6b18-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 13.56136ms
Apr 30 07:18:50.099: INFO: Pod "pod-projected-configmaps-325760a1-6b18-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02107467s
Apr 30 07:18:52.108: INFO: Pod "pod-projected-configmaps-325760a1-6b18-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02986188s
STEP: Saw pod success
Apr 30 07:18:52.108: INFO: Pod "pod-projected-configmaps-325760a1-6b18-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 07:18:52.115: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-projected-configmaps-325760a1-6b18-11e9-845c-f234dad8a085 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 30 07:18:52.190: INFO: Waiting for pod pod-projected-configmaps-325760a1-6b18-11e9-845c-f234dad8a085 to disappear
Apr 30 07:18:52.210: INFO: Pod pod-projected-configmaps-325760a1-6b18-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:18:52.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6193" for this suite.
Apr 30 07:18:58.237: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:18:58.390: INFO: namespace projected-6193 deletion completed in 6.17109619s

• [SLOW TEST:10.619 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:18:58.392: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-389b6002-6b18-11e9-845c-f234dad8a085
STEP: Creating a pod to test consume configMaps
Apr 30 07:18:58.476: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-389c4f3d-6b18-11e9-845c-f234dad8a085" in namespace "projected-8905" to be "success or failure"
Apr 30 07:18:58.481: INFO: Pod "pod-projected-configmaps-389c4f3d-6b18-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 5.43761ms
Apr 30 07:19:00.488: INFO: Pod "pod-projected-configmaps-389c4f3d-6b18-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01203934s
Apr 30 07:19:02.494: INFO: Pod "pod-projected-configmaps-389c4f3d-6b18-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018223853s
STEP: Saw pod success
Apr 30 07:19:02.494: INFO: Pod "pod-projected-configmaps-389c4f3d-6b18-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 07:19:02.504: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-projected-configmaps-389c4f3d-6b18-11e9-845c-f234dad8a085 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 30 07:19:02.549: INFO: Waiting for pod pod-projected-configmaps-389c4f3d-6b18-11e9-845c-f234dad8a085 to disappear
Apr 30 07:19:02.557: INFO: Pod pod-projected-configmaps-389c4f3d-6b18-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:19:02.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8905" for this suite.
Apr 30 07:19:08.582: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:19:08.752: INFO: namespace projected-8905 deletion completed in 6.187763693s

• [SLOW TEST:10.360 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:19:08.753: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-3ec6ec24-6b18-11e9-845c-f234dad8a085
STEP: Creating a pod to test consume configMaps
Apr 30 07:19:08.829: INFO: Waiting up to 5m0s for pod "pod-configmaps-3ec7d763-6b18-11e9-845c-f234dad8a085" in namespace "configmap-3469" to be "success or failure"
Apr 30 07:19:08.837: INFO: Pod "pod-configmaps-3ec7d763-6b18-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 7.576736ms
Apr 30 07:19:10.845: INFO: Pod "pod-configmaps-3ec7d763-6b18-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015080886s
Apr 30 07:19:12.852: INFO: Pod "pod-configmaps-3ec7d763-6b18-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02236703s
STEP: Saw pod success
Apr 30 07:19:12.852: INFO: Pod "pod-configmaps-3ec7d763-6b18-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 07:19:12.857: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-configmaps-3ec7d763-6b18-11e9-845c-f234dad8a085 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 30 07:19:12.900: INFO: Waiting for pod pod-configmaps-3ec7d763-6b18-11e9-845c-f234dad8a085 to disappear
Apr 30 07:19:12.904: INFO: Pod pod-configmaps-3ec7d763-6b18-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:19:12.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3469" for this suite.
Apr 30 07:19:18.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:19:19.095: INFO: namespace configmap-3469 deletion completed in 6.18388652s

• [SLOW TEST:10.342 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:19:19.095: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Apr 30 07:19:19.157: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:19:26.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-825" for this suite.
Apr 30 07:19:48.700: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:19:48.879: INFO: namespace init-container-825 deletion completed in 22.198823033s

• [SLOW TEST:29.784 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:19:48.880: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-7590
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Apr 30 07:19:48.974: INFO: Found 0 stateful pods, waiting for 3
Apr 30 07:19:58.987: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 30 07:19:58.987: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 30 07:19:58.987: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Apr 30 07:20:08.982: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 30 07:20:08.983: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 30 07:20:08.983: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Apr 30 07:20:08.999: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 exec --namespace=statefulset-7590 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 30 07:20:09.482: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 30 07:20:09.482: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 30 07:20:09.482: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Apr 30 07:20:19.531: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Apr 30 07:20:29.568: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 exec --namespace=statefulset-7590 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 30 07:20:30.076: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr 30 07:20:30.077: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 30 07:20:30.077: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 30 07:20:40.129: INFO: Waiting for StatefulSet statefulset-7590/ss2 to complete update
Apr 30 07:20:40.129: INFO: Waiting for Pod statefulset-7590/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 30 07:20:40.129: INFO: Waiting for Pod statefulset-7590/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 30 07:20:50.144: INFO: Waiting for StatefulSet statefulset-7590/ss2 to complete update
Apr 30 07:20:50.144: INFO: Waiting for Pod statefulset-7590/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 30 07:21:00.142: INFO: Waiting for StatefulSet statefulset-7590/ss2 to complete update
STEP: Rolling back to a previous revision
Apr 30 07:21:10.156: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 exec --namespace=statefulset-7590 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 30 07:21:10.664: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 30 07:21:10.664: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 30 07:21:10.664: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 30 07:21:20.712: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Apr 30 07:21:30.748: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 exec --namespace=statefulset-7590 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 30 07:21:31.251: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr 30 07:21:31.251: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 30 07:21:31.251: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 30 07:21:41.288: INFO: Waiting for StatefulSet statefulset-7590/ss2 to complete update
Apr 30 07:21:41.289: INFO: Waiting for Pod statefulset-7590/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Apr 30 07:21:41.289: INFO: Waiting for Pod statefulset-7590/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Apr 30 07:21:51.305: INFO: Waiting for StatefulSet statefulset-7590/ss2 to complete update
Apr 30 07:21:51.305: INFO: Waiting for Pod statefulset-7590/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr 30 07:22:01.301: INFO: Deleting all statefulset in ns statefulset-7590
Apr 30 07:22:01.306: INFO: Scaling statefulset ss2 to 0
Apr 30 07:22:31.356: INFO: Waiting for statefulset status.replicas updated to 0
Apr 30 07:22:31.361: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:22:31.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7590" for this suite.
Apr 30 07:22:37.421: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:22:37.585: INFO: namespace statefulset-7590 deletion completed in 6.190282817s

• [SLOW TEST:168.705 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:22:37.586: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating replication controller my-hostname-basic-bb4108df-6b18-11e9-845c-f234dad8a085
Apr 30 07:22:37.664: INFO: Pod name my-hostname-basic-bb4108df-6b18-11e9-845c-f234dad8a085: Found 0 pods out of 1
Apr 30 07:22:42.671: INFO: Pod name my-hostname-basic-bb4108df-6b18-11e9-845c-f234dad8a085: Found 1 pods out of 1
Apr 30 07:22:42.671: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-bb4108df-6b18-11e9-845c-f234dad8a085" are running
Apr 30 07:22:42.676: INFO: Pod "my-hostname-basic-bb4108df-6b18-11e9-845c-f234dad8a085-g67v8" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-30 07:22:43 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-30 07:22:47 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-30 07:22:47 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-30 07:22:43 +0000 UTC Reason: Message:}])
Apr 30 07:22:42.676: INFO: Trying to dial the pod
Apr 30 07:22:47.715: INFO: Controller my-hostname-basic-bb4108df-6b18-11e9-845c-f234dad8a085: Got expected result from replica 1 [my-hostname-basic-bb4108df-6b18-11e9-845c-f234dad8a085-g67v8]: "my-hostname-basic-bb4108df-6b18-11e9-845c-f234dad8a085-g67v8", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:22:47.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-417" for this suite.
Apr 30 07:22:53.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:22:53.931: INFO: namespace replication-controller-417 deletion completed in 6.20649543s

• [SLOW TEST:16.345 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:22:53.931: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:69
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Registering the sample API server.
Apr 30 07:22:54.907: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Apr 30 07:22:56.993: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692205780, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692205780, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692205780, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692205780, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 30 07:23:01.167: INFO: Waited 2.15705253s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:60
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:23:01.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-1177" for this suite.
Apr 30 07:23:07.709: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:23:07.925: INFO: namespace aggregator-1177 deletion completed in 6.310889573s

• [SLOW TEST:13.994 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:23:07.925: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:23:08.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2328" for this suite.
Apr 30 07:23:14.026: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:23:14.201: INFO: namespace services-2328 deletion completed in 6.193642084s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:6.276 seconds]
[sig-network] Services
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:23:14.201: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-wpxt
STEP: Creating a pod to test atomic-volume-subpath
Apr 30 07:23:14.337: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-wpxt" in namespace "subpath-9846" to be "success or failure"
Apr 30 07:23:14.346: INFO: Pod "pod-subpath-test-configmap-wpxt": Phase="Pending", Reason="", readiness=false. Elapsed: 8.5338ms
Apr 30 07:23:16.354: INFO: Pod "pod-subpath-test-configmap-wpxt": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01600705s
Apr 30 07:23:18.360: INFO: Pod "pod-subpath-test-configmap-wpxt": Phase="Running", Reason="", readiness=true. Elapsed: 4.022485453s
Apr 30 07:23:20.369: INFO: Pod "pod-subpath-test-configmap-wpxt": Phase="Running", Reason="", readiness=true. Elapsed: 6.03113553s
Apr 30 07:23:22.376: INFO: Pod "pod-subpath-test-configmap-wpxt": Phase="Running", Reason="", readiness=true. Elapsed: 8.038779167s
Apr 30 07:23:24.385: INFO: Pod "pod-subpath-test-configmap-wpxt": Phase="Running", Reason="", readiness=true. Elapsed: 10.04755214s
Apr 30 07:23:26.392: INFO: Pod "pod-subpath-test-configmap-wpxt": Phase="Running", Reason="", readiness=true. Elapsed: 12.054849913s
Apr 30 07:23:28.401: INFO: Pod "pod-subpath-test-configmap-wpxt": Phase="Running", Reason="", readiness=true. Elapsed: 14.063398987s
Apr 30 07:23:30.408: INFO: Pod "pod-subpath-test-configmap-wpxt": Phase="Running", Reason="", readiness=true. Elapsed: 16.070386167s
Apr 30 07:23:32.415: INFO: Pod "pod-subpath-test-configmap-wpxt": Phase="Running", Reason="", readiness=true. Elapsed: 18.07782658s
Apr 30 07:23:34.423: INFO: Pod "pod-subpath-test-configmap-wpxt": Phase="Running", Reason="", readiness=true. Elapsed: 20.08548705s
Apr 30 07:23:36.430: INFO: Pod "pod-subpath-test-configmap-wpxt": Phase="Running", Reason="", readiness=true. Elapsed: 22.092598313s
Apr 30 07:23:38.438: INFO: Pod "pod-subpath-test-configmap-wpxt": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.10022146s
STEP: Saw pod success
Apr 30 07:23:38.438: INFO: Pod "pod-subpath-test-configmap-wpxt" satisfied condition "success or failure"
Apr 30 07:23:38.444: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-subpath-test-configmap-wpxt container test-container-subpath-configmap-wpxt: <nil>
STEP: delete the pod
Apr 30 07:23:38.478: INFO: Waiting for pod pod-subpath-test-configmap-wpxt to disappear
Apr 30 07:23:38.484: INFO: Pod pod-subpath-test-configmap-wpxt no longer exists
STEP: Deleting pod pod-subpath-test-configmap-wpxt
Apr 30 07:23:38.484: INFO: Deleting pod "pod-subpath-test-configmap-wpxt" in namespace "subpath-9846"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:23:38.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9846" for this suite.
Apr 30 07:23:44.514: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:23:44.691: INFO: namespace subpath-9846 deletion completed in 6.195182483s

• [SLOW TEST:30.491 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:23:44.692: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-9509/configmap-test-e341799f-6b18-11e9-845c-f234dad8a085
STEP: Creating a pod to test consume configMaps
Apr 30 07:23:44.779: INFO: Waiting up to 5m0s for pod "pod-configmaps-e3426fe6-6b18-11e9-845c-f234dad8a085" in namespace "configmap-9509" to be "success or failure"
Apr 30 07:23:44.784: INFO: Pod "pod-configmaps-e3426fe6-6b18-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 5.013967ms
Apr 30 07:23:46.791: INFO: Pod "pod-configmaps-e3426fe6-6b18-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01234809s
Apr 30 07:23:48.799: INFO: Pod "pod-configmaps-e3426fe6-6b18-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020006217s
STEP: Saw pod success
Apr 30 07:23:48.799: INFO: Pod "pod-configmaps-e3426fe6-6b18-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 07:23:48.804: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-configmaps-e3426fe6-6b18-11e9-845c-f234dad8a085 container env-test: <nil>
STEP: delete the pod
Apr 30 07:23:48.844: INFO: Waiting for pod pod-configmaps-e3426fe6-6b18-11e9-845c-f234dad8a085 to disappear
Apr 30 07:23:48.852: INFO: Pod pod-configmaps-e3426fe6-6b18-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:23:48.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9509" for this suite.
Apr 30 07:23:54.882: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:23:55.054: INFO: namespace configmap-9509 deletion completed in 6.194575743s

• [SLOW TEST:10.362 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:23:55.054: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-e9703081-6b18-11e9-845c-f234dad8a085
STEP: Creating a pod to test consume secrets
Apr 30 07:23:55.208: INFO: Waiting up to 5m0s for pod "pod-secrets-e979d10f-6b18-11e9-845c-f234dad8a085" in namespace "secrets-9051" to be "success or failure"
Apr 30 07:23:55.215: INFO: Pod "pod-secrets-e979d10f-6b18-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 6.908834ms
Apr 30 07:23:57.222: INFO: Pod "pod-secrets-e979d10f-6b18-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013854174s
Apr 30 07:23:59.230: INFO: Pod "pod-secrets-e979d10f-6b18-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021408524s
STEP: Saw pod success
Apr 30 07:23:59.230: INFO: Pod "pod-secrets-e979d10f-6b18-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 07:23:59.236: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-secrets-e979d10f-6b18-11e9-845c-f234dad8a085 container secret-volume-test: <nil>
STEP: delete the pod
Apr 30 07:23:59.273: INFO: Waiting for pod pod-secrets-e979d10f-6b18-11e9-845c-f234dad8a085 to disappear
Apr 30 07:23:59.277: INFO: Pod pod-secrets-e979d10f-6b18-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:23:59.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9051" for this suite.
Apr 30 07:24:05.308: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:24:05.560: INFO: namespace secrets-9051 deletion completed in 6.27531792s
STEP: Destroying namespace "secret-namespace-4923" for this suite.
Apr 30 07:24:11.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:24:11.747: INFO: namespace secret-namespace-4923 deletion completed in 6.187742273s

• [SLOW TEST:16.694 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:24:11.748: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Apr 30 07:24:19.873: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 30 07:24:19.878: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 30 07:24:21.878: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 30 07:24:21.885: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 30 07:24:23.879: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 30 07:24:23.885: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 30 07:24:25.879: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 30 07:24:25.885: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 30 07:24:27.878: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 30 07:24:27.885: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 30 07:24:29.878: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 30 07:24:29.885: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 30 07:24:31.879: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 30 07:24:31.890: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 30 07:24:33.878: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 30 07:24:33.885: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 30 07:24:35.878: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 30 07:24:35.885: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 30 07:24:37.878: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 30 07:24:37.886: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 30 07:24:39.878: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 30 07:24:39.885: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 30 07:24:41.878: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 30 07:24:41.885: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 30 07:24:43.878: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 30 07:24:43.886: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 30 07:24:45.878: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 30 07:24:45.885: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 30 07:24:47.878: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 30 07:24:47.888: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 30 07:24:49.878: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 30 07:24:49.885: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:24:49.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-491" for this suite.
Apr 30 07:25:05.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:25:06.140: INFO: namespace container-lifecycle-hook-491 deletion completed in 16.230816773s

• [SLOW TEST:54.392 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:25:06.140: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:25:10.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8335" for this suite.
Apr 30 07:26:02.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:26:02.454: INFO: namespace kubelet-test-8335 deletion completed in 52.183198086s

• [SLOW TEST:56.314 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a read only busybox container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:26:02.456: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on tmpfs
Apr 30 07:26:02.534: INFO: Waiting up to 5m0s for pod "pod-355e3181-6b19-11e9-845c-f234dad8a085" in namespace "emptydir-6793" to be "success or failure"
Apr 30 07:26:02.540: INFO: Pod "pod-355e3181-6b19-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 5.515243ms
Apr 30 07:26:04.547: INFO: Pod "pod-355e3181-6b19-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012691486s
Apr 30 07:26:06.553: INFO: Pod "pod-355e3181-6b19-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019346593s
STEP: Saw pod success
Apr 30 07:26:06.554: INFO: Pod "pod-355e3181-6b19-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 07:26:06.558: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-355e3181-6b19-11e9-845c-f234dad8a085 container test-container: <nil>
STEP: delete the pod
Apr 30 07:26:06.611: INFO: Waiting for pod pod-355e3181-6b19-11e9-845c-f234dad8a085 to disappear
Apr 30 07:26:06.617: INFO: Pod pod-355e3181-6b19-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:26:06.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6793" for this suite.
Apr 30 07:26:12.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:26:12.827: INFO: namespace emptydir-6793 deletion completed in 6.200511993s

• [SLOW TEST:10.371 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:26:12.827: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 30 07:26:12.914: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3b8d7aad-6b19-11e9-845c-f234dad8a085" in namespace "projected-3113" to be "success or failure"
Apr 30 07:26:12.923: INFO: Pod "downwardapi-volume-3b8d7aad-6b19-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 8.095046ms
Apr 30 07:26:14.930: INFO: Pod "downwardapi-volume-3b8d7aad-6b19-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01604192s
Apr 30 07:26:16.937: INFO: Pod "downwardapi-volume-3b8d7aad-6b19-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02306429s
STEP: Saw pod success
Apr 30 07:26:16.938: INFO: Pod "downwardapi-volume-3b8d7aad-6b19-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 07:26:16.944: INFO: Trying to get logs from node 10.10.101.13-slave pod downwardapi-volume-3b8d7aad-6b19-11e9-845c-f234dad8a085 container client-container: <nil>
STEP: delete the pod
Apr 30 07:26:16.983: INFO: Waiting for pod downwardapi-volume-3b8d7aad-6b19-11e9-845c-f234dad8a085 to disappear
Apr 30 07:26:16.989: INFO: Pod downwardapi-volume-3b8d7aad-6b19-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:26:16.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3113" for this suite.
Apr 30 07:26:23.018: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:26:23.286: INFO: namespace projected-3113 deletion completed in 6.289408556s

• [SLOW TEST:10.459 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:26:23.287: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:26:27.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3344" for this suite.
Apr 30 07:27:11.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:27:11.649: INFO: namespace kubelet-test-3344 deletion completed in 44.245427087s

• [SLOW TEST:48.362 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:27:11.650: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating replication controller svc-latency-rc in namespace svc-latency-1157
I0430 07:27:11.730612      17 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-1157, replica count: 1
I0430 07:27:12.781572      17 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0430 07:27:13.781932      17 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0430 07:27:14.782279      17 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0430 07:27:15.782738      17 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 30 07:27:15.914: INFO: Created: latency-svc-kcqg8
Apr 30 07:27:15.925: INFO: Got endpoints: latency-svc-kcqg8 [42.19906ms]
Apr 30 07:27:15.965: INFO: Created: latency-svc-mhdgl
Apr 30 07:27:15.973: INFO: Got endpoints: latency-svc-mhdgl [46.790163ms]
Apr 30 07:27:16.041: INFO: Created: latency-svc-x77s2
Apr 30 07:27:16.051: INFO: Got endpoints: latency-svc-x77s2 [124.652053ms]
Apr 30 07:27:16.060: INFO: Created: latency-svc-vnkgl
Apr 30 07:27:16.070: INFO: Got endpoints: latency-svc-vnkgl [144.776423ms]
Apr 30 07:27:16.253: INFO: Created: latency-svc-tjg55
Apr 30 07:27:16.265: INFO: Got endpoints: latency-svc-tjg55 [337.986654ms]
Apr 30 07:27:16.279: INFO: Created: latency-svc-cv4w6
Apr 30 07:27:16.294: INFO: Got endpoints: latency-svc-cv4w6 [365.712627ms]
Apr 30 07:27:16.299: INFO: Created: latency-svc-grh2b
Apr 30 07:27:16.306: INFO: Got endpoints: latency-svc-grh2b [378.17733ms]
Apr 30 07:27:16.322: INFO: Created: latency-svc-nrlht
Apr 30 07:27:16.330: INFO: Got endpoints: latency-svc-nrlht [401.349493ms]
Apr 30 07:27:16.352: INFO: Created: latency-svc-c2gqm
Apr 30 07:27:16.357: INFO: Got endpoints: latency-svc-c2gqm [427.499023ms]
Apr 30 07:27:16.386: INFO: Created: latency-svc-2vfdm
Apr 30 07:27:16.392: INFO: Got endpoints: latency-svc-2vfdm [461.333317ms]
Apr 30 07:27:16.410: INFO: Created: latency-svc-c5xfm
Apr 30 07:27:16.419: INFO: Got endpoints: latency-svc-c5xfm [487.532034ms]
Apr 30 07:27:16.428: INFO: Created: latency-svc-vpbtt
Apr 30 07:27:16.440: INFO: Got endpoints: latency-svc-vpbtt [509.252597ms]
Apr 30 07:27:16.452: INFO: Created: latency-svc-ws547
Apr 30 07:27:16.474: INFO: Got endpoints: latency-svc-ws547 [54.873347ms]
Apr 30 07:27:16.488: INFO: Created: latency-svc-26556
Apr 30 07:27:16.496: INFO: Got endpoints: latency-svc-26556 [564.98213ms]
Apr 30 07:27:16.524: INFO: Created: latency-svc-qhnpz
Apr 30 07:27:16.533: INFO: Got endpoints: latency-svc-qhnpz [601.270277ms]
Apr 30 07:27:16.550: INFO: Created: latency-svc-9zd4n
Apr 30 07:27:16.561: INFO: Got endpoints: latency-svc-9zd4n [628.74224ms]
Apr 30 07:27:16.566: INFO: Created: latency-svc-2mgj9
Apr 30 07:27:16.576: INFO: Got endpoints: latency-svc-2mgj9 [644.349577ms]
Apr 30 07:27:16.580: INFO: Created: latency-svc-54hrj
Apr 30 07:27:16.596: INFO: Got endpoints: latency-svc-54hrj [623.102603ms]
Apr 30 07:27:16.609: INFO: Created: latency-svc-pbkh2
Apr 30 07:27:16.622: INFO: Got endpoints: latency-svc-pbkh2 [570.6562ms]
Apr 30 07:27:16.623: INFO: Created: latency-svc-4np97
Apr 30 07:27:16.631: INFO: Got endpoints: latency-svc-4np97 [561.230093ms]
Apr 30 07:27:16.668: INFO: Created: latency-svc-rc7tm
Apr 30 07:27:16.677: INFO: Got endpoints: latency-svc-rc7tm [411.865917ms]
Apr 30 07:27:16.699: INFO: Created: latency-svc-nkrj6
Apr 30 07:27:16.723: INFO: Got endpoints: latency-svc-nkrj6 [429.234836ms]
Apr 30 07:27:16.731: INFO: Created: latency-svc-dzsdl
Apr 30 07:27:16.740: INFO: Got endpoints: latency-svc-dzsdl [433.785556ms]
Apr 30 07:27:16.763: INFO: Created: latency-svc-m4kkb
Apr 30 07:27:16.787: INFO: Got endpoints: latency-svc-m4kkb [456.631773ms]
Apr 30 07:27:16.793: INFO: Created: latency-svc-9xf45
Apr 30 07:27:16.801: INFO: Got endpoints: latency-svc-9xf45 [443.965227ms]
Apr 30 07:27:16.811: INFO: Created: latency-svc-qv42j
Apr 30 07:27:16.823: INFO: Got endpoints: latency-svc-qv42j [430.66223ms]
Apr 30 07:27:16.871: INFO: Created: latency-svc-65s27
Apr 30 07:27:16.880: INFO: Got endpoints: latency-svc-65s27 [440.126747ms]
Apr 30 07:27:16.898: INFO: Created: latency-svc-sxp4g
Apr 30 07:27:16.902: INFO: Got endpoints: latency-svc-sxp4g [428.79205ms]
Apr 30 07:27:16.912: INFO: Created: latency-svc-cfc89
Apr 30 07:27:16.919: INFO: Got endpoints: latency-svc-cfc89 [422.721783ms]
Apr 30 07:27:16.948: INFO: Created: latency-svc-zchjr
Apr 30 07:27:16.959: INFO: Got endpoints: latency-svc-zchjr [426.225027ms]
Apr 30 07:27:16.972: INFO: Created: latency-svc-7gvp7
Apr 30 07:27:16.978: INFO: Got endpoints: latency-svc-7gvp7 [417.071327ms]
Apr 30 07:27:17.000: INFO: Created: latency-svc-j4z42
Apr 30 07:27:17.008: INFO: Got endpoints: latency-svc-j4z42 [431.49151ms]
Apr 30 07:27:17.020: INFO: Created: latency-svc-klnmb
Apr 30 07:27:17.027: INFO: Got endpoints: latency-svc-klnmb [430.878837ms]
Apr 30 07:27:17.043: INFO: Created: latency-svc-4vt9z
Apr 30 07:27:17.046: INFO: Got endpoints: latency-svc-4vt9z [424.271277ms]
Apr 30 07:27:17.063: INFO: Created: latency-svc-rnb5p
Apr 30 07:27:17.207: INFO: Got endpoints: latency-svc-rnb5p [575.192787ms]
Apr 30 07:27:17.247: INFO: Created: latency-svc-r5mw8
Apr 30 07:27:17.251: INFO: Got endpoints: latency-svc-r5mw8 [573.85907ms]
Apr 30 07:27:17.278: INFO: Created: latency-svc-zkngd
Apr 30 07:27:17.285: INFO: Got endpoints: latency-svc-zkngd [561.90309ms]
Apr 30 07:27:17.306: INFO: Created: latency-svc-6xhbh
Apr 30 07:27:17.313: INFO: Got endpoints: latency-svc-6xhbh [573.432677ms]
Apr 30 07:27:17.335: INFO: Created: latency-svc-kbhhd
Apr 30 07:27:17.344: INFO: Got endpoints: latency-svc-kbhhd [556.691773ms]
Apr 30 07:27:17.364: INFO: Created: latency-svc-zxfpv
Apr 30 07:27:17.373: INFO: Got endpoints: latency-svc-zxfpv [571.443966ms]
Apr 30 07:27:17.384: INFO: Created: latency-svc-z84wk
Apr 30 07:27:17.392: INFO: Got endpoints: latency-svc-z84wk [569.177403ms]
Apr 30 07:27:17.405: INFO: Created: latency-svc-x26rz
Apr 30 07:27:17.413: INFO: Got endpoints: latency-svc-x26rz [532.410097ms]
Apr 30 07:27:17.445: INFO: Created: latency-svc-dxgwk
Apr 30 07:27:17.447: INFO: Got endpoints: latency-svc-dxgwk [544.48607ms]
Apr 30 07:27:17.453: INFO: Created: latency-svc-xj7wc
Apr 30 07:27:17.460: INFO: Got endpoints: latency-svc-xj7wc [540.20755ms]
Apr 30 07:27:17.482: INFO: Created: latency-svc-5l8kt
Apr 30 07:27:17.482: INFO: Got endpoints: latency-svc-5l8kt [522.611594ms]
Apr 30 07:27:17.516: INFO: Created: latency-svc-9b2dz
Apr 30 07:27:17.516: INFO: Got endpoints: latency-svc-9b2dz [538.046714ms]
Apr 30 07:27:17.525: INFO: Created: latency-svc-9vz7k
Apr 30 07:27:17.540: INFO: Got endpoints: latency-svc-9vz7k [532.510567ms]
Apr 30 07:27:17.549: INFO: Created: latency-svc-f69qf
Apr 30 07:27:17.561: INFO: Got endpoints: latency-svc-f69qf [533.900556ms]
Apr 30 07:27:17.570: INFO: Created: latency-svc-rlwsc
Apr 30 07:27:17.578: INFO: Got endpoints: latency-svc-rlwsc [531.90978ms]
Apr 30 07:27:17.591: INFO: Created: latency-svc-ngzdz
Apr 30 07:27:17.599: INFO: Got endpoints: latency-svc-ngzdz [392.74178ms]
Apr 30 07:27:17.616: INFO: Created: latency-svc-frfvk
Apr 30 07:27:17.628: INFO: Got endpoints: latency-svc-frfvk [376.8246ms]
Apr 30 07:27:17.629: INFO: Created: latency-svc-7z4t6
Apr 30 07:27:17.636: INFO: Got endpoints: latency-svc-7z4t6 [350.895657ms]
Apr 30 07:27:17.658: INFO: Created: latency-svc-fccrm
Apr 30 07:27:17.665: INFO: Got endpoints: latency-svc-fccrm [352.220477ms]
Apr 30 07:27:17.693: INFO: Created: latency-svc-4xzt6
Apr 30 07:27:17.707: INFO: Got endpoints: latency-svc-4xzt6 [363.676633ms]
Apr 30 07:27:17.722: INFO: Created: latency-svc-mlp49
Apr 30 07:27:17.727: INFO: Got endpoints: latency-svc-mlp49 [354.22937ms]
Apr 30 07:27:17.738: INFO: Created: latency-svc-5zxlg
Apr 30 07:27:17.774: INFO: Got endpoints: latency-svc-5zxlg [382.216594ms]
Apr 30 07:27:17.784: INFO: Created: latency-svc-dr979
Apr 30 07:27:17.796: INFO: Got endpoints: latency-svc-dr979 [382.847476ms]
Apr 30 07:27:17.825: INFO: Created: latency-svc-7pqbw
Apr 30 07:27:17.834: INFO: Got endpoints: latency-svc-7pqbw [387.03375ms]
Apr 30 07:27:17.868: INFO: Created: latency-svc-tdsf2
Apr 30 07:27:17.868: INFO: Got endpoints: latency-svc-tdsf2 [408.393296ms]
Apr 30 07:27:17.910: INFO: Created: latency-svc-bznts
Apr 30 07:27:17.915: INFO: Got endpoints: latency-svc-bznts [432.57956ms]
Apr 30 07:27:17.926: INFO: Created: latency-svc-z2wkd
Apr 30 07:27:17.937: INFO: Got endpoints: latency-svc-z2wkd [420.94919ms]
Apr 30 07:27:17.951: INFO: Created: latency-svc-fb228
Apr 30 07:27:17.957: INFO: Got endpoints: latency-svc-fb228 [416.360437ms]
Apr 30 07:27:17.989: INFO: Created: latency-svc-sfwpc
Apr 30 07:27:18.000: INFO: Got endpoints: latency-svc-sfwpc [439.330134ms]
Apr 30 07:27:18.020: INFO: Created: latency-svc-z4tmk
Apr 30 07:27:18.036: INFO: Got endpoints: latency-svc-z4tmk [458.03516ms]
Apr 30 07:27:18.054: INFO: Created: latency-svc-khqsg
Apr 30 07:27:18.066: INFO: Got endpoints: latency-svc-khqsg [466.791924ms]
Apr 30 07:27:18.085: INFO: Created: latency-svc-72fp4
Apr 30 07:27:18.103: INFO: Got endpoints: latency-svc-72fp4 [474.80562ms]
Apr 30 07:27:18.108: INFO: Created: latency-svc-p2t7z
Apr 30 07:27:18.127: INFO: Got endpoints: latency-svc-p2t7z [490.52347ms]
Apr 30 07:27:18.157: INFO: Created: latency-svc-q5kgb
Apr 30 07:27:18.158: INFO: Got endpoints: latency-svc-q5kgb [492.1461ms]
Apr 30 07:27:18.183: INFO: Created: latency-svc-wwml7
Apr 30 07:27:18.199: INFO: Got endpoints: latency-svc-wwml7 [490.920743ms]
Apr 30 07:27:18.215: INFO: Created: latency-svc-bm4j9
Apr 30 07:27:18.215: INFO: Got endpoints: latency-svc-bm4j9 [487.829457ms]
Apr 30 07:27:18.265: INFO: Created: latency-svc-4n4f5
Apr 30 07:27:18.271: INFO: Got endpoints: latency-svc-4n4f5 [496.816747ms]
Apr 30 07:27:18.290: INFO: Created: latency-svc-xmc5g
Apr 30 07:27:18.293: INFO: Got endpoints: latency-svc-xmc5g [496.857313ms]
Apr 30 07:27:18.314: INFO: Created: latency-svc-kk4fl
Apr 30 07:27:18.322: INFO: Got endpoints: latency-svc-kk4fl [488.019733ms]
Apr 30 07:27:18.332: INFO: Created: latency-svc-mp286
Apr 30 07:27:18.342: INFO: Got endpoints: latency-svc-mp286 [473.538147ms]
Apr 30 07:27:18.357: INFO: Created: latency-svc-d5zm2
Apr 30 07:27:18.364: INFO: Got endpoints: latency-svc-d5zm2 [449.042847ms]
Apr 30 07:27:18.386: INFO: Created: latency-svc-gbcnv
Apr 30 07:27:18.388: INFO: Got endpoints: latency-svc-gbcnv [451.225966ms]
Apr 30 07:27:18.399: INFO: Created: latency-svc-xnlmq
Apr 30 07:27:18.412: INFO: Got endpoints: latency-svc-xnlmq [455.005954ms]
Apr 30 07:27:18.426: INFO: Created: latency-svc-ntnsm
Apr 30 07:27:18.446: INFO: Created: latency-svc-jkzhw
Apr 30 07:27:18.463: INFO: Got endpoints: latency-svc-ntnsm [462.625297ms]
Apr 30 07:27:18.472: INFO: Created: latency-svc-lkt57
Apr 30 07:27:18.502: INFO: Created: latency-svc-m5xrn
Apr 30 07:27:18.511: INFO: Got endpoints: latency-svc-jkzhw [474.460546ms]
Apr 30 07:27:18.528: INFO: Created: latency-svc-4dddb
Apr 30 07:27:18.548: INFO: Created: latency-svc-qwpm5
Apr 30 07:27:18.566: INFO: Got endpoints: latency-svc-lkt57 [499.58606ms]
Apr 30 07:27:18.577: INFO: Created: latency-svc-xclzg
Apr 30 07:27:18.597: INFO: Created: latency-svc-cqk97
Apr 30 07:27:18.623: INFO: Got endpoints: latency-svc-m5xrn [520.79228ms]
Apr 30 07:27:18.624: INFO: Created: latency-svc-whrc9
Apr 30 07:27:18.646: INFO: Created: latency-svc-s9hjx
Apr 30 07:27:18.661: INFO: Got endpoints: latency-svc-4dddb [533.911883ms]
Apr 30 07:27:18.671: INFO: Created: latency-svc-49rrk
Apr 30 07:27:18.761: INFO: Got endpoints: latency-svc-qwpm5 [603.31081ms]
Apr 30 07:27:18.764: INFO: Got endpoints: latency-svc-xclzg [564.979516ms]
Apr 30 07:27:18.772: INFO: Created: latency-svc-t9qpt
Apr 30 07:27:18.794: INFO: Created: latency-svc-m68zc
Apr 30 07:27:18.811: INFO: Got endpoints: latency-svc-cqk97 [595.676857ms]
Apr 30 07:27:18.822: INFO: Created: latency-svc-88298
Apr 30 07:27:18.857: INFO: Created: latency-svc-9bzps
Apr 30 07:27:18.875: INFO: Got endpoints: latency-svc-whrc9 [603.42626ms]
Apr 30 07:27:18.886: INFO: Created: latency-svc-c8kds
Apr 30 07:27:18.912: INFO: Got endpoints: latency-svc-s9hjx [618.949897ms]
Apr 30 07:27:18.918: INFO: Created: latency-svc-ljnzj
Apr 30 07:27:18.938: INFO: Created: latency-svc-rz2qx
Apr 30 07:27:18.961: INFO: Got endpoints: latency-svc-49rrk [639.034446ms]
Apr 30 07:27:18.969: INFO: Created: latency-svc-j7pfg
Apr 30 07:27:19.009: INFO: Created: latency-svc-8zgx7
Apr 30 07:27:19.019: INFO: Got endpoints: latency-svc-t9qpt [677.310093ms]
Apr 30 07:27:19.042: INFO: Created: latency-svc-f8748
Apr 30 07:27:19.071: INFO: Got endpoints: latency-svc-m68zc [707.18082ms]
Apr 30 07:27:19.077: INFO: Created: latency-svc-9ndjn
Apr 30 07:27:19.124: INFO: Got endpoints: latency-svc-88298 [735.23517ms]
Apr 30 07:27:19.144: INFO: Created: latency-svc-4f47j
Apr 30 07:27:19.163: INFO: Created: latency-svc-kf55w
Apr 30 07:27:19.165: INFO: Got endpoints: latency-svc-9bzps [752.89788ms]
Apr 30 07:27:19.187: INFO: Created: latency-svc-mfcrj
Apr 30 07:27:19.211: INFO: Got endpoints: latency-svc-c8kds [747.778087ms]
Apr 30 07:27:19.226: INFO: Created: latency-svc-wn5s2
Apr 30 07:27:19.251: INFO: Created: latency-svc-6pcxq
Apr 30 07:27:19.263: INFO: Got endpoints: latency-svc-ljnzj [752.113127ms]
Apr 30 07:27:19.264: INFO: Created: latency-svc-vnrlm
Apr 30 07:27:19.286: INFO: Created: latency-svc-47p6n
Apr 30 07:27:19.364: INFO: Got endpoints: latency-svc-rz2qx [798.051107ms]
Apr 30 07:27:19.370: INFO: Got endpoints: latency-svc-j7pfg [745.932293ms]
Apr 30 07:27:19.371: INFO: Created: latency-svc-2jr59
Apr 30 07:27:19.500: INFO: Got endpoints: latency-svc-8zgx7 [838.90076ms]
Apr 30 07:27:19.505: INFO: Got endpoints: latency-svc-f8748 [743.766056ms]
Apr 30 07:27:19.522: INFO: Created: latency-svc-tqdr2
Apr 30 07:27:19.525: INFO: Got endpoints: latency-svc-9ndjn [761.653763ms]
Apr 30 07:27:19.541: INFO: Created: latency-svc-tscp4
Apr 30 07:27:19.554: INFO: Created: latency-svc-lxwjw
Apr 30 07:27:19.563: INFO: Got endpoints: latency-svc-4f47j [752.541173ms]
Apr 30 07:27:19.570: INFO: Created: latency-svc-g2655
Apr 30 07:27:19.587: INFO: Created: latency-svc-pppp9
Apr 30 07:27:19.609: INFO: Created: latency-svc-bglvn
Apr 30 07:27:19.616: INFO: Got endpoints: latency-svc-kf55w [740.64093ms]
Apr 30 07:27:19.627: INFO: Created: latency-svc-b8bmk
Apr 30 07:27:19.647: INFO: Created: latency-svc-rk79j
Apr 30 07:27:19.659: INFO: Created: latency-svc-bd64s
Apr 30 07:27:19.660: INFO: Got endpoints: latency-svc-mfcrj [748.077193ms]
Apr 30 07:27:19.680: INFO: Created: latency-svc-8xhcb
Apr 30 07:27:19.712: INFO: Got endpoints: latency-svc-wn5s2 [750.758263ms]
Apr 30 07:27:19.736: INFO: Created: latency-svc-6ntmd
Apr 30 07:27:19.761: INFO: Got endpoints: latency-svc-6pcxq [741.872284ms]
Apr 30 07:27:19.783: INFO: Created: latency-svc-wb5lp
Apr 30 07:27:19.812: INFO: Got endpoints: latency-svc-vnrlm [740.06713ms]
Apr 30 07:27:19.847: INFO: Created: latency-svc-6tb7c
Apr 30 07:27:19.860: INFO: Got endpoints: latency-svc-47p6n [735.916693ms]
Apr 30 07:27:19.883: INFO: Created: latency-svc-8db5l
Apr 30 07:27:19.912: INFO: Got endpoints: latency-svc-2jr59 [747.48952ms]
Apr 30 07:27:19.932: INFO: Created: latency-svc-9srkk
Apr 30 07:27:19.961: INFO: Got endpoints: latency-svc-tqdr2 [749.561866ms]
Apr 30 07:27:19.984: INFO: Created: latency-svc-kv9dq
Apr 30 07:27:20.010: INFO: Got endpoints: latency-svc-tscp4 [747.19749ms]
Apr 30 07:27:20.039: INFO: Created: latency-svc-4mw6p
Apr 30 07:27:20.060: INFO: Got endpoints: latency-svc-lxwjw [695.523074ms]
Apr 30 07:27:20.078: INFO: Created: latency-svc-6sr7z
Apr 30 07:27:20.110: INFO: Got endpoints: latency-svc-g2655 [740.23851ms]
Apr 30 07:27:20.134: INFO: Created: latency-svc-tshm7
Apr 30 07:27:20.160: INFO: Got endpoints: latency-svc-pppp9 [659.365713ms]
Apr 30 07:27:20.183: INFO: Created: latency-svc-68h5d
Apr 30 07:27:20.209: INFO: Got endpoints: latency-svc-bglvn [704.188534ms]
Apr 30 07:27:20.228: INFO: Created: latency-svc-zp58j
Apr 30 07:27:20.263: INFO: Got endpoints: latency-svc-b8bmk [737.30453ms]
Apr 30 07:27:20.289: INFO: Created: latency-svc-phscq
Apr 30 07:27:20.310: INFO: Got endpoints: latency-svc-rk79j [746.12728ms]
Apr 30 07:27:20.333: INFO: Created: latency-svc-w5b7k
Apr 30 07:27:20.365: INFO: Got endpoints: latency-svc-bd64s [749.173063ms]
Apr 30 07:27:20.406: INFO: Created: latency-svc-jd2mm
Apr 30 07:27:20.410: INFO: Got endpoints: latency-svc-8xhcb [750.036477ms]
Apr 30 07:27:20.465: INFO: Got endpoints: latency-svc-6ntmd [752.316813ms]
Apr 30 07:27:20.474: INFO: Created: latency-svc-d78fj
Apr 30 07:27:20.519: INFO: Got endpoints: latency-svc-wb5lp [757.909803ms]
Apr 30 07:27:20.525: INFO: Created: latency-svc-6hmwk
Apr 30 07:27:20.547: INFO: Created: latency-svc-t4kgn
Apr 30 07:27:20.560: INFO: Got endpoints: latency-svc-6tb7c [747.929487ms]
Apr 30 07:27:20.585: INFO: Created: latency-svc-6pzzf
Apr 30 07:27:20.610: INFO: Got endpoints: latency-svc-8db5l [750.2353ms]
Apr 30 07:27:20.636: INFO: Created: latency-svc-bxwpc
Apr 30 07:27:20.661: INFO: Got endpoints: latency-svc-9srkk [748.062927ms]
Apr 30 07:27:20.683: INFO: Created: latency-svc-km2hg
Apr 30 07:27:20.712: INFO: Got endpoints: latency-svc-kv9dq [751.173117ms]
Apr 30 07:27:20.739: INFO: Created: latency-svc-snb78
Apr 30 07:27:20.760: INFO: Got endpoints: latency-svc-4mw6p [749.104467ms]
Apr 30 07:27:20.786: INFO: Created: latency-svc-dkx4h
Apr 30 07:27:20.811: INFO: Got endpoints: latency-svc-6sr7z [750.854237ms]
Apr 30 07:27:20.858: INFO: Created: latency-svc-m629n
Apr 30 07:27:20.869: INFO: Got endpoints: latency-svc-tshm7 [758.643147ms]
Apr 30 07:27:20.890: INFO: Created: latency-svc-tz9q8
Apr 30 07:27:20.912: INFO: Got endpoints: latency-svc-68h5d [752.321147ms]
Apr 30 07:27:20.934: INFO: Created: latency-svc-5fnwf
Apr 30 07:27:20.960: INFO: Got endpoints: latency-svc-zp58j [751.011414ms]
Apr 30 07:27:20.984: INFO: Created: latency-svc-wznwz
Apr 30 07:27:21.011: INFO: Got endpoints: latency-svc-phscq [748.530203ms]
Apr 30 07:27:21.038: INFO: Created: latency-svc-jzkpb
Apr 30 07:27:21.063: INFO: Got endpoints: latency-svc-w5b7k [753.002283ms]
Apr 30 07:27:21.090: INFO: Created: latency-svc-sdvpc
Apr 30 07:27:21.111: INFO: Got endpoints: latency-svc-jd2mm [746.38699ms]
Apr 30 07:27:21.136: INFO: Created: latency-svc-xcbz4
Apr 30 07:27:21.160: INFO: Got endpoints: latency-svc-d78fj [749.82095ms]
Apr 30 07:27:21.177: INFO: Created: latency-svc-dmh8x
Apr 30 07:27:21.212: INFO: Got endpoints: latency-svc-6hmwk [746.835783ms]
Apr 30 07:27:21.239: INFO: Created: latency-svc-jm8ch
Apr 30 07:27:21.261: INFO: Got endpoints: latency-svc-t4kgn [741.458153ms]
Apr 30 07:27:21.285: INFO: Created: latency-svc-8m48p
Apr 30 07:27:21.313: INFO: Got endpoints: latency-svc-6pzzf [752.88129ms]
Apr 30 07:27:21.344: INFO: Created: latency-svc-ftkzq
Apr 30 07:27:21.364: INFO: Got endpoints: latency-svc-bxwpc [754.441877ms]
Apr 30 07:27:21.389: INFO: Created: latency-svc-jsls5
Apr 30 07:27:21.422: INFO: Got endpoints: latency-svc-km2hg [760.93142ms]
Apr 30 07:27:21.449: INFO: Created: latency-svc-mq7z6
Apr 30 07:27:21.467: INFO: Got endpoints: latency-svc-snb78 [755.37339ms]
Apr 30 07:27:21.495: INFO: Created: latency-svc-d7q4p
Apr 30 07:27:21.511: INFO: Got endpoints: latency-svc-dkx4h [750.868016ms]
Apr 30 07:27:21.539: INFO: Created: latency-svc-p7bmb
Apr 30 07:27:21.560: INFO: Got endpoints: latency-svc-m629n [749.30582ms]
Apr 30 07:27:21.588: INFO: Created: latency-svc-kxdp9
Apr 30 07:27:21.611: INFO: Got endpoints: latency-svc-tz9q8 [742.24249ms]
Apr 30 07:27:21.637: INFO: Created: latency-svc-sdc8s
Apr 30 07:27:21.660: INFO: Got endpoints: latency-svc-5fnwf [747.781104ms]
Apr 30 07:27:21.687: INFO: Created: latency-svc-xgx25
Apr 30 07:27:21.711: INFO: Got endpoints: latency-svc-wznwz [750.25882ms]
Apr 30 07:27:21.742: INFO: Created: latency-svc-2lsb5
Apr 30 07:27:21.761: INFO: Got endpoints: latency-svc-jzkpb [749.52915ms]
Apr 30 07:27:21.783: INFO: Created: latency-svc-9qpmq
Apr 30 07:27:21.810: INFO: Got endpoints: latency-svc-sdvpc [746.936717ms]
Apr 30 07:27:21.829: INFO: Created: latency-svc-sq6s8
Apr 30 07:27:21.860: INFO: Got endpoints: latency-svc-xcbz4 [748.963533ms]
Apr 30 07:27:21.897: INFO: Created: latency-svc-fpvhv
Apr 30 07:27:21.909: INFO: Got endpoints: latency-svc-dmh8x [748.448173ms]
Apr 30 07:27:21.930: INFO: Created: latency-svc-mrbkz
Apr 30 07:27:21.961: INFO: Got endpoints: latency-svc-jm8ch [749.242836ms]
Apr 30 07:27:21.988: INFO: Created: latency-svc-sdj7z
Apr 30 07:27:22.011: INFO: Got endpoints: latency-svc-8m48p [750.475944ms]
Apr 30 07:27:22.034: INFO: Created: latency-svc-2fqgr
Apr 30 07:27:22.061: INFO: Got endpoints: latency-svc-ftkzq [747.982287ms]
Apr 30 07:27:22.089: INFO: Created: latency-svc-69zfg
Apr 30 07:27:22.113: INFO: Got endpoints: latency-svc-jsls5 [748.238163ms]
Apr 30 07:27:22.135: INFO: Created: latency-svc-86xbj
Apr 30 07:27:22.163: INFO: Got endpoints: latency-svc-mq7z6 [741.61732ms]
Apr 30 07:27:22.188: INFO: Created: latency-svc-kcmzp
Apr 30 07:27:22.210: INFO: Got endpoints: latency-svc-d7q4p [742.87702ms]
Apr 30 07:27:22.232: INFO: Created: latency-svc-pl77h
Apr 30 07:27:22.263: INFO: Got endpoints: latency-svc-p7bmb [752.667036ms]
Apr 30 07:27:22.285: INFO: Created: latency-svc-2ftsv
Apr 30 07:27:22.311: INFO: Got endpoints: latency-svc-kxdp9 [750.577044ms]
Apr 30 07:27:22.331: INFO: Created: latency-svc-mm27b
Apr 30 07:27:22.361: INFO: Got endpoints: latency-svc-sdc8s [750.023886ms]
Apr 30 07:27:22.390: INFO: Created: latency-svc-22nzt
Apr 30 07:27:22.411: INFO: Got endpoints: latency-svc-xgx25 [750.37706ms]
Apr 30 07:27:22.433: INFO: Created: latency-svc-w9fx7
Apr 30 07:27:22.462: INFO: Got endpoints: latency-svc-2lsb5 [751.227406ms]
Apr 30 07:27:22.490: INFO: Created: latency-svc-k4plp
Apr 30 07:27:22.513: INFO: Got endpoints: latency-svc-9qpmq [752.244287ms]
Apr 30 07:27:22.540: INFO: Created: latency-svc-2mt6b
Apr 30 07:27:22.561: INFO: Got endpoints: latency-svc-sq6s8 [750.645844ms]
Apr 30 07:27:22.596: INFO: Created: latency-svc-rgfwc
Apr 30 07:27:22.611: INFO: Got endpoints: latency-svc-fpvhv [750.09453ms]
Apr 30 07:27:22.647: INFO: Created: latency-svc-c48tl
Apr 30 07:27:22.662: INFO: Got endpoints: latency-svc-mrbkz [753.300407ms]
Apr 30 07:27:22.702: INFO: Created: latency-svc-sbgqw
Apr 30 07:27:22.721: INFO: Got endpoints: latency-svc-sdj7z [759.803553ms]
Apr 30 07:27:22.761: INFO: Got endpoints: latency-svc-2fqgr [749.523407ms]
Apr 30 07:27:22.770: INFO: Created: latency-svc-ftd8s
Apr 30 07:27:22.885: INFO: Got endpoints: latency-svc-69zfg [823.98696ms]
Apr 30 07:27:22.952: INFO: Got endpoints: latency-svc-kcmzp [788.61615ms]
Apr 30 07:27:22.953: INFO: Got endpoints: latency-svc-86xbj [839.847347ms]
Apr 30 07:27:22.965: INFO: Got endpoints: latency-svc-pl77h [754.18946ms]
Apr 30 07:27:22.970: INFO: Created: latency-svc-bkkwg
Apr 30 07:27:22.999: INFO: Created: latency-svc-s5h47
Apr 30 07:27:23.015: INFO: Got endpoints: latency-svc-2ftsv [751.702436ms]
Apr 30 07:27:23.021: INFO: Created: latency-svc-j8h9c
Apr 30 07:27:23.043: INFO: Created: latency-svc-9tdvd
Apr 30 07:27:23.069: INFO: Got endpoints: latency-svc-mm27b [757.517983ms]
Apr 30 07:27:23.073: INFO: Created: latency-svc-qjc74
Apr 30 07:27:23.112: INFO: Created: latency-svc-wblv2
Apr 30 07:27:23.119: INFO: Got endpoints: latency-svc-22nzt [757.098654ms]
Apr 30 07:27:23.127: INFO: Created: latency-svc-npx9z
Apr 30 07:27:23.138: INFO: Created: latency-svc-bqp2q
Apr 30 07:27:23.159: INFO: Got endpoints: latency-svc-w9fx7 [748.10599ms]
Apr 30 07:27:23.180: INFO: Created: latency-svc-fvm9p
Apr 30 07:27:23.211: INFO: Got endpoints: latency-svc-k4plp [748.902084ms]
Apr 30 07:27:23.230: INFO: Created: latency-svc-kcxv8
Apr 30 07:27:23.260: INFO: Got endpoints: latency-svc-2mt6b [746.739743ms]
Apr 30 07:27:23.284: INFO: Created: latency-svc-mqnpt
Apr 30 07:27:23.309: INFO: Got endpoints: latency-svc-rgfwc [748.38322ms]
Apr 30 07:27:23.333: INFO: Created: latency-svc-6hpcl
Apr 30 07:27:23.361: INFO: Got endpoints: latency-svc-c48tl [749.86736ms]
Apr 30 07:27:23.384: INFO: Created: latency-svc-rr9fg
Apr 30 07:27:23.411: INFO: Got endpoints: latency-svc-sbgqw [748.82197ms]
Apr 30 07:27:23.430: INFO: Created: latency-svc-lcldl
Apr 30 07:27:23.460: INFO: Got endpoints: latency-svc-ftd8s [738.808223ms]
Apr 30 07:27:23.481: INFO: Created: latency-svc-xt4sb
Apr 30 07:27:23.512: INFO: Got endpoints: latency-svc-bkkwg [750.773304ms]
Apr 30 07:27:23.539: INFO: Created: latency-svc-8f8tn
Apr 30 07:27:23.562: INFO: Got endpoints: latency-svc-s5h47 [676.944167ms]
Apr 30 07:27:23.591: INFO: Created: latency-svc-rkwdq
Apr 30 07:27:23.617: INFO: Got endpoints: latency-svc-j8h9c [664.364943ms]
Apr 30 07:27:23.643: INFO: Created: latency-svc-p897q
Apr 30 07:27:23.668: INFO: Got endpoints: latency-svc-9tdvd [715.03045ms]
Apr 30 07:27:23.704: INFO: Created: latency-svc-rgj6q
Apr 30 07:27:23.714: INFO: Got endpoints: latency-svc-qjc74 [748.885857ms]
Apr 30 07:27:23.735: INFO: Created: latency-svc-fqr94
Apr 30 07:27:23.761: INFO: Got endpoints: latency-svc-wblv2 [745.44843ms]
Apr 30 07:27:23.780: INFO: Created: latency-svc-rp4tj
Apr 30 07:27:23.816: INFO: Got endpoints: latency-svc-npx9z [746.859374ms]
Apr 30 07:27:23.845: INFO: Created: latency-svc-lfxhn
Apr 30 07:27:23.860: INFO: Got endpoints: latency-svc-bqp2q [741.749993ms]
Apr 30 07:27:23.882: INFO: Created: latency-svc-fv2sz
Apr 30 07:27:23.912: INFO: Got endpoints: latency-svc-fvm9p [753.097343ms]
Apr 30 07:27:23.963: INFO: Got endpoints: latency-svc-kcxv8 [751.43769ms]
Apr 30 07:27:24.011: INFO: Got endpoints: latency-svc-mqnpt [750.38075ms]
Apr 30 07:27:24.061: INFO: Got endpoints: latency-svc-6hpcl [751.660586ms]
Apr 30 07:27:24.111: INFO: Got endpoints: latency-svc-rr9fg [750.023844ms]
Apr 30 07:27:24.162: INFO: Got endpoints: latency-svc-lcldl [749.993046ms]
Apr 30 07:27:24.210: INFO: Got endpoints: latency-svc-xt4sb [750.62039ms]
Apr 30 07:27:24.261: INFO: Got endpoints: latency-svc-8f8tn [748.876533ms]
Apr 30 07:27:24.315: INFO: Got endpoints: latency-svc-rkwdq [752.888186ms]
Apr 30 07:27:24.361: INFO: Got endpoints: latency-svc-p897q [743.78318ms]
Apr 30 07:27:24.411: INFO: Got endpoints: latency-svc-rgj6q [742.582897ms]
Apr 30 07:27:24.460: INFO: Got endpoints: latency-svc-fqr94 [746.67453ms]
Apr 30 07:27:24.511: INFO: Got endpoints: latency-svc-rp4tj [750.327606ms]
Apr 30 07:27:24.562: INFO: Got endpoints: latency-svc-lfxhn [746.35842ms]
Apr 30 07:27:24.611: INFO: Got endpoints: latency-svc-fv2sz [750.579953ms]
Apr 30 07:27:24.611: INFO: Latencies: [46.790163ms 54.873347ms 124.652053ms 144.776423ms 337.986654ms 350.895657ms 352.220477ms 354.22937ms 363.676633ms 365.712627ms 376.8246ms 378.17733ms 382.216594ms 382.847476ms 387.03375ms 392.74178ms 401.349493ms 408.393296ms 411.865917ms 416.360437ms 417.071327ms 420.94919ms 422.721783ms 424.271277ms 426.225027ms 427.499023ms 428.79205ms 429.234836ms 430.66223ms 430.878837ms 431.49151ms 432.57956ms 433.785556ms 439.330134ms 440.126747ms 443.965227ms 449.042847ms 451.225966ms 455.005954ms 456.631773ms 458.03516ms 461.333317ms 462.625297ms 466.791924ms 473.538147ms 474.460546ms 474.80562ms 487.532034ms 487.829457ms 488.019733ms 490.52347ms 490.920743ms 492.1461ms 496.816747ms 496.857313ms 499.58606ms 509.252597ms 520.79228ms 522.611594ms 531.90978ms 532.410097ms 532.510567ms 533.900556ms 533.911883ms 538.046714ms 540.20755ms 544.48607ms 556.691773ms 561.230093ms 561.90309ms 564.979516ms 564.98213ms 569.177403ms 570.6562ms 571.443966ms 573.432677ms 573.85907ms 575.192787ms 595.676857ms 601.270277ms 603.31081ms 603.42626ms 618.949897ms 623.102603ms 628.74224ms 639.034446ms 644.349577ms 659.365713ms 664.364943ms 676.944167ms 677.310093ms 695.523074ms 704.188534ms 707.18082ms 715.03045ms 735.23517ms 735.916693ms 737.30453ms 738.808223ms 740.06713ms 740.23851ms 740.64093ms 741.458153ms 741.61732ms 741.749993ms 741.872284ms 742.24249ms 742.582897ms 742.87702ms 743.766056ms 743.78318ms 745.44843ms 745.932293ms 746.12728ms 746.35842ms 746.38699ms 746.67453ms 746.739743ms 746.835783ms 746.859374ms 746.936717ms 747.19749ms 747.48952ms 747.778087ms 747.781104ms 747.929487ms 747.982287ms 748.062927ms 748.077193ms 748.10599ms 748.238163ms 748.38322ms 748.448173ms 748.530203ms 748.82197ms 748.876533ms 748.885857ms 748.902084ms 748.963533ms 749.104467ms 749.173063ms 749.242836ms 749.30582ms 749.523407ms 749.52915ms 749.561866ms 749.82095ms 749.86736ms 749.993046ms 750.023844ms 750.023886ms 750.036477ms 750.09453ms 750.2353ms 750.25882ms 750.327606ms 750.37706ms 750.38075ms 750.475944ms 750.577044ms 750.579953ms 750.62039ms 750.645844ms 750.758263ms 750.773304ms 750.854237ms 750.868016ms 751.011414ms 751.173117ms 751.227406ms 751.43769ms 751.660586ms 751.702436ms 752.113127ms 752.244287ms 752.316813ms 752.321147ms 752.541173ms 752.667036ms 752.88129ms 752.888186ms 752.89788ms 753.002283ms 753.097343ms 753.300407ms 754.18946ms 754.441877ms 755.37339ms 757.098654ms 757.517983ms 757.909803ms 758.643147ms 759.803553ms 760.93142ms 761.653763ms 788.61615ms 798.051107ms 823.98696ms 838.90076ms 839.847347ms]
Apr 30 07:27:24.612: INFO: 50 %ile: 740.23851ms
Apr 30 07:27:24.612: INFO: 90 %ile: 752.888186ms
Apr 30 07:27:24.612: INFO: 99 %ile: 838.90076ms
Apr 30 07:27:24.612: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:27:24.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-1157" for this suite.
Apr 30 07:27:40.641: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:27:40.806: INFO: namespace svc-latency-1157 deletion completed in 16.186682157s

• [SLOW TEST:29.156 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:27:40.806: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Apr 30 07:27:44.936: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-6ffe1c31-6b19-11e9-845c-f234dad8a085,GenerateName:,Namespace:events-7056,SelfLink:/api/v1/namespaces/events-7056/pods/send-events-6ffe1c31-6b19-11e9-845c-f234dad8a085,UID:73942cae-6b19-11e9-924a-005056bc1aae,ResourceVersion:675612,Generation:0,CreationTimestamp:2019-04-30 07:27:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 878965723,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xw9rx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xw9rx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-xw9rx true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.101.13-slave,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0026af580} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0026af5a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:27:46 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:27:50 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:27:50 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:27:46 +0000 UTC  }],Message:,Reason:,HostIP:10.10.101.13,PodIP:10.168.6.178,StartTime:2019-04-30 07:27:46 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-04-30 07:27:49 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://ec8ee090f7d195555f2625615b813d4c1b515ee1c4450cf36a5989dc28882aff}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Apr 30 07:27:46.944: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Apr 30 07:27:48.960: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:27:48.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-7056" for this suite.
Apr 30 07:28:31.003: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:28:31.184: INFO: namespace events-7056 deletion completed in 42.20285848s

• [SLOW TEST:50.378 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:28:31.184: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Apr 30 07:29:11.371: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
	[quantile=0.5] = 17
	[quantile=0.9] = 47
	[quantile=0.99] = 49
For garbage_collector_attempt_to_delete_work_duration:
	[quantile=0.5] = 29
	[quantile=0.9] = 226193
	[quantile=0.99] = 226285
For garbage_collector_attempt_to_orphan_queue_latency:
	[quantile=0.5] = 17
	[quantile=0.9] = 17
	[quantile=0.99] = 17
For garbage_collector_attempt_to_orphan_work_duration:
	[quantile=0.5] = 266924
	[quantile=0.9] = 266924
	[quantile=0.99] = 266924
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
	[quantile=0.5] = 9
	[quantile=0.9] = 15
	[quantile=0.99] = 84
For garbage_collector_graph_changes_work_duration:
	[quantile=0.5] = 25
	[quantile=0.9] = 51
	[quantile=0.99] = 123
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
	[quantile=0.5] = 25
	[quantile=0.9] = 44
	[quantile=0.99] = 111
For namespace_queue_latency_sum:
	[] = 40529
For namespace_queue_latency_count:
	[] = 1144
For namespace_retries:
	[] = 1158
For namespace_work_duration:
	[quantile=0.5] = 321825
	[quantile=0.9] = 457547
	[quantile=0.99] = 829225
For namespace_work_duration_sum:
	[] = 323968749
For namespace_work_duration_count:
	[] = 1144
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:29:11.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3720" for this suite.
Apr 30 07:29:19.401: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:29:19.677: INFO: namespace gc-3720 deletion completed in 8.296951003s

• [SLOW TEST:48.492 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:29:19.678: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Apr 30 07:29:19.763: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:29:26.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3673" for this suite.
Apr 30 07:29:32.096: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:29:32.288: INFO: namespace init-container-3673 deletion completed in 6.209309947s

• [SLOW TEST:12.610 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:29:32.289: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test env composition
Apr 30 07:29:32.412: INFO: Waiting up to 5m0s for pod "var-expansion-b2747bbc-6b19-11e9-845c-f234dad8a085" in namespace "var-expansion-1404" to be "success or failure"
Apr 30 07:29:32.426: INFO: Pod "var-expansion-b2747bbc-6b19-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 13.996923ms
Apr 30 07:29:34.435: INFO: Pod "var-expansion-b2747bbc-6b19-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02255563s
Apr 30 07:29:36.442: INFO: Pod "var-expansion-b2747bbc-6b19-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03042289s
STEP: Saw pod success
Apr 30 07:29:36.443: INFO: Pod "var-expansion-b2747bbc-6b19-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 07:29:36.448: INFO: Trying to get logs from node 10.10.101.13-slave pod var-expansion-b2747bbc-6b19-11e9-845c-f234dad8a085 container dapi-container: <nil>
STEP: delete the pod
Apr 30 07:29:36.481: INFO: Waiting for pod var-expansion-b2747bbc-6b19-11e9-845c-f234dad8a085 to disappear
Apr 30 07:29:36.485: INFO: Pod var-expansion-b2747bbc-6b19-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:29:36.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1404" for this suite.
Apr 30 07:29:42.515: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:29:42.722: INFO: namespace var-expansion-1404 deletion completed in 6.228380793s

• [SLOW TEST:10.433 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:29:42.722: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating cluster-info
Apr 30 07:29:42.821: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 cluster-info'
Apr 30 07:29:43.402: INFO: stderr: ""
Apr 30 07:29:43.402: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:29:43.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4647" for this suite.
Apr 30 07:29:49.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:29:49.689: INFO: namespace kubectl-4647 deletion completed in 6.276885293s

• [SLOW TEST:6.967 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:29:49.690: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name projected-secret-test-bccf7ffe-6b19-11e9-845c-f234dad8a085
STEP: Creating a pod to test consume secrets
Apr 30 07:29:49.783: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-bcd0e3c1-6b19-11e9-845c-f234dad8a085" in namespace "projected-132" to be "success or failure"
Apr 30 07:29:49.802: INFO: Pod "pod-projected-secrets-bcd0e3c1-6b19-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 18.830217ms
Apr 30 07:29:51.809: INFO: Pod "pod-projected-secrets-bcd0e3c1-6b19-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026115704s
Apr 30 07:29:53.816: INFO: Pod "pod-projected-secrets-bcd0e3c1-6b19-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03376101s
STEP: Saw pod success
Apr 30 07:29:53.817: INFO: Pod "pod-projected-secrets-bcd0e3c1-6b19-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 07:29:53.823: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-projected-secrets-bcd0e3c1-6b19-11e9-845c-f234dad8a085 container secret-volume-test: <nil>
STEP: delete the pod
Apr 30 07:29:53.871: INFO: Waiting for pod pod-projected-secrets-bcd0e3c1-6b19-11e9-845c-f234dad8a085 to disappear
Apr 30 07:29:53.877: INFO: Pod pod-projected-secrets-bcd0e3c1-6b19-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:29:53.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-132" for this suite.
Apr 30 07:29:59.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:30:00.089: INFO: namespace projected-132 deletion completed in 6.199709997s

• [SLOW TEST:10.399 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:30:00.090: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 30 07:30:00.152: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:30:01.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-400" for this suite.
Apr 30 07:30:07.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:30:07.468: INFO: namespace custom-resource-definition-400 deletion completed in 6.19756021s

• [SLOW TEST:7.378 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:30:07.468: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-c768b596-6b19-11e9-845c-f234dad8a085
STEP: Creating a pod to test consume secrets
Apr 30 07:30:07.561: INFO: Waiting up to 5m0s for pod "pod-secrets-c76a117b-6b19-11e9-845c-f234dad8a085" in namespace "secrets-9209" to be "success or failure"
Apr 30 07:30:07.567: INFO: Pod "pod-secrets-c76a117b-6b19-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 5.771547ms
Apr 30 07:30:09.575: INFO: Pod "pod-secrets-c76a117b-6b19-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013734674s
Apr 30 07:30:11.584: INFO: Pod "pod-secrets-c76a117b-6b19-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023094124s
STEP: Saw pod success
Apr 30 07:30:11.585: INFO: Pod "pod-secrets-c76a117b-6b19-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 07:30:11.590: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-secrets-c76a117b-6b19-11e9-845c-f234dad8a085 container secret-volume-test: <nil>
STEP: delete the pod
Apr 30 07:30:11.689: INFO: Waiting for pod pod-secrets-c76a117b-6b19-11e9-845c-f234dad8a085 to disappear
Apr 30 07:30:11.694: INFO: Pod pod-secrets-c76a117b-6b19-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:30:11.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9209" for this suite.
Apr 30 07:30:17.725: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:30:17.953: INFO: namespace secrets-9209 deletion completed in 6.253021887s

• [SLOW TEST:10.486 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:30:17.954: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-7577
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-7577
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-7577
Apr 30 07:30:18.093: INFO: Found 0 stateful pods, waiting for 1
Apr 30 07:30:28.102: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Apr 30 07:30:28.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 exec --namespace=statefulset-7577 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 30 07:30:28.585: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 30 07:30:28.585: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 30 07:30:28.585: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 30 07:30:28.592: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr 30 07:30:38.601: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 30 07:30:38.601: INFO: Waiting for statefulset status.replicas updated to 0
Apr 30 07:30:38.625: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999233s
Apr 30 07:30:39.633: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.994226s
Apr 30 07:30:40.642: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.98604757s
Apr 30 07:30:41.650: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.97678771s
Apr 30 07:30:42.657: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.968815827s
Apr 30 07:30:43.667: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.961704247s
Apr 30 07:30:44.675: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.95259736s
Apr 30 07:30:45.684: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.94401682s
Apr 30 07:30:46.692: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.935607033s
Apr 30 07:30:47.701: INFO: Verifying statefulset ss doesn't scale past 1 for another 927.165637ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-7577
Apr 30 07:30:48.709: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 exec --namespace=statefulset-7577 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 30 07:30:49.116: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr 30 07:30:49.116: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 30 07:30:49.116: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 30 07:30:49.123: INFO: Found 1 stateful pods, waiting for 3
Apr 30 07:30:59.131: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 30 07:30:59.131: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 30 07:30:59.131: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Apr 30 07:30:59.141: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 exec --namespace=statefulset-7577 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 30 07:30:59.667: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 30 07:30:59.667: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 30 07:30:59.667: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 30 07:30:59.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 exec --namespace=statefulset-7577 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 30 07:31:00.239: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 30 07:31:00.239: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 30 07:31:00.240: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 30 07:31:00.240: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 exec --namespace=statefulset-7577 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 30 07:31:00.754: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 30 07:31:00.754: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 30 07:31:00.754: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 30 07:31:00.754: INFO: Waiting for statefulset status.replicas updated to 0
Apr 30 07:31:00.761: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Apr 30 07:31:10.774: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 30 07:31:10.774: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr 30 07:31:10.774: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr 30 07:31:10.793: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998864s
Apr 30 07:31:11.802: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.99339444s
Apr 30 07:31:12.811: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.984816667s
Apr 30 07:31:13.821: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.97536832s
Apr 30 07:31:14.837: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.96571918s
Apr 30 07:31:15.846: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.950138984s
Apr 30 07:31:16.854: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.94037673s
Apr 30 07:31:17.862: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.932381554s
Apr 30 07:31:18.871: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.92403439s
Apr 30 07:31:19.879: INFO: Verifying statefulset ss doesn't scale past 3 for another 915.386034ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-7577
Apr 30 07:31:20.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 exec --namespace=statefulset-7577 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 30 07:31:21.328: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr 30 07:31:21.328: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 30 07:31:21.328: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 30 07:31:21.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 exec --namespace=statefulset-7577 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 30 07:31:21.808: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr 30 07:31:21.808: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 30 07:31:21.808: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 30 07:31:21.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 exec --namespace=statefulset-7577 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 30 07:31:22.296: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr 30 07:31:22.296: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 30 07:31:22.296: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 30 07:31:22.296: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr 30 07:31:52.336: INFO: Deleting all statefulset in ns statefulset-7577
Apr 30 07:31:52.342: INFO: Scaling statefulset ss to 0
Apr 30 07:31:52.359: INFO: Waiting for statefulset status.replicas updated to 0
Apr 30 07:31:52.363: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:31:52.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7577" for this suite.
Apr 30 07:31:58.415: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:31:58.581: INFO: namespace statefulset-7577 deletion completed in 6.186635513s

• [SLOW TEST:100.627 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:31:58.581: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-secret-cwjs
STEP: Creating a pod to test atomic-volume-subpath
Apr 30 07:31:58.671: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-cwjs" in namespace "subpath-9104" to be "success or failure"
Apr 30 07:31:58.679: INFO: Pod "pod-subpath-test-secret-cwjs": Phase="Pending", Reason="", readiness=false. Elapsed: 8.207226ms
Apr 30 07:32:00.687: INFO: Pod "pod-subpath-test-secret-cwjs": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015960433s
Apr 30 07:32:02.694: INFO: Pod "pod-subpath-test-secret-cwjs": Phase="Running", Reason="", readiness=true. Elapsed: 4.023101153s
Apr 30 07:32:04.701: INFO: Pod "pod-subpath-test-secret-cwjs": Phase="Running", Reason="", readiness=true. Elapsed: 6.02999739s
Apr 30 07:32:06.708: INFO: Pod "pod-subpath-test-secret-cwjs": Phase="Running", Reason="", readiness=true. Elapsed: 8.0367044s
Apr 30 07:32:08.715: INFO: Pod "pod-subpath-test-secret-cwjs": Phase="Running", Reason="", readiness=true. Elapsed: 10.044462656s
Apr 30 07:32:10.722: INFO: Pod "pod-subpath-test-secret-cwjs": Phase="Running", Reason="", readiness=true. Elapsed: 12.051418646s
Apr 30 07:32:12.730: INFO: Pod "pod-subpath-test-secret-cwjs": Phase="Running", Reason="", readiness=true. Elapsed: 14.05878009s
Apr 30 07:32:14.738: INFO: Pod "pod-subpath-test-secret-cwjs": Phase="Running", Reason="", readiness=true. Elapsed: 16.0667073s
Apr 30 07:32:16.745: INFO: Pod "pod-subpath-test-secret-cwjs": Phase="Running", Reason="", readiness=true. Elapsed: 18.073911413s
Apr 30 07:32:18.753: INFO: Pod "pod-subpath-test-secret-cwjs": Phase="Running", Reason="", readiness=true. Elapsed: 20.08184182s
Apr 30 07:32:20.759: INFO: Pod "pod-subpath-test-secret-cwjs": Phase="Running", Reason="", readiness=true. Elapsed: 22.08852677s
Apr 30 07:32:22.767: INFO: Pod "pod-subpath-test-secret-cwjs": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.09576728s
STEP: Saw pod success
Apr 30 07:32:22.767: INFO: Pod "pod-subpath-test-secret-cwjs" satisfied condition "success or failure"
Apr 30 07:32:22.773: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-subpath-test-secret-cwjs container test-container-subpath-secret-cwjs: <nil>
STEP: delete the pod
Apr 30 07:32:22.818: INFO: Waiting for pod pod-subpath-test-secret-cwjs to disappear
Apr 30 07:32:22.825: INFO: Pod pod-subpath-test-secret-cwjs no longer exists
STEP: Deleting pod pod-subpath-test-secret-cwjs
Apr 30 07:32:22.825: INFO: Deleting pod "pod-subpath-test-secret-cwjs" in namespace "subpath-9104"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:32:22.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9104" for this suite.
Apr 30 07:32:28.860: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:32:29.074: INFO: namespace subpath-9104 deletion completed in 6.236523036s

• [SLOW TEST:30.493 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:32:29.075: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Apr 30 07:32:39.268: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 30 07:32:39.273: INFO: Pod pod-with-poststart-http-hook still exists
Apr 30 07:32:41.273: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 30 07:32:41.281: INFO: Pod pod-with-poststart-http-hook still exists
Apr 30 07:32:43.274: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 30 07:32:43.281: INFO: Pod pod-with-poststart-http-hook still exists
Apr 30 07:32:45.275: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 30 07:32:45.283: INFO: Pod pod-with-poststart-http-hook still exists
Apr 30 07:32:47.277: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 30 07:32:47.285: INFO: Pod pod-with-poststart-http-hook still exists
Apr 30 07:32:49.273: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 30 07:32:49.280: INFO: Pod pod-with-poststart-http-hook still exists
Apr 30 07:32:51.273: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 30 07:32:51.280: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:32:51.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9392" for this suite.
Apr 30 07:33:13.307: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:33:13.465: INFO: namespace container-lifecycle-hook-9392 deletion completed in 22.17694343s

• [SLOW TEST:44.390 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:33:13.465: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Apr 30 07:33:13.582: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 07:33:13.588: INFO: Number of nodes with available pods: 0
Apr 30 07:33:13.588: INFO: Node 10.10.101.13-slave is running more than one daemon pod
Apr 30 07:33:14.598: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 07:33:14.604: INFO: Number of nodes with available pods: 0
Apr 30 07:33:14.604: INFO: Node 10.10.101.13-slave is running more than one daemon pod
Apr 30 07:33:15.693: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 07:33:15.734: INFO: Number of nodes with available pods: 0
Apr 30 07:33:15.734: INFO: Node 10.10.101.13-slave is running more than one daemon pod
Apr 30 07:33:16.598: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 07:33:16.605: INFO: Number of nodes with available pods: 0
Apr 30 07:33:16.605: INFO: Node 10.10.101.13-slave is running more than one daemon pod
Apr 30 07:33:17.596: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 07:33:17.603: INFO: Number of nodes with available pods: 1
Apr 30 07:33:17.603: INFO: Node 10.10.101.13-slave is running more than one daemon pod
Apr 30 07:33:18.597: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 07:33:18.605: INFO: Number of nodes with available pods: 2
Apr 30 07:33:18.605: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Apr 30 07:33:18.646: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 07:33:18.654: INFO: Number of nodes with available pods: 1
Apr 30 07:33:18.654: INFO: Node 10.10.101.13-slave is running more than one daemon pod
Apr 30 07:33:19.663: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 07:33:19.670: INFO: Number of nodes with available pods: 1
Apr 30 07:33:19.670: INFO: Node 10.10.101.13-slave is running more than one daemon pod
Apr 30 07:33:20.664: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 07:33:20.670: INFO: Number of nodes with available pods: 1
Apr 30 07:33:20.670: INFO: Node 10.10.101.13-slave is running more than one daemon pod
Apr 30 07:33:21.663: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 07:33:21.668: INFO: Number of nodes with available pods: 1
Apr 30 07:33:21.668: INFO: Node 10.10.101.13-slave is running more than one daemon pod
Apr 30 07:33:22.664: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 07:33:22.670: INFO: Number of nodes with available pods: 2
Apr 30 07:33:22.670: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2592, will wait for the garbage collector to delete the pods
Apr 30 07:33:22.758: INFO: Deleting DaemonSet.extensions daemon-set took: 21.097267ms
Apr 30 07:33:23.059: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.58433ms
Apr 30 07:33:29.864: INFO: Number of nodes with available pods: 0
Apr 30 07:33:29.864: INFO: Number of running nodes: 0, number of available pods: 0
Apr 30 07:33:29.868: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2592/daemonsets","resourceVersion":"677088"},"items":null}

Apr 30 07:33:29.872: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2592/pods","resourceVersion":"677088"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:33:29.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2592" for this suite.
Apr 30 07:33:35.914: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:33:36.132: INFO: namespace daemonsets-2592 deletion completed in 6.236270106s

• [SLOW TEST:22.667 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:33:36.133: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Apr 30 07:33:36.258: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-1221,SelfLink:/api/v1/namespaces/watch-1221/configmaps/e2e-watch-test-resource-version,UID:475ea676-6b1a-11e9-924a-005056bc1aae,ResourceVersion:677135,Generation:0,CreationTimestamp:2019-04-30 07:33:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr 30 07:33:36.258: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-1221,SelfLink:/api/v1/namespaces/watch-1221/configmaps/e2e-watch-test-resource-version,UID:475ea676-6b1a-11e9-924a-005056bc1aae,ResourceVersion:677136,Generation:0,CreationTimestamp:2019-04-30 07:33:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:33:36.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1221" for this suite.
Apr 30 07:33:42.287: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:33:42.470: INFO: namespace watch-1221 deletion completed in 6.205616574s

• [SLOW TEST:6.337 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:33:42.471: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 30 07:33:42.571: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Apr 30 07:33:42.587: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 07:33:42.597: INFO: Number of nodes with available pods: 0
Apr 30 07:33:42.597: INFO: Node 10.10.101.13-slave is running more than one daemon pod
Apr 30 07:33:43.613: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 07:33:43.621: INFO: Number of nodes with available pods: 0
Apr 30 07:33:43.621: INFO: Node 10.10.101.13-slave is running more than one daemon pod
Apr 30 07:33:44.609: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 07:33:44.614: INFO: Number of nodes with available pods: 0
Apr 30 07:33:44.614: INFO: Node 10.10.101.13-slave is running more than one daemon pod
Apr 30 07:33:45.611: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 07:33:45.620: INFO: Number of nodes with available pods: 0
Apr 30 07:33:45.620: INFO: Node 10.10.101.13-slave is running more than one daemon pod
Apr 30 07:33:46.607: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 07:33:46.613: INFO: Number of nodes with available pods: 1
Apr 30 07:33:46.613: INFO: Node 10.10.101.13-slave is running more than one daemon pod
Apr 30 07:33:47.606: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 07:33:47.613: INFO: Number of nodes with available pods: 2
Apr 30 07:33:47.613: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Apr 30 07:33:47.675: INFO: Wrong image for pod: daemon-set-dfghd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 07:33:47.675: INFO: Wrong image for pod: daemon-set-p9b5p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 07:33:47.686: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 07:33:48.695: INFO: Wrong image for pod: daemon-set-dfghd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 07:33:48.696: INFO: Wrong image for pod: daemon-set-p9b5p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 07:33:48.704: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 07:33:49.694: INFO: Wrong image for pod: daemon-set-dfghd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 07:33:49.694: INFO: Wrong image for pod: daemon-set-p9b5p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 07:33:49.702: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 07:33:50.693: INFO: Wrong image for pod: daemon-set-dfghd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 07:33:50.693: INFO: Pod daemon-set-dfghd is not available
Apr 30 07:33:50.693: INFO: Wrong image for pod: daemon-set-p9b5p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 07:33:50.700: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 07:33:51.696: INFO: Wrong image for pod: daemon-set-dfghd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 07:33:51.696: INFO: Pod daemon-set-dfghd is not available
Apr 30 07:33:51.696: INFO: Wrong image for pod: daemon-set-p9b5p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 07:33:51.710: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 07:33:52.696: INFO: Wrong image for pod: daemon-set-p9b5p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 07:33:52.696: INFO: Pod daemon-set-qqdns is not available
Apr 30 07:33:52.706: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 07:33:53.694: INFO: Wrong image for pod: daemon-set-p9b5p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 07:33:53.694: INFO: Pod daemon-set-qqdns is not available
Apr 30 07:33:53.702: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 07:33:54.694: INFO: Wrong image for pod: daemon-set-p9b5p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 07:33:54.694: INFO: Pod daemon-set-qqdns is not available
Apr 30 07:33:54.701: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 07:33:55.694: INFO: Wrong image for pod: daemon-set-p9b5p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 07:33:55.701: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 07:33:56.694: INFO: Wrong image for pod: daemon-set-p9b5p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 07:33:56.701: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 07:33:57.694: INFO: Wrong image for pod: daemon-set-p9b5p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr 30 07:33:57.694: INFO: Pod daemon-set-p9b5p is not available
Apr 30 07:33:57.701: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 07:33:58.697: INFO: Pod daemon-set-w986q is not available
Apr 30 07:33:58.713: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Apr 30 07:33:58.729: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 07:33:58.735: INFO: Number of nodes with available pods: 1
Apr 30 07:33:58.735: INFO: Node 10.10.101.13-slave is running more than one daemon pod
Apr 30 07:33:59.744: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 07:33:59.749: INFO: Number of nodes with available pods: 1
Apr 30 07:33:59.749: INFO: Node 10.10.101.13-slave is running more than one daemon pod
Apr 30 07:34:00.744: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 07:34:00.751: INFO: Number of nodes with available pods: 1
Apr 30 07:34:00.751: INFO: Node 10.10.101.13-slave is running more than one daemon pod
Apr 30 07:34:01.745: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 07:34:01.750: INFO: Number of nodes with available pods: 1
Apr 30 07:34:01.750: INFO: Node 10.10.101.13-slave is running more than one daemon pod
Apr 30 07:34:02.743: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 07:34:02.753: INFO: Number of nodes with available pods: 2
Apr 30 07:34:02.753: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2755, will wait for the garbage collector to delete the pods
Apr 30 07:34:02.859: INFO: Deleting DaemonSet.extensions daemon-set took: 13.063837ms
Apr 30 07:34:03.159: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.522176ms
Apr 30 07:34:09.868: INFO: Number of nodes with available pods: 0
Apr 30 07:34:09.869: INFO: Number of running nodes: 0, number of available pods: 0
Apr 30 07:34:09.876: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2755/daemonsets","resourceVersion":"677307"},"items":null}

Apr 30 07:34:09.884: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2755/pods","resourceVersion":"677307"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:34:09.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2755" for this suite.
Apr 30 07:34:15.931: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:34:16.103: INFO: namespace daemonsets-2755 deletion completed in 6.190635896s

• [SLOW TEST:33.632 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:34:16.103: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override arguments
Apr 30 07:34:16.236: INFO: Waiting up to 5m0s for pod "client-containers-5ba24c53-6b1a-11e9-845c-f234dad8a085" in namespace "containers-7024" to be "success or failure"
Apr 30 07:34:16.243: INFO: Pod "client-containers-5ba24c53-6b1a-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 6.762414ms
Apr 30 07:34:18.251: INFO: Pod "client-containers-5ba24c53-6b1a-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01428348s
Apr 30 07:34:20.258: INFO: Pod "client-containers-5ba24c53-6b1a-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021478667s
Apr 30 07:34:22.265: INFO: Pod "client-containers-5ba24c53-6b1a-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.028494227s
STEP: Saw pod success
Apr 30 07:34:22.265: INFO: Pod "client-containers-5ba24c53-6b1a-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 07:34:22.270: INFO: Trying to get logs from node 10.10.101.13-slave pod client-containers-5ba24c53-6b1a-11e9-845c-f234dad8a085 container test-container: <nil>
STEP: delete the pod
Apr 30 07:34:22.304: INFO: Waiting for pod client-containers-5ba24c53-6b1a-11e9-845c-f234dad8a085 to disappear
Apr 30 07:34:22.310: INFO: Pod client-containers-5ba24c53-6b1a-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:34:22.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7024" for this suite.
Apr 30 07:34:28.344: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:34:28.545: INFO: namespace containers-7024 deletion completed in 6.225896416s

• [SLOW TEST:12.442 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:34:28.545: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-756.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-756.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 30 07:34:34.716: INFO: DNS probes using dns-756/dns-test-6305bf97-6b1a-11e9-845c-f234dad8a085 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:34:34.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-756" for this suite.
Apr 30 07:34:40.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:34:40.952: INFO: namespace dns-756 deletion completed in 6.208967863s

• [SLOW TEST:12.407 seconds]
[sig-network] DNS
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:34:40.953: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:34:47.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-7774" for this suite.
Apr 30 07:34:53.252: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:34:53.428: INFO: namespace namespaces-7774 deletion completed in 6.214679794s
STEP: Destroying namespace "nsdeletetest-9340" for this suite.
Apr 30 07:34:53.433: INFO: Namespace nsdeletetest-9340 was already deleted
STEP: Destroying namespace "nsdeletetest-3197" for this suite.
Apr 30 07:34:59.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:34:59.619: INFO: namespace nsdeletetest-3197 deletion completed in 6.18685836s

• [SLOW TEST:18.667 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:34:59.620: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-7589ee4f-6b1a-11e9-845c-f234dad8a085
STEP: Creating a pod to test consume configMaps
Apr 30 07:34:59.703: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-758aee52-6b1a-11e9-845c-f234dad8a085" in namespace "projected-6743" to be "success or failure"
Apr 30 07:34:59.711: INFO: Pod "pod-projected-configmaps-758aee52-6b1a-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 7.971733ms
Apr 30 07:35:01.719: INFO: Pod "pod-projected-configmaps-758aee52-6b1a-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016579746s
Apr 30 07:35:03.728: INFO: Pod "pod-projected-configmaps-758aee52-6b1a-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024939023s
STEP: Saw pod success
Apr 30 07:35:03.728: INFO: Pod "pod-projected-configmaps-758aee52-6b1a-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 07:35:03.735: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-projected-configmaps-758aee52-6b1a-11e9-845c-f234dad8a085 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 30 07:35:03.833: INFO: Waiting for pod pod-projected-configmaps-758aee52-6b1a-11e9-845c-f234dad8a085 to disappear
Apr 30 07:35:03.838: INFO: Pod pod-projected-configmaps-758aee52-6b1a-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:35:03.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6743" for this suite.
Apr 30 07:35:09.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:35:10.037: INFO: namespace projected-6743 deletion completed in 6.190646326s

• [SLOW TEST:10.417 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:35:10.038: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-8690
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating stateful set ss in namespace statefulset-8690
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-8690
Apr 30 07:35:10.131: INFO: Found 0 stateful pods, waiting for 1
Apr 30 07:35:20.138: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Apr 30 07:35:20.143: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 exec --namespace=statefulset-8690 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 30 07:35:20.617: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 30 07:35:20.617: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 30 07:35:20.617: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 30 07:35:20.625: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr 30 07:35:30.633: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 30 07:35:30.633: INFO: Waiting for statefulset status.replicas updated to 0
Apr 30 07:35:30.659: INFO: POD   NODE                PHASE    GRACE  CONDITIONS
Apr 30 07:35:30.659: INFO: ss-0  10.10.101.13-slave  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:16 +0000 UTC  }]
Apr 30 07:35:30.659: INFO: 
Apr 30 07:35:30.659: INFO: StatefulSet ss has not reached scale 3, at 1
Apr 30 07:35:31.668: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.991313017s
Apr 30 07:35:32.679: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.980861377s
Apr 30 07:35:33.688: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.97129997s
Apr 30 07:35:34.695: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.96263116s
Apr 30 07:35:35.703: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.955090554s
Apr 30 07:35:36.710: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.947582254s
Apr 30 07:35:37.718: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.939899154s
Apr 30 07:35:38.727: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.932602817s
Apr 30 07:35:39.735: INFO: Verifying statefulset ss doesn't scale past 3 for another 922.583574ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-8690
Apr 30 07:35:40.749: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 exec --namespace=statefulset-8690 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 30 07:35:41.212: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr 30 07:35:41.212: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 30 07:35:41.212: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 30 07:35:41.212: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 exec --namespace=statefulset-8690 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 30 07:35:41.708: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr 30 07:35:41.708: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 30 07:35:41.708: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 30 07:35:41.708: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 exec --namespace=statefulset-8690 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 30 07:35:42.182: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr 30 07:35:42.182: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 30 07:35:42.182: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 30 07:35:42.190: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 30 07:35:42.190: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 30 07:35:42.190: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Apr 30 07:35:42.195: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 exec --namespace=statefulset-8690 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 30 07:35:42.654: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 30 07:35:42.655: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 30 07:35:42.655: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 30 07:35:42.655: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 exec --namespace=statefulset-8690 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 30 07:35:43.179: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 30 07:35:43.179: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 30 07:35:43.179: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 30 07:35:43.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 exec --namespace=statefulset-8690 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 30 07:35:43.666: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr 30 07:35:43.666: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 30 07:35:43.666: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 30 07:35:43.666: INFO: Waiting for statefulset status.replicas updated to 0
Apr 30 07:35:43.673: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Apr 30 07:35:53.694: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 30 07:35:53.695: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr 30 07:35:53.695: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr 30 07:35:53.748: INFO: POD   NODE                PHASE    GRACE  CONDITIONS
Apr 30 07:35:53.748: INFO: ss-0  10.10.101.13-slave  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:16 +0000 UTC  }]
Apr 30 07:35:53.749: INFO: ss-1  10.10.101.14-slave  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:36 +0000 UTC  }]
Apr 30 07:35:53.749: INFO: ss-2  10.10.101.13-slave  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:36 +0000 UTC  }]
Apr 30 07:35:53.749: INFO: 
Apr 30 07:35:53.749: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 30 07:35:54.757: INFO: POD   NODE                PHASE    GRACE  CONDITIONS
Apr 30 07:35:54.757: INFO: ss-0  10.10.101.13-slave  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:16 +0000 UTC  }]
Apr 30 07:35:54.757: INFO: ss-1  10.10.101.14-slave  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:36 +0000 UTC  }]
Apr 30 07:35:54.757: INFO: ss-2  10.10.101.13-slave  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:36 +0000 UTC  }]
Apr 30 07:35:54.758: INFO: 
Apr 30 07:35:54.758: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 30 07:35:55.766: INFO: POD   NODE                PHASE    GRACE  CONDITIONS
Apr 30 07:35:55.767: INFO: ss-0  10.10.101.13-slave  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:16 +0000 UTC  }]
Apr 30 07:35:55.767: INFO: ss-1  10.10.101.14-slave  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:36 +0000 UTC  }]
Apr 30 07:35:55.767: INFO: ss-2  10.10.101.13-slave  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:36 +0000 UTC  }]
Apr 30 07:35:55.767: INFO: 
Apr 30 07:35:55.767: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 30 07:35:56.784: INFO: POD   NODE                PHASE    GRACE  CONDITIONS
Apr 30 07:35:56.784: INFO: ss-0  10.10.101.13-slave  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:16 +0000 UTC  }]
Apr 30 07:35:56.784: INFO: ss-1  10.10.101.14-slave  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:36 +0000 UTC  }]
Apr 30 07:35:56.784: INFO: ss-2  10.10.101.13-slave  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:36 +0000 UTC  }]
Apr 30 07:35:56.784: INFO: 
Apr 30 07:35:56.784: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 30 07:35:57.792: INFO: POD   NODE                PHASE    GRACE  CONDITIONS
Apr 30 07:35:57.792: INFO: ss-0  10.10.101.13-slave  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:16 +0000 UTC  }]
Apr 30 07:35:57.793: INFO: ss-1  10.10.101.14-slave  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:36 +0000 UTC  }]
Apr 30 07:35:57.793: INFO: ss-2  10.10.101.13-slave  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:36 +0000 UTC  }]
Apr 30 07:35:57.793: INFO: 
Apr 30 07:35:57.793: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 30 07:35:58.801: INFO: POD   NODE                PHASE    GRACE  CONDITIONS
Apr 30 07:35:58.801: INFO: ss-0  10.10.101.13-slave  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:16 +0000 UTC  }]
Apr 30 07:35:58.801: INFO: ss-1  10.10.101.14-slave  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:36 +0000 UTC  }]
Apr 30 07:35:58.802: INFO: ss-2  10.10.101.13-slave  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 07:35:36 +0000 UTC  }]
Apr 30 07:35:58.802: INFO: 
Apr 30 07:35:58.802: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 30 07:35:59.809: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.915040856s
Apr 30 07:36:00.815: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.907816913s
Apr 30 07:36:01.822: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.901238206s
Apr 30 07:36:02.836: INFO: Verifying statefulset ss doesn't scale past 0 for another 894.437556ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-8690
Apr 30 07:36:03.844: INFO: Scaling statefulset ss to 0
Apr 30 07:36:03.862: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr 30 07:36:03.868: INFO: Deleting all statefulset in ns statefulset-8690
Apr 30 07:36:03.875: INFO: Scaling statefulset ss to 0
Apr 30 07:36:03.892: INFO: Waiting for statefulset status.replicas updated to 0
Apr 30 07:36:03.898: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:36:03.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8690" for this suite.
Apr 30 07:36:09.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:36:10.140: INFO: namespace statefulset-8690 deletion completed in 6.212999697s

• [SLOW TEST:60.102 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:36:10.141: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-9f967f2d-6b1a-11e9-845c-f234dad8a085
STEP: Creating a pod to test consume secrets
Apr 30 07:36:10.248: INFO: Waiting up to 5m0s for pod "pod-secrets-9f9778e0-6b1a-11e9-845c-f234dad8a085" in namespace "secrets-8470" to be "success or failure"
Apr 30 07:36:10.253: INFO: Pod "pod-secrets-9f9778e0-6b1a-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 4.603683ms
Apr 30 07:36:12.260: INFO: Pod "pod-secrets-9f9778e0-6b1a-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01134138s
Apr 30 07:36:14.267: INFO: Pod "pod-secrets-9f9778e0-6b1a-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018766263s
STEP: Saw pod success
Apr 30 07:36:14.267: INFO: Pod "pod-secrets-9f9778e0-6b1a-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 07:36:14.274: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-secrets-9f9778e0-6b1a-11e9-845c-f234dad8a085 container secret-volume-test: <nil>
STEP: delete the pod
Apr 30 07:36:14.308: INFO: Waiting for pod pod-secrets-9f9778e0-6b1a-11e9-845c-f234dad8a085 to disappear
Apr 30 07:36:14.312: INFO: Pod pod-secrets-9f9778e0-6b1a-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:36:14.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8470" for this suite.
Apr 30 07:36:20.338: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:36:20.539: INFO: namespace secrets-8470 deletion completed in 6.220327477s

• [SLOW TEST:10.399 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:36:20.540: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Apr 30 07:36:20.612: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:36:39.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2088" for this suite.
Apr 30 07:36:45.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:36:45.959: INFO: namespace pods-2088 deletion completed in 6.183549444s

• [SLOW TEST:25.418 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:36:45.959: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Apr 30 07:36:46.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 create -f - --namespace=kubectl-1634'
Apr 30 07:36:46.615: INFO: stderr: ""
Apr 30 07:36:46.615: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 30 07:36:46.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1634'
Apr 30 07:36:46.857: INFO: stderr: ""
Apr 30 07:36:46.857: INFO: stdout: "update-demo-nautilus-7zx7k update-demo-nautilus-wqzmp "
Apr 30 07:36:46.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pods update-demo-nautilus-7zx7k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1634'
Apr 30 07:36:47.101: INFO: stderr: ""
Apr 30 07:36:47.101: INFO: stdout: ""
Apr 30 07:36:47.101: INFO: update-demo-nautilus-7zx7k is created but not running
Apr 30 07:36:52.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1634'
Apr 30 07:36:52.318: INFO: stderr: ""
Apr 30 07:36:52.318: INFO: stdout: "update-demo-nautilus-7zx7k update-demo-nautilus-wqzmp "
Apr 30 07:36:52.318: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pods update-demo-nautilus-7zx7k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1634'
Apr 30 07:36:52.528: INFO: stderr: ""
Apr 30 07:36:52.528: INFO: stdout: "true"
Apr 30 07:36:52.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pods update-demo-nautilus-7zx7k -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1634'
Apr 30 07:36:52.751: INFO: stderr: ""
Apr 30 07:36:52.752: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 30 07:36:52.752: INFO: validating pod update-demo-nautilus-7zx7k
Apr 30 07:36:52.768: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 30 07:36:52.768: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 30 07:36:52.768: INFO: update-demo-nautilus-7zx7k is verified up and running
Apr 30 07:36:52.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pods update-demo-nautilus-wqzmp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1634'
Apr 30 07:36:53.027: INFO: stderr: ""
Apr 30 07:36:53.027: INFO: stdout: "true"
Apr 30 07:36:53.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pods update-demo-nautilus-wqzmp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1634'
Apr 30 07:36:53.236: INFO: stderr: ""
Apr 30 07:36:53.236: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 30 07:36:53.236: INFO: validating pod update-demo-nautilus-wqzmp
Apr 30 07:36:53.252: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 30 07:36:53.252: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 30 07:36:53.252: INFO: update-demo-nautilus-wqzmp is verified up and running
STEP: scaling down the replication controller
Apr 30 07:36:53.269: INFO: scanned /root for discovery docs: <nil>
Apr 30 07:36:53.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-1634'
Apr 30 07:36:54.673: INFO: stderr: ""
Apr 30 07:36:54.673: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 30 07:36:54.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1634'
Apr 30 07:36:54.912: INFO: stderr: ""
Apr 30 07:36:54.912: INFO: stdout: "update-demo-nautilus-7zx7k update-demo-nautilus-wqzmp "
STEP: Replicas for name=update-demo: expected=1 actual=2
Apr 30 07:36:59.913: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1634'
Apr 30 07:37:00.113: INFO: stderr: ""
Apr 30 07:37:00.113: INFO: stdout: "update-demo-nautilus-7zx7k "
Apr 30 07:37:00.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pods update-demo-nautilus-7zx7k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1634'
Apr 30 07:37:00.334: INFO: stderr: ""
Apr 30 07:37:00.334: INFO: stdout: "true"
Apr 30 07:37:00.334: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pods update-demo-nautilus-7zx7k -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1634'
Apr 30 07:37:00.536: INFO: stderr: ""
Apr 30 07:37:00.536: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 30 07:37:00.536: INFO: validating pod update-demo-nautilus-7zx7k
Apr 30 07:37:00.544: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 30 07:37:00.545: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 30 07:37:00.545: INFO: update-demo-nautilus-7zx7k is verified up and running
STEP: scaling up the replication controller
Apr 30 07:37:00.548: INFO: scanned /root for discovery docs: <nil>
Apr 30 07:37:00.549: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-1634'
Apr 30 07:37:01.849: INFO: stderr: ""
Apr 30 07:37:01.849: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 30 07:37:01.849: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1634'
Apr 30 07:37:02.084: INFO: stderr: ""
Apr 30 07:37:02.084: INFO: stdout: "update-demo-nautilus-7zx7k update-demo-nautilus-zzg8s "
Apr 30 07:37:02.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pods update-demo-nautilus-7zx7k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1634'
Apr 30 07:37:02.292: INFO: stderr: ""
Apr 30 07:37:02.293: INFO: stdout: "true"
Apr 30 07:37:02.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pods update-demo-nautilus-7zx7k -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1634'
Apr 30 07:37:02.531: INFO: stderr: ""
Apr 30 07:37:02.531: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 30 07:37:02.531: INFO: validating pod update-demo-nautilus-7zx7k
Apr 30 07:37:02.539: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 30 07:37:02.539: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 30 07:37:02.539: INFO: update-demo-nautilus-7zx7k is verified up and running
Apr 30 07:37:02.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pods update-demo-nautilus-zzg8s -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1634'
Apr 30 07:37:02.771: INFO: stderr: ""
Apr 30 07:37:02.771: INFO: stdout: ""
Apr 30 07:37:02.771: INFO: update-demo-nautilus-zzg8s is created but not running
Apr 30 07:37:07.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1634'
Apr 30 07:37:07.989: INFO: stderr: ""
Apr 30 07:37:07.989: INFO: stdout: "update-demo-nautilus-7zx7k update-demo-nautilus-zzg8s "
Apr 30 07:37:07.989: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pods update-demo-nautilus-7zx7k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1634'
Apr 30 07:37:08.185: INFO: stderr: ""
Apr 30 07:37:08.185: INFO: stdout: "true"
Apr 30 07:37:08.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pods update-demo-nautilus-7zx7k -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1634'
Apr 30 07:37:08.394: INFO: stderr: ""
Apr 30 07:37:08.394: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 30 07:37:08.394: INFO: validating pod update-demo-nautilus-7zx7k
Apr 30 07:37:08.400: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 30 07:37:08.400: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 30 07:37:08.400: INFO: update-demo-nautilus-7zx7k is verified up and running
Apr 30 07:37:08.400: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pods update-demo-nautilus-zzg8s -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1634'
Apr 30 07:37:08.603: INFO: stderr: ""
Apr 30 07:37:08.603: INFO: stdout: "true"
Apr 30 07:37:08.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pods update-demo-nautilus-zzg8s -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1634'
Apr 30 07:37:08.806: INFO: stderr: ""
Apr 30 07:37:08.806: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 30 07:37:08.806: INFO: validating pod update-demo-nautilus-zzg8s
Apr 30 07:37:08.819: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 30 07:37:08.819: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 30 07:37:08.819: INFO: update-demo-nautilus-zzg8s is verified up and running
STEP: using delete to clean up resources
Apr 30 07:37:08.819: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 delete --grace-period=0 --force -f - --namespace=kubectl-1634'
Apr 30 07:37:09.048: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 30 07:37:09.048: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr 30 07:37:09.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-1634'
Apr 30 07:37:09.339: INFO: stderr: "No resources found.\n"
Apr 30 07:37:09.339: INFO: stdout: ""
Apr 30 07:37:09.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pods -l name=update-demo --namespace=kubectl-1634 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 30 07:37:09.616: INFO: stderr: ""
Apr 30 07:37:09.616: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:37:09.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1634" for this suite.
Apr 30 07:37:31.642: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:37:31.806: INFO: namespace kubectl-1634 deletion completed in 22.18163112s

• [SLOW TEST:45.847 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:37:31.807: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr 30 07:37:31.878: INFO: Waiting up to 5m0s for pod "downward-api-d03ee5f1-6b1a-11e9-845c-f234dad8a085" in namespace "downward-api-5201" to be "success or failure"
Apr 30 07:37:31.884: INFO: Pod "downward-api-d03ee5f1-6b1a-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 6.044813ms
Apr 30 07:37:33.892: INFO: Pod "downward-api-d03ee5f1-6b1a-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01447391s
Apr 30 07:37:35.900: INFO: Pod "downward-api-d03ee5f1-6b1a-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022123217s
STEP: Saw pod success
Apr 30 07:37:35.900: INFO: Pod "downward-api-d03ee5f1-6b1a-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 07:37:35.906: INFO: Trying to get logs from node 10.10.101.13-slave pod downward-api-d03ee5f1-6b1a-11e9-845c-f234dad8a085 container dapi-container: <nil>
STEP: delete the pod
Apr 30 07:37:35.943: INFO: Waiting for pod downward-api-d03ee5f1-6b1a-11e9-845c-f234dad8a085 to disappear
Apr 30 07:37:35.948: INFO: Pod downward-api-d03ee5f1-6b1a-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:37:35.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5201" for this suite.
Apr 30 07:37:41.976: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:37:42.153: INFO: namespace downward-api-5201 deletion completed in 6.196796106s

• [SLOW TEST:10.346 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:37:42.153: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr 30 07:37:42.247: INFO: Waiting up to 5m0s for pod "downward-api-d66c0619-6b1a-11e9-845c-f234dad8a085" in namespace "downward-api-2187" to be "success or failure"
Apr 30 07:37:42.260: INFO: Pod "downward-api-d66c0619-6b1a-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 13.022874ms
Apr 30 07:37:44.269: INFO: Pod "downward-api-d66c0619-6b1a-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021658557s
Apr 30 07:37:46.277: INFO: Pod "downward-api-d66c0619-6b1a-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029770797s
STEP: Saw pod success
Apr 30 07:37:46.277: INFO: Pod "downward-api-d66c0619-6b1a-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 07:37:46.284: INFO: Trying to get logs from node 10.10.101.14-slave pod downward-api-d66c0619-6b1a-11e9-845c-f234dad8a085 container dapi-container: <nil>
STEP: delete the pod
Apr 30 07:37:46.333: INFO: Waiting for pod downward-api-d66c0619-6b1a-11e9-845c-f234dad8a085 to disappear
Apr 30 07:37:46.341: INFO: Pod downward-api-d66c0619-6b1a-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:37:46.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2187" for this suite.
Apr 30 07:37:52.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:37:52.532: INFO: namespace downward-api-2187 deletion completed in 6.18386942s

• [SLOW TEST:10.379 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:37:52.533: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on node default medium
Apr 30 07:37:52.621: INFO: Waiting up to 5m0s for pod "pod-dc9c97d5-6b1a-11e9-845c-f234dad8a085" in namespace "emptydir-5239" to be "success or failure"
Apr 30 07:37:52.629: INFO: Pod "pod-dc9c97d5-6b1a-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 8.078177ms
Apr 30 07:37:54.638: INFO: Pod "pod-dc9c97d5-6b1a-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016982387s
Apr 30 07:37:56.644: INFO: Pod "pod-dc9c97d5-6b1a-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023769664s
STEP: Saw pod success
Apr 30 07:37:56.645: INFO: Pod "pod-dc9c97d5-6b1a-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 07:37:56.650: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-dc9c97d5-6b1a-11e9-845c-f234dad8a085 container test-container: <nil>
STEP: delete the pod
Apr 30 07:37:56.716: INFO: Waiting for pod pod-dc9c97d5-6b1a-11e9-845c-f234dad8a085 to disappear
Apr 30 07:37:56.721: INFO: Pod pod-dc9c97d5-6b1a-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:37:56.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5239" for this suite.
Apr 30 07:38:02.746: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:38:02.909: INFO: namespace emptydir-5239 deletion completed in 6.18081273s

• [SLOW TEST:10.376 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:38:02.909: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:38:32.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3696" for this suite.
Apr 30 07:38:38.423: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:38:38.596: INFO: namespace container-runtime-3696 deletion completed in 6.201109806s

• [SLOW TEST:35.687 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  blackbox test
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:38:38.597: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Apr 30 07:38:38.672: INFO: Waiting up to 5m0s for pod "pod-f80f7248-6b1a-11e9-845c-f234dad8a085" in namespace "emptydir-3131" to be "success or failure"
Apr 30 07:38:38.678: INFO: Pod "pod-f80f7248-6b1a-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 5.935116ms
Apr 30 07:38:40.685: INFO: Pod "pod-f80f7248-6b1a-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012312226s
Apr 30 07:38:42.694: INFO: Pod "pod-f80f7248-6b1a-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021328076s
STEP: Saw pod success
Apr 30 07:38:42.694: INFO: Pod "pod-f80f7248-6b1a-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 07:38:42.701: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-f80f7248-6b1a-11e9-845c-f234dad8a085 container test-container: <nil>
STEP: delete the pod
Apr 30 07:38:42.739: INFO: Waiting for pod pod-f80f7248-6b1a-11e9-845c-f234dad8a085 to disappear
Apr 30 07:38:42.745: INFO: Pod pod-f80f7248-6b1a-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:38:42.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3131" for this suite.
Apr 30 07:38:48.773: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:38:49.174: INFO: namespace emptydir-3131 deletion completed in 6.42099104s

• [SLOW TEST:10.577 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:38:49.175: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Apr 30 07:38:49.255: INFO: Waiting up to 5m0s for pod "pod-fe5ddbcf-6b1a-11e9-845c-f234dad8a085" in namespace "emptydir-1469" to be "success or failure"
Apr 30 07:38:49.264: INFO: Pod "pod-fe5ddbcf-6b1a-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 8.306544ms
Apr 30 07:38:51.271: INFO: Pod "pod-fe5ddbcf-6b1a-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015346984s
Apr 30 07:38:53.278: INFO: Pod "pod-fe5ddbcf-6b1a-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02283117s
STEP: Saw pod success
Apr 30 07:38:53.278: INFO: Pod "pod-fe5ddbcf-6b1a-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 07:38:53.285: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-fe5ddbcf-6b1a-11e9-845c-f234dad8a085 container test-container: <nil>
STEP: delete the pod
Apr 30 07:38:53.346: INFO: Waiting for pod pod-fe5ddbcf-6b1a-11e9-845c-f234dad8a085 to disappear
Apr 30 07:38:53.351: INFO: Pod pod-fe5ddbcf-6b1a-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:38:53.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1469" for this suite.
Apr 30 07:38:59.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:38:59.558: INFO: namespace emptydir-1469 deletion completed in 6.198129607s

• [SLOW TEST:10.383 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:38:59.558: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-048d1317-6b1b-11e9-845c-f234dad8a085
STEP: Creating a pod to test consume secrets
Apr 30 07:38:59.635: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-048df2c0-6b1b-11e9-845c-f234dad8a085" in namespace "projected-6813" to be "success or failure"
Apr 30 07:38:59.643: INFO: Pod "pod-projected-secrets-048df2c0-6b1b-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 7.943633ms
Apr 30 07:39:01.649: INFO: Pod "pod-projected-secrets-048df2c0-6b1b-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01462767s
Apr 30 07:39:03.657: INFO: Pod "pod-projected-secrets-048df2c0-6b1b-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021787933s
STEP: Saw pod success
Apr 30 07:39:03.657: INFO: Pod "pod-projected-secrets-048df2c0-6b1b-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 07:39:03.665: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-projected-secrets-048df2c0-6b1b-11e9-845c-f234dad8a085 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 30 07:39:03.703: INFO: Waiting for pod pod-projected-secrets-048df2c0-6b1b-11e9-845c-f234dad8a085 to disappear
Apr 30 07:39:03.711: INFO: Pod pod-projected-secrets-048df2c0-6b1b-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:39:03.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6813" for this suite.
Apr 30 07:39:09.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:39:09.906: INFO: namespace projected-6813 deletion completed in 6.18686398s

• [SLOW TEST:10.349 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:39:09.907: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Apr 30 07:39:20.099: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
	[quantile=0.5] = 24
	[quantile=0.9] = 551
	[quantile=0.99] = 558
For garbage_collector_attempt_to_delete_work_duration:
	[quantile=0.5] = 226873
	[quantile=0.9] = 242489
	[quantile=0.99] = 248608
For garbage_collector_attempt_to_orphan_queue_latency:
	[quantile=0.5] = NaN
	[quantile=0.9] = NaN
	[quantile=0.99] = NaN
For garbage_collector_attempt_to_orphan_work_duration:
	[quantile=0.5] = NaN
	[quantile=0.9] = NaN
	[quantile=0.99] = NaN
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
	[quantile=0.5] = 10
	[quantile=0.9] = 16
	[quantile=0.99] = 87
For garbage_collector_graph_changes_work_duration:
	[quantile=0.5] = 29
	[quantile=0.9] = 57
	[quantile=0.99] = 122
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
	[quantile=0.5] = 26
	[quantile=0.9] = 84
	[quantile=0.99] = 136
For namespace_queue_latency_sum:
	[] = 43228
For namespace_queue_latency_count:
	[] = 1206
For namespace_retries:
	[] = 1220
For namespace_work_duration:
	[quantile=0.5] = 318320
	[quantile=0.9] = 507390
	[quantile=0.99] = 663680
For namespace_work_duration_sum:
	[] = 339495032
For namespace_work_duration_count:
	[] = 1206
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:39:20.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8188" for this suite.
Apr 30 07:39:26.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:39:26.315: INFO: namespace gc-8188 deletion completed in 6.20648807s

• [SLOW TEST:16.408 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:39:26.315: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-1481d28a-6b1b-11e9-845c-f234dad8a085
STEP: Creating configMap with name cm-test-opt-upd-1481d4f5-6b1b-11e9-845c-f234dad8a085
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-1481d28a-6b1b-11e9-845c-f234dad8a085
STEP: Updating configmap cm-test-opt-upd-1481d4f5-6b1b-11e9-845c-f234dad8a085
STEP: Creating configMap with name cm-test-opt-create-1481d563-6b1b-11e9-845c-f234dad8a085
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:39:34.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2953" for this suite.
Apr 30 07:39:56.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:39:56.805: INFO: namespace configmap-2953 deletion completed in 22.185287633s

• [SLOW TEST:30.489 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:39:56.805: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Apr 30 07:39:57.631: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
	[quantile=0.5] = 24
	[quantile=0.9] = 551
	[quantile=0.99] = 558
For garbage_collector_attempt_to_delete_work_duration:
	[quantile=0.5] = 226379
	[quantile=0.9] = 242489
	[quantile=0.99] = 248608
For garbage_collector_attempt_to_orphan_queue_latency:
	[quantile=0.5] = NaN
	[quantile=0.9] = NaN
	[quantile=0.99] = NaN
For garbage_collector_attempt_to_orphan_work_duration:
	[quantile=0.5] = NaN
	[quantile=0.9] = NaN
	[quantile=0.99] = NaN
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
	[quantile=0.5] = 10
	[quantile=0.9] = 16
	[quantile=0.99] = 87
For garbage_collector_graph_changes_work_duration:
	[quantile=0.5] = 29
	[quantile=0.9] = 59
	[quantile=0.99] = 120
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
	[quantile=0.5] = 25
	[quantile=0.9] = 84
	[quantile=0.99] = 136
For namespace_queue_latency_sum:
	[] = 43334
For namespace_queue_latency_count:
	[] = 1210
For namespace_retries:
	[] = 1225
For namespace_work_duration:
	[quantile=0.5] = 337463
	[quantile=0.9] = 507829
	[quantile=0.99] = 663680
For namespace_work_duration_sum:
	[] = 340876523
For namespace_work_duration_count:
	[] = 1210
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:39:57.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3284" for this suite.
Apr 30 07:40:03.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:40:03.864: INFO: namespace gc-3284 deletion completed in 6.225035974s

• [SLOW TEST:7.059 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:40:03.865: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 30 07:40:03.942: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2ae2d5b8-6b1b-11e9-845c-f234dad8a085" in namespace "downward-api-9741" to be "success or failure"
Apr 30 07:40:03.948: INFO: Pod "downwardapi-volume-2ae2d5b8-6b1b-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 6.577713ms
Apr 30 07:40:05.958: INFO: Pod "downwardapi-volume-2ae2d5b8-6b1b-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016155283s
Apr 30 07:40:07.964: INFO: Pod "downwardapi-volume-2ae2d5b8-6b1b-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022255123s
STEP: Saw pod success
Apr 30 07:40:07.964: INFO: Pod "downwardapi-volume-2ae2d5b8-6b1b-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 07:40:07.969: INFO: Trying to get logs from node 10.10.101.13-slave pod downwardapi-volume-2ae2d5b8-6b1b-11e9-845c-f234dad8a085 container client-container: <nil>
STEP: delete the pod
Apr 30 07:40:08.038: INFO: Waiting for pod downwardapi-volume-2ae2d5b8-6b1b-11e9-845c-f234dad8a085 to disappear
Apr 30 07:40:08.043: INFO: Pod downwardapi-volume-2ae2d5b8-6b1b-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:40:08.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9741" for this suite.
Apr 30 07:40:14.072: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:40:14.240: INFO: namespace downward-api-9741 deletion completed in 6.188976577s

• [SLOW TEST:10.375 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:40:14.241: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Apr 30 07:40:14.304: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 create -f - --namespace=kubectl-3736'
Apr 30 07:40:14.988: INFO: stderr: ""
Apr 30 07:40:14.988: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 30 07:40:14.989: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3736'
Apr 30 07:40:15.202: INFO: stderr: ""
Apr 30 07:40:15.202: INFO: stdout: "update-demo-nautilus-78m8n update-demo-nautilus-x6r7s "
Apr 30 07:40:15.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pods update-demo-nautilus-78m8n -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3736'
Apr 30 07:40:15.444: INFO: stderr: ""
Apr 30 07:40:15.444: INFO: stdout: ""
Apr 30 07:40:15.444: INFO: update-demo-nautilus-78m8n is created but not running
Apr 30 07:40:20.445: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3736'
Apr 30 07:40:20.673: INFO: stderr: ""
Apr 30 07:40:20.673: INFO: stdout: "update-demo-nautilus-78m8n update-demo-nautilus-x6r7s "
Apr 30 07:40:20.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pods update-demo-nautilus-78m8n -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3736'
Apr 30 07:40:20.893: INFO: stderr: ""
Apr 30 07:40:20.893: INFO: stdout: "true"
Apr 30 07:40:20.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pods update-demo-nautilus-78m8n -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3736'
Apr 30 07:40:21.119: INFO: stderr: ""
Apr 30 07:40:21.119: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 30 07:40:21.119: INFO: validating pod update-demo-nautilus-78m8n
Apr 30 07:40:21.132: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 30 07:40:21.132: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 30 07:40:21.132: INFO: update-demo-nautilus-78m8n is verified up and running
Apr 30 07:40:21.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pods update-demo-nautilus-x6r7s -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3736'
Apr 30 07:40:21.335: INFO: stderr: ""
Apr 30 07:40:21.335: INFO: stdout: "true"
Apr 30 07:40:21.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pods update-demo-nautilus-x6r7s -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3736'
Apr 30 07:40:21.566: INFO: stderr: ""
Apr 30 07:40:21.566: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 30 07:40:21.566: INFO: validating pod update-demo-nautilus-x6r7s
Apr 30 07:40:21.580: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 30 07:40:21.580: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 30 07:40:21.580: INFO: update-demo-nautilus-x6r7s is verified up and running
STEP: using delete to clean up resources
Apr 30 07:40:21.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 delete --grace-period=0 --force -f - --namespace=kubectl-3736'
Apr 30 07:40:21.820: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 30 07:40:21.820: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr 30 07:40:21.820: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-3736'
Apr 30 07:40:22.108: INFO: stderr: "No resources found.\n"
Apr 30 07:40:22.108: INFO: stdout: ""
Apr 30 07:40:22.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pods -l name=update-demo --namespace=kubectl-3736 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 30 07:40:22.368: INFO: stderr: ""
Apr 30 07:40:22.368: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:40:22.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3736" for this suite.
Apr 30 07:40:44.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:40:44.654: INFO: namespace kubectl-3736 deletion completed in 22.26607733s

• [SLOW TEST:30.414 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:40:44.655: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Apr 30 07:40:54.793: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3316 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 30 07:40:54.793: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
Apr 30 07:40:55.101: INFO: Exec stderr: ""
Apr 30 07:40:55.101: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3316 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 30 07:40:55.101: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
Apr 30 07:40:55.386: INFO: Exec stderr: ""
Apr 30 07:40:55.386: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3316 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 30 07:40:55.386: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
Apr 30 07:40:55.637: INFO: Exec stderr: ""
Apr 30 07:40:55.637: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3316 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 30 07:40:55.637: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
Apr 30 07:40:55.895: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Apr 30 07:40:55.895: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3316 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 30 07:40:55.895: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
Apr 30 07:40:56.137: INFO: Exec stderr: ""
Apr 30 07:40:56.137: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3316 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 30 07:40:56.137: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
Apr 30 07:40:56.376: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Apr 30 07:40:56.376: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3316 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 30 07:40:56.376: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
Apr 30 07:40:56.627: INFO: Exec stderr: ""
Apr 30 07:40:56.627: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3316 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 30 07:40:56.627: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
Apr 30 07:40:56.865: INFO: Exec stderr: ""
Apr 30 07:40:56.865: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3316 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 30 07:40:56.865: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
Apr 30 07:40:57.120: INFO: Exec stderr: ""
Apr 30 07:40:57.120: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3316 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 30 07:40:57.120: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
Apr 30 07:40:57.371: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:40:57.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-3316" for this suite.
Apr 30 07:41:43.398: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:41:43.595: INFO: namespace e2e-kubelet-etc-hosts-3316 deletion completed in 46.215955854s

• [SLOW TEST:58.940 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:41:43.595: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1510
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 30 07:41:43.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-4749'
Apr 30 07:41:43.936: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr 30 07:41:43.936: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1515
Apr 30 07:41:43.952: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 delete jobs e2e-test-nginx-job --namespace=kubectl-4749'
Apr 30 07:41:44.178: INFO: stderr: ""
Apr 30 07:41:44.178: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:41:44.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4749" for this suite.
Apr 30 07:41:50.212: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:41:50.371: INFO: namespace kubectl-4749 deletion completed in 6.18644791s

• [SLOW TEST:6.776 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:41:50.372: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Apr 30 07:41:50.426: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:41:55.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8007" for this suite.
Apr 30 07:42:01.576: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:42:01.744: INFO: namespace init-container-8007 deletion completed in 6.194519143s

• [SLOW TEST:11.373 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:42:01.745: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Apr 30 07:42:01.834: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-275,SelfLink:/api/v1/namespaces/watch-275/configmaps/e2e-watch-test-watch-closed,UID:74bd97a6-6b1b-11e9-924a-005056bc1aae,ResourceVersion:679510,Generation:0,CreationTimestamp:2019-04-30 07:42:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr 30 07:42:01.834: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-275,SelfLink:/api/v1/namespaces/watch-275/configmaps/e2e-watch-test-watch-closed,UID:74bd97a6-6b1b-11e9-924a-005056bc1aae,ResourceVersion:679511,Generation:0,CreationTimestamp:2019-04-30 07:42:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Apr 30 07:42:01.855: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-275,SelfLink:/api/v1/namespaces/watch-275/configmaps/e2e-watch-test-watch-closed,UID:74bd97a6-6b1b-11e9-924a-005056bc1aae,ResourceVersion:679512,Generation:0,CreationTimestamp:2019-04-30 07:42:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr 30 07:42:01.855: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-275,SelfLink:/api/v1/namespaces/watch-275/configmaps/e2e-watch-test-watch-closed,UID:74bd97a6-6b1b-11e9-924a-005056bc1aae,ResourceVersion:679513,Generation:0,CreationTimestamp:2019-04-30 07:42:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:42:01.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-275" for this suite.
Apr 30 07:42:07.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:42:08.095: INFO: namespace watch-275 deletion completed in 6.22993942s

• [SLOW TEST:6.350 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:42:08.095: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1583
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 30 07:42:08.159: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-5073'
Apr 30 07:42:08.382: INFO: stderr: ""
Apr 30 07:42:08.383: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1588
Apr 30 07:42:08.397: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 delete pods e2e-test-nginx-pod --namespace=kubectl-5073'
Apr 30 07:42:09.874: INFO: stderr: ""
Apr 30 07:42:09.874: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:42:09.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5073" for this suite.
Apr 30 07:42:15.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:42:16.067: INFO: namespace kubectl-5073 deletion completed in 6.186150227s

• [SLOW TEST:7.972 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:42:16.068: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 30 07:42:16.143: INFO: Waiting up to 5m0s for pod "downwardapi-volume-79af0190-6b1b-11e9-845c-f234dad8a085" in namespace "downward-api-9173" to be "success or failure"
Apr 30 07:42:16.151: INFO: Pod "downwardapi-volume-79af0190-6b1b-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 7.643753ms
Apr 30 07:42:18.158: INFO: Pod "downwardapi-volume-79af0190-6b1b-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01491971s
Apr 30 07:42:20.165: INFO: Pod "downwardapi-volume-79af0190-6b1b-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02200239s
STEP: Saw pod success
Apr 30 07:42:20.165: INFO: Pod "downwardapi-volume-79af0190-6b1b-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 07:42:20.170: INFO: Trying to get logs from node 10.10.101.13-slave pod downwardapi-volume-79af0190-6b1b-11e9-845c-f234dad8a085 container client-container: <nil>
STEP: delete the pod
Apr 30 07:42:20.212: INFO: Waiting for pod downwardapi-volume-79af0190-6b1b-11e9-845c-f234dad8a085 to disappear
Apr 30 07:42:20.218: INFO: Pod downwardapi-volume-79af0190-6b1b-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:42:20.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9173" for this suite.
Apr 30 07:42:26.247: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:42:26.425: INFO: namespace downward-api-9173 deletion completed in 6.1988954s

• [SLOW TEST:10.358 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:42:26.426: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:42:30.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-6767" for this suite.
Apr 30 07:42:36.615: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:42:36.771: INFO: namespace emptydir-wrapper-6767 deletion completed in 6.178025097s

• [SLOW TEST:10.345 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:42:36.772: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1072.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-1072.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1072.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-1072.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1072.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-1072.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1072.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-1072.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1072.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-1072.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1072.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-1072.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1072.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 144.143.97.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.97.143.144_udp@PTR;check="$$(dig +tcp +noall +answer +search 144.143.97.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.97.143.144_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1072.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-1072.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1072.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-1072.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1072.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-1072.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1072.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-1072.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1072.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-1072.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1072.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-1072.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1072.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 144.143.97.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.97.143.144_udp@PTR;check="$$(dig +tcp +noall +answer +search 144.143.97.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.97.143.144_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 30 07:42:42.937: INFO: Unable to read wheezy_udp@dns-test-service.dns-1072.svc.cluster.local from pod dns-1072/dns-test-860dad15-6b1b-11e9-845c-f234dad8a085: the server could not find the requested resource (get pods dns-test-860dad15-6b1b-11e9-845c-f234dad8a085)
Apr 30 07:42:42.943: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1072.svc.cluster.local from pod dns-1072/dns-test-860dad15-6b1b-11e9-845c-f234dad8a085: the server could not find the requested resource (get pods dns-test-860dad15-6b1b-11e9-845c-f234dad8a085)
Apr 30 07:42:43.007: INFO: Unable to read jessie_udp@dns-test-service.dns-1072.svc.cluster.local from pod dns-1072/dns-test-860dad15-6b1b-11e9-845c-f234dad8a085: the server could not find the requested resource (get pods dns-test-860dad15-6b1b-11e9-845c-f234dad8a085)
Apr 30 07:42:43.013: INFO: Unable to read jessie_tcp@dns-test-service.dns-1072.svc.cluster.local from pod dns-1072/dns-test-860dad15-6b1b-11e9-845c-f234dad8a085: the server could not find the requested resource (get pods dns-test-860dad15-6b1b-11e9-845c-f234dad8a085)
Apr 30 07:42:43.018: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1072.svc.cluster.local from pod dns-1072/dns-test-860dad15-6b1b-11e9-845c-f234dad8a085: the server could not find the requested resource (get pods dns-test-860dad15-6b1b-11e9-845c-f234dad8a085)
Apr 30 07:42:43.066: INFO: Lookups using dns-1072/dns-test-860dad15-6b1b-11e9-845c-f234dad8a085 failed for: [wheezy_udp@dns-test-service.dns-1072.svc.cluster.local wheezy_tcp@dns-test-service.dns-1072.svc.cluster.local jessie_udp@dns-test-service.dns-1072.svc.cluster.local jessie_tcp@dns-test-service.dns-1072.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1072.svc.cluster.local]

Apr 30 07:42:48.206: INFO: DNS probes using dns-1072/dns-test-860dad15-6b1b-11e9-845c-f234dad8a085 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:42:48.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1072" for this suite.
Apr 30 07:42:54.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:42:54.498: INFO: namespace dns-1072 deletion completed in 6.181924264s

• [SLOW TEST:17.726 seconds]
[sig-network] DNS
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:42:54.498: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 30 07:42:54.559: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:42:58.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1001" for this suite.
Apr 30 07:43:38.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:43:38.827: INFO: namespace pods-1001 deletion completed in 40.18543517s

• [SLOW TEST:44.329 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:43:38.828: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service multi-endpoint-test in namespace services-1199
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1199 to expose endpoints map[]
Apr 30 07:43:38.919: INFO: Get endpoints failed (5.828207ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Apr 30 07:43:39.925: INFO: successfully validated that service multi-endpoint-test in namespace services-1199 exposes endpoints map[] (1.011918564s elapsed)
STEP: Creating pod pod1 in namespace services-1199
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1199 to expose endpoints map[pod1:[100]]
Apr 30 07:43:44.026: INFO: successfully validated that service multi-endpoint-test in namespace services-1199 exposes endpoints map[pod1:[100]] (4.08593053s elapsed)
STEP: Creating pod pod2 in namespace services-1199
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1199 to expose endpoints map[pod1:[100] pod2:[101]]
Apr 30 07:43:48.151: INFO: successfully validated that service multi-endpoint-test in namespace services-1199 exposes endpoints map[pod1:[100] pod2:[101]] (4.11726338s elapsed)
STEP: Deleting pod pod1 in namespace services-1199
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1199 to expose endpoints map[pod2:[101]]
Apr 30 07:43:49.186: INFO: successfully validated that service multi-endpoint-test in namespace services-1199 exposes endpoints map[pod2:[101]] (1.026590697s elapsed)
STEP: Deleting pod pod2 in namespace services-1199
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1199 to expose endpoints map[]
Apr 30 07:43:49.205: INFO: successfully validated that service multi-endpoint-test in namespace services-1199 exposes endpoints map[] (7.650167ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:43:49.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1199" for this suite.
Apr 30 07:44:11.269: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:44:11.447: INFO: namespace services-1199 deletion completed in 22.196857317s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:32.619 seconds]
[sig-network] Services
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:44:11.448: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-be77052b-6b1b-11e9-845c-f234dad8a085
STEP: Creating a pod to test consume secrets
Apr 30 07:44:11.544: INFO: Waiting up to 5m0s for pod "pod-secrets-be78007b-6b1b-11e9-845c-f234dad8a085" in namespace "secrets-9261" to be "success or failure"
Apr 30 07:44:11.553: INFO: Pod "pod-secrets-be78007b-6b1b-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 9.108893ms
Apr 30 07:44:13.561: INFO: Pod "pod-secrets-be78007b-6b1b-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016586676s
Apr 30 07:44:15.572: INFO: Pod "pod-secrets-be78007b-6b1b-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02788997s
STEP: Saw pod success
Apr 30 07:44:15.572: INFO: Pod "pod-secrets-be78007b-6b1b-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 07:44:15.582: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-secrets-be78007b-6b1b-11e9-845c-f234dad8a085 container secret-volume-test: <nil>
STEP: delete the pod
Apr 30 07:44:15.700: INFO: Waiting for pod pod-secrets-be78007b-6b1b-11e9-845c-f234dad8a085 to disappear
Apr 30 07:44:15.704: INFO: Pod pod-secrets-be78007b-6b1b-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:44:15.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9261" for this suite.
Apr 30 07:44:21.733: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:44:21.986: INFO: namespace secrets-9261 deletion completed in 6.273303163s

• [SLOW TEST:10.538 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:44:21.986: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Apr 30 07:44:30.158: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 30 07:44:30.164: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 30 07:44:32.164: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 30 07:44:32.171: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 30 07:44:34.164: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 30 07:44:34.171: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 30 07:44:36.164: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 30 07:44:36.171: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 30 07:44:38.164: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 30 07:44:38.172: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 30 07:44:40.164: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 30 07:44:40.171: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 30 07:44:42.164: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 30 07:44:42.170: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 30 07:44:44.164: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 30 07:44:44.172: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 30 07:44:46.164: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 30 07:44:46.172: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 30 07:44:48.164: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 30 07:44:48.171: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 30 07:44:50.164: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 30 07:44:50.171: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 30 07:44:52.165: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 30 07:44:52.172: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 30 07:44:54.164: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 30 07:44:54.171: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 30 07:44:56.164: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 30 07:44:56.171: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 30 07:44:58.164: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 30 07:44:58.171: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 30 07:45:00.164: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 30 07:45:00.171: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:45:00.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9592" for this suite.
Apr 30 07:45:22.197: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:45:22.368: INFO: namespace container-lifecycle-hook-9592 deletion completed in 22.190708553s

• [SLOW TEST:60.382 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:45:22.369: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Apr 30 07:45:26.979: INFO: Successfully updated pod "pod-update-activedeadlineseconds-e8b8da9e-6b1b-11e9-845c-f234dad8a085"
Apr 30 07:45:26.979: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-e8b8da9e-6b1b-11e9-845c-f234dad8a085" in namespace "pods-1966" to be "terminated due to deadline exceeded"
Apr 30 07:45:26.984: INFO: Pod "pod-update-activedeadlineseconds-e8b8da9e-6b1b-11e9-845c-f234dad8a085": Phase="Running", Reason="", readiness=true. Elapsed: 4.617114ms
Apr 30 07:45:28.992: INFO: Pod "pod-update-activedeadlineseconds-e8b8da9e-6b1b-11e9-845c-f234dad8a085": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.012936647s
Apr 30 07:45:28.992: INFO: Pod "pod-update-activedeadlineseconds-e8b8da9e-6b1b-11e9-845c-f234dad8a085" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:45:28.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1966" for this suite.
Apr 30 07:45:35.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:45:35.214: INFO: namespace pods-1966 deletion completed in 6.214140564s

• [SLOW TEST:12.845 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:45:35.214: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-5615
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 30 07:45:35.294: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr 30 07:46:01.435: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.168.6.186:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5615 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 30 07:46:01.435: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
Apr 30 07:46:01.798: INFO: Found all expected endpoints: [netserver-0]
Apr 30 07:46:01.804: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.168.84.228:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5615 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 30 07:46:01.804: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
Apr 30 07:46:02.075: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:46:02.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5615" for this suite.
Apr 30 07:46:24.108: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:46:24.346: INFO: namespace pod-network-test-5615 deletion completed in 22.26330256s

• [SLOW TEST:49.131 seconds]
[sig-network] Networking
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:46:24.347: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-projected-th9t
STEP: Creating a pod to test atomic-volume-subpath
Apr 30 07:46:24.467: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-th9t" in namespace "subpath-2180" to be "success or failure"
Apr 30 07:46:24.481: INFO: Pod "pod-subpath-test-projected-th9t": Phase="Pending", Reason="", readiness=false. Elapsed: 14.167653ms
Apr 30 07:46:26.489: INFO: Pod "pod-subpath-test-projected-th9t": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022276203s
Apr 30 07:46:28.497: INFO: Pod "pod-subpath-test-projected-th9t": Phase="Running", Reason="", readiness=true. Elapsed: 4.030013817s
Apr 30 07:46:30.503: INFO: Pod "pod-subpath-test-projected-th9t": Phase="Running", Reason="", readiness=true. Elapsed: 6.036176767s
Apr 30 07:46:32.508: INFO: Pod "pod-subpath-test-projected-th9t": Phase="Running", Reason="", readiness=true. Elapsed: 8.040930053s
Apr 30 07:46:34.513: INFO: Pod "pod-subpath-test-projected-th9t": Phase="Running", Reason="", readiness=true. Elapsed: 10.046725213s
Apr 30 07:46:36.652: INFO: Pod "pod-subpath-test-projected-th9t": Phase="Running", Reason="", readiness=true. Elapsed: 12.18522064s
Apr 30 07:46:38.660: INFO: Pod "pod-subpath-test-projected-th9t": Phase="Running", Reason="", readiness=true. Elapsed: 14.193099123s
Apr 30 07:46:40.666: INFO: Pod "pod-subpath-test-projected-th9t": Phase="Running", Reason="", readiness=true. Elapsed: 16.19954125s
Apr 30 07:46:42.673: INFO: Pod "pod-subpath-test-projected-th9t": Phase="Running", Reason="", readiness=true. Elapsed: 18.206739307s
Apr 30 07:46:44.681: INFO: Pod "pod-subpath-test-projected-th9t": Phase="Running", Reason="", readiness=true. Elapsed: 20.214756203s
Apr 30 07:46:46.689: INFO: Pod "pod-subpath-test-projected-th9t": Phase="Running", Reason="", readiness=true. Elapsed: 22.22206642s
Apr 30 07:46:48.697: INFO: Pod "pod-subpath-test-projected-th9t": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.230017827s
STEP: Saw pod success
Apr 30 07:46:48.697: INFO: Pod "pod-subpath-test-projected-th9t" satisfied condition "success or failure"
Apr 30 07:46:48.702: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-subpath-test-projected-th9t container test-container-subpath-projected-th9t: <nil>
STEP: delete the pod
Apr 30 07:46:48.753: INFO: Waiting for pod pod-subpath-test-projected-th9t to disappear
Apr 30 07:46:48.761: INFO: Pod pod-subpath-test-projected-th9t no longer exists
STEP: Deleting pod pod-subpath-test-projected-th9t
Apr 30 07:46:48.761: INFO: Deleting pod "pod-subpath-test-projected-th9t" in namespace "subpath-2180"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:46:48.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2180" for this suite.
Apr 30 07:46:54.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:46:54.976: INFO: namespace subpath-2180 deletion completed in 6.20277037s

• [SLOW TEST:30.629 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:46:54.977: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating pod
Apr 30 07:46:59.093: INFO: Pod pod-hostip-1fef6914-6b1c-11e9-845c-f234dad8a085 has hostIP: 10.10.101.13
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:46:59.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4004" for this suite.
Apr 30 07:47:21.120: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:47:21.279: INFO: namespace pods-4004 deletion completed in 22.178163426s

• [SLOW TEST:26.303 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:47:21.280: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
Apr 30 07:47:27.398: INFO: 0 pods remaining
Apr 30 07:47:27.398: INFO: 0 pods has nil DeletionTimestamp
Apr 30 07:47:27.398: INFO: 
STEP: Gathering metrics
Apr 30 07:47:28.478: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
	[quantile=0.5] = 464
	[quantile=0.9] = 100323
	[quantile=0.99] = 113562
For garbage_collector_attempt_to_delete_work_duration:
	[quantile=0.5] = 34417
	[quantile=0.9] = 319818
	[quantile=0.99] = 333047
For garbage_collector_attempt_to_orphan_queue_latency:
	[quantile=0.5] = NaN
	[quantile=0.9] = NaN
	[quantile=0.99] = NaN
For garbage_collector_attempt_to_orphan_work_duration:
	[quantile=0.5] = NaN
	[quantile=0.9] = NaN
	[quantile=0.99] = NaN
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
	[quantile=0.5] = 9
	[quantile=0.9] = 16
	[quantile=0.99] = 127
For garbage_collector_graph_changes_work_duration:
	[quantile=0.5] = 28
	[quantile=0.9] = 53
	[quantile=0.99] = 121
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
	[quantile=0.5] = 27
	[quantile=0.9] = 52
	[quantile=0.99] = 93
For namespace_queue_latency_sum:
	[] = 45442
For namespace_queue_latency_count:
	[] = 1267
For namespace_retries:
	[] = 1283
For namespace_work_duration:
	[quantile=0.5] = 335944
	[quantile=0.9] = 469567
	[quantile=0.99] = 629612
For namespace_work_duration_sum:
	[] = 355393030
For namespace_work_duration_count:
	[] = 1267
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:47:28.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2410" for this suite.
Apr 30 07:47:34.511: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:47:34.712: INFO: namespace gc-2410 deletion completed in 6.225218703s

• [SLOW TEST:13.432 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:47:34.712: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Apr 30 07:47:34.790: INFO: Waiting up to 5m0s for pod "pod-379c5e20-6b1c-11e9-845c-f234dad8a085" in namespace "emptydir-6884" to be "success or failure"
Apr 30 07:47:34.795: INFO: Pod "pod-379c5e20-6b1c-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 5.695973ms
Apr 30 07:47:36.814: INFO: Pod "pod-379c5e20-6b1c-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024455076s
Apr 30 07:47:38.822: INFO: Pod "pod-379c5e20-6b1c-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032195716s
STEP: Saw pod success
Apr 30 07:47:38.822: INFO: Pod "pod-379c5e20-6b1c-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 07:47:38.828: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-379c5e20-6b1c-11e9-845c-f234dad8a085 container test-container: <nil>
STEP: delete the pod
Apr 30 07:47:38.877: INFO: Waiting for pod pod-379c5e20-6b1c-11e9-845c-f234dad8a085 to disappear
Apr 30 07:47:38.882: INFO: Pod pod-379c5e20-6b1c-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:47:38.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6884" for this suite.
Apr 30 07:47:44.913: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:47:45.097: INFO: namespace emptydir-6884 deletion completed in 6.20615556s

• [SLOW TEST:10.384 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:47:45.097: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Apr 30 07:47:55.392: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
	[quantile=0.5] = 764
	[quantile=0.9] = 131416
	[quantile=0.99] = 598153
For garbage_collector_attempt_to_delete_work_duration:
	[quantile=0.5] = 123179
	[quantile=0.9] = 544477
	[quantile=0.99] = 704392
For garbage_collector_attempt_to_orphan_queue_latency:
	[quantile=0.5] = NaN
	[quantile=0.9] = NaN
	[quantile=0.99] = NaN
For garbage_collector_attempt_to_orphan_work_duration:
	[quantile=0.5] = NaN
	[quantile=0.9] = NaN
	[quantile=0.99] = NaN
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
	[quantile=0.5] = 9
	[quantile=0.9] = 16
	[quantile=0.99] = 208
For garbage_collector_graph_changes_work_duration:
	[quantile=0.5] = 28
	[quantile=0.9] = 57
	[quantile=0.99] = 124
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
	[quantile=0.5] = 27
	[quantile=0.9] = 52
	[quantile=0.99] = 93
For namespace_queue_latency_sum:
	[] = 45553
For namespace_queue_latency_count:
	[] = 1271
For namespace_retries:
	[] = 1287
For namespace_work_duration:
	[quantile=0.5] = 335944
	[quantile=0.9] = 482739
	[quantile=0.99] = 714085
For namespace_work_duration_sum:
	[] = 356747160
For namespace_work_duration_count:
	[] = 1271
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:47:55.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2260" for this suite.
Apr 30 07:48:01.421: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:48:01.617: INFO: namespace gc-2260 deletion completed in 6.21795022s

• [SLOW TEST:16.520 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:48:01.619: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-8vgjs in namespace proxy-1316
I0430 07:48:01.725497      17 runners.go:184] Created replication controller with name: proxy-service-8vgjs, namespace: proxy-1316, replica count: 1
I0430 07:48:02.776379      17 runners.go:184] proxy-service-8vgjs Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0430 07:48:03.777018      17 runners.go:184] proxy-service-8vgjs Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0430 07:48:04.778108      17 runners.go:184] proxy-service-8vgjs Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0430 07:48:05.778562      17 runners.go:184] proxy-service-8vgjs Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0430 07:48:06.779158      17 runners.go:184] proxy-service-8vgjs Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0430 07:48:07.779658      17 runners.go:184] proxy-service-8vgjs Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0430 07:48:08.780450      17 runners.go:184] proxy-service-8vgjs Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0430 07:48:09.780869      17 runners.go:184] proxy-service-8vgjs Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0430 07:48:10.781838      17 runners.go:184] proxy-service-8vgjs Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0430 07:48:11.782230      17 runners.go:184] proxy-service-8vgjs Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 30 07:48:11.788: INFO: setup took 10.105716507s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Apr 30 07:48:11.809: INFO: (0) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:162/proxy/: bar (200; 19.4023ms)
Apr 30 07:48:11.811: INFO: (0) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:160/proxy/: foo (200; 20.92032ms)
Apr 30 07:48:11.811: INFO: (0) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:1080/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:1080/proxy/rewriteme">test<... (200; 21.735067ms)
Apr 30 07:48:11.811: INFO: (0) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:1080/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:1080/proxy/rewriteme">... (200; 21.329666ms)
Apr 30 07:48:11.811: INFO: (0) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:162/proxy/: bar (200; 21.533713ms)
Apr 30 07:48:11.812: INFO: (0) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q/proxy/rewriteme">test</a> (200; 22.99646ms)
Apr 30 07:48:11.814: INFO: (0) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:160/proxy/: foo (200; 26.00402ms)
Apr 30 07:48:11.822: INFO: (0) /api/v1/namespaces/proxy-1316/services/http:proxy-service-8vgjs:portname1/proxy/: foo (200; 31.498254ms)
Apr 30 07:48:11.823: INFO: (0) /api/v1/namespaces/proxy-1316/services/proxy-service-8vgjs:portname2/proxy/: bar (200; 33.533414ms)
Apr 30 07:48:11.823: INFO: (0) /api/v1/namespaces/proxy-1316/services/proxy-service-8vgjs:portname1/proxy/: foo (200; 33.974073ms)
Apr 30 07:48:11.830: INFO: (0) /api/v1/namespaces/proxy-1316/services/http:proxy-service-8vgjs:portname2/proxy/: bar (200; 39.693203ms)
Apr 30 07:48:11.837: INFO: (0) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:460/proxy/: tls baz (200; 46.79362ms)
Apr 30 07:48:11.837: INFO: (0) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:443/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:443/proxy/tlsrewritem... (200; 46.738183ms)
Apr 30 07:48:11.839: INFO: (0) /api/v1/namespaces/proxy-1316/services/https:proxy-service-8vgjs:tlsportname2/proxy/: tls qux (200; 49.561514ms)
Apr 30 07:48:11.839: INFO: (0) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:462/proxy/: tls qux (200; 49.011417ms)
Apr 30 07:48:11.840: INFO: (0) /api/v1/namespaces/proxy-1316/services/https:proxy-service-8vgjs:tlsportname1/proxy/: tls baz (200; 49.433334ms)
Apr 30 07:48:11.853: INFO: (1) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:160/proxy/: foo (200; 13.009203ms)
Apr 30 07:48:11.860: INFO: (1) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:160/proxy/: foo (200; 19.260057ms)
Apr 30 07:48:11.860: INFO: (1) /api/v1/namespaces/proxy-1316/services/https:proxy-service-8vgjs:tlsportname2/proxy/: tls qux (200; 19.71836ms)
Apr 30 07:48:11.860: INFO: (1) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q/proxy/rewriteme">test</a> (200; 19.28799ms)
Apr 30 07:48:11.860: INFO: (1) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:162/proxy/: bar (200; 19.172124ms)
Apr 30 07:48:11.860: INFO: (1) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:462/proxy/: tls qux (200; 19.768783ms)
Apr 30 07:48:11.861: INFO: (1) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:1080/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:1080/proxy/rewriteme">... (200; 20.756597ms)
Apr 30 07:48:11.862: INFO: (1) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:443/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:443/proxy/tlsrewritem... (200; 20.640473ms)
Apr 30 07:48:11.862: INFO: (1) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:460/proxy/: tls baz (200; 21.34651ms)
Apr 30 07:48:11.863: INFO: (1) /api/v1/namespaces/proxy-1316/services/proxy-service-8vgjs:portname1/proxy/: foo (200; 23.47701ms)
Apr 30 07:48:11.864: INFO: (1) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:1080/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:1080/proxy/rewriteme">test<... (200; 23.34703ms)
Apr 30 07:48:11.864: INFO: (1) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:162/proxy/: bar (200; 23.849817ms)
Apr 30 07:48:11.865: INFO: (1) /api/v1/namespaces/proxy-1316/services/http:proxy-service-8vgjs:portname1/proxy/: foo (200; 23.650047ms)
Apr 30 07:48:11.865: INFO: (1) /api/v1/namespaces/proxy-1316/services/https:proxy-service-8vgjs:tlsportname1/proxy/: tls baz (200; 23.48094ms)
Apr 30 07:48:11.865: INFO: (1) /api/v1/namespaces/proxy-1316/services/proxy-service-8vgjs:portname2/proxy/: bar (200; 24.955167ms)
Apr 30 07:48:11.866: INFO: (1) /api/v1/namespaces/proxy-1316/services/http:proxy-service-8vgjs:portname2/proxy/: bar (200; 25.831414ms)
Apr 30 07:48:11.886: INFO: (2) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:160/proxy/: foo (200; 18.407147ms)
Apr 30 07:48:11.887: INFO: (2) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:1080/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:1080/proxy/rewriteme">test<... (200; 19.331477ms)
Apr 30 07:48:11.887: INFO: (2) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:160/proxy/: foo (200; 20.786016ms)
Apr 30 07:48:11.889: INFO: (2) /api/v1/namespaces/proxy-1316/services/http:proxy-service-8vgjs:portname1/proxy/: foo (200; 19.024524ms)
Apr 30 07:48:11.891: INFO: (2) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:162/proxy/: bar (200; 21.663457ms)
Apr 30 07:48:11.891: INFO: (2) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:460/proxy/: tls baz (200; 23.19759ms)
Apr 30 07:48:11.893: INFO: (2) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q/proxy/rewriteme">test</a> (200; 23.55979ms)
Apr 30 07:48:11.893: INFO: (2) /api/v1/namespaces/proxy-1316/services/proxy-service-8vgjs:portname1/proxy/: foo (200; 25.934563ms)
Apr 30 07:48:11.893: INFO: (2) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:1080/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:1080/proxy/rewriteme">... (200; 23.442046ms)
Apr 30 07:48:11.893: INFO: (2) /api/v1/namespaces/proxy-1316/services/https:proxy-service-8vgjs:tlsportname1/proxy/: tls baz (200; 22.29233ms)
Apr 30 07:48:11.893: INFO: (2) /api/v1/namespaces/proxy-1316/services/proxy-service-8vgjs:portname2/proxy/: bar (200; 25.78756ms)
Apr 30 07:48:11.894: INFO: (2) /api/v1/namespaces/proxy-1316/services/http:proxy-service-8vgjs:portname2/proxy/: bar (200; 25.473266ms)
Apr 30 07:48:11.895: INFO: (2) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:462/proxy/: tls qux (200; 24.608943ms)
Apr 30 07:48:11.895: INFO: (2) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:162/proxy/: bar (200; 26.31236ms)
Apr 30 07:48:11.895: INFO: (2) /api/v1/namespaces/proxy-1316/services/https:proxy-service-8vgjs:tlsportname2/proxy/: tls qux (200; 27.769837ms)
Apr 30 07:48:11.895: INFO: (2) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:443/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:443/proxy/tlsrewritem... (200; 25.463626ms)
Apr 30 07:48:11.908: INFO: (3) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:160/proxy/: foo (200; 13.030133ms)
Apr 30 07:48:11.914: INFO: (3) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:162/proxy/: bar (200; 15.96613ms)
Apr 30 07:48:11.915: INFO: (3) /api/v1/namespaces/proxy-1316/services/https:proxy-service-8vgjs:tlsportname2/proxy/: tls qux (200; 18.660313ms)
Apr 30 07:48:11.919: INFO: (3) /api/v1/namespaces/proxy-1316/services/https:proxy-service-8vgjs:tlsportname1/proxy/: tls baz (200; 20.39005ms)
Apr 30 07:48:11.920: INFO: (3) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:1080/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:1080/proxy/rewriteme">test<... (200; 23.205603ms)
Apr 30 07:48:11.921: INFO: (3) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:1080/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:1080/proxy/rewriteme">... (200; 22.546703ms)
Apr 30 07:48:11.921: INFO: (3) /api/v1/namespaces/proxy-1316/services/proxy-service-8vgjs:portname2/proxy/: bar (200; 24.54619ms)
Apr 30 07:48:11.921: INFO: (3) /api/v1/namespaces/proxy-1316/services/http:proxy-service-8vgjs:portname1/proxy/: foo (200; 22.083387ms)
Apr 30 07:48:11.921: INFO: (3) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:160/proxy/: foo (200; 23.82991ms)
Apr 30 07:48:11.922: INFO: (3) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:162/proxy/: bar (200; 24.245146ms)
Apr 30 07:48:11.922: INFO: (3) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:462/proxy/: tls qux (200; 24.120197ms)
Apr 30 07:48:11.923: INFO: (3) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:443/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:443/proxy/tlsrewritem... (200; 23.915156ms)
Apr 30 07:48:11.923: INFO: (3) /api/v1/namespaces/proxy-1316/services/proxy-service-8vgjs:portname1/proxy/: foo (200; 27.100836ms)
Apr 30 07:48:11.923: INFO: (3) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:460/proxy/: tls baz (200; 25.765604ms)
Apr 30 07:48:11.924: INFO: (3) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q/proxy/rewriteme">test</a> (200; 25.856157ms)
Apr 30 07:48:11.924: INFO: (3) /api/v1/namespaces/proxy-1316/services/http:proxy-service-8vgjs:portname2/proxy/: bar (200; 26.99049ms)
Apr 30 07:48:11.945: INFO: (4) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:460/proxy/: tls baz (200; 20.906794ms)
Apr 30 07:48:11.946: INFO: (4) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:162/proxy/: bar (200; 21.578966ms)
Apr 30 07:48:11.947: INFO: (4) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:1080/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:1080/proxy/rewriteme">... (200; 21.63904ms)
Apr 30 07:48:11.947: INFO: (4) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:1080/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:1080/proxy/rewriteme">test<... (200; 21.368427ms)
Apr 30 07:48:11.948: INFO: (4) /api/v1/namespaces/proxy-1316/services/http:proxy-service-8vgjs:portname1/proxy/: foo (200; 23.676674ms)
Apr 30 07:48:11.949: INFO: (4) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:160/proxy/: foo (200; 23.730887ms)
Apr 30 07:48:11.950: INFO: (4) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:443/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:443/proxy/tlsrewritem... (200; 24.392923ms)
Apr 30 07:48:11.950: INFO: (4) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:162/proxy/: bar (200; 24.699743ms)
Apr 30 07:48:11.950: INFO: (4) /api/v1/namespaces/proxy-1316/services/https:proxy-service-8vgjs:tlsportname2/proxy/: tls qux (200; 24.41042ms)
Apr 30 07:48:11.950: INFO: (4) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:462/proxy/: tls qux (200; 24.56941ms)
Apr 30 07:48:11.951: INFO: (4) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:160/proxy/: foo (200; 24.860877ms)
Apr 30 07:48:11.951: INFO: (4) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q/proxy/rewriteme">test</a> (200; 25.75798ms)
Apr 30 07:48:11.951: INFO: (4) /api/v1/namespaces/proxy-1316/services/proxy-service-8vgjs:portname1/proxy/: foo (200; 25.423784ms)
Apr 30 07:48:11.956: INFO: (4) /api/v1/namespaces/proxy-1316/services/proxy-service-8vgjs:portname2/proxy/: bar (200; 30.257676ms)
Apr 30 07:48:11.956: INFO: (4) /api/v1/namespaces/proxy-1316/services/http:proxy-service-8vgjs:portname2/proxy/: bar (200; 31.108883ms)
Apr 30 07:48:11.956: INFO: (4) /api/v1/namespaces/proxy-1316/services/https:proxy-service-8vgjs:tlsportname1/proxy/: tls baz (200; 30.528583ms)
Apr 30 07:48:11.964: INFO: (5) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:160/proxy/: foo (200; 8.19094ms)
Apr 30 07:48:11.965: INFO: (5) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:162/proxy/: bar (200; 8.75742ms)
Apr 30 07:48:11.970: INFO: (5) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:1080/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:1080/proxy/rewriteme">... (200; 14.308127ms)
Apr 30 07:48:11.971: INFO: (5) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:162/proxy/: bar (200; 14.247443ms)
Apr 30 07:48:11.971: INFO: (5) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:443/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:443/proxy/tlsrewritem... (200; 14.428077ms)
Apr 30 07:48:11.971: INFO: (5) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:462/proxy/: tls qux (200; 14.44897ms)
Apr 30 07:48:11.976: INFO: (5) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:460/proxy/: tls baz (200; 18.682487ms)
Apr 30 07:48:11.976: INFO: (5) /api/v1/namespaces/proxy-1316/services/https:proxy-service-8vgjs:tlsportname2/proxy/: tls qux (200; 18.851244ms)
Apr 30 07:48:11.976: INFO: (5) /api/v1/namespaces/proxy-1316/services/http:proxy-service-8vgjs:portname2/proxy/: bar (200; 18.901857ms)
Apr 30 07:48:11.976: INFO: (5) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:160/proxy/: foo (200; 18.870893ms)
Apr 30 07:48:11.976: INFO: (5) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q/proxy/rewriteme">test</a> (200; 19.63799ms)
Apr 30 07:48:11.976: INFO: (5) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:1080/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:1080/proxy/rewriteme">test<... (200; 19.37168ms)
Apr 30 07:48:11.979: INFO: (5) /api/v1/namespaces/proxy-1316/services/proxy-service-8vgjs:portname2/proxy/: bar (200; 22.08512ms)
Apr 30 07:48:11.980: INFO: (5) /api/v1/namespaces/proxy-1316/services/proxy-service-8vgjs:portname1/proxy/: foo (200; 23.06084ms)
Apr 30 07:48:11.980: INFO: (5) /api/v1/namespaces/proxy-1316/services/http:proxy-service-8vgjs:portname1/proxy/: foo (200; 23.335497ms)
Apr 30 07:48:11.980: INFO: (5) /api/v1/namespaces/proxy-1316/services/https:proxy-service-8vgjs:tlsportname1/proxy/: tls baz (200; 23.46243ms)
Apr 30 07:48:12.001: INFO: (6) /api/v1/namespaces/proxy-1316/services/proxy-service-8vgjs:portname2/proxy/: bar (200; 19.471557ms)
Apr 30 07:48:12.002: INFO: (6) /api/v1/namespaces/proxy-1316/services/proxy-service-8vgjs:portname1/proxy/: foo (200; 21.582387ms)
Apr 30 07:48:12.002: INFO: (6) /api/v1/namespaces/proxy-1316/services/http:proxy-service-8vgjs:portname1/proxy/: foo (200; 20.2951ms)
Apr 30 07:48:12.002: INFO: (6) /api/v1/namespaces/proxy-1316/services/http:proxy-service-8vgjs:portname2/proxy/: bar (200; 21.384997ms)
Apr 30 07:48:12.003: INFO: (6) /api/v1/namespaces/proxy-1316/services/https:proxy-service-8vgjs:tlsportname1/proxy/: tls baz (200; 22.69558ms)
Apr 30 07:48:12.004: INFO: (6) /api/v1/namespaces/proxy-1316/services/https:proxy-service-8vgjs:tlsportname2/proxy/: tls qux (200; 22.04049ms)
Apr 30 07:48:12.004: INFO: (6) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:460/proxy/: tls baz (200; 22.050334ms)
Apr 30 07:48:12.005: INFO: (6) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:162/proxy/: bar (200; 24.73969ms)
Apr 30 07:48:12.005: INFO: (6) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:160/proxy/: foo (200; 24.031793ms)
Apr 30 07:48:12.005: INFO: (6) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:162/proxy/: bar (200; 24.575184ms)
Apr 30 07:48:12.008: INFO: (6) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:1080/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:1080/proxy/rewriteme">test<... (200; 26.802613ms)
Apr 30 07:48:12.008: INFO: (6) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:160/proxy/: foo (200; 26.563523ms)
Apr 30 07:48:12.009: INFO: (6) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:1080/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:1080/proxy/rewriteme">... (200; 28.516166ms)
Apr 30 07:48:12.010: INFO: (6) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:443/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:443/proxy/tlsrewritem... (200; 28.824453ms)
Apr 30 07:48:12.010: INFO: (6) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:462/proxy/: tls qux (200; 28.98346ms)
Apr 30 07:48:12.010: INFO: (6) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q/proxy/rewriteme">test</a> (200; 28.971043ms)
Apr 30 07:48:12.024: INFO: (7) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:162/proxy/: bar (200; 13.921296ms)
Apr 30 07:48:12.024: INFO: (7) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:1080/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:1080/proxy/rewriteme">... (200; 13.423304ms)
Apr 30 07:48:12.024: INFO: (7) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q/proxy/rewriteme">test</a> (200; 13.667617ms)
Apr 30 07:48:12.025: INFO: (7) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:1080/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:1080/proxy/rewriteme">test<... (200; 14.33792ms)
Apr 30 07:48:12.025: INFO: (7) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:443/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:443/proxy/tlsrewritem... (200; 14.143213ms)
Apr 30 07:48:12.025: INFO: (7) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:160/proxy/: foo (200; 14.37121ms)
Apr 30 07:48:12.025: INFO: (7) /api/v1/namespaces/proxy-1316/services/http:proxy-service-8vgjs:portname2/proxy/: bar (200; 13.916773ms)
Apr 30 07:48:12.026: INFO: (7) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:160/proxy/: foo (200; 15.58033ms)
Apr 30 07:48:12.026: INFO: (7) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:162/proxy/: bar (200; 15.542967ms)
Apr 30 07:48:12.026: INFO: (7) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:460/proxy/: tls baz (200; 15.213214ms)
Apr 30 07:48:12.030: INFO: (7) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:462/proxy/: tls qux (200; 19.07574ms)
Apr 30 07:48:12.031: INFO: (7) /api/v1/namespaces/proxy-1316/services/http:proxy-service-8vgjs:portname1/proxy/: foo (200; 19.44413ms)
Apr 30 07:48:12.033: INFO: (7) /api/v1/namespaces/proxy-1316/services/https:proxy-service-8vgjs:tlsportname2/proxy/: tls qux (200; 21.519787ms)
Apr 30 07:48:12.033: INFO: (7) /api/v1/namespaces/proxy-1316/services/https:proxy-service-8vgjs:tlsportname1/proxy/: tls baz (200; 21.72207ms)
Apr 30 07:48:12.033: INFO: (7) /api/v1/namespaces/proxy-1316/services/proxy-service-8vgjs:portname2/proxy/: bar (200; 22.682047ms)
Apr 30 07:48:12.034: INFO: (7) /api/v1/namespaces/proxy-1316/services/proxy-service-8vgjs:portname1/proxy/: foo (200; 23.097357ms)
Apr 30 07:48:12.043: INFO: (8) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:462/proxy/: tls qux (200; 8.81236ms)
Apr 30 07:48:12.043: INFO: (8) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:1080/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:1080/proxy/rewriteme">test<... (200; 9.276703ms)
Apr 30 07:48:12.050: INFO: (8) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:162/proxy/: bar (200; 15.139873ms)
Apr 30 07:48:12.052: INFO: (8) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:443/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:443/proxy/tlsrewritem... (200; 17.00816ms)
Apr 30 07:48:12.052: INFO: (8) /api/v1/namespaces/proxy-1316/services/proxy-service-8vgjs:portname2/proxy/: bar (200; 17.651303ms)
Apr 30 07:48:12.052: INFO: (8) /api/v1/namespaces/proxy-1316/services/proxy-service-8vgjs:portname1/proxy/: foo (200; 17.773384ms)
Apr 30 07:48:12.052: INFO: (8) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q/proxy/rewriteme">test</a> (200; 17.65419ms)
Apr 30 07:48:12.052: INFO: (8) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:460/proxy/: tls baz (200; 17.67124ms)
Apr 30 07:48:12.053: INFO: (8) /api/v1/namespaces/proxy-1316/services/http:proxy-service-8vgjs:portname2/proxy/: bar (200; 18.089394ms)
Apr 30 07:48:12.053: INFO: (8) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:160/proxy/: foo (200; 19.178343ms)
Apr 30 07:48:12.053: INFO: (8) /api/v1/namespaces/proxy-1316/services/https:proxy-service-8vgjs:tlsportname2/proxy/: tls qux (200; 19.01307ms)
Apr 30 07:48:12.053: INFO: (8) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:1080/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:1080/proxy/rewriteme">... (200; 18.686863ms)
Apr 30 07:48:12.054: INFO: (8) /api/v1/namespaces/proxy-1316/services/http:proxy-service-8vgjs:portname1/proxy/: foo (200; 19.92751ms)
Apr 30 07:48:12.054: INFO: (8) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:160/proxy/: foo (200; 19.473347ms)
Apr 30 07:48:12.054: INFO: (8) /api/v1/namespaces/proxy-1316/services/https:proxy-service-8vgjs:tlsportname1/proxy/: tls baz (200; 20.319046ms)
Apr 30 07:48:12.055: INFO: (8) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:162/proxy/: bar (200; 20.76779ms)
Apr 30 07:48:12.068: INFO: (9) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q/proxy/rewriteme">test</a> (200; 11.442016ms)
Apr 30 07:48:12.068: INFO: (9) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:462/proxy/: tls qux (200; 11.752984ms)
Apr 30 07:48:12.069: INFO: (9) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:162/proxy/: bar (200; 13.005763ms)
Apr 30 07:48:12.069: INFO: (9) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:443/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:443/proxy/tlsrewritem... (200; 12.456764ms)
Apr 30 07:48:12.072: INFO: (9) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:162/proxy/: bar (200; 16.211117ms)
Apr 30 07:48:12.072: INFO: (9) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:1080/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:1080/proxy/rewriteme">test<... (200; 13.64035ms)
Apr 30 07:48:12.073: INFO: (9) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:160/proxy/: foo (200; 15.55474ms)
Apr 30 07:48:12.076: INFO: (9) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:1080/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:1080/proxy/rewriteme">... (200; 19.078557ms)
Apr 30 07:48:12.077: INFO: (9) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:460/proxy/: tls baz (200; 18.768684ms)
Apr 30 07:48:12.077: INFO: (9) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:160/proxy/: foo (200; 19.642317ms)
Apr 30 07:48:12.081: INFO: (9) /api/v1/namespaces/proxy-1316/services/http:proxy-service-8vgjs:portname1/proxy/: foo (200; 22.393337ms)
Apr 30 07:48:12.081: INFO: (9) /api/v1/namespaces/proxy-1316/services/https:proxy-service-8vgjs:tlsportname1/proxy/: tls baz (200; 22.857576ms)
Apr 30 07:48:12.082: INFO: (9) /api/v1/namespaces/proxy-1316/services/proxy-service-8vgjs:portname1/proxy/: foo (200; 24.1515ms)
Apr 30 07:48:12.082: INFO: (9) /api/v1/namespaces/proxy-1316/services/http:proxy-service-8vgjs:portname2/proxy/: bar (200; 24.040654ms)
Apr 30 07:48:12.082: INFO: (9) /api/v1/namespaces/proxy-1316/services/https:proxy-service-8vgjs:tlsportname2/proxy/: tls qux (200; 23.797297ms)
Apr 30 07:48:12.082: INFO: (9) /api/v1/namespaces/proxy-1316/services/proxy-service-8vgjs:portname2/proxy/: bar (200; 24.43124ms)
Apr 30 07:48:12.091: INFO: (10) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:162/proxy/: bar (200; 7.842363ms)
Apr 30 07:48:12.091: INFO: (10) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:1080/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:1080/proxy/rewriteme">... (200; 8.53104ms)
Apr 30 07:48:12.091: INFO: (10) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:443/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:443/proxy/tlsrewritem... (200; 8.08238ms)
Apr 30 07:48:12.095: INFO: (10) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:162/proxy/: bar (200; 10.52977ms)
Apr 30 07:48:12.096: INFO: (10) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:462/proxy/: tls qux (200; 12.972857ms)
Apr 30 07:48:12.097: INFO: (10) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q/proxy/rewriteme">test</a> (200; 12.731806ms)
Apr 30 07:48:12.097: INFO: (10) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:460/proxy/: tls baz (200; 11.81819ms)
Apr 30 07:48:12.097: INFO: (10) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:1080/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:1080/proxy/rewriteme">test<... (200; 12.169644ms)
Apr 30 07:48:12.097: INFO: (10) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:160/proxy/: foo (200; 13.035334ms)
Apr 30 07:48:12.098: INFO: (10) /api/v1/namespaces/proxy-1316/services/http:proxy-service-8vgjs:portname2/proxy/: bar (200; 15.690414ms)
Apr 30 07:48:12.098: INFO: (10) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:160/proxy/: foo (200; 13.627547ms)
Apr 30 07:48:12.103: INFO: (10) /api/v1/namespaces/proxy-1316/services/https:proxy-service-8vgjs:tlsportname2/proxy/: tls qux (200; 18.334647ms)
Apr 30 07:48:12.104: INFO: (10) /api/v1/namespaces/proxy-1316/services/proxy-service-8vgjs:portname2/proxy/: bar (200; 18.55907ms)
Apr 30 07:48:12.104: INFO: (10) /api/v1/namespaces/proxy-1316/services/proxy-service-8vgjs:portname1/proxy/: foo (200; 18.95809ms)
Apr 30 07:48:12.104: INFO: (10) /api/v1/namespaces/proxy-1316/services/https:proxy-service-8vgjs:tlsportname1/proxy/: tls baz (200; 19.770287ms)
Apr 30 07:48:12.106: INFO: (10) /api/v1/namespaces/proxy-1316/services/http:proxy-service-8vgjs:portname1/proxy/: foo (200; 20.708987ms)
Apr 30 07:48:12.125: INFO: (11) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:1080/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:1080/proxy/rewriteme">... (200; 17.928773ms)
Apr 30 07:48:12.125: INFO: (11) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:160/proxy/: foo (200; 18.29161ms)
Apr 30 07:48:12.125: INFO: (11) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:162/proxy/: bar (200; 18.11262ms)
Apr 30 07:48:12.125: INFO: (11) /api/v1/namespaces/proxy-1316/services/https:proxy-service-8vgjs:tlsportname2/proxy/: tls qux (200; 18.019303ms)
Apr 30 07:48:12.126: INFO: (11) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:443/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:443/proxy/tlsrewritem... (200; 18.736807ms)
Apr 30 07:48:12.126: INFO: (11) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:160/proxy/: foo (200; 18.168807ms)
Apr 30 07:48:12.126: INFO: (11) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:162/proxy/: bar (200; 19.90645ms)
Apr 30 07:48:12.126: INFO: (11) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:462/proxy/: tls qux (200; 18.90078ms)
Apr 30 07:48:12.127: INFO: (11) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q/proxy/rewriteme">test</a> (200; 20.561387ms)
Apr 30 07:48:12.127: INFO: (11) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:1080/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:1080/proxy/rewriteme">test<... (200; 19.628287ms)
Apr 30 07:48:12.127: INFO: (11) /api/v1/namespaces/proxy-1316/services/proxy-service-8vgjs:portname1/proxy/: foo (200; 20.338444ms)
Apr 30 07:48:12.127: INFO: (11) /api/v1/namespaces/proxy-1316/services/proxy-service-8vgjs:portname2/proxy/: bar (200; 20.255324ms)
Apr 30 07:48:12.127: INFO: (11) /api/v1/namespaces/proxy-1316/services/http:proxy-service-8vgjs:portname2/proxy/: bar (200; 20.062397ms)
Apr 30 07:48:12.127: INFO: (11) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:460/proxy/: tls baz (200; 20.970067ms)
Apr 30 07:48:12.128: INFO: (11) /api/v1/namespaces/proxy-1316/services/http:proxy-service-8vgjs:portname1/proxy/: foo (200; 20.44431ms)
Apr 30 07:48:12.130: INFO: (11) /api/v1/namespaces/proxy-1316/services/https:proxy-service-8vgjs:tlsportname1/proxy/: tls baz (200; 22.542517ms)
Apr 30 07:48:12.145: INFO: (12) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:162/proxy/: bar (200; 15.557663ms)
Apr 30 07:48:12.147: INFO: (12) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:162/proxy/: bar (200; 15.210127ms)
Apr 30 07:48:12.148: INFO: (12) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:1080/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:1080/proxy/rewriteme">... (200; 16.195443ms)
Apr 30 07:48:12.148: INFO: (12) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:1080/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:1080/proxy/rewriteme">test<... (200; 16.868486ms)
Apr 30 07:48:12.149: INFO: (12) /api/v1/namespaces/proxy-1316/services/http:proxy-service-8vgjs:portname2/proxy/: bar (200; 17.7636ms)
Apr 30 07:48:12.149: INFO: (12) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:462/proxy/: tls qux (200; 17.82291ms)
Apr 30 07:48:12.149: INFO: (12) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:160/proxy/: foo (200; 18.786386ms)
Apr 30 07:48:12.150: INFO: (12) /api/v1/namespaces/proxy-1316/services/proxy-service-8vgjs:portname2/proxy/: bar (200; 19.401356ms)
Apr 30 07:48:12.150: INFO: (12) /api/v1/namespaces/proxy-1316/services/https:proxy-service-8vgjs:tlsportname1/proxy/: tls baz (200; 18.550873ms)
Apr 30 07:48:12.150: INFO: (12) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q/proxy/rewriteme">test</a> (200; 20.102817ms)
Apr 30 07:48:12.150: INFO: (12) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:443/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:443/proxy/tlsrewritem... (200; 18.729787ms)
Apr 30 07:48:12.150: INFO: (12) /api/v1/namespaces/proxy-1316/services/proxy-service-8vgjs:portname1/proxy/: foo (200; 19.908184ms)
Apr 30 07:48:12.150: INFO: (12) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:460/proxy/: tls baz (200; 20.010867ms)
Apr 30 07:48:12.150: INFO: (12) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:160/proxy/: foo (200; 19.606104ms)
Apr 30 07:48:12.151: INFO: (12) /api/v1/namespaces/proxy-1316/services/https:proxy-service-8vgjs:tlsportname2/proxy/: tls qux (200; 20.169947ms)
Apr 30 07:48:12.151: INFO: (12) /api/v1/namespaces/proxy-1316/services/http:proxy-service-8vgjs:portname1/proxy/: foo (200; 19.462733ms)
Apr 30 07:48:12.166: INFO: (13) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:1080/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:1080/proxy/rewriteme">test<... (200; 14.633117ms)
Apr 30 07:48:12.171: INFO: (13) /api/v1/namespaces/proxy-1316/services/http:proxy-service-8vgjs:portname2/proxy/: bar (200; 19.885403ms)
Apr 30 07:48:12.172: INFO: (13) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:162/proxy/: bar (200; 18.19555ms)
Apr 30 07:48:12.173: INFO: (13) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:443/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:443/proxy/tlsrewritem... (200; 19.857457ms)
Apr 30 07:48:12.174: INFO: (13) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:162/proxy/: bar (200; 22.348257ms)
Apr 30 07:48:12.175: INFO: (13) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:462/proxy/: tls qux (200; 22.502467ms)
Apr 30 07:48:12.175: INFO: (13) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:460/proxy/: tls baz (200; 21.95393ms)
Apr 30 07:48:12.175: INFO: (13) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:160/proxy/: foo (200; 22.716497ms)
Apr 30 07:48:12.176: INFO: (13) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q/proxy/rewriteme">test</a> (200; 23.28659ms)
Apr 30 07:48:12.176: INFO: (13) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:1080/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:1080/proxy/rewriteme">... (200; 22.430893ms)
Apr 30 07:48:12.176: INFO: (13) /api/v1/namespaces/proxy-1316/services/https:proxy-service-8vgjs:tlsportname1/proxy/: tls baz (200; 22.670383ms)
Apr 30 07:48:12.177: INFO: (13) /api/v1/namespaces/proxy-1316/services/proxy-service-8vgjs:portname2/proxy/: bar (200; 23.91853ms)
Apr 30 07:48:12.177: INFO: (13) /api/v1/namespaces/proxy-1316/services/http:proxy-service-8vgjs:portname1/proxy/: foo (200; 23.878133ms)
Apr 30 07:48:12.177: INFO: (13) /api/v1/namespaces/proxy-1316/services/https:proxy-service-8vgjs:tlsportname2/proxy/: tls qux (200; 24.108056ms)
Apr 30 07:48:12.177: INFO: (13) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:160/proxy/: foo (200; 24.648144ms)
Apr 30 07:48:12.177: INFO: (13) /api/v1/namespaces/proxy-1316/services/proxy-service-8vgjs:portname1/proxy/: foo (200; 24.53382ms)
Apr 30 07:48:12.191: INFO: (14) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:1080/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:1080/proxy/rewriteme">test<... (200; 12.657013ms)
Apr 30 07:48:12.191: INFO: (14) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:162/proxy/: bar (200; 13.2426ms)
Apr 30 07:48:12.198: INFO: (14) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:462/proxy/: tls qux (200; 20.57349ms)
Apr 30 07:48:12.199: INFO: (14) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:460/proxy/: tls baz (200; 20.820557ms)
Apr 30 07:48:12.200: INFO: (14) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:160/proxy/: foo (200; 22.39726ms)
Apr 30 07:48:12.201: INFO: (14) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q/proxy/rewriteme">test</a> (200; 23.907327ms)
Apr 30 07:48:12.216: INFO: (14) /api/v1/namespaces/proxy-1316/services/http:proxy-service-8vgjs:portname1/proxy/: foo (200; 38.764157ms)
Apr 30 07:48:12.218: INFO: (14) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:162/proxy/: bar (200; 40.38987ms)
Apr 30 07:48:12.219: INFO: (14) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:160/proxy/: foo (200; 41.526693ms)
Apr 30 07:48:12.219: INFO: (14) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:1080/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:1080/proxy/rewriteme">... (200; 41.75506ms)
Apr 30 07:48:12.220: INFO: (14) /api/v1/namespaces/proxy-1316/services/https:proxy-service-8vgjs:tlsportname2/proxy/: tls qux (200; 42.62999ms)
Apr 30 07:48:12.221: INFO: (14) /api/v1/namespaces/proxy-1316/services/https:proxy-service-8vgjs:tlsportname1/proxy/: tls baz (200; 43.144053ms)
Apr 30 07:48:12.222: INFO: (14) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:443/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:443/proxy/tlsrewritem... (200; 44.600153ms)
Apr 30 07:48:12.222: INFO: (14) /api/v1/namespaces/proxy-1316/services/proxy-service-8vgjs:portname2/proxy/: bar (200; 44.461224ms)
Apr 30 07:48:12.229: INFO: (14) /api/v1/namespaces/proxy-1316/services/http:proxy-service-8vgjs:portname2/proxy/: bar (200; 51.280417ms)
Apr 30 07:48:12.290: INFO: (14) /api/v1/namespaces/proxy-1316/services/proxy-service-8vgjs:portname1/proxy/: foo (200; 112.073074ms)
Apr 30 07:48:12.371: INFO: (15) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:1080/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:1080/proxy/rewriteme">test<... (200; 79.452166ms)
Apr 30 07:48:12.371: INFO: (15) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:160/proxy/: foo (200; 79.501343ms)
Apr 30 07:48:12.372: INFO: (15) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:162/proxy/: bar (200; 80.26775ms)
Apr 30 07:48:12.374: INFO: (15) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:162/proxy/: bar (200; 82.491027ms)
Apr 30 07:48:12.375: INFO: (15) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q/proxy/rewriteme">test</a> (200; 83.331733ms)
Apr 30 07:48:12.375: INFO: (15) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:1080/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:1080/proxy/rewriteme">... (200; 83.904873ms)
Apr 30 07:48:12.376: INFO: (15) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:460/proxy/: tls baz (200; 83.892803ms)
Apr 30 07:48:12.376: INFO: (15) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:462/proxy/: tls qux (200; 84.166543ms)
Apr 30 07:48:12.377: INFO: (15) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:160/proxy/: foo (200; 84.684057ms)
Apr 30 07:48:12.377: INFO: (15) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:443/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:443/proxy/tlsrewritem... (200; 85.372133ms)
Apr 30 07:48:12.380: INFO: (15) /api/v1/namespaces/proxy-1316/services/https:proxy-service-8vgjs:tlsportname2/proxy/: tls qux (200; 88.2264ms)
Apr 30 07:48:12.384: INFO: (15) /api/v1/namespaces/proxy-1316/services/http:proxy-service-8vgjs:portname2/proxy/: bar (200; 92.417196ms)
Apr 30 07:48:12.384: INFO: (15) /api/v1/namespaces/proxy-1316/services/https:proxy-service-8vgjs:tlsportname1/proxy/: tls baz (200; 92.15727ms)
Apr 30 07:48:12.384: INFO: (15) /api/v1/namespaces/proxy-1316/services/http:proxy-service-8vgjs:portname1/proxy/: foo (200; 93.894063ms)
Apr 30 07:48:12.384: INFO: (15) /api/v1/namespaces/proxy-1316/services/proxy-service-8vgjs:portname1/proxy/: foo (200; 92.31848ms)
Apr 30 07:48:12.384: INFO: (15) /api/v1/namespaces/proxy-1316/services/proxy-service-8vgjs:portname2/proxy/: bar (200; 93.235473ms)
Apr 30 07:48:12.423: INFO: (16) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:460/proxy/: tls baz (200; 38.281397ms)
Apr 30 07:48:12.423: INFO: (16) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:162/proxy/: bar (200; 38.190114ms)
Apr 30 07:48:12.423: INFO: (16) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:443/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:443/proxy/tlsrewritem... (200; 37.594697ms)
Apr 30 07:48:12.423: INFO: (16) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:160/proxy/: foo (200; 38.019443ms)
Apr 30 07:48:12.423: INFO: (16) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:462/proxy/: tls qux (200; 38.144363ms)
Apr 30 07:48:12.428: INFO: (16) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:162/proxy/: bar (200; 42.21652ms)
Apr 30 07:48:12.428: INFO: (16) /api/v1/namespaces/proxy-1316/services/https:proxy-service-8vgjs:tlsportname2/proxy/: tls qux (200; 42.109166ms)
Apr 30 07:48:12.428: INFO: (16) /api/v1/namespaces/proxy-1316/services/proxy-service-8vgjs:portname2/proxy/: bar (200; 42.266553ms)
Apr 30 07:48:12.429: INFO: (16) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q/proxy/rewriteme">test</a> (200; 43.592714ms)
Apr 30 07:48:12.430: INFO: (16) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:1080/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:1080/proxy/rewriteme">test<... (200; 45.731834ms)
Apr 30 07:48:12.430: INFO: (16) /api/v1/namespaces/proxy-1316/services/proxy-service-8vgjs:portname1/proxy/: foo (200; 44.665737ms)
Apr 30 07:48:12.430: INFO: (16) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:160/proxy/: foo (200; 45.457347ms)
Apr 30 07:48:12.433: INFO: (16) /api/v1/namespaces/proxy-1316/services/http:proxy-service-8vgjs:portname1/proxy/: foo (200; 48.34564ms)
Apr 30 07:48:12.433: INFO: (16) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:1080/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:1080/proxy/rewriteme">... (200; 47.917207ms)
Apr 30 07:48:12.433: INFO: (16) /api/v1/namespaces/proxy-1316/services/https:proxy-service-8vgjs:tlsportname1/proxy/: tls baz (200; 48.632626ms)
Apr 30 07:48:12.436: INFO: (16) /api/v1/namespaces/proxy-1316/services/http:proxy-service-8vgjs:portname2/proxy/: bar (200; 51.59504ms)
Apr 30 07:48:12.455: INFO: (17) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:162/proxy/: bar (200; 17.46422ms)
Apr 30 07:48:12.455: INFO: (17) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:1080/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:1080/proxy/rewriteme">... (200; 17.760166ms)
Apr 30 07:48:12.455: INFO: (17) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:462/proxy/: tls qux (200; 18.128563ms)
Apr 30 07:48:12.455: INFO: (17) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:460/proxy/: tls baz (200; 17.545147ms)
Apr 30 07:48:12.456: INFO: (17) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:443/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:443/proxy/tlsrewritem... (200; 18.10717ms)
Apr 30 07:48:12.456: INFO: (17) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:160/proxy/: foo (200; 18.246293ms)
Apr 30 07:48:12.456: INFO: (17) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q/proxy/rewriteme">test</a> (200; 19.27738ms)
Apr 30 07:48:12.458: INFO: (17) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:160/proxy/: foo (200; 19.53738ms)
Apr 30 07:48:12.458: INFO: (17) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:1080/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:1080/proxy/rewriteme">test<... (200; 21.618606ms)
Apr 30 07:48:12.458: INFO: (17) /api/v1/namespaces/proxy-1316/services/http:proxy-service-8vgjs:portname1/proxy/: foo (200; 21.69164ms)
Apr 30 07:48:12.458: INFO: (17) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:162/proxy/: bar (200; 21.569443ms)
Apr 30 07:48:12.458: INFO: (17) /api/v1/namespaces/proxy-1316/services/http:proxy-service-8vgjs:portname2/proxy/: bar (200; 21.80355ms)
Apr 30 07:48:12.459: INFO: (17) /api/v1/namespaces/proxy-1316/services/proxy-service-8vgjs:portname1/proxy/: foo (200; 21.048227ms)
Apr 30 07:48:12.460: INFO: (17) /api/v1/namespaces/proxy-1316/services/proxy-service-8vgjs:portname2/proxy/: bar (200; 21.62831ms)
Apr 30 07:48:12.461: INFO: (17) /api/v1/namespaces/proxy-1316/services/https:proxy-service-8vgjs:tlsportname2/proxy/: tls qux (200; 22.51547ms)
Apr 30 07:48:12.463: INFO: (17) /api/v1/namespaces/proxy-1316/services/https:proxy-service-8vgjs:tlsportname1/proxy/: tls baz (200; 24.891657ms)
Apr 30 07:48:12.479: INFO: (18) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:443/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:443/proxy/tlsrewritem... (200; 11.442307ms)
Apr 30 07:48:12.479: INFO: (18) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:162/proxy/: bar (200; 13.003304ms)
Apr 30 07:48:12.479: INFO: (18) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:1080/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:1080/proxy/rewriteme">test<... (200; 14.39575ms)
Apr 30 07:48:12.480: INFO: (18) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:162/proxy/: bar (200; 13.02358ms)
Apr 30 07:48:12.480: INFO: (18) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:1080/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:1080/proxy/rewriteme">... (200; 13.397233ms)
Apr 30 07:48:12.481: INFO: (18) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q/proxy/rewriteme">test</a> (200; 14.374624ms)
Apr 30 07:48:12.481: INFO: (18) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:160/proxy/: foo (200; 15.734504ms)
Apr 30 07:48:12.481: INFO: (18) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:460/proxy/: tls baz (200; 15.417917ms)
Apr 30 07:48:12.481: INFO: (18) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:160/proxy/: foo (200; 17.030037ms)
Apr 30 07:48:12.481: INFO: (18) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:462/proxy/: tls qux (200; 18.09309ms)
Apr 30 07:48:12.485: INFO: (18) /api/v1/namespaces/proxy-1316/services/proxy-service-8vgjs:portname1/proxy/: foo (200; 20.596973ms)
Apr 30 07:48:12.485: INFO: (18) /api/v1/namespaces/proxy-1316/services/http:proxy-service-8vgjs:portname1/proxy/: foo (200; 22.234694ms)
Apr 30 07:48:12.488: INFO: (18) /api/v1/namespaces/proxy-1316/services/proxy-service-8vgjs:portname2/proxy/: bar (200; 24.24714ms)
Apr 30 07:48:12.489: INFO: (18) /api/v1/namespaces/proxy-1316/services/https:proxy-service-8vgjs:tlsportname2/proxy/: tls qux (200; 24.488773ms)
Apr 30 07:48:12.489: INFO: (18) /api/v1/namespaces/proxy-1316/services/https:proxy-service-8vgjs:tlsportname1/proxy/: tls baz (200; 25.90568ms)
Apr 30 07:48:12.492: INFO: (18) /api/v1/namespaces/proxy-1316/services/http:proxy-service-8vgjs:portname2/proxy/: bar (200; 26.0261ms)
Apr 30 07:48:12.512: INFO: (19) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:160/proxy/: foo (200; 18.77266ms)
Apr 30 07:48:12.512: INFO: (19) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:160/proxy/: foo (200; 20.34544ms)
Apr 30 07:48:12.512: INFO: (19) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:462/proxy/: tls qux (200; 17.46728ms)
Apr 30 07:48:12.513: INFO: (19) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:162/proxy/: bar (200; 18.130973ms)
Apr 30 07:48:12.513: INFO: (19) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q/proxy/rewriteme">test</a> (200; 18.69469ms)
Apr 30 07:48:12.517: INFO: (19) /api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:1080/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/http:proxy-service-8vgjs-4xz8q:1080/proxy/rewriteme">... (200; 22.399144ms)
Apr 30 07:48:12.517: INFO: (19) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:1080/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:1080/proxy/rewriteme">test<... (200; 23.840367ms)
Apr 30 07:48:12.517: INFO: (19) /api/v1/namespaces/proxy-1316/pods/proxy-service-8vgjs-4xz8q:162/proxy/: bar (200; 22.934893ms)
Apr 30 07:48:12.517: INFO: (19) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:443/proxy/: <a href="/api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:443/proxy/tlsrewritem... (200; 22.12026ms)
Apr 30 07:48:12.517: INFO: (19) /api/v1/namespaces/proxy-1316/pods/https:proxy-service-8vgjs-4xz8q:460/proxy/: tls baz (200; 23.60761ms)
Apr 30 07:48:12.520: INFO: (19) /api/v1/namespaces/proxy-1316/services/proxy-service-8vgjs:portname1/proxy/: foo (200; 27.487273ms)
Apr 30 07:48:12.522: INFO: (19) /api/v1/namespaces/proxy-1316/services/proxy-service-8vgjs:portname2/proxy/: bar (200; 29.660277ms)
Apr 30 07:48:12.522: INFO: (19) /api/v1/namespaces/proxy-1316/services/http:proxy-service-8vgjs:portname2/proxy/: bar (200; 28.510097ms)
Apr 30 07:48:12.524: INFO: (19) /api/v1/namespaces/proxy-1316/services/http:proxy-service-8vgjs:portname1/proxy/: foo (200; 28.61647ms)
Apr 30 07:48:12.524: INFO: (19) /api/v1/namespaces/proxy-1316/services/https:proxy-service-8vgjs:tlsportname1/proxy/: tls baz (200; 28.533044ms)
Apr 30 07:48:12.524: INFO: (19) /api/v1/namespaces/proxy-1316/services/https:proxy-service-8vgjs:tlsportname2/proxy/: tls qux (200; 31.327377ms)
STEP: deleting ReplicationController proxy-service-8vgjs in namespace proxy-1316, will wait for the garbage collector to delete the pods
Apr 30 07:48:12.594: INFO: Deleting ReplicationController proxy-service-8vgjs took: 14.402393ms
Apr 30 07:48:12.895: INFO: Terminating ReplicationController proxy-service-8vgjs pods took: 300.612057ms
[AfterEach] version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:48:15.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-1316" for this suite.
Apr 30 07:48:22.024: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:48:22.183: INFO: namespace proxy-1316 deletion completed in 6.17842108s

• [SLOW TEST:20.564 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:48:22.183: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 30 07:48:22.258: INFO: Waiting up to 5m0s for pod "downwardapi-volume-53e801cc-6b1c-11e9-845c-f234dad8a085" in namespace "projected-7195" to be "success or failure"
Apr 30 07:48:22.264: INFO: Pod "downwardapi-volume-53e801cc-6b1c-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 6.079106ms
Apr 30 07:48:24.272: INFO: Pod "downwardapi-volume-53e801cc-6b1c-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01396764s
Apr 30 07:48:26.281: INFO: Pod "downwardapi-volume-53e801cc-6b1c-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022308593s
STEP: Saw pod success
Apr 30 07:48:26.281: INFO: Pod "downwardapi-volume-53e801cc-6b1c-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 07:48:26.286: INFO: Trying to get logs from node 10.10.101.13-slave pod downwardapi-volume-53e801cc-6b1c-11e9-845c-f234dad8a085 container client-container: <nil>
STEP: delete the pod
Apr 30 07:48:26.329: INFO: Waiting for pod downwardapi-volume-53e801cc-6b1c-11e9-845c-f234dad8a085 to disappear
Apr 30 07:48:26.334: INFO: Pod downwardapi-volume-53e801cc-6b1c-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:48:26.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7195" for this suite.
Apr 30 07:48:32.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:48:32.537: INFO: namespace projected-7195 deletion completed in 6.19503525s

• [SLOW TEST:10.354 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:48:32.538: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 30 07:48:32.617: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5a13f66f-6b1c-11e9-845c-f234dad8a085" in namespace "projected-1473" to be "success or failure"
Apr 30 07:48:32.624: INFO: Pod "downwardapi-volume-5a13f66f-6b1c-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 6.822734ms
Apr 30 07:48:34.632: INFO: Pod "downwardapi-volume-5a13f66f-6b1c-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01490165s
Apr 30 07:48:36.640: INFO: Pod "downwardapi-volume-5a13f66f-6b1c-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0231297s
STEP: Saw pod success
Apr 30 07:48:36.640: INFO: Pod "downwardapi-volume-5a13f66f-6b1c-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 07:48:36.645: INFO: Trying to get logs from node 10.10.101.14-slave pod downwardapi-volume-5a13f66f-6b1c-11e9-845c-f234dad8a085 container client-container: <nil>
STEP: delete the pod
Apr 30 07:48:36.679: INFO: Waiting for pod downwardapi-volume-5a13f66f-6b1c-11e9-845c-f234dad8a085 to disappear
Apr 30 07:48:36.685: INFO: Pod downwardapi-volume-5a13f66f-6b1c-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:48:36.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1473" for this suite.
Apr 30 07:48:42.711: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:48:42.893: INFO: namespace projected-1473 deletion completed in 6.201634266s

• [SLOW TEST:10.355 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:48:42.893: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 30 07:48:42.969: INFO: Waiting up to 5m0s for pod "downwardapi-volume-60403d5a-6b1c-11e9-845c-f234dad8a085" in namespace "projected-6020" to be "success or failure"
Apr 30 07:48:42.975: INFO: Pod "downwardapi-volume-60403d5a-6b1c-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 5.904586ms
Apr 30 07:48:44.983: INFO: Pod "downwardapi-volume-60403d5a-6b1c-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013537516s
Apr 30 07:48:46.991: INFO: Pod "downwardapi-volume-60403d5a-6b1c-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020993326s
STEP: Saw pod success
Apr 30 07:48:46.991: INFO: Pod "downwardapi-volume-60403d5a-6b1c-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 07:48:46.996: INFO: Trying to get logs from node 10.10.101.13-slave pod downwardapi-volume-60403d5a-6b1c-11e9-845c-f234dad8a085 container client-container: <nil>
STEP: delete the pod
Apr 30 07:48:47.101: INFO: Waiting for pod downwardapi-volume-60403d5a-6b1c-11e9-845c-f234dad8a085 to disappear
Apr 30 07:48:47.106: INFO: Pod downwardapi-volume-60403d5a-6b1c-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:48:47.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6020" for this suite.
Apr 30 07:48:53.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:48:53.296: INFO: namespace projected-6020 deletion completed in 6.18336651s

• [SLOW TEST:10.402 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:48:53.296: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-6673475b-6b1c-11e9-845c-f234dad8a085
STEP: Creating a pod to test consume configMaps
Apr 30 07:48:53.379: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-667432cb-6b1c-11e9-845c-f234dad8a085" in namespace "projected-9390" to be "success or failure"
Apr 30 07:48:53.384: INFO: Pod "pod-projected-configmaps-667432cb-6b1c-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 5.335737ms
Apr 30 07:48:55.391: INFO: Pod "pod-projected-configmaps-667432cb-6b1c-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012246173s
Apr 30 07:48:57.398: INFO: Pod "pod-projected-configmaps-667432cb-6b1c-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019007353s
STEP: Saw pod success
Apr 30 07:48:57.398: INFO: Pod "pod-projected-configmaps-667432cb-6b1c-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 07:48:57.404: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-projected-configmaps-667432cb-6b1c-11e9-845c-f234dad8a085 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 30 07:48:57.476: INFO: Waiting for pod pod-projected-configmaps-667432cb-6b1c-11e9-845c-f234dad8a085 to disappear
Apr 30 07:48:57.480: INFO: Pod pod-projected-configmaps-667432cb-6b1c-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:48:57.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9390" for this suite.
Apr 30 07:49:03.508: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:49:03.673: INFO: namespace projected-9390 deletion completed in 6.18561259s

• [SLOW TEST:10.377 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:49:03.673: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr 30 07:49:03.756: INFO: Waiting up to 5m0s for pod "downward-api-6ca376a5-6b1c-11e9-845c-f234dad8a085" in namespace "downward-api-3504" to be "success or failure"
Apr 30 07:49:03.763: INFO: Pod "downward-api-6ca376a5-6b1c-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 7.347453ms
Apr 30 07:49:05.771: INFO: Pod "downward-api-6ca376a5-6b1c-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015302893s
Apr 30 07:49:07.788: INFO: Pod "downward-api-6ca376a5-6b1c-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03261385s
STEP: Saw pod success
Apr 30 07:49:07.788: INFO: Pod "downward-api-6ca376a5-6b1c-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 07:49:07.795: INFO: Trying to get logs from node 10.10.101.13-slave pod downward-api-6ca376a5-6b1c-11e9-845c-f234dad8a085 container dapi-container: <nil>
STEP: delete the pod
Apr 30 07:49:07.847: INFO: Waiting for pod downward-api-6ca376a5-6b1c-11e9-845c-f234dad8a085 to disappear
Apr 30 07:49:07.853: INFO: Pod downward-api-6ca376a5-6b1c-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:49:07.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3504" for this suite.
Apr 30 07:49:13.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:49:14.060: INFO: namespace downward-api-3504 deletion completed in 6.197724983s

• [SLOW TEST:10.387 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:49:14.061: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 30 07:49:14.146: INFO: Waiting up to 5m0s for pod "downwardapi-volume-72d4a1df-6b1c-11e9-845c-f234dad8a085" in namespace "downward-api-5652" to be "success or failure"
Apr 30 07:49:14.154: INFO: Pod "downwardapi-volume-72d4a1df-6b1c-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 8.567023ms
Apr 30 07:49:16.165: INFO: Pod "downwardapi-volume-72d4a1df-6b1c-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019564176s
Apr 30 07:49:18.172: INFO: Pod "downwardapi-volume-72d4a1df-6b1c-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026298383s
STEP: Saw pod success
Apr 30 07:49:18.172: INFO: Pod "downwardapi-volume-72d4a1df-6b1c-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 07:49:18.178: INFO: Trying to get logs from node 10.10.101.14-slave pod downwardapi-volume-72d4a1df-6b1c-11e9-845c-f234dad8a085 container client-container: <nil>
STEP: delete the pod
Apr 30 07:49:18.214: INFO: Waiting for pod downwardapi-volume-72d4a1df-6b1c-11e9-845c-f234dad8a085 to disappear
Apr 30 07:49:18.219: INFO: Pod downwardapi-volume-72d4a1df-6b1c-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:49:18.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5652" for this suite.
Apr 30 07:49:24.252: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:49:24.445: INFO: namespace downward-api-5652 deletion completed in 6.217879333s

• [SLOW TEST:10.385 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:49:24.446: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Apr 30 07:49:24.540: INFO: Waiting up to 5m0s for pod "pod-7906c0ca-6b1c-11e9-845c-f234dad8a085" in namespace "emptydir-6838" to be "success or failure"
Apr 30 07:49:24.564: INFO: Pod "pod-7906c0ca-6b1c-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 23.622663ms
Apr 30 07:49:26.572: INFO: Pod "pod-7906c0ca-6b1c-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031366616s
Apr 30 07:49:28.580: INFO: Pod "pod-7906c0ca-6b1c-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03924148s
STEP: Saw pod success
Apr 30 07:49:28.580: INFO: Pod "pod-7906c0ca-6b1c-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 07:49:28.586: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-7906c0ca-6b1c-11e9-845c-f234dad8a085 container test-container: <nil>
STEP: delete the pod
Apr 30 07:49:28.618: INFO: Waiting for pod pod-7906c0ca-6b1c-11e9-845c-f234dad8a085 to disappear
Apr 30 07:49:28.622: INFO: Pod pod-7906c0ca-6b1c-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:49:28.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6838" for this suite.
Apr 30 07:49:34.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:49:34.884: INFO: namespace emptydir-6838 deletion completed in 6.25416049s

• [SLOW TEST:10.438 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:49:34.884: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-4363
Apr 30 07:49:38.979: INFO: Started pod liveness-http in namespace container-probe-4363
STEP: checking the pod's current state and verifying that restartCount is present
Apr 30 07:49:38.985: INFO: Initial restart count of pod liveness-http is 0
Apr 30 07:49:55.057: INFO: Restart count of pod container-probe-4363/liveness-http is now 1 (16.071917574s elapsed)
Apr 30 07:50:17.141: INFO: Restart count of pod container-probe-4363/liveness-http is now 2 (38.155566557s elapsed)
Apr 30 07:50:35.207: INFO: Restart count of pod container-probe-4363/liveness-http is now 3 (56.22169696s elapsed)
Apr 30 07:50:57.293: INFO: Restart count of pod container-probe-4363/liveness-http is now 4 (1m18.308084224s elapsed)
Apr 30 07:52:03.551: INFO: Restart count of pod container-probe-4363/liveness-http is now 5 (2m24.5660578s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:52:03.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4363" for this suite.
Apr 30 07:52:09.600: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:52:09.763: INFO: namespace container-probe-4363 deletion completed in 6.181314154s

• [SLOW TEST:154.879 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:52:09.764: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-db8f2bfc-6b1c-11e9-845c-f234dad8a085
STEP: Creating a pod to test consume secrets
Apr 30 07:52:09.853: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-db8ffeac-6b1c-11e9-845c-f234dad8a085" in namespace "projected-3771" to be "success or failure"
Apr 30 07:52:09.858: INFO: Pod "pod-projected-secrets-db8ffeac-6b1c-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 4.87733ms
Apr 30 07:52:11.865: INFO: Pod "pod-projected-secrets-db8ffeac-6b1c-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012155337s
Apr 30 07:52:13.873: INFO: Pod "pod-projected-secrets-db8ffeac-6b1c-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020204713s
STEP: Saw pod success
Apr 30 07:52:13.873: INFO: Pod "pod-projected-secrets-db8ffeac-6b1c-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 07:52:13.879: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-projected-secrets-db8ffeac-6b1c-11e9-845c-f234dad8a085 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 30 07:52:13.925: INFO: Waiting for pod pod-projected-secrets-db8ffeac-6b1c-11e9-845c-f234dad8a085 to disappear
Apr 30 07:52:13.929: INFO: Pod pod-projected-secrets-db8ffeac-6b1c-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:52:13.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3771" for this suite.
Apr 30 07:52:19.961: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:52:20.128: INFO: namespace projected-3771 deletion completed in 6.19049821s

• [SLOW TEST:10.364 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:52:20.129: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-e1bc4e8c-6b1c-11e9-845c-f234dad8a085
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:52:24.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8161" for this suite.
Apr 30 07:52:46.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:52:46.456: INFO: namespace configmap-8161 deletion completed in 22.179379993s

• [SLOW TEST:26.327 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:52:46.457: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-f16d5d7e-6b1c-11e9-845c-f234dad8a085
STEP: Creating a pod to test consume secrets
Apr 30 07:52:46.542: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f16e76a8-6b1c-11e9-845c-f234dad8a085" in namespace "projected-8210" to be "success or failure"
Apr 30 07:52:46.552: INFO: Pod "pod-projected-secrets-f16e76a8-6b1c-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 9.1898ms
Apr 30 07:52:48.559: INFO: Pod "pod-projected-secrets-f16e76a8-6b1c-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01604973s
Apr 30 07:52:50.566: INFO: Pod "pod-projected-secrets-f16e76a8-6b1c-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023046726s
STEP: Saw pod success
Apr 30 07:52:50.566: INFO: Pod "pod-projected-secrets-f16e76a8-6b1c-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 07:52:50.572: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-projected-secrets-f16e76a8-6b1c-11e9-845c-f234dad8a085 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 30 07:52:50.611: INFO: Waiting for pod pod-projected-secrets-f16e76a8-6b1c-11e9-845c-f234dad8a085 to disappear
Apr 30 07:52:50.617: INFO: Pod pod-projected-secrets-f16e76a8-6b1c-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:52:50.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8210" for this suite.
Apr 30 07:52:56.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:52:56.811: INFO: namespace projected-8210 deletion completed in 6.185893227s

• [SLOW TEST:10.354 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:52:56.811: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override command
Apr 30 07:52:56.889: INFO: Waiting up to 5m0s for pod "client-containers-f7994483-6b1c-11e9-845c-f234dad8a085" in namespace "containers-9347" to be "success or failure"
Apr 30 07:52:56.894: INFO: Pod "client-containers-f7994483-6b1c-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 5.53758ms
Apr 30 07:52:58.901: INFO: Pod "client-containers-f7994483-6b1c-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012411443s
Apr 30 07:53:00.909: INFO: Pod "client-containers-f7994483-6b1c-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0201465s
STEP: Saw pod success
Apr 30 07:53:00.909: INFO: Pod "client-containers-f7994483-6b1c-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 07:53:00.915: INFO: Trying to get logs from node 10.10.101.13-slave pod client-containers-f7994483-6b1c-11e9-845c-f234dad8a085 container test-container: <nil>
STEP: delete the pod
Apr 30 07:53:00.949: INFO: Waiting for pod client-containers-f7994483-6b1c-11e9-845c-f234dad8a085 to disappear
Apr 30 07:53:00.954: INFO: Pod client-containers-f7994483-6b1c-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:53:00.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9347" for this suite.
Apr 30 07:53:06.979: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:53:07.139: INFO: namespace containers-9347 deletion completed in 6.178341167s

• [SLOW TEST:10.328 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:53:07.139: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 30 07:53:07.214: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fdc0964b-6b1c-11e9-845c-f234dad8a085" in namespace "downward-api-6550" to be "success or failure"
Apr 30 07:53:07.223: INFO: Pod "downwardapi-volume-fdc0964b-6b1c-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 9.16393ms
Apr 30 07:53:09.231: INFO: Pod "downwardapi-volume-fdc0964b-6b1c-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01602098s
Apr 30 07:53:11.239: INFO: Pod "downwardapi-volume-fdc0964b-6b1c-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024755347s
STEP: Saw pod success
Apr 30 07:53:11.239: INFO: Pod "downwardapi-volume-fdc0964b-6b1c-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 07:53:11.245: INFO: Trying to get logs from node 10.10.101.13-slave pod downwardapi-volume-fdc0964b-6b1c-11e9-845c-f234dad8a085 container client-container: <nil>
STEP: delete the pod
Apr 30 07:53:11.286: INFO: Waiting for pod downwardapi-volume-fdc0964b-6b1c-11e9-845c-f234dad8a085 to disappear
Apr 30 07:53:11.293: INFO: Pod downwardapi-volume-fdc0964b-6b1c-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:53:11.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6550" for this suite.
Apr 30 07:53:17.323: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:53:17.499: INFO: namespace downward-api-6550 deletion completed in 6.198703083s

• [SLOW TEST:10.360 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:53:17.500: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 30 07:53:17.575: INFO: Waiting up to 5m0s for pod "downwardapi-volume-03ed3603-6b1d-11e9-845c-f234dad8a085" in namespace "downward-api-6342" to be "success or failure"
Apr 30 07:53:17.582: INFO: Pod "downwardapi-volume-03ed3603-6b1d-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 6.324743ms
Apr 30 07:53:19.590: INFO: Pod "downwardapi-volume-03ed3603-6b1d-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014499226s
Apr 30 07:53:21.597: INFO: Pod "downwardapi-volume-03ed3603-6b1d-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021641333s
STEP: Saw pod success
Apr 30 07:53:21.597: INFO: Pod "downwardapi-volume-03ed3603-6b1d-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 07:53:21.602: INFO: Trying to get logs from node 10.10.101.13-slave pod downwardapi-volume-03ed3603-6b1d-11e9-845c-f234dad8a085 container client-container: <nil>
STEP: delete the pod
Apr 30 07:53:21.633: INFO: Waiting for pod downwardapi-volume-03ed3603-6b1d-11e9-845c-f234dad8a085 to disappear
Apr 30 07:53:21.638: INFO: Pod downwardapi-volume-03ed3603-6b1d-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:53:21.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6342" for this suite.
Apr 30 07:53:27.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:53:27.866: INFO: namespace downward-api-6342 deletion completed in 6.22171179s

• [SLOW TEST:10.366 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:53:27.867: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 30 07:53:27.954: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0a1cbcce-6b1d-11e9-845c-f234dad8a085" in namespace "projected-1419" to be "success or failure"
Apr 30 07:53:27.964: INFO: Pod "downwardapi-volume-0a1cbcce-6b1d-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 9.26907ms
Apr 30 07:53:29.974: INFO: Pod "downwardapi-volume-0a1cbcce-6b1d-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019269074s
Apr 30 07:53:31.981: INFO: Pod "downwardapi-volume-0a1cbcce-6b1d-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02662767s
STEP: Saw pod success
Apr 30 07:53:31.981: INFO: Pod "downwardapi-volume-0a1cbcce-6b1d-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 07:53:31.987: INFO: Trying to get logs from node 10.10.101.13-slave pod downwardapi-volume-0a1cbcce-6b1d-11e9-845c-f234dad8a085 container client-container: <nil>
STEP: delete the pod
Apr 30 07:53:32.125: INFO: Waiting for pod downwardapi-volume-0a1cbcce-6b1d-11e9-845c-f234dad8a085 to disappear
Apr 30 07:53:32.130: INFO: Pod downwardapi-volume-0a1cbcce-6b1d-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:53:32.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1419" for this suite.
Apr 30 07:53:38.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:53:38.323: INFO: namespace projected-1419 deletion completed in 6.186278607s

• [SLOW TEST:10.457 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:53:38.324: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-1056e6a0-6b1d-11e9-845c-f234dad8a085
STEP: Creating a pod to test consume secrets
Apr 30 07:53:38.403: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1057c9ae-6b1d-11e9-845c-f234dad8a085" in namespace "projected-4785" to be "success or failure"
Apr 30 07:53:38.410: INFO: Pod "pod-projected-secrets-1057c9ae-6b1d-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 6.489267ms
Apr 30 07:53:40.418: INFO: Pod "pod-projected-secrets-1057c9ae-6b1d-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014428417s
Apr 30 07:53:42.424: INFO: Pod "pod-projected-secrets-1057c9ae-6b1d-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021108144s
STEP: Saw pod success
Apr 30 07:53:42.424: INFO: Pod "pod-projected-secrets-1057c9ae-6b1d-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 07:53:42.431: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-projected-secrets-1057c9ae-6b1d-11e9-845c-f234dad8a085 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 30 07:53:42.464: INFO: Waiting for pod pod-projected-secrets-1057c9ae-6b1d-11e9-845c-f234dad8a085 to disappear
Apr 30 07:53:42.469: INFO: Pod pod-projected-secrets-1057c9ae-6b1d-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:53:42.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4785" for this suite.
Apr 30 07:53:48.495: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:53:48.656: INFO: namespace projected-4785 deletion completed in 6.178413327s

• [SLOW TEST:10.332 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:53:48.656: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:54:48.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4208" for this suite.
Apr 30 07:55:06.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:55:06.943: INFO: namespace container-probe-4208 deletion completed in 18.196762053s

• [SLOW TEST:78.286 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:55:06.943: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-452938d4-6b1d-11e9-845c-f234dad8a085
STEP: Creating a pod to test consume configMaps
Apr 30 07:55:07.023: INFO: Waiting up to 5m0s for pod "pod-configmaps-452a1dcd-6b1d-11e9-845c-f234dad8a085" in namespace "configmap-4978" to be "success or failure"
Apr 30 07:55:07.029: INFO: Pod "pod-configmaps-452a1dcd-6b1d-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 5.847687ms
Apr 30 07:55:09.036: INFO: Pod "pod-configmaps-452a1dcd-6b1d-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012772653s
Apr 30 07:55:11.044: INFO: Pod "pod-configmaps-452a1dcd-6b1d-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021212167s
STEP: Saw pod success
Apr 30 07:55:11.044: INFO: Pod "pod-configmaps-452a1dcd-6b1d-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 07:55:11.050: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-configmaps-452a1dcd-6b1d-11e9-845c-f234dad8a085 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 30 07:55:11.086: INFO: Waiting for pod pod-configmaps-452a1dcd-6b1d-11e9-845c-f234dad8a085 to disappear
Apr 30 07:55:11.091: INFO: Pod pod-configmaps-452a1dcd-6b1d-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:55:11.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4978" for this suite.
Apr 30 07:55:17.120: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:55:17.286: INFO: namespace configmap-4978 deletion completed in 6.18680351s

• [SLOW TEST:10.343 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:55:17.287: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-4b588d7e-6b1d-11e9-845c-f234dad8a085
STEP: Creating configMap with name cm-test-opt-upd-4b588e54-6b1d-11e9-845c-f234dad8a085
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-4b588d7e-6b1d-11e9-845c-f234dad8a085
STEP: Updating configmap cm-test-opt-upd-4b588e54-6b1d-11e9-845c-f234dad8a085
STEP: Creating configMap with name cm-test-opt-create-4b588eb2-6b1d-11e9-845c-f234dad8a085
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:56:48.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6377" for this suite.
Apr 30 07:57:10.462: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:57:10.644: INFO: namespace projected-6377 deletion completed in 22.200381557s

• [SLOW TEST:113.357 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:57:10.645: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Apr 30 07:57:10.715: INFO: Waiting up to 5m0s for pod "pod-8ee410a1-6b1d-11e9-845c-f234dad8a085" in namespace "emptydir-4737" to be "success or failure"
Apr 30 07:57:10.723: INFO: Pod "pod-8ee410a1-6b1d-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 7.877943ms
Apr 30 07:57:12.731: INFO: Pod "pod-8ee410a1-6b1d-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015694606s
Apr 30 07:57:14.738: INFO: Pod "pod-8ee410a1-6b1d-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022802656s
STEP: Saw pod success
Apr 30 07:57:14.738: INFO: Pod "pod-8ee410a1-6b1d-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 07:57:14.743: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-8ee410a1-6b1d-11e9-845c-f234dad8a085 container test-container: <nil>
STEP: delete the pod
Apr 30 07:57:14.781: INFO: Waiting for pod pod-8ee410a1-6b1d-11e9-845c-f234dad8a085 to disappear
Apr 30 07:57:14.786: INFO: Pod pod-8ee410a1-6b1d-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:57:14.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4737" for this suite.
Apr 30 07:57:20.815: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:57:20.996: INFO: namespace emptydir-4737 deletion completed in 6.201194017s

• [SLOW TEST:10.352 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:57:20.997: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with configMap that has name projected-configmap-test-upd-951240f2-6b1d-11e9-845c-f234dad8a085
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-951240f2-6b1d-11e9-845c-f234dad8a085
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:57:29.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5612" for this suite.
Apr 30 07:57:51.217: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:57:51.383: INFO: namespace projected-5612 deletion completed in 22.185965373s

• [SLOW TEST:30.385 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:57:51.383: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Apr 30 07:57:56.510: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:57:57.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-1169" for this suite.
Apr 30 07:58:19.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:58:19.727: INFO: namespace replicaset-1169 deletion completed in 22.186631497s

• [SLOW TEST:28.344 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:58:19.729: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Apr 30 07:58:24.342: INFO: Successfully updated pod "pod-update-b81170d4-6b1d-11e9-845c-f234dad8a085"
STEP: verifying the updated pod is in kubernetes
Apr 30 07:58:24.355: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:58:24.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6967" for this suite.
Apr 30 07:58:46.385: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:58:46.543: INFO: namespace pods-6967 deletion completed in 22.176498514s

• [SLOW TEST:26.814 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:58:46.543: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Apr 30 07:58:46.621: INFO: Waiting up to 5m0s for pod "pod-c80e25f9-6b1d-11e9-845c-f234dad8a085" in namespace "emptydir-1931" to be "success or failure"
Apr 30 07:58:46.627: INFO: Pod "pod-c80e25f9-6b1d-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 5.59506ms
Apr 30 07:58:48.635: INFO: Pod "pod-c80e25f9-6b1d-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013058484s
Apr 30 07:58:50.642: INFO: Pod "pod-c80e25f9-6b1d-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020173084s
STEP: Saw pod success
Apr 30 07:58:50.642: INFO: Pod "pod-c80e25f9-6b1d-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 07:58:50.648: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-c80e25f9-6b1d-11e9-845c-f234dad8a085 container test-container: <nil>
STEP: delete the pod
Apr 30 07:58:50.685: INFO: Waiting for pod pod-c80e25f9-6b1d-11e9-845c-f234dad8a085 to disappear
Apr 30 07:58:50.690: INFO: Pod pod-c80e25f9-6b1d-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:58:50.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1931" for this suite.
Apr 30 07:58:56.716: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:58:56.896: INFO: namespace emptydir-1931 deletion completed in 6.19994122s

• [SLOW TEST:10.353 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:58:56.897: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting the proxy server
Apr 30 07:58:56.955: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-610946863 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:58:57.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-526" for this suite.
Apr 30 07:59:03.175: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:59:03.342: INFO: namespace kubectl-526 deletion completed in 6.18508656s

• [SLOW TEST:6.445 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:59:03.344: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 30 07:59:03.403: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 07:59:07.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1548" for this suite.
Apr 30 07:59:51.709: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 07:59:51.878: INFO: namespace pods-1548 deletion completed in 44.190172916s

• [SLOW TEST:48.534 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 07:59:51.879: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-ef003c6b-6b1d-11e9-845c-f234dad8a085
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-ef003c6b-6b1d-11e9-845c-f234dad8a085
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 08:00:00.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-592" for this suite.
Apr 30 08:00:22.104: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 08:00:22.260: INFO: namespace configmap-592 deletion completed in 22.182446483s

• [SLOW TEST:30.382 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 08:00:22.261: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Apr 30 08:00:22.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 create -f - --namespace=kubectl-4542'
Apr 30 08:00:23.159: INFO: stderr: ""
Apr 30 08:00:23.159: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Apr 30 08:00:24.166: INFO: Selector matched 1 pods for map[app:redis]
Apr 30 08:00:24.167: INFO: Found 0 / 1
Apr 30 08:00:25.167: INFO: Selector matched 1 pods for map[app:redis]
Apr 30 08:00:25.168: INFO: Found 0 / 1
Apr 30 08:00:26.167: INFO: Selector matched 1 pods for map[app:redis]
Apr 30 08:00:26.167: INFO: Found 0 / 1
Apr 30 08:00:27.167: INFO: Selector matched 1 pods for map[app:redis]
Apr 30 08:00:27.167: INFO: Found 1 / 1
Apr 30 08:00:27.167: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Apr 30 08:00:27.172: INFO: Selector matched 1 pods for map[app:redis]
Apr 30 08:00:27.172: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 30 08:00:27.172: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 patch pod redis-master-rvc9q --namespace=kubectl-4542 -p {"metadata":{"annotations":{"x":"y"}}}'
Apr 30 08:00:27.396: INFO: stderr: ""
Apr 30 08:00:27.396: INFO: stdout: "pod/redis-master-rvc9q patched\n"
STEP: checking annotations
Apr 30 08:00:27.401: INFO: Selector matched 1 pods for map[app:redis]
Apr 30 08:00:27.401: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 08:00:27.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4542" for this suite.
Apr 30 08:00:49.429: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 08:00:49.592: INFO: namespace kubectl-4542 deletion completed in 22.18364328s

• [SLOW TEST:27.331 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 08:00:49.592: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Apr 30 08:00:49.657: INFO: PodSpec: initContainers in spec.initContainers
Apr 30 08:01:36.841: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-1165a163-6b1e-11e9-845c-f234dad8a085", GenerateName:"", Namespace:"init-container-4866", SelfLink:"/api/v1/namespaces/init-container-4866/pods/pod-init-1165a163-6b1e-11e9-845c-f234dad8a085", UID:"15013387-6b1e-11e9-924a-005056bc1aae", ResourceVersion:"683965", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63692208055, loc:(*time.Location)(0x8a060e0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"657497906"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-x6q5d", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc00203f300), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-x6q5d", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-x6q5d", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-x6q5d", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002079b98), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.10.101.13-slave", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002b29320), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002079c10)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002079c30)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc002079c38), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc002079c3c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692208055, loc:(*time.Location)(0x8a060e0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692208055, loc:(*time.Location)(0x8a060e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692208055, loc:(*time.Location)(0x8a060e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692208055, loc:(*time.Location)(0x8a060e0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.10.101.13", PodIP:"10.168.6.154", StartTime:(*v1.Time)(0xc0025b7fc0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001afbf10)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001afbf80)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://825a484990fc4c443f5b4f6cee9bd57768a0fe65f54f8e0126b1dd34683548be"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001dda0a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001dda000), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 08:01:36.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4866" for this suite.
Apr 30 08:01:58.872: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 08:01:59.039: INFO: namespace init-container-4866 deletion completed in 22.188706924s

• [SLOW TEST:69.447 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 08:01:59.039: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1619
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 30 08:01:59.096: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-8971'
Apr 30 08:01:59.369: INFO: stderr: ""
Apr 30 08:01:59.369: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Apr 30 08:02:04.421: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 get pod e2e-test-nginx-pod --namespace=kubectl-8971 -o json'
Apr 30 08:02:04.673: INFO: stderr: ""
Apr 30 08:02:04.673: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-04-30T08:02:05Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-8971\",\n        \"resourceVersion\": \"684044\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-8971/pods/e2e-test-nginx-pod\",\n        \"uid\": \"3e87cec6-6b1e-11e9-924a-005056bc1aae\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-lrnpd\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"10.10.101.13-slave\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-lrnpd\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-lrnpd\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-30T08:02:05Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-30T08:02:09Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-30T08:02:09Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-30T08:02:05Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://d709c144b1517e41c5deaa869f16a825d99cdcb264eb67c1fb64892655835100\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-04-30T08:02:08Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.10.101.13\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.168.6.158\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-04-30T08:02:05Z\"\n    }\n}\n"
STEP: replace the image in the pod
Apr 30 08:02:04.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 replace -f - --namespace=kubectl-8971'
Apr 30 08:02:05.057: INFO: stderr: ""
Apr 30 08:02:05.057: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1624
Apr 30 08:02:05.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 delete pods e2e-test-nginx-pod --namespace=kubectl-8971'
Apr 30 08:02:08.500: INFO: stderr: ""
Apr 30 08:02:08.500: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 08:02:08.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8971" for this suite.
Apr 30 08:02:14.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 08:02:14.693: INFO: namespace kubectl-8971 deletion completed in 6.185345543s

• [SLOW TEST:15.654 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 08:02:14.694: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 08:02:18.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6123" for this suite.
Apr 30 08:02:24.826: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 08:02:25.004: INFO: namespace kubelet-test-6123 deletion completed in 6.198789664s

• [SLOW TEST:10.311 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 08:02:25.005: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 30 08:02:25.116: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"4de3351e-6b1e-11e9-924a-005056bc1aae", Controller:(*bool)(0xc00266b77a), BlockOwnerDeletion:(*bool)(0xc00266b77b)}}
Apr 30 08:02:25.129: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"4de0d5bd-6b1e-11e9-924a-005056bc1aae", Controller:(*bool)(0xc0024fdab2), BlockOwnerDeletion:(*bool)(0xc0024fdab3)}}
Apr 30 08:02:25.141: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"4de1efce-6b1e-11e9-924a-005056bc1aae", Controller:(*bool)(0xc0024fdc4a), BlockOwnerDeletion:(*bool)(0xc0024fdc4b)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 08:02:30.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1067" for this suite.
Apr 30 08:02:36.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 08:02:36.388: INFO: namespace gc-1067 deletion completed in 6.21559836s

• [SLOW TEST:11.383 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 08:02:36.389: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Apr 30 08:02:36.468: INFO: Waiting up to 5m0s for pod "pod-510dfa99-6b1e-11e9-845c-f234dad8a085" in namespace "emptydir-3859" to be "success or failure"
Apr 30 08:02:36.475: INFO: Pod "pod-510dfa99-6b1e-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 7.30223ms
Apr 30 08:02:38.483: INFO: Pod "pod-510dfa99-6b1e-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014801223s
Apr 30 08:02:40.491: INFO: Pod "pod-510dfa99-6b1e-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023345756s
STEP: Saw pod success
Apr 30 08:02:40.491: INFO: Pod "pod-510dfa99-6b1e-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 08:02:40.496: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-510dfa99-6b1e-11e9-845c-f234dad8a085 container test-container: <nil>
STEP: delete the pod
Apr 30 08:02:40.594: INFO: Waiting for pod pod-510dfa99-6b1e-11e9-845c-f234dad8a085 to disappear
Apr 30 08:02:40.599: INFO: Pod pod-510dfa99-6b1e-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 08:02:40.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3859" for this suite.
Apr 30 08:02:46.625: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 08:02:46.829: INFO: namespace emptydir-3859 deletion completed in 6.222367853s

• [SLOW TEST:10.440 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 08:02:46.829: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-5746a1e4-6b1e-11e9-845c-f234dad8a085
STEP: Creating a pod to test consume configMaps
Apr 30 08:02:46.913: INFO: Waiting up to 5m0s for pod "pod-configmaps-5747b3a7-6b1e-11e9-845c-f234dad8a085" in namespace "configmap-1630" to be "success or failure"
Apr 30 08:02:46.924: INFO: Pod "pod-configmaps-5747b3a7-6b1e-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 10.427613ms
Apr 30 08:02:48.931: INFO: Pod "pod-configmaps-5747b3a7-6b1e-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01784131s
Apr 30 08:02:50.939: INFO: Pod "pod-configmaps-5747b3a7-6b1e-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025809266s
STEP: Saw pod success
Apr 30 08:02:50.939: INFO: Pod "pod-configmaps-5747b3a7-6b1e-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 08:02:50.945: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-configmaps-5747b3a7-6b1e-11e9-845c-f234dad8a085 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 30 08:02:50.982: INFO: Waiting for pod pod-configmaps-5747b3a7-6b1e-11e9-845c-f234dad8a085 to disappear
Apr 30 08:02:50.988: INFO: Pod pod-configmaps-5747b3a7-6b1e-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 08:02:50.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1630" for this suite.
Apr 30 08:02:57.017: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 08:02:57.195: INFO: namespace configmap-1630 deletion completed in 6.197964643s

• [SLOW TEST:10.366 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 08:02:57.195: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's command
Apr 30 08:02:57.279: INFO: Waiting up to 5m0s for pod "var-expansion-5d753074-6b1e-11e9-845c-f234dad8a085" in namespace "var-expansion-1520" to be "success or failure"
Apr 30 08:02:57.286: INFO: Pod "var-expansion-5d753074-6b1e-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 7.088713ms
Apr 30 08:02:59.292: INFO: Pod "var-expansion-5d753074-6b1e-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013434713s
Apr 30 08:03:01.300: INFO: Pod "var-expansion-5d753074-6b1e-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02148672s
STEP: Saw pod success
Apr 30 08:03:01.300: INFO: Pod "var-expansion-5d753074-6b1e-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 08:03:01.307: INFO: Trying to get logs from node 10.10.101.13-slave pod var-expansion-5d753074-6b1e-11e9-845c-f234dad8a085 container dapi-container: <nil>
STEP: delete the pod
Apr 30 08:03:01.350: INFO: Waiting for pod var-expansion-5d753074-6b1e-11e9-845c-f234dad8a085 to disappear
Apr 30 08:03:01.362: INFO: Pod var-expansion-5d753074-6b1e-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 08:03:01.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1520" for this suite.
Apr 30 08:03:07.391: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 08:03:07.569: INFO: namespace var-expansion-1520 deletion completed in 6.197954876s

• [SLOW TEST:10.374 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 08:03:07.570: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 30 08:03:07.658: INFO: Waiting up to 5m0s for pod "downwardapi-volume-63a459c7-6b1e-11e9-845c-f234dad8a085" in namespace "downward-api-1635" to be "success or failure"
Apr 30 08:03:07.667: INFO: Pod "downwardapi-volume-63a459c7-6b1e-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 9.42836ms
Apr 30 08:03:09.675: INFO: Pod "downwardapi-volume-63a459c7-6b1e-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016637904s
Apr 30 08:03:11.682: INFO: Pod "downwardapi-volume-63a459c7-6b1e-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023922297s
STEP: Saw pod success
Apr 30 08:03:11.682: INFO: Pod "downwardapi-volume-63a459c7-6b1e-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 08:03:11.688: INFO: Trying to get logs from node 10.10.101.13-slave pod downwardapi-volume-63a459c7-6b1e-11e9-845c-f234dad8a085 container client-container: <nil>
STEP: delete the pod
Apr 30 08:03:11.726: INFO: Waiting for pod downwardapi-volume-63a459c7-6b1e-11e9-845c-f234dad8a085 to disappear
Apr 30 08:03:11.731: INFO: Pod downwardapi-volume-63a459c7-6b1e-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 08:03:11.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1635" for this suite.
Apr 30 08:03:17.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 08:03:17.969: INFO: namespace downward-api-1635 deletion completed in 6.231413633s

• [SLOW TEST:10.400 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 08:03:17.970: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-69d6d59e-6b1e-11e9-845c-f234dad8a085
STEP: Creating a pod to test consume configMaps
Apr 30 08:03:18.059: INFO: Waiting up to 5m0s for pod "pod-configmaps-69d7a8b6-6b1e-11e9-845c-f234dad8a085" in namespace "configmap-9211" to be "success or failure"
Apr 30 08:03:18.067: INFO: Pod "pod-configmaps-69d7a8b6-6b1e-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 8.13368ms
Apr 30 08:03:20.074: INFO: Pod "pod-configmaps-69d7a8b6-6b1e-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015258074s
Apr 30 08:03:22.081: INFO: Pod "pod-configmaps-69d7a8b6-6b1e-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021699554s
STEP: Saw pod success
Apr 30 08:03:22.081: INFO: Pod "pod-configmaps-69d7a8b6-6b1e-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 08:03:22.086: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-configmaps-69d7a8b6-6b1e-11e9-845c-f234dad8a085 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 30 08:03:22.133: INFO: Waiting for pod pod-configmaps-69d7a8b6-6b1e-11e9-845c-f234dad8a085 to disappear
Apr 30 08:03:22.137: INFO: Pod pod-configmaps-69d7a8b6-6b1e-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 08:03:22.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9211" for this suite.
Apr 30 08:03:28.170: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 08:03:28.331: INFO: namespace configmap-9211 deletion completed in 6.186487663s

• [SLOW TEST:10.361 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 08:03:28.332: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 08:03:33.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3332" for this suite.
Apr 30 08:03:55.480: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 08:03:55.669: INFO: namespace replication-controller-3332 deletion completed in 22.209904443s

• [SLOW TEST:27.337 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 08:03:55.669: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Apr 30 08:03:55.755: INFO: Waiting up to 5m0s for pod "pod-804ff77e-6b1e-11e9-845c-f234dad8a085" in namespace "emptydir-5039" to be "success or failure"
Apr 30 08:03:55.762: INFO: Pod "pod-804ff77e-6b1e-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 6.69286ms
Apr 30 08:03:57.776: INFO: Pod "pod-804ff77e-6b1e-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02066027s
Apr 30 08:03:59.784: INFO: Pod "pod-804ff77e-6b1e-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02828371s
STEP: Saw pod success
Apr 30 08:03:59.784: INFO: Pod "pod-804ff77e-6b1e-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 08:03:59.789: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-804ff77e-6b1e-11e9-845c-f234dad8a085 container test-container: <nil>
STEP: delete the pod
Apr 30 08:03:59.835: INFO: Waiting for pod pod-804ff77e-6b1e-11e9-845c-f234dad8a085 to disappear
Apr 30 08:03:59.840: INFO: Pod pod-804ff77e-6b1e-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 08:03:59.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5039" for this suite.
Apr 30 08:04:05.866: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 08:04:06.034: INFO: namespace emptydir-5039 deletion completed in 6.187718516s

• [SLOW TEST:10.365 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 08:04:06.035: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 30 08:04:06.133: INFO: Create a RollingUpdate DaemonSet
Apr 30 08:04:06.140: INFO: Check that daemon pods launch on every node of the cluster
Apr 30 08:04:06.148: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 08:04:06.153: INFO: Number of nodes with available pods: 0
Apr 30 08:04:06.153: INFO: Node 10.10.101.13-slave is running more than one daemon pod
Apr 30 08:04:07.162: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 08:04:07.168: INFO: Number of nodes with available pods: 0
Apr 30 08:04:07.168: INFO: Node 10.10.101.13-slave is running more than one daemon pod
Apr 30 08:04:08.162: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 08:04:08.168: INFO: Number of nodes with available pods: 0
Apr 30 08:04:08.168: INFO: Node 10.10.101.13-slave is running more than one daemon pod
Apr 30 08:04:09.160: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 08:04:09.167: INFO: Number of nodes with available pods: 0
Apr 30 08:04:09.167: INFO: Node 10.10.101.13-slave is running more than one daemon pod
Apr 30 08:04:10.161: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 08:04:10.166: INFO: Number of nodes with available pods: 1
Apr 30 08:04:10.166: INFO: Node 10.10.101.14-slave is running more than one daemon pod
Apr 30 08:04:11.161: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 08:04:11.166: INFO: Number of nodes with available pods: 2
Apr 30 08:04:11.166: INFO: Number of running nodes: 2, number of available pods: 2
Apr 30 08:04:11.166: INFO: Update the DaemonSet to trigger a rollout
Apr 30 08:04:11.178: INFO: Updating DaemonSet daemon-set
Apr 30 08:04:16.200: INFO: Roll back the DaemonSet before rollout is complete
Apr 30 08:04:16.214: INFO: Updating DaemonSet daemon-set
Apr 30 08:04:16.214: INFO: Make sure DaemonSet rollback is complete
Apr 30 08:04:16.219: INFO: Wrong image for pod: daemon-set-24l6w. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr 30 08:04:16.219: INFO: Pod daemon-set-24l6w is not available
Apr 30 08:04:16.233: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 08:04:17.240: INFO: Wrong image for pod: daemon-set-24l6w. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr 30 08:04:17.240: INFO: Pod daemon-set-24l6w is not available
Apr 30 08:04:17.247: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 08:04:18.242: INFO: Wrong image for pod: daemon-set-24l6w. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr 30 08:04:18.242: INFO: Pod daemon-set-24l6w is not available
Apr 30 08:04:18.249: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 08:04:19.241: INFO: Wrong image for pod: daemon-set-24l6w. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr 30 08:04:19.241: INFO: Pod daemon-set-24l6w is not available
Apr 30 08:04:19.248: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr 30 08:04:20.370: INFO: Pod daemon-set-q88p7 is not available
Apr 30 08:04:20.377: INFO: DaemonSet pods can't tolerate node 10.10.101.12-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9644, will wait for the garbage collector to delete the pods
Apr 30 08:04:20.457: INFO: Deleting DaemonSet.extensions daemon-set took: 14.951317ms
Apr 30 08:04:20.757: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.456523ms
Apr 30 08:04:29.765: INFO: Number of nodes with available pods: 0
Apr 30 08:04:29.765: INFO: Number of running nodes: 0, number of available pods: 0
Apr 30 08:04:29.772: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9644/daemonsets","resourceVersion":"684755"},"items":null}

Apr 30 08:04:29.782: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9644/pods","resourceVersion":"684756"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 08:04:29.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9644" for this suite.
Apr 30 08:04:35.845: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 08:04:36.067: INFO: namespace daemonsets-9644 deletion completed in 6.25193712s

• [SLOW TEST:30.032 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 08:04:36.067: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Apr 30 08:04:36.182: INFO: Waiting up to 5m0s for pod "pod-98684b6d-6b1e-11e9-845c-f234dad8a085" in namespace "emptydir-6806" to be "success or failure"
Apr 30 08:04:36.188: INFO: Pod "pod-98684b6d-6b1e-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 6.500973ms
Apr 30 08:04:38.194: INFO: Pod "pod-98684b6d-6b1e-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01217264s
Apr 30 08:04:40.202: INFO: Pod "pod-98684b6d-6b1e-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020167753s
Apr 30 08:04:42.214: INFO: Pod "pod-98684b6d-6b1e-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.032337473s
STEP: Saw pod success
Apr 30 08:04:42.214: INFO: Pod "pod-98684b6d-6b1e-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 08:04:42.221: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-98684b6d-6b1e-11e9-845c-f234dad8a085 container test-container: <nil>
STEP: delete the pod
Apr 30 08:04:42.257: INFO: Waiting for pod pod-98684b6d-6b1e-11e9-845c-f234dad8a085 to disappear
Apr 30 08:04:42.261: INFO: Pod pod-98684b6d-6b1e-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 08:04:42.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6806" for this suite.
Apr 30 08:04:48.288: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 08:04:48.457: INFO: namespace emptydir-6806 deletion completed in 6.1892375s

• [SLOW TEST:12.390 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 08:04:48.457: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-projected-all-test-volume-9fc5a7f8-6b1e-11e9-845c-f234dad8a085
STEP: Creating secret with name secret-projected-all-test-volume-9fc5a7c5-6b1e-11e9-845c-f234dad8a085
STEP: Creating a pod to test Check all projections for projected volume plugin
Apr 30 08:04:48.551: INFO: Waiting up to 5m0s for pod "projected-volume-9fc5a68d-6b1e-11e9-845c-f234dad8a085" in namespace "projected-8906" to be "success or failure"
Apr 30 08:04:48.558: INFO: Pod "projected-volume-9fc5a68d-6b1e-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 7.23585ms
Apr 30 08:04:50.565: INFO: Pod "projected-volume-9fc5a68d-6b1e-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01404706s
Apr 30 08:04:52.571: INFO: Pod "projected-volume-9fc5a68d-6b1e-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02045645s
STEP: Saw pod success
Apr 30 08:04:52.571: INFO: Pod "projected-volume-9fc5a68d-6b1e-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 08:04:52.577: INFO: Trying to get logs from node 10.10.101.13-slave pod projected-volume-9fc5a68d-6b1e-11e9-845c-f234dad8a085 container projected-all-volume-test: <nil>
STEP: delete the pod
Apr 30 08:04:52.612: INFO: Waiting for pod projected-volume-9fc5a68d-6b1e-11e9-845c-f234dad8a085 to disappear
Apr 30 08:04:52.617: INFO: Pod projected-volume-9fc5a68d-6b1e-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 08:04:52.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8906" for this suite.
Apr 30 08:04:58.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 08:04:58.835: INFO: namespace projected-8906 deletion completed in 6.211522183s

• [SLOW TEST:10.378 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 08:04:58.836: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's args
Apr 30 08:04:58.916: INFO: Waiting up to 5m0s for pod "var-expansion-a5f5c653-6b1e-11e9-845c-f234dad8a085" in namespace "var-expansion-2937" to be "success or failure"
Apr 30 08:04:58.926: INFO: Pod "var-expansion-a5f5c653-6b1e-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 10.020437ms
Apr 30 08:05:00.933: INFO: Pod "var-expansion-a5f5c653-6b1e-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016957657s
Apr 30 08:05:02.941: INFO: Pod "var-expansion-a5f5c653-6b1e-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024684187s
STEP: Saw pod success
Apr 30 08:05:02.941: INFO: Pod "var-expansion-a5f5c653-6b1e-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 08:05:02.946: INFO: Trying to get logs from node 10.10.101.13-slave pod var-expansion-a5f5c653-6b1e-11e9-845c-f234dad8a085 container dapi-container: <nil>
STEP: delete the pod
Apr 30 08:05:02.986: INFO: Waiting for pod var-expansion-a5f5c653-6b1e-11e9-845c-f234dad8a085 to disappear
Apr 30 08:05:02.991: INFO: Pod var-expansion-a5f5c653-6b1e-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 08:05:02.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2937" for this suite.
Apr 30 08:05:09.016: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 08:05:09.176: INFO: namespace var-expansion-2937 deletion completed in 6.17885287s

• [SLOW TEST:10.341 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 08:05:09.177: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Apr 30 08:05:09.244: INFO: Waiting up to 5m0s for pod "pod-ac1deef8-6b1e-11e9-845c-f234dad8a085" in namespace "emptydir-4190" to be "success or failure"
Apr 30 08:05:09.251: INFO: Pod "pod-ac1deef8-6b1e-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 7.092183ms
Apr 30 08:05:11.259: INFO: Pod "pod-ac1deef8-6b1e-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01427823s
Apr 30 08:05:13.272: INFO: Pod "pod-ac1deef8-6b1e-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02728235s
STEP: Saw pod success
Apr 30 08:05:13.272: INFO: Pod "pod-ac1deef8-6b1e-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 08:05:13.276: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-ac1deef8-6b1e-11e9-845c-f234dad8a085 container test-container: <nil>
STEP: delete the pod
Apr 30 08:05:13.311: INFO: Waiting for pod pod-ac1deef8-6b1e-11e9-845c-f234dad8a085 to disappear
Apr 30 08:05:13.316: INFO: Pod pod-ac1deef8-6b1e-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 08:05:13.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4190" for this suite.
Apr 30 08:05:19.345: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 08:05:19.508: INFO: namespace emptydir-4190 deletion completed in 6.184433663s

• [SLOW TEST:10.331 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 08:05:19.509: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating server pod server in namespace prestop-1141
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-1141
STEP: Deleting pre-stop pod
Apr 30 08:05:34.645: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 08:05:34.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-1141" for this suite.
Apr 30 08:06:12.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 08:06:12.887: INFO: namespace prestop-1141 deletion completed in 38.222296346s

• [SLOW TEST:53.379 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 08:06:12.888: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 30 08:06:12.947: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Apr 30 08:06:12.959: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr 30 08:06:17.966: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr 30 08:06:17.966: INFO: Creating deployment "test-rolling-update-deployment"
Apr 30 08:06:17.982: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Apr 30 08:06:17.993: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Apr 30 08:06:20.006: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Apr 30 08:06:20.012: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692208384, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692208384, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692208384, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692208384, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-67599b4d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 30 08:06:22.019: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr 30 08:06:22.035: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-628,SelfLink:/apis/apps/v1/namespaces/deployment-628/deployments/test-rolling-update-deployment,UID:d8b166d4-6b1e-11e9-924a-005056bc1aae,ResourceVersion:685313,Generation:1,CreationTimestamp:2019-04-30 08:06:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-04-30 08:06:24 +0000 UTC 2019-04-30 08:06:24 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-04-30 08:06:27 +0000 UTC 2019-04-30 08:06:24 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-67599b4d9" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Apr 30 08:06:22.041: INFO: New ReplicaSet "test-rolling-update-deployment-67599b4d9" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-67599b4d9,GenerateName:,Namespace:deployment-628,SelfLink:/apis/apps/v1/namespaces/deployment-628/replicasets/test-rolling-update-deployment-67599b4d9,UID:d8b604c7-6b1e-11e9-924a-005056bc1aae,ResourceVersion:685301,Generation:1,CreationTimestamp:2019-04-30 08:06:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment d8b166d4-6b1e-11e9-924a-005056bc1aae 0xc002f6d230 0xc002f6d231}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Apr 30 08:06:22.041: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Apr 30 08:06:22.042: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-628,SelfLink:/apis/apps/v1/namespaces/deployment-628/replicasets/test-rolling-update-controller,UID:d5b39ef9-6b1e-11e9-924a-005056bc1aae,ResourceVersion:685311,Generation:2,CreationTimestamp:2019-04-30 08:06:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment d8b166d4-6b1e-11e9-924a-005056bc1aae 0xc002f6d167 0xc002f6d168}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 30 08:06:22.048: INFO: Pod "test-rolling-update-deployment-67599b4d9-p84j7" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-67599b4d9-p84j7,GenerateName:test-rolling-update-deployment-67599b4d9-,Namespace:deployment-628,SelfLink:/api/v1/namespaces/deployment-628/pods/test-rolling-update-deployment-67599b4d9-p84j7,UID:d8b759ac-6b1e-11e9-924a-005056bc1aae,ResourceVersion:685300,Generation:0,CreationTimestamp:2019-04-30 08:06:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-67599b4d9 d8b604c7-6b1e-11e9-924a-005056bc1aae 0xc002f6dab0 0xc002f6dab1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-gkkk2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gkkk2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-gkkk2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.101.13-slave,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f6db10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f6db30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 08:06:24 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 08:06:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 08:06:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 08:06:24 +0000 UTC  }],Message:,Reason:,HostIP:10.10.101.13,PodIP:10.168.6.177,StartTime:2019-04-30 08:06:24 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-04-30 08:06:26 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://080f7a60f325636dd69a6042c6c6ae9ae1d1fad5f94254c988e65d8152b9356b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 08:06:22.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-628" for this suite.
Apr 30 08:06:28.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 08:06:28.273: INFO: namespace deployment-628 deletion completed in 6.217838516s

• [SLOW TEST:15.386 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 08:06:28.275: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Apr 30 08:06:32.934: INFO: Successfully updated pod "annotationupdatedb461f90-6b1e-11e9-845c-f234dad8a085"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 08:06:36.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8545" for this suite.
Apr 30 08:06:59.028: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 08:06:59.198: INFO: namespace projected-8545 deletion completed in 22.19132441s

• [SLOW TEST:30.923 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 08:06:59.199: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Starting the proxy
Apr 30 08:06:59.262: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-610946863 proxy --unix-socket=/tmp/kubectl-proxy-unix704987926/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 08:06:59.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4277" for this suite.
Apr 30 08:07:05.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 08:07:05.668: INFO: namespace kubectl-4277 deletion completed in 6.207353584s

• [SLOW TEST:6.469 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 08:07:05.669: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1354
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 30 08:07:05.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-1892'
Apr 30 08:07:06.012: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr 30 08:07:06.012: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Apr 30 08:07:06.024: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-ldbt7]
Apr 30 08:07:06.024: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-ldbt7" in namespace "kubectl-1892" to be "running and ready"
Apr 30 08:07:06.031: INFO: Pod "e2e-test-nginx-rc-ldbt7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.979064ms
Apr 30 08:07:08.037: INFO: Pod "e2e-test-nginx-rc-ldbt7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01264904s
Apr 30 08:07:10.045: INFO: Pod "e2e-test-nginx-rc-ldbt7": Phase="Running", Reason="", readiness=true. Elapsed: 4.020138517s
Apr 30 08:07:10.045: INFO: Pod "e2e-test-nginx-rc-ldbt7" satisfied condition "running and ready"
Apr 30 08:07:10.045: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-ldbt7]
Apr 30 08:07:10.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 logs rc/e2e-test-nginx-rc --namespace=kubectl-1892'
Apr 30 08:07:10.330: INFO: stderr: ""
Apr 30 08:07:10.330: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1359
Apr 30 08:07:10.330: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610946863 delete rc e2e-test-nginx-rc --namespace=kubectl-1892'
Apr 30 08:07:10.551: INFO: stderr: ""
Apr 30 08:07:10.551: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 08:07:10.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1892" for this suite.
Apr 30 08:07:32.582: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 08:07:32.742: INFO: namespace kubectl-1892 deletion completed in 22.18137973s

• [SLOW TEST:27.074 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 08:07:32.743: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 30 08:07:32.843: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Apr 30 08:07:37.851: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr 30 08:07:37.851: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr 30 08:07:41.904: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-7525,SelfLink:/apis/apps/v1/namespaces/deployment-7525/deployments/test-cleanup-deployment,UID:08502f90-6b1f-11e9-924a-005056bc1aae,ResourceVersion:685628,Generation:1,CreationTimestamp:2019-04-30 08:07:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-04-30 08:07:43 +0000 UTC 2019-04-30 08:07:43 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-04-30 08:07:47 +0000 UTC 2019-04-30 08:07:43 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-55cbfbc8f5" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Apr 30 08:07:41.912: INFO: New ReplicaSet "test-cleanup-deployment-55cbfbc8f5" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55cbfbc8f5,GenerateName:,Namespace:deployment-7525,SelfLink:/apis/apps/v1/namespaces/deployment-7525/replicasets/test-cleanup-deployment-55cbfbc8f5,UID:0853ab40-6b1f-11e9-924a-005056bc1aae,ResourceVersion:685617,Generation:1,CreationTimestamp:2019-04-30 08:07:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 08502f90-6b1f-11e9-924a-005056bc1aae 0xc001dbddb7 0xc001dbddb8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Apr 30 08:07:41.921: INFO: Pod "test-cleanup-deployment-55cbfbc8f5-z5rw5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55cbfbc8f5-z5rw5,GenerateName:test-cleanup-deployment-55cbfbc8f5-,Namespace:deployment-7525,SelfLink:/api/v1/namespaces/deployment-7525/pods/test-cleanup-deployment-55cbfbc8f5-z5rw5,UID:085529f9-6b1f-11e9-924a-005056bc1aae,ResourceVersion:685616,Generation:0,CreationTimestamp:2019-04-30 08:07:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-55cbfbc8f5 0853ab40-6b1f-11e9-924a-005056bc1aae 0xc0025f64f7 0xc0025f64f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-fn5ht {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fn5ht,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-fn5ht true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.101.13-slave,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025f6570} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025f65a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 08:07:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 08:07:47 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 08:07:47 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 08:07:43 +0000 UTC  }],Message:,Reason:,HostIP:10.10.101.13,PodIP:10.168.6.174,StartTime:2019-04-30 08:07:43 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-04-30 08:07:46 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://64075a37e9e62f1e67ae8e14a570840dec10c9580410c17ee0c6ccc00006f20f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 08:07:41.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7525" for this suite.
Apr 30 08:07:47.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 08:07:48.142: INFO: namespace deployment-7525 deletion completed in 6.210972057s

• [SLOW TEST:15.399 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 08:07:48.142: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Apr 30 08:07:48.564: INFO: Pod name wrapped-volume-race-0b12454a-6b1f-11e9-845c-f234dad8a085: Found 0 pods out of 5
Apr 30 08:07:53.580: INFO: Pod name wrapped-volume-race-0b12454a-6b1f-11e9-845c-f234dad8a085: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-0b12454a-6b1f-11e9-845c-f234dad8a085 in namespace emptydir-wrapper-9396, will wait for the garbage collector to delete the pods
Apr 30 08:08:09.723: INFO: Deleting ReplicationController wrapped-volume-race-0b12454a-6b1f-11e9-845c-f234dad8a085 took: 11.882537ms
Apr 30 08:08:10.024: INFO: Terminating ReplicationController wrapped-volume-race-0b12454a-6b1f-11e9-845c-f234dad8a085 pods took: 300.43112ms
STEP: Creating RC which spawns configmap-volume pods
Apr 30 08:08:46.052: INFO: Pod name wrapped-volume-race-2d557f91-6b1f-11e9-845c-f234dad8a085: Found 0 pods out of 5
Apr 30 08:08:51.066: INFO: Pod name wrapped-volume-race-2d557f91-6b1f-11e9-845c-f234dad8a085: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-2d557f91-6b1f-11e9-845c-f234dad8a085 in namespace emptydir-wrapper-9396, will wait for the garbage collector to delete the pods
Apr 30 08:09:07.186: INFO: Deleting ReplicationController wrapped-volume-race-2d557f91-6b1f-11e9-845c-f234dad8a085 took: 13.654197ms
Apr 30 08:09:07.487: INFO: Terminating ReplicationController wrapped-volume-race-2d557f91-6b1f-11e9-845c-f234dad8a085 pods took: 300.71435ms
STEP: Creating RC which spawns configmap-volume pods
Apr 30 08:09:50.023: INFO: Pod name wrapped-volume-race-5375983c-6b1f-11e9-845c-f234dad8a085: Found 0 pods out of 5
Apr 30 08:09:55.037: INFO: Pod name wrapped-volume-race-5375983c-6b1f-11e9-845c-f234dad8a085: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-5375983c-6b1f-11e9-845c-f234dad8a085 in namespace emptydir-wrapper-9396, will wait for the garbage collector to delete the pods
Apr 30 08:10:11.169: INFO: Deleting ReplicationController wrapped-volume-race-5375983c-6b1f-11e9-845c-f234dad8a085 took: 13.720306ms
Apr 30 08:10:11.470: INFO: Terminating ReplicationController wrapped-volume-race-5375983c-6b1f-11e9-845c-f234dad8a085 pods took: 300.711ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 08:10:50.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-9396" for this suite.
Apr 30 08:10:58.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 08:10:58.576: INFO: namespace emptydir-wrapper-9396 deletion completed in 8.199362357s

• [SLOW TEST:190.434 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 08:10:58.577: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 30 08:10:58.657: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7c611690-6b1f-11e9-845c-f234dad8a085" in namespace "downward-api-8008" to be "success or failure"
Apr 30 08:10:58.663: INFO: Pod "downwardapi-volume-7c611690-6b1f-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 6.544394ms
Apr 30 08:11:00.671: INFO: Pod "downwardapi-volume-7c611690-6b1f-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014309767s
Apr 30 08:11:02.680: INFO: Pod "downwardapi-volume-7c611690-6b1f-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02331281s
STEP: Saw pod success
Apr 30 08:11:02.680: INFO: Pod "downwardapi-volume-7c611690-6b1f-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 08:11:02.686: INFO: Trying to get logs from node 10.10.101.14-slave pod downwardapi-volume-7c611690-6b1f-11e9-845c-f234dad8a085 container client-container: <nil>
STEP: delete the pod
Apr 30 08:11:02.723: INFO: Waiting for pod downwardapi-volume-7c611690-6b1f-11e9-845c-f234dad8a085 to disappear
Apr 30 08:11:02.728: INFO: Pod downwardapi-volume-7c611690-6b1f-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 08:11:02.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8008" for this suite.
Apr 30 08:11:08.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 08:11:08.961: INFO: namespace downward-api-8008 deletion completed in 6.224899883s

• [SLOW TEST:10.385 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 08:11:08.962: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Apr 30 08:11:09.059: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-4714,SelfLink:/api/v1/namespaces/watch-4714/configmaps/e2e-watch-test-label-changed,UID:862ec8ba-6b1f-11e9-924a-005056bc1aae,ResourceVersion:687026,Generation:0,CreationTimestamp:2019-04-30 08:11:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr 30 08:11:09.059: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-4714,SelfLink:/api/v1/namespaces/watch-4714/configmaps/e2e-watch-test-label-changed,UID:862ec8ba-6b1f-11e9-924a-005056bc1aae,ResourceVersion:687027,Generation:0,CreationTimestamp:2019-04-30 08:11:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Apr 30 08:11:09.059: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-4714,SelfLink:/api/v1/namespaces/watch-4714/configmaps/e2e-watch-test-label-changed,UID:862ec8ba-6b1f-11e9-924a-005056bc1aae,ResourceVersion:687028,Generation:0,CreationTimestamp:2019-04-30 08:11:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Apr 30 08:11:19.104: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-4714,SelfLink:/api/v1/namespaces/watch-4714/configmaps/e2e-watch-test-label-changed,UID:862ec8ba-6b1f-11e9-924a-005056bc1aae,ResourceVersion:687047,Generation:0,CreationTimestamp:2019-04-30 08:11:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr 30 08:11:19.105: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-4714,SelfLink:/api/v1/namespaces/watch-4714/configmaps/e2e-watch-test-label-changed,UID:862ec8ba-6b1f-11e9-924a-005056bc1aae,ResourceVersion:687048,Generation:0,CreationTimestamp:2019-04-30 08:11:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Apr 30 08:11:19.105: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-4714,SelfLink:/api/v1/namespaces/watch-4714/configmaps/e2e-watch-test-label-changed,UID:862ec8ba-6b1f-11e9-924a-005056bc1aae,ResourceVersion:687049,Generation:0,CreationTimestamp:2019-04-30 08:11:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 08:11:19.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4714" for this suite.
Apr 30 08:11:25.132: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 08:11:25.313: INFO: namespace watch-4714 deletion completed in 6.200734767s

• [SLOW TEST:16.351 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 08:11:25.314: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Apr 30 08:11:25.399: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1182,SelfLink:/api/v1/namespaces/watch-1182/configmaps/e2e-watch-test-configmap-a,UID:8fef927c-6b1f-11e9-924a-005056bc1aae,ResourceVersion:687073,Generation:0,CreationTimestamp:2019-04-30 08:11:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr 30 08:11:25.399: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1182,SelfLink:/api/v1/namespaces/watch-1182/configmaps/e2e-watch-test-configmap-a,UID:8fef927c-6b1f-11e9-924a-005056bc1aae,ResourceVersion:687073,Generation:0,CreationTimestamp:2019-04-30 08:11:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Apr 30 08:11:35.421: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1182,SelfLink:/api/v1/namespaces/watch-1182/configmaps/e2e-watch-test-configmap-a,UID:8fef927c-6b1f-11e9-924a-005056bc1aae,ResourceVersion:687091,Generation:0,CreationTimestamp:2019-04-30 08:11:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Apr 30 08:11:35.422: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1182,SelfLink:/api/v1/namespaces/watch-1182/configmaps/e2e-watch-test-configmap-a,UID:8fef927c-6b1f-11e9-924a-005056bc1aae,ResourceVersion:687091,Generation:0,CreationTimestamp:2019-04-30 08:11:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Apr 30 08:11:45.436: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1182,SelfLink:/api/v1/namespaces/watch-1182/configmaps/e2e-watch-test-configmap-a,UID:8fef927c-6b1f-11e9-924a-005056bc1aae,ResourceVersion:687108,Generation:0,CreationTimestamp:2019-04-30 08:11:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr 30 08:11:45.436: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1182,SelfLink:/api/v1/namespaces/watch-1182/configmaps/e2e-watch-test-configmap-a,UID:8fef927c-6b1f-11e9-924a-005056bc1aae,ResourceVersion:687108,Generation:0,CreationTimestamp:2019-04-30 08:11:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Apr 30 08:11:55.454: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1182,SelfLink:/api/v1/namespaces/watch-1182/configmaps/e2e-watch-test-configmap-a,UID:8fef927c-6b1f-11e9-924a-005056bc1aae,ResourceVersion:687126,Generation:0,CreationTimestamp:2019-04-30 08:11:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr 30 08:11:55.454: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1182,SelfLink:/api/v1/namespaces/watch-1182/configmaps/e2e-watch-test-configmap-a,UID:8fef927c-6b1f-11e9-924a-005056bc1aae,ResourceVersion:687126,Generation:0,CreationTimestamp:2019-04-30 08:11:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Apr 30 08:12:05.469: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-1182,SelfLink:/api/v1/namespaces/watch-1182/configmaps/e2e-watch-test-configmap-b,UID:a7d11f65-6b1f-11e9-924a-005056bc1aae,ResourceVersion:687144,Generation:0,CreationTimestamp:2019-04-30 08:12:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr 30 08:12:05.469: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-1182,SelfLink:/api/v1/namespaces/watch-1182/configmaps/e2e-watch-test-configmap-b,UID:a7d11f65-6b1f-11e9-924a-005056bc1aae,ResourceVersion:687144,Generation:0,CreationTimestamp:2019-04-30 08:12:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Apr 30 08:12:15.485: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-1182,SelfLink:/api/v1/namespaces/watch-1182/configmaps/e2e-watch-test-configmap-b,UID:a7d11f65-6b1f-11e9-924a-005056bc1aae,ResourceVersion:687162,Generation:0,CreationTimestamp:2019-04-30 08:12:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr 30 08:12:15.485: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-1182,SelfLink:/api/v1/namespaces/watch-1182/configmaps/e2e-watch-test-configmap-b,UID:a7d11f65-6b1f-11e9-924a-005056bc1aae,ResourceVersion:687162,Generation:0,CreationTimestamp:2019-04-30 08:12:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 08:12:25.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1182" for this suite.
Apr 30 08:12:31.517: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 08:12:31.685: INFO: namespace watch-1182 deletion completed in 6.189973263s

• [SLOW TEST:66.372 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 08:12:31.686: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 30 08:12:35.841: INFO: Waiting up to 5m0s for pod "client-envvars-b64e753c-6b1f-11e9-845c-f234dad8a085" in namespace "pods-650" to be "success or failure"
Apr 30 08:12:35.847: INFO: Pod "client-envvars-b64e753c-6b1f-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 6.016303ms
Apr 30 08:12:37.855: INFO: Pod "client-envvars-b64e753c-6b1f-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013750243s
Apr 30 08:12:39.862: INFO: Pod "client-envvars-b64e753c-6b1f-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020906223s
STEP: Saw pod success
Apr 30 08:12:39.862: INFO: Pod "client-envvars-b64e753c-6b1f-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 08:12:39.867: INFO: Trying to get logs from node 10.10.101.14-slave pod client-envvars-b64e753c-6b1f-11e9-845c-f234dad8a085 container env3cont: <nil>
STEP: delete the pod
Apr 30 08:12:39.907: INFO: Waiting for pod client-envvars-b64e753c-6b1f-11e9-845c-f234dad8a085 to disappear
Apr 30 08:12:39.912: INFO: Pod client-envvars-b64e753c-6b1f-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 08:12:39.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-650" for this suite.
Apr 30 08:13:19.939: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 08:13:20.112: INFO: namespace pods-650 deletion completed in 40.192483033s

• [SLOW TEST:48.427 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 08:13:20.113: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 08:13:24.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3542" for this suite.
Apr 30 08:14:12.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 08:14:12.427: INFO: namespace kubelet-test-3542 deletion completed in 48.20872108s

• [SLOW TEST:52.315 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command in a pod
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 08:14:12.428: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
Apr 30 08:14:13.030: INFO: created pod pod-service-account-defaultsa
Apr 30 08:14:13.030: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Apr 30 08:14:13.039: INFO: created pod pod-service-account-mountsa
Apr 30 08:14:13.039: INFO: pod pod-service-account-mountsa service account token volume mount: true
Apr 30 08:14:13.050: INFO: created pod pod-service-account-nomountsa
Apr 30 08:14:13.050: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Apr 30 08:14:13.061: INFO: created pod pod-service-account-defaultsa-mountspec
Apr 30 08:14:13.061: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Apr 30 08:14:13.072: INFO: created pod pod-service-account-mountsa-mountspec
Apr 30 08:14:13.072: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Apr 30 08:14:13.087: INFO: created pod pod-service-account-nomountsa-mountspec
Apr 30 08:14:13.087: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Apr 30 08:14:13.107: INFO: created pod pod-service-account-defaultsa-nomountspec
Apr 30 08:14:13.107: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Apr 30 08:14:13.117: INFO: created pod pod-service-account-mountsa-nomountspec
Apr 30 08:14:13.117: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Apr 30 08:14:13.128: INFO: created pod pod-service-account-nomountsa-nomountspec
Apr 30 08:14:13.128: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 08:14:13.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-1626" for this suite.
Apr 30 08:14:53.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 08:14:53.344: INFO: namespace svcaccounts-1626 deletion completed in 40.19928768s

• [SLOW TEST:40.916 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 08:14:53.345: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr 30 08:14:53.403: INFO: Creating deployment "test-recreate-deployment"
Apr 30 08:14:53.412: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Apr 30 08:14:53.436: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Apr 30 08:14:55.453: INFO: Waiting deployment "test-recreate-deployment" to complete
Apr 30 08:14:55.459: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692208899, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692208899, loc:(*time.Location)(0x8a060e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63692208899, loc:(*time.Location)(0x8a060e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63692208899, loc:(*time.Location)(0x8a060e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d57d5ff7c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 30 08:14:57.466: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Apr 30 08:14:57.483: INFO: Updating deployment test-recreate-deployment
Apr 30 08:14:57.483: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr 30 08:14:57.590: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-4519,SelfLink:/apis/apps/v1/namespaces/deployment-4519/deployments/test-recreate-deployment,UID:0bec4548-6b20-11e9-924a-005056bc1aae,ResourceVersion:687780,Generation:2,CreationTimestamp:2019-04-30 08:14:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-04-30 08:15:03 +0000 UTC 2019-04-30 08:15:03 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-04-30 08:15:03 +0000 UTC 2019-04-30 08:14:59 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-c9cbd8684" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Apr 30 08:14:57.599: INFO: New ReplicaSet "test-recreate-deployment-c9cbd8684" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-c9cbd8684,GenerateName:,Namespace:deployment-4519,SelfLink:/apis/apps/v1/namespaces/deployment-4519/replicasets/test-recreate-deployment-c9cbd8684,UID:0e612dc7-6b20-11e9-924a-005056bc1aae,ResourceVersion:687779,Generation:1,CreationTimestamp:2019-04-30 08:15:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 0bec4548-6b20-11e9-924a-005056bc1aae 0xc0027d8ec0 0xc0027d8ec1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 30 08:14:57.599: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Apr 30 08:14:57.600: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7d57d5ff7c,GenerateName:,Namespace:deployment-4519,SelfLink:/apis/apps/v1/namespaces/deployment-4519/replicasets/test-recreate-deployment-7d57d5ff7c,UID:0bed6a13-6b20-11e9-924a-005056bc1aae,ResourceVersion:687769,Generation:2,CreationTimestamp:2019-04-30 08:14:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 0bec4548-6b20-11e9-924a-005056bc1aae 0xc0027d8de7 0xc0027d8de8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 30 08:14:57.606: INFO: Pod "test-recreate-deployment-c9cbd8684-cr5z9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-c9cbd8684-cr5z9,GenerateName:test-recreate-deployment-c9cbd8684-,Namespace:deployment-4519,SelfLink:/api/v1/namespaces/deployment-4519/pods/test-recreate-deployment-c9cbd8684-cr5z9,UID:0e625624-6b20-11e9-924a-005056bc1aae,ResourceVersion:687781,Generation:0,CreationTimestamp:2019-04-30 08:15:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-c9cbd8684 0e612dc7-6b20-11e9-924a-005056bc1aae 0xc0027d9720 0xc0027d9721}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xjzkk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xjzkk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xjzkk true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.101.13-slave,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027d9780} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027d97a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 08:15:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 08:15:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-30 08:15:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-30 08:15:03 +0000 UTC  }],Message:,Reason:,HostIP:10.10.101.13,PodIP:,StartTime:2019-04-30 08:15:03 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 08:14:57.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4519" for this suite.
Apr 30 08:15:03.646: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 08:15:03.829: INFO: namespace deployment-4519 deletion completed in 6.215940147s

• [SLOW TEST:10.484 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 08:15:03.830: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-0e8fa0a1-6b20-11e9-845c-f234dad8a085
STEP: Creating a pod to test consume configMaps
Apr 30 08:15:03.917: INFO: Waiting up to 5m0s for pod "pod-configmaps-0e90be34-6b20-11e9-845c-f234dad8a085" in namespace "configmap-5892" to be "success or failure"
Apr 30 08:15:03.943: INFO: Pod "pod-configmaps-0e90be34-6b20-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 26.1809ms
Apr 30 08:15:05.950: INFO: Pod "pod-configmaps-0e90be34-6b20-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033399947s
Apr 30 08:15:07.958: INFO: Pod "pod-configmaps-0e90be34-6b20-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040884883s
STEP: Saw pod success
Apr 30 08:15:07.958: INFO: Pod "pod-configmaps-0e90be34-6b20-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 08:15:07.963: INFO: Trying to get logs from node 10.10.101.13-slave pod pod-configmaps-0e90be34-6b20-11e9-845c-f234dad8a085 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 30 08:15:08.068: INFO: Waiting for pod pod-configmaps-0e90be34-6b20-11e9-845c-f234dad8a085 to disappear
Apr 30 08:15:08.072: INFO: Pod pod-configmaps-0e90be34-6b20-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 08:15:08.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5892" for this suite.
Apr 30 08:15:14.104: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 08:15:14.358: INFO: namespace configmap-5892 deletion completed in 6.278146837s

• [SLOW TEST:10.528 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr 30 08:15:14.360: INFO: >>> kubeConfig: /tmp/kubeconfig-610946863
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr 30 08:15:14.440: INFO: Waiting up to 5m0s for pod "downwardapi-volume-14d74ffd-6b20-11e9-845c-f234dad8a085" in namespace "projected-8436" to be "success or failure"
Apr 30 08:15:14.450: INFO: Pod "downwardapi-volume-14d74ffd-6b20-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 10.016273ms
Apr 30 08:15:16.458: INFO: Pod "downwardapi-volume-14d74ffd-6b20-11e9-845c-f234dad8a085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017672833s
Apr 30 08:15:18.466: INFO: Pod "downwardapi-volume-14d74ffd-6b20-11e9-845c-f234dad8a085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02610543s
STEP: Saw pod success
Apr 30 08:15:18.467: INFO: Pod "downwardapi-volume-14d74ffd-6b20-11e9-845c-f234dad8a085" satisfied condition "success or failure"
Apr 30 08:15:18.475: INFO: Trying to get logs from node 10.10.101.14-slave pod downwardapi-volume-14d74ffd-6b20-11e9-845c-f234dad8a085 container client-container: <nil>
STEP: delete the pod
Apr 30 08:15:18.520: INFO: Waiting for pod downwardapi-volume-14d74ffd-6b20-11e9-845c-f234dad8a085 to disappear
Apr 30 08:15:18.527: INFO: Pod downwardapi-volume-14d74ffd-6b20-11e9-845c-f234dad8a085 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr 30 08:15:18.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8436" for this suite.
Apr 30 08:15:24.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 30 08:15:24.724: INFO: namespace projected-8436 deletion completed in 6.18763168s

• [SLOW TEST:10.364 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.1-beta.0.44+b7394102d6ef77/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
Apr 30 08:15:24.724: INFO: Running AfterSuite actions on all nodes
Apr 30 08:15:24.742: INFO: Running AfterSuite actions on node 1
Apr 30 08:15:24.742: INFO: Skipping dumping logs from cluster

Ran 204 of 3584 Specs in 5631.356 seconds
SUCCESS! -- 204 Passed | 0 Failed | 0 Pending | 3380 Skipped PASS

Ginkgo ran 1 suite in 1h33m57.228265246s
Test Suite Passed
